{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcFatBIhzdu"
      },
      "source": [
        "## Development Notebook: build and test base layers for Anathem Transformer (aka Silo'd Transformer)\n",
        "\n",
        "### Notes\n",
        "- the google-minature models have the same vocab size and heads as bert-large-ucased\n",
        "- the minature-google papers discusses the classification and distallation tasks & corpus's including:\n",
        "    - *NLI* (Natural language inference involves classifying pairs of sentences (a premise and a hypothesis) as entailment, contradiction, or neutral. This task is representative of the scenario in which proxy data is non-trivial to gather (Gururangan et al., 2018). We chose MNLI (Williams et al., 2018) as our target dataset. Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "    - *sentiment analysis* -\n",
        "- the MTEB leader best model is e5-large (24 layers) which uses the CLS token. It is also \"instruction fine-tuned\", requiring query and passage prefixes.\n",
        "- distillation example: https://github.com/philschmid/knowledge-distillation-transformers-pytorch-sagemaker/blob/master/knowledge-distillation.ipynb\n",
        "    - they set temperature to 2: which results in a flatter probability distribution. I could make this dynamic -> start 0.5 progress to 1\n",
        "    - they set alpha to 0.5, which balances label-loss vs distil-loss\n",
        "\n",
        "#### Loss MLM - hf example:\n",
        "- https://github.com/huggingface/transformers/blob/601ac5b1dc1438f00d09696588f2deb0f045ae3b/src/transformers/modeling_bert.py#L1001-L1004\n",
        "    - notice that when initializing CrossEntropyLoss, the ignore index is -100, so, when I make the masked-token objective, I can compute the loss by masking out all -100?\n",
        "\n",
        "\n",
        "#### DataCollator for Masked MLM - hf example\n",
        "- https://github.com/huggingface/transformers/blob/ee88ae59940fd4b2c8fc119373143d7a1175c651/src/transformers/data/data_collator.py#L607\n",
        "\n",
        "\n",
        "# Dataset specifics\n",
        "\n",
        "### From the Google mini-architectures:\n",
        "- with labels: Williams 2018 (NLI-task): citation: https://aclanthology.org/N18-1101/; available at https://huggingface.co/datasets/multi_nli  \n",
        "    - how should I process these? [sep] or sentence pairs? or both?\n",
        "    - I could do sentence-pairs for teaching & labels, I guess (why not)\n",
        "    - I could also include concatenated text, stricly with labels (what would be the point of this though? Better sub-sectioning the input data, not so much a sentence-vector thing\n",
        "- with no-labels, used for teaching: Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "\n",
        "### 1) MLM Tasks\n",
        "- Pile (multi-domain, books, wiki, law, and more) - curate and remove twitter  \n",
        "    - see urls at: https://github.com/EleutherAI/the-pile/blob/master/the_pile/datasets.py\n",
        "    - https://the-eye.eu/public/AI/pile_preliminary_components/\n",
        "- Supplements to pile:  \n",
        "    - https://huggingface.co/datasets/him1411/EDGAR10-Q - numeric filings\n",
        "    - eloukas/edgar-corpus - annual reports (but it is in weird sections)\n",
        "    - LEDGAR .jsonl https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A - this can be streamed too\n",
        "    - Pile of Law - https://huggingface.co/datasets/pile-of-law/pile-of-law - but cannot be streamed\n",
        "- JanosAudran/financial-reports-sec - SEC financial reports in small sentences\n",
        "- RefinedWeb - a competitor to Pile, curated common-crawl - https://arxiv.org/abs/2306.01116\n",
        "- CNN_dailymail? ag_news?\n",
        "\n",
        "### A) Retrieval Tasks\n",
        "In general, what loss would I use for the QA & retrieval tasks? Distillation is obvious, but what about\n",
        "- SQUAD - has QA pairs - squad_v2\n",
        "    - good for distillation\n",
        "- ORCA - has GPT-like prompting QA pairs: https://huggingface.co/datasets/Open-Orca/OpenOrca/viewer/Open-Orca--OpenOrca/train?row=29\n",
        "- Simple-Wiki https://huggingface.co/datasets/embedding-data/simple-wiki - has paraphrases\n",
        "- embedding-data/coco_captions_quintets - multiple captions as paraphrases\n",
        "- embedding-data/simple-wiki - pairs of paraphrases from wikipedia\n",
        "- embedding-data/SPECTER - triplets of {anchor, pos, neg}, small headline-like snippets in technical /statistical /science fields\n",
        "- https://huggingface.co/embedding-data - has a lot of retrieval tasks\n",
        "- LLukas22/scidocs - titles and abstracts\n",
        "- LEDGAR - can possible do triplets on same label\n",
        "- Rahmaa/ElsevieR_ClEaN - possible relation between title and abstract\n",
        "- embedding-data/WikiAnswers - 25 question paraphrases (maybe no answers)\n",
        "\n",
        "### B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/  \n",
        "    - but see: wanicca/WikiHowQA-mnbvc - looks good\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- LLukas22/lfqa_preprocessed - question and answers 226k\n",
        "- gbharti/finance-alpaca (like FIQA - finance Q&A)\n",
        "- embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- sciq - science questions - see question and support\n",
        "- wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers\n",
        "- EnglishDictionary - auto convert \"What is the definition of X'?\n",
        "\n",
        "## C) NER tasks\n",
        "- tner/ontonotes5 - has > 12 entities and 59.9k\n",
        "- tner/multinerd - 23 entiteis and 157k test set - see also tner/wikineural which has a 98.8k training set?\n",
        "-\n",
        "\n",
        "\n",
        "# Teacher Models\n",
        "\n",
        "## Embeddings\n",
        "Mteb leaderboard\n",
        "\n",
        "- instructor-xl / large - this does best, but it prepends instructions that are domain specific (like science this, or wikipedia that.... it could be possible to do that with the Pile dataset, possible) https://huggingface.co/hkunlp/instructor-xl\n",
        "- https://huggingface.co/intfloat/e5-large-v2 - winner otherwise\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XS2jBKoMmMn"
      },
      "source": [
        "#### Playing Around with novel architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQy_iTw-1g8O",
        "outputId": "de93a59e-f393-43dc-fac3-abd799c56fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25 langdetect\n",
        "#%pip install langdetect\n",
        "from langdetect import detect\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyM4UGicwXON"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def has_many_errors(text, threshold=0.5):\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    # Get a list of misspelled words\n",
        "    misspelled = blob.words.spellcheck()\n",
        "\n",
        "    # Filter words that are not recognized\n",
        "    misspelled = [word[0] for word in misspelled if word[1] == '']\n",
        "\n",
        "    # Calculate the ratio of misspelled words to total words\n",
        "    misspelled_ratio = len(misspelled) / len(blob.words) if len(blob.words) > 0 else 0\n",
        "\n",
        "    return misspelled_ratio >= threshold\n",
        "\n",
        "# Example usage\n",
        "text1 = \"This is a sample English text with a few misspelled words.\"\n",
        "text2 = \"Thsi is a smaple Enlgish text wtih a feew misspeled wrdos.\"\n",
        "text3 = \"Это русский текст.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bExiVpB-wcrY",
        "outputId": "91346396-f9ff-4bd3-d90e-97beb29b8264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "    - ''\n",
            "**********************************************************************\n",
            "\n"
          ]
        },
        {
          "ename": "MissingCorpusError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/tokenizers.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m'''Return a list of sentences.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e8c4872f2514>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhas_many_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-51b26c3bdf83>\u001b[0m in \u001b[0;36mhas_many_errors\u001b[0;34m(text, threshold)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Get a list of misspelled words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmisspelled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspellcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Filter words that are not recognized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/blob.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mWordList\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mWordList\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mword\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \"\"\"\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWordList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_punc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/tokenizers.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, include_punc, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         _word_tokenizer.itokenize(sentence, include_punc=include_punc,\n\u001b[1;32m     72\u001b[0m                                 *args, **kwargs)\n\u001b[0;32m---> 73\u001b[0;31m         for sentence in sent_tokenize(text))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/base.py\u001b[0m in \u001b[0;36mitokenize\u001b[0;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m##### SENTIMENT ANALYZERS ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingCorpusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
          ]
        }
      ],
      "source": [
        "has_many_errors(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "bCv855u5Mlgr",
        "outputId": "1d562d9e-05a3-405e-fffa-e6301d59a2e2"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5f5cdcd6a5ec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataSet' from 'torch.utils.data' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, DataSet\n",
        "from typing import List, Optional\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "\n",
        "model_string = 'google/bert_uncased_L-12_H-512_A-8' # 'distilroberta-base\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "basemod = AutoModel.from_pretrained(model_string)\n",
        "basemod.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tNKrJaiXDvA"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "eNfU7szJWwfh",
        "outputId": "afd7de82-dcac-45b0-f9a1-4b874b1f529b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-761fa45d06d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomTokenizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google/bert_uncased_L-12_H-512_A-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cls_prepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, model_string='google/bert_uncased_L-12_H-512_A-8', n_cls_prepend = 4, n_pad_to_multiple_of=4):\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not (k[0]=='_' or k=='tokenize' or k=='encode' or k=='build_inputs_with_special_tokens' or k == 'batch_encode_plus'):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "\n",
        "        # run through base tokenizer\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens, return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        #batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "\n",
        "\n",
        "# Note, if I use the vanilla LineByLineTextDataset, it just calls tokenizer.__call__ turns on the `use_special_tokens`, and it pads to a multiple of optional\n",
        "# .. so somehow I need to ensure that, whatever base function it calls as part of the tokenizer pipeline, it will continue using MY new function\n",
        "# the tokenizer.__call__ DOES NOT use `encode` nor `tokenize` otherwise my modifications would manifest\n",
        "# looks like `prepare_for_model` (and maybe `batch_prepare_for_model`) is what adds special tokens?\n",
        "# looks like `prepare_for_model` just calls `build_inputs_with_special_tokens`, so maybe intervene there?\n",
        "#         if add_special_tokens:\n",
        "#            sequence = self.build_inputs_with_special_tokens(ids, pair_ids)\n",
        "#            token_type_ids = self.create_token_type_ids_from_sequences(ids, pair_ids)\n",
        "# editing `build_inputs_with_special_tokens` didn't work either\n",
        "\n",
        "# FOOFU:\n",
        "# see how .pad works: https://github.com/huggingface/transformers/blob/c5454eba9eac00a3e7d0a46a3d25aacd43187f1e/src/transformers/tokenization_utils_base.py#L2887\n",
        "# notice the `self.model_input_names[0]` list for a tokenizer -> I should update this for my unique inputs\n",
        "# ... and there is also a ._pad function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te7PvCnbvX-E"
      },
      "outputs": [],
      "source": [
        "tokenizer2 = CustomTokenizer()\n",
        "tokenizer2.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjHCfFlda8w"
      },
      "outputs": [],
      "source": [
        "#toks = tokenizer2.encode(text[0], add_special_tokens=True)\n",
        "#print(len(toks)) # works\n",
        "#print(toks[:10])\n",
        "\n",
        "tokens = tokenizer2(text, padding='longest', return_tensors=None) # doesn't work, obviously\n",
        "#print(tokens)\n",
        "print(len(tokens['input_ids'][0]))\n",
        "print(len(tokens['attention_mask'][0]))\n",
        "\n",
        "print(len(tokens['input_ids'][1]))\n",
        "print(len(tokens['attention_mask'][1]))\n",
        "\n",
        "tokens\n",
        "\n",
        "#tokenizer2.batch_encode_plus(text, add_special_tokens=True) # doesn't work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo5BhFq0kuJH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DToaqxfoM6bR"
      },
      "outputs": [],
      "source": [
        "dir(basemod)\n",
        "# base embedding layers\n",
        "layer_emb = copy.deepcopy(basemod._modules['embeddings'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha_xqtWlNIfI"
      },
      "outputs": [],
      "source": [
        "# base trasnformers (full)\n",
        "layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9OMlauFNTPZ"
      },
      "outputs": [],
      "source": [
        "# text\n",
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with legal issues1.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, willful misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "import math\n",
        "\n",
        "#padding_length = int(math.ceil(max_length / 4)) * 4\n",
        "tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "input_shape = tokens['input_ids'].size()\n",
        "\n",
        "# change token padding to be multiple of 4\n",
        "#ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "#if input_shape[-1]!=ideal_length:\n",
        "#  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "#  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "tokens['token_type_ids'] = token_type_ids\n",
        "past_key_values_length =0\n",
        "\n",
        "# need to extend attention mask\n",
        "extended_attention_mask = basemod.get_extended_attention_mask(tokens['attention_mask'], input_shape)\n",
        "tokens['extended_attention_mask'] = extended_attention_mask\n",
        "print(tokens.keys())\n",
        "print(tokens['input_ids'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4DF2F2y3WVs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIisgmAC3SgY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_PXX-SRjd7Mv",
        "outputId": "9be41735-2875-4ac5-ee8e-d0be3fbf3a2b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c65df7c427ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m silo_dimensions = {0:basemod.config.hidden_size,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   }\n\u001b[1;32m      5\u001b[0m \u001b[0mreintegration_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'basemod' is not defined"
          ]
        }
      ],
      "source": [
        "silo_dimensions = {0:basemod.config.hidden_size,\n",
        "                  1:basemod.config.hidden_size//2,\n",
        "                  2:basemod.config.hidden_size//4,\n",
        "                  }\n",
        "reintegration_dim = silo_dimensions[1] + silo_dimensions[2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XuMY6iaRNpOc",
        "outputId": "a9e272e9-2e80-4b29-dc62-536f42bd1334"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-40b0ed09dca5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_output = layer_emb(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'position_ids'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_emb' is not defined"
          ]
        }
      ],
      "source": [
        "embedding_output = layer_emb(\n",
        "            input_ids=tokens['input_ids'],\n",
        "            position_ids=tokens.get('position_ids',None),\n",
        "            token_type_ids=tokens['token_type_ids'],\n",
        "            inputs_embeds=None,\n",
        "            past_key_values_length=past_key_values_length\n",
        ")\n",
        "print(embedding_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3kgUzTJsO_1i",
        "outputId": "5d16b103-4d99-40de-8c0c-039faefd0e64"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-40a2b2d12b51>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# basemodel transformer outputs: *full bert model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m out_l1 = layer_basetransformer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extended_attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#tokens['attention_mask'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_basetransformer' is not defined"
          ]
        }
      ],
      "source": [
        "# basemodel transformer outputs: *full bert model\n",
        "out_l1 = layer_basetransformer(\n",
        "    hidden_states = embedding_output,\n",
        "    attention_mask = tokens['extended_attention_mask'],#tokens['attention_mask'],\n",
        "    head_mask=None,\n",
        "    encoder_hidden_states=None,\n",
        "    encoder_attention_mask=None,\n",
        "    #past_key_values=0,\n",
        "    #use_cache=None,\n",
        "    output_attentions=True,\n",
        "    #output_hidden_states=True,\n",
        "    #return_dict=True\n",
        ")\n",
        "\n",
        "hidden_states_l1 = out_l1[0]\n",
        "self_attention_l1 = out_l1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvj_XlNsTYXt"
      },
      "outputs": [],
      "source": [
        "# Next Layer:\n",
        "# Query -> max pool and reduce  hidden dimension // 2\n",
        "# Key -> reduce hidden_dim // 2\n",
        "# value -> reduce hidden_dim //2\n",
        "#maxpool_l2 = nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "maxpool_l2 = nn.Sequential(\n",
        "    nn.Dropout(0.05),\n",
        "    nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True),\n",
        ")\n",
        "\n",
        "maxpool_l2_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ5xAaELVuwk",
        "outputId": "b5dbf2f4-277d-4b55-97ac-0453fed2908d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n",
            "torch.Size([2, 24, 768])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 48])\n",
            "torch.Size([2, 1, 1, 48])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "# reduce dimension of hidden states\n",
        "hiddens_states_l1_reduced = maxpool_l2(hidden_states_l1)\n",
        "print(hidden_states_l1.shape)\n",
        "print(hiddens_states_l1_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l1_reduced = maxpool_l2_attn(tokens['attention_mask'].float())\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "print(input_shape)\n",
        "extended_attention_mask_l1_reduced = basemod.get_extended_attention_mask(attention_mask_l1_reduced, attention_mask_l1_reduced.shape)\n",
        "print(tokens['extended_attention_mask'].shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AcdIY3shHWN"
      },
      "outputs": [],
      "source": [
        "# Try to do Multi Headed attenion with differently sized query and value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYHtEQNFgh7U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "import copy\n",
        "\n",
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "bertlayer_l2_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")\n",
        "\n",
        "bertlayer_l3_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size // 2,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03mPp6aHgh9Y",
        "outputId": "e19aaf75-0247-498f-d967-2777f6f6df2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2 = bertlayer_l2_reduction(\n",
        "        hidden_states = hiddens_states_l1_reduced,\n",
        "        attention_mask = extended_attention_mask_l1_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l1,\n",
        "        encoder_attention_mask= tokens['extended_attention_mask'],\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "hidden_states_l2 = out_l2[0]\n",
        "print(hidden_states_l2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlN5aOsYgh_z",
        "outputId": "29b499c5-25ab-4dfb-de8e-ffc76c316e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12])\n",
            "torch.Size([2, 1, 1, 12])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Next dimension reduction:\n",
        "hiddens_states_l2_reduced = maxpool_l2(hidden_states_l2)\n",
        "print(hidden_states_l2.shape)\n",
        "print(hiddens_states_l2_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l2_reduced = maxpool_l2_attn(attention_mask_l1_reduced.float())\n",
        "print(attention_mask_l2_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "extended_attention_mask_l2_reduced = basemod.get_extended_attention_mask(attention_mask_l2_reduced, attention_mask_l2_reduced.shape)\n",
        "print(extended_attention_mask_l2_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  out_l3 = bertlayer_l3_reduction(\n",
        "        hidden_states = hiddens_states_l2_reduced, # input has been maxpooled\n",
        "        attention_mask = extended_attention_mask_l2_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l2,\n",
        "        encoder_attention_mask= extended_attention_mask_l1_reduced,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "  hidden_states_l3 = out_l3[0]\n",
        "  print(hidden_states_l3.shape)\n",
        "\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q-GTg2fgiCB",
        "outputId": "c44f4175-70a0-4e38-e774-ee10df37de88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"_name_or_path\": \"distilroberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.29.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "\n",
        "config_lowres_encoder = copy.deepcopy(basemod.config)\n",
        "config_lowres_encoder.hidden_size = config_lowres_encoder.hidden_size//4\n",
        "config_lowres_encoder.num_hidden_layers = 3\n",
        "print(config_lowres_encoder)\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "encoder_lowres = BertEncoder(config_lowres_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIN07S24_qp",
        "outputId": "bd44c178-932e-4c56-bfc8-56363ef9bff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "out_encoder_lowres = encoder_lowres(\n",
        "    hidden_states=hidden_states_l3,\n",
        "    attention_mask=extended_attention_mask_l2_reduced,\n",
        "    head_mask = None,\n",
        "    return_dict=True,\n",
        ")\n",
        "hidden_states_lowres = out_encoder_lowres[0]\n",
        "print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM75xap8L5cB"
      },
      "outputs": [],
      "source": [
        "## Upresolution Layer: up-resolution from dim-3 to dim-2 is as follows:\n",
        "# hs_l3 -> upsampled sequence-length as hs-l2\n",
        "# -> could have another attention-based mechanism that expands dimension of hs-l2\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "#hidden_states_upscaled_3to2_nearest = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='nearest').transpose(-2,-1)\n",
        "#hidden_states_upscaled_3to2_linear = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='linear').transpose(-2,-1)\n",
        "\n",
        "upscaler_x2 = InterpolateCombo(scale_factor=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfpn9mEsPPCf"
      },
      "outputs": [],
      "source": [
        "hidden_states_upscaled3to2 = upscaler_x2(hidden_states_lowres)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GXB-9waPBv_"
      },
      "outputs": [],
      "source": [
        "## BertAttentiveIntegrator\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edzAlaOIPDa5"
      },
      "outputs": [],
      "source": [
        "bertlayer_l3_to_l2_crossattn = BertCrossAttention(\n",
        "        config=basemod.config,\n",
        "        hidden_size=silo_dimensions[1],\n",
        "        hidden_size_query=silo_dimensions[2],\n",
        "        position_embedding_type=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMmeXSBoipPv",
        "outputId": "ffce4e9c-101b-4d90-c31e-ea81ce0828be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 192])\n",
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "print(hidden_states_upscaled3to2.shape)\n",
        "print(hidden_states_l2.shape)\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVMll5RTQyVh",
        "outputId": "5ac82f6c-dd52-4295-9534-159d0dd26ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2_postencode = bertlayer_l3_to_l2_crossattn(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "hidden_states_l2_postencode = out_l2_postencode[0]\n",
        "print(hidden_states_l2_postencode.shape)\n",
        "assert hidden_states_l2_postencode.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5HD6Rc7POU",
        "outputId": "17ff76a1-827c-4945-9ae6-92535113b493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n",
            "3072\n",
            "4.0\n"
          ]
        }
      ],
      "source": [
        "print(basemod.config.hidden_size)\n",
        "print(basemod.config.intermediate_size)\n",
        "print(basemod.config.intermediate_size/basemod.config.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_ElURFHWk3B"
      },
      "outputs": [],
      "source": [
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = query_hidden_states,\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeJysFTAgZm_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from low-res to mid-res\n",
        "bert_integrative_layer_midres = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[2],\n",
        "    intermediate_size=silo_dimensions[1]*4,\n",
        ")\n",
        "\n",
        "# from mid-res to high-res\n",
        "bert_integrative_layer_hires = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[0],\n",
        "    hidden_size_query=reintegration_dim,\n",
        "    intermediate_size=silo_dimensions[0]*4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcZ3MU-4hFN3",
        "outputId": "c521b9fe-1ccc-4e49-d8df-75f4801f795b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "hidden_states_midres = bert_integrative_layer_midres(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "print(hidden_states_midres.shape)\n",
        "assert hidden_states_midres.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iavtqpUohJAs",
        "outputId": "272bdcee-3341-41ea-bd80-87a1b6d0fe8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 576])\n"
          ]
        }
      ],
      "source": [
        "# upscale the l2 and l3 to the full dimension\n",
        "upscaler_x4 = InterpolateCombo(scale_factor=4)\n",
        "hidden_states_upscaled3to1 = upscaler_x4(hidden_states_lowres)\n",
        "hidden_states_upscaled2to1 = upscaler_x2(hidden_states_midres)\n",
        "\n",
        "hidden_states_upscaled = torch.cat(\n",
        "    (hidden_states_upscaled2to1, hidden_states_upscaled3to1),\n",
        "    axis=2)\n",
        "\n",
        "print(hidden_states_upscaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gDwXueYhJ1B",
        "outputId": "ed02eb22-18ea-4bce-91b2-bfc5ccf3ccd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n"
          ]
        }
      ],
      "source": [
        "# final layer to bring it up to full dimension\n",
        "hidden_states_hires = bert_integrative_layer_hires(\n",
        "    hidden_states = hidden_states_l1,\n",
        "    attention_mask = extended_attention_mask,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled,\n",
        "    query_attention_mask = extended_attention_mask\n",
        ")\n",
        "print(hidden_states_hires.shape)\n",
        "assert hidden_states_hires.shape == hidden_states_l1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv4ZVcYORoL_",
        "outputId": "df6aca9a-68c3-4cc4-c579-7fa0e8518c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_states_hires.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJQJVvdMle3v",
        "outputId": "3e4830ce-7b1c-4d9b-c584-947339137ee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 24])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_mask_l1_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Z0KGMfm-Mn"
      },
      "source": [
        "### The Reduce and Integrate layer:\n",
        "- this is like a Transformer block, but:\n",
        "- does dimension reduction along sequence and embedding-dim\n",
        "- includes a skip connection from previous hidden-states of the same dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExGOdKwWm_46"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# this is the layer that just does cross-attention between a seq-reduced query and full-size value and key\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "\n",
        "BertReduceAddIntegrativeLayer\n",
        "inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkiZo9Npm_xi"
      },
      "outputs": [],
      "source": [
        "# initialize the mid-resolution BertReduceAndIntegrate layer\n",
        "bert_reduce_add_integrate_midres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[1], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[0],\n",
        "    hidden_size_query=silo_dimensions[0],\n",
        "    intermediate_size=silo_dimensions[1]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")\n",
        "\n",
        "bert_reduce_add_integrate_lowres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[2], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[1],\n",
        "    intermediate_size=silo_dimensions[2]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxtTomiPxQn8",
        "outputId": "0d221d7e-a51b-4a93-af5f-a7f23af07e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_hires_reduced = maxpool_l2(hidden_states_hires)\n",
        "assert hidden_states_hires_reduced.shape[1] == hidden_states_midres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres.shape)\n",
        "hidden_states_midres = bert_reduce_add_integrate_midres(\n",
        "    inputs = hidden_states_hires, # from highres outputs previous layer (key, values)\n",
        "    hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask=None,\n",
        "    query_hidden_states = hidden_states_hires_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        ")\n",
        "print(hidden_states_midres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPGNtX3KxQuY",
        "outputId": "9a5d53a5-acf3-4255-b624-7aa38bf0ad9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12, 192])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_midres_reduced = maxpool_l2(hidden_states_midres)\n",
        "assert hidden_states_midres_reduced.shape[1] == hidden_states_lowres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  print(hidden_states_lowres.shape)\n",
        "  hidden_states_lowres = bert_reduce_add_integrate_lowres(\n",
        "      inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "      hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "      attention_mask = extended_attention_mask_l2_reduced,\n",
        "      head_mask=None,\n",
        "      query_hidden_states = hidden_states_midres_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        "  )\n",
        "  print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFdByXbYAz2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJAHT_SyxQwK"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from transformers.modeling_utiles import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQPJPPkpmibK"
      },
      "source": [
        "### Base-Layer nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbBLQZJJlu6n"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 2, # number of transformer stacks\n",
        "    scale_ratio2 = 0.5, # reduce sequence-length by X, from high-res to mid-res\n",
        "    scale_ratio3 = 0.25, # reduce sequence-length by Y, from high-res to low-res\n",
        "    multipler_intermediate2 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    multipler_intermediate3 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05, # dropout when performing downscaling from one-sequence length to next\n",
        "    use_cheap_integrator_for_stacks = [],\n",
        "    do_mlm=False,# whether to output MLM token predictions\n",
        "    do_cls=False,# whether to output a pooled sentence-vector for sequence classification\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config,'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks',num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multipler_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multipler_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", use_cheap_integrator_for_stacks)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        # cheap (non-transformer) method to integrate high- and mid-res hidden states\n",
        "        bert_integrative_layer_1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        # full Transformer layer as mid-to-highres upscaling\n",
        "        BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1//2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    bert_integrative_layer_1 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size,\n",
        "        hidden_size_query=config.query_size1,\n",
        "        intermediate_size=config.intermediate_size_l1\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_l1\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"attention\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled3to2        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_highres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_highres\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "class BertClassificationHead(nn.Module):\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "def tokenize_anathem(text, device=device):\n",
        "    #padding_length = int(math.ceil(max_length / 4)) *\n",
        "    tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "    input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    # change token padding to be multiple of 4\n",
        "    #ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "    #if input_shape[-1]!=ideal_length:\n",
        "    #  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "    #  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "    tokens['token_type_ids'] = token_type_ids\n",
        "    for k,v in tokens.items():\n",
        "        tokens[k] = v.to(device)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdRq7bM3pQhp",
        "outputId": "452ade89-f3b4-4404-ab8f-8442de7689bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#config = make_config('distilroberta-base')\n",
        "#config = make_config('t5-small') # can't use t5 because it uses relative\n",
        "config = make_config('google/bert_uncased_L-12_H-512_A-8') #\n",
        "\n",
        "if False:\n",
        "  (tokenizer,basemod,layer_embedding,layer_basetransformer,maxpool,maxpool_attn,bert_reducer_l2,\n",
        "   bert_reducer_l3,bert_encoder_lowres,upscaler_x2,upscaler_x4,bert_integrative_layer_2,bert_integrative_layer_1) = initialize(config)\n",
        "\n",
        "# make the basemod and tokenizer\n",
        "basemod = AutoModel.from_pretrained(config.model_string)\n",
        "basemod.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgEOUtHYoB-I"
      },
      "outputs": [],
      "source": [
        "# the Anathem encoder includes the embeddings and first transformer block\n",
        "anathem_encoder1 = AnathemBaseModule(config, basemod, tokenizer)\n",
        "anathem_encoder2 = AnathemMidModule(config, basemod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87RTY9a059mQ"
      },
      "outputs": [],
      "source": [
        "cls_head = BertClassificationHead(config, n_classes = 3, activation = 'none',device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-1aZOdgB_g8"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"* Welcome home to this gorgeously upgraded, beautifully maintained, three-bedroom home with double attached garage. Drive up to this quiet cul-de-sac and let the experience begin. On the main floor, you’ll notice the abundance of natural light. There is a separate office with view over the front of the property. The layout was customized, with a great open living space. The kitchen is a chef’s dream, with a breakfast bar, granite countertops, stainless steel appliance package, a pantry, and a view out to the sunny west facing yard.\",\n",
        "    \"There’s room for formal dining and the family room has a gas fireplace to relax by on the cooler nights. Out back, there’s a stunner of a deck, perfect for BBQ season! Upstairs, you’ll find a massive bonus room with tons of windows. There are two, secondary bedrooms and the master suite is amazing\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbt_zlrlCVEU"
      },
      "outputs": [],
      "source": [
        "tokens = tokenize_anathem(text,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XpXyV6YW4DI",
        "outputId": "6e4777a3-d95c-48ce-d799-2b761e72213c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#stack 1\n",
        "out1 = anathem_encoder1(\n",
        "      input_ids = tokens['input_ids'],\n",
        "      attention_mask = tokens['attention_mask'],\n",
        "      token_type_ids = tokens['token_type_ids']\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A87nQ24Ccoh",
        "outputId": "bbf75272-c1db-4da1-9543-acfe3832812b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.8376, -0.3891, -0.6668],\n",
              "        [-0.8747, -0.3621, -0.7735]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stack2\n",
        "out2 = anathem_encoder2(\n",
        "      hidden_states_highres = hidden_states[0],\n",
        "      hidden_states_midres = hidden_states[1],\n",
        "      hidden_states_lowres = hidden_states[2],\n",
        "      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out2\n",
        "\n",
        "cls_head(hidden_states[0], tokens['attention_mask'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQ9ABhkU8pE",
        "outputId": "76b0b2cb-196f-44c5-9079-4b9992a9835d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out1[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBi1G7ay63nr"
      },
      "outputs": [],
      "source": [
        "####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2L-jYJ6u4qd"
      },
      "outputs": [],
      "source": [
        "## Next steps, do something simple like sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLHCo5vZ-brJ"
      },
      "outputs": [],
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from scipy.special import softmax\n",
        "#datasets_list = list_datasets()\n",
        "#[k for k in datasets_list if 'phrasebank' in k]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "04db53bae1ea4e81a1acbad7401cd331",
            "81afc2262c8545dab41aacde91066b7d",
            "b96a361475c947e5a0f9e5f0f867ced7",
            "f697e928e02f405d99c43c4b1fd890c9",
            "6da885f236a24cf5a09add7c9927db76",
            "638f36ef35ec4ec88ba057c63093eca2",
            "4b35ff0e35ca4e6088f2f1f687ff924c",
            "e1c9ec9890384cb4b17139a7335e371e",
            "adef362bc525401c8b657d33dfec55ce",
            "f5912ed9e9c944e5ae35be20f0634165",
            "c7d86dc22b0747dba72d6aa5fd899df0"
          ]
        },
        "id": "rvjAv19p1Un6",
        "outputId": "a84e2ae7-d09e-49f8-b454-00f8c494fd17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset financial_phrasebank (/root/.cache/huggingface/datasets/financial_phrasebank/sentences_75agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04db53bae1ea4e81a1acbad7401cd331",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#[k for k in datasets_list if 'phrasebank' in k]\n",
        "\n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_75agree')\n",
        "\n",
        "# split\n",
        "idx_train, idx_val = train_test_split(np.arange(len(dataset['train']['sentence'])), test_size=0.1)\n",
        "dataset_train = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]}  for idx in idx_train]\n",
        "dataset_val = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]} for idx in idx_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_fRokuwB1h9",
        "outputId": "cbbc64cc-0bad-42bd-987c-aec7460b3960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3107\n",
            "346\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset_train)); print(len(dataset_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B86BY_m_x12"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"torch dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.data = dataset\n",
        "        self.n = len(self.data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        unit = self.data[idx]\n",
        "        return unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh3NKKrZ_xuX"
      },
      "outputs": [],
      "source": [
        "ds_train = MyDataset(dataset_train)\n",
        "ds_val = MyDataset(dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn4rR8QqEiS3"
      },
      "outputs": [],
      "source": [
        "batch_size_train = 12\n",
        "batch_size_val = 36\n",
        "lr = 0.00005\n",
        "eval_iter = 20\n",
        "n_epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9JPB6miBpQ9"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(ds_train, batch_size=batch_size_train, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=batch_size_val, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbhvjxbeKHh9"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(list(anathem_encoder1.parameters()) + list(anathem_encoder2.parameters()) + list(cls_head.parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "fPmQOT5OEnEY",
        "outputId": "cd172411-6a85-4bce-f076-9d03d8dc276f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:19: f1:0.402 (0.000); prec:0.352 (0.000); rec:0.469 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:39: f1:0.326 (0.000); prec:0.400 (0.000); rec:0.372 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:59: f1:0.459 (0.158); prec:0.531 (0.405); rec:0.485 (0.095)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:79: f1:0.506 (0.305); prec:0.583 (0.450); rec:0.494 (0.231)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:99: f1:0.499 (0.190); prec:0.555 (0.383); rec:0.551 (0.116)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:119: f1:0.552 (0.280); prec:0.663 (0.568); rec:0.534 (0.179)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:139: f1:0.661 (0.469); prec:0.708 (0.600); rec:0.636 (0.385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-d95d13a5603a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "optimizer.zero_grad()\n",
        "anathem_encoder1.train()\n",
        "anathem_encoder2.train()\n",
        "cls_head.train()\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "\n",
        "      # tokenize the batch\n",
        "      tokens = tokenize_anathem(batch['text'],device)\n",
        "      target = batch['label'].to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      out1 = anathem_encoder1(\n",
        "        input_ids = tokens['input_ids'],\n",
        "        attention_mask = tokens['attention_mask'],\n",
        "        token_type_ids = tokens['token_type_ids']\n",
        "      )\n",
        "      (hidden_states, extended_attention_masks) = out1\n",
        "\n",
        "      features,_ = anathem_encoder2(\n",
        "          hidden_states_highres = hidden_states[0],\n",
        "          hidden_states_midres = hidden_states[1],\n",
        "          hidden_states_lowres = hidden_states[2],\n",
        "          extended_attention_mask_highres = extended_attention_masks[0],\n",
        "          extended_attention_mask_midres = extended_attention_masks[1],\n",
        "          extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "      )\n",
        "\n",
        "      # prediction\n",
        "      preds = cls_head(features[0], tokens['attention_mask'])\n",
        "\n",
        "      # loss\n",
        "      loss = nn.functional.cross_entropy(preds, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # do evaluation\n",
        "      if ((iteration+1) % eval_iter)==0:\n",
        "          anathem_encoder1.eval()\n",
        "          anathem_encoder2.eval()\n",
        "          cls_head.eval()\n",
        "          # tokenize the eval\n",
        "          eval_logits = []\n",
        "          eval_targets = []\n",
        "          for i, batch_eval in enumerate(tqdm(dl_val, disable=True)):\n",
        "              with torch.no_grad():\n",
        "                  # tokenize the batch\n",
        "                  tokens_eval = tokenize_anathem(batch_eval['text'], device)\n",
        "                  labels_eval = batch_eval['label'].to(device)\n",
        "                  out_eval1 = anathem_encoder1(\n",
        "                      input_ids = tokens_eval['input_ids'],\n",
        "                      attention_mask = tokens_eval['attention_mask'],\n",
        "                      token_type_ids = tokens_eval['token_type_ids']\n",
        "                  )\n",
        "                  (hidden_states, extended_attention_masks) = out_eval1\n",
        "                  features,_ = anathem_encoder2(\n",
        "                      hidden_states_highres = hidden_states[0],\n",
        "                      hidden_states_midres = hidden_states[1],\n",
        "                      hidden_states_lowres = hidden_states[2],\n",
        "                      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "                  )\n",
        "                  # prediction\n",
        "                  batch_logits = cls_head(features[0], tokens_eval['attention_mask'])\n",
        "                  eval_logits+=batch_logits.detach().tolist()\n",
        "                  eval_targets+=labels_eval.detach().tolist()\n",
        "\n",
        "          eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)\n",
        "          print('E:%d; i:%d: f1:%0.3f (%0.3f); prec:%0.3f (%0.3f); rec:%0.3f (%0.3f)' % (epoch, iteration, eval_f1.mean(), eval_f1.min(), eval_prec.mean(), eval_prec.min(), eval_recall.mean(), eval_recall.min()))\n",
        "          cls_head.train()\n",
        "          anathem_encoder1.train()\n",
        "          anathem_encoder2.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVZ7tZ7JYSO",
        "outputId": "60a71e09-6d52-49f5-f42d-bf6cb36c9d2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZugKHbocDR0"
      },
      "source": [
        "## Test performance speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chS7dYV4cA2a",
        "outputId": "97dccd81-d967-42a4-de00-278241cc1dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for anathem: 33283328\n"
          ]
        }
      ],
      "source": [
        "# how many parameters in the model in total\n",
        "from math import prod\n",
        "nparam = 0\n",
        "for encoder in [anathem_encoder1, anathem_encoder2]:\n",
        "    for na,l in encoder.named_parameters():\n",
        "        nparam+=prod(l.data.shape)\n",
        "print('Number of parameters for anathem: %d' % nparam)\n",
        "# 33676544"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOKuhoSQgN28",
        "outputId": "118fbf58-b22a-4e63-ee9a-b5382eba30f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# compare this to distilbert\n",
        "#other_mod = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "other_mod = AutoModel.from_pretrained('google/bert_uncased_L-12_H-512_A-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNPeFA5gg-3u",
        "outputId": "c58db76c-2e88-4cf8-d1e1-ddc3ee70b194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for other-mod: 53982720\n"
          ]
        }
      ],
      "source": [
        "nparam = 0\n",
        "for na,l in other_mod.named_parameters():\n",
        "    nparam+=prod(l.data.shape)\n",
        "\n",
        "print('Number of parameters for other-mod: %d' % nparam)\n",
        "\n",
        "# number of parameters for anathem-trans: 33676544 (google/bert_uncased_L-12_H-512_A-8)\n",
        "# number of parametres for anathem-trans: 78973824 (includng 2 more mid-res encoders)\n",
        "# number of parameters for anathem-trans: 73062528 (with a 768 dimension)\n",
        "# Number of parameters for distilroberta: 82118400 (with a 768 dimension)\n",
        "# Number of parameters  all-MiniLM-L6-v2: 22713216\n",
        "# Number of parameters google/bert_uncased_L-12_H-512_A-8: 53982720 (512 dim, 12L)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En8rgr4mSNBt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIeQesGRSOKl"
      },
      "source": [
        "## Test Performance Speed at inference (CPU)\n",
        "- distilroberta-base: 10 batches: 23.517s , CPU\n",
        "- oogle/bert_uncased_L-12_H-512_A-8: 10 batches: 12.44s, CPU\n",
        "- anathem (distilroberta-768): 10 batches, 23.23s,\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 10 batches, ~7.5s, CPU\n",
        "\n",
        "## Test Performance Speed at inference (GPU)\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 30 batches, 0.79s, GPU\n",
        "- google/bert_uncased_L-12_H-512_A-8: 30 batches: 0.8 GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwXj277YTa71"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiKeaFEQKLUg",
        "outputId": "db5c7019-151b-4bc7-de75-6bacfd6d2e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8027215003967285\n"
          ]
        }
      ],
      "source": [
        "time1 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time2 = time.time()\n",
        "        print(time2-time1)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        (hidden_states, extended_attention_masks) = anathem_encoder1(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )\n",
        "        features,_ = anathem_encoder2(\n",
        "            hidden_states_highres = hidden_states[0],\n",
        "            hidden_states_midres = hidden_states[1],\n",
        "            hidden_states_lowres = hidden_states[2],\n",
        "            extended_attention_mask_highres = extended_attention_masks[0],\n",
        "            extended_attention_mask_midres = extended_attention_masks[1],\n",
        "            extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaHOImksIE4s",
        "outputId": "e25c00cc-a643-46ff-ed4f-a54be0b86c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7066085338592529\n"
          ]
        }
      ],
      "source": [
        "time3 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time4 = time.time()\n",
        "        print(time4-time3)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        out = basemod(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpDJu4TrGJme",
        "outputId": "3223ab06-d6db-4c25-da03-b33c72689884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.86464646, 0.52173913])"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kO-XYGLFCuk"
      },
      "outputs": [],
      "source": [
        "eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcAhKojQOKOt"
      },
      "source": [
        "## Variant: Possibly Faster Integrative Layer\n",
        "\n",
        "The above version uses a BertIntegrativeLayer that uses the high-res hidden-states as the key/values, and the upscaled-low res as the query\n",
        "\n",
        "This variant flips it: the high-res is the query (thereby upscaling via attention) and the low-res are the value and keys\n",
        "\n",
        "#### Varient #2 has slightly fewer parameters: 33283328 vs 336"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVu2yPrYDJrr",
        "outputId": "5a5aa9e0-a25a-41eb-a762-64ea010ce58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=912c71a09879d3cf51b9382dd9ef132640c98d05d4fc67b1a10e50e32f92892d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, rank_bm25, langdetect, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 langdetect-1.0.9 multiprocess-0.70.15 rank_bm25-0.2.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1 xxhash-3.3.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25 langdetect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxVyqa3vNlYc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForMaskedLM\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "import math\n",
        "from langdetect import detect\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, Optional, Sequence, Tuple, Union\n",
        "from transformers.utils import PaddingStrategy\n",
        "\n",
        "EncodedInput = List[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RILlmtI3NxD8"
      },
      "outputs": [],
      "source": [
        "class CustomTokenizer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    ):\n",
        "        # initialize the tokenizer from the base model\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        # how many cls tokens to prepend to the fullsize data\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not ((k[0]=='_') or (k in ['tokenize','encode','build_inputs_with_special_tokens','batch_encode_plus','encode_plus','pad'])):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "        self.downscale_multiple = downscale_multiple\n",
        "        # downscale attention\n",
        "        self.maxpool_attn = nn.MaxPool1d(\n",
        "            (self.downscale_multiple), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True\n",
        "        )\n",
        "\n",
        "        # ensure excess_token_ids are included for .pad operations\n",
        "        if 'excess_cls_ids' not in self.base_tokenizer.model_input_names:\n",
        "            self.base_tokenizer.model_input_names += ['excess_cls_ids']\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._batch_prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        # downscale the attention, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='excess_cls_ids'\n",
        "        )\n",
        "        return tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_tokenizer)\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [self.cls_token_id]*(n_cls_prepend-1)+tokens['input_ids'] + [self.pad_token_id]*self._num_pad_tokens(tokens['input_ids'])\n",
        "        tokens['excess_cls_ids'] = [0]*(n_cls_prepend)+tokens['attention_mask'][1:] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        tokens['attention_mask'] = [1]*(n_cls_prepend-1)+tokens['attention_mask'] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                tokens['token_type_ids'][0]\n",
        "            ]*(n_cls_prepend-1) + tokens['token_type_ids'] + [tokens['token_type_ids'][-1]]*self._num_pad_tokens(tokens['token_type_ids'])\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def _batch_prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['excess_cls_ids'] = [\n",
        "            [0]*(n_cls_prepend)+attnmask[1:] +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                # we use the token_type_ids\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def encode_plus(self, text, add_special_tokens=True, return_tensors=None, *args, **kwargs):\n",
        "        tokens = self.base_tokenizer.encode_plus(text, add_special_tokens=add_special_tokens, return_tensors=return_tensors, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "        return tokens\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "    def downscale_attention(self, tokens, downscale_multiple=None, name = 'attention_mask'):\n",
        "        \"\"\"\n",
        "        Reduces the sequence-dimenion by self.downscale_multiple using nn.maxpool\n",
        "        Adds the downscale attention to the tokens dictionary\n",
        "        \"\"\"\n",
        "        if downscale_multiple is None:\n",
        "            downscale_multiple = [self.downscale_multiple, self.downscale_multiple]\n",
        "\n",
        "        # fullsize attention\n",
        "        attn = tokens[name]\n",
        "        if not isinstance(attn, torch.Tensor):\n",
        "            attn = torch.Tensor(attn)\n",
        "\n",
        "        for i, mult in enumerate(downscale_multiple):\n",
        "            name_of_downsized_attn = '%s_l%d' % (name, i+2)\n",
        "            with torch.no_grad():\n",
        "                attn = self.maxpool_attn(attn.float())\n",
        "            tokens[name_of_downsized_attn] = attn\n",
        "        return tokens\n",
        "\n",
        "    def pad(\n",
        "        self,\n",
        "        encoded_inputs,\n",
        "        pad_to_multiple_of=4,\n",
        "        return_tensors=None,\n",
        "        padding: Union[bool, str, PaddingStrategy] = True,\n",
        "        max_length: Optional[int] = None,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Pad a list of tokenized-inputs to the same batch-length, with special processing of Anathem-specific inputs\"\"\"\n",
        "\n",
        "        # which are conventional inputs and which are anathem specific\n",
        "        conventional_input_nm = [k for k in encoded_inputs[0].keys() if k in ['input_ids', 'token_type_ids','attention_mask']]\n",
        "        unconventional_input_nm = [k for k in encoded_inputs[0].keys() if k not in conventional_input_nm]\n",
        "\n",
        "        # pad the vanilla inputs\n",
        "        conventional_encoded_inputs = self.base_tokenizer.pad([\n",
        "                {k:v for k,v in encoded_input.items() if k in conventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "            ], pad_to_multiple_of=pad_to_multiple_of, return_tensors=return_tensors, padding=padding, max_length=max_length, *args, **kwargs\n",
        "        )\n",
        "\n",
        "        # deal with the remaining inputs\n",
        "        padding_strategy, _, max_length, _ = self.base_tokenizer._get_padding_truncation_strategies(\n",
        "            padding=padding, max_length=max_length, verbose=False\n",
        "        )\n",
        "\n",
        "        #required_input = encoded_inputs[][self.model_input_names[0]]\n",
        "        # this is stupid, I need to pad each input in batch individually\n",
        "        special_anathem_inputs = [\n",
        "                {k:v for k,v in encoded_input.items() if k in unconventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "        ]\n",
        "        special_anathem_encoded_inputs = self.pad_special_anathem_inputs(\n",
        "            special_anathem_inputs=special_anathem_inputs,\n",
        "            encoded_inputs=conventional_encoded_inputs,\n",
        "            max_length=max_length,\n",
        "            padding_strategy=padding_strategy,#: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "            pad_to_multiple_of=pad_to_multiple_of,\n",
        "            return_tensors=return_tensors\n",
        "        )\n",
        "        # let's see if I can just insert into the conventional_encode_inputs\n",
        "        conventional_encoded_inputs.update(special_anathem_encoded_inputs) # apparently I can just append..\n",
        "\n",
        "        # downscale the attention and add to inputs\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='excess_cls_ids'\n",
        "        )\n",
        "        return conventional_encoded_inputs\n",
        "\n",
        "    def pad_special_anathem_inputs(\n",
        "        self,\n",
        "        special_anathem_inputs,\n",
        "        encoded_inputs,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None,\n",
        "        return_tensors=None,\n",
        "    ):\n",
        "        required_input = encoded_inputs[self.model_input_names[0]]\n",
        "        batch_size,max_length = required_input.shape\n",
        "        #print(batch_size,max_length)\n",
        "        assert batch_size == len(special_anathem_inputs)\n",
        "        assert isinstance(special_anathem_inputs, list)\n",
        "        padding_strategy = PaddingStrategy.MAX_LENGTH\n",
        "        special_anathem_batch_outputs = {}\n",
        "        for i in range(batch_size):\n",
        "            inputs = special_anathem_inputs[i] #{k: v[i] for k, v in special_anathem_inputs.items()}\n",
        "            assert isinstance(inputs, dict)\n",
        "            outputs = self._pad_special_anathem_input(\n",
        "                inputs,\n",
        "                max_length=max_length,\n",
        "                padding_strategy=padding_strategy,\n",
        "                pad_to_multiple_of=pad_to_multiple_of\n",
        "            )\n",
        "            for key, value in outputs.items():\n",
        "                if key not in special_anathem_batch_outputs:\n",
        "                    special_anathem_batch_outputs[key] = []\n",
        "                special_anathem_batch_outputs[key].append(value)\n",
        "\n",
        "        return BatchEncoding(special_anathem_batch_outputs, tensor_type=return_tensors) # returning because of failure\n",
        "\n",
        "    def _pad_special_anathem_input(\n",
        "        self,\n",
        "        special_anathem_input,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Pad encoded Anathem-specific inputs (on left/right and up to predefined length or max length in the batch)\n",
        "        \"\"\"\n",
        "        assert isinstance(special_anathem_input, dict)\n",
        "        len_required_input = len(special_anathem_input[list(special_anathem_input.keys())[0]])\n",
        "        if max_length is not None and pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
        "            max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
        "\n",
        "        needs_to_be_padded = padding_strategy != PaddingStrategy.DO_NOT_PAD and len_required_input != max_length\n",
        "\n",
        "        # Initialize attention mask if not present\n",
        "        if needs_to_be_padded:\n",
        "            special_anathem_outputs = dict.fromkeys(special_anathem_input.keys())\n",
        "            difference = max_length - len_required_input\n",
        "            if self.padding_side == \"right\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = special_anathem_input[k] + [0] * difference\n",
        "            elif self.padding_side == \"left\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = [0] * difference + special_anathem_input[k]\n",
        "            else:\n",
        "                raise ValueError(\"Invalid padding strategy:\" + str(self.padding_side))\n",
        "\n",
        "            return special_anathem_outputs\n",
        "        return special_anathem_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e2f772d1181b417e8f3bc2feee4f6e16",
            "825fb9aa19594a61b2a779837eb230b4",
            "b076eddbd7a74d5495615776c26a6f3e",
            "75d76bf886514ba5ac9fedee0fcfba8d",
            "e9685ee9b4aa47fcb5a3a79261ca87c7",
            "686aaeb98c1a4e688af5030963b8525e",
            "0a024ed7f3514fd6a544804a8bee0d78",
            "f230ba518eed434fb107f97c66293470",
            "1a7dd0c3112945959e9908425fcaa8b8",
            "80fd0e5e6b8f47c6a4c9557f127ef73b",
            "b963a45c28d1437f86109f283a370f38",
            "bdc7642ca3e748069974df4a510470ce",
            "1034a93ce59f439bb128b6c096eefdf2",
            "4a16335de26a43c09d578cbbe20e98d1",
            "573b3112cbee4ba581c18884df0a269e",
            "4fe04dcab6654d0594a56109e7eb6805",
            "c225230ea12f4f90bd461485f300580e",
            "4d3b7432f11a4a4b9eb444743d158c0d",
            "1d567e39c5ac4b9f8d9908111b04100f",
            "f619ea2b062a4eacb80ade328d56c2aa",
            "bc799bb2e34741fabc79181ea30ee78f",
            "a78c45e4929847f0a635988d1ef9d78f"
          ]
        },
        "id": "8TRaTA1dDv10",
        "outputId": "1b1d9054-f164-49ea-eb1e-300eb4223758"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f772d1181b417e8f3bc2feee4f6e16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc7642ca3e748069974df4a510470ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = CustomTokenizer(\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qTUF85MsPkS",
        "outputId": "ef24d6fc-34fa-4865-cbe4-800035ff05e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.base_tokenizer.model_input_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6pmDZa6D22L"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrb_tyIFXoz",
        "outputId": "388102cd-666c-41fd-c565-bdf683e416bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids 40\n",
            "input_ids [101, 101, 101, 101, 1037, 3115, 103, 11075, 2003, 1037, 23701, 6299, 11075, 2008, 2163, 2008, 2028, 2283, 2180, 1005, 1056, 2907, 1996, 2060, 20090, 2005, 12394, 1010, 6409, 1010, 2030, 5366, 3378, 2007, 3314, 1012, 102, 0, 0, 0]\n",
            "token_type_ids 40\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 40\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "excess_cls_ids 40\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "input_ids 48\n",
            "input_ids [101, 101, 101, 101, 2009, 2788, 3774, 1997, 2048, 3787, 1024, 1037, 9495, 2724, 2030, 25652, 1998, 1037, 103, 14987, 1012, 1996, 9495, 2724, 2030, 25652, 2003, 1996, 103, 1997, 1996, 3820, 1010, 23337, 1010, 2030, 27988, 1997, 1996, 27427, 6633, 3490, 14116, 2283, 2030, 2049, 18460, 102]\n",
            "token_type_ids 48\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 48\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "excess_cls_ids 48\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "---\n",
            "CONVENTIONAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "SPECIAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "input_ids 2\n",
            "48\n",
            "48\n",
            "token_type_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask 2\n",
            "48\n",
            "48\n",
            "excess_cls_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask_l2 2\n",
            "24\n",
            "24\n",
            "attention_mask_l3 2\n",
            "12\n",
            "12\n",
            "excess_cls_ids_l2 2\n",
            "24\n",
            "24\n",
            "excess_cls_ids_l3 2\n",
            "12\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "# FOOFU\n",
        "# in the vanilla DataCollatorForLanguageModelling, if the data is pretokenized (unpadded)\n",
        "#    then collator will simply \"pad\", the input_ids and the attention_mask (but not the generated excess_cls_ids, nor the attention_mask_l2 or l3)\n",
        "#    ... but, I created these _l2,_l3 assuming that everything was already padded properly\n",
        "# so, adding excess_token_ids to _model_names_inputs (or whatev, doesn't automatically cause the behaviour I wanted)\n",
        "# the error is because the _pad specifically only handles special_token_ids and token_type_ids in a very specific way\n",
        "#... there is no generic list_of_names to enforce padding of generic inputs.\n",
        "\n",
        "# options:\n",
        "# --- make an updated \"pad\" function for the tokenizer, that will likewise apply padding\n",
        "tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "\n",
        "for tok in tokens:\n",
        "    for k,v in tok.items():\n",
        "        print(k,len(v))\n",
        "        print(k,v)\n",
        "print('---')\n",
        "\n",
        "pad_out = tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt')\n",
        "print('CONVENTIONAL')\n",
        "print(pad_out)\n",
        "\n",
        "#for k,v in tokenizer.base_tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt').items():\n",
        "print('SPECIAL')\n",
        "print(pad_out)\n",
        "for k,v in pad_out.items():\n",
        "    print(k, len(v))\n",
        "    for j in v:\n",
        "        print(len(j))\n",
        "\n",
        "\n",
        "# still need to do: reduce attention_mask\n",
        "# return as tensor\n",
        "# merge and make a BatchEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxawLdRdHStR",
        "outputId": "e76fe1b0-3584-48a0-db64-806542ac0c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pad_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3WljX9NzSW"
      },
      "outputs": [],
      "source": [
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n",
        "try:\n",
        "    from transformers.modeling_utils import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbXNphafOX2i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size= self.hidden_size, # high dim output\n",
        "            hidden_size_query = self.hidden_size_query, # high dim query\n",
        "            hidden_size_keyvalue = self.hidden_size_keyvalues, # low-dim keyvalues\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        keyvalue_hidden_states: torch.Tensor=None, # low-res hidden-states (1/2 seq-dim) used for key-value pairs\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to query\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = keyvalue_hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = torch.cat((hidden_states, query_to_concat_hidden_states),axis=2),\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "        assert cross_hidden_states.shape[1]==hidden_states.shape[1], f\"{cross_hidden_states.shape[1]},{cross_hidden_states.shape[2]} vs {hidden_states.shape[1]},{hidden_states[2]}\"\n",
        "        assert cross_hidden_states.shape[2]==hidden_states.shape[2]\n",
        "\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.output_attn(cross_hidden_states)\n",
        "        cross_hidden_states = self.dropout_attn(cross_hidden_states)\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        intermediate_states = self.intermediate(intermediate_states)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        out_states = self.output_intm(intermediate_states)\n",
        "        out_states = self.dropout_intm(out_states)\n",
        "        out_states = self.lnorm_intm(out_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOl85thAOiu3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class CheapMLPIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Cheap (non-transformer) Integrator layer that merges a (low-res) layers with higher-res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues=None, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        if hidden_size_keyvalues is None:\n",
        "            hidden_size_keyvalues = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(2*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # expand hidden-size to a multiple\n",
        "        self.dense_expander = nn.Linear(\n",
        "            self.hidden_size_query,\n",
        "            self.intermediate_size\n",
        "        ) # deflate back to same size as hidden-state\n",
        "        self.dense_deflator = nn.Linear(\n",
        "            self.intermediate_size,\n",
        "            self.hidden_size\n",
        "        )\n",
        "\n",
        "        # intermediate activation function\n",
        "        self.intermediate_act_fn = nn.RReLU(0.0625, 0.125)\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.lnorm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask = None, # ignored\n",
        "        head_mask = None, # ignored\n",
        "        keyvalue_hidden_states =None, # ignored\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to hidden_states\n",
        "        query_attention_mask = None, # ignored\n",
        "        past_key_value = None, # ignored\n",
        "        output_attentions = False, # ignored\n",
        "    ) -> torch.Tensor:\n",
        "\n",
        "        # concat (lowres) to hidden-states\n",
        "        inputs = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        # expand x2 dimension\n",
        "        intermediate_states = self.dense_expander(inputs)\n",
        "        # activation (leaky relue)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        # like BertOutput\n",
        "        out_states = self.dense_deflator(intermediate_states)\n",
        "        # dropout\n",
        "        out_states = self.dropout(out_states)\n",
        "        # combine with hidden-state inputs\n",
        "        out_states = self.lnorm(out_states + hidden_states)\n",
        "\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo-LWT_jOFNa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    sequence_classification_intermediate_dim = None, # default is the same as the basemodel hidden-dim\n",
        "    sequence_classification_out_dim = None, # default is x2 same as the basemodel hidden-dim\n",
        "    do_mlm =False,\n",
        "    do_cls = False\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config, 'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks', num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multiplier_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multiplier_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", do_cheap_integrator)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # hidden dimension\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_intermediate_dim\",\n",
        "        sequence_classification_intermediate_dim  if sequence_classification_intermediate_dim is not None else [\n",
        "            int(base_config.hidden_size*s)\n",
        "            for s in [1, scale_ratio2, scale_ratio3]\n",
        "        ]\n",
        "    )\n",
        "    # final dimension outputed for sequence classification\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_out_dim\",\n",
        "        sequence_classification_out_dim  if sequence_classification_out_dim is not None else base_config.hidden_size*2\n",
        "    )\n",
        "\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None, stack_id=1):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: from low-res to mide-res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    if not do_cheap_integrator:\n",
        "        # from mid-res to high-res\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "\n",
        "def initialize_finaltransformerlayers(config, basemod=None, tokenizer=None, names_encoder_module = 'encoder', stack_id=3):\n",
        "    \"\"\"Initializes the final BertLayer before output, but copying the final BertLayer from `Basemod`\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    assert basemod is not None, \"`initialize_finaltransformerlayers` requires the basemod to instantiate the final transformer block\"\n",
        "\n",
        "    # get the Encoder stacks\n",
        "    assert names_encoder_module in basemod._modules.keys(), 'expected %s in basemod._modules' % names_encoder_module\n",
        "    basemod_encoder_stack = get_to_bertlayer(basemod, target_layer_name = names_encoder_module)\n",
        "\n",
        "    # get the name of the final transformer block (-1) in encoder\n",
        "    names_of_final_transformer_block = list(basemod_encoder_stack._modules['layer']._modules.keys())[-1]\n",
        "\n",
        "    # get the final transformer block (NN weights pretrained)\n",
        "    bert_finaltransformer_block = basemod_encoder_stack._modules['layer']._modules[\n",
        "        names_of_final_transformer_block\n",
        "    ]\n",
        "\n",
        "    return copy.deepcopy(bert_finaltransformer_block)\n",
        "\n",
        "def get_to_bertlayer(basemod, target_layer_name = 'encoder', model_string = None):\n",
        "    \"\"\"Clumsily locates a particular layer within a pretrained bert model\"\"\"\n",
        "    if  target_layer_name in basemod._modules.keys():\n",
        "        return basemod._modules[target_layer_name]\n",
        "    elif target_layer_name in basemod._modules['bert']._modules.keys():\n",
        "        return basemod._modules['bert']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L79IXfrOKEs"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None,\n",
        "            stack_id=0\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer, stack_id=0)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        self.stack_id = 0\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l3,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        #hidden_states_upscaled = torch.cat((\n",
        "        #    hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        #),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l2,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1,\n",
        "            query_attention_mask = extended_attention_mask_l2\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "                (attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"extended_attention_masks\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "            \"attention_masks\":(attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "            stack_id = 1\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer, stack_id)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_lowres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2\n",
        "        )\n",
        "        #hidden_states_midres = self.bert_integrative_layer_2(\n",
        "        #    hidden_states = hidden_states_l2,\n",
        "        #    attention_mask = extended_attention_mask_midres,\n",
        "        #    head_mask = None,\n",
        "        #    query_hidden_states = hidden_states_upscaled3to2)\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        #hidden_states_upscaled = torch.cat((hidden_states_upscaled2to1, hidden_states_upscaled3to1),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_midres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1\n",
        "        )\n",
        "\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemEncoder(nn.Module):\n",
        "    \"\"\"Anathem cores stacks of layers, from embeddings to final transformer block\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # initialize embedings and first stack\n",
        "        self.anathem_base_stack = AnathemBaseModule(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            past_key_values_length,\n",
        "            device,\n",
        "        )\n",
        "\n",
        "        # initialize all subsequence stacks\n",
        "        self.anathem_mid_stack = nn.ModuleList([\n",
        "            AnathemMidModule(\n",
        "                config,\n",
        "                basemod,\n",
        "                tokenizer,\n",
        "                past_key_values_length,\n",
        "                device,\n",
        "                stack_id = i\n",
        "            ) for i in range(1, self.config.num_transformer_stacks)\n",
        "        ])\n",
        "\n",
        "        # initialize the final transformer modules\n",
        "        self.final_transformer_block = initialize_finaltransformerlayers(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            stack_id=self.config.num_transformer_stacks+1\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = False,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        output_hidden_states: Optional[bool] = False,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # embed and run through first stack of transformers\n",
        "        hidden_states, extended_attention_masks, attention_masks = self.anathem_base_stack(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2,\n",
        "            attention_mask_l3=attention_mask_l3,\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "\n",
        "        # middle stack of transformers\n",
        "        for i, anathem_stack in enumerate(self.anathem_mid_stack):\n",
        "\n",
        "            # run through each stack (1-2)\n",
        "            hidden_states, extended_attention_masks = anathem_stack(\n",
        "                hidden_states_highres = hidden_states[0],\n",
        "                hidden_states_midres = hidden_states[1],\n",
        "                hidden_states_lowres = hidden_states[2],\n",
        "                extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "            )\n",
        "\n",
        "        # hidden states (high,med,low resolution)\n",
        "        hidden_states_highres, hidden_states_midres, hidden_states_lowres = hidden_states\n",
        "\n",
        "        # run through final transformer block (pretrained)\n",
        "        out_final = self.final_transformer_block(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_masks[0],\n",
        "            head_mask=None,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        #print(type(out_final))\n",
        "        #print(len(out_final))\n",
        "        hidden_states_highres = out_final[0]\n",
        "        if not output_attentions:\n",
        "            return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks\n",
        "\n",
        "        attention_final = out_final[1]\n",
        "        return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks, attention_final\n",
        "\n",
        "\n",
        "class BertGenericClassificationHead(nn.Module):\n",
        "    \"\"\"Instantiates a basic classification head that takes the CLS token and mean of the final layer for classification\"\"\"\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "class AnathemMultiSiloPooler(nn.Module):\n",
        "    \"\"\"\n",
        "    Pools the token-embeddings along the sequence dimenions for a final sentence-vector.\n",
        "    The pooling occuras across all three 'silos'\n",
        "    The pooling consists of the CLS token as well as mean pooling, concatenated token\n",
        "    Use the pooling outputs prior to any sequenceClassification\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        dim_out = None,\n",
        "        mean_activation = nn.Tanhshrink,\n",
        "        out_activation = None,\n",
        "        dims_in = None,\n",
        "        p_dropout=None,\n",
        "        device=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # dimensions of the hiddens states being processed as inputs\n",
        "        if dims_in is None:\n",
        "            try:\n",
        "                dims_in = config.sequence_classification_intermediate_dim\n",
        "            except:\n",
        "                dims_in = [dim_out, dim_out//2, dim_out//4]\n",
        "        self.dims_in = dims_in\n",
        "        self.dim_in = sum(dims_in)\n",
        "        self.hidden_size = config.hidden_size\n",
        "        if dim_out is None:\n",
        "            try:\n",
        "                dim_out = config.sequence_classification_out_dim\n",
        "            except:\n",
        "                dim_out = config.hidden_size*2\n",
        "        self.dim_out = dim_out\n",
        "        self.mean_activation = mean_activation\n",
        "\n",
        "        #self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if out_activation == 'none' or out_activation is None:\n",
        "            self.activation = lambda x: x\n",
        "        elif out_activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif out_activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif out_activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "        # linear layer operating on the concatenated CLS tokens from all silos\n",
        "        self.cls_pooler = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            nn.Linear(self.dim_in, int(self.hidden_size)),\n",
        "        )\n",
        "\n",
        "        # pre-mean-pooling (one for each silo)\n",
        "        #self.pre_poolers = [nn.Sequential(\n",
        "        #    nn.Dropout(p_dropout),\n",
        "        #    nn.Linear(dim,dim)\n",
        "        #    ) for dim in self.dims_in\n",
        "        # ]\n",
        "        self.pre_poolers = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            self.mean_activation\n",
        "        )\n",
        "\n",
        "        # sequential layer to concatenate the mean tokens from multiple tokens\n",
        "        self.mean_pooler = nn.Linear(self.dim_in, self.hidden_size)\n",
        "\n",
        "    def forward(self, hidden_states, attention_masks, excess_cls_ids=None) -> torch.Tensor:\n",
        "        \"\"\"Combines CLS token and mean-pooling for the sentence-vectorization\"\"\"\n",
        "\n",
        "        # CLS/first-tokens from all silos, all concatenated together\n",
        "        first_token_tensors = self._get_cls_tokens_all_silos(hidden_states)\n",
        "\n",
        "        # mean pooling\n",
        "        mean_pooled_tensors = self._mean_pool_all_silos(hidden_states, attention_masks, excess_cls_ids)\n",
        "\n",
        "        # concatenate CLS and mean\n",
        "        pooled_output = torch.concat((first_token_tensors, mean_pooled_tensors), axis=1)\n",
        "\n",
        "        return self.activation(pooled_output)\n",
        "\n",
        "    def _get_cls_token(self, hidden_state):\n",
        "        \"\"\"Grabs the CLS token from a hidden-states\"\"\"\n",
        "        return hidden_state[:, 0]\n",
        "\n",
        "    def _get_cls_tokens_all_silos(self, hidden_states):\n",
        "        \"\"\"Grabs the CLS token from all hidden_states\"\"\"\n",
        "        first_tokens = [\n",
        "            self._get_cls_token(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "        # concat all first tokens\n",
        "        all_first_tokens_cat = torch.cat(first_tokens,axis=1)\n",
        "        # run the concatenated first-tokens through Dense\n",
        "        all_first_tokens_out = self.cls_pooler(all_first_tokens_cat)\n",
        "        return all_first_tokens_out\n",
        "\n",
        "    def _mean_pool(self, hidden_state, attention_mask=None, excess_cls_id=None):\n",
        "        \"\"\"Pool along a sequence dimension (for just one silo)\"\"\"\n",
        "        if excess_cls_id is None:\n",
        "            excess_cls_id = attention_mask\n",
        "        input_mask_expanded = excess_cls_id.unsqueeze(-1).expand(hidden_state.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        return sum_embeddings / sum_mask\n",
        "\n",
        "    def _mean_pool_all_silos(self, hidden_states, attention_masks=None, excess_cls_ids=None):\n",
        "        \"\"\"Pool along a sequence dimension (for all silos)\"\"\"\n",
        "        if excess_cls_ids is None:\n",
        "            excess_cls_ids = attention_masks\n",
        "\n",
        "        # pre-pool: dense-layer before pooling\n",
        "        hidden_states = [\n",
        "            self.pre_poolers(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "\n",
        "        # mean pool each silo\n",
        "        mean_pooled_states = [\n",
        "            self._mean_pool(\n",
        "                hidden_state=hidden_state, excess_cls_id=excess_cls_id\n",
        "            ) for hidden_state, excess_cls_id\n",
        "            in zip(hidden_states, excess_cls_ids)\n",
        "        ]\n",
        "\n",
        "        # concat all mean-pooled states\n",
        "        all_mean_pooled_states = torch.cat(mean_pooled_states,axis=1)\n",
        "        # run the concatenated meanpooled states through Dense\n",
        "        all_mean_pooled_states = self.mean_pooler(all_mean_pooled_states)\n",
        "        return all_mean_pooled_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J18VNXqTYNY2"
      },
      "outputs": [],
      "source": [
        "class AnathemTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=None,\n",
        "        device=None,\n",
        "        do_mlm = None,\n",
        "        do_cls = None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # default config\n",
        "        if config is None:\n",
        "            config = make_config()\n",
        "        self.config = config\n",
        "        self.do_mlm = config.do_mlm if do_mlm is None else do_mlm\n",
        "        self.do_cls = config.do_cls if do_cls is None else do_cls\n",
        "\n",
        "        # device\n",
        "        if device is None:\n",
        "            if torch.cuda.is_available():\n",
        "                device = torch.device('cuda')\n",
        "            else:\n",
        "                device = torch.device('cpu')\n",
        "        self.device= device\n",
        "\n",
        "        # get the basemodel (and its masked LM head\n",
        "        self.model_string = self.config.model_string\n",
        "        basemodelLM_pretrained = AutoModelForMaskedLM.from_pretrained(self.model_string)\n",
        "\n",
        "        # get the Pretrained BertEncoder\n",
        "        basemod_pretrained = get_to_bertlayer(\n",
        "            basemodelLM_pretrained,\n",
        "            target_layer_name = 'encoder'\n",
        "        )\n",
        "\n",
        "        # make the tokenizer (based on pretrained)\n",
        "        self.tokenizer = CustomTokenizer(\n",
        "            model_string=self.config.model_string,\n",
        "            n_cls_prepend = int(1/config.scale_ratio3),\n",
        "            n_pad_to_multiple_of= int(1/config.scale_ratio3)\n",
        "        )\n",
        "\n",
        "        # make the Embedding and first layers (pretrained)\n",
        "        self.encoder = AnathemEncoder(\n",
        "            self.config,\n",
        "            basemod=basemod_pretrained,\n",
        "            tokenizer=self.tokenizer ,\n",
        "            past_key_values_length = None,\n",
        "            device=self.device,\n",
        "        )\n",
        "\n",
        "        # get the Pretrained maskedLM head\n",
        "        if self.do_mlm:\n",
        "            # perform maskedLM\n",
        "            self.mlm = get_to_bertlayer(\n",
        "                basemodelLM_pretrained,\n",
        "                target_layer_name = 'cls'\n",
        "            )\n",
        "        else:\n",
        "            self.mlm = lambda x : x\n",
        "\n",
        "        # make the sequence-classification head\n",
        "        if self.do_cls:\n",
        "            self.pooler = AnathemMultiSiloPooler(\n",
        "                config=self.config,\n",
        "                mean_activation = nn.Tanhshrink(),\n",
        "                dims_in = self.config.sequence_classification_intermediate_dim,\n",
        "                p_dropout=self.config.hidden_dropout_prob,\n",
        "                device=self.device\n",
        "            )\n",
        "\n",
        "    def _get_name(self):\n",
        "        return 'ANATHEM_MODEL_FOR_MLM'\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l2: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l3: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # run through base-layer (embeddings, transformer-block, 1 anathem stack)\n",
        "        outputs_encoder = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2, # optional downsized attention mask for sequence-dim 1/2\n",
        "            attention_mask_l3=attention_mask_l3, # optional downsized attention mask for sequence-dim 1/4\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=False\n",
        "        )\n",
        "        if output_attentions:\n",
        "            hidden_states, extended_attention_masks, attention = outputs_encoder\n",
        "        else:\n",
        "            hidden_states, extended_attention_masks = outputs_encoder\n",
        "            attention = None\n",
        "\n",
        "        out_mlm = {'logits':None}\n",
        "        out_pooled_vector = None\n",
        "        hidden_states_highres, hidden_states_midres, hiddenstates_lowres = hidden_states\n",
        "\n",
        "        # MLM outputs\n",
        "        if self.do_mlm:\n",
        "            out_mlm = self.mlm(hidden_states_highres)\n",
        "\n",
        "        # sequence pooling (for classification)\n",
        "        if self.do_cls:\n",
        "            out_pooled_vector = self.pooler(\n",
        "                hidden_states=hidden_states,\n",
        "                attention_masks=(attention_mask, attention_mask_l2, attention_mask_l3),\n",
        "                excess_cls_ids=(excess_cls_ids, excess_cls_ids_l2, excess_cls_ids_l3)\n",
        "            )\n",
        "        #\n",
        "        if return_dict:\n",
        "            return {\n",
        "                'hidden_states':(hidden_states_highres, hidden_states_midres, hiddenstates_lowres),\n",
        "                'pooled':out_pooled_vector,\n",
        "                'logits':out_mlm['logits'],\n",
        "                'attention':attention,\n",
        "                'extended_attention_masks':extended_attention_masks\n",
        "            }\n",
        "        return hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fb064cacf0e243299a2d092facae8c79",
            "be7af49d0afe4ecdaa800be969d5a3e7",
            "560c716068a645d596cc2fe9b886c0ad",
            "08c60bb508854cc9b6772ab78502b6fb",
            "e84136de295d4d39b44c908ff2458ba9",
            "2166426a7a224f1da2065f3221463693",
            "77d712d32c0f491cb9a58df33b012b0c",
            "235afab600844a9f8ef8f45cdba142e0",
            "c7537c19825a49cd8f3343c153fe56ef",
            "497aad7b9ab34f158382033f65d9a8c9",
            "814c0fc7e64c49bfa85d5087d1e07cb4"
          ]
        },
        "id": "jYu06BPCY1Oz",
        "outputId": "a8d0df70-d7a6-47ac-ab3a-e6377dd18a37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb064cacf0e243299a2d092facae8c79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelstring_teacher_mlm = 'bert-base-uncased'\n",
        "model_string = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "\n",
        "config = make_config(\n",
        "    modelstring = model_string,\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    do_mlm=True,\n",
        "    do_cls=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496,
          "referenced_widgets": [
            "19e70f5c3ae04d4b8b4a86c1233418be",
            "c7fcfc2727db445695b908ffd3370feb",
            "546b278b05e643a4905055d1d7ffeea5",
            "289aa49d154a496d9804cf30545bc5fc",
            "f54be5e820704ad2b31b6b7a6b946181",
            "8a0851189dae4fbdb953f6afe6f3ba29",
            "01f4a70e089f4fe5abb0d9246aeee403",
            "195b549a3cd745ffbe55e24f5865b1da",
            "fe156388571b4c63b5fc5f5ca857e522",
            "36c0e136fa3f400bab5deec7a0aff11f",
            "bcee86d4105743f5a69c595029994bc8",
            "9c8b871e03af41ada7990e7b76084f84",
            "33ae5a6ee9244aeea02e10990e8dd3da",
            "470a84311bbf40c6ae6322d6edc353ae",
            "8974203b2bde4395b3144ffe61596643",
            "d4ea11ee38044f7cb7ffe1a5b018bda7",
            "5f1b9961c6b14a1a92f3cb2c82883a17",
            "dfd3f1f64d81471083416a3e4ca6aa60",
            "9568bdb74f3e450f91b3558cf5ad5da1",
            "b7b946e1ad95455b818512986f83f7cd",
            "5fdca1f2b388437fac7624c0eca1ec26",
            "1c00f260ca44415c9c2cc342c9cab470",
            "476c5672e7784cda8255af2049de1ecd",
            "73e2bfea29de4c47b0c60590deff9771",
            "4326c46139fd4b6882d864400e35a9bc",
            "a53d537c8c0e48d1a77fbc22e5c41402",
            "4eba976ecf5145e0a60cc8a838bff5c9",
            "2750de9a4c5740b080f5a8145de41111",
            "ecf9c5705a7b491c82d4e8b5cbd8c439",
            "e76cddc6d7d04d3fb01c11225ec1b6a2",
            "9ad1276e945e4915a079e97e06048ee9",
            "02191a5509094a0abcf8862d3a8ee4cd",
            "5c69e45579f54fc6b2415ebbad4da477",
            "8dbb1fccc920458cbffc7029953e5363",
            "29e9e92bc30c4b2f89416481b4fb1455",
            "1c5678cdeb204d21b94526ccdab34d32",
            "dea6b34486294d388d68aa9ef3aaa281",
            "e34566724c6e4598860e77d6b710faf8",
            "b34433ff3b52491fb5829b9f1522e162",
            "5250f6a6e5c34894adb20a9120388ba0",
            "0381ff6309df4052bb0ce823e7ff741b",
            "bd79d8ce5e28404c988f4965873a2f2c",
            "b70156e5cb144e75b97697a2439d9a5d",
            "96e7d97dc8f44c7d873060a89f82ce0e",
            "aa099b9c51d6447a9a22fb13b103cb41",
            "03a6cc127c8c4f03bab0b31bb3a1721b",
            "08fbdead6ab540d4a1d2d8f06879e417",
            "5f0512fb3607471f817b5c215d94e4d8",
            "0457dfcb462c4173bbfb7890bb043c97",
            "d6ccd976679e45fcbf6d6b5d06360ea6",
            "f6c454dc6dcb4528b7b05b83c72640fc",
            "029adddbce024f50bc5d7a06d304632d",
            "d2a8de725a934927b52792351e0d5099",
            "dcd68849bd0a44238fbb9bec129b0511",
            "3312caf3fc76420ead7f4945675df52a",
            "169e8fa7a73d4797945e98ccba4cd10c",
            "b072faf11c504e39939d1ad4534f9112",
            "f3707c74969e4f6c84d6a36b59d6fa9e",
            "32184fc9b099416a8d49ef3c3f8c3a2e",
            "2b95b44611524401ac7826dab5a21aa8",
            "3fb4b68eda9f481abbc7b2456644e16b",
            "3c54d6fd6a004ed98c1cb595a0bb84a0",
            "7f511160291e4a4a82f8694772449ea8",
            "91eebca40ce344039704522c4570353c",
            "2137d76adc0b4235bcf4e52ab94ae445",
            "fcb506371e6e4cd2947988d6c7050809",
            "a5967030d5aa4581b66d319588b92db4",
            "6baecbf668bc4a6f93be03e5f671b76a",
            "a33ab96c585c411ab148d76865b848f2",
            "5589d685cbc94ea0a045dcba0e69a7e5",
            "01ac22caf29c4b2baf0ebc428f3398b3",
            "1d322e088a6a4904a0b99740d8d4e45c",
            "20402646761d4cf3975763fc130d6ff5",
            "5183ef3eec0d4bdfbcc5544b0fec573b",
            "3751db7e581847efa6c224dd50c9b7bb",
            "600bc8f5877547aca898f8c85902040e",
            "b65ef6da8ad34e2285813544d00bf3e5",
            "4ef3bcbd56164ddaac3068fb93a66630",
            "0cbd831de3c64f4aa269776dc73c5e28",
            "d947bfe9101646c9a7222ada482d4455",
            "8e9137be11744d329bceecd548d91025",
            "326c1c104f254d1189c78c6abd318451",
            "a4848184b58645b2a572c6e1a1231f05",
            "92d450929c8e45539c2726eaf96d5ddb",
            "d9a90b08aaec44d9962e8c090b8d0baa",
            "70225a6a843d4ccf87d1b43d4cf1895b",
            "8c45ce351a9b45dda4359b706ea36aba",
            "9e2644d3c3bb40aa9eba632e756112a3",
            "a6770d150cfa459780d5adb12fc7c7b8",
            "78608a4a3a8f4c119d9a0128153a39eb",
            "91de7341a97a4415b5656ee33fe6395f",
            "82f1dc2ca5ef4e45818a2b9107732d58",
            "5e1a387877054dacbb6bf1fa32b08d7a",
            "48729429682c4b37a624ba2eb55d1966",
            "6eeb3579c2b644a6b8501cc246083c97",
            "8f1bf2df4214449483a37dc84d9f3c43",
            "9afa2b87f4a94a58b7c639a0a7f63813",
            "8ae32d0dd19e40e8a0fc4b04b325abd6",
            "20ae65dc26cb4ab98a9637dfa2bd5a62",
            "641fd37171904fb590b7877d8403aeea",
            "e8f710e2dcfc40398ce16a4ac265cc26",
            "377a7fa0ebce4c8a96a55c6e1c08403f",
            "5ed5174d9d6c4680bb7cc1e803184102",
            "2c148a8aa9fe4f30a69392f10a350eac",
            "177dee7aa0754c7db2b595f83a4eb105",
            "2fe3c4d6e4774be691e7c0551fd334ff",
            "6ff3a2b6be1f4220b0e3c055fc587c7e",
            "af816340aae74a81a6eaf63a1933f5bf",
            "91bcf74809894d39b5199ca23691f00f",
            "85a35c16364f4c6880dbbecf061faf44"
          ]
        },
        "id": "Y7HRRYhrfm18",
        "outputId": "0fc7cf35-f252-47f1-a9a0-3b2ef5615da2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e70f5c3ae04d4b8b4a86c1233418be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c8b871e03af41ada7990e7b76084f84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "476c5672e7784cda8255af2049de1ecd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dbb1fccc920458cbffc7029953e5363",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa099b9c51d6447a9a22fb13b103cb41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "169e8fa7a73d4797945e98ccba4cd10c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5967030d5aa4581b66d319588b92db4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ef3bcbd56164ddaac3068fb93a66630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6770d150cfa459780d5adb12fc7c7b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "641fd37171904fb590b7877d8403aeea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "anamod = AnathemTransformer(\n",
        "        config=config,\n",
        "        device=None,\n",
        "        do_mlm = True,\n",
        "        do_cls = True\n",
        "    )\n",
        "\n",
        "teacher_mlm = AutoModelForMaskedLM.from_pretrained(modelstring_teacher_mlm)\n",
        "\n",
        "\n",
        "from torch import Tensor\n",
        "class TeacherEmbedder:\n",
        "\n",
        "    def __init__(self, pretrained_name = 'intfloat/e5-large-v2'):\n",
        "        self.pretrained_name = pretrained_name\n",
        "        self.teacher_tokenizer = AutoTokenizer.from_pretrained(pretrained_name)\n",
        "        self.teacher_embedder = AutoModel.from_pretrained(pretrained_name)\n",
        "\n",
        "    @staticmethod\n",
        "    def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "    def forward(self, input_text, prepend = 'passage: '):\n",
        "        input_text = [prepend + s for s in input_text]\n",
        "        with torch.no_grad():\n",
        "            batch_dict = self.teacher_tokenizer(input_text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "            outputs = self.teacher_embedder(**batch_dict)\n",
        "            embeddings = self.average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "        return embeddings\n",
        "\n",
        "    def __call__(self, input_text, prepend = 'passage: '):\n",
        "        return self.forward(input_text)\n",
        "\n",
        "\n",
        "teacher_emb = TeacherEmbedder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_BdVwTUsWj1",
        "outputId": "2e956c25-393b-4fc3-996e-5b18796b9e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertOnlyMLMHead(\n",
            "  (predictions): BertLMPredictionHead(\n",
            "    (transform): BertPredictionHeadTransform(\n",
            "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (transform_act_fn): GELUActivation()\n",
            "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(anamod.mlm) # MLM head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PaoAjDffxVd",
        "outputId": "868f0300-5add-4258-da89-da358ddf8b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids', 'attention_mask_l2', 'attention_mask_l3', 'excess_cls_ids_l2', 'excess_cls_ids_l3'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 512])\n",
            "torch.Size([2, 24, 256])\n",
            "torch.Size([2, 12, 128])\n",
            "torch.Size([2, 1024])\n",
            "torch.Size([2, 48, 30522])\n",
            "torch.Size([2, 48, 30522])\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'a', 'standard', 'liability', 'clause', 'is', 'a', 'wai', '##ver', 'clause', 'that', 'states', 'that', 'one', 'party', 'won', \"'\", 't', 'hold', 'the', 'other', 'liable', 'for', 'damages', ',', 'losses', ',', 'or', 'costs', 'associated', 'with', 'issues', '.', 's', '.', '.', 'it', '.', 'the', 'it', 'it', 'it', 'parties', 'one', 'party']\n",
            "Anamod\n",
            "['-', 'the', '-', '-', 'a', '-', '-', '-', '.', 'a', '-', '-', '.', '.', 'is', '.', 'the', '.', '-', \"'\", 's', '.', 'the', 'other', ',', 'for', 'me', ',', 'my', ',', 'or', 'the', '-', 'with', 'the', '.', 'the', 'he', 'he', 'he', '-', '-', ',', ',', ',', 'the', '-', ',']\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'it', 'usually', 'consists', 'of', 'two', 'elements', ':', 'a', 'trigger', 'event', 'or', 'circumstance', 'and', 'a', 'trigger', 'obligation', '.', 'the', 'trigger', 'event', 'or', 'circumstance', 'is', 'the', 'violation', 'of', 'the', 'agreement', ',', 'misconduct', ',', 'or', 'negligence', 'of', 'the', 'ind', '##em', '##ni', '##fying', 'party', 'or', 'its', '.', 's']\n",
            "Anamod\n",
            "['-', 'the', 'the', '-', 'it', 'or', 'the', 'of', 'two', 'of', ':', 'a', 'the', ',', 'or', ',', 'and', 'a', '-', 'of', '.', 'the', 'trigger', '-', 'or', '-', 'is', 'the', 'part', 'of', 'the', 'or', ',', 'the', ',', 'or', ',', 'of', 'the', 'ind', '##em', ',', ',', ',', 'or', 'the', '-', 'the']\n",
            "torch.Size([4, 1024])\n"
          ]
        }
      ],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "inputs = anamod.tokenizer(text, add_special_tokens=True, return_tensors='pt', padding='longest')\n",
        "\n",
        "print(inputs.keys())\n",
        "inputs\n",
        "\n",
        "outputs = anamod.forward(\n",
        "    input_ids = inputs['input_ids'],\n",
        "    attention_mask = inputs['attention_mask'],\n",
        "    attention_mask_l2 = inputs['attention_mask_l2'],\n",
        "    attention_mask_l3 = inputs['attention_mask_l3'],\n",
        "    excess_cls_ids = inputs['excess_cls_ids'],\n",
        "    excess_cls_ids_l2 = inputs['excess_cls_ids_l2'],\n",
        "    excess_cls_ids_l3 = inputs['excess_cls_ids_l3']\n",
        ")\n",
        "# hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "\n",
        "outputs_teacher_mlm = teacher_mlm(input_ids = inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "\n",
        "print(outputs[0][0].shape) # full hidden state sequence\n",
        "print(outputs[0][1].shape) # mid hidden state sequence\n",
        "print(outputs[0][2].shape) # small hidden state sequence\n",
        "print(outputs[1].shape) # sentencevector\n",
        "print(outputs[2].shape) # mlm outputs\n",
        "\n",
        "#\n",
        "print(outputs_teacher_mlm['logits'].shape) # Teacher shape mlm\n",
        "\n",
        "predicted_token_ids1 = outputs_teacher_mlm[0][0].argmax(dim=-1)\n",
        "predicted_token_ids2 = outputs[2][0].argmax(dim=-1)\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][0].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][0].argmax(dim=-1)))\n",
        "\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][1].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][1].argmax(dim=-1)))\n",
        "\n",
        "# try to embed text with the teacher_emb\n",
        "text2 = input_texts = [\n",
        "    'query: how much protein should a female eat',\n",
        "    'query: summit define',\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"\n",
        "]\n",
        "sentence_embeddings = teacher_emb(text2)\n",
        "print(sentence_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzb5l9wymf4D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "1a3234bae89d4c1eb7e84da16675cde8",
            "7c50e41b12ab40ae88db5a68806a5287",
            "9a675022c08043438f0288c2dc3d1692",
            "42ed4267878a46a9a1a1de7f63006ab4",
            "a587d42c581c4f75984a189ebe1b1831",
            "1aea1f6de91a43a4b491c82ffc1522be",
            "3c45e6794f974b4199098bcd87765e63",
            "ff58b4945b004e9996568c228986d287",
            "1290569b6a4d490fbfc8ca3915983263",
            "ba76516f42224f79a9dfe8a36385bb22",
            "c6b2dc48588b482f80e9a2473dc5b452",
            "e7bd0a23537441b6a41373c7db399423",
            "7bdb5cce9c364437970f01220e5f0aa3",
            "5df7aa079833485bbde65e4658b496e0",
            "e9149263e2264fe6b5e5cb50f67d55c2",
            "e3712984d7774865be2c1e97faf82d57",
            "3e72971bf9804c3688c24e0a3eca0da7",
            "d36c80ffd8824fdb8e1e344f41fa3669",
            "283065bbec654b89a6be726e3fe790fd",
            "ebf0c7ac01e441d68a38cac5fed89d00",
            "ab8bf4aa34c5452d8c6d01df44402eea",
            "c1ad349038c94c1f9ec7b1d0d7245699",
            "fc40e712ccca489e8cb2eaadbc47aa54",
            "d87e9ee37dfe44bcad7b97ccfef0f5ff",
            "afd68f4512e045c2bfaa46eb36d4ab5a",
            "db1f664494c94faf8998df1f25718b9f",
            "63a2424581894ab48ad61b9f38cc882e",
            "44ce4959b2bc410a8b455eb2adb7ffc9",
            "422ac21cdb1d45a8a0814ef00c9769ff",
            "f387685057a6405f86292bd9ce5df000",
            "808dad49922a431d9c43faf48478a069",
            "5c96dd4ef67f4900af004f322706921f",
            "c519b80ce005494caf41456ec90111bf",
            "694f0df64a4b433aa22afef48d968090",
            "75d264b002cc4c3889089fe28f6cfa80",
            "f6a686a076954e0c9c5d11429a14d582",
            "9f512b3c83bf4fcaa1640cf5cdbea8c8",
            "282f350bdadd41fa82b37f527ffe8a63",
            "052465580f854b15be0d29e9dc59125b",
            "619bcc47eac24a098ac5908bddc4297d",
            "0a320f7b8bba47ddb97d2aff966e162f",
            "0e215f7f87fc48bfbb3e74c9c97b23a8",
            "5ab64a9556124cf892f33cc9973240ea",
            "656cb0e3b85c4a57936749caa02f664d",
            "f7ca459667fe48c2a54d0ca13ccfe114",
            "91738a91e20344f1b848ccc39bd0b686",
            "ae85f3dd9b864de7897e02a2313c8093",
            "e97d23572a21475fa4b5b9fa4454d4cc",
            "32f65d2703c048929de10720219fdf53",
            "f9d88bd9fdda49bcbf01366f8fe6fab2",
            "ca5cfab63b2d47869f69b772f9801d69",
            "ea00ba0feb164981bdb521803fd29049",
            "16501e0f5de84fc7bbbdcc9b37f61d85",
            "68db1531b9574e72a2ff0d52995a7347",
            "eeafa1a037dd42a88774f76ea6275360",
            "e891d996e42f425cb2b31d563dfc77ef",
            "216e1650231e471fa0d88e3d73bf6da0",
            "d1dafb9eb15541489d740cbf202fac2f",
            "e362a74248d24aa28ab7dd3500c9d303",
            "1eb78591c14840daaf6741730f2280f8",
            "a2bbd67afcb9463cb0f78d7a24c5f126",
            "ad9c165248ef4e0b9c357316b95f66af",
            "adc06005b98c44f0a6308cbd4f6a3527",
            "eace7bc2187b4dd0af47dbee9327903a",
            "a9f66a8eed1443d099d0fadab83d02e9",
            "292c0b150eb84f06a012e2084b035350",
            "755e3809aa3043f99d3664955a3a2c03",
            "44d07abd85374cca92698119139b140e",
            "00001f9f055045f9ae35f94f76be8fe4",
            "1e7d06e9df9b4a88a003bbba433c1cae",
            "a87f8ff9f575436da0dcf9a31642f7b7",
            "1deae35c0489408fa7e374cd93cca642",
            "260f38a6c52d464999f74443c04cdc03",
            "c16dd57325504698b35f155d1bd040b5",
            "7950d803ab5b4c4ab10dc9e0902e34b1",
            "d151de5a1862426f9d3ab2aaae73f4d9",
            "3963ddae09b14417abf20a566ce82a03",
            "03a8f530cfb0469998f56dcca5f00803",
            "cafc757655d74a2697f4ba566b3623ee",
            "46cd1079cad04e7ea04959e14225b7fb",
            "c508e67d54c24888b82b66108681da19",
            "b08eba43d39846869bdd9050836be1cb",
            "d1837578698f426d8c65a40770a3488c",
            "fdf37a5ac48c477d99318631238a5756",
            "ef504e4ab1384063bff714e1649e0aa3",
            "7b387dec327543f79f957f81fb651cc7",
            "d71e718353ac40788febf07676b3cb25",
            "addf3619a835489f8d9f3ce4498daf36",
            "3315267c32f24d29804c12af760956aa",
            "31fef27ae4d44fa691185c3fa750756a",
            "11db36da26a94bae9ad00e99a10d8c5a",
            "f4bb56cde5b042e8821ee26d25da4ea2",
            "312b0a411cf7451d845fae7b77dff7d6",
            "fa205a1da88e418a881efb0963042e9d",
            "30f6111712e2491198ac03400ef0ce7d",
            "c5323c16a9ca4decbe25c651a14517de",
            "eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "ffe8145192c34433b3140f05b5b2528f",
            "3988d9e57bc841b49a5079130f071dfc",
            "d9bcbb8cd61d4fa5b9e0b95304f8969c",
            "8ea68f6b18c342938de8be19d3896038",
            "0b0c4175d283414ab014c95269b4421b",
            "00c7829ca16746089c8896865f374b1f",
            "f9f77be1c3044483bbd3714a5a45e2ad",
            "b42f3b105ff645dcb58805289594baad",
            "d4214693adb54e44b31fd40e549802b8",
            "b17a0dd6bd24481e8e597415bfc02c87",
            "2c43b4c9b58842acaf321862c3a1625d",
            "99ef066e53974658a59443c917b2c615",
            "98bd45b05dda4319adf853b5104f0a0a",
            "0003c5e497294b5abf83ff5edbf90261",
            "28542ed3d1b443c9a7ba7074825ee208",
            "7c01fc1aabb0486f9f1f0674b46b5481",
            "6b349f8f7890488eaa05b156ec971bf6",
            "1602c7712db64b829a6ed1fa73367a1e",
            "d72812af3cd8475f8a76a8ff3ec236e9",
            "40731cc8e1a245868c9bf6d0972c0467",
            "6f102144e4fd4840b77808f1e6ff7697",
            "82084929de714135a363f5693f4a0aac",
            "f3537b58aca04f398663d6a8f6bd7cf8",
            "0ea16b4f2c6d428191dd7d31d21ad659"
          ]
        },
        "id": "b2ueft2IwxIr",
        "outputId": "4d0bdc1a-4261-4233-cfc0-d686ea8b1e84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a3234bae89d4c1eb7e84da16675cde8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7bd0a23537441b6a41373c7db399423",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc40e712ccca489e8cb2eaadbc47aa54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset glue/mrpc to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "694f0df64a4b433aa22afef48d968090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7ca459667fe48c2a54d0ca13ccfe114",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e891d996e42f425cb2b31d563dfc77ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "755e3809aa3043f99d3664955a3a2c03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03a8f530cfb0469998f56dcca5f00803",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3315267c32f24d29804c12af760956aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9bcbb8cd61d4fa5b9e0b95304f8969c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0003c5e497294b5abf83ff5edbf90261",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHq4Udecy1S6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSdXchNStSMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "pQXS1wenz68U",
        "outputId": "09fec374-2e3b-47d5-d4eb-02ab69561b78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f52e91588ea352bb.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-055028f389e5>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hit %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m: hit 19"
          ]
        }
      ],
      "source": [
        "\n",
        "## Test a batched inference routine: including loss calculations\n",
        "## steps:\n",
        "## 1) tokenize inputs internal to a torch dataset (encode_plus?)\n",
        "## 2) loop through dataloader, with a MLM collator also set?\n",
        "## 3) do inference using teacher\n",
        "## 5) do inference using anathem\n",
        "## 6) loss\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from torch.optim import AdamW\n",
        "from math import prod\n",
        "\n",
        "# load dummy dataset\n",
        "dataset_glue = load_dataset('glue', 'mrpc', split='test') # small set\n",
        "\n",
        "# tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "# tokenize\n",
        "dataset_glue = dataset_glue.map(lambda e: tokenizer.encode_plus(e['sentence1'], add_special_tokens=True))\n",
        "print(dataset_glue.features)\n",
        "dataset_glue = dataset_glue.remove_columns(column_names = ['sentence1','sentence2','idx','label'])\n",
        "print(dataset_glue.features)\n",
        "_ = \"\"\"\n",
        "{'sentence1': Value(dtype='string', id=None),\n",
        " 'sentence2': Value(dtype='string', id=None),\n",
        " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
        " 'idx': Value(dtype='int32', id=None),\n",
        " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
        " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
        " \"\"\"\n",
        "\n",
        "# MLM collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")\n",
        "\n",
        "# MLM distillation loss function (kl-divergence between teacher and student outputs)\n",
        "loss_fn_mlm_distil = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "loss_fn_mlm_labels = nn.CrossEntropyLoss(ignore_index=-100) # non-masked tokens have -100\n",
        "weights_mlm_distil = 0.5\n",
        "weights_mlm_labels = (1-weights_mlm_distil)\n",
        "\n",
        "# dataloader with MLM collator\n",
        "dl_mlm = DataLoader(dataset_glue, collate_fn=data_collator, batch_size=4)\n",
        "\n",
        "# optimizer\n",
        "optimizer = AdamW(anamod.parameters(), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "\n",
        "for step_i, batch in enumerate(dl_mlm):\n",
        "\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    # label loss\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "    optimizer.zero_grad()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    #\n",
        "    optimizer.step()\n",
        "\n",
        "    if ((step_i+1) % 20) ==0:\n",
        "        raise NotImplementedError('hit %d' % step_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyCvyxgiqAdm"
      },
      "source": [
        "## MultiTask Training: adapted from s-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "dab6a9ff832540bfae51a3f0dcfedfba",
            "c5adcad970e4455cbf797f14e2e5303e",
            "928bc9d9e240469298d2a267fe3b9e65",
            "24e977d511bd4f03bc8d730cd4c86027",
            "4b4dae6b5bd5474491e1c86a6e462ebf",
            "21f6c046574b4badbf5dac2bd4989d67",
            "e844aa942c604f17b61375f59aad56f3",
            "595530337aab40f6b5cc24d69b3ebaf9",
            "85aa23b715f248248204a2bdf3e5f7ec",
            "3f2b4543fdb94a1d9153de7f18d108be",
            "da3eb201a16240aaa91baf19b49d4209",
            "f53073dd81bf427188a9cfde75c18bff",
            "2b5f6a6687b34036bd5a87c8b61dc2c3",
            "b0546b4b929f4fe3927af49ab119d99a",
            "37e0abc511f04624986368ef45b50131",
            "d365ebcd816a44da80bc74870dd008bd",
            "d265db9a419d4edfbdb91e4bd8f78846",
            "aae2a30b7f474dbcbf55aa677b9518f9",
            "df31cc0682014cdb881817de1c02288f",
            "01fa51a473a6472da89d47bf1116e575",
            "33088ffab85f4898bc39a1167e70388c",
            "1672001c1d7e449f9cc0ce76fcf50fc8",
            "fc2d3eb4b1304b97bf336245736983ec",
            "4d798a40b2a24c4f8ce823023d75ea6a",
            "429379eb4c4f452d94a52521911811a8",
            "49a90c227b9342ddbb670c9fe85591cc",
            "843d11a2271246f49dbabe80fc4762d4",
            "f10d3cde2d7b4121971d8e19e3362b30",
            "4818654025b94f38a631b2bcdf36014c",
            "f68c38cc7bf84db2ab1540ca985599e2",
            "d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "8a1ecdd97d194a9ab63a15980d1e2e31",
            "5dd1df4079d44b1aad849b4a0a5e3b55",
            "2958b232a65d47d7950e040ddd583898",
            "82db512ae4ce4b1fbde3aed3d893e032",
            "8b3982acce834b95a6f318dfb78add1c",
            "3df2e72406454de7ade25cfe0fca7295",
            "979449deb4254629b80f0089584c851a",
            "cd748fe04232441abb30f153e54f9890",
            "8eda2864b2774815bd6d860c1fdf2625",
            "09a93d25cd25426e9c60222b29321889",
            "0db15040be1242378220fa56a21aba28",
            "7834f7deaa3b43669cd0de893fa62448",
            "cfa5b162648c4abca773a478c3e3beb9",
            "2a7388d890b2460c86be4cd32187f319",
            "38b91d162c304c6eaad444f0abffa931",
            "0f331a136adf425f87a1a35682256cd9",
            "1f65726d2e20471e99928e5dc96726c7",
            "dae9d080adfc4bfbba896820bbf57c3b",
            "9ef72b344a964832bd2b19140d230f7b",
            "b719af868833401c86d45d2ae059c868",
            "46f2289d8f6c460892864f1ef5ad8e08",
            "f81a1dd1a8b547b39297478219b41c81",
            "454aeb5a95b94bb580698d8d2f62f43f",
            "a417b74f6fdb4dedbd6bf3408d0dea69",
            "42c13d8f7c694c6599c0a2e10ca0765f",
            "0322aeeda2bd42c1b8ce348bd56424eb",
            "c0908ccc452b42e681765c37a139e878",
            "251219f28bd54de9a608686672dddf0d",
            "e982215023c24a3caf881dd3986cca86",
            "5398b51140574840979cfe9ae2640c96",
            "d6012c2d60024501a1bd8c529bf055e6",
            "d74fd39704b44cea8f012402e7449a80",
            "f5e5dd22e0b24a30a485b54dbdacf1cf",
            "7e61f641028148e988678a2ecbe24a21",
            "df8de4914b3f4c51b4e048f053a0e009",
            "868c8d0c5a4a4535a00dd833ad0dbb6f",
            "7c1ea655a2844e0e81c89529f95acb4c",
            "f4a51d5c122645a5a58acfbadb0cf752",
            "5bd4908665db4c8baac9d52a40a1c28e",
            "000f6133e191461c893cffdc6783a5f9",
            "b5fca62c132b4b9c9af64955480ac905",
            "7081369f016f46ec9ad16edcedd027b0",
            "8631f393c12e4ebaa57838a4f1c1efb0",
            "bc7e0e6c4b154e55875c6fddc0aac6f0",
            "46ff0481a7a94abb9cea91aaacd1ea29",
            "05fd99843ed746d1baf705e6c31881f6"
          ]
        },
        "id": "1C-THFy0tPik",
        "outputId": "5118abac-4cb3-47f3-d368-683d051edb47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab6a9ff832540bfae51a3f0dcfedfba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f53073dd81bf427188a9cfde75c18bff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.88k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc2d3eb4b1304b97bf336245736983ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset multi_nli/default to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2958b232a65d47d7950e040ddd583898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a7388d890b2460c86be4cd32187f319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42c13d8f7c694c6599c0a2e10ca0765f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "868c8d0c5a4a4535a00dd833ad0dbb6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset multi_nli downloaded and prepared to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "### Normal label-based losses (MLI\n",
        "# -- https://huggingface.co/datasets/multi_nli\n",
        "dataset_nli3 = load_dataset('multi_nli', split='train') # 383k examples\n",
        "\n",
        "# I think I should keep the text untokenize for the multi-task, maybe use the default collator from sbert\n",
        "dataset_nli3 = dataset_nli3.remove_columns(\n",
        "    column_names = ['promptID', 'pairID', 'premise_binary_parse', 'premise_parse','hypothesis_binary_parse', 'hypothesis_parse', 'genre']\n",
        ")\n",
        "\n",
        "dl_mli3 = DataLoader(dataset_nli3, batch_size=4, shuffle=True)\n",
        "\n",
        "\n",
        "# make a classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZRIJYI8eBBC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClassifierMNLI3(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size = 512,\n",
        "        do_subtract = True,\n",
        "        dropout = 0.1,\n",
        "        n_labels = 3\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.do_subtract = do_subtract\n",
        "        self.dropout_p = dropout\n",
        "        self.n_labels = n_labels\n",
        "        self.size_of_concatenated_inputs = self.hidden_size*2*2 + self.do_subtract*self.hidden_size*2\n",
        "\n",
        "        # final output\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Dropout(self.dropout_p),\n",
        "            nn.Linear(self.size_of_concatenated_inputs, self.n_labels)\n",
        "        )\n",
        "    def forward(self, input1, input2):\n",
        "        features_concat = torch.concat((\n",
        "            input1,\n",
        "            input2,\n",
        "            torch.sub(input1,input2)\n",
        "        ),axis=1)\n",
        "        return self.layer(features_concat)\n",
        "\n",
        "\n",
        "# Make classifier for MNLI labelled data\n",
        "classifier_mnli3 = ClassifierMNLI3(\n",
        "    hidden_size = anamod.config.hidden_size,\n",
        "    n_labels=3\n",
        ")\n",
        "classifier_mnli3.train()\n",
        "anamod.train()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(anamod.encoder.parameters()) +  list(anamod.pooler.parameters()) + list(classifier_mnli3.parameters()),\n",
        "    lr=0.0001\n",
        ")\n",
        "\n",
        "# make loss function (3 labels)\n",
        "loss_fn_nmli3 = nn.CrossEntropyLoss()\n",
        "weights_mnli_distil = 0.5\n",
        "weights_mnli_labels = (1-weights_mnli_distil)\n",
        "\n",
        "loss_fn_mnli3_distil = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "rBSnisaFT-3O",
        "outputId": "7fa6b430-8619-400b-cf57-20a3c5e76fd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6361832022666931\n",
            "0.5656223297119141\n",
            "0.3880550265312195\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1cec90a56f65>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# NEXT do distillation loss with teacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfeature_teacher_nmli1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mfeature_teacher_nmli2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hypothesis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# MNLI distillation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, batch_mnli in enumerate(dl_mli3):\n",
        "    optimizer.zero_grad()\n",
        "    # get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # mnli predictions n labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # mnli binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label']) * weights_nmli_labels\n",
        "    #loss_cls_nmli3.backward()\n",
        "\n",
        "    # NEXT do distillation loss with teacher\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%3 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "had3LEY4a5rT",
        "outputId": "6e2912df-f412-446d-f31a-f3a8710cbe98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3287630081176758\n",
            "1.1084638833999634\n",
            "1.1774473190307617\n",
            "1.0645709037780762\n",
            "1.091556429862976\n",
            "1.1649658679962158\n",
            "1.319928765296936\n",
            "1.1654601097106934\n",
            "0.9826673865318298\n",
            "1.1563453674316406\n",
            "1.0446501970291138\n",
            "1.1165382862091064\n",
            "1.1049705743789673\n",
            "0.9217707514762878\n",
            "1.14559006690979\n",
            "1.1429061889648438\n",
            "0.9149771928787231\n",
            "1.207316279411316\n",
            "1.1845396757125854\n",
            "1.2629420757293701\n",
            "0.9769338369369507\n",
            "1.0895546674728394\n",
            "1.0898280143737793\n",
            "1.1648684740066528\n",
            "0.9611557126045227\n",
            "1.044935703277588\n",
            "1.144046425819397\n",
            "1.099448561668396\n",
            "1.0884103775024414\n",
            "1.142393946647644\n",
            "1.0853071212768555\n",
            "1.1239224672317505\n",
            "1.0658488273620605\n",
            "1.1993112564086914\n",
            "0.9642707109451294\n",
            "1.182077407836914\n",
            "1.3221166133880615\n",
            "1.1279082298278809\n",
            "1.0723700523376465\n",
            "1.1399314403533936\n",
            "1.0013256072998047\n",
            "1.1049387454986572\n",
            "1.0147031545639038\n",
            "1.2314361333847046\n",
            "1.0651648044586182\n",
            "1.1327135562896729\n",
            "0.9887092709541321\n",
            "1.0250582695007324\n",
            "1.1199613809585571\n",
            "1.094027042388916\n",
            "1.091330885887146\n",
            "1.098750114440918\n",
            "1.1193275451660156\n",
            "1.1657143831253052\n",
            "1.0800719261169434\n",
            "1.152091383934021\n",
            "1.1550073623657227\n",
            "1.0005279779434204\n",
            "1.063902497291565\n",
            "1.0364967584609985\n",
            "1.0193161964416504\n",
            "1.1669244766235352\n",
            "1.055404543876648\n",
            "1.2059553861618042\n",
            "1.1156867742538452\n",
            "1.1356735229492188\n",
            "1.1261953115463257\n",
            "1.0520744323730469\n",
            "1.0741896629333496\n",
            "1.0739905834197998\n",
            "1.1333951950073242\n",
            "1.0113921165466309\n",
            "1.1244165897369385\n",
            "1.1339558362960815\n",
            "1.125321626663208\n",
            "1.0819061994552612\n",
            "1.1043788194656372\n",
            "1.108479380607605\n",
            "1.148271083831787\n",
            "1.0951212644577026\n",
            "1.1449416875839233\n",
            "1.0795189142227173\n",
            "1.1403652429580688\n",
            "1.086578130722046\n",
            "1.0184922218322754\n",
            "1.1535804271697998\n",
            "1.0355476140975952\n",
            "1.120854377746582\n"
          ]
        }
      ],
      "source": [
        "# Combine the teacher training with classification\n",
        "optimizer = AdamW(list(anamod.parameters()) + list(classifier_mnli3.parameters()), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "for i,(batch_mlm, batch_mnli) in enumerate(zip(dl_mlm, dl_mli3)):\n",
        "    optimizer.zero_grad()\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # mlm teacher outputs\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "        # to do this, I'd need to have the original text, and NOT pre-tokenized text\n",
        "        #teacher_emb(input_text=batch['premise'], prepend = 'passage: ')\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    #loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    #loss_mlm_distil.backward()\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "\n",
        "    # loss on paragraph embedding\n",
        "\n",
        "    # BACKPROP MLM label loss and distilloss\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "\n",
        "    # NLI task: get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label'])\n",
        "    #loss_cls_nmli3.backward()\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%4 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "NWWBkB_gqEkE",
        "outputId": "6a69aabe-43c8-42bc-dd5f-f15a8840b73d"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8c7bf2d1f796>\"\u001b[0;36m, line \u001b[0;32m319\u001b[0m\n\u001b[0;31m    self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "class TrainerMultiTask:\n",
        "    \"\"\"Adapted from the uklab/sentence-transformers .fit() function\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            do_reload = True,\n",
        "            epochs_total_lifetime = 5,\n",
        "            scheduler: str = 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            output_path: str = None,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = False,\n",
        "            checkpoint_path: str = 'checkpoint.pt',\n",
        "            checkpoint_path_optimizer: str = 'checkpoint_optimizer.pt',\n",
        "            checkpoint_path_scheduler: str = 'checkpoint_scheduler.pt',\n",
        "            checkpoint_path_trainer_state: str = 'checkpoint_trainer_state.json',\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 0,\n",
        "            do_minimize_global_objective: Int = 1\n",
        "        ):\n",
        "            self.epochs_global = -1 # track the total number of epochs\n",
        "            self.epochs_total_lifetime = epochs_total_lifetime # total number of epochs over lifetime\n",
        "            self.global_step = 0 # track the toatl number of steps\n",
        "            self.do_minimize = do_minimize_global_objective\n",
        "            self.best_score = 9999999 if self.do_minimize else -9999999\n",
        "            self.output_path = output_path\n",
        "            self.checkpoint_path = checkpoint_path\n",
        "            self.checkpoint_path_optimizer = checkpoint_path_optimizer\n",
        "            self.checkpoint_path_scheduler = checkpoint_path_scheduler\n",
        "            self.checkpoint_path_trainer_state = checkpoint_path_trainer_state\n",
        "            self.scheduler_state_dict = None\n",
        "            self.optimizer_state_dict = None\n",
        "            self.trainer_state = None\n",
        "            self.loss_models_states = None\n",
        "            if do_reload:\n",
        "                print('attempting to reload cached model, optimizer, scheduler, and saved trainer sate')\n",
        "                model_state, loss_models_states = self.load_saved_model(self.checkpoint_path)\n",
        "                self.model_state = model_state\n",
        "                self.loss_models_states = loss_models_states\n",
        "                self.scheduler_state_dicts = self.load_saved_scheduler(self.checkpoint_path_scheduler)\n",
        "                self.optimizer_state_dicts = self.load_saved_optimizer(self.checkpoint_path_optimizer)\n",
        "                self.trainer_state = self.load_saved_trainer_state(self.checkpoint_path_trainer_state)\n",
        "\n",
        "    def fit(self,\n",
        "            train_objectives: Iterable[Tuple[DataLoader, nn.Module]],\n",
        "            model=None,\n",
        "            weights_train_objectives:List = None,\n",
        "            teachers: List = None,\n",
        "            evaluator: SentenceEvaluator = None,\n",
        "            epochs: int = 1,\n",
        "            epochs_total_lifetime = None,\n",
        "            steps_per_epoch = None,\n",
        "            scheduler: str = None, # 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = True,\n",
        "            checkpoint_path = None,\n",
        "            checkpoint_path_optimizer= None,\n",
        "            checkpoint_path_scheduler= None,\n",
        "            checkpoint_path_trainer_config= None,\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 2\n",
        "            ):\n",
        "        \"\"\"\n",
        "        Train the model with the given training objective\n",
        "        Each training objective is sampled in turn for one batch.\n",
        "        We sample only as many batches from each objective as there are in the smallest one\n",
        "        to make sure of equal training with each dataset.\n",
        "\n",
        "        :param train_objectives: Tuples of (DataLoader, LossFunction). Pass more than one for multi-task learning\n",
        "        :param evaluator: An evaluator (sentence_transformers.evaluation) evaluates the model performance during training on held-out dev data. It is used to determine the best model that is saved to disc.\n",
        "        :param epochs: Number of epochs for training\n",
        "        :param steps_per_epoch: Number of training steps per epoch. If set to None (default), one epoch is equal the DataLoader size from train_objectives.\n",
        "        :param scheduler: Learning rate scheduler. Available schedulers: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        :param warmup_steps: Behavior depends on the scheduler. For WarmupLinear (default), the learning rate is increased from o up to the maximal learning rate. After these many training steps, the learning rate is decreased linearly back to zero.\n",
        "        :param optimizer_class: Optimizer\n",
        "        :param optimizer_params: Optimizer parameters\n",
        "        :param weight_decay: Weight decay for model parameters\n",
        "        :param evaluation_steps: If > 0, evaluate the model using evaluator after each number of training steps\n",
        "        :param output_path: Storage path for the model and evaluation files\n",
        "        :param save_best_model: If true, the best model (according to evaluator) is stored at output_path\n",
        "        :param max_grad_norm: Used for gradient normalization.\n",
        "        :param use_amp: Use Automatic Mixed Precision (AMP). Only for Pytorch >= 1.6.0\n",
        "        :param callback: Callback function that is invoked after each evaluation.\n",
        "                It must accept the following three parameters in this order:\n",
        "                `score`, `epoch`, `steps`\n",
        "        :param show_progress_bar: If True, output a tqdm progress bar\n",
        "        :param checkpoint_path: Folder to save checkpoints during training\n",
        "        :param checkpoint_save_steps: Will save a checkpoint after so many steps\n",
        "        :param checkpoint_save_total_limit: Total number of checkpoints to store\n",
        "        \"\"\"\n",
        "        if self.model_state is not None:\n",
        "            print('reloading saved model state into model')\n",
        "            model.load_state_dict(self.model_state)\n",
        "            self.model = model\n",
        "\n",
        "        # paths (optional update)\n",
        "        self.checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        self.checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        self.checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        self.checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "        self._target_device = model.device\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.weight_decay = weight_decay\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.optimizer_params = optimizer_params\n",
        "        self.evaluation_steps = evaluation_steps\n",
        "\n",
        "        if use_amp:\n",
        "            from torch.cuda.amp import autocast\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        #self.to(self._target_device)\n",
        "\n",
        "        dataloaders = [dataloader for dataloader, _ in train_objectives]\n",
        "\n",
        "        # Use smart batching\n",
        "        if len(collators)==0 or collators is None:\n",
        "            print('using default batch collators')\n",
        "        for dli, dataloader in enumerate(dataloaders):\n",
        "            if dataloader.collate_fn is None:\n",
        "                print('using default batch collators for dataloader %d' % dli)\n",
        "                dataloader.collate_fn = self.smart_batching_collate\n",
        "\n",
        "        loss_models = [loss for _, loss in train_objectives]\n",
        "        for midx, loss_model in enumerate(loss_models):\n",
        "            if self.loss_models_states is not None:\n",
        "                # reload each loss_model.classifier's saved states\n",
        "                if hassattr(loss_model, 'classifier'):\n",
        "                    loss_model.classifier.load_state_dict(self.loss_models_states[midx])\n",
        "            loss_model.to(self._target_device)\n",
        "\n",
        "        if steps_per_epoch is None or steps_per_epoch == 0:\n",
        "            steps_per_epoch = min([len(dataloader) for dataloader in dataloaders])\n",
        "\n",
        "        if epochs_total_lifetime is None:\n",
        "            epochs_total_lifetime = self.epochs_total_lifetime\n",
        "        num_train_steps = int(steps_per_epoch * epochs_total_lifetime)\n",
        "\n",
        "        # Prepare optimizers\n",
        "        #optimizers = []\n",
        "        #schedulers = []\n",
        "        #for model_idx, loss_model in enumerate(loss_models):\n",
        "        #    param_optimizer = list(loss_model.named_parameters())#\n",
        "        #    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        #    optimizer_grouped_parameters = [\n",
        "        #        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "        #        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        #    ]\n",
        "        #    optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        #    scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        #    if self.optimizer_state_dicts is not None:\n",
        "        #        # reload optimizer states\n",
        "        #        optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "        #    if self.scheduler_state_dicts is not None:\n",
        "        #        # relead scheduler states\n",
        "        #        scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "        #    optimizers.append(optimizer)\n",
        "        #    schedulers.append(scheduler_obj)\n",
        "\n",
        "        # from: https://stackoverflow.com/questions/46377599/when-to-use-individual-optimizers-in-pytorch\n",
        "        optimizer_parameters = set()\n",
        "        for model_idx, loss_model in enumerate(loss_models):\n",
        "            optimizer_parameters |= loss_model.named_parameters()\n",
        "\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in optimizer_parameters if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in optimizer_parameters if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        if self.optimizer_state_dicts is not None:\n",
        "            # reload optimizer states\n",
        "            #optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "            optimizer.load_state_dict(self.optimizer_state_dicts)\n",
        "        if self.scheduler_state_dicts is not None:\n",
        "            # relead scheduler states\n",
        "            #scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "            scheduler_obj.load_state_dict(self.scheduler_state_dicts)\n",
        "\n",
        "        global_step = self.global_step\n",
        "        data_iterators = [iter(dataloader) for dataloader in dataloaders]\n",
        "\n",
        "        num_train_objectives = len(train_objectives)\n",
        "\n",
        "        for epoch in trange(epochs, desc=\"Epoch\", disable=not show_progress_bar):\n",
        "            self.epochs_global += epoch\n",
        "            training_steps = 0\n",
        "\n",
        "            for loss_model in loss_models:\n",
        "                loss_model.zero_grad()\n",
        "                loss_model.train()\n",
        "\n",
        "            for _ in trange(steps_per_epoch, desc=\"Iteration\", smoothing=0.05, disable=not show_progress_bar):\n",
        "\n",
        "                # loop through multiple tasks\n",
        "                for train_idx in range(num_train_objectives):\n",
        "                    loss_model = loss_models[train_idx]\n",
        "                    loss_weight = weights_train_objectives[train_idx]\n",
        "                    teacher = teachers[train_idx]\n",
        "                    optimizer = optimizers[train_idx]\n",
        "                    scheduler = schedulers[train_idx]\n",
        "                    data_iterator = data_iterators[train_idx]\n",
        "\n",
        "                    try:\n",
        "                        data = next(data_iterator)\n",
        "                    except StopIteration:\n",
        "                        data_iterator = iter(dataloaders[train_idx])\n",
        "                        data_iterators[train_idx] = data_iterator\n",
        "                        data = next(data_iterator)\n",
        "\n",
        "                    features, labels = data\n",
        "                    features = list(map(lambda batch: batch_to_device(batch, self._target_device), features))\n",
        "                    if labels is not None:\n",
        "                        labels = labels.to(self._target_device)\n",
        "\n",
        "                    loss_value = loss_model(features, labels, teacher=teacher)\n",
        "                    loss_value *= loss_weight\n",
        "                    loss_value.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad_norm)\n",
        "                optimizers.step()\n",
        "                optimizers.zero_grad()\n",
        "                schedulers.step()\n",
        "\n",
        "                # TODO: integrate amp: https://discuss.pytorch.org/t/ddp-amp-gradient-accumulation-calling-optimizer-step-leads-to-nan-loss/162624\n",
        "                training_steps += 1\n",
        "                global_step += 1\n",
        "                self.global_step = global_step\n",
        "\n",
        "                if evaluation_steps > 0 and training_steps % evaluation_steps == 0:\n",
        "                    self._eval_during_training(evaluator, output_path, save_best_model, epoch, training_steps, callback)\n",
        "\n",
        "                    for loss_model in loss_models:\n",
        "                        loss_model.zero_grad()\n",
        "                        loss_model.train()\n",
        "\n",
        "                if self.checkpoint_path is not None and checkpoint_save_steps is not None and checkpoint_save_steps > 0 and global_step % checkpoint_save_steps == 0:\n",
        "                    self._save_checkpoint(\n",
        "                        model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "                    )\n",
        "\n",
        "            self._eval_during_training(evaluator, output_path, save_best_model, epoch, -1, callback)\n",
        "\n",
        "        #if evaluator is None and output_path is not None:   #No evaluator, but output path: save final model version\n",
        "        #    self.save(output_path)\n",
        "\n",
        "        if checkpoint_path is not None:\n",
        "            self._save_checkpoint(\n",
        "                model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "            )\n",
        "\n",
        "    def evaluate(self, evaluator: SentenceEvaluator, output_path: str = None):\n",
        "        \"\"\"\n",
        "        Evaluate the model\n",
        "\n",
        "        :param evaluator:\n",
        "            the evaluator\n",
        "        :param output_path:\n",
        "            the evaluator can write the results to this path\n",
        "        \"\"\"\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "        return evaluator(self, output_path)\n",
        "\n",
        "    def _eval_during_training(self, evaluator, output_path, save_best_model, epoch, steps, callback):\n",
        "        \"\"\"Runs evaluation during the training\"\"\"\n",
        "        eval_path = output_path\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "            eval_path = os.path.join(output_path, \"eval\")\n",
        "            os.makedirs(eval_path, exist_ok=True)\n",
        "\n",
        "        if evaluator is not None:\n",
        "            score = evaluator(self, output_path=eval_path, epoch=epoch, steps=steps)\n",
        "            if callback is not None:\n",
        "                callback(score, epoch, steps)\n",
        "            if score > self.best_score:\n",
        "                self.best_score = score\n",
        "                if save_best_model:\n",
        "                    self.save(output_path)\n",
        "\n",
        "    def _save_checkpoint(\n",
        "        self,\n",
        "        model,\n",
        "        optimizers,\n",
        "        schedulers,\n",
        "        loss_models,\n",
        "        checkpoint_save_total_limit,\n",
        "        step,\n",
        "        checkpoint_path = None,\n",
        "        checkpoint_path_optimizer = None,\n",
        "        checkpoint_path_scheduler = None,\n",
        "        checkpoint_path_trainer_state =None\n",
        "    ):\n",
        "        # Store new checkpoint\n",
        "        checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "\n",
        "        # model states\n",
        "        self.model_state = model.state_dict()\n",
        "        self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'model_state_dict':self.model_state,\n",
        "            'loss_models_state_dicts':self.loss_models_states,\n",
        "        }, \"%s-%08g\" % (checkpoint_path, step))\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer_state_dicts = optimizers.state_dict() #[opt.state_dict() for opt in optimizers],\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'optimizer_state_dicts':self.optimizer_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_optimizer, step))\n",
        "\n",
        "        # scheduler\n",
        "        self.scheduler_state_dicts = schedulers.state_dict() #[scheduler.state_dict() for scheduler in schedulers]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'scheduler_state_dicts':self.scheduler_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_scheduler, step))\n",
        "\n",
        "        # trainer info\n",
        "        with open(checkpoint_path_trainer_state, 'w') as jcon:\n",
        "            trainer_objs_to_save = {\n",
        "                'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "                'max_grad_norm':self.max_grad_norm,\n",
        "                'weight_decay':self.weight_decay,\n",
        "                'warmup_steps':self.warmup_steps,\n",
        "                'optimizer_params':self.optimizer_params,\n",
        "                'evaluation_steps':self.evaluation_steps,\n",
        "                'checkpoint_path_optimizer': \"%s-%08g\" % (checkpoint_path_optimizer, step),\n",
        "                'checkpoint_path_scheduler': \"%s-%08g\" % (checkpoint_path_scheduler, step),\n",
        "            }\n",
        "            json.dump(trainer_objs_to_save, jcon)\n",
        "\n",
        "        # Delete old checkpoints\n",
        "        if checkpoint_save_total_limit is not None and checkpoint_save_total_limit > 0:\n",
        "            old_checkpoints = []\n",
        "            dir_to_checkpoints = \"/\".join(checkpoint_path.split('/')[:-1])\n",
        "            for f in os.listdir(dir_to_checkpoints):\n",
        "                if bool(re.search('(\\-[0-9]+$',f)) & (checkpoint_path in f):\n",
        "                    # get step of saved checkpoint\n",
        "                    old_pt_step = int(re.search('(?<=\\-)[0-9]+$',f).group())\n",
        "                    old_checkpoints.append({\n",
        "                        'step': old_pt_step, 'path': os.path.join(dir_to_checkpoints, f)\n",
        "                    })\n",
        "\n",
        "            if len(old_checkpoints) > checkpoint_save_total_limit:\n",
        "                old_checkpoints = sorted(old_checkpoints, key=lambda x: x['step'])\n",
        "                oldest_step = old_checkpoints[0]['step']\n",
        "                for old_checkpoint in old_checkpoints:\n",
        "                    if old_checkpoint['step']==oldest_step:\n",
        "                        print('deleting old checkpoint: %s' % old_checkpoint['path'])\n",
        "                        shutil.rmtree(old_checkpoint['path'])\n",
        "\n",
        "    def _grab_loss_states(loss_model):\n",
        "        \"\"\"Gets the loss_model.state_dict() for a model embedded in a loss function\"\"\"\n",
        "        return loss_model.classifier.state_dict()\n",
        "\n",
        "    def load_saved_model(checkpoint_path=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path = self.checkpoint_path if checkpoint_path is None else checkpoint_path\n",
        "        saved_dict = torch.load(checkpoint_path)\n",
        "        return saved_dict['model_state_dict'], saved_dict['loss_models_state_dicts']\n",
        "\n",
        "    def load_saved_scheduler(checkpoint_path_scheduler=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_scheduler = self.checkpoint_path_scheduler if checkpoint_path_scheduler is None else checkpoint_path_scheduler\n",
        "        saved_dict = torch.load(checkpoint_path_scheduler)\n",
        "        return saved_dict['scheduler_state_dicts']\n",
        "\n",
        "    def load_saved_optimizer(checkpoint_path_optimizer=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_optimizer = self.checkpoint_path_optimizer if checkpoint_path_optimizer is None else checkpoint_path_optimizer\n",
        "        saved_dict = torch.load(checkpoint_path_optimizer)\n",
        "        return saved_dict['optimizer_state_dicts']\n",
        "\n",
        "    def load_saved_trainer_state(checkpoint_path_trainer_state):\n",
        "        checkpoint_path_trainer_state = self.checkpoint_path_trainer_state if checkpoint_path_trainer_state is None else checkpoint_path_trainer_state\n",
        "        with open(checkpoint_path_trainer_state, 'r') as jcon:\n",
        "            trainer_state = json.load(jcon)\n",
        "        self.epochs_global = trainer_state['epochs_global']\n",
        "        self.global_step = trainer_state['global_step']\n",
        "        self.step = trainer_state['step']\n",
        "        self.max_grad_norm = trainer_state['max_grad_norm']\n",
        "        self.weight_decay = trainer_state['weight_decay']\n",
        "        self.warmup_steps = trainer_state['warmup_steps']\n",
        "        self.optimizer_params = trainer_state['optimizer_params']\n",
        "        self.evaluation_steps = trainer_state['evaluation_steps']\n",
        "\n",
        "    def _load_auto_model(self, model_name_or_path):\n",
        "        \"\"\"\n",
        "        Creates a simple Transformer + Mean Pooling model and returns the modules\n",
        "        \"\"\"\n",
        "        logger.warning(\"No sentence-transformers model found with name {}. Creating a new one with MEAN pooling.\".format(model_name_or_path))\n",
        "        transformer_model = Transformer(model_name_or_path)\n",
        "        pooling_model = Pooling(transformer_model.get_word_embedding_dimension(), 'mean')\n",
        "        return [transformer_model, pooling_model]\n",
        "\n",
        "    def _load_sbert_model(self, model_path):\n",
        "        \"\"\"\n",
        "        Loads a full sentence-transformers model\n",
        "        \"\"\"\n",
        "        # Check if the config_sentence_transformers.json file exists (exists since v2 of the framework)\n",
        "        config_sentence_transformers_json_path = os.path.join(model_path, 'config_sentence_transformers.json')\n",
        "        if os.path.exists(config_sentence_transformers_json_path):\n",
        "            with open(config_sentence_transformers_json_path) as fIn:\n",
        "                self._model_config = json.load(fIn)\n",
        "\n",
        "            if '__version__' in self._model_config and 'sentence_transformers' in self._model_config['__version__'] and self._model_config['__version__']['sentence_transformers'] > __version__:\n",
        "                logger.warning(\"You try to use a model that was created with version {}, however, your version is {}. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\\n\\n\\n\".format(self._model_config['__version__']['sentence_transformers'], __version__))\n",
        "\n",
        "        # Check if a readme exists\n",
        "        model_card_path = os.path.join(model_path, 'README.md')\n",
        "        if os.path.exists(model_card_path):\n",
        "            try:\n",
        "                with open(model_card_path, encoding='utf8') as fIn:\n",
        "                    self._model_card_text = fIn.read()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Load the modules of sentence transformer\n",
        "        modules_json_path = os.path.join(model_path, 'modules.json')\n",
        "        with open(modules_json_path) as fIn:\n",
        "            modules_config = json.load(fIn)\n",
        "\n",
        "        modules = OrderedDict()\n",
        "        for module_config in modules_config:\n",
        "            module_class = import_from_string(module_config['type'])\n",
        "            module = module_class.load(os.path.join(model_path, module_config['path']))\n",
        "            modules[module_config['name']] = module\n",
        "\n",
        "        return modules\n",
        "\n",
        "    @staticmethod\n",
        "    def load(input_path):\n",
        "        return SentenceTransformer(input_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_scheduler(optimizer, scheduler: str, warmup_steps: int, t_total: int):\n",
        "        \"\"\"\n",
        "        Returns the correct learning rate scheduler. Available scheduler: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        \"\"\"\n",
        "        scheduler = scheduler.lower()\n",
        "        if scheduler == 'constantlr':\n",
        "            return transformers.get_constant_schedule(optimizer)\n",
        "        elif scheduler == 'warmupconstant':\n",
        "            return transformers.get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
        "        elif scheduler == 'warmuplinear':\n",
        "            return transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosine':\n",
        "            return transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosinewithhardrestarts':\n",
        "            return transformers.get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown scheduler {}\".format(scheduler))\n",
        "\n",
        "    @property\n",
        "    def device(self) -> device:\n",
        "        \"\"\"\n",
        "        Get torch.device from module, assuming that the whole module has one device.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return next(self.parameters()).device\n",
        "        except StopIteration:\n",
        "            # For nn.DataParallel compatibility in PyTorch 1.5\n",
        "\n",
        "            def find_tensor_attributes(module: nn.Module) -> List[Tuple[str, Tensor]]:\n",
        "                tuples = [(k, v) for k, v in module.__dict__.items() if torch.is_tensor(v)]\n",
        "                return tuples\n",
        "\n",
        "            gen = self._named_members(get_members_fn=find_tensor_attributes)\n",
        "            first_tuple = next(gen)\n",
        "            return first_tuple[1].device\n",
        "\n",
        "    @property\n",
        "    def tokenizer(self):\n",
        "        \"\"\"\n",
        "        Property to get the tokenizer that is used by this model\n",
        "        \"\"\"\n",
        "        return self.model.tokenizer\n",
        "\n",
        "    #@tokenizer.setter\n",
        "    #def tokenizer(self, value):\n",
        "    #    self._first_module().tokenizer = value\n",
        "\n",
        "    @property\n",
        "    def max_seq_length(self):\n",
        "        \"\"\"\n",
        "        Property to get the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        return self.model._first_module().max_seq_length\n",
        "\n",
        "    @max_seq_length.setter\n",
        "    def max_seq_length(self, value):\n",
        "        \"\"\"\n",
        "        Property to set the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        self.model._first_module().max_seq_length = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2hwROspo0uI"
      },
      "source": [
        "### Load a Standard Dataset for MLM task\n",
        "\n",
        "Also need to grab datasets here: https://arxiv.org/pdf/1908.08962.pdf\n",
        "\n",
        "```\n",
        "    The Pile dataset looks good: https://pile.eleuther.ai/\n",
        "    https://arxiv.org/abs/2101.00027\n",
        "    PubMed Central, ArXiv, GitHub, the FreeLaw Project, Stack Exchange, the US\n",
        "    Patent and Trademark Office, PubMed, Ubuntu IRC, HackerNews, YouTube, PhilPapers, and NIH ExPorter.\n",
        "    We also introduce OpenWebText2 and\n",
        "    BookCorpus2, which are extensions of the original\n",
        "    OpenWebText (Gokaslan and Cohen, 2019) and\n",
        "    BookCorpus (Zhu et al., 2015; Kobayashi, 2018)\n",
        "    datasets, respectively.\n",
        "    In addition, we incorporate several existing highquality datasets: Books3 (Presser, 2020), Project Gutenberg (PG-19) (Rae et al., 2019), OpenSubtitles (Tiedemann, 2016), English Wikipedia, DM Mathematics (Saxton et al., 2019), EuroParl\n",
        "    (Koehn, 2005), and\n",
        "\n",
        "    ABout the law:\n",
        "    and other metadata, we focused specifically on\n",
        "    court opinions due to an abundance of full-text\n",
        "    entries. This data is entirely within the public domain.\n",
        "\n",
        "```\n",
        "\n",
        "Scientific Papers: You can use the scientific_papers dataset, which includes a large collection of scientific papers from various domains. It covers research articles from fields such as computer science, physics, biology, and more.\n",
        "\n",
        "Patents: The patent_citations dataset contains patent text data along with citation information, making it suitable for training language models with a focus on technical and scientific domains.\n",
        "\n",
        "ArXiv: The arxiv dataset includes research papers from the arXiv repository, covering a wide range of scientific disciplines. It can be used to enhance the exposure of your model to academic literature.\n",
        "\n",
        "PubMed: The pubmed dataset consists of abstracts from biomedical research articles indexed in PubMed. It is a valuable resource if you want to incorporate biomedical and life sciences content into your MLM pretraining.\n",
        "\n",
        "joelito/Multi_Legal_Pile - use subset `en_all` to access EU-courts, and other datasets\n",
        "\n",
        "\n",
        "Looks like streaming data is available:\n",
        "https://huggingface.co/learn/nlp-course/chapter5/4?fw=pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-boy1-ZoqWI",
        "outputId": "50b32ac5-66e9-48d2-d44d-734b53058d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynndescent\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (1.11.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (0.56.4)\n",
            "Requirement already satisfied: llvmlite>=0.30 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (0.39.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->pynndescent) (67.7.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->pynndescent) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Building wheels for collected packages: langdetect, pynndescent\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=b27fb582e060d16d6e4c1b48f5269932dc623cf0f7a10f25748bf71a94b12a7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=2d91dcbe7811914b4d33dd1ba096ef602430efabeacb4d5fefa1098bfced6c0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built langdetect pynndescent\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, rank_bm25, langdetect, dill, multiprocess, huggingface-hub, transformers, pynndescent, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.2 langdetect-1.0.9 multiprocess-0.70.15 pynndescent-0.5.10 rank_bm25-0.2.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2 xxhash-3.3.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "### Load a standard dataset\n",
        "%pip install transformers datasets zstandard rank_bm25 langdetect pynndescent\n",
        "# need the zstandard to use the streaming data function from huggingface datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0KGmDMqKlxC4"
      },
      "outputs": [],
      "source": [
        "import lzma\n",
        "from datasets import load_dataset\n",
        "from itertools import islice\n",
        "from datasets import interleave_datasets # for interweaving streaming datasets\n",
        "#from transformers import BertTokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from langdetect import detect\n",
        "import copy\n",
        "from math import prod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eoEELjudRvL_"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pI0G9zyjuH-6"
      },
      "outputs": [],
      "source": [
        "def check_is_code(text):\n",
        "    \"\"\"Estimates a ratio of special char (that may indicate math/code notation); less than 10% is code for normal text\"\"\"\n",
        "    nchar = min(5000,len(text))\n",
        "    nchar_after_removespecialchar = len(re.sub(r\"[\\<\\>\\_\\@\\^\\=\\+\\*\\$\\{\\[\\]\\}\\(\\)\\/\\\\\\.]\",'',text[:5000]))\n",
        "    ratio_specialchar = 1-nchar_after_removespecialchar/nchar\n",
        "    return ratio_specialchar\n",
        "\n",
        "def check_language(text, special_char_threshold=0.10):\n",
        "    \"\"\"Verifies that a string is: i) English, and ii) not overly mathematical/code\"\"\"\n",
        "    ratio_specialchar = check_is_code(text)\n",
        "    if ratio_specialchar>=special_char_threshold:\n",
        "        return False, ratio_specialchar\n",
        "    try:\n",
        "        is_eng = detect(text[:200]+\" hello\")=='en'\n",
        "        return is_eng, -1\n",
        "    except:\n",
        "        return False, -1\n",
        "\n",
        "if False:\n",
        "    bad_language = []\n",
        "    good_language = []\n",
        "    foo = load_dataset(\"EleutherAI/the_pile_deduplicated\", split='train',streaming=True).shuffle(buffer_size=20000).take(20000)\n",
        "    for e in foo:\n",
        "        is_good, ratiospecialchar = check_language(e['text'])\n",
        "        if not is_good:\n",
        "            bad_language.append((e['text'], ratiospecialchar))\n",
        "        else:\n",
        "            if ratiospecialchar>0.025:\n",
        "                good_language.append((e['text'], ratiospecialchar))\n",
        "\n",
        "    print(len(bad_language)); print(len(good_language))\n",
        "    bad_language = [p for p in bad_language if p[-1]>0]\n",
        "    bad_language = sorted(zip([score for _,score in bad_language],[w for w,_ in bad_language]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "30h2nnzWnDpz"
      },
      "outputs": [],
      "source": [
        "\n",
        "CHAR_PER_WORD = 6.36\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "config = {\n",
        "    'max_seq_length':512,\n",
        "    'min_seq_length':48,\n",
        "    'max_chunk_size':6,\n",
        "    'min_sentence_len':20,\n",
        "    'seed':42\n",
        "}\n",
        "\n",
        "\n",
        "class ExampleProcessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=config,\n",
        "        char_per_word = CHAR_PER_WORD,\n",
        "        nlp =nlp,\n",
        "    ):\n",
        "        self.nlp = nlp\n",
        "        self.char_per_word = char_per_word\n",
        "        self.max_seq_length = config.get('max_seq_length', 512) # maximum word-length for chunks for mlm objective (else split)\n",
        "        self.min_seq_length = config.get('min_seq_length', 128) # min sequence length for chunks (else discard\n",
        "        self.max_chunk_size = config.get('max_chunk_size', 5) # maximum number of chunks of text to take (each ~512 in length)\n",
        "        self.min_sentence_len = config.get('min_sentence_len', 20) # for next-sentence, min sentence size to merge together\n",
        "        self.seed = config.get('seed', 42)\n",
        "        self.max_chunk_length = self.max_chunk_size * self.max_seq_length\n",
        "        self.max_chunk_length_char = int(self.max_chunk_length*self.char_per_word)\n",
        "        self.min_seq_length_char = int(self.min_seq_length*self.char_per_word)\n",
        "        self.min_sentence_length_char = int(self.min_sentence_len*self.char_per_word)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_into_chunks(text, chunk_char_size, overlapping_size = 50):\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        end = chunk_char_size + overlapping_size\n",
        "        while start < len(text):\n",
        "            chunk = text[start:end]\n",
        "            period_index = chunk.find(\". \")\n",
        "            if period_index != -1:\n",
        "                chunk = chunk[period_index + 1:]\n",
        "            else:\n",
        "                first_space_index = chunk.find(\" \")\n",
        "                if first_space_index != -1:\n",
        "                    chunk = chunk[first_space_index + 1:]\n",
        "            # Check if the chunk has been split and contains more than one word\n",
        "            #if start > 0 and \" \" in chunk:\n",
        "            if end < len(text) and \" \" in chunk and chunk[-1]!=\" \":\n",
        "                last_space_index = chunk.rfind(\" \")\n",
        "                chunk = chunk[:last_space_index]\n",
        "            chunks.append(chunk)\n",
        "            start += chunk_char_size\n",
        "            end += chunk_char_size\n",
        "        return chunks\n",
        "\n",
        "    def split_chunk_into_sentences(self, chunk, discard_first_sentence=True, discard_last_sentence=True ):\n",
        "        doc = self.nlp(chunk)\n",
        "        MAX_CHAR_LEN = int(self.max_seq_length*self.char_per_word)\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        if discard_first_sentence:\n",
        "            sentences = sentences[1:]\n",
        "        if discard_last_sentence:\n",
        "            sentences = sentences[:-1]\n",
        "\n",
        "        super_list_concatenated = [] # accumulates concatenated sentences\n",
        "        super_list_raw_sentences = [] # accumulates raw sentences (for next-sentence prediction)\n",
        "        buffer = []\n",
        "        buffer_len = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_len = len(sentence)\n",
        "\n",
        "            if buffer_len + sentence_len > MAX_CHAR_LEN:\n",
        "                super_list_concatenated.append(\" \".join(buffer))\n",
        "                super_list_raw_sentences.extend(buffer)\n",
        "                buffer = []\n",
        "                buffer_len = 0\n",
        "\n",
        "            buffer.append(sentence)\n",
        "            buffer_len += sentence_len\n",
        "\n",
        "        if buffer:  # If there are any remaining sentences in the buffer\n",
        "            super_list_concatenated.append(\" \".join(buffer))\n",
        "            super_list_raw_sentences.extend(buffer)\n",
        "\n",
        "        return super_list_concatenated, super_list_raw_sentences\n",
        "\n",
        "    def _sample_chunk_span(self, text, max_chunk_length_char):\n",
        "        chunks = self.split_into_chunks(text, max_chunk_length_char)\n",
        "        # randomly sample from the chunks\n",
        "        #FOOBAR SAMPLE FROM CHUNKS\n",
        "        return random.choice(chunks)\n",
        "\n",
        "    def is_too_small_quickcheck(self, text, textlen=None):\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.min_seq_length_char*0.9\n",
        "\n",
        "    def is_too_small(self, nwords):\n",
        "        return nwords < self.min_seq_length\n",
        "\n",
        "    def is_larger_than_max_chunk_quickcheck(self, text, textlen):\n",
        "        \"\"\"if it is larger than a chunksize, then we need to sample chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen > self.max_chunk_length_char\n",
        "\n",
        "    def is_short_than_a_chunk(self, text, textlen):\n",
        "        \"\"\"if it is shorter than a chunk, then we'll take all text, in chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.max_chunk_length_char\n",
        "\n",
        "    def is_smaller_than_two_paragraphs(self, text):\n",
        "        charlen = len(text)\n",
        "        if charlen < (1.5*self.max_seq_length*self.char_per_word):\n",
        "            return True, re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        if charlen > (2.5*self.max_seq_length*self.char_per_word):\n",
        "            return False, None\n",
        "        # inbetween cases, split and calculate the number of words\n",
        "        textsplit = re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        nwords = len(textsplit)\n",
        "        if nwords < 1.2*self.max_seq_length:\n",
        "            return True, textsplit\n",
        "        return False, textsplit\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_sentences(list_of_sentences, min_sentence_char_length):\n",
        "        \"\"\"Merges small sentences in a sequence of sentence, until the strings are greater than `min_sentence_char_length`\"\"\"\n",
        "        processed_sentences = []\n",
        "        buffer = \"\"\n",
        "\n",
        "        for sentence in list_of_sentences:\n",
        "            if len(sentence) < min_sentence_char_length:\n",
        "                buffer = buffer + \" \" + sentence\n",
        "                if (len(buffer)>=min_sentence_char_length):\n",
        "                    processed_sentences.append(buffer.strip())\n",
        "                    buffer = \"\"\n",
        "            else:\n",
        "                if (len(buffer)<min_sentence_char_length):\n",
        "                    to_add = buffer + \" \" + sentence\n",
        "                    processed_sentences.append(to_add.strip())\n",
        "                    buffer = \"\"\n",
        "                else:\n",
        "                    processed_sentences.extend([buffer.strip(), sentence.strip()])\n",
        "\n",
        "        if buffer:  # If there are any remaining sentences in the buffer\n",
        "            processed_sentences.append(buffer)\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def process(self, text):\n",
        "        \"\"\"Chunks and samples large portions of text\"\"\"\n",
        "\n",
        "        charlen = len(text.strip())\n",
        "\n",
        "        # DISCARD if it is too small for copus\n",
        "        if self.is_too_small_quickcheck(text, charlen):\n",
        "\n",
        "            return {'text':[], 'do_accept':False, 'sentences':[]}\n",
        "\n",
        "        # sample span of chunks: if it larger than our max chunk size\n",
        "        if self.is_larger_than_max_chunk_quickcheck(text, charlen):\n",
        "            text_span_chunks = self._sample_chunk_span(text, self.max_chunk_length_char)\n",
        "        else:\n",
        "            text_span_chunks = text\n",
        "\n",
        "        # check if it smaller, than 1.5 seqlen, then we just accept it all as one unit to truncate later in tokenizer\n",
        "        is_smaller_than_2_paras, textsplit = self.is_smaller_than_two_paragraphs(text_span_chunks)\n",
        "\n",
        "        if is_smaller_than_2_paras:\n",
        "\n",
        "            # check if less than minsize\n",
        "            if self.is_too_small(len(textsplit)):\n",
        "                # if too small, return nothing\n",
        "                return {'text':[], 'do_accept':False, 'sentences':[]}\n",
        "\n",
        "            # return text to be truncated\n",
        "            return {'text':[text_span_chunks], 'do_accept':True, 'sentences':[]}\n",
        "\n",
        "        # leftover cases: text that needs to be chunked into ~512 / max_seq_len\n",
        "        text_to_return, sentences_to_return = self.split_chunk_into_sentences(text_span_chunks)\n",
        "\n",
        "        # return text strings as list of chunks, flag\n",
        "        return {\n",
        "            'text':text_to_return,\n",
        "            'do_accept':True,\n",
        "            'sentences':self.preprocess_sentences(sentences_to_return, self.min_sentence_length_char),\n",
        "        }\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.process(text)\n",
        "if False:\n",
        "    example_processor = ExampleProcessor(config=data_streaming_config, char_per_word = CHAR_PER_WORD, nlp =nlp)\n",
        "    text = \"\"\"As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy's capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor.Red-faced, the Army Air Corps commanders sought to minimize the attack's results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell's carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game's umpires sided with the Army. Their report made no mention of Yarnell's attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy's victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**\"\"\"\n",
        "    text += text\n",
        "    text += text\n",
        "    text += text\n",
        "    text += text\n",
        "    foo = example_processor(text = text)\n",
        "    foo,is_good, foo_sentences = foo.values()\n",
        "    print(is_good)\n",
        "    print('mlm_sentences')\n",
        "    print(foo)\n",
        "\n",
        "    print('next sentences:') # this seems to be working okay\n",
        "    print(foo_sentences)\n",
        "    print(len(foo_sentences))\n",
        "\n",
        "\n",
        "    # works: test the process_sentences\n",
        "    print(example_processor.preprocess_sentences([\"This is fine.\",\"foo\",'sh',\"This is fine and long.\",\"This is also find and long.\",'No', \"This is long and good.\"], 10))\n",
        "\n",
        "    # works, this returns split sentences\n",
        "    example_processor.split_chunk_into_sentences(\n",
        "        chunk=\"This is the first sentence. This is the 2nd sentence and another. I'm the third sentence. Hello, this is me. 5th sentence here. And finally its me.\",\n",
        "        discard_first_sentence=True, discard_last_sentence=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJXQz58BQIub"
      },
      "outputs": [],
      "source": [
        "### Random (Smark) Negative Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy5s-lmwQL75"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import pynndescent\n",
        "import numpy as np\n",
        "import os\n",
        "from math import prod\n",
        "\n",
        "class NegativeExampleGenerator:\n",
        "    \"\"\"Builds a queryable corpus of negative examples using ANN and approximate TFIDF vectors\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_reps = 1,\n",
        "            n_takes = 5000,\n",
        "            #dataset_name = 'cerebras/SlimPajama-627B',\n",
        "            tfidf_nfeatures = 3000,\n",
        "            nchar_max_paragraph=3000,\n",
        "            nword_max=100,\n",
        "            nchar_max_word=4,\n",
        "            max_sent_total = 5,\n",
        "            corpus = None,\n",
        "            save_cache = '/tmp/negative_corpus_cache.pkl'\n",
        "    ):\n",
        "        self.stopwords = [\n",
        "            'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n",
        "            'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its',\n",
        "            'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
        "            'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
        "            'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',\n",
        "            'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',\n",
        "            'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up',\n",
        "            'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
        "            'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n",
        "            'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will',\n",
        "            'just', 'don', 'should', 'now'\n",
        "        ]\n",
        "        self.n_reps = n_reps\n",
        "        self.n_takes = n_takes\n",
        "        self.tfidf_nfeatures = tfidf_nfeatures\n",
        "        self.nchar_max_paragraph = nchar_max_paragraph\n",
        "        self.nword_max = nword_max\n",
        "        self.nchar_max_word = nchar_max_word\n",
        "        self.max_sent_total = max_sent_total\n",
        "        self.save_cache = save_cache\n",
        "        if corpus is None:\n",
        "            # fetch the corpus from streaming data (or reload from cache if available)\n",
        "            print('warning: `corpus` is empty. Generating default corpus from RedPajama')\n",
        "            self.corpus_static = self.fetch_default_corpus(self.save_cache)\n",
        "        else:\n",
        "            assert isinstance(corpus,list)\n",
        "            assert len(corpus)>0\n",
        "            print('using predefined corpus of length: %s' % len(corpus))\n",
        "            self.corpus_static = corpus\n",
        "\n",
        "        # build an ann index\n",
        "        self.build_ann_index(self.corpus_static)\n",
        "\n",
        "    def fetch_default_corpus(self, cache_file):\n",
        "        \"\"\"fetches streaming corpus and converts to a static list of data\"\"\"\n",
        "        corpus_static = []\n",
        "        if os.path.isfile(cache_file):\n",
        "            print('reloading negative corpus %s for NegativeExampleGenerator' % cache_file)\n",
        "            with open(cache_file, 'rb') as pcon:\n",
        "                corpus_static = pickle.load(pcon)\n",
        "                self.n_reps = pickle.load(pcon)\n",
        "                self.n_takes = pickle.load(pcon)\n",
        "                self.tfidf_nfeatures = pickle.load(pcon)\n",
        "                self.nchar_max_paragraph = pickle.load(pcon)\n",
        "                self.nword_max = pickle.load(pcon)\n",
        "                self.nchar_max_word = pickle.load(pcon)\n",
        "                self.max_sent_total = pickle.load(pcon)\n",
        "        else:\n",
        "            print('fetching streaming corpus for negatives (RedPajama)(%s reps)' % self.n_reps)\n",
        "            # first do random draws from the corpora\n",
        "            redpajama_set_name_support = [\"RedPajamaCommonCrawl\", \"RedPajamaC4\", \"RedPajamaStackExchange\", \"RedPajamaWikipedia\",\"RedPajamaBook\", \"RedPajamaArxiv\"]\n",
        "            for i_rep in range(self.n_reps):\n",
        "                # load the streaming datasets (RedPajama)\n",
        "                corpus_streaming = datasets.load_dataset(\n",
        "                    'cerebras/SlimPajama-627B',\n",
        "                    split=\"train\",\n",
        "                    streaming=True\n",
        "                ).shuffle(\n",
        "                    buffer_size = self.n_takes\n",
        "                ).filter(\n",
        "                    lambda x : x['meta']['redpajama_set_name'] in redpajama_set_name_support\n",
        "                ).take(\n",
        "                    self.n_takes\n",
        "                ).remove_columns('meta')\n",
        "                # convert streaming data to static and check language\n",
        "                this_corpus_static = [\n",
        "                    e['text'] for e in corpus_streaming #if langdetect(e['text'][:200]+' hello')=='en'\n",
        "                    if check_language(e['text'])[0]\n",
        "                ]\n",
        "                # take only a few sentences per text\n",
        "                this_corpus_static = [\n",
        "                    self.limit_text_to_k_sentences(s, k=self.max_sent_total) for s in this_corpus_static\n",
        "                ]\n",
        "                # filtering again non-english\n",
        "                this_corpus_static = [\n",
        "                    s for s in this_corpus_static\n",
        "                    if check_language(s)[0]\n",
        "                ]\n",
        "                # add\n",
        "                corpus_static += this_corpus_static\n",
        "                if (i_rep % 5)==0:\n",
        "                    print('size of negative corpus: %d' % len(corpus_static))\n",
        "\n",
        "            print('finished collecting streaming examples for negative corpus. Saving to %s' % self.save_cache)\n",
        "            # save the cache\n",
        "            with open(self.save_cache, 'wb') as pcon:\n",
        "                pickle.dump(corpus_static, pcon)\n",
        "                pickle.dump(self.n_reps, pcon)\n",
        "                pickle.dump(self.n_takes, pcon)\n",
        "                pickle.dump(self.tfidf_nfeatures, pcon)\n",
        "                pickle.dump(self.nchar_max_paragraph, pcon)\n",
        "                pickle.dump(self.nword_max, pcon)\n",
        "                pickle.dump(self.nchar_max_word, pcon)\n",
        "                picke.dump(self.max_sent_total, pcon)\n",
        "\n",
        "        return corpus_static\n",
        "\n",
        "    def build_ann_index(self, corpus):\n",
        "        \"\"\"vectorizes a corpus and builds an ann index\"\"\"\n",
        "        # stem words in preparation for tfidf vectorizer\n",
        "        corpus_processed = [\n",
        "            self.preprocess_text_to_index(s) for s in corpus\n",
        "        ]\n",
        "        # convert the corpus into tfidfvectors\n",
        "        self.tfidfvectorizer = TfidfVectorizer(max_features=self.tfidf_nfeatures)\n",
        "        self.tfidfvectorizer.fit(corpus_processed)\n",
        "        self.corpus_vectors = self.tfidfvectorizer.transform(corpus_processed)\n",
        "\n",
        "        # build the ann index\n",
        "        self.ann_index = pynndescent.NNDescent(self.corpus_vectors)\n",
        "        print('finished building the ANN index')\n",
        "\n",
        "    @staticmethod\n",
        "    def limit_text_to_k_sentences(text, k=5):\n",
        "        \"\"\"splits text into sentences, then limits the paragraph to just `k` sentences\"\"\"\n",
        "        if len(text)<400:\n",
        "            return text\n",
        "        text = text[:10000]\n",
        "        sentences = [s for s in re.split(r\"(?<=\\w\\w\\.)\\s+\",text) if len(s)>1]\n",
        "        n_sent = len(sentences)\n",
        "        if n_sent<=k:\n",
        "            return text\n",
        "        # if larger than limit, pick a (pseudo)random set of sentences\n",
        "        random_sent_start_max_offset = n_sent-k\n",
        "        random_sent_start_offset = ord(sentences[-1][:10][-1]) % random_sent_start_max_offset\n",
        "        random_sent_end_offset = random_sent_start_offset + k\n",
        "        return \" \".join(sentences[random_sent_start_offset:random_sent_end_offset])\n",
        "\n",
        "    def preprocess_text_to_index(self, text):\n",
        "        \"\"\"converts text into small k-character word stems before passing to TFIDF\"\"\"\n",
        "        ptext = text[:self.nchar_max_paragraph].lower()\n",
        "        ptext = ' '.join([\n",
        "            w[:self.nchar_max_word] for w in ptext.split(' ')[:self.nword_max]\n",
        "            if (w not in self.stopwords)\n",
        "        ])\n",
        "        ptext = re.sub(\"\\W+\",' ',ptext).strip()\n",
        "        return ptext\n",
        "\n",
        "    def process_query(self,text):\n",
        "        \"\"\"Vectorizes query text for retrieval\"\"\"\n",
        "        query_processed = self.preprocess_text_to_index(text)\n",
        "        return self.tfidfvectorizer.transform([query_processed]), query_processed\n",
        "\n",
        "    def find_negative(self, query_text, k=1, skip=1):\n",
        "        \"\"\"Finds similar text to the query text, skipping the first `skip` and returning `k` top matches\"\"\"\n",
        "        query_vector, query_processed = self.process_query(query_text)\n",
        "        ann_idx,scores = self.ann_index.query(query_vector, k = k+skip)\n",
        "        retrieved_text = [\n",
        "            self.corpus_static[i] for i in ann_idx[0][skip:]\n",
        "        ]\n",
        "        retrieved_text = [\n",
        "            s for s in retrieved_text\n",
        "            if (\n",
        "                s.lower().replace(\" \",\"\")[:100]!=query_text.lower().replace(\" \",\"\")[:100]\n",
        "            )\n",
        "        ]\n",
        "        if len(retrieved_text)>0:\n",
        "            return retrieved_text, scores\n",
        "        # check that the texts are different\n",
        "        skip+=1\n",
        "        return self.find_negative(query_text, k=k, skip=skip)\n",
        "\n",
        "# Build the Negative Corpus\n",
        "negative_example_generator= NegativeExampleGenerator(\n",
        "    n_reps = 1, #\n",
        "    n_takes = 40000,\n",
        "    tfidf_nfeatures = 4000,\n",
        "    nchar_max_paragraph=3000,\n",
        "    nword_max=100,\n",
        "    nchar_max_word=4,\n",
        "    save_cache = 'negative_corpus_cache.pkl'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISTzJb5XQ8Ud",
        "outputId": "a0dc6566-e3a9-4ed4-90d4-565327d5bde2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "كما أنّ ضرب الأسواق المدنية المزدحمة، الذي أسفر عن مقتل ما يقرب من مائة من مواطنيها، من قبل الحكومة أمر غير مقبول في أي ظرف من الظروف،\" قال السيّد دي مستورا. هجمات أمس تأتي في أعقاب القصف العشوائي على دمشق الاسبوع الماضي من قبل جماعات المعارضة المسلحة وقطع إمدادات المياه، وجميعها تدابير تؤثر على المدنيين وهو أمر غير مقبول. هذه الهجمات الاخيرة هي مثال آخر على وحشية الصراع الدائر. \"يجب السماح بوصول المساعدات الإنسانية دون قيد أو شرط ويجب أن يُتوقّف القتل.\n"
          ]
        }
      ],
      "source": [
        "# test query\n",
        "neg_retrievals,_ = negative_example_generator.find_negative(\n",
        "    \"MIT is an elite education institution based in Boston Massatusetts and is one of the first institutions of higher learning in the USA, dating back to the founding fathers. Recently, it has become embroiled in a series of scandels to do with free speech and allegations of scientific misconduct\",\n",
        "    k=1, skip=1\n",
        ")\n",
        "for _ in neg_retrievals: print(_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSP-Hmb8vUm_"
      },
      "source": [
        "#### A Sample of 1000 will have...\n",
        "... approximately 1523 samples of 512-long examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmhZQWnl1EUQ",
        "outputId": "0f914448-6879-4d45-c0c5-39054e8d9e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'anchor': 'a b c', 'next': 'd', 'opposite': 'f'}, {'anchor': 'b c d', 'next': 'e', 'opposite': 'a'}, {'anchor': 'c d e', 'next': 'f', 'opposite': 'b'}]\n"
          ]
        }
      ],
      "source": [
        "# FUNCTIONS TO MAKE THE TRAINING AND VAL SETs\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "## convert the streaming dataset in a static dataset\n",
        "def convert_streaming_dataset_to_static_corpus(\n",
        "    streaming_dataset,\n",
        "    skip=0,\n",
        "    take=1000\n",
        "):\n",
        "    \"\"\"Takes a streaming_dataset and converts it into a list of examples\"\"\"\n",
        "    if skip !=0:\n",
        "        dataset_to_make_static = streaming_dataset.skip(skip).take(take)\n",
        "    else:\n",
        "        dataset_to_make_static = streaming_dataset.take(take)\n",
        "\n",
        "    examples_static_mlm = [] # data for MLM objective\n",
        "    examples_static_nextsentence = [] # data for next sentence task\n",
        "    for i, example in enumerate(dataset_to_make_static):\n",
        "        # chunk text into ~512 text-strings, and sentences\n",
        "        examples_processed = example_processor(text = example['text'])\n",
        "        # chunk, accept/reject, sentences\n",
        "        example_parsed, do_accept, parsed_sentences = examples_processed.values()\n",
        "        if is_do_acceptgood:\n",
        "            # mlm gets the chunks of text-strings\n",
        "            examples_static_mlm.extend(example_parsed)\n",
        "            if len(parsed_sentences)>15:\n",
        "                # sentences for next sentence prediction: make triplet of s1,s2,opposite, where opposites get label=1\n",
        "                examples_static_nextsentence.extend(\n",
        "                    convert_sequence_into_nextsentence_pairs(parsed_sentences)\n",
        "                )\n",
        "                #FOOFU - STOPPED HERE TO FIGURE OUT WHY MY NEXT-SENTENCE STUFF IS SO LONG\n",
        "        if (i+1)%100==0:\n",
        "            print(\"...streaming size: \" % len(examples_static_mlm))\n",
        "\n",
        "    return examples_static_mlm, examples_static_nextsentence\n",
        "\n",
        "def convert_sequence_into_nextsentence_pairs(list_of_sentences):\n",
        "    \"\"\"Converts a list of sentences into a list of dicts, with next-sentence pairs\"\"\"\n",
        "    n = len(list_of_sentences)\n",
        "\n",
        "    def opposite(i,n):\n",
        "        return (i + round(n/2+1)) % n\n",
        "\n",
        "    list_of_nextsentence_pairs = []\n",
        "    # loop through sequence, make triplet of anchor1+anchor2, next and an opposite\n",
        "    #for o1a, o1b, o2 in zip(range(0,n-2), range(1,n-1), range(2,n)):\n",
        "    for o1a, o1b, o1c, o2 in zip(range(0,n-3), range(1,n-2), range(2,n-1), range(3,n)):\n",
        "        # anchor text is three sentences\n",
        "        s_anchor = list_of_sentences[o1a] + \" \" + list_of_sentences[o1b] + \" \" +  list_of_sentences[o1c]\n",
        "        # target is the fourth (next-sentence)\n",
        "        s_next = list_of_sentences[o2]\n",
        "        s_opposite = list_of_sentences[opposite(o1b,n)]\n",
        "        list_of_nextsentence_pairs.append(\n",
        "            {\n",
        "                \"anchor\":s_anchor,\n",
        "                \"next\":s_next,\n",
        "                \"opposite\":s_opposite\n",
        "            }\n",
        "        )\n",
        "    return list_of_nextsentence_pairs\n",
        "\n",
        "print(convert_sequence_into_nextsentence_pairs(['a','b','c','d','e','f']))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXTSEPARATOR = \"%0XTEXTXEPARAT0RX%0\"\n",
        "\n",
        "def chunk_docs_into_chunks_and_sentences(\n",
        "    list_of_strings,\n",
        "    nlp=None,\n",
        "    config_chunking=None,\n",
        "    seed = 42,\n",
        "    fieldname='text',\n",
        "    min_number_of_sentence_for_nextsentence_prediction = 15\n",
        "):\n",
        "    \"\"\"Splits long docs into chunks that do next exceet max_seq_len, as well as sentences for next-sentence-prediction \"\"\"\n",
        "    if nlp is None:\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "        nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "    if config_chunking is None:\n",
        "        config_chunking = {\n",
        "            'max_seq_length':512,\n",
        "            'min_seq_length':48,\n",
        "            'max_chunk_size':6,\n",
        "            'min_sentence_len':20,\n",
        "            'seed':seed\n",
        "        }\n",
        "    else:\n",
        "        config_chunking.update({'seed':seed})\n",
        "\n",
        "    # initialize the example processor\n",
        "    example_processor = ExampleProcessor(\n",
        "        config=config_chunking, char_per_word = CHAR_PER_WORD, nlp =nlp\n",
        "    )\n",
        "\n",
        "    examples_static_chunks = [] # data for MLM objective\n",
        "    examples_static_nextsentence = [] # data for next sentence task\n",
        "    for i, example in enumerate(list_of_strings):\n",
        "        # chunk text into ~512 text-strings, and sentences\n",
        "        if isinstance(example,str):\n",
        "            examples_processed = example_processor(text = example)\n",
        "        elif isinstance(example,dict):\n",
        "            examples_processed = example_processor(text = example[fieldname])\n",
        "        # chunk, accept/reject, sentences\n",
        "        example_parsed, do_accept, parsed_sentences = examples_processed.values()\n",
        "        if do_accept:\n",
        "            # mlm gets the text-strings chunked to size 512\n",
        "            examples_static_chunks.extend(example_parsed)\n",
        "            if len(parsed_sentences)> min_number_of_sentence_for_nextsentence_prediction: #4:\n",
        "                # sentences for next sentence prediction: make triplet of s1,s2,opposite, where opposites get label=1\n",
        "                examples_static_nextsentence.extend(\n",
        "                    convert_sequence_into_nextsentence_pairs(parsed_sentences)\n",
        "                )\n",
        "\n",
        "    return examples_static_chunks, examples_static_nextsentence\n",
        "\n",
        "def nwords_quick(text):\n",
        "    return len([w for w in text.split(\" \") if len(w)>0])\n",
        "\n",
        "def flatten(list_of_lists):\n",
        "    return [subl for l in list_of_lists for subl in l]\n",
        "\n",
        "def initialize_and_get_mlm_streaming_datasets(\n",
        "    data_streaming_config,\n",
        "    streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_mlm.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_mlm_%03g.pkl',\n",
        "    do_check_english = True\n",
        "):\n",
        "    \"\"\"Converts stream of unlabelled text data into static datasets for: MLM task and next-sentence-prediction task\"\"\"\n",
        "    # list of files to stream\n",
        "    files = data_streaming_config['files']\n",
        "    # number of examples to take from stream for validation set\n",
        "    val_size = data_streaming_config['val_size']\n",
        "    # number of examples to take from stream for training set\n",
        "    train_chunk_size = data_streaming_config['train_chunk_size']\n",
        "    min_seq_len = data_streaming_config['min_seq_length']\n",
        "    # normalization constant for normalizing the weights into probabilities\n",
        "    probability_normalization_const = sum([x[2] for x in files])\n",
        "\n",
        "    # where to initialize start-stream for training data\n",
        "    if start_proportion is None:\n",
        "        start_proportion = np.random.RandomState(seed+epoch).uniform()*0.99\n",
        "\n",
        "    # reload cached files\n",
        "    path_to_train_cache = None if not '%03g' in path_to_train_cache_epoch else path_to_train_cache_epoch % epoch\n",
        "    do_make_valset = not os.path.isfile(path_to_val_cache)\n",
        "    do_make_trainset = not os.path.isfile(path_to_train_cache)\n",
        "    if not do_make_valset:\n",
        "        print('RELOADING VAL-MLM SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            datalist_val_mlm_static = pickle.load(pcon)\n",
        "            datalist_val_sentences_static = pickle.load(pcon)\n",
        "            epoch = pickle.load(pcon)\n",
        "            log_source_val = pickle.load(pcon)\n",
        "        print('VAL-MLM SET SIZE: %d' % len(datalist_val_mlm_static))\n",
        "    else:\n",
        "        datalist_val_mlm_static, datalist_val_sentences_static, log_source_val = [],[],{}\n",
        "    if not do_make_trainset:\n",
        "        print('RELOADING VAL-QA SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_train_cache,'rb') as pcon:\n",
        "            datalist_train_mlm_static = pickle.load(pcon)\n",
        "            datalist_train_sentences_static = pickle.load(pcon)\n",
        "            epoch = pickle.load(pcon)\n",
        "            log_source_train = pickle.load(pcon)\n",
        "        print('TRAIN-MLM EPOCH-%d SET SIZE: %d' % (epoch, len(datalist_train_mlm_static)))\n",
        "    else:\n",
        "        datalist_train_mlm_static, datalist_train_sentences_static,log_source_train = [],[],{}\n",
        "\n",
        "    if (do_make_trainset or do_make_valset):\n",
        "\n",
        "        # initialize the nlp-sentencizer for chunking\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "        nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "        # loop through datasets\n",
        "        for (mlm_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle, threshold_specialchar), dataset_key in zip(\n",
        "            files, streaming_cleaning_functions.keys()\n",
        "        ):\n",
        "            if prob ==0:\n",
        "                continue\n",
        "            prob /= probability_normalization_const\n",
        "\n",
        "            # get cleaning & filter functions for streaming data functionality\n",
        "            clean_func, filter_func, removefeature_names = streaming_cleaning_functions[dataset_key]\n",
        "\n",
        "            # set arguments for the load_dataset (huggingface repos)\n",
        "            load_dataset_args = {\n",
        "                'path':mlm_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "            }\n",
        "            # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "            if mlm_nm.endswith('.jsonl') or mlm_nm.endswith('.jsonl.zip') or mlm_nm.endswith('.jsonl.zst'):\n",
        "                load_dataset_args.update({'path':'json','data_files':mlm_nm})\n",
        "\n",
        "            # special proecssing of datasets with multiple partitions\n",
        "            if bool(partition_shuffle): # or str(epoch)=='val':\n",
        "\n",
        "                n_files, n_per_file = partition_shuffle\n",
        "                dataset_size = n_per_file\n",
        "                print('trying %s initialization (shuffling through %d files)' % (mlm_nm, n_files))\n",
        "\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func)\n",
        "\n",
        "                # validation set\n",
        "                if do_make_valset:\n",
        "                    # take from stream\n",
        "                    n_valset_take = max(int(prob*val_size), 1)\n",
        "                    print('take %d from %s validation'% (n_valset_take, mlm_nm))\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert stream to a static set (and check english language)\n",
        "                    dset_static_val_thisset =[\n",
        "                        e['text'] for e in dset_stream_val\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "                # training set\n",
        "                if do_make_trainset:\n",
        "                    # randomly skip a bunch from this set\n",
        "                    skip_to_start = int(start_proportion*n_per_file)\n",
        "                    take_from_this_set = max(int(round(train_chunk_size*prob)),1)\n",
        "                    print('take %d from %s training'% (take_from_this_set, mlm_nm))\n",
        "                    # shuffle: take a random data partition (from the dataset's list of files)\n",
        "                    dset_stream_train = dset_stream.shuffle(\n",
        "                        seed = seed+epoch, buffer_size = skip_to_start+take_from_this_set,\n",
        "                    )\n",
        "                    dset_stream_train = dset_stream_train.skip(\n",
        "                        skip_to_start # random skip through dataset to new start position\n",
        "                    ).take(\n",
        "                        take_from_this_set # take this amount for the training ste\n",
        "                    ).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert training to static dataset\n",
        "                    dset_static_train_thisset =[\n",
        "                        e['text'] for e in dset_stream_train\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "            else:\n",
        "                # regular streaming\n",
        "                print('trying %s initialization' % mlm_nm)\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "                # take from stream\n",
        "                n_valset_take = max(int(prob*val_size), 1) # size of valset\n",
        "                print('take %d from %s validation'% (n_valset_take, mlm_nm))\n",
        "                skip_to_start = int(start_proportion*(dataset_size-n_valset_take)) # random point to skip to\n",
        "                n_train_take = max(int(round(train_chunk_size*prob)),1) # size of train set\n",
        "                print('take %d from %s train'% (n_train_take, mlm_nm))\n",
        "                if do_make_valset:\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take)\n",
        "                    # checking for: existence of any words and ii) size of sequence meets minimum criteria\n",
        "                    dset_static_val_thisset = [\n",
        "                        e['text'] for e in dset_stream_val\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "                if do_make_trainset:\n",
        "                    dset_stream_train = dset_stream.skip(n_valset_take+skip_to_start).take(n_train_take)\n",
        "                    # checking for: existence of any words and ii) size of sequence meets minimum criteria\n",
        "                    dset_static_train_thisset = [\n",
        "                        e['text'] for e in dset_stream_train\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "            print('Done getting streams/reloading from %s' % mlm_nm)\n",
        "            # check language, chunk sentences\n",
        "            if do_make_valset:\n",
        "                # discard non-english\n",
        "                dset_static_val_thisset =[\n",
        "                    e for e in dset_static_val_thisset\n",
        "                    if check_language(e, threshold_specialchar)[0]\n",
        "                ]\n",
        "                print('done val language check')\n",
        "                # split multi-answers that I want made into separate texts\n",
        "                dset_static_val_thisset = [\n",
        "                    e for e in dset_static_val_thisset\n",
        "                    if TEXTSEPARATOR not in e\n",
        "                ] + flatten([\n",
        "                    e.split(TEXTSEPARATOR) for e in dset_static_val_thisset\n",
        "                    if TEXTSEPARATOR in e\n",
        "                ])\n",
        "                # chunk the docs (512-tokens and next-sentence prediction sentences)\n",
        "                dset_val_chunked_for_mlm, dset_val_nextsentence = chunk_docs_into_chunks_and_sentences(\n",
        "                    list_of_strings=dset_static_val_thisset,\n",
        "                    config_chunking=copy.deepcopy(data_streaming_config),\n",
        "                    seed=seed+epoch,\n",
        "                    nlp=nlp\n",
        "                )\n",
        "                print('done val longtext chunking')\n",
        "                # add to val set\n",
        "                datalist_val_mlm_static.extend(dset_val_chunked_for_mlm)\n",
        "                datalist_val_sentences_static.extend(dset_val_nextsentence)\n",
        "                # log the sources of text\n",
        "                log_source_val[dataset_key] = len(dset_val_chunked_for_mlm)\n",
        "\n",
        "            # check language, chunk sentences\n",
        "            if do_make_trainset:\n",
        "                # discard non-english\n",
        "                dset_static_train_thisset =[\n",
        "                    e for e in dset_static_train_thisset\n",
        "                    if check_language(e, threshold_specialchar)[0]\n",
        "                ]\n",
        "                print('done train language check')\n",
        "                # split multi-answers that I want made into separate texts\n",
        "                dset_static_val_thisset = [\n",
        "                    e for e in dset_static_train_thisset\n",
        "                    if TEXTSEPARATOR not in e\n",
        "                ] + flatten([\n",
        "                    e.split(TEXTSEPARATOR) for e in dset_static_train_thisset\n",
        "                    if TEXTSEPARATOR in e\n",
        "                ])\n",
        "                # chunk the docs (512-tokens and next-sentence prediction sentences)\n",
        "                dset_train_chunked_for_mlm, dset_train_nextsentence = chunk_docs_into_chunks_and_sentences(\n",
        "                    list_of_strings=dset_static_train_thisset,\n",
        "                    config_chunking=copy.deepcopy(data_streaming_config),\n",
        "                    seed=seed+epoch,\n",
        "                    nlp=nlp\n",
        "                )\n",
        "                print('done trains longtext chunking')\n",
        "\n",
        "                # ensure that none of the examples in the traning set are in the validation set\n",
        "                if do_make_valset:\n",
        "                    dset_train_chunked_for_mlm = [\n",
        "                        s for s in dset_train_chunked_for_mlm\n",
        "                        if s not in dset_val_chunked_for_mlm\n",
        "                    ]\n",
        "                    dset_train_nextsentence = [\n",
        "                        tlt for tlt in dset_train_nextsentence\n",
        "                        if (\n",
        "                            tlt['anchor'] not in [\n",
        "                                vtlt['anchor'] for vtlt in dset_val_nextsentence\n",
        "                            ]\n",
        "                        )\n",
        "                    ]\n",
        "\n",
        "                # add to training set\n",
        "                datalist_train_mlm_static.extend(dset_train_chunked_for_mlm)\n",
        "                datalist_train_sentences_static.extend(dset_train_nextsentence)\n",
        "                # log the sources of text\n",
        "                log_source_train[dataset_key] = len(dset_train_chunked_for_mlm)\n",
        "\n",
        "        print('Done collecting streaming data')\n",
        "\n",
        "    if do_make_valset:\n",
        "        print('saving streamed validation data: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_val_mlm_static, pcon)\n",
        "            pickle.dump(datalist_val_sentences_static, pcon)\n",
        "            pickle.dump(epoch,pcon)\n",
        "            pickle.dump(log_source_val, pcon)\n",
        "    if do_make_trainset:\n",
        "        print('saving streamed training for epoch %d: %s' % (epoch, path_to_train_cache))\n",
        "        with open(path_to_train_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_train_mlm_static, pcon)\n",
        "            pickle.dump(datalist_train_sentences_static, pcon)\n",
        "            pickle.dump(epoch,pcon)\n",
        "            pickle.dump(log_source_train,pcon)\n",
        "    return {\n",
        "        'train':{\n",
        "            'mlm':datalist_train_mlm_static,\n",
        "            'nextsentence':datalist_train_sentences_static\n",
        "        },\n",
        "        'val':{\n",
        "            'mlm':datalist_val_mlm_static,\n",
        "            'nextsentence':datalist_val_sentences_static\n",
        "        },\n",
        "        'epoch':epoch,\n",
        "        'index_stream':start_proportion,\n",
        "        'log_source':{'train':log_source_train, 'val':log_source_val}\n",
        "    }"
      ],
      "metadata": {
        "id": "xKzN6v3_imHY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sjJhRB5fBZBB"
      },
      "outputs": [],
      "source": [
        "DEBATESUM_EXTREMIST_FILTER_OUT1 = ['13th Aff - DDI 2020 AT.html5', '13th Amendment Case Neg - DDI 2020 GG.html5', '13th Amendment Neg - DDI 2020 FS.html5', '13th Neg - DDI 2020 AT.html5', '13th Neg - DDI 2020 KM.html5', '1ac Airports - DDI 2015 KQ.html5', '1ac Borders - DDI 2015 KQ.html5', '1ac critical financial surveillance pedagogy - DDI 2015 KS.html5', '2 for 1 DA - JDI 2017.html5', '2020 DA - Berkeley 2019.html5', '2020 DA - MSDI 2020.html5', '2020 Election DA - JDI 2020.html5', '2020 Election-Starter - Georgetown 2020.html5', '2020 Elections DA - Michigan7 2019 CCPW.html5', '2nd Session Packet - WTO topic - TDI 2021.html5', 'A Door Into the Ocean Affirmative - HSS 2014.html5', 'A Door Into the Ocean Negative - HSS 2014.html5', 'AIIB Aff Supplement - Michigan7 2016.html5', 'AIIB Aff Wave 1 - Michigan7 2016.html5', 'AIIB Aff-Neg - JDI 2016.html5', 'AIIB Neg Starter - Michigan7 2016.html5', 'AIIB Neg Updates - MNDI 2016.html5', 'ALPR Negative - Michigan7 2015.html5', 'ANTS Aff - Michigan7 2019 HKMM.html5', 'ASAT Aff-Neg - Rohan - Wake 2016 RKS.html5', 'AT - Advantage CPs Updates - Michigan 7 2022 CPWW.html5', 'AT - Afropessism K - Michigan 7 2022 BFHR.html5', 'AT - Baudrillard K - Michigan 7 2022 K LAB.html5', 'AT - Cap K - Michigan 7 2022 CPWW.html5', 'AT - Cap K - UTNIF 2022.html5', 'AT - Cybernetics K - Starter - Michigan 7 2022.html5', 'AT - DOD Tradeoff DA Starter - Michigan 7 2022.html5', 'AT - Dept of State CP - SDI 2022.html5', 'AT - Empire K - Michigan Classic 2022 BBE.html5', 'AT - Fem IR K - CNDI 2022.html5', 'AT - Fem IR K - Starter - Michigan 7 2022.html5', 'AT - Fund DOD CP - Michigan 7 2022 BEJJ.html5', 'AT - IR Ks - Analytic Eclecticism - Michigan Classic 2022 MMP.html5', 'AT - Imperialism K Supplement - CNDI 2022.html5', 'AT - Leahy Law CP - Michigan 7 2022 FMPS.html5', 'AT - Midterms GOP Good DA - Michigan 7 2022 CPWW.html5', 'AT - Militarism K - CNDI 2022.html5', 'AT - Militarism K - Emory 2022.html5', 'AT - Orientalism K Updates - Michigan 7 2022 CPWW.html5', 'AT - Primacy DA - UTNIF 2022.html5', 'AT - Queer IR K - Michigan 7 2022 CPWW.html5', 'AT - Queer IR K - Michigan Classic 2022 BBE.html5', 'AT - Racial IR K - Michigan 7 2022 FMPS.html5', 'AT - Russian Relations DAs - Michigan 7 2022 CPWW.html5', 'AT - Security K - MSDI 2022.html5', 'AT - Security K - Michigan Classic 2022 BBE.html5', 'AT - Settler Colonialism K - Michigan 7 2022 BFHR.html5', 'AT - Settler Colonialism K - Michigan 7 2022 K LAB.html5', 'AT - Turkey PIC Addendum - UTNIF 2022.html5', 'AT - War Powers Act CP - Michigan 7 2022 FMPS.html5', 'AT Antiblackness Survival Strategies and Word PICs - Ruth - Wake 2016 RKS.html5', 'AT Baudrillard - Wake 2019.html5', 'AT Framework - Northwestern 2015 Sophomores .html5', 'AT Framing Contentions - DDI 2020 GG.html5', 'AT Kritik - Northwestern 2015 6WS.html5', 'AT Queer Terror K - Northwestern 2015.html5', 'AT Rights Malthus - Michigan7 2014 GRAMS.html5', 'AT Third Space - Katie - Wake 2016 RKS Seniors.html5', 'ATC Politics Updates - UTNIF 2017.html5', 'Ableism - Michigan7 2015.html5', 'Ableism K - Michigan7 2021 BFPSW.html5', 'Ableism K v. K Affirmatives - Northwestern 2015.html5', 'Abolish ICE Neg - DDI 2018 KM.html5', 'Abolish ICE aff - Gonzaga 2020 LB.html5', 'Abolish ICE neg - Gonzaga 2020 LB.html5', 'Abolish Policing 1.0 - Gonzaga 2020 LO.html5', 'AbolishICE Aff and Neg Updates 1 - SDI 2020.html5', 'AbolishICE Aff and Neg Updates 2 - SDI 2020.html5', 'AbolishICE Negative - SDI 2020.html5', 'Abolition Aff - Georgetown 2020.html5', 'Abolition Aff Neg Starter - UTNIF 2020.html5', 'Abolition K - Berkeley 2020 Starter Pack.html5', 'Abolition K - JDI 2020.html5', 'Abolition K - Northwestern 2020 BW.html5', 'Abolition K - Session 2 - UTNIF 2017.html5', 'Abolition K - UTNIF 2020.html5', 'Abolition K Starter - Georgetown 2020.html5', 'Abolition K Supplement - Berkeley 2020 Wave 2.html5', 'Abolition K and Aff Answers - Gonzaga 2020 MM.html5', 'Abolition Neg - Georgetown 2020.html5', 'Abolitionist Pedagogy Aff - Berkeley 2017.html5', 'Abolitionist Pedagogy Neg - Berkeley 2017.html5', 'Academic Achievement Core - Wake 2017.html5', 'Academy K - Michigan7 2021 K Lab.html5', 'Academy K - Wake 2019.html5', 'Activism File - UTNIF 2018.html5', 'Addendum - DA - Progressive Opposition DA - Michigan7 2020 BFHPR.html5', 'Addendum - DNA Aff - MichiganClassic 2020 LOSVW.html5', 'Advantage Answers File - UNT 2017.html5', 'Advantage CP - Berkeley 2017.html5', 'Advantage CP - DDI 2018.html5', 'Advantage CP Core - MichiganClassic 2016.html5', 'Advantage CP Core - Northwestern 2015 6WS.html5', 'Advantage CP Toolbox - Northwestern 2014.html5', 'Advantage CPs  - Michigan7 2017 OW.html5', 'Advantage CPs - Anthony - Wake 2016 RKS.html5', 'Advantage CPs - Berkeley 2019.html5', 'Advantage CPs - HSS 2015.html5', 'Advantage CPs - HSS 2017.html5', 'Advantage CPs - Michigan7 2013 PCFJV.html5', 'Advantage CPs - Michigan7 2015.html5', 'Advantage CPs - Michigan7 2016.html5', 'Advantage CPs - Michigan7 2021 BFHPR.html5', 'Advantage CPs - MichiganClassic 2021 BMZ.html5', 'Advantage CPs - Northwestern 2018.html5', 'Advantage CPs - SDI 2021 Scholars.html5', 'Advantage CPs - Wake 2017.html5', 'Advantage CPs Core Supplement - MichiganClassic 2017 OW.html5', 'Aegis Neg - DDI 2019 LO.html5', 'Aerial Surveillance Affirmative - Michigan7 2015.html5', 'Aerial Surveillance Affirmative - Northwestern 2015.html5', 'Aerial Surveillance Negative - Northwestern 2015.html5', 'Aff - AI Clarity - Michigan Classic 2022 CGNO.html5', 'Aff - AI Ethics - Starter - Michigan 7 2022.html5', 'Aff - AI Ethics 2 - MNDI 2022 PHA.html5', 'Aff - AI LAWs - MSDI 2022.html5', 'Aff - AI Logistics - CNDI 2022.html5', 'Aff - AI Subs - Michigan 7 2022 BFHR.html5', 'Aff - AI TEVV - MNDI 2022 PHA.html5', 'Aff - Abolish ICE - MichiganClassic 2020 ACV.html5', 'Aff - Ban OCOs - MSDI 2022.html5', 'Aff - Becoming War - Michigan 7 2022 K LAB.html5', 'Aff - Black Disability - Michigan 7 2022 K LAB.html5', 'Aff - Collateral Consequences - Michigan7 2020 BFHPR.html5', 'Aff - Corporate Crime - Michigan7 2020 BFHPR.html5', 'Aff - Cyber Article 5 - Northwestern 2022.html5', 'Aff - Cyber Space Assets 2 - Michigan 7 2022 BFHR.html5', 'Aff - Cybersecurity - NAUDL 2022.html5', 'Aff - Cyborg Writing - Michigan 7 2022 BFHR.html5', 'Aff - Digital Cyclops - Michigan 7 2022 BFHR.html5', 'Aff - Digital Cyclops 2 - Michigan 7 2022 BFHR.html5', 'Aff - Disease - UTNIF 2022.html5', 'Aff - Disinformation - CNDI 2022.html5', 'Aff - Fem IR - Michigan 7 2022 K LAB.html5', 'Aff - Gendered LAWs - Michigan 7 2022 FMPS.html5', 'Aff - Guantanamo - Michigan7 2020 EHJPS.html5', 'Aff - Imperialism 1AC - Michigan 7 2022 K LAB.html5', 'Aff - Information Warfare - Michigan 7 2022 BEJJ.html5', 'Aff - Information Warfare Addendum - Michigan Classic 2022 HJV.html5', 'Aff - Intellectual Property - Michigan 7 2022 FMPS.html5', 'Aff - K Answer Updates - Michigan7 2020 BFHPR.html5', 'Aff - Marijuana Supplement 2 - Michigan7 2020 BFHPR.html5', 'Aff - Neg - Indeterminate Sentencing - Michigan7 2020 EHJPS.html5', 'Aff - Neg - Mandatory Minimum Sentencing - Michigan7 2020 HKMM.html5', 'Aff - Neg DNA Database Reform - Michigan7 2020 Starter Pack.html5', 'Aff - Neg Death Penalty - Michigan7 2020 Starter Pack.html5', 'Aff - Neg Death Penalty Supplement - MichiganClassic 2020 MMP.html5', 'Aff - Neg Juvenile Justice - Michigan7 2020 CCPTW.html5', 'Aff - Neg Police Militarization Supplement - MichiganClassic 2020 MMP.html5', 'Aff - Neg Sex Workers - MichiganClassic 2020 LOSVW.html5', 'Aff - Neg White Collar Crime Grading - MichiganClassic 2020 LOSVW.html5', 'Aff - OCO Info Sharing - Georgetown 2022.html5', 'Aff - OCOs - Starter - Michigan 7 2022.html5', 'Aff - PRISM - Michigan 7 2022 CPWW.html5', 'Aff - Police Militarization 1ac - Michigan7 2020 Starter Pack.html5', 'Aff - Policing - Michigan7 2020 EHJPS.html5', 'Aff - Policing 2 - Michigan7 2020 EHJPS.html5', 'Aff - Rememory - Michigan 7 2022 BFHR.html5', 'Aff - Sett Col - Michigan7 2020 K Lab.html5', 'Aff - Techno Orientalism - Michigan 7 2022 BFHR.html5', 'Aff - War on Drugs - Michigan7 2020 BFHPR.html5', 'Aff - Warren Terror - Michigan 7 2022 K LAB.html5', 'Aff - Warren Terror Supplement - Michigan 7 2022 K LAB.html5', 'Aff Ans. to Deleuze - Michigan7 2020 K Lab.html5', 'Aff Critique Updates - SDI 2016.html5', 'Aff Economics K - Michigan7 2013.html5', 'Aff K - Deleuze - Michigan7 2020 K Lab.html5', 'Aff K Answers  - MichiganClassic 2019 BFHMRS.html5', 'Aff K Toolbox 2 - Michigan7 2013.html5', 'Aff K of TSA Case Neg - Northwestern 2015 6WS.html5', 'Aff Neg - Environmental Crimes - Michigan7 2020 BFHPR.html5', 'Aff Neolib K 2 - Michigan7 2013.html5', 'Aff Neolib K 3 - Michigan7 2013.html5', 'Aff Schopenhauer K - Michigan7 2013.html5', 'Aff Supplement - SDI 2017 EER.html5', 'Aff Tournament Updates - SDI 2017 PSW.html5', 'Affective Correspondences Aff-Neg - Ruth - Wake 2016 RKS.html5', 'Afghanistan Aff - Michigan7 2016.html5', 'Africa Brain Drain - MichiganClassic 2018 BO.html5', 'Africom Aff - Wake 2019.html5', 'Afro Asia Aff - Michigan7 2016.html5', 'Afro Asia Aff Supplement - Michigan7 2016.html5', 'Afro Pessimism Core - SDI 2015.html5', 'Afro Pessimism Critique - HSS 2015.html5', 'Afro Pessimism-Athanasopolous - Wake 2016 RKS Workshop.html5', 'Afro-Asia Neg - Michigan7 2016.html5', 'Afro-Orientalism Aff - Michigan7 2016.html5', 'Afro-Orientalism Kritik - Wake 2016 RKS K Lab.html5', 'Afro-Orientalism Neg - Michigan7 2016.html5', 'Afro-Pessimism Basic - Wake 2017.html5', 'Afro-Pessimism Core - RKS - Wake 2017.html5', 'Afro-Pessimism K - Michigan7 2016.html5', 'Afro-Pessimism K Answers - Michigan7 2016.html5', 'AfroPessimism - Gonzaga 2014.html5', 'Afrofuturism Aff   Neg - Wake 2017.html5', 'Afrofuturism Aff Supplement - Michigan7 2016.html5', 'Afrofuturism Critique - Michigan7 2015.html5', 'Afrofuturism Neg - DDI 2014 MS.html5', 'Afrofuturism case neg - DDI 2014 SWS.html5', 'Afropessimism - SDI 2018 PSW.html5', 'Afropessimism 2.0 - UTNIF 2020.html5', 'Afropessimism Aff - Wake 2019.html5', 'Afropessimism Aff Neg - Michigan7 2021 K Lab.html5', 'Afropessimism Answers - HSS 2016.html5', 'Afropessimism K - Michigan7 2021 K Lab.html5', 'Afropessimism K - Northwestern 2017.html5', 'Afropessimism Updated - Wake 2016 RKS K Lab.html5', 'Ag DA Supplement - Michigan7 2021 HKMLR.html5', 'Ag Efficiency Aff - Berkeley 2021.html5', 'Ag Efficiency Neg - Berkeley 2021.html5', 'Ag Runoff Aff Neg - UTNIF 2021.html5', 'Ag Runoff Case Neg - MSDI 2021.html5', 'Ag Subsidies Aff - Michigan7 2021 BFHPR.html5', 'Ag Subsidies Case Neg - Michigan7 2021 BFHPR.html5', 'Agamben Aff - UTNIF 2017.html5', 'Agamben Affirmative and Neg - Wake 2018.html5', 'Agamben Affirmative and Negative - Northwestern 2015.html5', 'Agamben Case Neg - UTNIF 2017.html5', 'Agamben Critique 2 - Michigan7 2015.html5', 'Agamben Critique 3 - Michigan7 2015.html5', 'Agamben Critique Answers - Michigan7 2015.html5', 'Agamben K - Master File - UTNIF 2018.html5', 'Agamben K - MichiganClassic 2017 OW.html5', 'Agamben K - Northwestern 2015.html5', 'Agamben Kritik - Michigan7 2018 MMMR.html5', 'Agamben Supplement - MichiganClassic 2015.html5', 'Agenda DA - JDI 2020.html5', 'Agenda Links Iran Sanctions DA - Michigan7 2016.html5', 'Agenda Politics - Northwestern 2014.html5', 'Agenda Politics - Wake 2017.html5', 'Agent CPs - Northwestern 2015 6WS.html5', 'Algae Counterplan - UNT 2013.html5', 'Algal Biofuels Affirmative - HSS 2014.html5', 'Algal Biofuels Negative - HSS 2014.html5', 'Alien Futurity Negative - UTNIF 2018.html5', 'All American Aff - Wake 2019.html5', 'Alliance DA Supplement - Berkeley 2019.html5', 'Alliance Impact Core - Michigan7 2019 HKMM.html5', 'Allied Prolif DA - MichiganClassic 2016.html5', 'Allies DA - Michigan7 2019 BFHR.html5', 'Amendment CP - Northwestern 2015.html5', 'Amendment CP Updates - Berkeley 2017.html5', 'American Exceptionalism Critique - SDI 2014.html5', 'Anarch-AntiMilitarism Aff - Michigan7 2019 HKMM.html5', 'Anthro Answers - Michigan7 2014.html5', 'Anthro K - Michigan7 2014 BEFJR.html5', 'Anthro K - Northwestern 2014.html5', 'Anthro K Aff Answers - Michigan7 2014 BEFJR.html5', 'Anthropocentrism Aff and Neg - Lauryn - Wake 2016 RKS K Lab.html5', 'Anthropocentrism Critique - Baylor 2014.html5', 'Anthropocentrism Critique - Berkeley 2014.html5', 'Anthropocentrism Critique - Georgetown 2014.html5', 'Anthropocentrism Critique - HSS 2014.html5', 'Anthropocentrism Critique - Samford 2014.html5', 'Anthropocentrism Critique Answers - HSS 2014.html5', 'Anthropocentrism K - Michigan7 2021 HKMLR.html5', 'Anti-Blackness Critique - UTNIF 2015.html5', 'Anti-Blackness K - Wave 1 - Michigan7 2017 AFMMKK.html5', 'Anti-Blackness Supplement - Michigan7 2017 BFHHR.html5', 'Anti-Settler Education K - UTNIF 2017.html5', 'Antiblackness - Michigan7 2018 K Lab.html5', 'Antiblackness Answers Compiled - Wake 2018.html5', 'Antiblackness K - Berkeley 2017.html5', 'Antiblackness K - MichiganClassic 2019 K Lab.html5', 'Antiblackness Kritik - SDI 2019.html5', 'Antiblackness Updates - Berkeley 2017.html5', 'Antiblackness and Pan Answers - Northwestern 2015.html5', 'Antilab Grab Bag - Georgetown 2014.html5', 'Apoc Warming K - Michigan7 2014 BEFJR.html5', 'Apocalyptic Discourse K - Northwestern 2014.html5', 'Appeasement DA  - Michigan7 2019 FFPSV.html5', 'Appeasement DA - Berkeley 2016.html5', 'Appeasement DA - DDI 2016.html5', 'Appeasement DA - Michigan7 2016.html5', 'Appeasement DA - NDCA 2016.html5', 'Appeasement DA 2 - Michigan7 2013.html5', 'Appeasement DA Answers - NDCA 2016.html5', 'Appeasement DA Updates - Michigan7 2016.html5', 'Appeasement Disadvantage - UTNIF 2013.html5', 'Appeasement Disadvantages - Northwestern 2013 4WeekSeniors.html5', 'Aquaculture Affirmative - Georgetown 2014.html5', 'Aquaculture Affirmative - JDI 2014.html5', 'Aquaculture Affirmative - Samford 2014.html5', 'Aquaculture Negative - Samford 2014.html5', 'Aquarius Reef Base Aff and Neg - Michigan7 2014 GRAMS.html5', 'Aquatic Invasive Species Affirmative - Michigan7 2014 GRAMS.html5', 'Arctic Aff Wave 1 - Michigan7 2016.html5', 'Arctic Aff Wave 2 - Michigan7 2016.html5', 'Arctic Aff-Neg - JDI 2016.html5', 'Arctic Coop Neg - Michigan7 2016.html5', 'Arctic Coop Neg 2 - Michigan7 2016.html5', 'Arctic Coop Neg 3 - Michigan7 2016.html5', 'Arctic Mapping Affirmative - Michigan7 2014 GRAMS.html5', 'Arctic Mapping Negative - Michigan7 2014 GRAMS.html5', 'Arctic OCS Affirmative - JDI 2014.html5', 'Arctic OCS Negative - JDI 2014.html5', 'Area Studies K - Michigan7 2013.html5', 'Armed Drones AFF - Wake 2015.html5', 'Arms Control K  - Michigan7 2019 Starter Pack.html5', 'Arms Sales K - Scholars - Gonzaga 2019.html5', 'Arms Sales Updates - Michigan7 2019 FFPSV.html5', 'Art Education K - Supplement - Michigan7 2017 AFMMKK.html5', 'Artic Aff - DDI 2014 SWS.html5', 'Artic Coop neg - DDI 2014 MS.html5', 'Artic Ports Neg - DDI 2014 TW.html5', 'Asia as method k - DDI 2016 CT.html5', 'Asian Masterfile - Wake 2018.html5', 'Assemblage Negative - DDI 2015 ST.html5', 'Assessments Neg - DDI 2017 ST.html5', 'Assurances DA Answers - MSDI 2016.html5', 'Asylum Aff - DDI 2018 KM.html5', 'Asylum Aff - Gonzaga 2018 Scholars.html5', 'Asylum Aff 2 - UNT 2018.html5', 'Asylum Case Neg - DDI 2018 AT.html5', 'Asylum Neg - Gonzaga 2018 Scholars.html5', 'Auctions CP - Northwestern 2018.html5', 'Autonomous Education K - UTNIF 2017.html5', 'BIE Neg Wave 1 - DDI 2017 ST.html5', 'BIT Aff - DDI 2016 HS.html5', 'BIT Aff - Michigan7 2016.html5', 'BIT Aff-Neg - Northwestern 2016.html5', 'BIT Affirmative - Additional 2AC Blocks - SDI 2016.html5', 'BIT Affirmative - MSDI 2016.html5', 'BIT Neg - Michigan7 2016.html5', 'BIT Negative - Berkeley 2016.html5', 'BLACKLANTIS Aff Neg - Michigan7 2021 K Lab.html5', 'BMD Affirmative - Berkeley 2016.html5', 'BMD Negative - Berkeley 2016.html5', 'Backdoor Negative - DDI 2015 CT.html5', 'Backdoors Affirmative - DDI 2015 SWS.html5', 'Backdoors Negative - DDI 2015 MM.html5', 'Backlash DA and Answers - Gonzaga 2018 DMB.html5', 'Ban Prisons Affirmative and Negative - Northwestern 2015.html5', 'Bank of the South CP - Michigan7 2013 CFJPV.html5', 'Barracudas Supplement - Berkeley 2014.html5', 'Base DA - DDI 2018 AT.html5', 'Base DA - Michigan7 2017 BFHR.html5', 'Base DA - Northwestern 2018.html5', 'Base DA - Packet - SDI 2018.html5', 'Base DA Updates - Berkeley 2018.html5', 'Base DA Updates - Michigan7 2018 HJPV.html5', 'Base DA Updates - Northwestern 2018.html5', 'Bataille Aff   Neg - Michigan7 2017 AFMMKK.html5', 'Bataille Aff Neg - Michigan7 2016.html5', 'Bataille Aff Updates - Michigan7 2014.html5', 'Bataille Aff master file - Wake 2019.html5', 'Bataille K - Michigan7 2016.html5', 'Bataille K - Michigan7 2019 K Lab.html5', 'Bataille K Answers - Michigan7 2016.html5', 'Bataille K Supplement - Michigan7 2016.html5', 'Bataille Ks - Wake 2018.html5', 'Bataille Supplement - Michigan7 2017 BFHHR.html5', 'Bataillie Neg - Michigan7 2016.html5', 'Baudrillard   STEM Aff - Wake 2017.html5', 'Baudrillard - Wake 2019.html5', 'Baudrillard Aff   Neg - Michigan7 2019 K Lab.html5', 'Baudrillard Aff - Michigan7 2016.html5', 'Baudrillard Aff and Neg - Michigan7 2018 K Lab.html5', 'Baudrillard K - Michigan7 2016.html5', 'Baudrillard K - Wake 2017.html5', 'Baudrillard Link File - Michigan7 2017 AFMMKK.html5', 'Baudrillard Neg - Michigan7 2016.html5', 'Baudrillard Supplement - Michigan7 2017 BFHHR.html5', 'Biden Mechanism Affirmative - SDI 2019.html5', 'Biden Mechanism Negative - SDI 2019.html5', 'Biodiversity Bad 3.0 - Michigan7 2014 BEFJR.html5', 'Biometric Surveillance Aff - Neg - MichiganClassic 2020 LOSVW.html5', 'Biometrics Aff Addendum - Northwestern 2015 6WS.html5', 'Biometrics Aff and Neg - Northwestern 2015 Sophomores .html5', 'Biometrics Negative Supplement - Northwestern 2015.html5', 'Biopiracy K - DDI 2014 KQ.html5', 'Biopolitical Borders Kritik - Berkeley 2018.html5', 'Biopolitics K - Gonzaga 2018 DMB.html5', 'Biopolitics K - Gonzaga 2020.html5', 'Biopolitics K - Wake 2018.html5', 'Biopolitics K Supplement - Michigan7 2021 CCPW.html5', 'Biopower K - Berkeley 2017.html5', 'Biopower K - JDI 2015.html5', 'Biopower K - JDI 2020.html5', 'Black Atlantic Affirmative - HSS 2014.html5', 'Black Cybernetics Aff - Michigan7 2019 K Lab.html5', 'Black FW - Wake 2019.html5', 'Black Fem K   Reparations - Wake 2017.html5', 'Black Fem K  AfroFuturism Supplement - Wake 2017.html5', 'Black Feminism - DDI 2015 ST.html5', 'Black Framework - Wake 2017.html5', 'Black Genealogy Case Neg - DDI 2018 AT.html5', 'Black Genealogy Neg - DDI 2018 KM.html5', 'Black Islamophobia Aff and Neg - Wake 2018 RKS.html5', 'Black Marxism K - Berkeley 2020 Wave 3.html5', 'Black Nationalism Affirmative - HSS 2015.html5', 'Black Nationalism Negative - HSS 2015.html5', 'Black Nihilism - Wake 2016.html5', 'Black Palestinian Aff  - Wake 2019 (1).html5', 'Blood Quantum Affirmative and Neg - Wake 2018.html5', 'Body Cameras Negative - MSDI 2020.html5', 'Body Cavity Searches Negative - DDI 2015 CT.html5', 'Border Art Aff and Neg - UTNIF 2018.html5', 'Border Drones Affirmative - Northwestern 2015 6WS.html5', 'Border Drones Negative - Northwestern 2015 6WS.html5', 'Border Surveillance Negative - Michigan7 2015.html5', 'Borders 1ac - DDI 2015 KS.html5', 'Borders Affirmative and Negative - Gonzaga 2013.html5', 'Borders Critique - Emory 2015.html5', 'Borders Impact File - Northwestern 2018.html5', 'Borders K - DDI 2015 ST.html5', 'Borders K - Starter Packet - Michigan7 2018.html5', 'Borders K - Wake 2018.html5', 'Borders Kritik - Georgetown 2018.html5', 'Borders Kritik - UTNIF 2013.html5', 'Borders Neg - DDI 2015 KQ.html5', 'Borders Negative - DDI 2015 ST.html5', 'Brown Feminist Killjoy - Wake 2018.html5', 'Buddhism K 2 - Michigan7 2013.html5', 'Bulk Data Affirmative - JDI 2015.html5', 'Bulk Data Affirmative - MSDI 2015.html5', 'Bulk Data Collection Negative - JDI 2015.html5', 'CAT AFF - MichiganClassic 2019 MPP.html5', 'CAT Neg  - MichiganClassic 2019 MPP.html5', 'CBA Aff - DDI 2021 AT.html5', 'CBA Case Neg - DDI 2021 AT.html5', 'CBA Case Neg - DDI 2021 KM.html5', 'CBFM - DDI 2014 KQ.html5', 'CBM and NFU Aff-Neg - JDI 2016.html5', 'CCP Collapse Core - Michigan7 2016.html5', 'CCP Collapse Good - Northwestern 2016.html5', 'CCP DA - MSDI 2016.html5', 'CCP Democracy Turn - HSS 2016.html5', 'CCS Counterplan - JDI 2014.html5', 'CDC Tradeoff DA - UTNIF 2017.html5', 'CDCL Aff-Neg - JDI 2016.html5', 'CIR DA 1 - Michigan7 2013.html5', 'CMSP Case neg - DDI 2014 TW.html5', 'CMSP and Exploration Disadvantage - MSDI 2014.html5', 'CMSP neg - DDI 2014 MS.html5', 'COINTELPRO Aff and Negative Upgrade - Northwestern 2015 6WS.html5', 'COINTELPRO Affirmative - Northwestern 2015 6WS.html5', 'COINTELPRO Negative - Northwestern 2015 6WS.html5', 'CP - Advantage CPs - MNDI 2022 PHA.html5', 'CP - Advantage CPs - Michigan 7 2022 CPWW.html5', 'CP - Advantage CPs - Michigan Classic 2022 CGNO.html5', 'CP - Burdensharing QPQ - Michigan 7 2022 BEJJ.html5', 'CP - Civil Military CP - Michigan 7 2022 BFHR.html5', 'CP - Congress - Michigan7 2020 Starter Pack.html5', 'CP - Courts - Michigan7 2020 BFHPR.html5', 'CP - Dept of State CP - Packet - Michigan 7 2022.html5', 'CP - EU CP - Michigan 7 2022 BFHR.html5', \"CP - Executive CP's - Michigan7 2020 BFHPR.html5\", 'CP - State Referendum - Michigan7 2020 BFHPR.html5', 'CP - States - Michigan7 2020 BFHPR.html5', 'CP - States Courts - MichiganClassic 2020 LOSVW.html5', 'CP - Supreme Court - Michigan 7 2022 BFHR.html5', 'CP - Turkey PIC - Michigan 7 2022 BFHR.html5', 'CP - UN CP - Michigan 7 2022 BFHR.html5', 'CP - Unilateral CP - CNDI 2022.html5', 'CP - Unilateral CP - MSDI 2022.html5', 'CRT Case Neg - DDI 2017 AS.html5', 'CTE Aff   Neg - Wave 2 - Michigan7 2017 CPPR.html5', 'CTE Aff - Wave 1 - Michigan7 2017 BFHHR.html5', 'CTE Aff Supplement - MichiganClassic 2017 CFJ.html5', 'CTE Neg - Michigan7 2017 BFHHR.html5', 'CTE Tradeoff DA - MSDI 2017.html5']\n",
        "\n",
        "DEBATESUM_EXTREMIST_FILTER_OUT2 = ['Camp Tournament Updates - SDI 2018 DLGM.html5', 'Camp Updates  - MichiganClassic 2017 OW.html5', 'Camp Updates - Final - Michigan7 2017 AFMKK.html5', 'Cap Good Core - Wake 2018.html5', 'Cap Good Updates - MichiganClassic 2021 MMP.html5', 'Cap K  - JDI 2021.html5', 'Cap K - Berkeley 2020 Wave 4.html5', 'Cap K - DDIx 2021.html5', 'Cap K - Links - Wake 2018.html5', 'Cap K - Michigan7 2014.html5', 'Cap K - SDI 2018 BGHT.html5', 'Cap K - Starter Packet - Wake 2018.html5', 'Cap K - UNT 2018.html5', 'Cap K - Wake 2019.html5', 'Cap K Links - Michigan7 2014.html5', 'Cap K Preinstitute Set - Wake 2019.html5', 'Cap K and Answers - Gonzaga 2020 LO.html5', 'Cap K and Fem K Updates - SDI 2017.html5', 'Cap K of Race based Affs - Northwestern 2014.html5', 'Cap K vs Identity Teams - Northwestern 2015.html5', 'Cap K vs K Affirmatives - Michigan7 2018 CPPWW.html5', 'Cap K vs Race Affs - Michigan7 2014.html5', 'Cap Kritik vs K Affirmatives - Michigan7 2018 BFHPR.html5', 'Cap Supplement - UTNIF 2020.html5', 'Cap and Neolib Kritik - Michigan7 2018 CPWW.html5', 'Cap and Semiocap K - MichiganClassic 2019 K Lab.html5', 'Cap and Trade CP - Michigan7 2014 CHHJPV.html5', 'Cap v. K Affirmatives - DDI 2015 SWS.html5', 'Cap vs K Affs - Michigan7 2019 BFHR.html5', 'Capitalism Critique - Berkeley 2014.html5', 'Capitalism Critique - Georgetown 2014.html5', 'Capitalism Critique - MSDI 2014.html5', 'Capitalism Critique - Michigan7 2015.html5', 'Capitalism Critique - SDI 2015.html5', 'Capitalism Critique - SDI 2016.html5', 'Capitalism Critique - UNT 2014.html5', 'Capitalism Critique Supplement - Berkeley 2014.html5', 'Capitalism Critique vs Non-Traditional Affirmatives - HSS 2014.html5', 'Capitalism Critique vs Non-Traditional Affirmatives Answers - HSS 2014.html5', 'Capitalism Critique vs Policy Affirmatives - HSS 2014.html5', 'Capitalism Critique vs Policy Affirmatives 2 - HSS 2014.html5', 'Capitalism Impact Core - Michigan7 2021 EHJJPP.html5', 'Capitalism K - Berkeley 2019.html5', 'Capitalism K - Marc - Wake 2016 RKS.html5', 'Capitalism K - Northwestern 2021 DFW.html5', 'Capitalism K - SDI 2017 BHT.html5', 'Capitalism K - Wake 2017.html5', 'Capitalism K Answers Supplement - Emory 2016.html5', 'Capitalism K vs K Affs - Michigan7 2017 BFHHR.html5', 'Capitalism Kritik - Gonzaga 2013.html5', 'Capitalism Kritik - NDCA 2016.html5', 'Capitalism Kritik - UTNIF 2013.html5', 'Capitalism Kritik Answers - NDCA 2016.html5', 'Capitalism Kritik Supplement - Gonzaga 2013.html5', 'Capitalism Kritik Updates - UNT 2013.html5', 'Capitol Police Neg - DDI 2020 HL.html5', 'Carcerality - Wake 2018 RKS.html5', 'Cede the Political - Michigan7 2018 CPPWW.html5', 'Cede the Political DA - Michigan7 2019 CCPW.html5', 'Cede the Political DA - Michigan7 2021 CCPW.html5', 'Census Affirmative - Michigan7 2015.html5', 'Charter School Desegregation Aff - HSS 2017.html5', 'Charter School Desegregation Neg - HSS 2017.html5', 'Circumvention - Berkeley 2018.html5', 'Circumvention - Georgetown 2020.html5', 'Circumvention - MSDI 2015.html5', 'Circumvention - Northwestern 2017.html5', 'Circumvention - Northwestern 2018.html5', 'Circumvention Answers - Northwestern 2015 6WS.html5', 'Circumvention Core - Berkeley 2019.html5', 'Circumvention Core - SDI 2018 KUZ.html5', 'Circumvention DA - Michigan7 2015.html5', 'Circumvention File - Michigan7 2017 AFMMKK.html5', 'Circumvention and Gradualism - Northwestern 2015 6WS.html5', 'Citizenship K - Links - Wake 2018.html5', 'Citizenship K - Master - Wake 2018.html5', 'Citizenship K - Michigan7 2018 K Lab.html5', 'Citizenship K - Packet - SDI 2018.html5', 'Citizenship Test Case Neg - DDI 2018 AT.html5', 'Civic Education Aff - Michigan7 2017 CPPR.html5', 'Civic Education Neg  - Michigan7 2017 BFHHR.html5', 'Civic Education Neg - Michigan7 2017 CPPR.html5', 'Civil Forfeiture Aff - Neg - Berkeley 2020 Wave 4.html5', 'Climate Aff-Neg Starter Pack - Northwestern 2016.html5', 'Climate Case Neg - DDI 2016 HS.html5', 'Climate Cooperation Negative - Berkeley 2016.html5', 'Climate Financing CP - Sophomores - Gonzaga 2019.html5', 'Climate Literacy Aff - Berkeley 2017.html5', 'Climate Migration 1AC - UTNIF 2018.html5', 'Climate Migration Negative - UTNIF 2018.html5', 'Climate Neg - Michigan7 2016.html5', 'Climate Offsets CP - Michigan7 2019 BFHR.html5', 'Climate Refugees Aff and Neg - Michigan7 2018 HJPV.html5', 'Cloud Seeding Case Neg - DDI 2021 GG.html5', 'Cloud Seeding Case Neg - DDI 2021 KM.html5', 'Cloud Seeding Case Neg - DDI 2021 KS.html5', 'Coal Disadvantage - WSDI 2014.html5', 'Coastal Marine Spatial Planning Affirmative - JDI 2014.html5', 'Colonial Cartography Critique - WSDI 2014.html5', 'Coloniality K - Northwestern 2021.html5', 'Coloniality Kritik - DDI 2013.html5', 'Coloniality Kritik - UNT 2013.html5', 'Coloniality Kritik Supplement - DDI 2013.html5', 'Colorblindness Critique - HSS 2015.html5', 'Colorblindness K  - Michigan7 2017 BFHHR.html5', 'Commissions CP - Michigan7 2018 CPWW.html5', 'Common Core Aff - Wake 2017.html5', 'Common Core Affirmative - HSS 2015.html5', 'Common Core Neg - Wake 2017.html5', 'Common Core Negative - HSS 2015.html5', 'Communicative Engagement CP - Berkeley 2016.html5', 'Communicative Engagement Case Neg - DDI 2016 BAM.html5', 'Communicative Engagement Case Neg - DDI 2016 HS.html5', 'Communicative Engagement Neg - DDI 2016 MS.html5', 'Community based fisheries case neg - DDI 2014 SWS.html5', 'Competitive Grants CP - Michigan7 2017 BFHR.html5', 'Competitiveness Bad - Michigan7 2017 FFRSV.html5', 'Competitiveness Bad DA   Answers - Michigan7 2017 BFHR.html5', 'Computer Science Education Aff - UTNIF 2017.html5', 'Computer Science Education Neg - UTNIF 2017.html5', 'Con Con CP - SDI 2021.html5', 'Con Con and Con Amend CP - Compiled - Berkeley 2020 Wave 4.html5', 'Condition CP Starter Pack - Northwestern 2016.html5', 'Congress & Distinguish CP - DDI 2017.html5', 'Congress Advantage - Georgetown 2019.html5', 'Congressional Elections DA - Michigan7 2016.html5', 'Congressional Oversight Neg - DDI 2019 LO.html5', 'Connolly File - Michigan7 2018 MMMR.html5', 'Conquest K - Gonzaga 2021.html5', 'Conquest K Supplement - Gonzaga 2021.html5', 'Conrad 30 Negative - MichiganClassic 2018 FH.html5', 'Consult Congress CP - Michigan7 2019 FFPSV.html5', 'Consult India CP - JDI 2016.html5', 'Consult Indigenous CP - Michigan7 2021 CCPW.html5', 'Consult States CP - JDI 2014.html5', 'Consult the Indigineous Counterplan - Northwestern 2013 Sophomores.html5', 'Consumption K - MichiganClassic 2014.html5', 'Coordinated Mapping Aff - DDI 2014 MS.html5', 'Core Packet - Varsity - TDI 2021.html5', 'Corporate Inversions Politics DA - Michigan7 2014.html5', 'Cosmopolitanism Critique - Michigan7 2015.html5', 'Cosmopolitanism K - Georgetown 2016.html5', 'Cosmopolitanism K - SDI 2018 BJMSS.html5', 'Cosmopolitanism Kritik - Michigan7 2018 K Lab.html5',  'Court Capital DA - SDI 2020.html5', 'Court Capital DA - Wake 2015.html5', 'Court Clog DA - Georgetown 2020.html5', 'Court Clog DA - Version 2 - Michigan7 2018 CPWW.html5', 'Court DAs   Answers - Wave 1 - Michigan7 2017 BFHHR.html5', 'Court DAs - Berkeley 2018.html5', 'Court DAs - Wave 2 - Michigan7 2017 BFHHR.html5', 'Court Generics - Berkeley 2017.html5', 'Court Legitimacy DA - DDI 2017.html5', 'Court Legitimacy DA - Michigan7 2015.html5', 'Court Packing DA - Michigan Draft - Berkeley 2020 Wave 4.html5', 'Court Politics DA - Michigan7 2021 BFHPR.html5', 'Court Politics DA - Michigan7 2021 EHJJPP.html5', 'Court Stripping Turn - DDI 2017.html5', 'Courts Affirmative - SDI 2015.html5', 'Courts Affirmative - Samford 2015.html5', 'Courts Affirmative Supplement - SDI 2015.html5', 'Courts CP  - JDI 2021.html5', 'Courts CP - Berkeley 2020 Wave 2.html5', 'Courts CP - Gonzaga 2018 Scholars.html5', 'Courts CP - JDI 2017.html5', 'Courts CP - JDI 2020.html5', 'Courts CP - MSDI 2020.html5', 'Courts CP - Michigan7 2017 HJPPV.html5', 'Courts CP%2C XO CP%2C Circumvention - DDI 2015 SWS.html5', 'Courts Core - SDI 2017 NNP.html5', 'Courts Neg Wave 2 - Berkeley 2017.html5', 'Courts Negative - Michigan7 2015.html5', 'Courts Politics DA - Berkeley 2020 Starter Pack.html5', 'Courts Politics DA - JDI 2017.html5', 'Courts Politics DA - Northwestern 2015.html5', 'Courts Turns - UTNIF 2015.html5', 'Courts v. Congress - UNT 2015.html5', 'Cp - Con Con Preview - Michigan7 2020 Starter Pack.html5', 'Credibility Bad DA - SDI 2019.html5', 'Crime DA - MSDI 2015.html5', 'Criminology Answers - UTNIF 2020.html5', 'Critical Cartography Affirmative and Negative - Gonzaga 2014.html5', 'Critical Geography Critique - UTNIF 2015.html5', 'Critical Marijuana Aff and Neg - JDI 2020.html5', 'Critical Neglect Affirmative and Negative - Northwestern 2013 6WeekSeniors.html5', 'Critical Neglect Negative Supplement - Northwestern 2013 6WeekSeniors.html5', 'Critical Policing Aff and Neg - JDI 2020.html5', 'Critical Race Theory Critique - Michigan7 2015.html5', 'Critical Race Theory K  - DDI 2017.html5', 'Critical Terror Studies - DDI 2015 SWS.html5', 'Critique Aff Negative - UNT 2014.html5', 'Critique Affirmative - UNT 2014.html5', 'Critique Answers - Georgetown 2014.html5', 'Critique Answers - Reformism Good - SDI 2015.html5', 'Critique Answers - WSDI 2014.html5', 'Critique Answers Supplement - Michigan7 2015.html5', 'Critique Immigration Affirmative - Michigan7 2015.html5', 'Critique Immigration Negative - Michigan7 2015.html5', 'Crypto 2acs - DDI 2015 ST.html5', 'Crypto Affirmative - DDI 2015 ST.html5', 'Crypto Negative - DDI 2015 ST.html5', 'Cthulhu Mythos Affirmative - Gonzaga 2014.html5', 'Cthulhu Mythos Negative - Gonzaga 2014.html5', 'Cuba Aff - SCDI 2013.html5', 'Cuba Affirmative - Advanced - DDIx 2013.html5', 'Cuba Affirmative Update - Emory 2013.html5', 'Cuba Core - Northwestern 2013 Plus One.html5', 'Cuba Embargo Negative - Emory 2013.html5', 'Cuba Embargo Negative - GMU 2013.html5', 'Cuba Embargo Negative - JDI 2013.html5', 'Cuba Embargo Negative - Sanctions and Russia - SDI 2013.html5', 'Cuba Embargo Negative Supplement 2 - SDI 2013.html5', 'Cuba Embargo Negative Updates - Northwestern 2013 6WeekJuniors.html5', 'Cuba Food Aff - Michigan7 2013 ACHM.html5', 'Cuba Hospitality Affirmative - Northwestern 2013 6WeekJuniors.html5', 'Cuba Hospitality Negative - Northwestern 2013 6WeekJuniors.html5', 'Cuba K Aff and Neg - Wave 2 - Michigan7 2013 ACHM.html5', 'Cuba Neoliberalism Aff and Neg - SDI 2013.html5', 'Cuba Oil Affirmative - JDI 2013.html5', 'Cuba Oil Negative - Georgia 2014.html5', 'Cuba Rum Affirmative - DDI 2013 CM.html5', 'Cuba Science Cooperation Affirmative - Gonzaga 2013.html5', 'Cuba Sugar Ethanol Aff and Neg - UNT 2013.html5', 'Cuba Sugar Ethanol Kritik Aff and Neg - JDI 2013.html5', 'Cuba TRI Kritik Negative - UTNIF 2013.html5', 'Cuba Telecommunications Affirmative - Northwestern 2013 6Weekseniors.html5', 'Cuba Terror Aff - MichiganClassic 2013 CT.html5', 'Cuba Terror List Aff - K Version - MichiganClassic 2013 CT.html5', 'Cuba Terror List Affirmative - Gonzaga 2013.html5', 'Cuba Terror List Affirmative - HSS 2013.html5', 'Cuba Tourism Affirmative - MSDI 2013.html5', 'Cuba Trade Aff Wave 2 - Michigan7 2013 HJPP.html5', 'Cuba Trade Aff Wave 3 - Michigan7 2013 HJPP.html5', 'Cuba Travel Ban Aff - MNDI 2013 CT.html5', 'Cuba Travel Ban Aff - Michigan7 2013 ACHM.html5', 'Cuba Travel Neg - MNDI 2013 CT.html5', 'Cuban Embargo Negative - DDI 2013 AC.html5', 'Cuban ICT Negative - Northwestern 2013 6WeekJuniors.html5', 'Cultural Competency - Neg Supplement - SDI 2017 EER.html5', 'Cultural Competency Aff - SDI 2017 EER.html5', 'Cultural Competency Neg - SDI 2017 EER.html5', 'Curtiss Wright Aff - DDI 2019 KM.html5', 'Curtiss Wright Neg - DDI 2019 KM.html5', 'Cyber Aff - Michigan7 2016.html5', 'Cyber Case Neg - DDI 2016 CT.html5', 'Cyber DA - MSDI 2015.html5', 'Cyber Dams Aff Neg - DDI 2021 GDDI.html5', 'Cyber Neg - Michigan7 2016.html5', 'Cybernetics Aff   Neg Updates - Michigan7 2017 AFMMKK.html5', 'Cybernetics K - Michigan7 2017 AFMMKK.html5', 'Cybernetics K Answers - Michigan7 2017 AFMMKK.html5', 'Cybernetics Kritik - Michigan7 2018 K Lab.html5', 'Cyborgs Affirmative - Michigan7 2015.html5', 'Cyborgs Negative - Michigan7 2015.html5', 'DA - 2020 Elections 2 - Michigan7 2020 BFHPR.html5', 'DA - 2020 Elections Preview - Michigan7 2020 Starter Pack.html5', 'DA - 2020 Elections Preview 3 - Reproductive Rights Impact - Michigan7 2020 Starter Pack.html5', 'DA - 2020 Elections Updates - MichiganClassic 2020 MMP.html5', 'DA - Agenda Link Core - Michigan7 2020 BFHPR.html5', 'DA - Assurance DA - Northwestern 2022.html5', 'DA - BLM - Michigan7 2020 BFHPR.html5', 'DA - China Good - CNDI 2022.html5', 'DA - Court Capital - Michigan7 2020 Starter Pack.html5', 'DA - Court Clog - Michigan7 2020 Starter Pack.html5', 'DA - Court Packing - Michigan7 2020 BFHPR.html5', 'DA - DOD Tradeoff - UTNIF 2022.html5', 'DA - DOD Tradeoff DA - Harvard 2022.html5', 'DA - Democracy Bad - Michigan7 2020 BFHPR.html5', 'DA - Elections Supplement - Michigan7 2020 CCPTW.html5', 'DA - Elections Updates - MichiganClassic 2020 BFMZ.html5', 'DA - Elections Wave 1 - Michigan7 2020 FFPSVV.html5', 'DA - Federalism - Michigan7 2020 BFHPR.html5', 'DA - Food Innovation DA - MSDI 2022.html5', 'DA - Midterms - CNDI 2022.html5', 'DA - Midterms - Michigan 7 2022 FMPS.html5', 'DA - Midterms - Michigan Classic 2022 BVL.html5', 'DA - Midterms GOP Good - Michigan Classic 2022 CS.html5', 'DA - Midterms Updates - Michigan Classic 2022 MMP.html5', 'DA - NATO Cohesion - GDI 2022.html5', 'DA - NDAA - Michigan7 2020 BFHPR.html5', 'DA - Oversight DA - Michigan 7 2022 BFHR.html5', 'DA - Police Unions - Michigan7 2020 HKMM.html5', 'DA - Politics BBB - Michigan 7 2022 BFHR.html5', 'DA - Politics Competitiveness - Michigan 7 2022 BFHR.html5', 'DA - Primacy - UTNIF 2022.html5', 'DA - Russia Relations - Michigan 7 2022 CPWW.html5', 'DA - Senate Elections - Michigan7 2020 BFHPR.html5', 'DA - Stimulus - Michigan7 2020 BFHPR.html5', 'DA - Strategic Concept - Michigan 7 2022 BFHR.html5', 'DA - Strategic Concept v2 - Michigan 7 2022 BFHR.html5', 'DACA Neg - Starter Packet - Wake 2018.html5', 'DC Vouchers Aff - HSS 2017.html5', 'DC Vouchers Neg - HSS 2017.html5', 'DDX Packet - DDIx 2018.html5', 'DOE Tradeoff DA   Answers  - Michigan7 2017 BFHHR.html5', 'DREAM Act - Military PIC - SDI 2018 BGHT.html5', 'DREAM Act Aff - Military Advantage - SDI 2018 BJMSS.html5', 'DREAM Act Aff Compiled - SDI 2018 BJMSS.html5', 'DREAM Act Aff Neg - Berkeley 2018.html5', 'DREAM Act Affirmative - Packet - SDI 2018.html5', 'DREAM Act Neg Compiled - SDI 2018 BJMSS.html5', 'DREAM Act Neg Supplement - SDI 2018 DGLM.html5', 'DREAM Act Negative - Packet - SDI 2018.html5', 'DREAM Aff Updates - Wake 2018.html5', 'Dams Aff Neg - Michigan7 2021.html5', 'Dark Deleuze Answers  - Wake 2018.html5', 'Dark Deleuze K - Wake 2018 RKS.html5', 'De-Dev - Michigan7 2014.html5', 'De-Development - SDI 2019.html5', 'DeDev Core - Michigan7 2017 CMMW.html5', 'DeDev and Growth Good - Michigan7 2016.html5', 'DeDevelopment Updates - Michigan7 2018 CPWW.html5', 'DeSchooling K  - Michigan7 2017 BFHHR.html5', 'DeSchooling K - Wake 2017.html5', 'DeSchooling Kritik - UNT 2017.html5', 'DeVos Credibility DA - MSDI 2017.html5', 'DeVos DA   Answers  - Michigan7 2017.html5', 'Death Bad and Good Core - Wake 2018.html5', 'Death Penalty Aff - DDI 2020 HL.html5', 'Death Penalty Aff - Neg - Berkeley 2020 Wave 2.html5', 'Death Penalty Aff and Neg Updates - JDI 2020.html5', 'Death Penalty Affirmative - SDI 2020.html5', 'Death Penalty Case Neg - DDI 2020 GG.html5', 'Death Penalty Expansion - Aff and Neg - Gonzaga 2020 MM.html5', 'Death Penalty K version - Georgetown 2020.html5', 'Death Penalty Neg - DDI 2020 AT.html5', 'Death Penalty Neg - DDI 2020 FS.html5', 'Death Penalty Neg - DDI 2020 KM.html5', 'Death Penalty Neg Updates - SDI 2020.html5', 'Death Penalty Negative - MSDI 2020.html5', 'Death Penalty Negative - SDI 2020.html5', 'Debt Ceiling DA - Berkeley 2017.html5', 'Debt Ceiling DA - Michigan7 2017 BFHHR.html5', 'Debt Ceiling Politics DA - Berkeley 2019.html5', 'Debt Ceiling Politics DA - DDI 2019 KM.html5', 'Debt Negative - DDI 2015 ST.html5', 'Decarceration Affirmative - SDI 2020.html5', 'Decarceration Negative - SDI 2020.html5', 'Decoloniality Answers - DDI 2013 SS.html5', 'Decoloniality Kritik - UTNIF 2013.html5', 'Decoloniality Neg - DDI 2017 ST.html5', 'Decoloniality Negative - DDI 2013 AC.html5', 'Decolonization Neg - DDI 2017 AS.html5', 'Dedev - DDI 2016 KQ.html5', 'Dedev - DDI 2020 GG.html5', 'Dedev - JDI 2017.html5', 'Dedev Neg - DDI 2020 AT.html5', 'Dedevelopment - DDI 2014 KQ.html5', 'Dedevelopment - JDI 2016.html5', 'Dedevelopment - Northwestern 2014.html5', 'Dedevelopment Good - Emory 2014.html5', 'Dedevelopment Impact File - Northwestern 2018.html5', 'Deep Ecology K - DDI 2021.html5', 'Defending Apocalyptic Representations - Northwestern 2015 6WS.html5',  'Deferred Action Affirmative - MSDI 2015.html5', 'Dehumanism Aff and Neg - Packet - SDI 2018.html5', 'Deleuze - DDI 2015 SWS.html5', 'Deleuze Aff   Neg - Michigan7 2019 K Lab.html5', 'Deleuze Aff Neg - Michigan7 2021 BFHPR.html5', 'Deleuze K - Michigan7 2016.html5', 'Deleuze Kritik - Michigan7 2018 K Lab.html5', 'Deleuze Pedagogy Aff - Michigan7 2017 AFMMKK.html5', 'Delooze - Wake 2019.html5', 'Derrida K - UNT 2018.html5', 'Derrida Kritik - DDI 2013 CM.html5', 'Derrida Terror Negative - DDI 2015 CT.html5', 'Deschooling K  - DDI 2017.html5', 'Deschooling K  - Gonzaga 2017.html5', 'Deschooling K - MSDI 2017.html5', 'Deschooling K - Northwestern 2017.html5', 'Desegregation Aff   Neg - Starter Set - Michigan7 2017.html5', 'Desegregation Aff   Neg - Wave 2 - Michigan7 2017 HJPPV.html5', 'Desegregation Aff   Neg - Wave 3 - Michigan7 2017 HJPPV.html5', 'Desegregation Aff Neg Supplement - MNDI 2017 GJJS.html5', 'Destroy the Oceans - Michigan7 2014 GRAMS.html5', 'Detention Affirmative - Michigan7 2018 BFHPR.html5', 'Detention Affirmative - Starter - UTNIF 2018.html5', 'Detention Negative - Michigan7 2018 BFHPR.html5', 'Detention Negative - Starter - UTNIF 2018.html5', 'Development Assistance Affirmative - DDI 2013 KQ.html5', 'Development Discourse K - SCDI 2013.html5', 'Development Kritik Affirmative Answers - Northwestern 2013 4WeekSeniors.html5', 'Development Kritik Supplement - JDI 2013.html5', 'Development PIC - DDI 2014 KQ.html5', 'Development Word PIC - DDI 2013 CM.html5', 'Development Word PIC Answers - HSS 2014.html5',  'Dip Cap DA - Michigan7 2016.html5', 'Dip Cap DA Wave 2 - MichiganClassic 2016.html5', 'Diplomatic Capital DA - JDI 2016.html5']\n",
        "\n",
        "DEBATESUM_EXTREMIST_FILTER_OUT3 = ['Diplomatic Capital Disadvantage - Gonzaga 2013.html5', 'Disability Aff - Wake 2017.html5', 'Disability Aff Supplement - Berkeley 2017.html5', 'Disability K - Michigan7 2018 FFGSV.html5', 'Disability K - Wake 2017.html5', 'Discourse Critique - Gonzaga 2014.html5', 'Discourse Kritiks - DDI 2013 SS.html5', 'Disruption Aff - Berkeley 2017.html5', 'Disruption Neg - Berkeley 2017.html5', 'Diversionary War Answers - Michigan7 2017.html5', 'Diversity Visas Aff and Neg - Michigan7 2018 FFGSV.html5', 'Do It Elsewhere CP - Northwestern 2014.html5', 'Domestic Detention Affirmative - JDI 2015.html5', 'Domestic Violence Aff - Starter Packet - Michigan7 2018.html5', 'Domestic Violence Aff and Neg Supplement - MNDI 2018 GJJJ.html5', 'Domestic Violence Aff and Neg and Gender K - Michigan7 2018 BFHPR.html5', 'Domestic Violence Affirmative - MichiganClassic 2018.html5', 'Domestic Violence Neg - Starter Packet - Michigan7 2018.html5', 'Domestic Violence Negative - MichiganClassic 2018.html5', 'Domestic Word PIC - Michigan7 2015.html5', 'Dress Code Aff - Berkeley 2017.html5', 'Dress Code Neg - Berkeley 2017.html5', 'Drug Courts Neg - DDI 2020 FS.html5', 'Drug Decriminalization Affirmative - MSDI 2020.html5', 'Drug Treatment Aff -Starter - Georgetown 2020.html5', 'EB Visas Aff and Neg - Wake 2018.html5', 'EB-5 Aff - Version 2 - Michigan7 2018 BFHPR.html5', 'EB-5 Affirmative - Wave 1 - Michigan7 2018 BFHPR.html5', 'EB-5 Negative - Wave 2 - Michigan7 2018 BFHPR.html5', 'EB5 Aff and Neg - Northwestern 2018.html5', 'EB5 Aff and Neg Updates - Northwestern 2018.html5', 'EBSA neg - DDI 2014 CM.html5', 'EBSA neg - DDI 2014 MS.html5', 'ECPA Affirmative - Northwestern 2015 6WS.html5', 'ECPA Negative - Northwestern 2015 6WS.html5', 'EE Case Neg - DDI 2017 AS.html5', 'EEZ Leasing Aff - Northwestern 2014.html5', 'EEZ Leasing Neg - Northwestern 2014.html5', 'EEZ Mapping Aff - Northwestern 2014.html5', 'EPA Tradeoff DA - DDI 2021.html5', 'EPA Tradeoff DA - Michigan7 2021 BFHPR.html5', 'EPA Tradeoff DA File 2 - Michigan7 2021 BFHPR.html5',  'Eco Feminism Critique - HSS 2014.html5', 'Eco Feminism Critique - SDI 2014.html5', 'Eco K - Northwestern 2014.html5', 'Eco Securitization K - Northwestern 2014.html5', 'Eco-Feminism Critique - WSDI 2014.html5', 'Eco-Managerialism Critique - WSDI 2014.html5', 'Eco-Socialism Critique - WSDI 2014.html5', 'EcoFem Case neg - DDI 2014 TW.html5', 'EcoFem V2 Aff - DDI 2014 SWS.html5', 'EcoPhenomenology 2AC - SDI 2014.html5', 'EcoPhenomenology Critique - SDI 2014.html5', 'Ecodoomsaying Critique - Emory 2014.html5', 'Ecofem neg - DDI 2014 MS.html5', 'Ecofeminism - Michigan7 2014.html5', 'Ecofeminism Critique - Berkeley 2014.html5', 'Ecofeminism K - DDI 2021.html5', 'Ecofeminism K - Michigan7 2014.html5', 'Ecofeminism neg - DDI 2014 KQ.html5', 'Ecological Loss Aff Neg - Michigan7 2021 K Lab.html5', 'Ecomarxism Critique - UTNIF 2014.html5', 'Economics Critique Core - JDI 2014.html5', 'Ecophenomenology Critique - HSS 2014.html5', 'Education Key File - HSS 2017.html5', 'Educational Commons Aff - Michigan7 2017 BFHHR.html5', 'Educational Commons Neg - Michigan7 2017 BFHHR.html5', 'Educational Futurism K - Michigan7 2017 AFMMKK.html5', 'Educational Futurism K - Wake 2017.html5', 'Effective Altruism K - Michigan7 2021 BFHPR.html5', 'Election DA Starter Pack - Northwestern 2016.html5', 'Elections DA - Berkeley 2016.html5', 'Elections DA - Berkeley 2020 Starter Pack.html5', 'Elections DA - DDI 2015 SWS.html5', 'Elections DA - Impact Turns - Wake 2016 RKS Seniors.html5', 'Elections DA - Michigan7 2016.html5', 'Elections DA - Northwestern 2014.html5', 'Elections DA - Northwestern 2015 6WS.html5', 'Elections DA - SDI 2020.html5', 'Elections DA - Samford 2020.html5', 'Elections DA - UTNIF 2015.html5', 'Elections DA - Updates 1 - SDI 2016.html5', 'Elections DA - Updates 2 - SDI 2016.html5', 'Elections DA - Updates 3 - SDI 2016.html5', 'Elections DA - Wave 1 - Wake 2016 RKS.html5', 'Elections DA Answers - Emory 2016.html5', 'Elections DA Starter - Michigan7 2016.html5', 'Elections DA Supplement - SDI 2016.html5', 'Elections DA Updates 1 - MichiganClassic 2016.html5', 'Elections DA v K - MichiganClassic 2016.html5', 'Elections Disadvantage - HSS 2016.html5', 'Embargo Word PIC - DDI 2013 CM.html5', 'Embassies Negative - DDI 2015 MM.html5', 'Embodiment Critique - UTNIF 2015.html5', 'Employment Visas Aff Neg - Berkeley 2018.html5', 'Enclosure Kritik - Northwestern 2013 4WeekSeniors.html5', 'Endangered Species Aff -Louis - Wake 2016 RKS.html5', 'Endangered Species Neg - Louis - Wake 2016 RKS.html5', 'Energy Disadvantage - Berkeley 2014.html5', 'Energy Prices DA - Michigan7 2013.html5', 'Env Managerialism  - Gonzaga 2021.html5', 'Environment Core - Baylor 2014.html5', 'Environment Critique - JDI 2014.html5', 'Environment DA - Michigan7 2018 BFHPR.html5', 'Environment DA - Northwestern 2014.html5', 'Environment DA Answers - Michigan7 2018 MMMR.html5', 'Environment Disadvantages - Gonzaga 2014.html5', 'Environment Impact Turns - Michigan7 2021 BFHPR.html5', 'Environment K - MSDI 2021.html5', 'Environment Management K - Michigan7 2021 CCPW.html5', 'Environmental Apocalyptic Framing Critique - HSS 2014.html5', 'Environmental Crimes Aff Masterfile - DDI 2020 GG.html5', 'Environmental Education Aff - JDI 2017.html5', 'Environmental Education Neg - JDI 2017.html5', 'Environmental Justice K - Berkeley 2021.html5', 'Environmental Justice Kritik generic - DDI 2014 Security Kritik generic.html5', 'Environmental K Answers - Michigan7 2014 BEFJR.html5', 'Environmental Management and Security Critique Answers - Gonzaga 2014.html5', 'Environmental Personhood Case Neg - DDI 2021 FJ.html5', 'Environmental Personhood Case Neg - DDI 2021 GG.html5', 'Environmental Personhood Case Neg - DDI 2021 HL.html5', 'Environmental Security K - Michigan7 2014 BEFJR.html5', 'Ephemeral Streams Case Neg - Berkeley 2021.html5', 'Epistemic Anxiety K - Berkeley 2016.html5', 'Equalize Funding Neg - DDI 2017 ST.html5', 'Eurocentrism K - Wake 2017.html5',  'Executive Counterplan - Gonzaga 2013.html5', 'Executive Order Counterplan - GMU 2014.html5', 'Executive Order Counterplan - JDI 2014.html5', 'Executive Power DA - Georgetown 2019.html5', 'Executive Power DA and CP - DDI 2019 Generic.html5', 'Exploration Critique - Wake 2014.html5', 'Exploration K - DDI 2014 KQ.html5', 'Export Controls Affirmative - Berkeley 2016.html5',  'FBI Drug Testing Affirmative - HSS 2015.html5', 'FDA Aff and Neg - Northwestern 2015 6WS.html5', 'Fabulation Case neg - Wake 2019.html5', 'Failed States Kritik - JDI 2013.html5', 'Family Aff - Gonzaga 2018 Sophomores.html5', 'Family Aff and Neg 2.0 - Gonzaga 2018 Sophomores.html5', 'Family Immigration Aff Neg - Northwestern 2018.html5', 'Family Separation Aff and Neg - SDI 2018 BJMSS.html5', 'Famine K - Northwestern 2014.html5', 'Farm Bill DA - MichiganClassic 2018 AKZ.html5', 'Farmworkers Aff and Neg - MichiganClassic 2018 BO.html5', 'Fear of the Ocean Affirmative - Michigan7 2014 GRAMS.html5', 'Federal Evidence Aff-Neg - Berkeley 2020 Starter Pack.html5', 'Federal Prisons Neg - UNT 2017.html5', 'Fem IR K - Michigan7 2014.html5', 'Fem IR K - Michigan7 2019 HKMM.html5', 'Fem IR Kritik - DDI 2013 KQ.html5', 'Fem IR Saudi Aff - DDI 2019 KS .html5', 'Fem K Supplement - MichiganClassic 2018 FH.html5', 'Fem Open Borders Aff and Neg - Michigan7 2018 CPWW.html5', 'Fem Psychoanalysis K - Wake 2016 RKS K Lab.html5', 'Feminism Critique - HSS 2017.html5', 'Feminism Critique - Samford 2015.html5', 'Feminism Critique of Privacy - MichiganClassic 2015.html5', 'Feminism IR Critique - Gonzaga 2014.html5', 'Feminism K - Wake 2017.html5', 'Feminism Kritik - GMU 2013.html5', 'Feminism Kritik - Gonzaga 2013.html5', 'Feminism Ks Answers  - Wake 2018.html5', 'Feminist Killjoy K - Wake 2016 RKS K Lab.html5', 'Feminist Killjoy Supplement - Wake 2016 RKS K Lab.html5', 'Feminist Materialism K - Wake 2016 RKS K Lab.html5', 'Feminist Pedagogy K - Berkeley 2017.html5', 'Feminist Terror K - Northwestern 2015.html5', 'Fiat, Hope and Pragmatism Core - Wake 2018.html5', 'Filipino Aff - Northwestern 2014.html5', 'Final Patch Update File - Michigan7 2017 BFHHR.html5', 'Final Update File - Michigan7 2017 CMMW.html5', 'Final Updates  - Michigan7 2017 BCPPR.html5', 'Final Updates - Michigan7 2018 BFHPR.html5', 'Final Updates - Michigan7 2018 CPPWW.html5', 'Final Updates - Michigan7 2018 K Lab.html5', 'Florida Disadvantage - UTNIF 2014.html5', 'Foreign Embassies Negative Supplement - Michigan7 2015.html5', 'Foreign Students Negative Supplement - Northwestern 2015.html5', 'Forensic Ecology Aff and Neg - Wake 2019.html5', 'Foucault Affirmative - UTNIF 2015.html5', 'Foucault Critique - Michigan7 2015.html5', 'Foucault K - Michigan7 2017 CPPR.html5', 'Foucault K - Northwestern 2015.html5', 'Foucault Negative - UTNIF 2015.html5', 'Fracking Aff - MSDI 2021.html5', 'Fracking Aff Neg - Berkeley 2021.html5', 'Fracking Aff Neg - Northwestern 2021 DFW.html5', 'Fracking Aff Neg - UTNIF 2021.html5', 'Fracking Case Neg - MSDI 2021.html5', 'Fracking Case Neg - Michigan7 2021 BFHPR.html5', 'Fracking Neg Addendum - Northwestern 2021 DFW.html5', 'Fracking Supplement - MichiganClassic 2021 MMP.html5', 'Framework - Berkeley 2016.html5', 'Framework - Berkeley 2017.html5', 'Framework - Berkeley 2018.html5', 'Framework - Cap K vs K Affs 2 - Michigan 7 2022 BFHR.html5', 'Framework - Georgetown 2014.html5', 'Framework - Gonzaga 2017.html5', 'Framework - Gonzaga 2018.html5', 'Framework - Max - Wake 2016 RKS.html5', 'Framework - Michigan7 2014 GRAMS.html5', 'Framework - Michigan7 2015.html5', 'Framework - Michigan7 2019 HKMM.html5', 'Framework - Neg K Affs - Michigan 7 2022 BFHR.html5', 'Framework - Neg vs K Affs Toolbox - Michigan 7 2022 FMPS.html5', 'Framework - SDI 2013 Starter.html5', 'Framework - SDI 2016.html5', 'Framework - SDI 2018 BJMSS.html5', 'Framework - Scholars - Gonzaga 2019.html5', 'Framework - UNT 2014.html5', 'Framework - UNT 2018.html5', 'Framework - Wake 2016 RKS K Lab.html5', 'Framework - Wake 2018.html5', 'Framework Addendum - Northwestern 2015 6WS.html5', 'Framework Addendum - Wake 2016 RKS K Lab.html5', 'Framework Answers - Berkeley 2017.html5', 'Framework Booster - Michigan7 2016.html5', 'Framework Core - Michigan7 2016.html5', 'Framework Core - Wave 1 - Michigan7 2017.html5', 'Framework Opening Packet - SDI 2015.html5', 'Framework Supplement - Michigan7 2016.html5', 'Framework Supplement 3 - Michigan7 2016.html5', 'Framework Updates - Michigan7 2014 HHJPV.html5', 'Framing - Michigan7 2021 BFHPR.html5', 'Free Black Girls Aff - Michigan7 2017 AFMMKK.html5', 'Free Market CP  Answers - Michigan7 2017 HJPPV.html5', 'Free Market CP - UTNIF 2017.html5', 'Free Market CP Updates - Michigan7 2017 BFHHR.html5', 'Free Market Core - SDI 2017 EER.html5', 'Free Trade - UNT 2013.html5', 'Freirean Dialogue Aff - SDI 2017 BHT.html5', 'Freirean Dialogue Neg - SDI 2017 BHT.html5', 'Frontier K - Michigan7 2014 GRAMS.html5', 'Fugitivity Affirmative - Michigan7 2015.html5', 'Fugitivity Master File - Michigan7 2017 AFMMKK.html5', 'Fugitivity Negative - Michigan7 2015.html5', 'Funding Equity Neg - MSDI 2017.html5', 'Fusion Centers Aff and Neg Upgrades - JDI 2015.html5', 'Fusion Centers Affirmative - JDI 2015.html5', 'Fusion Centers Affirmative and Negative - MichiganClassic 2015.html5', 'Fusion Centers Negative - MNDI 2015.html5', 'Fusion Centers Updates - JDI 2015.html5', 'Futurity K - UTNIF 2018.html5', 'Gameworks - Michigan7 2015.html5', 'Gender Ableism Aff - Wake 2016 RKS K Lab.html5', 'Gender Asylum Affirmative - Northwestern 2018.html5', 'Gender Critique - UNT 2014.html5', 'Gender Critique - UTNIF 2014.html5', 'Gender Critique - UTNIF 2015.html5', 'Gender IR K - Wake 2016 RKS K Lab.html5', 'Gender IR K - Wave 1 - Wake 2016 RKS K Lab.html5', 'Gender K - Michigan7 2016.html5', 'Gender K - Michigan7 2017 FFRSV.html5', 'Gender K - Michigan7 2021 BFPSW.html5', 'Gender Kritik - Michigan7 2018 MMMR.html5', 'Gender Kritik - SDI 2019.html5', 'Gender Negative - SDI 2019.html5', 'Gender Neutral Bathroom CP - SDI 2017 EER.html5', 'Gender Privacy K - DDI 2015 SWS.html5', 'Gendered Language - Michigan7 2014 CFJMP.html5', 'Generic Aff Answers - Northwestern 2014.html5', 'Generic Critique Answers - Michigan7 2015.html5', 'Geoengineering neg - DDI 2014 MS.html5', 'Geography K 1 - Michigan7 2013.html5', 'Gift Kritik - DDI 2013 SS.html5', 'Global Local and Consumption K - Northwestern 2014.html5', 'Google EMRs DA - HSS 2015.html5', 'Grand Bargain Aff - DDI 2016 HS.html5', 'Grand Bargain Case Neg - DDI 2016 KQ .html5', 'Grants Aff-Neg - Berkeley 2017.html5', 'Greasetrap masterfile - Wake 2019.html5', 'Gree Tech Case Neg - DDI 2016 KQ.html5', 'Green Finance Aff Neg - MichiganClassic 2016.html5', 'Green Psychoanalysis - Wake 2018.html5', 'Green Tech Aff - DDI 2016 KQ.html5', 'Green Tech Case Neg - DDI 2016 CT .html5', 'Growth Bad - JDI 2014.html5', 'Growth Bad Core - SDI 2017 PSW.html5', 'Growth Good - JDI 2017.html5', 'Guantanamo Bay Affirmative - SDI 2013.html5', 'Guantanamo Bay Negative - SDI 2013.html5', 'Guest Worker Aff and Neg - Michigan7 2018 CPPWW.html5', 'Guidance CP - Michigan7 2021 BFHPR.html5', 'Gumbs Aff - Michigan7 2021 K Lab.html5', 'Gumbs Case Neg - Michigan7 2021 BFPSW.html5', 'Gumbs Case Neg - Michigan7 2021 K Lab.html5', 'H1-B Negative - Emory 2018.html5', 'HHHpretournmentupdates - Georgetown 2020.html5', 'HR Condition CP - Michigan7 2016.html5', 'HRIA CP - Northwestern 2018.html5', 'HUMINT Advantage Answers - HSS 2015.html5', 'Handmaids Negative - DDI 2015 ST.html5', 'Handmaids Negative - DDI 2015 SWS.html5', 'Handmaids Tale Affirmative - DDI 2015 CT.html5', 'Hauntology K - Wake 2017.html5', 'Health Care Coop Case Neg - DDI 2016 MS.html5', 'Health Diplomacy Aff - Michigan7 2016.html5', 'Health Diplomacy Neg - Michigan7 2016.html5', 'Health Surveillance Affirmative and Negative - Michigan7 2015.html5', 'Health care cooperation - DDI 2016 MS.html5', 'Healthcare cooperation 2.0 - DDI 2016 MS.html5', 'Heg Bad Impact Core - Michigan7 2019 FFPSV.html5', 'Heg Core - Gonzaga 2017.html5', 'Heg Core - Wake 2018.html5', 'Heg Good Impact Core - Michigan7 2019 FFPSV.html5', 'Heg Impact File - Michigan7 2021 BFPSW.html5', 'Heg bad - DDI 2014 MS.html5', 'Hegemony - UNT 2013.html5', 'Hegemony Answers - Michigan7 2017 BFHHR.html5', 'Hegemony Bad - SDI 2013.html5', 'Hegemony Bad 3.0 - Michigan7 2014 BEFJR.html5', 'Hegemony Bad Core - Michigan7 2018 BFHPR.html5', 'Hegemony Bad and Answers - HSS 2017 PSW.html5', 'Hegemony Core - Berkeley 2017.html5', 'Hegemony Core - Michigan7 2014 CHHJPV.html5', 'Hegemony Core - Michigan7 2014 GRAMS.html5', 'Hegemony Core - Michigan7 2015.html5', 'Hegemony Core - Michigan7 2018 BFHPR.html5', 'Hegemony Core - SDI 2018 PS.html5', 'Hegemony Core - SDI 2019.html5', 'Hegemony Good   Bad - Michigan7 2017.html5', 'Hegemony Good - Michigan7 2017 BFHHR.html5', 'Hegemony Impact File - Northwestern 2015.html5', 'Hei Ren Aff and Neg - NDCA 2016.html5', 'Heidegger Critique - Berkeley 2014.html5', 'Heidegger Critique - JDI 2014.html5', 'Heidegger Critique - UTNIF 2014.html5', 'Heidegger Critique Wave 2 - JDI 2014.html5', 'Heidegger K - Berkeley 2017.html5', 'Heidegger K - Michigan7 2014.html5', 'Heidegger K - Michigan7 2021.html5', 'Heidegger K - Northwestern 2014.html5', 'Heidegger Supplement - Michigan7 2021 K Lab.html5', 'Heidegger case neg - DDI 2014 SWS.html5', 'High Skilled Aff - Georgetown 2018.html5', 'High Skilled Aff Updates - Georgetown 2018.html5', 'High Skilled Aff and Neg - Updates - Michigan7 2018 BFHPR.html5', 'High Skilled Aff and Neg Updates - Michigan7 2018 BFHPR.html5', 'High Skilled Immigrants Case Neg - DDI 2018 AT.html5', 'High Skilled Neg - Georgetown 2018.html5', 'High Skilled Workers Aff - SDI 2018 BJMSS.html5', 'High Skilled Workers Neg - SDI 2018 BJMSS.html5', 'High Tech Agriculture Advantage - HSS 2016.html5', 'High-Skilled Immigration Negative - Northwestern 2018.html5', 'Hip-Hop Pedagogy K - UTNIF 2017.html5', 'Historical Materialism Critique - UTNIF 2015.html5', 'Historical Materialism K - Michigan7 2016.html5', 'Horse Trading DA - Michigan7 2017 BFHHR.html5', 'Horse Trading DA - Michigan7 2018 MMMR.html5', 'Horse Trading DA - SDI 2018 NR.html5', 'Horse Trading DA - UTNIF 2018.html5', 'Human Rights Aff   Neg - Michigan7 2019 Starter Pack.html5', 'Human Rights Aff 2.0 - Michigan7 2019 HJPP.html5', 'Human Rights Condition CPs - Michigan7 2013 ACHM.html5', 'Human Rights Conditions CP - Berkeley 2016.html5', 'Human Rights Credibility Bad DA - Michigan7 2015.html5', 'Human Rights Neg 2-0 - Michigan7 2019 HJPP.html5', 'Human Trafficking Aff and Neg - SDI 2018 BGHT.html5', 'Humanities DA - Berkeley 2017.html5', 'ICBMs Aff - DDI 2021 KM.html5', 'ICBMs Case Neg - DDI 2021 AT.html5', 'ICBMs Case Neg - DDI 2021 GG.html5', 'ICBMs Case Neg - DDI 2021 KM.html5', 'ICE Aff - Berkeley 2017.html5', 'ICE Aff - Neg - Berkeley 2020 Wave 4.html5', 'ICE Aff-Neg Updates - Berkeley 2017.html5', 'ICE Affirmative Supplement - Michigan7 2015.html5', 'ICE Affirmative and Negative - Michigan7 2015.html5', 'ICE Neg - Berkeley 2017.html5', 'ICJ CP - JDI 2015.html5', 'IDEA Aff - Michigan7 2017 FFRSV.html5', 'IDEA Neg - Michigan7 2017 FFRSV.html5', 'IDEA Neg Updates - Michigan7 2017 BFHHR.html5', 'IDEA Quality of Life Aff - HSS 2017.html5', 'IDEA Quality of Life Neg - HSS 2017.html5', 'ILAW K - MichiganClassic 2014 SS.html5', 'ILaw Adv Aff Neg - TDI 2021 student research.html5', 'ILaw Core - SDI 2018 HLR.html5', 'INCSEA Aff - Michigan7 2016.html5', 'INSCEA Neg - Michigan7 2016.html5', 'IOOS Aff Neg - Northwestern 2014 6 week.html5', 'IPR Aff - DDI 2016 MS.html5', 'IPR Case Neg - DDI 2016 BAM.html5', 'IPR Case Neg - DDI 2016 CT.html5', 'IPR Case Neg - DDI 2016 MS.html5', 'IR Core  - Michigan7 2019 HJPP.html5', 'ISS Affirmative - MSDI 2016.html5', 'ISS Negative - MSDI 2016.html5', 'Ice Breakers Neg - Wake 2016 RKS Seniors.html5', 'Icebreakers Affirmative - Michigan7 2014 CHHJPV.html5', 'Icebreakers Updates 3.0 - Michigan7 2014.html5', 'Identity Critique - Michigan7 2015.html5', 'Identity K Aff Answers - Michigan7 2014.html5', 'Identity Negative - Michigan7 2014.html5', 'Ideology K - UTNIF 2017.html5', 'Illegal Immigrant K 1 - Michigan7 2013.html5', 'Illegitimacy Aff - Wake 2018.html5', 'Illinois Senate Elections DA - SDI 2016.html5', 'Immigration Bad - Northwestern 2013 6WeekJuniors.html5', 'Immigration Court Reform CP - MichiganClassic 2018 BO.html5', 'Immigration Critique - Michigan7 2015.html5',  'Immigration Enforcement Neg - MSDI 2020.html5']\n",
        "\n",
        "DEBATESUM_EXTREMIST_FILTER_OUT4 = ['Impact Turns - UTNIF 2017.html5', 'Impact Turns Aff   Neg - Michigan7 2019 BFHMRS.html5', 'Impact Turns Core - Michigan7 2017 CBPPR.html5', 'Impacts - Democracy Bad - Michigan 7 2022 BFHR.html5', 'Impacts - Heg Bad - Michigan 7 2022 CPWW.html5', 'Impacts - Heg Good - Michigan 7 2022 CPWW.html5', 'Impacts - Heg Good Bad Supplement - Michigan 7 2022 BEJJ.html5', 'Impacts - Hegemony - Mean Green 2022.html5', 'Impacts - Impact Updates - Michigan Classic 2022 MMP.html5',  'Impeachment DA - UTNIF 2017.html5', 'Imperceptible Movements Kritik - Michigan7 2018 K Lab.html5', 'Imperial Capital K - UTNIF 2018.html5', 'Imperialism - Terror DA K  - Michigan7 2019 K Lab.html5', 'Imperialism K - Berkeley 2016.html5', 'Imperialism K 2 - Michigan7 2013.html5', 'Imperialism Kritik - Georgetown 2018.html5', 'Imperialism Kritik - JDI 2013.html5',  'Indigenous CP vs Fisheries - DDI 2014 MS.html5', 'Infrastructure Politics - Michigan7 2021 BFHPR.html5', 'Infrastructure Politics - SDI 2021.html5', 'Infrastructure Politics DA - MSDI 2021.html5', 'Infrastructure Politics File 3 - Michigan7 2021 BFHPR.html5',  'Innovation Bad - Inequality - Michigan7 2018 BFHPR.html5', 'Intercommunalism Aff - Wake 2016 Early Bird AS.html5', 'Intercommunalism Neg - Wake 2016 Early Bird AS.html5', 'International Actor CPs - Northwestern 2014.html5', 'International Agent CPs - Berkeley 2018.html5', 'International CPs - Northwestern 2014.html5',  'International Relations Feminism Kritik - Berkeley 2013.html5', 'International Relations Theories - Georgetown 2016.html',  'Intralocality K - Michigan7 2014 BEFRJ.html5', 'Intro Packet - Mandatory Minimums and Case Neg - DDIx 2020.html5', 'Iran Politics DA - WSDI 2015.html5',  'Iron Fertilization neg - DDI 2014 CM.html5', 'Iron Triangle Neg - DDI 2019 KM.html5', 'Iron Triangle Neg - DDI 2019 LO.html5', 'Islamophobia Affirmative - DDI 2015 SWS.html5', 'Islamophobia Affirmative - HSS 2015.html5', 'Islamophobia Affirmative - Michigan7 2015.html5', 'Islamophobia Negative - DDI 2015 MM.html5', 'Islamophobia Negative - DDI 2015 ST.html5', 'Islamophobia Negative - DDI 2015 SWS.html5', 'Islamophobia Negative - HSS 2015.html5', 'Islamophobia Negative - Michigan7 2015.html5', 'Islamophombia Neg - DDI 2015 KQ.html5', 'Israel Aff   Neg - Michigan7 2019 Starter Pack.html5', 'Israel Aff Supplement - MichiganClassic 2019 HJO.html5', 'Israel Affirmative - SDI 2019.html5', 'Israel BDS Aff Preinstitute Set - Wake 2019.html5', 'Israel BDS Neg Preinstitute Set - Wake 2019.html5',  'Israel FMF Aff Neg - Berkeley 2019.html5', 'Israel Militant Anti-Militarism Aff   Neg - Michigan7 2019 K Lab.html5', 'Israel Set Col aff and neg - Scholars - Gonzaga 2019.html5', 'Israel Zionism Aff Neg - Berkeley 2019.html5', 'Judicial Activism DA - Michigan7 2018 CPWW.html5',  'Judicial Grounds CP  - Michigan7 2017 BFHHR.html5', 'K - AI Imperialism - CNDI 2022.html5', 'K - Abolition - Michigan7 2020 HKMM.html5', 'K - Abolition - MichiganClassic 2020 ACV.html5', 'K - Abolition Addendum - Michigan7 2020 K Lab.html5', 'K - Abolition Updates - MichiganClassic 2020 BFMZ.html5', 'K - Afropessimism - Michigan 7 2022 K LAB.html5', 'K - Afropessimism - Michigan7 2020 K Lab.html5', 'K - Afropessimism Wave 1 - Michigan7 2020 K Lab.html5', 'K - Anti Blackness Updates - Michigan Classic 2022 MMP.html5', 'K - Baudrillard - Michigan 7 2022 K LAB.html5', 'K - Baudrillard Supplement - Michigan Classic 2022 BBE.html5', 'K - CRT - Michigan7 2020 CCPTW.html5', 'K - Cap - Michigan7 2020 CCPTW.html5', 'K - Cap K - Michigan 7 2022 CPWW.html5', 'K - Cap K - Starter - Michigan 7 2022.html5', 'K - Cap K - UTNIF 2022.html5', 'K - Cap K Updates - Michigan Classic 2022 MMP.html5', 'K - Cap K v K Affs - Michigan7 2020 BFHPR.html5', 'K - Cap K vs K Affs - Michigan7 2020 CCPTW.html5',  'K - Cybernetics - Michigan 7 2022 FMPS.html5', 'K - Cybernetics Supplement - Michigan Classic 2022 BBE.html5', 'K - Deleuze Supplement - Michigan7 2020 K Lab.html5', 'K - Disability - Michigan 7 2022 K LAB.html5', 'K - Empire - Michigan 7 2022 K LAB.html5', 'K - Fem IR - Starter - Michigan 7 2022.html5', 'K - Fem IR 2 - Michigan 7 2022 K LAB.html5', 'K - Fem IR 3 - Michigan 7 2022 K LAB.html5', 'K - Fem IR 4 - Michigan 7 2022 K LAB.html5', 'K - Fem IR K - CNDI 2022.html5', 'K - Fem IR Supplement - CNDI 2022.html5', 'K - Fem IR Supplement - Michigan Classic 2022 BBE.html5', 'K - Fem IR Supplement - Michigan Classic 2022 BLV.html5', 'K - Final K Supplement - Michigan 7 2022 FMPS.html5', 'K - Foucault - MichiganClassic 2020 LOSVW.html5', 'K - IR Imperialism - UTNIF 2022.html5', 'K - Imperialism - Michigan 7 2022 BFHR.html5', 'K - Militarism - CNDI 2022.html5', 'K - Militarism - Emory 2022.html5', 'K - Militarism - Michigan Classic 2022 CGNO.html5', 'K - Militarism Supplement - CNDI 2022.html5', 'K - Necropolitics - Michigan7 2020 K Lab.html5', 'K - New Wave - Michigan7 2020 K Lab.html5', 'K - Orientalism - Michigan 7 2022 CPWW.html5', 'K - Psychoanalysis - Michigan 7 2022 BFHR.html5', 'K - Queer IR - Michigan 7 2022 CPWW.html5', 'K - Queer IR Supplement - Michigan Classic 2022 BBE.html5', 'K - Racial IR - Michigan 7 2022 FMPS.html5', 'K - Racial IR K - Georgetown 2022.html5', 'K - Racial IR Supplement - Michigan Classic 2022 BBE.html5', 'K - Racialized Security - GDI 2022.html5', 'K - Security - Michigan 7 2022 BEJJ.html5', 'K - Security - Packet - SDI 2022.html5', 'K - Security - Starter - GDI 2022.html5', 'K - Security - UTNIF 2022.html5', 'K - Security K - Georgetown 2022.html5', 'K - Security K - MSDI 2022.html5', 'K - Security K - Mean Green 2022.html5', 'K - Security K - Northwestern 2022.html5', 'K - Security Supplement - GDI 2022.html5', 'K - Security Supplement - Michigan Classic 2022 BBE.html5', 'K - Sett Col - Berkeley 2020 Wave 4.html5', 'K - Sett Col - Michigan7 2020 FFPSVV.html5', 'K - Sett Col Preview - Michigan7 2020 Starter Pack.html5', 'K - Settler Colonialism - Michigan 7 2022 K LAB.html5', 'K - Will to Technology - Michigan 7 2022 BFHR.html5', 'K Aff Answers - Michigan7 2016.html5', 'K Aff Neg - Michigan7 2019 BFHR.html5', 'K Aff Supplement - Michigan7 2019 FFPSV.html5', 'K Affirmatives - Answers - Michigan7 2018 BFHPR.html5', 'K Answers Final - Michigan7 2016.html5', 'K Answers Update - Michigan7 2021 BFHPR.html5', 'K Lab Neg Supplement - Michigan7 2016.html5', 'K Lab Updates 7-26 - Michigan7 2021 K Lab.html5', 'K Link Supplement vs Space Col - Michigan7 2021 BFPSW.html5', 'K Links Supplement - Michigan7 2016.html5', 'K Updates Supplement - Michigan7 2021 HKMLR.html5', 'K of Debate Aff - Michigan7 2016.html5', 'K of Debate Case Neg - Michigan7 2016.html5', 'K- Mouths Shut - UNT 2015.html5', 'KJN Wave 3 - JDI 2020.html5', 'Kant Aff Neg - TDI 2021.html5', 'Kavanaugh Confirmation Politics DA - Northwestern 2018.html5', 'Kinship Aff and Neg - Michigan7 2018 K Lab.html5', 'Kritik Answer Supplement - Michigan7 2017 BFHHR.html5', 'Kritik Answers - Aff and Neg - Wave 3 - Michigan7 2018 BFHPR.html5', 'Kritik Answers - Berkeley 2018.html5', 'Kritik Answers - DDI 2015 SWS.html5', 'Kritik Answers - MSDI 2016.html5', 'Kritik Answers - Michigan7 2018.html5', 'Kritik Answers - Wave 1 - Michigan7 2018 BFHPR.html5', 'Kritik Answers - Wave 2 - Michigan7 2018 BFHPR.html5', 'Kritik Answers Supplement - Michigan7 2017 FFRSV.html5', 'Kritik Updates - Wave 2  - Michigan7 2017 AFMMKK.html5', 'Kritikal Cuba Affirmative - DDI 2013 KQ.html5', 'Kritikal water  - JDI 2021.html5', 'Kunlun Physiognomy Aff - Michigan7 2016.html5', 'LGBT Policy Affirmative - Michigan7 2015.html5', 'LGBT Policy Negative - Michigan7 2015.html5', 'LNG Exports Negative - MNDI 2014 LT.html5', 'LOST Affirmative - Michigan7 2014 CFJKMP.html5', 'LOST Affirmative Supplement - Gonzaga 2014.html5', 'Lab Achievement Gap K - DDI 2017 ST.html5', 'Lab Victimology K - Wake 2017.html5', 'Labor Markets DA - Wake 2018.html5', 'Labor Politics DA - Berkeley 2018.html5', 'Lat Crit Kritik - Gonzaga 2013.html5', 'Latin America Democracy Toolbox - Northwestern 2013 6WeekJuniors.html5', 'Latin America Growth Core - Northwestern 2013 6WeekSeniors.html5', 'Latin America Instability Core - DDI 2013.html5', 'Latin American Neoliberalism Kritik - Emory 2013.html5', 'Lead Aff - MSDI 2021.html5', 'Lead Case Neg - MSDI 2021.html5', 'Leftist Disadvantages - UTNIF 2014.html5', 'Legal Status CP - DDI 2018.html5', 'Legalism Critique - Georgia 2015.html5', 'Legalism Critique - HSS 2015.html5', 'Legalism Critique - SDI 2015.html5', 'Legalism Critique - UTNIF 2015.html5', 'Legalism K - MSDI 2020.html5', 'Legalism K - Northwestern 2015 6WS.html5', 'Legalism K - SDI 2018 PSW.html5', 'Legalism K Core - SDI 2018 BJMSS.html5', 'Legalism and Foucault Updates - Michigan7 2015.html5', 'Legalization Aff and Neg Updates - SDI 2020.html5', 'Legalization Affirmative - SDI 2020.html5', 'Legalization Negative - SDI 2020.html5', 'Legislative Veto Neg - DDI 2019 LO.html5', 'Leprosy Aff and Neg - Wake 2018.html5', 'Leprosy K - Full File - Wake 2018.html5', 'Leverage CP - Asia - DDI 2019 Generic.html5', 'Liberal Internationalism Kritik - GMU 2013.html5', 'Liberal Internationalism Kritik Supplement - GMU 2013.html5', 'Liberal Militarism K - DDI 2019 Generic.html5', 'Liberal Order Bad   Good - Michigan7 2019 CCPW.html5', 'Liberal Pacification Kritik - HSS 2019.html5', 'Liberalism Good - Michigan7 2019 CCPW.html5', 'Ligotti masterfile - Wake 2019.html5', 'Lingchi Aff - Michigan7 2016.html5', 'Lingchi Case Neg - Michigan7 2016.html5', 'Linguistic Imperialism K - Michigan7 2016.html5', 'Linguistic Indeterminacy DA v K - Michigan7 2016.html5', 'Linguistic Terrorism Aff - Wake 2018.html5', 'Loan Shift DA - UTNIF 2017.html5', 'Logistics Aff Neg - Michigan7 2021 K Lab.html5', 'Low Skill Aff Neg - Berkeley 2018.html5', 'Luke K Updates - Michigan7 2014 GRAMS.html5', 'Lunches Aff - Emory 2017.html5', 'MLAT Neg - DDI 2020 AT.html5', 'MLATs Case Neg - DDI 2020 GG.html5', 'MPAs Aff Neg - Michigan7 2021 BFHPR.html5', 'MPAs Neg - Samford 2021.html5', 'MSP case negs - DDI 2014 SWS.html5', 'MSP neg - DDI 2014 CM.html5', 'MSP neg - DDI 2014 KQ.html5', 'MTCR Neg - DDI 2019 LO.html5', 'Makah Neg Updates - Michigan7 2014.html5', 'Makah Whaling Aff - Northwestern 2014.html5', 'Makah Whaling Aff and Neg - Gonzaga 2014.html5', 'Makah Whaling Aff and Neg - Michigan7 2014 CFJMP.html5', 'Makah Whaling Aff and Neg - Michigan7 2014 GRAMS.html5', 'Makah Whaling Affirmative - HSS 2014.html5', 'Makah Whaling Neg - Northwestern 2014.html5', 'Makah Whaling Negative - HSS 2014.html5', 'Man3 Aff   Neg - Michigan7 2017 AFMMKK.html5', 'Managerialism Kritik - JDI 2013.html5', 'Mandatory Minimums Aff - Gonzaga 2020 MM.html5', 'Mandatory Minimums Negative - MSDI 2020.html5', 'Mann Act 1ac - DDI 2015 KS.html5', 'Mann Act Negative - DDI 2015 MM.html5', 'Manufacturing and Naval Power Bad - Michigan7 2014.html5', 'Maquiladoras Affirmative - DDI 2013 KQ.html5', 'Marihuana Aff - Neg - Berkeley 2020 Starter Pack.html5', 'Marijuana Aff Supplement - Berkeley 2020 Wave 2.html5', 'Marijuana Decrim Aff - DDI 2020 FS.html5', 'Marine Protected Areas Aff Neg - Michigan7 2021.html5', 'Marine Reserves Affirmative - Georgetown 2014.html5', 'Marine Reserves Negative - SDI 2014.html5', 'Market Economy Status Aff - Michigan7 2016.html5', 'Market Economy Status Neg - Michigan7 2016.html5', 'Marxism Kritik - DDI 2014 SWS.html5', 'Medical Cooperation Case Neg - DDI 2016 BAM.html5', 'Medical Microbes Aff - Northwestern 2014.html5', 'Medical Records Affirmative - JDI 2015.html5', 'Medical Records Supplement - JDI 2015.html5', 'Melancholy Aff - Wake 2018.html5', 'Mental Health Neg - MSDI 2017.html5', 'Metadata Affirmative - Georgia 2015.html5', 'Metadata Negative - Georgia 2015.html5', 'Metaphors Bad - Michigan7 2014 GRAMS.html5', 'Mexican Renewables Aff and Neg Updates - Michigan7 2013 ACHM.html5', 'Mexican Renewables Neg - Michigan7 2013 BFJR.html5', 'Mexico ACE Border Ports Affirmative - Northwestern 2013 6WeekJuniors.html5', 'Mexico ACE Border Ports Negative - Wave 1 - Northwestern 2013 6WeekJuniors.html5', 'Mexico Aff - DDI 2021 GG.html5', 'Mexico Aff - DDI 2021 KS.html5', 'Mexico Aff and Neg Wave 1 - Sophomores - Gonzaga 2019.html5', 'Mexico Aff and Neg supplement - Sophomores - Gonzaga 2019.html5', 'Mexico Case Neg - DDI 2021 AT.html5', 'Mexico Case Neg - DDI 2021 FJ.html5', 'Mexico Case Neg - DDI 2021 HL.html5', 'Mexico Case Neg - DDI 2021 KM.html5', 'Mexico Case Neg - DDI 2021 KS.html5', 'Mexico Energy Affirmative - Northwestern 2013 6WeekSeniors.html5', 'Mexico Energy Affirmative - Wave 1 - Northwestern 2013 Sophomores.html5', 'Mexico Energy Negative - Northwestern 2013 6WeekJuniors.html5', 'Mexico Energy Negative Supplement - Northwestern 2013 6WeekSeniors.html5', 'Mexico Grand Bargain Affirmative - MSDI 2013.html5', 'Mexico Guest Workers Advantages - HSS 2013.html5', 'Mexico Guest Workers Affirmative - HSS 2013.html5', 'Mexico Guest Workers Negative - HSS 2013.html5', 'Mexico HRC Affirmative - HSS 2013.html5', 'Mexico HRC Negative - HSS 2013.html5', 'Mexico Honduras  - Wake 2019.html5', 'Mexico Human Rights Conditions CP - HSS 2013.html5', 'Mexico Judicial Reform Affirmative - MSDI 2013.html5', 'Mexico Judicial Reform Negative - MSDI 2013.html5', 'Mexico Labor-LGBTQ QPQ CPs - Michigan7 2013 BFJR.html5', 'Mexico Maquiladoras Affirmative - Northwestern 2013 4WeekJuniors.html5', 'Mexico Maquiladoras Affirmative and Negative Supplement - Northwestern 2013 4WeekJuniors.html5', 'Mexico Neg - DDI 2019 KM.html5', 'Mexico Neg - DDI 2019 LO.html5', 'Mexico Neg Supplement - Michigan7 2013 HJPP.html5', 'Mexico Negative - MSDI 2013.html5', 'Mexico Negative - Wake 2013.html5', 'Mexico Open Borders Affirmative - HSS 2013.html5', 'Mexico POEs Affirmative - UNT 2013.html5', 'Mexico TRCs Affirmative - JDI 2013.html5', 'Mexico TTIP Affirmative - HSS 2013.html5', 'Mexico Transport Negative - Gonzaga 2013.html5', 'Mexico Visa Affirmative - Northwestern 2013 6WeekSeniors.html5', 'Mexico Women in Juarez Affirmative - JDI 2013.html5', 'Mexico Women in Juarez Negative - JDI 2013.html5', 'Microfinance Affirmative - DDI 2013 KQ.html5', 'Microfinance Negative - DDI 2013 KQ.html5', 'Microfinancing Negative - DDI 2013 SS.html5', 'Middle Passage Aff - Michigan7 2014 BEFJR.html5', 'Middle Passage Aff and Neg - SDI 2018 NR.html5', 'Middle Passage Affirmative - HSS 2014.html5', 'Middle Passage Affirmative and Negative - Berkeley 2014.html5', 'Middle Passage Critique - UNT 2014.html5', 'Middle Passage Neg - Michigan7 2014 BEFJR.html5', 'Middle Passage Negative - HSS 2014.html5', 'Middle Passage Negative Supplement - SDI 2014.html5', 'Middle Passage Updates - Michigan7 2014 BEFJR.html5', 'Middle Passage case negs - DDI 2014 SWS.html5', 'Middle passage neg - DDI 2014 KQ.html5', 'Midterm Elections DA - MNDI 2014 AM.html5', 'Midterms - Updates - MNDI 2018 GJJJ.html5', 'Midterms - Wave 2 - Michigan7 2018 BFHPR.html5', 'Midterms DA - DDI 2018.html5', 'Midterms DA - Northwestern 2017.html5', 'Midterms DA - Northwestern 2018.html5', 'Midterms DA - Packet - SDI 2018.html5', 'Midterms DA - Starter - UTNIF 2018.html5', 'Midterms DA - Starter - Wake 2018.html5', 'Midterms DA - Starter Packet - Michigan7 2018.html5', 'Midterms DA Answers - Packet - SDI 2018.html5', 'Midterms DA Updates - Berkeley 2018.html5', 'Midterms DA Wave 1 - Berkeley 2017.html5', 'Midterms Dems Good DA - JDI 2017.html5', 'Midterms Disadvantage - UTNIF 2014.html5', 'Midterms Disadvantage - WSDI 2014.html5', 'Midterms Disadvantage Update - UTNIF 2014.html5', 'Midterms Updates - Berkeley 2017.html5', 'Midterms Updates - SDI 2018 GMRS.html5', 'Militarism Aff - DDI 2019 LO.html5', 'Militarism Aff-Neg - Michigan7 2019 K Lab.html5', 'Militarism Affirmative - Gonzaga 2014.html5', 'Militarism K - Berkeley 2019.html5', 'Militarism K Supplement - Berkeley 2019.html5', 'Militarism K Supplement - MichiganClassic 2019 HJO.html5', 'Militarism K and PIC - Gonzaga 2018 Scholars.html5', 'Militarism Neg - DDI 2019 LO.html5', 'Military CP - Michigan7 2014 CHHJPV.html5', 'Military Counterplan - JDI 2014.html5', 'Military ESA Aff - MichiganClassic 2017 MZ.html5', \"Military ESA's Aff  - JDI 2017.html5\", 'Military ESAs Neg  - MichiganClassic 2017 MZ.html5', 'Military Engagement CP - Michigan7 2016.html5', 'Military Impact Aid Aff - Wake 2017.html5', 'Military Recruitment Aff - Berkeley 2017.html5', 'Military Recruitment Aff-Neg - Berkeley 2017.html5', 'Military Recruitment Neg - Berkeley 2017.html5', 'Military in Schools Aff - Gonzaga 2017.html5', 'Milliken 1ac - DDI 2017 AS.html5', 'Milliken Aff  - Berkeley 2017.html5', 'Milliken Aff - SDI 2017.html5', 'Milliken Aff - Wake 2017.html5', 'Milliken Aff Updates - Berkeley 2017.html5', 'Milliken Case Neg - Wake 2017.html5', 'Milliken Neg - Berkeley 2017.html5', 'Milliken Neg - DDI 2017 ST.html5', 'Milliken Neg - SDI 2017.html5', 'Milliken v Bradley 2ac - DDI 2017 AS.html5', 'Misc Case Updates - MichiganClassic 2016.html5', 'Misc K Answers - Michigan7 2016.html5', 'Misc Supplement - Berkeley 2020 Wave 4.html5', 'Miscelleanous - NeoLib%2C Shunning%2C Cuba Embargo - Berkeley 2013.html5', 'Model Minority Aff - Berkeley 2017.html5', 'Model Minority Aff - Wake 2018.html5', 'Model Minority Aff Updates - Berkeley 2017.html5', 'Model Minority K - Berkeley 2017.html5', 'Model Minority K - Wake 2018.html5', 'Model Minority Neg - Berkeley 2017.html5', 'Modern Water Aff Neg - Michigan7 2021 K Lab.html5', 'Morality Starter - SDI 2014.html5', 'Morton K - Michigan7 2021 K Lab.html5', 'Mosques Negative - DDI 2015 ST.html5', 'Moten Case Negative - DDI 2015 SWS.html5', 'Moten Masterfile - Wake 2018.html5', 'Moten Neg - DDI 2020 AT.html5', 'Moten Neg - DDI 2020 FS.html5', 'Mourning Aff - Wake 2018.html5', 'Movements DA - Berkeley 2020 Wave 2.html5', 'Multitude Security Kritik - UTNIF 2013.html5', 'Multivalent Oppression K - Northwestern 2015.html5', 'Myth of the Model Minority Aff - Wake 2017.html5', 'NACTI Aff - MNDI 2013 DM.html5', 'NAIF Neg - Michigan7 2013 HJPP.html5', 'NEPA CP - DDI 2021.html5', 'NEPA CP - Michigan7 2014 HJPV.html5', 'NEPA Environmental Assessment Counterplan - Northwestern 2013 6WeekJuniors.html5', 'NGA CP - Michigan7 2021 CCPW.html5', 'NGA CP - SDI 2021.html5', 'NIH Tradeoff DA - UTNIF 2017.html5', 'NSA AFF - Wake 2015.html5', 'NSA Aff - UNT 2015.html5', 'NSA Affirmative and Negative Supplement - Michigan7 2015.html5', 'NSA Courts Aff and Neg - JDI 2015.html5', 'NSA NEG - Wake 2015.html5', 'NSA Neg - UNT 2015.html5', 'NSD Starter Pack 2021 - Right to strike - NSD 2021.html5', 'NSLA Neg - DDI 2017 ST.html5', 'NWS CP - Michigan7 2021 BFHPR.html5', 'National Standards Aff - Neg - Northwestern 2017.html5', 'Nationalism Kritik - Northwestern 2018.html5', 'Native American Education Neg - SDI 2017 BHL.html5', 'Native American Immigration Affirmative - SDI 2018 HLR.html5', 'Native American Immigration Negative - SDI 2018 HLR.html5', 'Native Americans Aff - MSDI 2017.html5', 'Native Immersion Aff - Berkeley 2017.html5', 'Native Immersion Neg - Berkeley 2017.html5', 'Native Languages Aff - UNT 2017.html5', 'Native Mining Aff - DDI 2021 KM.html5', 'Native Mining Case Neg - DDI 2021 KS.html5', 'Native Water Rights Aff - MGC 2021.html5', 'Native Water Rights Neg - MGC 2021.html5', 'Natives Aff - Michigan7 2021 EHJJPP.html5', 'Natives Aff - Neg - Northwestern 2017.html5', 'Natives Aff Updates Wave 1 - DDI 2017 ST.html5', 'Natives Case Neg - Michigan7 2021 EHJJPP.html5', 'Natives Education 1ac v1 - DDI 2017 ST.html5', 'Natives Education 1ac v2 - DDI 2017 ST.html5', 'Natives Education Aff   Neg - Michigan7 2017 FFRSV.html5', 'Natives Education Aff - Version 2 - Michigan7 2017 FFRSV.html5', 'Natives Education Neg Update - Michigan7 2017.html5', 'Natives Education Supplement - Michigan7 2017 CPBR.html5', 'Natives Neg - DDI 2017 AS.html5', 'Natural Disasters Aff - Michigan7 2016.html5', 'Natural Disasters Neg - Michigan7 2016.html5', 'Natural Gas Add-ons and Answers - Northwestern 2014.html5', 'Natural Gas Aff and Neg - Michigan7 2014.html5', 'Natural Gas Neg - Michigan7 2014.html5']\n",
        "\n",
        "\n",
        "DEBATESUM_EXTREMIST_FILTER_OUT5 = ['NecroPolitics Aff  - Wake 2017.html5', 'Necropolitics K - Wake 2017.html5', 'Necropolitics Neg - Georgetown 2020.html5', 'Neg - AI Clarity - Michigan Classic 2022 CGNO.html5', 'Neg - AI LAWs - NAUDL 2022.html5', 'Neg - AI TEVV - MNDI 2022 PHA.html5', 'Neg - Abolish ICE - MichiganClassic 2020 ACV.html5', 'Neg - Ban OCOs - MSDI 2022.html5', 'Neg - Cognitive Biotechnology - Michigan 7 2022 CPWW.html5', 'Neg - Collateral Consequences - Michigan7 2020 BFHPR.html5', 'Neg - Corporate Crime - Michigan7 2020 BFHPR.html5', 'Neg - Cyber 5G - Michigan 7 2022 BEJJ.html5', 'Neg - Cyber Info Sharing - Packet - SDI 2022.html5', 'Neg - Cyber Space Assets - Michigan 7 2022 BEJJ.html5', 'Neg - Cyber Space Assets - Michigan 7 2022 BFHR.html5', 'Neg - Cybersecurity - NAUDL 2022.html5', 'Neg - Cyborg Writing - Michigan 7 2022 BFHR.html5', 'Neg - Death Penalty 2 - Michigan7 2020 EHJPS.html5', 'Neg - Digital Cyclops - Michigan 7 2022 BFHR.html5', 'Neg - Disease - UTNIF 2022.html5', 'Neg - Disinformation - CNDI 2022.html5', 'Neg - Gendered LAWs - Michigan 7 2022 FMPS.html5', 'Neg - Guantanamo - Michigan7 2020 EHJPS.html5', 'Neg - Information Warfare - Michigan 7 2022 BEJJ.html5', 'Neg - Intellectual Property - Michigan 7 2022 FMPS.html5', 'Neg - K Affs Misc - Michigan7 2020 BFHPR.html5', 'Neg - Marijuana Decriminalization - Michigan7 2020 Starter Pack.html5', 'Neg - Marijuana Supplement 2 - Michigan7 2020 BFHPR.html5', 'Neg - Misc Updates 1 - Michigan7 2020 BFHPR.html5', 'Neg - OCOs - Starter - Michigan 7 2022.html5', 'Neg - OCOs 2 - Michigan 7 2022 BFHR.html5', 'Neg - PGMs - Michigan 7 2022 BFHR.html5', 'Neg - Policing - Michigan7 2020 EHJPS.html5', 'Neg - Rememory - Michigan 7 2022 BFHR.html5', 'Neg - Sett Col - Michigan7 2020 K Lab.html5', 'Neg - Solvency Takeouts - Michigan 7 2022 BFHR.html5', 'Neg - Solvency Takeouts - Michigan 7 2022 FMPS.html5', 'Neg - Techno Orientalism - Michigan 7 2022 BFHR.html5', 'Neg - War on Drugs - Michigan7 2020 BFHPR.html5', 'Neg Updates - 4 Week Tourney - SDI 2017 PSW.html5', 'Negative Framework Updates - Michigan7 2014 BEFJR.html5', 'Neocolonialism K - Wake 2016 RKS K Lab.html5', 'Neolib K - Georgetown 2021.html5', 'Neolib K - Michigan7 2016.html5', 'Neolib K -- AT Impact Cards - Michigan7 2013.html5', 'Neolib K -- Ethics Cards - Michigan7 2013.html5', 'Neolib K 2 - Michigan7 2013.html5', 'Neolib K Answers - Michigan7 2016.html5', 'Neolib K Supplement - Michigan7 2018 BFHPR.html5', 'Neolib K vs Race Affs - Michigan7 2013.html5', 'Neolib K-Starter - Georgetown 2020.html5', 'Neoliberalism Addendum State-phobia K - Northwestern 2015.html5', 'Neoliberalism Critique - HSS 2014.html5', 'Neoliberalism Critique - MSDI 2015.html5', 'Neoliberalism Critique - Michigan7 2015.html5', 'Neoliberalism Critique - UTNIF 2015.html5', 'Neoliberalism Critique Answers - HSS 2014.html5', 'Neoliberalism Critique Supplement - MSDI 2015.html5', 'Neoliberalism Generic - DDI 2013.html5', 'Neoliberalism Generic - DDI 2016.html5', 'Neoliberalism Impacts - DDI 2015 MM.html5', 'Neoliberalism K  - Gonzaga 2017.html5', 'Neoliberalism K  - Starter Set - Michigan7 2017.html5', 'Neoliberalism K - Berkeley 2016.html5', 'Neoliberalism K - Berkeley 2021.html5', 'Neoliberalism K - DDI 2018.html5', 'Neoliberalism K - Gonzaga 2015.html5', 'Neoliberalism K - JDI 2016.html5', 'Neoliberalism K - JDI 2020.html5', 'Neoliberalism K - MichiganClassic 2019 EGW.html5', 'Neoliberalism K - Northwestern 2015.html5', 'Neoliberalism K - SDI 2016.html5', 'Neoliberalism K Answers - Berkeley 2017 Cubs.html5', 'Neoliberalism K Answers - Starter Pack - UNT 2017.html5', 'Neoliberalism K Updates - Berkeley 2017.html5', 'Neoliberalism K Updates - Michigan7 2017 CPPR.html5', 'Neoliberalism K Updates - SDI 2016.html5', 'Neoliberalism K vs K Affs - Michigan7 2017.html5', 'Neoliberalism Kritik - Berkeley 2018.html5', 'Neoliberalism Kritik - JDI 2013.html5', 'Neoliberalism Kritik - Samford 2013.html5', 'Neoliberalism Kritik - UTNIF 2013.html5', 'Neoliberalism Kritik - Wake 2013.html5', 'Neoliberalism Kritik Answers - HSS 2013.html5', 'Neoliberalism Kritik Supplement - Northwestern 2013 6WeekJuniors.html5', 'Neoliberalism Kritik Supplement - Northwestern 2013 Sophomores.html5', 'Neoliberalism Kritik Update - Emory 2013.html5', 'Neoliberalism Kritik Wave 2 - Berkeley 2018.html5', 'Neoliberalism Kritik Wave 3 - Berkeley 2018.html5', 'Neoliberalism Link -- Prisons - DDI 2015 MM.html5', 'Neoliberalism Supplement - Michigan7 2015.html5', 'Neoliberalism Supplement - SDI 2013.html5', 'Net Widening DA - MSDI 2020.html5', 'NetWidening turns - Gonzaga 2020 LO.html5', 'New Aff Blocks - SDI Tourney Final - SDI 2017 BLRS.html5', 'New Jim Code - UTNIF 2020.html5', 'Nietzsche K - DDI 2015 SWS.html5', 'Nietzsche K - Michigan7 2019 BFHR.html5', 'Nietzsche Kritik - Berkeley 2018.html5', 'Nietzsche Kritik - Michigan7 2018 K Lab.html5', 'Nietzschean Agonism Aff   Neg - Michigan7 2017 AFKKMM.html5', 'Nietzschean Agonism Neg  - Michigan7 2017 BFHHR.html5', 'Nigeria Aff  - MichiganClassic 2019 BAZ.html5', 'Nigeria Neg - MichiganClassic 2019 BAZ.html5', 'No Borders Affirmative - Starter - UTNIF 2018.html5', 'No Borders Negative - Starter - UTNIF 2018.html5', 'No One Is illegal Aff and Neg - Wake 2018.html5', 'No War K - DDI 2016 KQ.html5', 'Nomads Affirmative - Georgetown 2014.html5', 'Nommo 1ac  neg 2.0 - Wake 2019.html5', 'Nonviolence K - MichiganClassic 2019 FH.html5', 'North Korea Affirmative - HSS 2016.html5', 'North Korea BMD Affirmative - MSDI 2016.html5', 'North Korea Disaster Planning Aff - Northwestern 2016.html5', 'North Korea Disaster Planning Neg - Northwestern 2016.html5', 'Nuclear Dialogue Aff - MichiganClassic 2016.html5', 'Nuclear Dialogue Case Neg - DDI 2016 BAM.html5', 'Nuclear Dialogue Neg - MichiganClassic 2016.html5', 'Nuclear Energy Aff - Northwestern 2016.html5', 'Nuclear Energy Coop Aff - Michigan7 2016.html5', 'Nuclear Energy Coop Neg - Michigan7 2016.html5', 'Nuclear Energy Neg - Northwestern 2016.html5', 'Nuclear Fear K - DDI 2016 KQ.html5', 'Nuclear Ks - Michigan7 2013.html5', 'Nuclear Lab to Lab Affirmative - HSS 2016.html5', 'Nuclear Lab to Lab Negative - HSS 2016.html5', 'Nuclear Shipping - Michigan7 2014 GRAMS.html5', 'Nuclear Shipping Aff - DDI 2014 KQ.html5', 'Nuclear Shipping neg - DDI 2014 MS.html5', 'Nullification CP - Northwestern 2015.html5', 'Nurses Affirmative - Wave 1 - Michigan7 2018 BFHPR.html5', 'Nurses Affirmative - Wave 2 - Michigan7 2018 BFHPR.html5', 'Nurses Neg - DDI 2018 KM.html5', 'Nurses Negative - Michigan7 2018 BFHPR.html5', 'OCS Affirmative Environment Advantage - UNT 2014.html5', 'OCS Affirmative Wave 2 - MSDI 2014.html5', 'OCS Drilling Affirmative 1 - HSS 2014.html5', 'OCS Drilling Negative 1 - HSS 2014.html5', 'OSD Negative - Michigan7 2014 GRAMS.html5', 'OSEA Affirmative Wave 2 - Georgetown 2014.html5', 'OSEA Negative Wave 2 - Georgetown 2014.html5', 'OSMR aff v 2 - DDI 2014 SWS.html5', 'OTEC Aff - DDI 2014 TW.html5', 'OTEC Aff - Michigan7 2014 CJFP.html5', 'OTEC Aff - Northwestern 2014.html5', 'OTEC Aff and Neg - GMU 2014.html5', 'OTEC Affirmative - UNT 2014.html5', 'OTEC Affirmative Novice Version - Gonzaga 2014.html5', 'OTEC Neg - Michigan7 2014 CJFP.html5', 'OTEC Neg - Northwestern 2014.html5', 'OTEC Negative - HSS 2014.html5', 'OTEC Negative - MSDI 2014.html5', 'OTEC Negative - WSDI 2014.html5', 'OTEC Updates - Michigan7 2014.html5', 'Objectivism K - Wake 2017.html5', 'Ocean Acidification Critique Affirmative - UTNIF 2014.html5', 'Ocean Adv Answers - Michigan7 2014.html5', 'Ocean Affect Aff - Northwestern 2014.html5', 'Ocean Affect Neg - Northwestern 2014.html5', 'Ocean Biodiversity Core - SDI 2014.html5', 'Ocean Borders K - Michigan7 2014.html5', 'Ocean Discourse Critique - WSDI 2014.html5', 'Ocean Drones Affirmative - Michigan7 2014 BEJFR.html5', 'Ocean Drones Negative - Michigan7 2014 BEJFR.html5', 'Ocean Drones and OTEC - Michigan7 2014.html5', 'Ocean Energy Production Critique - Wake 2014.html5', 'Ocean Impact Defense - UNT 2014.html5', 'Ocean Security Critique - MSDI 2014.html5', 'Oceanic Ontology Critique - UTNIF 2014.html5', 'Oceans Critique - GMU 2014.html5', 'Oceans Development Critique - Emory 2014.html5', 'Oceans Development Critique Answers - Emory 2014.html5', 'Odyssey Aff 2.0 - Michigan7 2014 GRAMS.html5', 'Odyssey Affirmative - Michigan7 2014 GRAMS.html5', 'Odyssey Negative - Michigan7 2014 GRAMS.html5', 'Offshore Drilling Aff - DDI 2021 HL.html5', 'Offshore Drilling Case Neg - DDI 2021 GG.html5', 'Offshore Drilling Case Neg - DDI 2021 HL.html5', 'Offshore Drilling Negative - SDI 2014.html5', 'Offshore Natural Gas Negative - Emory 2014.html5', 'Offshore Wind 3.0 - Michigan7 2014 BEFJR.html5', 'Oil Affirmative - SDI 2014.html5', 'Oil DA  - Michigan7 2019 HKMM.html5', 'Oil DA - Berkeley 2017.html5', 'Oil DA - DDI 2019 KS .html5', 'Oil DA - Michigan7 2014 GJPP.html5', 'Oil Dependence Core - HSS 2014.html5', 'Oil Disadvantage - JDI 2014.html5', 'Oil Drilling Affirmative - Michigan7 2014 GJPP.html5', 'Oil Negative - Wake 2014.html5', 'Onshore CPs Upgrades - MichiganClassic 2014 SS.html5', 'Onto-Proletarian K - Wake 2018.html5', 'Ontological Terror Aff and Neg - Michigan7 2018 K Lab.html5', 'Ontological Terror Aff and Neg - Wake 2018 RKS.html5', 'Ontological Terror Masterfile - Wake 2018.html5', 'Opacity K - Northwestern 2015.html5', 'Open Borders Aff Neg - Berkeley 2018.html5', 'Open Borders Aff and Neg - Starter Packet - Michigan7 2018.html5', 'Open Borders Planless Aff and Neg - Gonzaga 2018 DMB.html5', 'Opium Mourning Aff - Michigan7 2016.html5', 'Opium Mourning Neg - Michigan7 2016.html5', 'Opt Out Neg - DDI 2017 ST.html5', 'Orientalism Critique - SDI 2016.html5', 'Orientalism K - Berkeley 2016.html5', 'Orientalism K - Berkeley 2019.html5', 'Orientalism K - Michigan7 2013.html5', 'Orientalism K - Michigan7 2016.html5', 'Orientalism Masterfile - Wake 2019.html5', 'Orion Sonar Disadvantage - Georgetown 2014.html5', 'Overfishing Core - Gonzaga 2014.html5', 'Overheating DA - Michigan7 2018 MMMR.html5', 'Overload Core - Michigan7 2015.html5', 'Overpopulation DA - Master - Wake 2018.html5', 'PCLOB Process CP - Northwestern 2015.html5', 'PFAS - Gonzaga 2021.html5', 'PICs Core - Northwestern 2015 6WS.html5', 'PQD - SDI 2021 2 week.html5', 'PRISM Affirmative - MNDI 2015.html5', 'PRISM Affirmative Supplement - MNDI 2015.html5', 'PSG Asylum Aff - Georgetown 2018.html5', 'PTD Aff - Michigan7 2021 BFHPR.html5', 'PTD Case Neg - Michigan7 2021 BFHPR.html5', 'Pakistan Affirmative - HSS 2016.html5', 'Pakistan Negative - HSS 2016.html5', 'Pan Aff - Wake 2016 RKS K Lab.html5', 'Pan K - DDI 2015 ST.html5', 'Pan K - MNDI 2016.html5', 'Pan K and Fem Answers - Michigan7 2016.html5', 'Pan Neg - Wake 2016 RKS K Lab.html5', 'Pandemic Aff-Neg - Christina - Wake 2016 RKS.html5', 'Path to Citizenship Affirmative - Northwestern 2018.html5', 'Path to Citizenship Negative - Northwestern 2018.html5', 'Performance Args - Wake 2019.html5', 'Performance Debate Good Bad - Georgetown 2014.html5', 'Performance Master File - Wake 2018 RKS.html5', 'Performance and Method Answers  - Wake 2018.html5', 'Personal Ocean Exploration Affirmative - Wake 2014.html5', 'Personal Ocean Exploration Negative - Wake 2014.html5', 'Pessimism - Starter Packet - Wake 2018.html5', 'Pessimism Critique Answers - SDI 2015.html5', 'Physics Aff - HSS 2017.html5', 'Physics Neg - HSS 2017.html5', 'Picking Losers - MichiganClassic 2014 SS.html5', 'Pinker Answers - Michigan7 2017 FFRSV.html5', 'Pirates Critique - UTNIF 2014.html5', 'Pirates case neg - DDI 2014 TW.html5', 'Plague Reps K - JDI 2015.html5', 'Planless Aff Masterfile - DDI 2020 GG.html5', 'Plastics Disadvantage - UTNIF 2014.html5', 'Plea Bargaining Aff - Neg - Berkeley 2020 Wave 2.html5', 'Plenary Power DA - Michigan7 2018 BFHPR.html5', 'Plenary Powers Aff - Berkeley 2017.html5', 'Plenary Powers Neg - Berkeley 2017.html5', 'PoMo K - Michigan7 2021 K Lab.html5', 'Poland Aff   Neg - Michigan7 2019.html5', 'Police Militarization Aff and Neg - Northwestern 2020.html5', 'Police Union Backlash DA - MSDI 2020.html5', 'Policing Negative - DDI 2015 CT.html5', 'Politic of Funk - Michigan7 2017 AFKKMM.html5', 'Political Geography K - Berkeley 2016.html5', 'Political Geography K Generic - DDI 2016.html5', 'Political Theology - Michigan7 2019 K Lab.html5', 'Politics - Georgia 2015.html5', 'Politics - Negative - UNT 2013.html5', 'Politics - TPA - Michigan7 2015.html5', 'Politics - TPP - HSS 2015.html5', 'Politics - UTNIF 2015.html5', 'Politics Core - UTNIF 2013.html5', 'Politics Core 2.0 - SDI 2017 BLRS.html5', 'Politics Core generic - DDI 2014.html5', 'Politics DA - CIR - Northwestern 2013 Starter Packet.html5', 'Politics DA - Emory 2021.html5', 'Politics DA - SCDI 2013.html5', 'Politics DA - Starter Set - Michigan7 2017.html5', 'Politics DA - UNT 2015.html5', 'Politics DA - UNT 2017.html5', 'Politics DA Updates - Berkeley 2017.html5', 'Politics DA Updates - Michigan7 2017 BFHHR.html5', 'Politics Disadvantage - Immigration - HSS 2013.html5', 'Politics Disadvantage - Internal Links - HSS 2013.html5', 'Politics Disadvantage - Links - HSS 2013.html5', 'Politics Disadvantage - Wake 2013.html5', 'Politics Generic - DDI 2013.html5', 'Politics Internal Links Core - HSS 2014.html5', 'Politics Links - Georgia 2014.html5', 'Politics NSA Reform Disadvantage - Emory 2014.html5', 'Politics Update - Michigan7 2014 GRAMS.html5', 'Politics Update - MichiganClassic 2021 MMP.html5', 'Politics Updates - Michigan7 2018 BFHPR.html5', 'Politics Updates - SDI 2019.html5', 'Politlcs Elections - DDI 2016.html5', 'Population DA - Georgetown 2018.html5', 'Populism Good and Bad - Michigan7 2018 BFHPR.html5', 'Postcolonial Feminism Kritik - UTNIF 2013.html5', 'Postcolonial Feminism Kritik Answers - UTNIF 2013.html5', 'Postcolonialism Kritik - Gonzaga 2013.html5', 'Posthumanism Aff - Wake 2017.html5', 'Preciado v Psychoanalysis - Michigan7 2016.html5', 'Presidential Powers DA - Samford 2019.html5', 'Pressure CP - Berkeley 2016.html5', 'Pressure Core - Berkeley 2016.html5', 'Prisons Aff   Neg - Wave 1 - Michigan7 2017 BFHHR.html5', 'Prisons Aff - JDI 2017.html5', 'Prisons Affirmative - Michigan7 2015.html5', 'Prisons Neg - DDI 2015 KQ.html5', 'Prisons Neg - JDI 2017.html5', 'Prisons Negative - DDI 2015 MM.html5', 'Prisons Negative - DDI 2015 SWS.html5', 'Prisons Negative - Michigan7 2015.html5', 'Prisons Negative Addendum - Northwestern 2015 6WS.html5', 'Privacy Affirmative Version 2 - Northwestern 2015 6WS.html5', 'Privacy Core - HSS 2015.html5', 'Privacy Critique - Michigan7 2015.html5', 'Privacy Generic - DDI 2015 SWS.html5', 'Privacy K - Northwestern 2015.html5', 'Private CP - DDI 2021.html5', 'Privatization CP - Berkeley 2017.html5', 'Privatization CP - Gonzaga 2017.html5', 'Privatization CP - Michigan7 2021 BFHPR.html5', 'Privatization CP - Northwestern 2017.html5', 'Privatization Core - MichiganClassic 2021 FOPVW.html5', 'Privatization DA - UTNIF 2015.html5', 'Privitization CP - Northwestern 2014.html5', 'Process Counterplans - Northwestern 2013 6WeekSeniors.html5', 'Prolif reps K Starter Set - Gonzaga 2019.html5', 'Proliferation - Michigan7 2019 BFHR.html5', 'Prosecutorial Discretion CP - SDI 2018 BGHT.html5', 'Psychoanalysis Bad - Michigan7 2019 CCPW.html5', 'Psychoanalysis Critique - Michigan7 2015.html5', 'Psychoanalysis Critique - UTNIF 2015.html5', 'Psychoanalysis K  - Michigan7 2017 BFHHR.html5', 'Psychoanalysis K - Michigan7 2014 GRAMS.html5', 'Psychoanalysis K - Michigan7 2014 HJPV.html5', 'Psychoanalysis K - Michigan7 2016.html5', 'Psychoanalysis K - Michigan7 2021 HKMLR.html5', 'Psychoanalysis K - Wake 2017.html5', 'Psychoanalysis K - Wake 2019.html5', 'Psychoanalysis K Answers - Michigan7 2016.html5', 'Psychoanalysis K Answers - Michigan7 2017 BFHHR.html5', 'Psychoanalysis K Answers - Supplement - Michigan7 2017.html5', 'Psychoanalysis K vs K Affs - Michigan7 2018 BFHPR.html5', 'Puar Aff and Neg - Wake 2018.html5', 'Puar Critique - Michigan7 2015.html5', 'Public Charge Aff  - DDI 2018 AT.html5', 'Public Charge Aff and Neg - Michigan7 2018 CPWW.html5', 'Public Charge Aff and Neg 2.0 - Gonzaga 2018 Sophomores.html5', 'Public Charge Case Neg - DDI 2018 AT.html5', 'Public Charge Neg - DDI 2018 KM.html5', 'Push Out Aff   Neg - Wake 2017.html5', 'Qatar Aff  - Michigan7 2019 BFHR.html5', 'Qatar Neg - Michigan7 2019 BFHR.html5', 'Qualified Immunity Aff Neg - UTNIF 2020.html5', 'Qualified Immunity Supplement - UTNIF 2020.html5', 'Quantum Life Aff and Neg - Michigan7 2018 K Lab.html5', 'Quare Atlantic Negative - JDI 2014.html5', 'Quashie masterfile - Wake 2019.html5', 'Queer China Aff-Neg - Wave 2 - Wake 2016 RKS.html5', 'Queer Delinquents K - UTNIF 2017.html5', 'Queer Ecology Critique - Georgetown 2014.html5', 'Queer IR K - Berkeley 2019.html5', 'Queer Immigration Aff Neg - Berkeley 2018.html5', 'Queer Inhumanism K - Michigan7 2016.html5', 'Queer K - DDI 2015 ST.html5', 'Queer Migration K - Michigan7 2018 K Lab.html5', 'Queer Nothingness - UTNIF 2020.html5', 'Queer Pessimism Answers - Wake 2018.html5', 'Queer Pessimism neg - DDI 2014 KQ.html5', 'Queer Terror K - Northwestern 2015.html5', 'Queer Theory Answers - Michigan7 2016.html5', 'Queer Theory K - Michigan7 2017 AFKKMM.html5', 'Queer Theory K Answers - Michigan7 2017 AFKKMM.html5', 'Queer Theory Ks - UTNIF 2018.html5', 'Queer Toxicity Aff Supplement - Wake 2016 RKS K Lab.html5', 'Queer Toxicity Neg - Michigan7 2016.html5', 'Queer Trans Ks - Michigan7 2016.html5', 'Queerness Affirmative and Negative - Michigan7 2015.html5', 'Queerness K - Berkeley 2017.html5', 'Queerness Supplement - Michigan7 2016.html5', 'R-Spec File - Wake 2019.html5', 'REE Aff - Northwestern 2014.html5', 'REHY Sex Ed Aff   Neg - MichiganClassic 2017 OW.html5', 'REHY Sex Ed Aff - UTNIF 2017.html5', 'REHY Sex Ed Neg - UTNIF 2017.html5', 'RFS Addendum - Michigan7 2021 BFPSW.html5', 'RFS Aff - Michigan7 2021 BFHPR.html5', 'ROC 2ac K answers Preinstitute Set - Wake 2019 (1).html5', 'ROC Aff and Neg Preinstitute Set - Wake 2019.html5', 'ROC Grand Bargain Aff - DDI 2016 KQ.html5', 'ROC aff supplement - Wake 2019.html5', 'RPP Process CP - Georgetown 2020.html5', 'RRS Lab Supplement - Gonzaga 2017.html5', 'RTE Neg - Michigan7 2017 BFHHLR.html5', 'Race Binary Kritik - Northwestern 2013 6WeekJuniors.html5', 'Race Census Affirmative - Michigan7 2015.html5', 'Race Labor K - UNT 2018.html5', 'Race War v2 - Wake 2019.html5', 'Racial Capitalism K - Michigan7 2021 K Lab.html5', 'Racial Profiling Negative - MSDI 2020.html5', 'Racial Surveillance Affirmative - SDI 2015.html5', 'Racial Surveillance Negative - SDI 2015.html5', 'Radical Autonomy K - Northwestern 2014.html5', 'Radical Convivial Ed Aff - UTNIF 2017.html5', 'Radical Convivial Ed Neg - UTNIF 2017.html5', 'Radical Thought Aff (Baudrillard) - Michigan7 2017 AFKKMM.html5', 'Radical Thought Neg (Baudrillard) - Michigan7 2017 AFKKMM.html5', 'Realism Good - Michigan7 2019 CCPW.html5', 'Reappropriation ans for word pics - DDI 2014 SWS.html5', 'Red Atlantic neg - DDI 2014 MS.html5', 'Red Atlantic neg - DDI 2014 TW.html5', 'Referendum CP - Northwestern 2015.html5', 'Reform Arms Sales CP - Emory 2019.html5', 'Reform Fatigue DA - MSDI 2017.html5', 'Reform Good - Michigan7 2020 CCPTW.html5', 'Refugees Aff - Gonzaga 2018 Scholars.html5', 'Refugees Aff Neg - Berkeley 2018.html5', 'Refugees Aff and Neg - Gonzaga 2018 Pre-Institute Packet.html5', 'Refugees Aff and Neg - Northwestern 2018.html5', 'Refugees Aff and Neg - SDI 2018 SP.html5', 'Refugees Aff and Neg - Wake 2018.html5', 'Refugees Affirmative - SDI 2018 BJMSS.html5', 'Refugees Affirmative - Wave 1 - Michigan7 2018 HJPV.html5', 'Refugees Neg - Gonzaga 2018 Scholars.html5', 'Refugees Neg Addendum - SDI 2018 SP.html5', 'Refugees Negative - SDI 2018 BJMSS.html5', 'Reg Neg CP - Berkeley 2021.html5', 'Reg Neg CP - Michigan7 2021 BFHPR.html5', 'Reg Neg CP - Northwestern 2014.html5', 'Regional Natives Aff - MichiganClassic 2021 FOPVW.html5', 'Regulation CPs  - Michigan7 2017 HJPPV.html5', 'Reject the Res Aff-Neg - Wake 2016 RKS K Lab.html5', 'Relations and Drug War Impact Defense - Georgetown 2013.html5', 'Religious Surveillance Aff Supplement - Michigan7 2015.html5', 'Religious Surveillance Aff and Neg Supplement 2 - Michigan7 2015.html5', 'Religious Surveillance Neg Supplement - Michigan7 2015.html5', 'Remittances DA - SDI 2018 BGHT.html5', 'Remote Sensing Affirmative - Michigan7 2014 CFJP.html5', 'Renewables Disadvantage - UNT 2013.html5', 'Renewables Disadvantage - Wake 2014.html5', 'Reparations Aff   Neg - Wake 2017.html5', 'Reps Defenses - Michigan7 2019 CCPW.html5', 'Reps of Suffering K - Michigan7 2013.html5', 'Reschooling Aff - Berkeley 2017.html5', 'Reschooling Neg - Berkeley 2017.html5', 'Research CP - Northwestern 2017.html5', 'Revisionism Yes-No - MichiganClassic 2019 RW.html5', 'Right to Education Aff - Gonzaga 2017.html5', 'Right to Education Aff - JDI 2017.html5', 'Right to Education Aff - Michigan7 2017 BFHHR.html5', 'Right to Education Aff - Northwestern 2017.html5', 'Right to Education Case Neg - DDI 2017 AS.html5', 'Right to Education Neg - DDI 2017 ST.html5', 'Right to Education Neg - Gonzaga 2017.html5', 'Right to Education Neg - JDI 2017.html5', 'Right to Education Neg - Northwestern 2017.html5', 'Rights K - DDI 2017 ST.html5', 'Rights Malthus - JDI 2015.html5', 'Rights Malthus - Northwestern 2015 6WS.html5', 'Rights Malthus - UTNIF 2015.html5', 'Rights Malthus DA Supplement - Michigan7 2015.html5', 'Risk Analysis Core - Michigan7 2015.html5', 'Risk Assessment Core - Michigan7 2017 HJPPV.html5', 'River Rights Aff - Michigan7 2021 EHJJPP.html5', 'River Rights Aff Neg - Northwestern 2021.html5', 'River Rights Case Neg - Michigan7 2021 EHJJPP.html5', 'Rodriguez 1ac v2 - DDI 2017 ST.html5', 'Rodriguez Aff - DDI 2017 ST.html5', 'Rodriguez Funding Aff  - MSDI 2017.html5', 'Rodriguez Updates - DDI 2017 ST.html5', 'Root Cause Core - HSS 2014.html5', 'Rubbish Affirmative - UTNIF 2014.html5', 'Rural Education Aff   Neg  - MichiganClassic 2017 MT.html5', 'Russia Alliance DA - Michigan7 2016.html5', 'Russia Arctic CP and DA - Northwestern 2014.html5', 'Russia CP - Michigan7 2013 BJFR.html5', 'Russia Counterplan and Disadvantage - SDI 2013.html5', 'Russia DA - Berkeley 2019.html5', 'Russia DA - MSDI 2021.html5', 'Russia DA - Michigan7 2019 Starter Pack.html5', 'Russia DA 2 - Michigan7 2019 BFHR.html5', 'Russia Disadvantage - Wake 2013.html5', 'Russia Fill In DA - Gonzaga 2019.html5', 'Russia SOI DA - Michigan7 2014 GRAMS.html5', 'S Visas Aff Neg - Berkeley 2018.html5', 'S%26ED Aff Wave 2 - Michigan7 2016.html5', 'SAFE Kit Testing Negative - MSDI 2020.html5', 'SCS Affirmative - Berkeley 2016.html5', 'SCS Affirmative Updates - Emory 2016.html5']\n",
        "\n",
        "\n",
        "DEBATESUM_EXTREMIST_FILTER_OUT6 = ['SCS Grand Bargain Negative - MSDI 2016.html5', 'SCS I-Law Neg - Michigan7 2016.html5', 'SCS ILaw Aff - Michigan7 2016.html5', 'SDWA Aff Neg - Michigan7 2021 BFPSW.html5', 'SEC Affirmative - HSS 2015.html5', 'SED Aff - Michigan7 2016.html5', 'SED Neg - Michigan7 2016.html5', 'SEL Neg - MSDI 2017.html5', 'SIV Aff T Update - DDI 2018 AT.html5', 'SIV Neg - DDI 2018 KM.html5', 'SMR neg - DDI 2014 KQ.html5', 'SP1 XO 12333 Negative - UTNIF 2015.html5', 'SSD Aff and Neg 2.0 - Michigan7 2014 CHHJPV.html5', 'SSD Affirmative - Michigan7 2014 CHHJPV.html5', 'SSD Affirmative Upgrades - Michigan7 2014.html5', 'SSD Negative Updates - Michigan7 2014.html5', 'SSRA Aff Supplement - SDI 2015.html5', 'SSRA Affirmative - Emory 2015.html5', 'SSRA Affirmative - Northwestern 2015.html5', 'SSRA Affirmative - SDI 2015.html5', 'SSRA Affirmative and Negative - Northwestern 2015.html5', 'STEM Aff  - Gonzaga 2017.html5', 'STEM Aff  - MSDI 2017.html5', 'STEM Aff - Starter Pack - UNT 2017.html5', 'STEM Neg - DDI 2017 AS.html5', 'STEM Neg - Northwestern 2017.html5', 'STEM Supplement - Berkeley 2017.html5', 'Sabotage Aff  - Wake 2019.html5', 'Saltwater Slavery Affirmative - SDI 2014.html5', 'Sanctions Core - MSDI 2013.html5', 'Sarbanes Oxley Affirmative and Negative - Northwestern 2015.html5', 'Satellite K Aff Answers - Michigan7 2016.html5', 'Satellite K Answers - Michigan7 2016.html5', 'Satellite Ks - Michigan7 2016.html5', 'Satire Updates - Michigan7 2014.html5', 'Say No Negative - SDI 2016.html5', 'Schmitt Critique - Michigan7 2015.html5', 'Schmitt Kritik - Northwestern 2013 6WeekSeniors.html5', 'School Abolition Neg - Michigan7 2017.html5', 'School Choice Bad and Good - SDI 2017.html5', 'School Choice CP Supplement - HSS 2017.html5', 'School Discipline Aff - Neg - JDI 2017.html5', 'School Lunches Aff - Neg - Northwestern 2017.html5', 'School Lunches Aff - Version 2 - Wake 2017.html5', 'School to Prison Pipeline Aff - Berkeley 2017.html5', 'School to Prison Pipeline Aff - HSS 2017.html5', 'School to Prison Pipeline Neg - Berkeley 2017.html5', 'School to Prison Pipeline Neg - HSS 2017.html5', 'School to Prison Pipeline Supplement - Berkeley 2017.html5', 'School to Prison Pipeline aff - UNT 2015.html5', 'Science Good Bad - Michigan7 2014 GRAMS.html5', 'Sea Turtle Protection Affirmative - JDI 2014.html5', 'Sea Turtle Protection Negative - JDI 2014.html5', 'Seaborgs Aff K Updates - Michigan7 2014.html5', 'Seaborgs Aff and Neg - Michigan7 2014 CHHJPV.html5', 'Seaborgs Affirmative Upgrades - Michigan7 2014.html5', 'Secrecy CP - MichiganClassic 2015.html5', 'Section 702 K Affirmative - Gonzaga 2015.html5', 'Section 702 Negative - DDI 2015 CT.html5', 'Secularism K - UTNIF 2017.html5', 'Security Critique - Georgia 2014.html5', 'Security Critique - JDI 2014.html5', 'Security Critique - SDI 2016.html5', 'Security Critique - UTNIF 2014.html5', 'Security Critique Link Updates - HSS 2016.html5', 'Security K  - 4 Week Lab - Gonzaga 2019.html5', 'Security K  - Michigan7 2019 BFHR.html5', 'Security K - Berkeley 2016.html5', 'Security K - DDI 2014 MS.html5', 'Security K - DDI 2015 KQ.html5', 'Security K - JDI 2015.html5', 'Security K - Michigan7 2016.html5', 'Security K - Michigan7 2018 FFGSV.html5', 'Security K - Michigan7 2021 BFPSW.html5', 'Security K - WSDI 2015.html5', 'Security K - Wake 2019.html5', 'Security K Answers - Michigan7 2016.html5', 'Security K Generic - DDI 2016.html5', 'Security K Links - Wake 2016 RKS Seniors.html5', 'Security K Starter Set - Gonzaga 2019.html5', 'Security K Supplement - JDI 2015.html5', 'Security K supplement - 4 Week Lab - Gonzaga 2019.html5', 'Security Kritik - Berkeley 2018.html5', 'Security Kritik - Emory 2013.html5', 'Security Kritik - Emory 2019.html5', 'Security Kritik - Georgia 2013.html5', 'Security Kritik - JDI 2013.html5', 'Security Kritik - Northwestern 2013 6WeekSeniors.html5', 'Security Kritik - SDI 2019.html5', 'Security Kritik Addendum - Northwestern 2013 6WeekSeniors.html5', 'Security Kritik Generic - DDI 2013.html5', 'Security and Feminism K - Wake 2015.html5', 'Security and Feminism K Answers - Wake 2015.html5', 'Security supplement- Scholars - Gonzaga 2019.html5', 'Segregation Aff - Neg - Northwestern 2017.html5', 'Sequestration Aff - Northwestern 2014.html5', 'Sequestration Neg - Northwestern 2014.html5', 'Set Col - Wake 2019.html5', 'Set Col 2.0 - Wake 2019.html5', 'Settler Colomialism Aff - Wake 2018 RKS.html5', 'Settler Colonialism Aff   Neg - Wake 2017.html5', 'Settler Colonialism Aff - Berkeley 2018.html5', 'Settler Colonialism Answers - Michigan7 2021 BFPSW.html5', 'Settler Colonialism K  - Michigan7 2019 K Lab.html5', 'Settler Colonialism K - Berkeley 2019.html5', 'Settler Colonialism K - DDI 2018.html5', 'Settler Colonialism K - DDI 2021.html5', 'Settler Colonialism K - Michigan7 2019 BFHR.html5', 'Settler Colonialism K - Michigan7 2019 CPWW.html5', 'Settler Colonialism K - Packet - SDI 2018.html5', 'Settler Colonialism K - SDI 2021.html5', 'Settler Colonialism K - UTNIF 2021.html5', 'Settler Colonialism K - Wake 2017.html5', 'Settler Colonialism Kritik - Berkeley 2018.html5', 'Settler Colonialism Kritik - Michigan7 2018 FFGSV.html5', 'Settler Colonialism Kritik - Michigan7 2018 HJPV.html5', 'Settler Colonialism Kritik - Northwestern 2018.html5', 'Settler Enclosure K - MGC 2021.html5', 'Settlerism Aff and Neg - Michigan7 2018 K Lab.html5', 'Settlerism Answers  - Wake 2018.html5', 'Settlerism K - Berkeley 2017.html5', 'Settlerism K - DDI 2015 SWS.html5', 'Settlerism K - UTNIF 2018.html5', 'Settlerism K - Wake 2018 RKS.html5', 'Settlerism Links - Wake 2018.html5', 'Settlerism Supplement - Michigan7 2021 BFPSW.html5', 'Sex Education Aff - JDI 2017.html5', 'Sex Education Neg - JDI 2017.html5', 'Sexual Difference Critique - HSS 2014.html5', 'Shipping Disadvantage - UTNIF 2014.html5', 'Shunning Disadvantage - Gonzaga 2013.html5', 'Shunning K - MSDI 2016.html5', 'Shunning Kritik - MSDI 2013.html5', 'Skilled Immigration Aff and Neg - Starter Packet - Michigan7 2018.html5', 'Small Arms Aff Neg - Berkeley 2019.html5', 'Social Movements AFF - Wake 2015.html5', 'Social Movements NEG - Wake 2015.html5', 'Soft Power Core - SDI 2015.html5', 'Solvency Core - Berkeley 2017.html5', 'Sousveillance Critique - UTNIF 2015.html5', 'South Sudan Refugees Negative - Michigan7 2018 BFHPR.html5', 'Space Aff - DDI 2016 ct.html5', 'Space Case Neg - DDI 2016 CT.html5', 'Space Case Neg v CT - DDI 2016 HS.html5', 'Space Col Supplement - Michigan7 2021 EHJJPP.html5', 'Space Coop Neg - Michigan7 2016.html5', 'Space Cooperation Affirmative - SDI 2016.html5', 'Space Cooperation Case Neg - DDI 2016 BAM.html5', 'Space Cooperation Negative - SDI 2016.html5', 'Space Elevator Aff - Michigan7 2014.html5', 'Space Elevator Neg - Michigan7 2014.html5', 'Space Exploration Aff Neg - TDI 2021.html5', 'Space Trade-off DA - Michigan7 2014 GRAMS.html5', 'Spanos K - Wake 2019.html5', 'Spark - Michigan7 2019 BFHR.html5', 'Special Interest Visas Aff and Neg - SDI 2018 NR.html5', 'Special Interest Visas Aff and Neg Updated - SDI 2018 BGHT.html5', 'Special Needs Affirmative - Michigan7 2015.html5', 'Special Needs Negative - Michigan7 2015.html5', 'Speciesism Critique - Samford 2014.html5', 'Specters Affirmative Wave 2 - UTNIF 2014.html5', 'Specters Negative - UTNIF 2014.html5', 'Specters Negative Wave 2 - UTNIF 2014.html5', 'Speed K - Gonzaga 2017.html5', 'Spending DA - DDI 2017.html5', 'Spending DA - Emory 2017.html5', 'Spending DA - HSS 2017.html5', 'Spending DA - MSDI 2017.html5', 'Spending DA - Northwestern 2017.html5', 'Spending Disadvantage - HSS 2014.html5', 'Standardized Testing Neg - MSDI 2017.html5', 'Starter Pack - Gonzaga 2017.html5', 'Startup Visas Aff Neg - Berkeley 2018.html5', 'State Budget Advantage Final - UNT 2017.html5', 'State CP DAs - Berkeley 2017.html5', 'State Dept Tradeoff DA - Michigan7 2016.html5', 'State Reformism Good Core - HSS 2014.html5', 'States CP - Berkeley 2017.html5', 'States CP - Berkeley 2020 Starter Pack.html5', 'States CP - Berkeley 2021.html5', 'States CP - DDI 2017.html5', 'States CP - Emory 2017.html5', 'States CP - Gonzaga 2017.html5', 'States CP - JDI 2017.html5', 'States CP - JDI 2021.html5', 'States CP - MSDI 2017.html5', 'States CP - MSDI 2020.html5', 'States CP - MSDI 2021.html5', 'States CP - Michigan7 2021 BFHPR.html5', 'States CP - Northwestern 2014.html5', 'States CP - SDI 2018 BGHT.html5', 'States CP - SDI 2021.html5', 'States CP - Starter Pack - JDI 2017.html5', 'States CP - Starter Set - Michigan7 2017.html5', 'States CP - WSDI 2015.html5', 'States CP - Wave 2 - Michigan7 2017 BFHHR.html5', 'States CP 2.0 - Georgetown 2020.html5', 'States CP Answers - Northwestern 2017.html5', 'States CP Supplement - HSS 2017.html5', 'States CP Updates - Berkeley 2017.html5', 'States CP Wave 2 - Berkeley 2017.html5', 'States CP and Federalism - Georgetown 2020.html5', 'States CP and Federalism - Georgetown 2021.html5', 'States CP-Federalism DA - DDI 2021.html5', 'States Federalism - Starter Pack - UNT 2017.html5', 'States and Federalism - Michigan7 2014.html5', 'Stem Aff - HSS 2017.html5', 'Stem Neg - HSS 2017.html5', 'Stick UP  - Wake 2019.html5', 'Stop and Frisk Aff-Neg - Berkeley 2020 Starter Pack.html5', 'Stop and Frisk Affirmative - Michigan7 2015.html5', 'Stored Communications Act Negative - HSS 2015.html5', 'Strategic Ambiguity Critique - SDI 2015.html5', 'Strategic Dialogue Affirmative - SDI 2016.html5', 'Strategic Dialogue Negative - SDI 2016.html5', 'Strikes CP - JDI 2016.html5', 'Student Privacy Neg - MSDI 2017.html5', 'Subjugated Knowledge K Master File - UTNIF 2017.html5', 'Substantive Due Process DA - Gonzaga 2017.html5', 'Sudan Aff - Michigan7 2016.html5', 'Sudan Neg - Michigan7 2016.html5', 'Suffering Reps K - Northwestern 2014.html5', 'Surveillance Aff Neg - Samford 2015.html5', 'Surveillance Assemblages Affirmative - DDI 2015 CT.html5', 'Surveillance Critiques - Michigan7 2015.html5', 'Suspend Whiteness Critique - SDI 2016.html5', 'Syria Affirmative - Northwestern 2018.html5', 'T - Abolition - Michigan7 2020 FFPSVV.html5', 'T - Engagement - Michigan7 2016.html5', 'T - Framework - Michigan 7 2022 FMPS.html5', 'T - Framework - Michigan7 2020 HKMM.html5', 'T - Framework Addendum - Michigan7 2020 BFHPR.html5', 'T - no plan - DDI 2014 SWS.html5', 'T Visas Critical Aff Neg - Berkeley 2018.html5', 'T Visas Policy Aff Neg - Berkeley 2018.html5', 'T-Bonds QPQ CP - Michigan7 2016.html5', 'T-Framework - Michigan7 2021 HKMLR.html5', 'TDL-CNN Aff Neg - MichiganClassic 2021 FOPVW.html5', 'THAAD Affirmative - 2AC Blocks - SDI 2016.html5', 'THAAD Affirmative - 2AC Blocks Supplement - SDI 2016.html5', 'THAAD Affirmative Supplement 1 - SDI 2016.html5', 'THAAD Affirmative Supplement 2 - SDI 2016.html5', 'THAAD Negative - SDI 2016.html5', 'TPP Aff - DDI 2016 CT.html5', 'TPP Aff-Neg Starter Pack - Northwestern 2016.html5', 'TPP Affirmative - Berkeley 2016.html5', 'TPP Case Neg - DDI 2016 HS.html5', 'TPP Neg - Michigan7 2013 HJPP.html5', 'TPP Politics DA - Michigan7 2016.html5', 'TPP Withdrawal Affirmative - Berkeley 2016.html5', 'TPP Withdrawal Negative - Berkeley 2016.html5', 'TRIG Aff Neg - Berkeley 2018.html5', 'TSA Aff and Neg Upgrade - Northwestern 2015 6WS.html5', 'TSA Affirmative - DDI 2015 SWS.html5', 'TSA Body Scanners Negative - Michigan7 2015.html5', 'Tactical Carnival Aff Neg - Berkeley 2019.html5', 'Taiwan Advantage - Georgetown 2016.html5', 'Tax Credit Scholarships CP - UNT 2017.html5', 'Tax Cuts Politics DA - Berkeley 2017.html5', 'Tax Reform Politics DA - HSS 2017.html5', 'Tax Reform Politics DA - Version 2 - Michigan7 2017 BFHHR.html5', 'Tax Reform Politics Starter DA - MSDI 2017.html5', 'Tax Reform Politics Updates - 4 Week Tourney - HSS 2017 GMMS.html5', 'Tax Reform Politics Updates - SDI 2017 GMMS.html5', 'Teacher Tenure Aff - Neg - JDI 2017.html5', 'Tear Gas Aff and Neg - Sophomores - Gonzaga 2019.html5', 'Tech Industry Advantage - HSS 2015.html5', 'Tech Leadership Bad DA - Michigan7 2014 BEFJR.html5', 'Tech Sector Advantage - HSS 2016.html5', 'Techno-Orientalism K - Wake 2017.html5', 'Technocracy K - Northwestern 2017.html5', 'Technology Critique - Michigan7 2015.html5', 'Temporary CP - Michigan7 2018 BFHPR.html5', 'Temporary Visa CPs - UTNIF 2018.html5', 'Terror 2acs - DDI 2015 ST.html5', 'Terror Case Neg - DDI 2015 MM.html5', 'Terror DA - Berkeley 2018.html5', 'Terror DA - Gonzaga 2018 DMB.html5', 'Terror DA Updates - Berkeley 2018.html5', 'Terror List Affirmative - DDI 2013 AC.html5', 'Terror Talk K - Michigan7 2013.html5', 'Terror Talk Kritik - HSS 2013.html5', 'Terror Talk Security Affirmative - DDI 2015 CT.html5', 'Terrorism DA - DDI 2018.html5', 'Terrorism DA - Georgetown 2015.html5', 'Terrorism DA - JDI 2015.html5', 'Terrorism DA - MSDI 2015.html5', 'Terrorism DA - Samford 2015.html5', 'Terrorism DA Answers - MSDI 2015.html5', 'Terrorism DA Supplement - Michigan7 2015.html5', 'Terrorism DA Updates - MNDI 2015.html5', 'Terrorism Reps K - Northwestern 2015.html5', 'Thai Slavery K Aff - DDI 2014 SWS.html5', 'Thai slavery case neg - DDI 2014 TW.html5', 'Theory File - JDI 2015.html5', 'Third Party Affirmative - Northwestern 2015.html5', 'Third Party Negative - Northwestern 2015.html5', 'Third World Consciousness Aff-Neg - Wake 2016 RKS K Lab.html5', 'Third World bad - DDI 2014 TW.html5', 'Third Worldism Cap K - Wake 2018.html5', 'This is not an aff aff and neg - Michigan7 2014 CHHJPV.html5', 'Title 1 Aff - Gonzaga 2017.html5', 'Title 1 Neg - Gonzaga 2017.html5', 'Title 1 Neg - Version 2 - Michigan7 2017 CPPR.html5', 'Title I Aff - Neg Supplement - Gonzaga 2017.html5', 'Title I Aff - Wave 2 - Michigan7 2017 HJPPV.html5', 'Title I Financing Aff - Berkeley 2017.html5', 'Title I Financing Neg - Berkeley 2017.html5', 'Title I Portability Aff - Neg - JDI 2017.html5', 'Tohono Affirmative - DDI 2015 SWS.html5', 'Tohono Negative - DDI 2015 CT.html5', 'Tohono Negative - DDI 2015 SWS.html5', 'Topic DAs - UTNIF 2015.html5', 'Topic Education and Framework Impacts - Northwestern 2015.html5', 'Topic Impact Core - JDI 2015.html5', 'Topic Link Supplement - Michigan7 2021 K Lab.html5', 'Topicality   Framework File - Wake 2017.html5', 'Topicality - Berkeley 2018.html5', 'Topicality - Blake - Wake 2016 RKS.html5', 'Topicality - Emory 2018.html5', 'Topicality - Gonzaga 2018 Sophomores.html5', 'Topicality - Gonzaga 2021.html5', 'Topicality - HSS 2013.html5', 'Topicality - JDI 2021.html5', 'Topicality - MSDI 2017.html5', 'Topicality - MSDI 2020.html5', 'Topicality - MSDI 2021.html5', 'Topicality - Michigan7 2014 BEFJR.html5', 'Topicality - Northwestern 2016 6WI.html5', 'Topicality - SDI 2016.html5', 'Topicality - SDI 2019.html5', 'Topicality - SDI 2020.html5', 'Topicality - Samford 2014.html5', 'Topicality - Starter Packet - UNT 2018.html5', 'Topicality - UTNIF 2013.html5', 'Topicality - Wake 2015.html5', 'Topicality Aff Supplement Wave 4 - Berkeley 2017.html5', 'Topicality Core - Various Versions - Michigan7 2018 FFGSV.html5', 'Topicality Education Supplement Wave 4 - Berkeley 2017.html5', 'Topicality Engagement is QPQ - NDCA 2016.html5', 'Topicality Engagement is QPQ Aff Answers - NDCA 2016.html5', 'Topicality Funding Supplement Wave 4 - Berkeley 2017.html5', 'Topicality Not Framework - China - HSS 2016.html5', 'Topicality Regulation Supplement Wave 4 - Berkeley 2017.html5', 'Topicality Substantial Supplement Wave 4 - Berkeley 2017.html5', 'Topicality Supplement - Michigan7 2015.html5', 'Topicality Supplement - Michigan7 2016.html5', 'Topicality Supplement - Michigan7 2019 FFPSV.html5', 'Topicality Supplement - UTNIF 2015.html5', 'Topicality Supplement 2 - Michigan7 2016.html5', 'Topicality Supplement Wave 3 - Berkeley 2017.html5', 'Topicality Voting Issues - SDI 2014.html5', 'Topicality v K Affs - DDI 2017 ST.html5', 'Torture Trade Aff - Michigan7 2019 CCPW.html5', 'Totalizing the West K - DDI 2017 ST.html5', 'Tournament Updates - DDI 2018 KM.html5', 'Toxicity Aff - Michigan7 2016.html5', 'Track 2 CP - Berkeley 2016.html5', 'Trade Core - Berkeley 2013.html5', 'Trade Core - DDI 2013.html5', 'Tradeoff Disadvantage - UNT 2014.html5', 'Trafficking Aff and Neg - Michigan7 2018 FFGSV.html5', 'Trafficking Case Neg - DDI 2018 AT.html5', 'Trafficking Neg - DDI 2018 KM.html5', 'Trans Rage K - Michigan7 2016.html5', 'Trans-Bathroom Neg - Starter Pack - HSS 2017.html5', 'Transgenic Fish Affirmative and Negative - Berkeley 2014.html5', 'Translators Aff and Neg - Wave 1 - Michigan7 2018 BFHPR.html5', 'Translators Negative - Michigan7 2018 BFHPR.html5', 'Transnational Anti-Blackness Answers - UTNIF 2018.html5', 'Transnational Anti-Blackness K - UTNIF 2018.html5', 'Transphobia K - DDI 2015 ST.html5', 'Travel Ban Affirmative - Michigan7 2018 MMR.html5', 'Travel Ban Affirmative - SDI 2018 BJMSS.html5', 'Travel Ban Court Politics - HSS 2017.html5', 'Travel Ban Court Politics 2.0 - SDI 2017 BHT.html5', 'Travel Ban Negative - Michigan7 2018 FFGSV.html5', 'Travel Ban Negative - Michigan7 2018 MMMR.html5', 'Tribal Mining Case Neg - DDI 2021 AT.html5', 'Tribal Mining Case Neg - DDI 2021 GG.html5', 'Tribal Mining Case Neg - DDI 2021 KM.html5', 'Trump Agenda Bad Supplement - MichiganClassic 2017 GJJS.html5', 'Trump Bad DA - Michigan7 2017.html5', 'Trump Bad DA - Version 2 - Michigan7 2017 BFHHR.html5', 'Trump Base DA - HSS 2017 BHT.html5', 'Trump Impact Core - Michigan7 2018 FFGSV.html5', 'Trump Impact Core - Michigan7 2018 MMMR.html5', 'Tsunami Warning Affirmative - HSS 2014.html5', 'Tsunamis Negative - SDI 2014.html5', 'U Visas Aff and Neg - SDI 2018 PSW.html5', 'U Visas Affirmative - Michigan7 2018 HJPV.html5', 'UN UPR CP - Michigan7 2015.html5', 'US - Earth Relations K Affirmative - Michigan7 2014 BEFJR.html5', 'USBR Tradeoff DA - DDI 2021.html5', 'USCIS Clog DA - Michigan7 2018 CPWW.html5', 'USFG Topicality - SDI 2014.html5', 'USICA  DA - JDI 2021.html5', 'USMCA Politics DA - Michigan7 2019 Starter Pack.html5', 'USMCA Politics DA 2 - Michigan7 2019 BFHR.html5', 'Ukraine aff and neg - Wake 2019.html5', 'Undercommons K - Berkeley 2017.html5', 'Undocumented Immigrants Aff   Neg  - Michigan7 2017 CMMW.html5', 'Unfunded Mandates   Spending DAs - Michigan7 2017 FFRSV.html5', 'Ungovernability K  - Michigan7 2019 Starter Pack.html5', 'Ungovernability K - Michigan7 2019 HKMM.html5', 'Unions DA - Northwestern 2018.html5', 'Update File - Michigan7 2018 FFGSV.html5', 'Update File - MichiganClassic 2018 BO.html5', 'Update File - Wave 3 - Michigan7 2017 HJPPV.html5', 'Updates - Wave 3 - Michigan7 2017 FFRSV.html5', 'Use of Force Standard Aff and Neg - Georgetown 2020.html5', 'Utopian Borders Aff and Neg - Michigan7 2018 CPWW.html5', 'Vaccines Aff   Neg - Wave 1 - Michigan7 2017 FFRSV.html5', 'Vaccines Aff   Neg Updates - Michigan7 2017 FFRSV.html5', 'Vaccines Aff - UTNIF 2017.html5', 'Vaccines DA - HSS 2015.html5', 'Vaccines Neg - UTNIF 2017.html5', 'Value Added Achievement Bad - DDI 2017 AS.html5', 'Venezuela Aff - SCDI 2013.html5', 'Venezuela Affirmative - MSDI 2013.html5', 'Venezuela Affirmative - Wake 2013.html5', 'Venezuela Conditions CP - HSS 2013.html5', 'Venezuela Debt Relief Kritik Affirmative - DDI 2013.html5', 'Venezuela K - Michigan7 2013.html5', 'Venezuela Politics DA 1 - Michigan7 2013.html5', 'Venezuela Ports Aff and Neg - Michigan7 2013.html5', 'Venezuela QPQ Negative - HSS 2013.html5', 'Venezuela Relations Disadvantage - MSDI 2013.html5', 'Venezuela Starter Pack - UTNIF 2013.html5', 'Video Surveillance Affirmative - Michigan7 2015.html5', 'Video Surveillance Negative - Michigan7 2015.html5']\n",
        "\n",
        "\n",
        "DEBATESUM_EXTREMIST_FILTER_OUT7 = ['Vigilantism DA - MSDI 2020.html5', 'Visa Aff - DDI 2017 AS.html5', 'Visuality and Identity - DDI 2015 SWS.html5', 'Vol CP + Ag DA - Gonzaga 2021.html5', 'Vouchers Aff  - MSDI 2017.html5', 'Vouchers Neg - MSDI 2017.html5', 'WCC Neg - DDI 2020 FS.html5', 'WOTUS Aff - DDI 2021 FJ.html5', 'WOTUS Aff - DDIx 2021.html5', 'WOTUS Aff - Michigan7 2021 EHJJPP.html5', 'WOTUS Aff - SDI 2021.html5', 'WOTUS Case Neg - DDI 2021 AT.html5', 'WOTUS Case Neg - DDI 2021 KM.html5', 'WOTUS Natives Aff Neg - SDI 2021.html5', 'WOTUS Neg Supplement - MichiganClassic 2021 MMP.html5', 'WOTUS Updates - Michigan7 2021 EHJJPP.html5', 'Wag the Dog DA - Berkeley 2017.html5', 'Wages DA - Berkeley 2018.html5', 'Wages DA - Northwestern 2018.html5', 'Wages DA - UNT 2018.html5', 'Wages DA - Version 2 - SDI 2018 BJMSS.html5', 'Wages DA - Wave 2 - Michigan7 2018 BFHPR.html5', 'Wakanda CP - Michigan7 2019 K Lab.html5', 'Wake Work Aff   Neg - Michigan7 2017 AFMMKK.html5', 'War Impact Core - Michigan7 2014.html5', 'War Powers DA - Michigan7 2015.html5', 'Warming Aff - DDI 2016 MS.html5', 'Warming Aff-Neg - JDI 2016.html5', 'Warming Core - Gonzaga 2013.html5', 'Warming Core - Gonzaga 2014.html5', 'Water Capitalism K - Michigan7 2021 CCPW.html5', 'Water Colonialism K - Michigan7 2021 BFHPR.html5', 'Water Colonialism K - Michigan7 2021.html5', 'Water Infrastructure Aff - Michigan7 2021.html5', 'Water Infrastructure Aff Neg - Michigan7 2021 BFPSW.html5', 'Water Infrastructure Case Neg - Michigan7 2021.html5', 'Water Security K  - Gonzaga 2021.html5', 'Water Trading Aff - DDI 2021 GDDI.html5', 'Water Trading Case Neg - DDI 2021 GDDI.html5', 'Water Wars Impact Core - Michigan7 2021 HKMLR.html5', 'Weaponitis K - Sophomores - Gonzaga 2019.html5', 'Weaponitis Kritik - Georgetown 2019.html5', 'Weapons Focus K - DDI 2019 Generic.html5', 'Welfare Aff and Neg - Northwestern 2015.html5', 'Welfare DA - Berkeley 2018.html5', 'Welfare Neg Supplement - Northwestern 2015.html5', 'Welfare Surveillance Aff and Neg - Northwestern 2015.html5', 'Welfare Surveillance Affirmative - SDI 2015.html5', 'Welfare Surveillance Negative - SDI 2015.html5', 'Western Epistemology K - Michigan7 2014.html5', 'White Collar Crime Neg - DDI 2020 HL.html5', 'White FW - Wake 2019.html5', 'Whitewashing Counterplan - DDI 2013 CM.html5', 'Wikimedia Affirmative - Northwestern 2015.html5', 'Wind Power Affirmative 2AC - SDI 2014.html5', 'Word PICs - Michigan7 2018 HJPV.html5', 'Workplace Raids Affirmative - HSS 2015.html5', 'Workplace Raids Negative - HSS 2015.html5', 'Yes No War - Michigan7 2014 GRAMS.html5', 'Yes War - JDI 2015.html5', 'ZTP Negative - MSDI 2020.html5', 'Zambia Aff - Michigan7 2016.html5', 'Zambia Neg - Michigan7 2016.html5', 'Zapatistas Affirmative - DDI 2013 AC.html5', 'Zelman Aff - Berkeley 2017.html5', 'Zero Days Negative - Michigan7 2015.html5', 'Zero Tolerance Aff  - MSDI 2017.html5', 'Zero Tolerance Aff - DDI 2017 AS.html5', 'Zero Tolerance Neg - DDI 2017 AS.html5', 'Zero Tolerance Neg - MSDI 2017.html5', 'Zero Tolerance Policies Aff Wave 1 - DDI 2017 ST.html5', 'Zika Politics DA - Berkeley 2016.html5', 'Zong v1 neg - DDI 2014 MS.html5', 'Zong v2 neg - DDI 2014 MS.html5', 'anti blackness master file - Wake 2019.html5', 'cap good - DDI 2014 SWS.html5', 'cards for rks tournament - Wake 2019.html5', 'communicative engagement aff - DDI 2016 CT.html5', 'community fisheries case neg - DDI 2014 SWS.html5', 'ecofem case neg - DDI 2014 SWS.html5', 'heidegger neg - DDI 2014 KQ.html5', 'politics - infrastructure - JDI 2021.html5']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foo = load_dataset(\"Hellisotherpeople/DebateSum\",split='train',streaming=True).filter(\n",
        "    lambda x : (x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT2) and (len(x['Full-Document'].split(' '))>500)\n",
        ")\n",
        "bar = [e for e in foo]"
      ],
      "metadata": {
        "id": "35SIfH6GaJZE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fd84482d10704f60adbc647cfb47b95e",
            "9ff7579aaccc469c81597b9600121114",
            "2e7e744df0a94152a01a659d0ddc5d9d",
            "b60a8ec2aea74e30abf3266c33ff5cf2",
            "fa3f0c50db6c4a189932059908bb5b56",
            "007ff759ee214271b5ae7440474e3917",
            "2e298213e70f4e7caf7bbfe4f210699f",
            "e29f42f9692e4ac1bdd6ae11295c7dd0",
            "21093f9c444f44dca7b7ad4c8f7d3968",
            "d533792a09ba47469c8183bb47589bd6",
            "e75725f396d94906b61978bb61639dc3"
          ]
        },
        "outputId": "e77d96c7-8635-41b3-fbcd-bc4b7b2af532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd84482d10704f60adbc647cfb47b95e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = [e for e in bar if e['OriginalDebateFileName'] in [\n",
        "'DOD and Navy Counterplan - SDI 2014.html5'\n",
        "]]"
      ],
      "metadata": {
        "id": "mbMx2ne3asRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsK_b58Na1Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w6pkap_3a1H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4xJ9EAfa1OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0mWbB3lBazT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #     'In the following passage from a financial statement \"{XX^^CONTENT^^XX}\", what does the number \"{XX^^NUM^^XX}\" represent?\\nAnswer: \"{XX^^ANS^^XX}\"',\n",
        "\n",
        "def filter_finer139(x):\n",
        "    return sum(x['ner_tags'])>0\n",
        "\n",
        "def clean_finer139_for_mlm(x):\n",
        "    tokens,tags = x['tokens'], x['ner_tags']\n",
        "    passage = re.sub(\"(?<=\\w)\\s+(?=[\\’\\,\\;\\.\\”\\)])\",\"\",re.sub(\"(?<=\\d)\\s\\%\",\"%\",re.sub(\"\\$\\s(?=\\d)\",\"$\",\" \".join(tokens))))\n",
        "    #print(passage)\n",
        "    concept_answers = [\n",
        "        (w,FINER139_CLASSES[t].strip(),i)\n",
        "        for i,(w,t) in enumerate(zip(tokens, tags)) if t!=0\n",
        "    ]\n",
        "    which_take = ord(passage[:20].replace(\" \",\"\")[-1])\n",
        "    ans_triplet = concept_answers[which_take % len(concept_answers)]\n",
        "    # get all answers of same classe\n",
        "    other_answers_of_same_class = [a for a in concept_answers if a[1]==ans_triplet[1]]\n",
        "    if len(other_answers_of_same_class)==1:\n",
        "        tnumber,ansclass,idx = ans_triplet\n",
        "        is_dollar = \"$\" if tokens[idx-1]=='$' else \"\"\n",
        "        is_unit = tokens[idx+1] if tokens[idx+1].lower() in ['million','billion','hundred','thousand','percent','%','hundred-thousand'] else \"\"\n",
        "        tnumber = (is_dollar + tnumber + \" \"+is_unit).strip().replace(' %',\"%\")\n",
        "        ansprefix = {0:'a',1:'an',2:\"the\",3:'the'}[int(ansclass[0] in ['a','e','i','o','u','y'])+2*(ansclass[-1]=='s')]\n",
        "        ansclass = {0:ansclass.title(), 1:ansclass}[which_take % 2]\n",
        "        template = TEMPLATE_FINER139[which_take % len(TEMPLATE_FINER139)]\n",
        "        text = template.replace(\"{NUMBER}\",tnumber).replace(\"{ANSWER}\",ansclass).replace(\"{PREFIX}\",ansprefix).replace('{PASSAGE}',passage)\n",
        "        return {'text':text}\n",
        "    else:\n",
        "        multi_number= []\n",
        "        for ans_triplet in other_answers_of_same_class:\n",
        "            tnumber,ansclass,idx = ans_triplet\n",
        "            is_dollar = \"$\" if tokens[idx-1]=='$' else \"\"\n",
        "            is_unit = tokens[idx+1] if tokens[idx+1].lower() in ['million','billion','hundred','thousand','percent','%','hundred-thousand'] else \"\"\n",
        "            tnumber = (is_dollar + tnumber + \" \"+is_unit).strip().replace(' %',\"%\")\n",
        "            multi_number.append(tnumber)\n",
        "        multi_number = list(set(multi_number))\n",
        "        # combine the multi numbers\n",
        "        sep = {0:'/',1:' / ', 2:' and ', 3: ' & ', 4:' + '}[which_take % 5]\n",
        "        tnumber = \", \".join(multi_number[:-1]) + sep + multi_number[-1]\n",
        "        ansprefix = {0:'a',1:'an',2:\"the\",3:'the'}[int(ansclass[0] in ['a','e','i','o','u','y'])+2*(ansclass[-1]=='s')]\n",
        "        ansclass = {0:ansclass.title(), 1:ansclass}[which_take % 2]\n",
        "        template = TEMPLATE_FINER139[which_take % len(TEMPLATE_FINER139)]\n",
        "        text = template.replace(\"{NUMBER}\",tnumber).replace(\"{ANSWER}\",ansclass).replace(\"{PREFIX}\",ansprefix).replace('{PASSAGE}',passage)\n",
        "        return {'text':text}\n",
        "\n",
        "TEMPLATE_FINER139 =[\n",
        "    'In the following passage from a financial statement \"{PASSAGE}\", what does the number \"{NUMBER}\" represent?\\nAnswer: \"{ANSWER}\"',\n",
        "    'Context: {PASSAGE}.\\nQuestion: What financial concept does the value \"{NUMBER}\" pertain to?\\nAnswer: {PREFIX} {ANSWER}',\n",
        "    \"Look at the number {NUMBER} in this statement: '{PASSAGE}'. What is {NUMBER}?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"Here is a sentence from a company's financial report: '{PASSAGE}'\\nQuestion: what is it's {ANSWER}?\\nAnswer: '{NUMBER}'\",\n",
        "    \"Please extract {PREFIX} {ANSWER} from this paragraph:\\n'{PASSAGE}'\\nAnswer: {NUMBER}\",\n",
        "    \"Question: I need to find an example of {PREFIX} {ANSWER} in the following financial statement: '{PASSAGE}'.\\nANSWER: The value {NUMBER} represents the company's {ANSWER}\",\n",
        "    \"CONTEXT: {PASSAGE}\\nQUESTION: what is the '{ANSWER}'?\\nANSWER: {NUMBER}\",\n",
        "    \"QUESTION: what is the {ANSWER}?\\nCONTEXT: {PASSAGE}\\nANSWER: {NUMBER}\",\n",
        "    \"The company reported: '{PASSAGE}'. Find the numeric value representing its '{ANSWER}'\\nAssistant: Certainly, the value is: {NUMBER}\",\n",
        "    \"Human: What does the reported number {NUMBER} refer to in this financial disclosure: '{PASSAGE}'.\\nAssistant: {ANSWER}\",\n",
        "    \"Q: According to the following passage, what is the company's reported '{ANSWER}'?\\nCONTEXT: {PASSAGE}\\nAns: '{NUMBER}'\",\n",
        "    \"CONTEXT: {PASSAGE}\\nQUESTION: what does the value {NUMBER} mean to the company?\\nANSWER: {ANSWER} is {NUMBER}\",\n",
        "    \"Human: I need an example of '{ANSWER}'. Please write an example of a company's financial statement where {ANSWER} is {NUMBER}.\\nAssistant: Certainly, here is an example financial statement: '{PASSAGE}'\",\n",
        "] + [\n",
        "    'Based on the financial statement excerpt \"{PASSAGE}\", can you explain what the number(s) \"{NUMBER}\" represents?\\nAnswer: \"{ANSWER}\"',\n",
        "    'I came across this in a financial report: \"{PASSAGE}\". What exactly does the number(s) \"{NUMBER}\" signify?\\nAnswer: {PREFIX} {ANSWER}',\n",
        "    \"Could you help me understand the value '{NUMBER}' in the statement '{PASSAGE}'? What does it represent?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"From the financial report, I found the sentence '{PASSAGE}'.\\nWhat is the significance of '{NUMBER}'?\\nAnswer: '{ANSWER}'\",\n",
        "    \"Could you please extract the {ANSWER} from this passage:\\n'{PASSAGE}'\\nAnswer: {NUMBER}\",\n",
        "    \"I'm looking for an example of {PREFIX} {ANSWER} in a financial statement. Can you find it in this passage: '{PASSAGE}'?\\nAnswer: The value {NUMBER} represents the company's {ANSWER}\",\n",
        "    \"In this context: '{PASSAGE}', can you tell me what the {ANSWER} refers to?\\nAnswer: {NUMBER}\",\n",
        "    \"What is the value(s) of {ANSWER} in the context of '{PASSAGE}'?\\nAnswer: {NUMBER}\",\n",
        "    \"According to the company's report: '{PASSAGE}', where can I find the numeric representation of its '{ANSWER}'?\\nAssistant: Certainly, the value is: {NUMBER}\",\n",
        "    \"Could you explain what the reported number {NUMBER} signifies in this financial disclosure: '{PASSAGE}'?\\nAssistant: {ANSWER}\",\n",
        "    \"Given the following passage, can you tell me what the company's reported '{ANSWER}' is?\\nContext: {PASSAGE}\\nAnswer: '{NUMBER}'\",\n",
        "    \"What is the {ANSWER} according to this passage: '{PASSAGE}'?\\nAnswer: {ANSWER} is {NUMBER}\",\n",
        "    \"I need an example of '{ANSWER}'. Can you provide an example of a company's financial statement where {ANSWER} is {NUMBER}?\\nAssistant: Certainly, here is an example financial statement: '{PASSAGE}'\",\n",
        "    \"I came across this in a financial report: '{PASSAGE}'. What exactly does the number '{NUMBER}' signify?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"Can you explain what '{NUMBER}' represents in this financial statement excerpt: '{PASSAGE}'?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"Given this paragraph '{PASSAGE}'. Can you tell me what the value '{NUMBER}' stands for?\\nAnswer: '{ANSWER}'\",\n",
        "    \"I need to find an example of {PREFIX} {ANSWER} in the following financial statement: '{PASSAGE}'.\\nANSWER: The value {NUMBER} represents the company's {ANSWER}\",\n",
        "    \"In this context: '{PASSAGE}', can you tell me what the value of '{ANSWER}' is?\\nAnswer: {NUMBER}\",\n",
        "    \"Could you please explain what the reported number {NUMBER} means in this financial disclosure: '{PASSAGE}'?\\nAssistant: the value(s) refer to '{ANSWER}'\",\n",
        "    \"Based on the financial statement excerpt '{PASSAGE}', can you explain what the number '{NUMBER}' represents?\\nAnswer: '{ANSWER}'\",\n",
        "    \"Could you explain what '{NUMBER}' represents in this financial statement excerpt: '{PASSAGE}'?\\nAnswer: '{ANSWER}'\",\n",
        "    \"From the company's financial report: '{PASSAGE}'. What is the significance of '{NUMBER}'?\\nAnswer: '{ANSWER}'\",\n",
        "    \"I need to find an example of '{ANSWER}'. Please write an example of a company's financial statement where {ANSWER} is {NUMBER}.\\nAssistant: Certainly, here is an example financial statement: '{PASSAGE}'\",\n",
        "    \"Can you explain what '{NUMBER}' represents in this financial statement excerpt: '{PASSAGE}'?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"I need an example of '{ANSWER}'. Can you provide an example of a company's financial statement where {ANSWER} is {NUMBER}?\\nAssistant: Certainly, here is an example financial statement: '{PASSAGE}'\",\n",
        "    \"Could you help me understand the value '{NUMBER}' in the statement '{PASSAGE}'? What does it represent?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"Here is a sentence from a company's financial report: '{PASSAGE}'\\nQuestion: what is it's {ANSWER}?\\nAnswer: '{NUMBER}'\",\n",
        "    \"Look at the number {NUMBER} in this statement: '{PASSAGE}'. What is {NUMBER}?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"Please extract {PREFIX} {ANSWER} from this paragraph:\\n'{PASSAGE}'\\nAnswer: {NUMBER}\",\n",
        "    \"Context: {PASSAGE}.\\nQuestion: What financial concept does the value '{NUMBER}' pertain to?\\nAnswer: {PREFIX} {ANSWER}\",\n",
        "    \"In the following passage from a financial statement '{PASSAGE}', what does the number '{NUMBER}' represent?\\nAnswer: '{ANSWER}'\",\n",
        "    \"What is the {ANSWER} according to this passage: '{PASSAGE}'?\\nAnswer: {ANSWER} is {NUMBER}\",\n",
        "    \"CONTEXT: {PASSAGE}\\nQUESTION: what does the value(s) {NUMBER} mean to the company?\\nANSWER: '{ANSWER}' is {NUMBER}\",\n",
        "    \"The company reported: '{PASSAGE}'. Find the numeric value representing its '{ANSWER}'\\nAssistant: Certainly, the value is: {NUMBER}\",\n",
        "    \"Human: What does the reported number {NUMBER} refer to in this financial disclosure: '{PASSAGE}'.\\nAssistant: {ANSWER}\",\n",
        "    \"Q: According to the following passage, what is the company's reported '{ANSWER}'?\\nCONTEXT: {PASSAGE}\\nAns: '{NUMBER}'\",\n",
        "    \"In this context: '{PASSAGE}', can you tell me what '{NUMBER}' refers to?\\nAnswer: {ANSWER}\",\n",
        "    \"What is the quantitative meaning of '{ANSWER}' according to this reported-paragraph: '{PASSAGE}'?\\nAnswer: {NUMBER}\",\n",
        "    \"According to the company's report: '{PASSAGE}', where can I find the numeric representation of its '{ANSWER}'?\\nAssistant: Certainly, the value is: {NUMBER}\",\n",
        "    \"Could you explain what the reported number {NUMBER} signifies in this financial disclosure: '{PASSAGE}'?\\nAssistant: {ANSWER}\",\n",
        "    \"Given the following passage, can you tell me what the company's reported '{ANSWER}' is?\\nContext: {PASSAGE}\\nAnswer: '{NUMBER}'\",\n",
        "    \"What is the '{ANSWER}' according to this passage: '{PASSAGE}'?\\nAnswer: {ANSWER} is {NUMBER}\",\n",
        "    \"I need an example of '{ANSWER}'. Can you provide an example of a company's financial statement where {ANSWER} is {NUMBER}?\\nAssistant: Certainly, here is an example financial statement: '{PASSAGE}'\"\n",
        "]\n",
        "\n",
        "FINER139_CLASSES ={0: 'I do not know',\n",
        " 1: 'accrual for environmental loss contingencies',\n",
        " 2: 'weighted average useful life of acquired finite-lived intangible assets',\n",
        " 3: 'weighted average useful life of acquired finite-lived intangible assets',\n",
        " 4: 'allocated expense for share-based compensation',\n",
        " 5: 'amortization of financing costs',\n",
        " 6: 'amortization of intangible assets',\n",
        " 7: 'amortization of intangible assets',\n",
        " 8: 'securities excluded from earnings per share computation due to antidilution',\n",
        " 9: 'securities excluded from earnings per share computation due to antidilution',\n",
        " 10: 'area of real estate property',\n",
        " 11: 'area of real estate property',\n",
        " 12: 'charges for impairment of assets',\n",
        " 13: 'number of shares issued for equity interests in business acquisitions',\n",
        " 14: 'percentage of voting interests acquired in business acquisition',\n",
        " 15: 'percentage of voting interests acquired in business acquisition',\n",
        " 16: 'acquisition-related costs in business combinations',\n",
        " 17: 'consideration transferred in business combinations',\n",
        " 18: 'contingent consideration liability in business combinations',\n",
        " 19: 'intangible assets (other than goodwill) acquired and liabilities assumed in business combinations',\n",
        " 20: 'intangible assets acquired and liabilities assumed in business combinations',\n",
        " 21: 'amortization of capitalized contract costs',\n",
        " 22: 'fair value disclosure of cash and cash equivalents',\n",
        " 23: 'exercise price of warrants or rights in a specific class',\n",
        " 24: 'shares reserved for future issuance in common stock capital',\n",
        " 25: 'dividends per share declared in common stock',\n",
        " 26: 'par or stated value per share of common stock',\n",
        " 27: 'common stock shares authorized',\n",
        " 28: 'common stock shares authorized',\n",
        " 29: 'common stock shares outstanding',\n",
        " 30: 'concentration risk percentage1',\n",
        " 31: 'contract with customer liability',\n",
        " 32: 'contract with customer liability revenue recognized',\n",
        " 33: 'cumulative effect of new accounting principle in period of adoption',\n",
        " 34: 'debt instrument basis spread on variable rate1',\n",
        " 35: 'debt instrument carrying amount',\n",
        " 36: 'conversion price of convertible debt instrument',\n",
        " 37: 'face value of debt instrument',\n",
        " 38: 'face value of debt instrument',\n",
        " 39: 'fair value of debt instrument',\n",
        " 40: 'effective interest rate of debt instrument',\n",
        " 41: 'stated interest rate of debt instrument',\n",
        " 42: 'maturity date of debt instrument',\n",
        " 43: 'maturity date of debt instrument',\n",
        " 44: 'redemption price of debt instrument',\n",
        " 45: 'term of debt instrument',\n",
        " 46: 'term of debt instrument',\n",
        " 47: 'unamortized discount on debt instrument',\n",
        " 48: 'weighted average interest rate of debt',\n",
        " 49: 'gross deferred finance costs',\n",
        " 50: 'net deferred finance costs',\n",
        " 51: 'defined benefit plan contributions by employer',\n",
        " 52: 'defined contribution plan cost recognized',\n",
        " 53: 'depreciation',\n",
        " 54: 'derivative fixed interest rate',\n",
        " 55: 'derivative notional amount',\n",
        " 56: 'consideration for disposal group (including discontinued operation)',\n",
        " 57: 'effective income tax rate for continuing operations',\n",
        " 58: 'reconciliation of effective income tax rate to federal statutory income tax rate',\n",
        " 59: 'total compensation costs not-yet-recognized of non-vested awards (for employee service share-based compensation programs)',\n",
        " 60: 'total compensation costs not-yet-recognized of non-vested awards (for employee service share-based compensation programs) for period of recognition',\n",
        " 61: 'total compensation costs not-yet-recognized of non-vested awards (for employee service share-based compensation programs) for period of recognition',\n",
        " 62: 'total compensation costs not-yet-recognized of non-vested awards other than options (for employee service share-based compensation programs)',\n",
        " 63: 'tax benefits from compensation expense (for employee service share-based compensation programs)',\n",
        " 64: 'ownership percentage (for equity method investment)',\n",
        " 65: 'ownership percentage (equity method investment)',\n",
        " 66: 'equity method investments',\n",
        " 67: 'useful life of finite lived intangible assets',\n",
        " 68: 'useful life of finite lived intangible assets',\n",
        " 69: 'gains losses on extinguishment of debt',\n",
        " 70: 'goodwill',\n",
        " 71: 'goodwill impairment loss',\n",
        " 72: 'guarantee obligations maximum exposure',\n",
        " 73: 'income (loss) from equity method investments',\n",
        " 74: 'income tax expense benefit',\n",
        " 75: 'interest expense',\n",
        " 76: 'interest expense debt',\n",
        " 77: 'lease and rental expense',\n",
        " 78: 'lessee operating lease renewal term',\n",
        " 79: 'lessee operating lease renewal term',\n",
        " 80: 'lessee operating lease term of contract',\n",
        " 81: 'lessee operating lease term of contract',\n",
        " 82: 'letters of credit outstanding amount',\n",
        " 83: 'line of credit',\n",
        " 84: 'fee percentage for line of credit facility commitment',\n",
        " 85: 'current borrowing capacity of the line of credit facility',\n",
        " 86: 'line of credit facility interest rate at period end',\n",
        " 87: 'maximum borrowing capacity line of credit facility',\n",
        " 88: 'line of credit facility remaining borrowing capacity',\n",
        " 89: 'line of credit facility unused capacity commitment fee percentage',\n",
        " 90: 'long term debt',\n",
        " 91: 'fair value of long term debt',\n",
        " 92: 'loss contingency accrual at carrying value',\n",
        " 93: 'value of damages sought (loss contingency)',\n",
        " 94: 'estimate of possible loss for the loss contingency',\n",
        " 95: 'loss contingency pending claims number',\n",
        " 96: 'pending claims number (loss contingency)',\n",
        " 97: 'minority-interest ownership percentage by noncontrolling owners',\n",
        " 98: 'minority interest ownership percentage, by parent',\n",
        " 99: 'number of operating segments',\n",
        " 100: 'number of real estate properties',\n",
        " 101: 'quantity of real estate properties',\n",
        " 102: 'number of reportable segments',\n",
        " 103: 'operating lease cost',\n",
        " 104: 'operating lease expense',\n",
        " 105: 'operating lease liability',\n",
        " 106: 'operating lease payments',\n",
        " 107: 'operating lease right of use asset',\n",
        " 108: 'operating lease weighted average discount rate percent',\n",
        " 109: 'weighted-average remaining lease-term of operating lease',\n",
        " 110: \"operating lease's weighted-average remaining term\",\n",
        " 111: 'operating leases rent net expense',\n",
        " 112: 'operating loss carryforwards',\n",
        " 113: 'gross payments to acquire businesses',\n",
        " 114: 'payments to acquire businesses, net of cash acquired',\n",
        " 115: 'dividend rate of preferred stock (as percent)',\n",
        " 116: 'preferred stock shares authorized',\n",
        " 117: 'preferred stock shares authorized',\n",
        " 118: 'proceeds from issuance of common stock',\n",
        " 119: 'useful life of property, plants and equipment',\n",
        " 120: 'useful life of equipment, property and plants',\n",
        " 121: 'requested rate of increase (or decrease) pertaining to public utilities',\n",
        " 122: 'related party transaction amounts of transaction',\n",
        " 123: 'related party transaction amounts of transaction',\n",
        " 124: 'transaction expenses from transactions with related party',\n",
        " 125: 'transaction expenses incurred from transacting with related parties',\n",
        " 126: 'repayments of debt',\n",
        " 127: 'expected costs related to restructuring',\n",
        " 128: 'charges related to restructuring',\n",
        " 129: 'company revenue from contract with customer excluding assessed tax',\n",
        " 130: 'revenue from contract with customer including assessed tax',\n",
        " 131: 'company revenue from related parties',\n",
        " 132: 'revenue remaining performance obligation',\n",
        " 133: 'revenues',\n",
        " 134: 'number of shares during stock-sale tranaction',\n",
        " 135: 'number of shares issued in transaction for sale of stocks',\n",
        " 136: 'sale of stock price per share',\n",
        " 137: 'share-based compensation',\n",
        " 138: 'award vesting period for stock-based compensation arrangement by share-based payment',\n",
        " 139: 'share based compensation arrangement by share based payment (award vesting period)',\n",
        " 140: 'share-based compensation arrangement equity instruments (other than options grants)',\n",
        " 141: 'equity instruments (other than options grants) for stock-based compensation arrangement',\n",
        " 142: 'weighted-average grant date for the fair value of share based compensation arrangement',\n",
        " 143: 'non-vested number of equity instruments, for share based compensation not pertaining to options',\n",
        " 144: 'total fair value of stock-based compensation arrangement (not including options vested) for the reporting period',\n",
        " 145: 'number of shares authorized for share-based compensation',\n",
        " 146: 'number of shares authorized for stock-based compensation',\n",
        " 147: 'number of shares available for grant (for stock-based compensation)',\n",
        " 148: 'total intrinsic value of exercised options in the reporting period (as part of stock-based awards)',\n",
        " 149: 'options grants for share-based compensation for the reporting period',\n",
        " 150: 'weighted-average grant date for the fair value of share based compensation arrangement',\n",
        " 151: 'share price',\n",
        " 152: 'award vesting rights percentage for for share-based compensation arrangement by sharebased payment award',\n",
        " 153: 'vesting rights percentage for share-based compensation arrangement',\n",
        " 154: 'expiration period of share-based compensation',\n",
        " 155: 'expiration period for stock-based awards/compensation',\n",
        " 156: 'new issues issued during period',\n",
        " 157: 'new issues issued during the reporting period',\n",
        " 158: 'stock repurchase program authorized amount',\n",
        " 159: 'repurchase amount of remaining authorized stock in the repurchase program',\n",
        " 160: 'stock repurchased and retired during the quarter',\n",
        " 161: 'number of shares repurchased during period',\n",
        " 162: 'number of shares repurchased during the reporting period',\n",
        " 163: 'prior year claims and claims adjustment expense for property casualty insurance underwriters (supplemental information)',\n",
        " 164: \"treasury stocks' average cost per share acquired\",\n",
        " 165: 'treasury stock shares acquired',\n",
        " 166: 'amount of treasury stock acquired',\n",
        " 167: 'cost method for acquired treasury stock value ',\n",
        " 168: 'unrecognized tax benefits',\n",
        " 169: 'unrecognized tax benefits that would impact effective tax rate',\n",
        " 170: 'gross deferred finance costs',\n",
        " 171: 'common stock par or stated value per share',\n",
        " 172: 'loss contingency estimate of possible loss',\n",
        " 173: 'defined contribution plan recognized cost',\n",
        " 174: 'fair value of debt instrument',\n",
        " 175: 'recognized revenue of contract with customer liability',\n",
        " 176: 'revenue remaining performance obligation',\n",
        " 177: 'total compensation cost of employee share-based compensation nonvested awards not yet recognized',\n",
        " 178: 'stated percentage of interest rate for debt instrument',\n",
        " 179: 'operating loss carryforwards',\n",
        " 180: 'minority interest ownership percentage by noncontrolling owners',\n",
        " 181: 'interest expense',\n",
        " 182: 'long term debt',\n",
        " 183: 'share based compensation',\n",
        " 184: 'debt-weighted average interest rate',\n",
        " 185: 'debt instrument carrying amount',\n",
        " 186: 'debt instrument convertible conversion price',\n",
        " 187: 'income tax expense benefit',\n",
        "                   # done\n",
        " 188: 'total compensation cost for share-based payment award options granted in the period (weighted average grant date fair value)',\n",
        " 189: 'nonvested awards - total compensation cost not yet recognized for share-based awards (excluding options) for employee service share-based compensation',\n",
        " 190: 'equity method investments',\n",
        " 191: 'unamortized discount on debt instruments',\n",
        " 192: 'gains/losses on extinguishment of debt',\n",
        " 193: 'number of shares available for grant for share-based payment awards',\n",
        " 194: 'recognized identifiable assets acquired and liabilities assumed, intangible assets (other than goodwill) pertaining to business combination',\n",
        " 195: 'preferred stock: dividend rate percentage',\n",
        " 196: 'revenue from contracts with customers (including assessed tax)',\n",
        " 197: 'operating lease: weighted average discount rate percentage',\n",
        " 198: 'line of credit',\n",
        " 199: 'maximum borrowing capacity of line of credit facility',\n",
        " 200: 'effective income tax rate reconciliation at federal statutory income tax rate',\n",
        " 201: 'commitment fee percentage for line of credit facility',\n",
        " 202: 'business combination: consideration transferred',\n",
        " 203: 'common stock dividends per share declared',\n",
        " 204: 'basis spread on variable rate of debt instrument',\n",
        " 205: 'disposal group (including discontinued operations): consideration',\n",
        " 206: 'gross number of share-based payment award options granted in the period (share-based compensation arrangement)',\n",
        " 207: 'common stock: shares outstanding',\n",
        " 208: 'amortization of financing costs',\n",
        " 209: 'line of credit facility: current borrowing capacity',\n",
        " 210: 'treasury stock value (acquired - cost method)',\n",
        " 211: 'nonvested number of equity instruments other than options (share-based compensation arrangement)',\n",
        " 212: 'debt instrument: effective interest rate percentage',\n",
        " 213: 'sale of stock: price per share',\n",
        " 214: 'capitalized contract cost amortization',\n",
        " 215: 'restructuring charges',\n",
        " 216: 'total fair value of vested equity instruments other than options in period (share-based compensation arrangement)',\n",
        " 217: 'accrual for environmental loss contingencies',\n",
        " 218: 'fair value disclosure of cash and cash equivalents',\n",
        " 219: 'proceeds from issuance of common stock',\n",
        " 220: 'revenues',\n",
        " 221: 'recognized identifiable assets acquired and liabilities assumed, for intangibles (due to business combination)',\n",
        " 222: 'letters of credit: outstanding amount',\n",
        " 223: 'weighted average grant date fair value of equity instruments (other than options) granted in the period',\n",
        " 224: 'operating lease payments',\n",
        " 225: 'line of credit facility: remaining borrowing capacity',\n",
        " 226: 'payments to acquire businesses (gross)',\n",
        " 227: 'average cost per share of treasury stock acquired',\n",
        " 228: 'deferred finance costs (net)',\n",
        " 229: 'stock repurchase program: authorized amount',\n",
        " 230: 'interest expense on debt',\n",
        " 231: 'contract with customer: liability',\n",
        " 232: 'operating lease expense',\n",
        " 233: 'depreciation',\n",
        " 234: 'allocated share-based compensation expense',\n",
        " 235: 'loss contingency accrual at carrying value',\n",
        " 236: 'unused capacity commitment fee percentage for line of credit facility',\n",
        " 237: 'prior year claims and claims adjustment expense for property casualty insurance underwriters (supplemental information)',\n",
        " 238: 'operating lease liability',\n",
        " 239: 'revenue from related parties',\n",
        " 240: 'payments to acquire businesses (net of cash acquired)',\n",
        " 241: 'business combination: contingent consideration liability',\n",
        " 242: 'loss contingency: damages sought value',\n",
        " 243: 'number of operating segments',\n",
        " 244: 'business acquisition: equity interests issued or issuable - number of shares issued',\n",
        " 245: 'operating lease: right of use asset',\n",
        " 246: 'business combination: acquisition-related costs',\n",
        " 247: 'unrecognized tax benefits',\n",
        " 248: 'guarantee obligations: maximum exposure',\n",
        " 249: 'restructuring and related costs: expected cost',\n",
        " 250: 'defined benefit plan contributions by employer',\n",
        " 251: 'operating lease cost',\n",
        " 252: 'derivative: fixed interest rate',\n",
        " 253: 'goodwill',\n",
        " 254: 'goodwill impairment loss',\n",
        " 255: 'common stock capital: shares reserved for future issuance',\n",
        " 256: 'stock repurchased and retired during period: shares',\n",
        " 257: 'tax benefit from compensation expense for employee service share-based compensation',\n",
        " 258: 'income (loss) from equity method investments',\n",
        " 259: 'number of reportable segments',\n",
        " 260: 'fair value of long-term debt',\n",
        " 261: 'repayments of debt',\n",
        " 262: 'concentration risk percentage',\n",
        " 263: 'debt instrument: redemption price percentage',\n",
        " 264: 'cumulative effect of new accounting principle in period of adoption',\n",
        " 265: 'share price',\n",
        " 266: 'unrecognized tax benefits that would impact effective tax rate',\n",
        " 267: 'total intrinsic value of options exercised in the period for share-based compensation arrangement',\n",
        " 268: 'effective income tax rate (continuing operations)',\n",
        " 269: 'revenue from contracts with customers (excluding assessed tax)',\n",
        " 270: 'stock repurchase program: remaining authorized repurchase amount',\n",
        " 271: 'interest rate for line of credit facility at the end of the reporting period',\n",
        " 272: 'exercise price of warrant or other exercised right',\n",
        " 273: 'operating leases rent expense (net)',\n",
        " 274: 'lease and rental expense',\n",
        " 275: 'requested rate increase (or decrease) amount (public utilities)',\n",
        " 276: 'minority interest ownership percentage by parent',\n",
        " 277: 'asset impairment charges',\n",
        " 278: 'notional amount of derivative'}\n",
        "\n",
        "\n",
        " TEMPLATES_SQUAD = [\n",
        "    'Q: {QUESTION}\\nCONTEXT: {PASSAGE}\\nA: {ANSWER}',\n",
        "    'Human: {QUESTION}\\nCONTEXT:{PASSAGE}\\nAssistant: {ANSWER}',\n",
        "    'Given the following passage \"{PASSAGE}\", {QUESTION}.\\nANSWER: {ANSWER}',\n",
        "    \"{QUESTION} Answer based on the following text: '{PASSAGE}'.\\nAnswer: {ANSWER}\",\n",
        "    'I have a question: {QUESTION}.\\nThe answer is in this excerpt: \"{PASSAGE}\". Please answer my question.\\n\\nAssistant: Certainly! The answer is \"{ANSWER}\"',\n",
        "    'Human: Given this paragraph \"{PASSAGE}\", {QUESTION}.\\n\\nExpert: According the preceding paragraph, the answer to the question \"{QUESTION}\" is \"{ANSWER}\"',\n",
        "    \"Question: {QUESTION}\\n\\nContext: {PASSAGE}\\n\\n Answer: {ANSWER}\",\n",
        "    \"User: I have a question about this passage: {PASSAGE}\\n\\nAssistant: Yes, please ask me your question?\\n\\nUser: {QUESTION}\\n\\nAssistant: The answer is {ANSWER}\",\n",
        "] + [\n",
        "    \"Context: '{PASSAGE}. Based on the preceding context, {QUESTION}\\n\\n. Assistant: the answer is {ANSWER}\",\n",
        "    'Human: {QUESTION}\\nCONTEXT:{PASSAGE}\\nAssistant: {ANSWER}',\n",
        "    'Given the following passage \"{PASSAGE}\", {QUESTION}.\\nANSWER: {ANSWER}',\n",
        "    \"{QUESTION} Please answer based on the following text: '{PASSAGE}'.\\nAnswer: {ANSWER}\",\n",
        "    'I have a question: {QUESTION}.\\nThe answer is in this excerpt: \"{PASSAGE}\".\\nPlease answer my question.\\n\\nAssistant: Certainly! The answer is \"{ANSWER}\"',\n",
        "    'Human: Given this paragraph \"{PASSAGE}\", {QUESTION}.\\n\\nExpert: According the preceding paragraph, the correct answer is \"{ANSWER}\"',\n",
        "    \"Question: {QUESTION}\\n\\nContext: {PASSAGE}\\n\\n Answer: {ANSWER}\",\n",
        "    \"USER: Here is a passage to do with '{ANSWER}': {PASSAGE}.\\nWhat is an appropriate exam question based on this passage?\\n\\nRESPONDENT: Here is an example question based on your passage: '{PASSAGE}'\",\n",
        "    \"User: I have a question about this passage: {PASSAGE}\\n\\nAssistant: Yes, what is your question?\\n\\nUser: {QUESTION}\\n\\nAssistant: The answer is {ANSWER}\",\n",
        "    \"Human: I have a question about this paragraph: {PASSAGE}\\n\\nAssistant: What is the question?\\n\\nHuman: {QUESTION} Can you answer?\\n\\nAssistant: Certainly, the correct answer is '{ANSWER}'\",\n",
        "    \"User: Can you provide context for this question '{QUESTION}'\\n\\nAssistant: Certainly, here is the context: '{PASSAGE}'\\n\\nUser: What is the answer to the question?\\n\\nAnswer: '{ANSWER}'\",\n",
        "    \"I need information about {QUESTION}.\\nContext: {PASSAGE}\\nAnswer: {ANSWER}\",\n",
        "    \"I'd like to know '{QUESTION}' based on the information in this paragraph: '{PASSAGE}', what is the answer?\\nAnswer: {ANSWER}\",\n",
        "    \"What is the answer to the question: {QUESTION}\\nHere is the paragraph necessary to answer: '{PASSAGE}'\\nAnswer: {ANSWER}\",\n",
        "    \"Please provide context for this question: {QUESTION}\\nAssistant: Certainly, here is the context: '{PASSAGE}'\\nWhat is the answer to the question?\\nAnswer: {ANSWER}\",\n",
        "    'User: I would like to know \"{QUESTION}\". I have this information to address the question: \"{PASSAGE}\". \\nBased on that text,  what is the answer?\\n\\nAssistant\\'s Answer: \"{ANSWER}\"',\n",
        "    \"What is the answer to the question: {QUESTION}?\\nHere is some context: '{PASSAGE}'\\nAnswer: {ANSWER}\",\n",
        "    'Question: {QUESTION}\\n\\nCONTEXT: {PASSAGE}\\n\\nAnswer: {ANSWER}',\n",
        "    \"What is the answer to the question: {QUESTION}?\\nHere is the information required to answer: '{PASSAGE}'\\nAnswer: {ANSWER}\",\n",
        "    \"Human: Please answer the following question based on the information in the 'Context'.\\nQuestion: {QUESTION}\\nContext:{PASSAGE}\\n\\nAI: Okay, I believe the answer is '{ANSWER}'\",\n",
        "    \"Human: Please answer the following question based on the information below.\\nQuestion: {QUESTION}\\nContext:{PASSAGE}\\n\\nAI: Okay, I believe the correct answer to the question '{QUESTION}' is '{ANSWER}'\",\n",
        "    \"I'm trying to understand '{QUESTION}', given the information in this text: '{PASSAGE}'\\n\\nRespondent: Okay, I can answer that. The answer is {ANSWER}\",\n",
        "    \"Please help me with {QUESTION}.\\nGiven this passage: '{PASSAGE}', what is the answer?\\nAnswer: {ANSWER}\",\n",
        "    \"I have a question: '{QUESTION}'.\\nBased on this context, what is the answer?\\nCONTEXT: '{PASSAGE}'\\n\\nAnswer: {ANSWER}\",\n",
        "    \"User: What is the answer to the following question '{QUESTION}'\\n\\nPlease use this additional context to answer the question: '{PASSAGE}'\\n\\nAssistant: {ANSWER}\",\n",
        "    'Q: {QUESTION}\\nCONTEXT: {PASSAGE}\\nA: {ANSWER}',\n",
        "]\n",
        "\n",
        "def random_by_char(text, take=3, charlim=10):\n",
        "    nums = [ord(ch) for ch in 'xqz'+text.replace(' ','')[:charlim]][(-1*take):]\n",
        "    return 3*prod(nums[:2])-nums[-1]\n",
        "\n",
        "def clean_squad(x):\n",
        "    \"\"\"Converst squad triplet (q,context, a) into a pseudo-conversation using templates\"\"\"\n",
        "    passagetext = x['context']\n",
        "    template = TEMPLATES_SQUAD[random_by_char(passagetext) % len(TEMPLATES_SQUAD)]\n",
        "    text = template.replace(\n",
        "        \"{QUESTION}\", x['question']\n",
        "    ).replace(\n",
        "        \"{ANSWER}\", x['answers']['text'][0]\n",
        "    ).replace(\n",
        "        \"{PASSAGE}\", passagetext\n",
        "    )\n",
        "    return {'text':text}\n"
      ],
      "metadata": {
        "id": "6qzDWhlMRKc0"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "oz7n3lp6oH49"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_stream_refinedweb(x):\n",
        "    x['text'] = x['content']\n",
        "    return x\n",
        "\n",
        "def clean_stream_arxiv(x):\n",
        "    x['text'] = x['abstract']\n",
        "    return x\n",
        "\n",
        "def clean_stream_pubmedsum(x):\n",
        "    x['text'] = x['article']\n",
        "    return x\n",
        "\n",
        "def remove_first_http_url(text):\n",
        "    \"\"\"Removes http strings from hackersnews\"\"\"\n",
        "    pattern = r'http[s]*://[^ ]+'\n",
        "    return re.sub(pattern, '', text, 1)\n",
        "\n",
        "#def parse_hacker_news(text):\n",
        "#    \"\"\"removes hackernews' thread separators ----- ===== ~~~ and removes urls\"\"\"\n",
        "#    return remove_first_http_url(\" \".join([\" \".join(j.split('\\n')[1:]) for j in text.replace(\"------\\n\",\"~~~\\n\").replace(\"======\\n\",\"~~~\\n\").split(\"~~~\\n\")]))\n",
        "#def clean_hackernews(x):\n",
        "#    x['text'] = parse_hacker_news(x['text'])\n",
        "#    return x\n",
        "\n",
        "def clean_ledgarmlm(x):\n",
        "    x['text'] = x['provision']\n",
        "    return x\n",
        "\n",
        "def clean_casetextbook(example):\n",
        "    \"\"\"Removes tables and excess \\n includes somes specifics for Saylor books footmatter\"\"\"\n",
        "    # discards the first 8 percent\n",
        "    #discard = int(0.08*len(example['text']))\n",
        "    #example['text'] = example['text'][discard:].replace('\\n',\" \")\n",
        "    example = clean_irs_advice_mlm(example)\n",
        "    # discard the first 8 lines ~ they are usually boilerplate text\n",
        "    example['text'] = '\\n'.join(example['text'].split('\\n')[8:])\n",
        "    example['text'] = example['text'].replace(\"Saylor URL: http://www.saylor.org/books\",\" \").replace(\"Saylor.org\", \" \").replace('Saylor Books', \" \")\n",
        "    return example\n",
        "\n",
        "def clean_edgarcorpus(example):\n",
        "    example['text'] = example['section_1'] + \"\\n\" + example['section_2'] + \"\\n\" + example['section_3'] + \"\\n\" + example['section_7']\n",
        "    return example\n",
        "\n",
        "def clean_elseiver_mlm(example):\n",
        "    example['text'] = example['Clean_Title'] + \" - \" + example['Clean_Summary'] + \"\\n\" + example['Clean_Text']\n",
        "    return example\n",
        "\n",
        "def clean_financial_news_mlm(example):\n",
        "    example['text'] = example['title'] + \"\\n\" + example['text']\n",
        "    return example\n",
        "\n",
        "def filter_pileall_mlm(x):\n",
        "    return x['meta']['pile_set_name'] in ['NIH ExPorter','OpenWebText2','PubMed Abstracts','StackExchange','Wikipedia (en)','ArXiv']\n",
        "\n",
        "def filter_europarl_mlm(x):\n",
        "    return len(x['text'])>60*7 # at least a small paragraphs\n",
        "\n",
        "def clean_courtlistener(x):\n",
        "    text = x['text']\n",
        "    # remove the tables just makes things worse\n",
        "    #text = \"\\n\".join([s for s in text.split('\\n') if not is_potential_table(s)])\n",
        "    text = text.replace(\".\\n\",'XxXx').replace(\":\\n\",'YyYy').replace(\"-\\n\",'').replace(\"\\n\",\" \").replace('XxXx','.\\n').replace('YyYy',':\\n')\n",
        "    return {'text':text}\n",
        "\n",
        "def clean_irs_advice_mlm(x):\n",
        "    text = x['text']\n",
        "    pattern = r'\\x0C'\n",
        "    text = re.sub(pattern, \"\", text) # ^L characters\n",
        "    text = re.sub(r'^[\\d,.%$+\\-\\s\\=]+\\n?$',\"\",text,flags=re.MULTILINE | re.DOTALL)\n",
        "    text = re.sub(r'\\-{10,}',\"\",text)\n",
        "    text = re.sub(r'^(.*)?[Pp]age\\s\\d+\\n?$',\"\",text,flags=re.MULTILINE)\n",
        "    #x['text'] = text.replace(\"\\n\",\" \").strip()\n",
        "    text = text.replace(\".\\n\",'XxXx').replace(\":\\n\",'YyYy').replace(\"-\\n\",'').replace(\"\\n\",\" \").replace('XxXx','.\\n').replace('YyYy',':\\n')\n",
        "    # find tables and remove\n",
        "    text = \"\\n\".join([s for s in text.split('\\n') if not is_potential_table(s)])\n",
        "    return {'text':text}\n",
        "\n",
        "def clean_secproceedings_mlm(x):\n",
        "    text = x['text']\n",
        "    if 'I.\\n' in text:\n",
        "        text = \"\".join(re.split(r\"^I.\\n\", text, flags=re.MULTILINE)[1:])\n",
        "    else:\n",
        "        text = '\\n'.join(text.split('\\n')[10:])\n",
        "    # I don't remember what this removes\n",
        "    pattern = r'\\x0C'\n",
        "    s = re.sub(pattern, \"\", text) # ^L characters\n",
        "    # removes a number ( or (12)) that is just a line with no text\n",
        "    text = re.sub(r'^(\\()*\\d+[\\.\\)]?\\n?$', '', text,flags=re.MULTILINE)\n",
        "    # remove sentence-breaks\n",
        "    s = s.replace(\".\\n\",'XxXx').replace(\":\\n\",'YyYy').replace(\"-\\n\",'').replace(\"\\n\",\" \").replace('XxXx','.\\n').replace('YyYy',':\\n')\n",
        "    s = s.replace('¶',' ')\n",
        "    x['text'] = s\n",
        "    return x\n",
        "\n",
        "def filter_notcodelike(x):\n",
        "    \"\"\"checks if text has a lot of non-alphanumeric characters that indicates it is probably computer code / math notation\"\"\"\n",
        "    ratio_specialchar = check_is_code(x['text'])\n",
        "    return ratio_specialchar<0.1\n",
        "\n",
        "def clean_hackernews(x):\n",
        "    x['text']= x['Title'] + ' ' + remove_first_http_url(x['Text'])\n",
        "    return x\n",
        "\n",
        "def filter_hackernews(x):\n",
        "    return (len(x['Text']) > 60) and (check_is_code(x['Text'])<0.1)\n",
        "\n",
        "#def filter_bigpatent(x):\n",
        "#    return 'SUMMARY' in x['description'] and 'BACKGROUND' in x['description']\n",
        "\n",
        "def clean_bigpatent(x):\n",
        "    start_offset=0; end_offset=1\n",
        "    if 'BACKGROUND OF THE INVENTION' in x['description']:\n",
        "        start_offset = x['description'].index('BACKGROUND OF THE INVENTION')+27\n",
        "    elif 'BACKGROUND OF INVENTION' in x['description']:\n",
        "        start_offset = x['description'].index('BACKGROUND OF INVENTION')+23\n",
        "    elif 'BACKGROUND' in x['description']:\n",
        "        start_offset = x['description'].index('BACKGROUND')+10\n",
        "    if 'SUMMARY OF THE INVENTION' in x['description']:\n",
        "        end_offset = x['description'].index('SUMMARY OF THE INVENTION')\n",
        "    elif 'SUMMARY OF INVENTION' in x['description']:\n",
        "        end_offset = x['description'].index('SUMMARY OF INVENTION')\n",
        "    elif 'SUMMARY' in x['description']:\n",
        "        end_offset = x['description'].index('SUMMARY')\n",
        "    if end_offset < (start_offset+20):\n",
        "        return {\n",
        "            'text': '\\n'.join(x['description'].split('\\n')[:4]) + x['abstract']\n",
        "        }\n",
        "    background_text = x['description'][start_offset:end_offset]\n",
        "    # remove all [xxxx] number breaks\n",
        "    background_text = re.sub(\"\\[[0-9]+\\]\\s*\",\"\", background_text)\n",
        "    return {\n",
        "        'text': (background_text.strip() + \"\\n\"+ x['abstract'])\n",
        "    }\n",
        "\n",
        "def clean_govreport(x):\n",
        "    x['text'] = x['document']\n",
        "    return x\n",
        "\n",
        "def filter_debatesum(x):\n",
        "    \"\"\"fiters out extremist/hateful content from the debatesum dataset (auto-labelled, poor precision)\"\"\"\n",
        "    if len(str(x['Full-Document']).split(' '))<400:\n",
        "        return False\n",
        "    if x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT1:\n",
        "        return False\n",
        "    if x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT2:\n",
        "        return False\n",
        "    if x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT3:\n",
        "        return False\n",
        "    if x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT4:\n",
        "        return False\n",
        "    if x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT5:\n",
        "        return False\n",
        "    if x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT6:\n",
        "        return False\n",
        "    if x['OriginalDebateFileName'] in DEBATESUM_EXTREMIST_FILTER_OUT7:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def clean_debatesum(x):\n",
        "    x['text'] = re.sub(r'\\s+',\" \",str(x['Full-Document']))\n",
        "    return x\n",
        "\n",
        "## world bank processing functions\n",
        "def is_potential_table(line):\n",
        "    \"\"\"Checks if a text is a table\"\"\"\n",
        "    num_and_special_count = sum([len(w) for w in re.findall(r'[0-9.,=\\(\\)$€£*\\%\\-\\/\\:]+', line)])\n",
        "    total_chars = len(line)\n",
        "    if total_chars==0:\n",
        "        return True\n",
        "    num_and_special_ratio = num_and_special_count / total_chars\n",
        "    if num_and_special_ratio > 0.25:\n",
        "        return True\n",
        "    words = line.split()\n",
        "    upper_title_words = [word for word in words if word.isupper() or word.istitle()]\n",
        "    ratio = len(upper_title_words) / len(words) if len(words) > 0 else 0\n",
        "    if ratio > 0.5:\n",
        "        return True\n",
        "    # Heuristic 3: Check if the line starts with a number (common in tables)\n",
        "    if re.search(\"^[0-9]\", line) and re.search(\"[0-9]$\", line):\n",
        "        return True\n",
        "    nchar = len(re.sub(r\"\\s+\",\"\",line))\n",
        "    nspace = len(re.sub(r\"\\w+\",\"\",line))\n",
        "    if nspace !=0 and nchar/nspace <3.2:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def clean_worldbank(x):\n",
        "    # remove weird characters\n",
        "    pattern = r'\\x0C'\n",
        "    s = re.sub(pattern, \"\", x['document_text']) # ^L characters\n",
        "    s = re.sub(r'\\\\\\.', \".\", s) # \\. artifacts\n",
        "    # remove excess/inccorect \\n breaks\n",
        "    s = s.replace(\".\\n\",'XxXx').replace(\":\\n\",'YyYy').replace(\"-\\n\",'').replace(\"\\n\",\" \").replace('XxXx','.\\n').replace('YyYy',':\\n')\n",
        "    s = s.replace('¶',' ')\n",
        "    # discard text that is clearly tabular\n",
        "    s_cleaned = \"\\n\".join([\n",
        "        p for p in s.split('\\n') if not is_potential_table(p)\n",
        "    ])\n",
        "    return {'text':s_cleaned}\n",
        "\n",
        "LIST_OF_HOSTGUEST_PAIRS = [\n",
        "    (\"Interviewer\", \"Interviewee\"),\n",
        "    (\"Host\", \"Guest\"),(\"Talk Show Host\", \"Guest Speaker\"),(\"Person 1\", \"Person 2\"),\n",
        "    (\"Podcast Host\", \"Guest Speaker\"),\n",
        "    (\"Moderator\", \"Panelist\"),\n",
        "    (\"Questioner\", \"Responder\"),\n",
        "    (\"Facilitator\", \"Participant\"),\n",
        "    (\"Host\", \"Expert\"),\n",
        "    (\"Quizmaster\", \"Contestant\"),\n",
        "    (\"Speaker\", \"Contributor\"),\n",
        "    (\"Interviewer\", \"Discussant\"),\n",
        "    (\"Agent\", \"Subject\"),\n",
        "    (\"Facilitator\", \"Delegate\"),\n",
        "    (\"Show Host\", \"Commentator\"),\n",
        "    (\"Questioner\", \"Commentator\"),\n",
        "    (\"Speaker\", \"Respondent\"),\n",
        "    (\"Moderator\", \"Guest Speaker\"),\n",
        "    (\"Examiner\", \"Candidate\"),\n",
        "    (\"Instructor\", \"Student\"),\n",
        "    (\"Host\", \"Expert\"),\n",
        "    (\"Interviewer\", \"Respondent\"),\n",
        "    (\"MC\", \"Panelist\"),(\"Speaker1\", \"Speaker2\"),\n",
        "]\n",
        "\n",
        "def clean_lexfridmanchat(x):\n",
        "    convo = x['conversations']\n",
        "    nm1,nm2 = LIST_OF_HOSTGUEST_PAIRS[ord(convo[0]['value'].replace(' ',\"\")[:20][-1]) % len(LIST_OF_HOSTGUEST_PAIRS)]\n",
        "    map_to_names = {'human':nm1, 'gpt':nm2}\n",
        "    text = '\\n'.join([\n",
        "        '%s: \"%s\"' % (map_to_names[talkfrag['from']], talkfrag['value']) for talkfrag in convo\n",
        "    ])\n",
        "    return {'text':text}\n",
        "\n",
        "def clean_essayforum(x):\n",
        "    return {'text':x['Correct Grammar']}\n",
        "\n",
        "TEXTSEPARATOR = \"%0XTEXTXEPARAT0RX%0\"\n",
        "\n",
        "# variants of Question, Context, Answer for ask historians\n",
        "TEMPLATES_ASKHISTORIANS = {\n",
        "    'no_context':[\n",
        "        \"Q:{QUESTION}|||A:{ANSWER}\",\n",
        "        \"Q:{QUESTION}\\nA:{ANSWER}\",\n",
        "        \"{QUESTION}\\n\\n{ANSWER}\",\n",
        "        \"QUESTION:{QUESTION}\\nANSWER:{ANSWER}\",\n",
        "        \"QUESTION:{QUESTION}|||ANSWER:{ANSWER}\",\n",
        "        \"Human:{QUESTION}\\n\\nAssistant:{ANSWER}\",\n",
        "        \"User:{QUESTION}\\n\\nRespondent:{ANSWER}\",\n",
        "        \"Speaker-1:{QUESTION}\\n\\nSpeaker-2:{ANSWER}\",\n",
        "        \"Speaker-A:{QUESTION}\\n\\nSpeaker-B:{ANSWER}\",\n",
        "    ],\n",
        "    \"context\":[\n",
        "        \"Q:{QUESTION} {SELFTEXT}\\nA:{ANSWER}\",\n",
        "        \"Q:{SELFTEXT} {QUESTION}\\n\\nA:{ANSWER}\",\n",
        "        \"QUESTION:{QUESTION}\\n{SELFTEXT}\\nANSWER:{ANSWER}\",\n",
        "        \"Background:{SELFTEXT}\\nQuestion:{QUESTION}\\n\\nANSWER:{ANSWER}\",\n",
        "        \"Intro:{SELFTEXT}\\nQuestion:{QUESTION}\\n\\nANSWER:{ANSWER}\",\n",
        "        \"USER:{SELFTEXT} Question:{QUESTION}\\n\\nRespondent:{ANSWER}\",\n",
        "        \"Human:{SELFTEXT} {QUESTION}\\n\\nAssistant:{ANSWER}\",\n",
        "        \"Speaker A:{SELFTEXT} {QUESTION}\\n\\Speaker B:{ANSWER}\",\n",
        "        \"Human:I have a question: {QUESTION}\\nAssistant: Can you elaborate a little more?\\nHuman:{SELFTEXT}\\nAssistant:{ANSWER}\"\n",
        "        \"Human:{QUESTION}\\nAssistant: Can you rephrase the question, but with more detail?\\nHuman:{SELFTEXT}\\nAssistant:{ANSWER}\"\n",
        "        \"Human:{QUESTION} {SELFTEXT}\\n\\nAssistant:{ANSWER}\",\n",
        "        \"User:{QUESTION}  {SELFTEXT}\\n\\nRespondent:{ANSWER}\",\n",
        "        \"Speaker-1:{SELFTEXT} {QUESTION}\\n\\nSpeaker-2:{ANSWER}\",\n",
        "        \"User:{QUESTION} {SELFTEXT}\\n\\nBot:{ANSWER}\",\n",
        "        \"User:{QUESTION} {SELFTEXT}\\n\\nBot:{ANSWER}\",\n",
        "\n",
        "    ],}\n",
        "\n",
        "\n",
        "def filter_askhistorians(x):\n",
        "    if len(x['answers']['text'])==0:\n",
        "        return False\n",
        "    if len(x['title'])<10:\n",
        "        return False\n",
        "    if '?' not in x['title']:\n",
        "        return False\n",
        "    return x\n",
        "\n",
        "def make_text_for_askhistorians(question, answers, selftext):\n",
        "    \"\"\"splits answers into multiple separable texts\n",
        "    [print(k+'\\n-----\\n') for k in make_text_for_askhistorians(\"Hello?\", [\"a1\",'a2','a3'], \"this is ome text\").split('%0XTEXTXEPARAT0RX%0')]\n",
        "    \"\"\"\n",
        "    if len(answers)>1:\n",
        "        out_texts_listed = []\n",
        "        for answer in answers:\n",
        "            out_texts_listed.append(make_text_for_askhistorians(\n",
        "                question, [answer], selftext\n",
        "            ))\n",
        "        return TEXTSEPARATOR.join(out_texts_listed)\n",
        "\n",
        "    # no self text\n",
        "    if len(selftext)<2:\n",
        "        # find a template\n",
        "        template = TEMPLATES_ASKHISTORIANS['no_context'][\n",
        "                random_by_char(answers[0]) % len(TEMPLATES_ASKHISTORIANS['no_context'])\n",
        "        ]\n",
        "        out_text = template.replace(\"{QUESTION}\",question).replace(\"{ANSWER}\",answers[0])\n",
        "        return out_text\n",
        "    # yes self-text\n",
        "    out_texts_listed = [make_text_for_askhistorians(question, answers, \"\")]\n",
        "    # find a template\n",
        "    template = TEMPLATES_ASKHISTORIANS['context'][\n",
        "        random_by_char(answers[0]) % len(TEMPLATES_ASKHISTORIANS['context'])\n",
        "    ]\n",
        "    out_texts_listed += [template.replace(\"{QUESTION}\",question).replace(\"{ANSWER}\",answers[0]).replace(\"{SELFTEXT}\", selftext)]\n",
        "    return TEXTSEPARATOR.join(out_texts_listed)\n",
        "\n",
        "\n",
        "def clean_askhistorians(x):\n",
        "    out_text=  make_text_for_askhistorians(\n",
        "        x['title'], x['answers']['text'], x['selftext']\n",
        "    )\n",
        "    return {'text':out_text}\n",
        "\n",
        "PAIRS_OF_USERASSISTANT_NAMES = [(\"Human\",\"Assistant\")]*3 + [(\"User\",\"Assistant\")]*3+[\n",
        "        (\"Human\",\"Respondent\"), (\"User\",\"Respondent\"), (\"Person 1\",\"Person 2\"), (\"Speaker 1\",\"Speaker 2\"), (\"User\",\"Helper\"),(\"Client\",\"Agent\"), (\"Human\",\"Agent\")\n",
        "]\n",
        "\n",
        "def clean_isotonicconversations(x):\n",
        "    \"\"\"Randomizes the names of speakers and question-askers, as well as removes other non-natural language text\"\"\"\n",
        "    text = x['text']\n",
        "    if len(list(re.findall(\"####Human####:\",text)) + list(re.findall(r\"\\n+human\\:\",text))) == 1:\n",
        "         names_of_agents = [('Question', \"Answer\")]*2 + [(\"Q\",'A')] + [('Question', \"Response\")]\n",
        "    else:\n",
        "        names_of_agents = PAIRS_OF_USERASSISTANT_NAMES\n",
        "    name_human, name_bot = names_of_agents[random_by_char(text,charlim=20) % len(names_of_agents)]\n",
        "    # easy replace: expect template of ####human###\n",
        "    text = text.replace(\"####Human####\",name_human).replace(\"####Assistant####\",name_bot)\n",
        "    # more difficult for weird follow-up questions\n",
        "    if 'human:' in text.lower() or 'humans:' in text.lower():\n",
        "        text = re.sub('\\n+Huma(n|ns)\\:',\"\\n\\n\"+name_human+\":\", text, flags=re.MULTILINE)\n",
        "    if 'assistant:' in text.lower():\n",
        "        text = re.sub('\\n+Assistant\\:',\"\\n\\n\"+name_bot+\":\", text, flags=re.MULTILINE)\n",
        "    text = text.replace('<|stop|>',\"\").replace('\\nOutput:',\"\")\n",
        "    # remove lines that are just a single number\n",
        "    #text = re.sub(\"\\:\\n(?=\\d)\",\"^XxXx^\",text,flag).\n",
        "    return {'text':text}\n",
        "\n",
        "def clean_legalcontractslong(x):\n",
        "    # remove pagination like 5 -----\n",
        "    text = re.sub(r\"\\s*\\d+\\s*\\-+\",\"\",x['text'])\n",
        "    # remove extended -------\n",
        "    text = re.sub(r\"\\s*\\-{4,}\\s*\",\"\",text)\n",
        "    # remove extended ——————————————\n",
        "    text = re.sub(r\"\\s*\\—{4,}\\s*\",\"\",text)\n",
        "    # remove extended __\n",
        "    text = re.sub(r\"\\s*\\_{3,}\\s*\",\"___\",text)\n",
        "    # remove multiple line breaks\n",
        "    text = re.sub(r\"\\n+\",\"\\n\",text,flags=re.MULTILINE)\n",
        "    # calculate the word count per line\n",
        "    lines = [l.strip() for l in text.split('\\n') if len(l.strip())>0]\n",
        "    if len(lines)<5:\n",
        "        return {'text':text}\n",
        "    # calculate word count\n",
        "    wc = [len([w for w in l.strip().split(' ') if len(w)>0]) for l in lines]\n",
        "    # calculate densities\n",
        "    density = [wc[0]] + [\n",
        "        sum(l)/3 for l in zip(wc[:-2], wc[1:-1], wc[2:])\n",
        "    ] + [wc[-1]]\n",
        "    # threshold\n",
        "    threshold_on_density = 3.01\n",
        "    # remove sections likely to be pagination/signatures and other table-like-stuff\n",
        "    filtered_text = \"\\n\".join([\n",
        "        l for d,l in zip(density[:-2], lines) if d>=threshold_on_density\n",
        "    ])\n",
        "    # attach sentences that are incorrectly split into paragras\n",
        "    filtered_text = filtered_text.replace(\n",
        "        \".\\n\",'XxXx'\n",
        "    ).replace(\":\\n\",'YyYy').replace(\";\\n\",'ZzZz').replace(\"-\\n\",'').replace(\"\\n\",\" \").replace(\n",
        "        'XxXx','.\\n'\n",
        "    ).replace('YyYy',':\\n').replace('ZzZz',';\\n')\n",
        "    #\n",
        "    #faketext = \"\\n\".join([\n",
        "    #    \"d:%0.3f:::%s\" % (d,s) for d,s in zip(density, lines)\n",
        "    #])\n",
        "    return {'text':filtered_text}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print('NEED TO VERIFY IF PILE DEDUP CAN BE STREAMED: YES')\n",
        "print('ADD \"santoshtyss/us-court-cases\" to have case-law\"')\n",
        "print('remove more debates from the filter')\n",
        "\n",
        "print('Consider filtering big_patent for just the backgrounds')\n",
        "\n",
        "\n",
        "mlm_streaming_cleaning_functions = {\n",
        "    #'EleutherAI/pile/all':(lambda x: x, filter_pileall_mlm, ['meta']), # GONE\n",
        "    'EleutherAI/the_pile_deduplicated':(lambda x: x, filter_notcodelike, []),\n",
        "    # monology/pile-uncopyrighted -> this seems like the original pile that I was using, with book3 removed\n",
        "    \"tiiuae/falcon-refinedweb\":(clean_stream_refinedweb, None, ['url', 'timestamp', 'dump', 'segment', 'image_urls','content']),\n",
        "    'Skylion007/openwebtext':(lambda x : x, None, []),\n",
        "    \"Cohere/wikipedia-22-12\":(lambda x : x, None, ['id', 'title', 'url', 'wiki_id', 'views', 'paragraph_id', 'langs']),\n",
        "    \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\":(lambda x: x, None, ['meta']),\n",
        "    \"nRuaif/book2-lite-cleaned\":(lambda x: {'text':x['text'][1000:]}, None, []),\n",
        "    \"macrocosm/arxiv_abstracts\":(clean_stream_arxiv, None, ['embeddings', 'doi','abstract']),\n",
        "    \"ccdv/pubmed-summarization\":(clean_stream_pubmedsum, None, ['abstract','article']),\n",
        "    #\"conceptofmind/pile_uspto_backgrounds\":(lambda x : x ,None, ['meta']),\n",
        "    'big_patent':(clean_bigpatent, None, ['description', 'abstract']),\n",
        "    \"pile-of-law/pile-of-law/euro_parl\":(lambda x : x, filter_europarl_mlm, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    #\"philArchive\": fails, but available as subset in eloukas/edgar-corpus as domain=='PhilPapers'\n",
        "    'kerinin/hackernews-stories':(clean_hackernews, filter_hackernews, ['Title','Text','labels']),\n",
        "    \"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\":(lambda x:x, None,['meta']),\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\":(clean_ledgarmlm,None,['provision','source']),\n",
        "    \"pile-of-law/pile-of-law/r_legaladvice\":(lambda x : x, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/exam_outlines\":(lambda x : x, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/cc_casebooks\":(clean_casetextbook, None, ['created_timestamp', 'downloaded_timestamp', 'url']), # clean_casetextbook\n",
        "    \"eloukas/edgar-corpus\":(\n",
        "        clean_edgarcorpus, None, [\n",
        "            'filename', 'cik', 'year', 'section_1A', 'section_1B', 'section_4', 'section_1', 'section_2', 'section_3', 'section_7',\n",
        "            'section_5', 'section_6', 'section_8', 'section_9', 'section_10', 'section_7A', 'section_9A', 'section_9B',\n",
        "            'section_11', 'section_12', 'section_13', 'section_14', 'section_15'\n",
        "        ]),\n",
        "    \"Rahmaa/ElsevieR_ClEaN\":(clean_elseiver_mlm, None, ['Unnamed: 0', 'Clean_Title', 'Clean_Text', 'Clean_Summary']),\n",
        "    'ashraq/financial-news-articles':(clean_financial_news_mlm, None, ['title','url']),\n",
        "    'pile-of-law/pile-of-law/courtlistener_opinions':(clean_courtlistener, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/sec_administrative_proceedings\":(clean_secproceedings_mlm, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/irs_legal_advice_memos\":(clean_irs_advice_mlm, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    'launch/gov_report':(clean_govreport, None, ['id','document','summary']),\n",
        "    'izumi-lab/open-text-books':(lambda x: x, None, []),\n",
        "    'gigant/ted_descriptions':(lambda x: {'text':x['descr']}, None, []),\n",
        "    'Skelebor/book_titles_and_descriptions':(lambda x : {'text': x['description']},lambda x : len(str(x['description']))>80, []),\n",
        "    'joelito/legal_case_document_summarization':(lambda x: {'text':x['summary']}, None, []),\n",
        "    'joelito/legal-mc4/en':(lambda x:x, None, ['url','timestamp','matches']),\n",
        "    'Hellisotherpeople/DebateSum':(clean_debatesum, filter_debatesum,[\n",
        "        '#CharsAbstract', '#CharsDocument', '#CharsExtract', '#WordsAbstract', '#WordsDocument', '#WordsExtract', 'AbsCompressionRatio', 'Abstract', 'Citation',\n",
        "        'DebateCamp', 'ExtCompressionRatio', 'Extract', 'Tag', 'Unnamed: 0', 'Year', 'Full-Document','OriginalDebateFileName'\n",
        "    ]),\n",
        "    'lukesjordan/worldbank-project-documents':(clean_worldbank, None, ['project_id','document_text','document_type']),\n",
        "    '64bits/lex_fridman_podcast_for_llm_vicuna':(clean_lexfridmanchat, None, ['conversations','id']),\n",
        "    'nid989/EssayFroum-Dataset':(clean_essayforum, None, ['Cleaned Essay','Correct Grammar']),\n",
        "    \"nlpaueb/finer-139\":(clean_finer139_for_mlm, filter_finer139, ['ner_tags','tokens','id']),\n",
        "    'squad':(clean_squad, None, ['context','question','answers','title','id']),\n",
        "    'Pavithree/askHistorians':(clean_askhistorians, filter_askhistorians, ['q_id','title','selftext','document','subreddit','url','answers']),\n",
        "    \"Isotonic/human_assistant_conversation\":(clean_isotonicconversations, None, [\"prompt\",\"response\"]),\n",
        "    \"albertvillanova/legal_contracts\":(clean_legalcontractslong, None,[]),\n",
        "}\n",
        "\n",
        "# entries: url, subset, probability, size, option(name of postprocess subsetting), shuffle?\n",
        "mlm_files = [\n",
        "    ('EleutherAI/the_pile_deduplicated', None, 16.21, 134000000, 'mlm', (1650, 81405), 0.1), # 1650 files each with ~?\n",
        "    # monology/pile-uncopyrighted -> this seems like the original pile that I was using, with book3 removed\n",
        "    (\"tiiuae/falcon-refinedweb\", None, 17.11, 968000000, \"mlm\", (5534, 174000), 0.1), # CC; has 5534 files as parquet (each with ~174919)\n",
        "    ('Skylion007/openwebtext', None, 5.0, 4000000, 'mlm', (21, 213000), 0.1),\n",
        "    (\"Cohere/wikipedia-22-12\", 'en', 35.0, 8590000, \"mlm\",(351, 100000), 0.16), # wikipedia has 351 files (each with 100000 examples)\n",
        "    (\"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\", None, 4.8/2, 34500, \"mlm\", (15, 9900), 0.15), # has 15 files (each with with ~9978/9983)\n",
        "    (\"nRuaif/book2-lite-cleaned\", None, 4.8/2, 81500, \"mlm\", (818, 100), 0.1),\n",
        "    (\"macrocosm/arxiv_abstracts\", None, 3.6, 2250000, \"mlm\", (23, 2250000//23), 0.12), # set to zero because in PILE (has 23 parquet files)\n",
        "    (\"ccdv/pubmed-summarization\", None, 0, 120000, \"mlm\", False, 0.12), # 3.75 set to zero because elsiever and pubmed in Pile below\n",
        "    ('big_patent', 'all', 0.60, 154000, 'mlm', False, 0.15), # use as an alternative to /NIH_ExPORTER_awarded_grant_text.jsonl.zst\n",
        "    (\"pile-of-law/pile-of-law\",'euro_parl', 0.55, 7254, \"mlm\", False, 0.1),\n",
        "    # I think I should remove the hackernews because it was originally included as a discussion-tree in pile\n",
        "    ('kerinin/hackernews-stories', None, 0, 31300, 'mlm', (8, 52220), 0.1), # 1.7 hackernews stories alternative: this was originally included because of discussion\n",
        "    (\"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\", None, 0, 985651, \"mlm\", False, 0.15), # still works, but may fail eventually\n",
        "    (\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", None, 6.25, 1200000, \"mlm\", False, 0.2),\n",
        "    (\"pile-of-law/pile-of-law\",'r_legaladvice', 1.63, 109740, \"mlm\", False, 0.15),\n",
        "    (\"pile-of-law/pile-of-law\",'exam_outlines', 0.1, 12, \"mlm\",False, 0.2), # useless (but interesting)\n",
        "    (\"pile-of-law/pile-of-law\",'cc_casebooks',0.5, 59 ,\"mlm\",False, 0.2),\n",
        "    (\"eloukas/edgar-corpus\", \"full\", 2.15, 47000, \"mlm\",(28, 4000), 0.15), # has 28 files each with 1k-5k (variable amount of data: 1styear 1060 vs 5508 in 2018\n",
        "    (\"Rahmaa/ElsevieR_ClEaN\", None, 1.7, 31600, \"mlm\", False, 0.15),\n",
        "    ('ashraq/financial-news-articles', None, 1.0, 306000, \"mlm\", (2, 153100), 0.1), # has 2 files (each with 153121)\n",
        "    ('pile-of-law/pile-of-law','courtlistener_opinions',  1.25, 1000000 , \"mlm\", (16, 229000), 0.1), # has 16 files (each with 229678 to 526543)\n",
        "    ('pile-of-law/pile-of-law',\"sec_administrative_proceedings\", 0.9, 10805, \"mlm\", False, 0.1), # 118.4 MiB\n",
        "    ('pile-of-law/pile-of-law',\"irs_legal_advice_memos\", 0.76, 442, \"mlm\", False,0.18), # 35.8 MiB\n",
        "    ('launch/gov_report','plain_text',0.55, 17500, 'mlm', False, 0.1),\n",
        "    ('izumi-lab/open-text-books',None,  3.45, 150000, 'mlm', False, 0.15),\n",
        "    ('gigant/ted_descriptions',None, 0, 5705, 'mlm', False, 0.2), # too small and irrelevant\n",
        "    ('Skelebor/book_titles_and_descriptions', None, 2.24, 1000000,'mlm', (2, 1000000//2), 0.2),\n",
        "    ('joelito/legal_case_document_summarization',None, 2.2, 7700, 'mlm', False, 0.2),\n",
        "    ('joelito/legal-mc4','en', 1.1, 180000, 'mlm', False, 0.1),\n",
        "    ('Hellisotherpeople/DebateSum', None, 1.58, 24647, 'mlm',False, 0.9),\n",
        "    ('lukesjordan/worldbank-project-documents', None, 0.35, 15700, 'mlm', False, 0.08),\n",
        "    ('64bits/lex_fridman_podcast_for_llm_vicuna',None, 0.52, 17200,'mlm',False,0.5),\n",
        "    ('nid989/EssayFroum-Dataset',None, 0.71, 25600,'mlm',False,0.5),\n",
        "    ('nlpaueb/finer-139',None, 1.05, 179195, 'mlm',False, 0.8),\n",
        "    ('squad',None, 1.59, 87600, 'mlm', False, 0.2),\n",
        "    ('Pavithree/askHistorians',None, 0.59, 51300,'mlm',False, 0.8),\n",
        "    (\"Isotonic/human_assistant_conversation\",None,1.05, 58700, 'mlm',(3, 195590),0.09),\n",
        "    (\"albertvillanova/legal_contracts\", None, 1.0, 106000, 'mlm', False, 0.15),\n",
        "] #\n",
        "\n",
        "# entries: url, subset, probability, size, option(name of postprocess subsetting), shuffle?\n",
        "# looks like the Pile is finally gone\n",
        "# monology/pile says it will be available in december\n",
        "# the_pile_openwebtext2 -> substitute? (no)\n",
        "# could just use: EleutherAI/the_pile_deduplicated and then filter for english and exclude too much special characters\n",
        "\n",
        "print([k[2] for k in mlm_files])\n",
        "total_prob = sum([k[2] for k in mlm_files])\n",
        "for url, f in zip(mlm_files,mlm_streaming_cleaning_functions.keys()):\n",
        "    print(\"%0.3f\" % (url[2]/total_prob) + \"  \"+ url[0] + \" ||| \" + f + '\\n')\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':mlm_files,\n",
        "    'val_size':2000,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':6000,\n",
        "    'max_chunk_start':1000000,\n",
        "    \"seed\":42,\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWTUlLlfizu-",
        "outputId": "28613bd3-bc5e-4c26-c5f1-a39f95251e27"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADD \"santoshtyss/us-court-cases\" to have case-law\"\n",
            "remove more debates from the filter\n",
            "Consider filtering big_patent for just the backgrounds\n",
            "[16.21, 17.11, 5.0, 35.0, 2.4, 2.4, 3.6, 0, 0.6, 0.6, 0, 0, 6.25, 1.63, 0.1, 0.5, 2.15, 1.7, 1.0, 1.35, 0.9, 0.76, 0.55, 3.4, 0, 2.24, 2.2, 1.1, 1.58, 0.35, 0.5, 0.71, 1.0, 1.55, 0.56, 1.0, 1.0]\n",
            "0.139  EleutherAI/the_pile_deduplicated ||| EleutherAI/the_pile_deduplicated\n",
            "\n",
            "0.146  tiiuae/falcon-refinedweb ||| tiiuae/falcon-refinedweb\n",
            "\n",
            "0.043  Skylion007/openwebtext ||| Skylion007/openwebtext\n",
            "\n",
            "0.299  Cohere/wikipedia-22-12 ||| Cohere/wikipedia-22-12\n",
            "\n",
            "0.021  Multi-Domain-Expert-Layers/the_pile_books3_packed_128k ||| Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\n",
            "\n",
            "0.021  nRuaif/book2-lite-cleaned ||| nRuaif/book2-lite-cleaned\n",
            "\n",
            "0.031  macrocosm/arxiv_abstracts ||| macrocosm/arxiv_abstracts\n",
            "\n",
            "0.000  ccdv/pubmed-summarization ||| ccdv/pubmed-summarization\n",
            "\n",
            "0.005  big_patent ||| big_patent\n",
            "\n",
            "0.005  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/euro_parl\n",
            "\n",
            "0.000  kerinin/hackernews-stories ||| kerinin/hackernews-stories\n",
            "\n",
            "0.000  https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst ||| https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\n",
            "\n",
            "0.053  https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip ||| https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\n",
            "\n",
            "0.014  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/r_legaladvice\n",
            "\n",
            "0.001  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/exam_outlines\n",
            "\n",
            "0.004  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/cc_casebooks\n",
            "\n",
            "0.018  eloukas/edgar-corpus ||| eloukas/edgar-corpus\n",
            "\n",
            "0.015  Rahmaa/ElsevieR_ClEaN ||| Rahmaa/ElsevieR_ClEaN\n",
            "\n",
            "0.009  ashraq/financial-news-articles ||| ashraq/financial-news-articles\n",
            "\n",
            "0.012  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/courtlistener_opinions\n",
            "\n",
            "0.008  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/sec_administrative_proceedings\n",
            "\n",
            "0.006  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/irs_legal_advice_memos\n",
            "\n",
            "0.005  launch/gov_report ||| launch/gov_report\n",
            "\n",
            "0.029  izumi-lab/open-text-books ||| izumi-lab/open-text-books\n",
            "\n",
            "0.000  gigant/ted_descriptions ||| gigant/ted_descriptions\n",
            "\n",
            "0.019  Skelebor/book_titles_and_descriptions ||| Skelebor/book_titles_and_descriptions\n",
            "\n",
            "0.019  joelito/legal_case_document_summarization ||| joelito/legal_case_document_summarization\n",
            "\n",
            "0.009  joelito/legal-mc4 ||| joelito/legal-mc4/en\n",
            "\n",
            "0.014  Hellisotherpeople/DebateSum ||| Hellisotherpeople/DebateSum\n",
            "\n",
            "0.003  lukesjordan/worldbank-project-documents ||| lukesjordan/worldbank-project-documents\n",
            "\n",
            "0.004  64bits/lex_fridman_podcast_for_llm_vicuna ||| 64bits/lex_fridman_podcast_for_llm_vicuna\n",
            "\n",
            "0.006  nid989/EssayFroum-Dataset ||| nid989/EssayFroum-Dataset\n",
            "\n",
            "0.009  nlpaueb/finer-139 ||| nlpaueb/finer-139\n",
            "\n",
            "0.013  squad ||| squad\n",
            "\n",
            "0.005  Pavithree/askHistorians ||| Pavithree/askHistorians\n",
            "\n",
            "0.009  Isotonic/human_assistant_conversation ||| Isotonic/human_assistant_conversation\n",
            "\n",
            "0.009  albertvillanova/legal_contracts ||| albertvillanova/legal_contracts\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c43238e777524e35aeaef39563f826e1",
            "e0afd506237e4827b18342517efe57c2",
            "48bb2ed3d83e4478a54e91ba139c5e00",
            "c1b45bd7bb5441ae8351484e31220759",
            "3a922b09e0434f5a83b30283e292c1b0",
            "297d52865a7040c98c75eda8db8a66b0",
            "9128f342fa6f40ddaf96c76479def9e0",
            "49e8ab3a33b84fa0927e70de97b68eff",
            "67ed3e714bb546939ef59e3c3b1a46ef",
            "e0126d9955004e67859e2408793c3701",
            "3d179887256d4468a241726c7a29fb8f",
            "6b4127c09ddb41c1991b93d5078f4c65",
            "eb80343332eb4fdaa7fafdece8f32a6a",
            "0573a106e0444bd89fa1313eb7c26367",
            "5548f2ecaf504a1eb3ef99ff409dd98a",
            "23e9342a3beb41a690427a8e86392b15",
            "0b46b750f04142779145773b00c249f1",
            "b098cade41154470814779005282469f",
            "160e0b74b9fe48979e428d553235cf0b",
            "224cfe84583b4a3881bb003755d4fccc",
            "14ea1273931a4f6a9c3f0b1617ae1909",
            "f12cef0d863749faa4558bece58e2aeb",
            "fb08200519154d5381a5715cc29707b9",
            "1e166f9ef4ba4be5a27a2ec9f4fbc673",
            "38c4fabce8694b89b18712d4b39815dd",
            "19c6e423258e4a42bf71de3a8060cd97",
            "448e8344500040408be758becd00f4a6",
            "e1e28e6f4c864e82822526d444cdf78e",
            "e7345f9a6e3e480fa02a0ac049e8fb88",
            "fe15b58e99f84aeda754a4bcda6c9e5c",
            "f97391ce1a914eb7b82348d974f8a8a5",
            "af1200c003dd4a0aa844cb14b36496c2",
            "8a352fc0efd44e438533a8a263efdd7b",
            "f8d2c2bd16d24bd2a9ec2df58a9cf3ae",
            "0ea1d19a194e49e88dd90042297277af",
            "fd5e89c8d6854e9a96a972a13e3096bc",
            "13a4626956e4467e9fdbdffab367b3af",
            "8cb11f382c8d4fbb94616b72e99da66d",
            "7a7539e5355a40c69e86226be61285a8",
            "8a991feecc3a4895a67df0ec38443f94",
            "3467a336a1844a7c996cbebe5deac8a4",
            "26e2834b1cf444c38c0f42d70ba49740",
            "fd818c8682c14a338008db4e5fe42b8c",
            "b6d39bda64dc4c0b82bd00f031a4e581",
            "7b916d718a6544daa5965a3a619e1728",
            "caa1e364a3544af7a34c1d0bef26d16d",
            "272f34f0ca354f4f9a90b6bbd5c6d851",
            "fb3e27581b984a679b1508c856d6a358",
            "f0844bdd8e8d4caa8a4f459d0f548a6d",
            "c00eeb575ce5464887956b0ff0ede32e",
            "d297c38ad8d24e77a6c875c6377864c0",
            "d1ecfc23fcd44a54bc6b75fec187a031",
            "f7c2c7840e6e4bc7bfeff9f81e954be7",
            "4d975a33184e4d63bb6f525407983792",
            "26085109203d4b398e4966ccc379aa3a",
            "14eba8c9409c473096dec47c8a186d1f",
            "2d95088402554b039e0977e123ae4217",
            "2bb64f37a0c5460e8a0d851bfc6bf89b",
            "a2297235480a4003a13872b54af61181",
            "fc3a5e9bf99f4e3f9f32de8138346e62",
            "b7c0c9fff4e8438298a2aab83fd7c53a",
            "666454f8106d4e57888e04642c41b8cb",
            "874a62a373984e9393bb7859e246593e",
            "495456125b5f47b69486c166a1e5d5fe",
            "bedea9cba199496dae77c0ce91b04cb2",
            "b0b7d45a4c744c17b88a4e7a25c508b6",
            "afe6880488e64eab812601ef388eca2f",
            "b8109862e59a4e058d6713be8415e762",
            "bae28893878d4fb58b0051f1571ff12e",
            "95c067ece86a48548ee1d2b334d87925",
            "3b0b9e2af2764af59e4ae9fd813d0284",
            "719321cb029240d1b38b94f6d75a0f6e",
            "ae0fa1ccfe124196bcb6692339c14334",
            "e2aade6602744914bffc54454af15de0",
            "66f9eb352d20486f80100dc14d326e95",
            "06e9433317d546ee820335ceee7adf0b",
            "577cc621be9f406fb22ef6fa1abfb49c",
            "7ca4ee24afc04298add4e206e5a53605",
            "8dc6c33bc73446849848863fea619e33",
            "fa37d5ff022942ff9d32644d9d76b05e",
            "f8080e1384084a189666337dfe8f44e4",
            "40c4f9b712c842caba16fa5918923071",
            "3d0c74b4ca3849ef973af8fba5b47101",
            "964d92d06550458483ce5d067cc61ce4",
            "b3b70384de334fcba234fd3bfceb7e02",
            "ff08c86e7cc0462880f28c798e4ffb8e",
            "22e6e5f5f02a4ba5bd9a11d5ccab0fd2",
            "a4029b791f9e47918a8cdeb184bc2a1e",
            "72567b16e1984c428e7368926fea768b",
            "4c7061ab398f450d8d495012dc95a496",
            "c27d7d7ea5c741eaaf61cac62bab7cad",
            "e43626722ac74d02ae8690a21fdcaca9",
            "79cae125ecf64c1ead7f98249fdf496d",
            "d0981d02b28842efa959c9a0935fb427",
            "758dd0e6f0d54287bb45ade05c50b135",
            "120cf4a2275e4b019f24cb176558e903",
            "c2a29e82e80e4b22aa079c425c8f04b4",
            "40b97ca997494945b3d99f68406ba678",
            "0c691ed21baa46b197239590f3ae3a38",
            "5ee4c88368574473b7c5e2e894c4d1da",
            "2dac1de01da14074a85b8cf7bcd49a1e",
            "4e8b7112975a4bdc8d8b3708de285270",
            "ff95d0ac8fe54b059e793969a0fc9c73",
            "5d9164e3a4f64fda8bf69f66ead6f55f",
            "dea7ccd32f674b888ba89786a99bba11",
            "c05f9a6948e1471495722d39a47df80f",
            "cd5882fa65374a4bafa3754c391e2e91",
            "04dc945f096c466dba2aff03e85109a7",
            "65f0fcb8b52b496fbb9eacc7e3fbc09b",
            "6803b0c7867542629accd9594aba8320",
            "955441547db940c68eafd6edbb24f2c4",
            "33b94ff78b774c0bb396764214faae15",
            "c51c0aec84d34d8795230b826c0e506c",
            "33b8304d91a742c88594e9a243c69d90",
            "93c388a0e311479aa3f9cb5cfd09c82a",
            "b33d5b31cfd6458e9f4e2f225ceb563b",
            "8f5968e4b8384018bfe3888af7ac62eb",
            "4f3bb043811d46ccb5117ee7ce232a21",
            "f481b94794cd4fdc9a0ed71c6c38f9d7",
            "04375298c8424abdbaf0b5bcc94e489e",
            "af2015e115a1433ca9e41558643f014a",
            "cd0caf5d91fc40309873b71a45a1cd2f",
            "4385d67e0f1d4168a9dd96885985f758",
            "d34082f569d84c3fa29bfc3c66cea638",
            "9c639b77ca884d6aba8945c0a92aad94",
            "f520a638e72643089418892b9b5ab94a",
            "9002759dd55a40f798648710e92db520",
            "54dcf39846c24c6f87cf1a07780ccc4f",
            "cf14d365c4424c849a4d898e8072157d",
            "5478b2c60e034b44bfa207fa1e3b7f8f",
            "0c49b91924fa4eea914de60e9f988692",
            "b2ee39a1e0584d8c88e4c3e7cee9b37f",
            "90da2949a0f541d9ad3fa4f78fc8f7d6",
            "24e09036434943a1bce7ef46550bc5bd",
            "67a2cce9f2404056b681165ac17678a5",
            "d651c8426f454582a32f3acb37da0a63",
            "069f474a6c4f464da9972305e58c72a8",
            "3ffe62ef08a944cfaf3c6fe0fd9c4ce5",
            "ca194b931bfa4f8a875f15bad42b0fa3",
            "d020cc432f244c33a97d4eefc9865b68",
            "780bfecb2dac4de786aa086c2af3d81c",
            "528bce053b854342b240faafa39b2cc7",
            "1a53607085ee488caf12759c72a461ff",
            "200a9c0022b84f65a00e46d83026947b",
            "f2a80d6f02be4de7a88a58fe5de9d752",
            "1d8488d7777e4ae1962ee8be12873903",
            "618f705d86a14639976b6709cc290217",
            "717505a3082d4dcab5b0f33987a5937e",
            "b7908eef16524107a7e86cc81e91059e",
            "85dccac58992488585353f8d041d514a",
            "e90b51900386436295455f234fbced72",
            "e7082e615a8844a38925e855f99683ec",
            "8d57c838ae6a435bbe0438bf68e5e6ae",
            "6d8a520ea349445cb9204396b11693fc",
            "dfe8a82fffee4e23ba904d825078528c",
            "8582f481238f44a2b8e0eef31a32bae6",
            "13ce480e479f40c2818c42246458950f",
            "48f06e02aed645cf9867835ac2ec3b94",
            "e990bc95b57c4d6fb4ec5cd6a323d86c",
            "f559109a6d0f4ab3bee2f4e8b8416627",
            "98128518f73f45b4903d4c63f071b304",
            "2b1aac8c47fd4625b70e0fb489778ad4",
            "f1badb046f624314ab85ab3d89c10815",
            "66b68d260c4f48809fc0f747a1fe365e",
            "ed966cab67a84ea789d607f86620b17e",
            "4cb3a81901894e7f82870d74ddb55da9",
            "1f21c95352d84be18e7631e0052c59a2",
            "ecf69f2a875e4d98a18cad2f42bf5db8",
            "76f8a367981f4eeea2b495d04e47dec8",
            "a4f81bc6e3db4967a47e29bf03b67a02",
            "d36805fe4947441d9d63a417e54b7d22",
            "5d7f7c36954d4e8f986a0accb5b9396e",
            "08d6faf821044a72842bbc436aa8b09e",
            "b7769b11c7e94a3281ee10e9f39e8024",
            "aaf3cc4af5c949d9bf46aae7daf1009a",
            "3249bf189c2d465e8f0ea6c2afdb59d7",
            "2443766ea4b74d13b94486abeee250f8",
            "8f5e250391cf44f49274098a70d35567",
            "3487dc3b86664dfb8bb1fc0e2b84c11d",
            "cb53243191084bae8f9a4ef972a7b3b7",
            "dcd78d7361fb4b22bdc1be87c291df0e",
            "e8772173f7b142fcb7b7e0908ba6f12c",
            "b0793cf7a10f4f10b58cf64d0e7ab0c7",
            "d265b9410fa34feda6509183e7a621f4",
            "474d1c3f82ec4444ae3e7748e0e75425",
            "ce9f60888a214a67bbc783a577bbc492",
            "08ae4d41f85d4e1d97ce027ad5bb7920",
            "1f72b84448df4eb28a591049f8bb087c",
            "ec4e69abb86e46b99f48d91c111dcf31",
            "09a1e9b08eda42a59395451ca0dd28f4",
            "5a06cd8312b047db93988f1adeb3face",
            "472bd9d2df9946b7a3fb7293bdeb7439",
            "0c4a53e9dea2405f8ee219138db63cea",
            "a358ef20b2874bcfb8a5e103b2a66776",
            "9f9a8885756c4e08b003e8e2bc3d6498",
            "30bb71ba18904f628908b5ee5e2e5449",
            "0e536b2f5ad84aa3bb43fe5f62ac294e",
            "dda8a43130d142a582df5141c4c5a5de",
            "9434269dd2934fe69b952e54f030bc1a",
            "72038bf8a3cc481099de6c3f447e1b69",
            "0485bd9ab4af4809916700c1cdaa6f45",
            "308fcd2c63f845ab9ee763f8244d3bb8",
            "49e1b9ceae9a4948b7eb139427b02087",
            "bcbc6ad6edd04b48b02b5435ccaed987",
            "0ee1bdf4892c4b46aee6611c074d2498",
            "c0bcaa390871497692127229045408b3",
            "4c09b488a64c484cafe81da5df728600",
            "25faac3263c948d29af93d16b771dc6a",
            "29493556a8a44d54898b7dd5d31f2f39",
            "087cabed0b364060bf7d072a0e4666ce",
            "7a98757727be426bb3ab922c560c68a4",
            "cfdd33227b9f4feaa349607e63a7fa21",
            "39a05751596e4dd48d74db3920d03294",
            "31ef123f5006445cb367a1437afeb3b8",
            "e23598ee5e6543368976eb061fa0ad4d",
            "ab66db253fa24e179c36780a46ad37af",
            "7c706eef058c4dbb9d0ac870752d12ad",
            "cc417ba68cf54f67aae4ff0af7221960",
            "321bcb07ce24410bbfe621e37b8a60ec",
            "c653d0ec04c443d385f3ac2739723824",
            "a39f9264f89740d2b4087fbbb184019f",
            "25985ae5820443b6bc43ea5f1b0affd1",
            "2a5a7200841a45a1a507f9b1adca18b1",
            "e825483e96574238aabfcd793ff08b5d",
            "5f35a5d79c0f4d8cae3800a4573d7c8b",
            "552e363453ff48e59f58c8df67e4d8e6",
            "22928eaf7a034396aabc94de6af991b1",
            "0a6e0b3bf4be46cf80d47b1303d14703",
            "dd99c4f0bba1468aad56dd501840db01",
            "0a97c29bf89343e4b712ea77aac38726",
            "ba205a2067154511bb5739a67b602bc0",
            "49d66e5bf4fe4bbfa8f0d34af9e57e37",
            "ec6c762ac89e4c91bf1bfd228976a3a6",
            "b8b3be37b1d94aaaab723c190cb81644",
            "1c8112c1a6804c0384bcb47f8124ef4a",
            "ee1eb3b787324a02a4f9eaff02be1d6b",
            "d37c0585e68142b8aedf3d21f4105d81",
            "9e93fa146d4c4800a3b775c952c07b94",
            "f5c66057d62c4e979c40065bfb203f7f",
            "623f8e18e31f4c6c9b82d13588e53640",
            "d695949d3ca943f18556617cd6e24ec7",
            "1989a88e7a5f427c88895c3a50a75ff9",
            "d9d69a9bcd2f4eaf8eea31db00e3331d",
            "b48b8103cc48422da880bed80c4b5844",
            "43484f23ef104b73b156453d3c8b48b2",
            "8a6827861c3044e0b8875c104f0c3f7d",
            "49b35a44d15d4ec7bbbc20915689baa1",
            "10d9e1027d9343a3a81dd6441080d514",
            "cf98b06559384d88b559c4702798c42d",
            "5a9880cdb8264ba8a53e16f80ef76fce",
            "f030abf2c75b45c4ab99848b0e6e52bb",
            "3bf315cbf5bf4650ac975ad38cc7c63f",
            "441bce894af6474799b5151fd0dc0290",
            "f2d393d146434ccba6141c4de3177670",
            "3af39c16fe4d46828afb28e16bfc3343",
            "b56beaf76c474f0f8e7a6a774d6ff5b1",
            "e6f48556674c4bb4bd08cd2a206b792c",
            "b2eb3d7f0b934382b45e3424bd74326c",
            "441bb0efdd77486ba5056c07435e9038",
            "259472e0b6b4432bb37fc036b9860eec",
            "277ef151fbcd4f72b0083ef50ff7556d",
            "c8e54f24dc854c8a9d5cf54b4f7eaccf",
            "f85dc1c0ad9942f38e3d9c8a10c5921b",
            "586a901aeb7846dc8012f962eba33dde",
            "aa681087d04342db816bf7871e46dcf3",
            "937c333aeb1e459c83369464f7d52157",
            "979c6a06e2364605ab52a60ca0805bbc",
            "496fe7d431e54dd7b221eeb1cbf5445f",
            "c2ecf01731ba4f9fb4ef9b2bc10eac0f",
            "9aafe0c198644ab5905926a2bc2cffd3",
            "3ee86ab306a54dfcb11907386b2804a3",
            "4c24fe2e0a174981ac838a00e15f0742",
            "02eba717388548bb84467b89b298cbdd",
            "13fc6b3e48374cfe85ea43e9588cd179",
            "e980fc0205024032ae0c73eb41373de0",
            "67ea2c4aaab7448f89606660d35f561a",
            "00783993887e41309e4ac21b9042b090",
            "7bc19bbd312944b28fc2f7e2dc94a939",
            "4ca0016c8aec4a898737d0980e37b732",
            "078ccbed975b4c3195458a5366c62147",
            "9639a03dc49042368a0368fe42ac6bed",
            "382b0231b7c749e2854e8fe3b38fc6b0",
            "e3c90a1a3791478dad529a7e86607931",
            "3da7757910f543188bfe2b23a232e57b",
            "c301024c62974346a719abb16cf59a55",
            "033dfd6abf1a47a09e856595cdb40294",
            "7e27d08cc8224206b0f86bbc81c0a167",
            "db16132e0c904763a0afa0353a112fe4",
            "e884470ccded4f91b299d2c212b2badc",
            "f933fc623fdf44ba9ad91402ad00c45e",
            "8d4884fec41949bcaa91e2b857e3e17c",
            "3ef3789139f743f3b2d271a57be8c969",
            "12c2d06cd75a4d3eb7dc70cdb12e78a7",
            "2a020b971470409a87de9cda980368eb",
            "ef62d5973471498b9d3609df1752f341",
            "551f253f04f5441cac92f4654cbf350a",
            "6f560e5e02ad4272b5024c31ece49c8b",
            "e2449243b56243e7bd3ae7bc2f4cde37",
            "a0bbdac5a518428283b9c2f0223bddb3",
            "93789c8e4ab44608b55cac224abed8e5",
            "d331b857fa504df4b1a56f99b7222951",
            "de5d1956052149d4bcefef91833fe10c",
            "b99fcd896fb9447d9534df2b6572928f",
            "4daaf8c90a9c49978feada1ebcdee2c1",
            "aa166da33fa04214a7c7bc278a1bc4be",
            "7fd20cd579e14f8b96285c9b1bbd127c",
            "17e3eff2eb8743f994b861ec9298ce9c",
            "aae110daa26844dc9c4f7d10c6135f62",
            "9b74c9d9355a4bf19152b5a41e999a34",
            "51c692ed7f424f45bbd154d6f1c1d441",
            "6e28dffef1ff4c1395925437671013c3",
            "13da363a292a4cec9f59866445718e5f",
            "bb7dab0e54af4529b2d55eca3fbe295b",
            "98bc5ce28f784993b69620d3dc36bd6b",
            "76cca9cc9a924d9589ec9f8da8b522ed",
            "0aa8573d5c6644988020545a3de1c7e9",
            "b40873939bcf49d6b2a787162892838c",
            "5bbb2edd7eee420b9a8ae487ba7a0679",
            "97f685ef70ca4b0ebd07d08ac8ef63dc"
          ]
        },
        "id": "euHxSzBA2cFG",
        "outputId": "0ceabbdc-34d6-4cc6-bfed-acc91b5eee0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying EleutherAI/the_pile_deduplicated initialization (shuffling through 1650 files)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1650 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c43238e777524e35aeaef39563f826e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from EleutherAI/the_pile_deduplicated validation\n",
            "take 277 from EleutherAI/the_pile_deduplicated training\n",
            "Done getting streams/reloading from EleutherAI/the_pile_deduplicated\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying tiiuae/falcon-refinedweb initialization (shuffling through 5534 files)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/5534 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b4127c09ddb41c1991b93d5078f4c65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from tiiuae/falcon-refinedweb validation\n",
            "take 292 from tiiuae/falcon-refinedweb training\n",
            "Done getting streams/reloading from tiiuae/falcon-refinedweb\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Skylion007/openwebtext initialization (shuffling through 21 files)\n",
            "take 1 from Skylion007/openwebtext validation\n",
            "take 85 from Skylion007/openwebtext training\n",
            "Done getting streams/reloading from Skylion007/openwebtext\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Cohere/wikipedia-22-12 initialization (shuffling through 351 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 2 from Cohere/wikipedia-22-12 validation\n",
            "take 598 from Cohere/wikipedia-22-12 training\n",
            "Done getting streams/reloading from Cohere/wikipedia-22-12\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Multi-Domain-Expert-Layers/the_pile_books3_packed_128k initialization (shuffling through 15 files)\n",
            "take 1 from Multi-Domain-Expert-Layers/the_pile_books3_packed_128k validation\n",
            "take 41 from Multi-Domain-Expert-Layers/the_pile_books3_packed_128k training\n",
            "Done getting streams/reloading from Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying nRuaif/book2-lite-cleaned initialization (shuffling through 818 files)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/816 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb08200519154d5381a5715cc29707b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from nRuaif/book2-lite-cleaned validation\n",
            "take 41 from nRuaif/book2-lite-cleaned training\n",
            "Done getting streams/reloading from nRuaif/book2-lite-cleaned\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying macrocosm/arxiv_abstracts initialization (shuffling through 23 files)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8d2c2bd16d24bd2a9ec2df58a9cf3ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from macrocosm/arxiv_abstracts validation\n",
            "take 62 from macrocosm/arxiv_abstracts training\n",
            "Done getting streams/reloading from macrocosm/arxiv_abstracts\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying big_patent initialization\n",
            "take 1 from big_patent validation\n",
            "take 10 from big_patent train\n",
            "Done getting streams/reloading from big_patent\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying pile-of-law/pile-of-law initialization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b916d718a6544daa5965a3a619e1728"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/25.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14eba8c9409c473096dec47c8a186d1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from pile-of-law/pile-of-law validation\n",
            "take 10 from pile-of-law/pile-of-law train\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.euro_parl.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.euro_parl.jsonl.xz\n",
            "Done getting streams/reloading from pile-of-law/pile-of-law\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-5bd96a4d9bfd62a2\n",
            "INFO:datasets.builder:Using custom data configuration default-5bd96a4d9bfd62a2\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip validation\n",
            "take 107 from https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip train\n",
            "Done getting streams/reloading from https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying pile-of-law/pile-of-law initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from pile-of-law/pile-of-law validation\n",
            "take 28 from pile-of-law/pile-of-law train\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.r_legaldvice.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.r_legaldvice.jsonl.xz\n",
            "Done getting streams/reloading from pile-of-law/pile-of-law\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying pile-of-law/pile-of-law initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from pile-of-law/pile-of-law validation\n",
            "take 2 from pile-of-law/pile-of-law train\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.examoutlines.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.examoutlines.jsonl.xz\n",
            "Done getting streams/reloading from pile-of-law/pile-of-law\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying pile-of-law/pile-of-law initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from pile-of-law/pile-of-law validation\n",
            "take 9 from pile-of-law/pile-of-law train\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.cc_casebooks.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.cc_casebooks.jsonl.xz\n",
            "Done getting streams/reloading from pile-of-law/pile-of-law\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying eloukas/edgar-corpus initialization (shuffling through 28 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/edgar-corpus.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a97879a87e4a23ed18a404fbc53698af174a89130d54d2662fbb31361b29975c.a6b5c996cf6cb814c357c6be4099b2fe8418ed3506d14517915cfb2f1dbc5549.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/edgar-corpus.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a97879a87e4a23ed18a404fbc53698af174a89130d54d2662fbb31361b29975c.a6b5c996cf6cb814c357c6be4099b2fe8418ed3506d14517915cfb2f1dbc5549.py.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.64k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afe6880488e64eab812601ef388eca2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/edgar-corpus.py in cache at /root/.cache/huggingface/datasets/downloads/a97879a87e4a23ed18a404fbc53698af174a89130d54d2662fbb31361b29975c.a6b5c996cf6cb814c357c6be4099b2fe8418ed3506d14517915cfb2f1dbc5549.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/edgar-corpus.py in cache at /root/.cache/huggingface/datasets/downloads/a97879a87e4a23ed18a404fbc53698af174a89130d54d2662fbb31361b29975c.a6b5c996cf6cb814c357c6be4099b2fe8418ed3506d14517915cfb2f1dbc5549.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/a97879a87e4a23ed18a404fbc53698af174a89130d54d2662fbb31361b29975c.a6b5c996cf6cb814c357c6be4099b2fe8418ed3506d14517915cfb2f1dbc5549.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/a97879a87e4a23ed18a404fbc53698af174a89130d54d2662fbb31361b29975c.a6b5c996cf6cb814c357c6be4099b2fe8418ed3506d14517915cfb2f1dbc5549.py\n",
            "https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/d6a140d0ea4425f1b16ac44ee14d5071bfe4ff24dc22630baaec36ad3d95c028.47bb1a34b4776937628da47f28595b0d93431703a469e86e4354812a30299cc1.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/d6a140d0ea4425f1b16ac44ee14d5071bfe4ff24dc22630baaec36ad3d95c028.47bb1a34b4776937628da47f28595b0d93431703a469e86e4354812a30299cc1.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/43.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ca4ee24afc04298add4e206e5a53605"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/d6a140d0ea4425f1b16ac44ee14d5071bfe4ff24dc22630baaec36ad3d95c028.47bb1a34b4776937628da47f28595b0d93431703a469e86e4354812a30299cc1\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/eloukas/edgar-corpus/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/d6a140d0ea4425f1b16ac44ee14d5071bfe4ff24dc22630baaec36ad3d95c028.47bb1a34b4776937628da47f28595b0d93431703a469e86e4354812a30299cc1\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/d6a140d0ea4425f1b16ac44ee14d5071bfe4ff24dc22630baaec36ad3d95c028.47bb1a34b4776937628da47f28595b0d93431703a469e86e4354812a30299cc1\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/d6a140d0ea4425f1b16ac44ee14d5071bfe4ff24dc22630baaec36ad3d95c028.47bb1a34b4776937628da47f28595b0d93431703a469e86e4354812a30299cc1\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/eloukas--edgar-corpus/c2f9ada1db31915d6af4cc19f0ad9486cd0bab93c5c26bb32850e5a1f74f2bd7\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/eloukas--edgar-corpus/c2f9ada1db31915d6af4cc19f0ad9486cd0bab93c5c26bb32850e5a1f74f2bd7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from eloukas/edgar-corpus validation\n",
            "take 37 from eloukas/edgar-corpus training\n",
            "Done getting streams/reloading from eloukas/edgar-corpus\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Rahmaa/ElsevieR_ClEaN initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/Rahmaa/ElsevieR_ClEaN/resolve/091860c29d4d69c06bf41f15090e03c787424fda/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/cbac8c5c9aaa279c9275b6eb38eed4f9eadea05912fa872f3392e7c41407638d.094a50cb8064faee8c4cb789efc018e2ed5bcdc14dcae7d757da917ebaf6626b.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/Rahmaa/ElsevieR_ClEaN/resolve/091860c29d4d69c06bf41f15090e03c787424fda/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/cbac8c5c9aaa279c9275b6eb38eed4f9eadea05912fa872f3392e7c41407638d.094a50cb8064faee8c4cb789efc018e2ed5bcdc14dcae7d757da917ebaf6626b.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72567b16e1984c428e7368926fea768b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/Rahmaa/ElsevieR_ClEaN/resolve/091860c29d4d69c06bf41f15090e03c787424fda/README.md in cache at /root/.cache/huggingface/datasets/downloads/cbac8c5c9aaa279c9275b6eb38eed4f9eadea05912fa872f3392e7c41407638d.094a50cb8064faee8c4cb789efc018e2ed5bcdc14dcae7d757da917ebaf6626b\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/Rahmaa/ElsevieR_ClEaN/resolve/091860c29d4d69c06bf41f15090e03c787424fda/README.md in cache at /root/.cache/huggingface/datasets/downloads/cbac8c5c9aaa279c9275b6eb38eed4f9eadea05912fa872f3392e7c41407638d.094a50cb8064faee8c4cb789efc018e2ed5bcdc14dcae7d757da917ebaf6626b\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/cbac8c5c9aaa279c9275b6eb38eed4f9eadea05912fa872f3392e7c41407638d.094a50cb8064faee8c4cb789efc018e2ed5bcdc14dcae7d757da917ebaf6626b\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/cbac8c5c9aaa279c9275b6eb38eed4f9eadea05912fa872f3392e7c41407638d.094a50cb8064faee8c4cb789efc018e2ed5bcdc14dcae7d757da917ebaf6626b\n",
            "Using custom data configuration default-64887fd44f3099ea\n",
            "INFO:datasets.builder:Using custom data configuration default-64887fd44f3099ea\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from Rahmaa/ElsevieR_ClEaN validation\n",
            "take 29 from Rahmaa/ElsevieR_ClEaN train\n",
            "Done getting streams/reloading from Rahmaa/ElsevieR_ClEaN\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying ashraq/financial-news-articles initialization (shuffling through 2 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/ashraq/financial-news-articles/resolve/9920e8130b63513c598a6cdde10df3e2728bccef/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/b2785c62f11a7b7b0c0607784cd7180cf38a1457530150136d1f465f6f7b6977.78203cceda51700ab31adfc29b11cb1e3a368c608b7286797757649eaf892e7c.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/ashraq/financial-news-articles/resolve/9920e8130b63513c598a6cdde10df3e2728bccef/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/b2785c62f11a7b7b0c0607784cd7180cf38a1457530150136d1f465f6f7b6977.78203cceda51700ab31adfc29b11cb1e3a368c608b7286797757649eaf892e7c.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/543 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ee4c88368574473b7c5e2e894c4d1da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/ashraq/financial-news-articles/resolve/9920e8130b63513c598a6cdde10df3e2728bccef/README.md in cache at /root/.cache/huggingface/datasets/downloads/b2785c62f11a7b7b0c0607784cd7180cf38a1457530150136d1f465f6f7b6977.78203cceda51700ab31adfc29b11cb1e3a368c608b7286797757649eaf892e7c\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/ashraq/financial-news-articles/resolve/9920e8130b63513c598a6cdde10df3e2728bccef/README.md in cache at /root/.cache/huggingface/datasets/downloads/b2785c62f11a7b7b0c0607784cd7180cf38a1457530150136d1f465f6f7b6977.78203cceda51700ab31adfc29b11cb1e3a368c608b7286797757649eaf892e7c\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/b2785c62f11a7b7b0c0607784cd7180cf38a1457530150136d1f465f6f7b6977.78203cceda51700ab31adfc29b11cb1e3a368c608b7286797757649eaf892e7c\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/b2785c62f11a7b7b0c0607784cd7180cf38a1457530150136d1f465f6f7b6977.78203cceda51700ab31adfc29b11cb1e3a368c608b7286797757649eaf892e7c\n",
            "Using custom data configuration default-46ecf33ad989e148\n",
            "INFO:datasets.builder:Using custom data configuration default-46ecf33ad989e148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from ashraq/financial-news-articles validation\n",
            "take 17 from ashraq/financial-news-articles training\n",
            "Done getting streams/reloading from ashraq/financial-news-articles\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying pile-of-law/pile-of-law initialization (shuffling through 16 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from pile-of-law/pile-of-law validation\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.courtlisteneropinions.0.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.courtlisteneropinions.1.jsonl.xz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <generator object PileOfLaw._generate_examples at 0x7ca0f02cfa70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\", line 233, in __iter__\n",
            "    yield from self.generate_examples_fn(**self.kwargs)\n",
            "RuntimeError: generator ignored GeneratorExit\n",
            "Exception ignored in: <generator object ExamplesIterable.__iter__ at 0x7ca0f02ce880>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\", line 233, in __iter__\n",
            "    yield from self.generate_examples_fn(**self.kwargs)\n",
            "RuntimeError: generator ignored GeneratorExit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 23 from pile-of-law/pile-of-law training\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.courtlisteneropinions.7.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.courtlisteneropinions.2.jsonl.xz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <generator object PileOfLaw._generate_examples at 0x7ca0f02cdd20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\", line 261, in __iter__\n",
            "    yield from self.generate_examples_fn(**kwargs_with_shuffled_shards)\n",
            "RuntimeError: generator ignored GeneratorExit\n",
            "Exception ignored in: <generator object ShuffledDataSourcesExamplesIterable.__iter__ at 0x7ca0f02cfa70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\", line 261, in __iter__\n",
            "    yield from self.generate_examples_fn(**kwargs_with_shuffled_shards)\n",
            "RuntimeError: generator ignored GeneratorExit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done getting streams/reloading from pile-of-law/pile-of-law\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying pile-of-law/pile-of-law initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from pile-of-law/pile-of-law validation\n",
            "take 15 from pile-of-law/pile-of-law train\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.sec.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.sec.jsonl.xz\n",
            "Done getting streams/reloading from pile-of-law/pile-of-law\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying pile-of-law/pile-of-law initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from pile-of-law/pile-of-law validation\n",
            "take 13 from pile-of-law/pile-of-law train\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.irs_legal_advice_memos.jsonl.xz\n",
            "Error reading file: https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.irs_legal_advice_memos.jsonl.xz\n",
            "Done getting streams/reloading from pile-of-law/pile-of-law\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying launch/gov_report initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/launch/gov_report/resolve/main/gov_report.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/8592f359583c23cec40549ae340147d412ae4ff68cb41ef637a3946cf068096c.beda861b3eaffcb858aee41560c69e53169e1d43c68036e03d0fe55058d10a05.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/launch/gov_report/resolve/main/gov_report.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/8592f359583c23cec40549ae340147d412ae4ff68cb41ef637a3946cf068096c.beda861b3eaffcb858aee41560c69e53169e1d43c68036e03d0fe55058d10a05.py.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "955441547db940c68eafd6edbb24f2c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/launch/gov_report/resolve/main/gov_report.py in cache at /root/.cache/huggingface/datasets/downloads/8592f359583c23cec40549ae340147d412ae4ff68cb41ef637a3946cf068096c.beda861b3eaffcb858aee41560c69e53169e1d43c68036e03d0fe55058d10a05.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/launch/gov_report/resolve/main/gov_report.py in cache at /root/.cache/huggingface/datasets/downloads/8592f359583c23cec40549ae340147d412ae4ff68cb41ef637a3946cf068096c.beda861b3eaffcb858aee41560c69e53169e1d43c68036e03d0fe55058d10a05.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/8592f359583c23cec40549ae340147d412ae4ff68cb41ef637a3946cf068096c.beda861b3eaffcb858aee41560c69e53169e1d43c68036e03d0fe55058d10a05.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/8592f359583c23cec40549ae340147d412ae4ff68cb41ef637a3946cf068096c.beda861b3eaffcb858aee41560c69e53169e1d43c68036e03d0fe55058d10a05.py\n",
            "https://huggingface.co/datasets/launch/gov_report/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/fc200ae7e538ce53944ce22c4c6ae32a88eaff8460b85d0c0162b3561bd47b66.99c73aa01f57c69db33c491f995aa8edfb756af728bed02dc3c0966b7750ff66.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/launch/gov_report/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/fc200ae7e538ce53944ce22c4c6ae32a88eaff8460b85d0c0162b3561bd47b66.99c73aa01f57c69db33c491f995aa8edfb756af728bed02dc3c0966b7750ff66.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.69k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd0caf5d91fc40309873b71a45a1cd2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/launch/gov_report/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/fc200ae7e538ce53944ce22c4c6ae32a88eaff8460b85d0c0162b3561bd47b66.99c73aa01f57c69db33c491f995aa8edfb756af728bed02dc3c0966b7750ff66\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/launch/gov_report/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/fc200ae7e538ce53944ce22c4c6ae32a88eaff8460b85d0c0162b3561bd47b66.99c73aa01f57c69db33c491f995aa8edfb756af728bed02dc3c0966b7750ff66\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/fc200ae7e538ce53944ce22c4c6ae32a88eaff8460b85d0c0162b3561bd47b66.99c73aa01f57c69db33c491f995aa8edfb756af728bed02dc3c0966b7750ff66\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/fc200ae7e538ce53944ce22c4c6ae32a88eaff8460b85d0c0162b3561bd47b66.99c73aa01f57c69db33c491f995aa8edfb756af728bed02dc3c0966b7750ff66\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report/f54a652210ba40a8e19722a37211f8d0623e7170deedab282a05dafd311e23b5\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report/f54a652210ba40a8e19722a37211f8d0623e7170deedab282a05dafd311e23b5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from launch/gov_report validation\n",
            "take 9 from launch/gov_report train\n",
            "Done getting streams/reloading from launch/gov_report\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying izumi-lab/open-text-books initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/izumi-lab/open-text-books/resolve/1245fefd628d37483366b8e707fdc5650fd3c48e/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/3a6cafa442d623fa1a9fafa6256d2bde1a822e6981244e62afbdcf597f27d9f3.e56fddbfa20be2788374fbcc61e92813080be196c0cacb299e34c84c57efcef2.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/izumi-lab/open-text-books/resolve/1245fefd628d37483366b8e707fdc5650fd3c48e/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/3a6cafa442d623fa1a9fafa6256d2bde1a822e6981244e62afbdcf597f27d9f3.e56fddbfa20be2788374fbcc61e92813080be196c0cacb299e34c84c57efcef2.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/488 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90da2949a0f541d9ad3fa4f78fc8f7d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/izumi-lab/open-text-books/resolve/1245fefd628d37483366b8e707fdc5650fd3c48e/README.md in cache at /root/.cache/huggingface/datasets/downloads/3a6cafa442d623fa1a9fafa6256d2bde1a822e6981244e62afbdcf597f27d9f3.e56fddbfa20be2788374fbcc61e92813080be196c0cacb299e34c84c57efcef2\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/izumi-lab/open-text-books/resolve/1245fefd628d37483366b8e707fdc5650fd3c48e/README.md in cache at /root/.cache/huggingface/datasets/downloads/3a6cafa442d623fa1a9fafa6256d2bde1a822e6981244e62afbdcf597f27d9f3.e56fddbfa20be2788374fbcc61e92813080be196c0cacb299e34c84c57efcef2\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/3a6cafa442d623fa1a9fafa6256d2bde1a822e6981244e62afbdcf597f27d9f3.e56fddbfa20be2788374fbcc61e92813080be196c0cacb299e34c84c57efcef2\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/3a6cafa442d623fa1a9fafa6256d2bde1a822e6981244e62afbdcf597f27d9f3.e56fddbfa20be2788374fbcc61e92813080be196c0cacb299e34c84c57efcef2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from izumi-lab/open-text-books validation\n",
            "take 58 from izumi-lab/open-text-books train\n",
            "Done getting streams/reloading from izumi-lab/open-text-books\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Skelebor/book_titles_and_descriptions initialization (shuffling through 2 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/Skelebor/book_titles_and_descriptions/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/6dcb956807b8b6aaf3a753564d5464713b7ffeaac04908f47e091dae787fb14e.095651d2bbba48c3c8e07c927c14c89687ed181f2f2c31088706cc34e1e1dde5.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/Skelebor/book_titles_and_descriptions/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/6dcb956807b8b6aaf3a753564d5464713b7ffeaac04908f47e091dae787fb14e.095651d2bbba48c3c8e07c927c14c89687ed181f2f2c31088706cc34e1e1dde5.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "200a9c0022b84f65a00e46d83026947b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/Skelebor/book_titles_and_descriptions/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/6dcb956807b8b6aaf3a753564d5464713b7ffeaac04908f47e091dae787fb14e.095651d2bbba48c3c8e07c927c14c89687ed181f2f2c31088706cc34e1e1dde5\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/Skelebor/book_titles_and_descriptions/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/6dcb956807b8b6aaf3a753564d5464713b7ffeaac04908f47e091dae787fb14e.095651d2bbba48c3c8e07c927c14c89687ed181f2f2c31088706cc34e1e1dde5\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/6dcb956807b8b6aaf3a753564d5464713b7ffeaac04908f47e091dae787fb14e.095651d2bbba48c3c8e07c927c14c89687ed181f2f2c31088706cc34e1e1dde5\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/6dcb956807b8b6aaf3a753564d5464713b7ffeaac04908f47e091dae787fb14e.095651d2bbba48c3c8e07c927c14c89687ed181f2f2c31088706cc34e1e1dde5\n",
            "Using custom data configuration default-063eaaba3b58f51c\n",
            "INFO:datasets.builder:Using custom data configuration default-063eaaba3b58f51c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from Skelebor/book_titles_and_descriptions validation\n",
            "take 38 from Skelebor/book_titles_and_descriptions training\n",
            "Done getting streams/reloading from Skelebor/book_titles_and_descriptions\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying joelito/legal_case_document_summarization initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/joelito/legal_case_document_summarization/resolve/176a3f11b7ef453947b486c1de843068d108acef/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/de9e48164b70a1b900a9fa88b72938a55fe54984edc38a894dcaaf1edcda10c2.9c20a1a696c0f24d17f910f503c09ec1eeaf660d470fa30f899e3f069646900f.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/joelito/legal_case_document_summarization/resolve/176a3f11b7ef453947b486c1de843068d108acef/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/de9e48164b70a1b900a9fa88b72938a55fe54984edc38a894dcaaf1edcda10c2.9c20a1a696c0f24d17f910f503c09ec1eeaf660d470fa30f899e3f069646900f.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/2.60k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfe8a82fffee4e23ba904d825078528c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/joelito/legal_case_document_summarization/resolve/176a3f11b7ef453947b486c1de843068d108acef/README.md in cache at /root/.cache/huggingface/datasets/downloads/de9e48164b70a1b900a9fa88b72938a55fe54984edc38a894dcaaf1edcda10c2.9c20a1a696c0f24d17f910f503c09ec1eeaf660d470fa30f899e3f069646900f\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/joelito/legal_case_document_summarization/resolve/176a3f11b7ef453947b486c1de843068d108acef/README.md in cache at /root/.cache/huggingface/datasets/downloads/de9e48164b70a1b900a9fa88b72938a55fe54984edc38a894dcaaf1edcda10c2.9c20a1a696c0f24d17f910f503c09ec1eeaf660d470fa30f899e3f069646900f\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/de9e48164b70a1b900a9fa88b72938a55fe54984edc38a894dcaaf1edcda10c2.9c20a1a696c0f24d17f910f503c09ec1eeaf660d470fa30f899e3f069646900f\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/de9e48164b70a1b900a9fa88b72938a55fe54984edc38a894dcaaf1edcda10c2.9c20a1a696c0f24d17f910f503c09ec1eeaf660d470fa30f899e3f069646900f\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n",
            "Using custom data configuration default-71e9190d0e325326\n",
            "INFO:datasets.builder:Using custom data configuration default-71e9190d0e325326\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from joelito/legal_case_document_summarization validation\n",
            "take 38 from joelito/legal_case_document_summarization train\n",
            "Done getting streams/reloading from joelito/legal_case_document_summarization\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying joelito/legal-mc4 initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/legal-mc4.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/3bed0c147bfb100a1b112f6cc6ffb22c50bf5799c7c3714007cac6b504af973f.b84ac56a6004b2fc44e4fefe4c03b9985e565ee1bc4cf4495b05ac02699fbbdb.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/legal-mc4.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/3bed0c147bfb100a1b112f6cc6ffb22c50bf5799c7c3714007cac6b504af973f.b84ac56a6004b2fc44e4fefe4c03b9985e565ee1bc4cf4495b05ac02699fbbdb.py.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cb3a81901894e7f82870d74ddb55da9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/legal-mc4.py in cache at /root/.cache/huggingface/datasets/downloads/3bed0c147bfb100a1b112f6cc6ffb22c50bf5799c7c3714007cac6b504af973f.b84ac56a6004b2fc44e4fefe4c03b9985e565ee1bc4cf4495b05ac02699fbbdb.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/legal-mc4.py in cache at /root/.cache/huggingface/datasets/downloads/3bed0c147bfb100a1b112f6cc6ffb22c50bf5799c7c3714007cac6b504af973f.b84ac56a6004b2fc44e4fefe4c03b9985e565ee1bc4cf4495b05ac02699fbbdb.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/3bed0c147bfb100a1b112f6cc6ffb22c50bf5799c7c3714007cac6b504af973f.b84ac56a6004b2fc44e4fefe4c03b9985e565ee1bc4cf4495b05ac02699fbbdb.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/3bed0c147bfb100a1b112f6cc6ffb22c50bf5799c7c3714007cac6b504af973f.b84ac56a6004b2fc44e4fefe4c03b9985e565ee1bc4cf4495b05ac02699fbbdb.py\n",
            "https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/713b46c86ba9022773d298e2ccae8af90ee704d43385c7515f6e1188e42ba8a2.dd9adffcbb25e2d8bc7a52263093267fe5ee4d259608b7867f9533fac4076631.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/713b46c86ba9022773d298e2ccae8af90ee704d43385c7515f6e1188e42ba8a2.dd9adffcbb25e2d8bc7a52263093267fe5ee4d259608b7867f9533fac4076631.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2443766ea4b74d13b94486abeee250f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/713b46c86ba9022773d298e2ccae8af90ee704d43385c7515f6e1188e42ba8a2.dd9adffcbb25e2d8bc7a52263093267fe5ee4d259608b7867f9533fac4076631\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/joelito/legal-mc4/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/713b46c86ba9022773d298e2ccae8af90ee704d43385c7515f6e1188e42ba8a2.dd9adffcbb25e2d8bc7a52263093267fe5ee4d259608b7867f9533fac4076631\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/713b46c86ba9022773d298e2ccae8af90ee704d43385c7515f6e1188e42ba8a2.dd9adffcbb25e2d8bc7a52263093267fe5ee4d259608b7867f9533fac4076631\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/713b46c86ba9022773d298e2ccae8af90ee704d43385c7515f6e1188e42ba8a2.dd9adffcbb25e2d8bc7a52263093267fe5ee4d259608b7867f9533fac4076631\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/joelito--legal-mc4/d84fb43ce5371570557909381a2bc123a510770c499c1b6743d56d659b298a76\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/joelito--legal-mc4/d84fb43ce5371570557909381a2bc123a510770c499c1b6743d56d659b298a76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from joelito/legal-mc4 validation\n",
            "take 19 from joelito/legal-mc4 train\n",
            "Done getting streams/reloading from joelito/legal-mc4\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Hellisotherpeople/DebateSum initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/Hellisotherpeople/DebateSum/resolve/d65bea5f7a48f9af06453e855dbffe1753a0f508/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/09258cb7fca93fc1751a4952007d2dbd3ccb6c05c0fe88b3e4e18c70c7d2f7ac.b1d75e4446247940af3d4a609e5b2334adeeca5160b579f63f0cbf442302c7eb.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/Hellisotherpeople/DebateSum/resolve/d65bea5f7a48f9af06453e855dbffe1753a0f508/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/09258cb7fca93fc1751a4952007d2dbd3ccb6c05c0fe88b3e4e18c70c7d2f7ac.b1d75e4446247940af3d4a609e5b2334adeeca5160b579f63f0cbf442302c7eb.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f72b84448df4eb28a591049f8bb087c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/Hellisotherpeople/DebateSum/resolve/d65bea5f7a48f9af06453e855dbffe1753a0f508/README.md in cache at /root/.cache/huggingface/datasets/downloads/09258cb7fca93fc1751a4952007d2dbd3ccb6c05c0fe88b3e4e18c70c7d2f7ac.b1d75e4446247940af3d4a609e5b2334adeeca5160b579f63f0cbf442302c7eb\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/Hellisotherpeople/DebateSum/resolve/d65bea5f7a48f9af06453e855dbffe1753a0f508/README.md in cache at /root/.cache/huggingface/datasets/downloads/09258cb7fca93fc1751a4952007d2dbd3ccb6c05c0fe88b3e4e18c70c7d2f7ac.b1d75e4446247940af3d4a609e5b2334adeeca5160b579f63f0cbf442302c7eb\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/09258cb7fca93fc1751a4952007d2dbd3ccb6c05c0fe88b3e4e18c70c7d2f7ac.b1d75e4446247940af3d4a609e5b2334adeeca5160b579f63f0cbf442302c7eb\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/09258cb7fca93fc1751a4952007d2dbd3ccb6c05c0fe88b3e4e18c70c7d2f7ac.b1d75e4446247940af3d4a609e5b2334adeeca5160b579f63f0cbf442302c7eb\n",
            "Using custom data configuration default-a92ef6f92972f484\n",
            "INFO:datasets.builder:Using custom data configuration default-a92ef6f92972f484\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from Hellisotherpeople/DebateSum validation\n",
            "take 27 from Hellisotherpeople/DebateSum train\n",
            "Done getting streams/reloading from Hellisotherpeople/DebateSum\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying lukesjordan/worldbank-project-documents initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/lukesjordan/worldbank-project-documents/resolve/c435ecfd98f198f2ea0e741591d347423ff056e7/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7bb3c2b0a5c56b702f43accda31033e3311ce1419c66e79fb041b5c33e153f50.2bdaa713397083611c0501f63cbc0acf0b68ec058942afbb7500bf10623b1df9.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/lukesjordan/worldbank-project-documents/resolve/c435ecfd98f198f2ea0e741591d347423ff056e7/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7bb3c2b0a5c56b702f43accda31033e3311ce1419c66e79fb041b5c33e153f50.2bdaa713397083611c0501f63cbc0acf0b68ec058942afbb7500bf10623b1df9.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9434269dd2934fe69b952e54f030bc1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/lukesjordan/worldbank-project-documents/resolve/c435ecfd98f198f2ea0e741591d347423ff056e7/README.md in cache at /root/.cache/huggingface/datasets/downloads/7bb3c2b0a5c56b702f43accda31033e3311ce1419c66e79fb041b5c33e153f50.2bdaa713397083611c0501f63cbc0acf0b68ec058942afbb7500bf10623b1df9\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/lukesjordan/worldbank-project-documents/resolve/c435ecfd98f198f2ea0e741591d347423ff056e7/README.md in cache at /root/.cache/huggingface/datasets/downloads/7bb3c2b0a5c56b702f43accda31033e3311ce1419c66e79fb041b5c33e153f50.2bdaa713397083611c0501f63cbc0acf0b68ec058942afbb7500bf10623b1df9\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/7bb3c2b0a5c56b702f43accda31033e3311ce1419c66e79fb041b5c33e153f50.2bdaa713397083611c0501f63cbc0acf0b68ec058942afbb7500bf10623b1df9\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/7bb3c2b0a5c56b702f43accda31033e3311ce1419c66e79fb041b5c33e153f50.2bdaa713397083611c0501f63cbc0acf0b68ec058942afbb7500bf10623b1df9\n",
            "Using custom data configuration default-e638d47d71533118\n",
            "INFO:datasets.builder:Using custom data configuration default-e638d47d71533118\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from lukesjordan/worldbank-project-documents validation\n",
            "take 6 from lukesjordan/worldbank-project-documents train\n",
            "Done getting streams/reloading from lukesjordan/worldbank-project-documents\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying 64bits/lex_fridman_podcast_for_llm_vicuna initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/64bits/lex_fridman_podcast_for_llm_vicuna/resolve/22ce5eaa1e0015e37cede361d7147738679af2d4/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/4bd20262c630a62e81fcd24f85a51c9a02f66cae76f7bdf473a836c745d60518.fdb38b86eb866e3b19b6bdb7f3df0050bb45f72f811c511d4872061102797b17.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/64bits/lex_fridman_podcast_for_llm_vicuna/resolve/22ce5eaa1e0015e37cede361d7147738679af2d4/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/4bd20262c630a62e81fcd24f85a51c9a02f66cae76f7bdf473a836c745d60518.fdb38b86eb866e3b19b6bdb7f3df0050bb45f72f811c511d4872061102797b17.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "087cabed0b364060bf7d072a0e4666ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/64bits/lex_fridman_podcast_for_llm_vicuna/resolve/22ce5eaa1e0015e37cede361d7147738679af2d4/README.md in cache at /root/.cache/huggingface/datasets/downloads/4bd20262c630a62e81fcd24f85a51c9a02f66cae76f7bdf473a836c745d60518.fdb38b86eb866e3b19b6bdb7f3df0050bb45f72f811c511d4872061102797b17\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/64bits/lex_fridman_podcast_for_llm_vicuna/resolve/22ce5eaa1e0015e37cede361d7147738679af2d4/README.md in cache at /root/.cache/huggingface/datasets/downloads/4bd20262c630a62e81fcd24f85a51c9a02f66cae76f7bdf473a836c745d60518.fdb38b86eb866e3b19b6bdb7f3df0050bb45f72f811c511d4872061102797b17\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/4bd20262c630a62e81fcd24f85a51c9a02f66cae76f7bdf473a836c745d60518.fdb38b86eb866e3b19b6bdb7f3df0050bb45f72f811c511d4872061102797b17\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/4bd20262c630a62e81fcd24f85a51c9a02f66cae76f7bdf473a836c745d60518.fdb38b86eb866e3b19b6bdb7f3df0050bb45f72f811c511d4872061102797b17\n",
            "Some files matched the pattern 'hf://datasets/64bits/lex_fridman_podcast_for_llm_vicuna@22ce5eaa1e0015e37cede361d7147738679af2d4/**' but don't have valid data file extensions: ['hf://datasets/64bits/lex_fridman_podcast_for_llm_vicuna@22ce5eaa1e0015e37cede361d7147738679af2d4/Lex_Podcast_Dataset_Processing.ipynb']\n",
            "INFO:datasets.data_files:Some files matched the pattern 'hf://datasets/64bits/lex_fridman_podcast_for_llm_vicuna@22ce5eaa1e0015e37cede361d7147738679af2d4/**' but don't have valid data file extensions: ['hf://datasets/64bits/lex_fridman_podcast_for_llm_vicuna@22ce5eaa1e0015e37cede361d7147738679af2d4/Lex_Podcast_Dataset_Processing.ipynb']\n",
            "Using custom data configuration default-03df91a7331b5fd9\n",
            "INFO:datasets.builder:Using custom data configuration default-03df91a7331b5fd9\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from 64bits/lex_fridman_podcast_for_llm_vicuna validation\n",
            "take 9 from 64bits/lex_fridman_podcast_for_llm_vicuna train\n",
            "Done getting streams/reloading from 64bits/lex_fridman_podcast_for_llm_vicuna\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying nid989/EssayFroum-Dataset initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/nid989/EssayFroum-Dataset/resolve/73d805de8c0299677d1037085f4272949da330ef/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/dec2e69624f46513d3200c23bec332a0cebb802c17a149d56eb13ddb5c9ee96b.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/nid989/EssayFroum-Dataset/resolve/73d805de8c0299677d1037085f4272949da330ef/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/dec2e69624f46513d3200c23bec332a0cebb802c17a149d56eb13ddb5c9ee96b.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a39f9264f89740d2b4087fbbb184019f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/nid989/EssayFroum-Dataset/resolve/73d805de8c0299677d1037085f4272949da330ef/README.md in cache at /root/.cache/huggingface/datasets/downloads/dec2e69624f46513d3200c23bec332a0cebb802c17a149d56eb13ddb5c9ee96b.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/nid989/EssayFroum-Dataset/resolve/73d805de8c0299677d1037085f4272949da330ef/README.md in cache at /root/.cache/huggingface/datasets/downloads/dec2e69624f46513d3200c23bec332a0cebb802c17a149d56eb13ddb5c9ee96b.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/dec2e69624f46513d3200c23bec332a0cebb802c17a149d56eb13ddb5c9ee96b.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/dec2e69624f46513d3200c23bec332a0cebb802c17a149d56eb13ddb5c9ee96b.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82\n",
            "Using custom data configuration default-37b2eeb461bc6060\n",
            "INFO:datasets.builder:Using custom data configuration default-37b2eeb461bc6060\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from nid989/EssayFroum-Dataset validation\n",
            "take 12 from nid989/EssayFroum-Dataset train\n",
            "Done getting streams/reloading from nid989/EssayFroum-Dataset\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying nlpaueb/finer-139 initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/finer-139.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a5fec3087527d120b900829086bbc4d8e59ba573cb38feaf605c2deb09f39a45.81e852345f8ad63ed894c4683d8245865735f379658add909f748da831df90f2.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/finer-139.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a5fec3087527d120b900829086bbc4d8e59ba573cb38feaf605c2deb09f39a45.81e852345f8ad63ed894c4683d8245865735f379658add909f748da831df90f2.py.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/19.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49d66e5bf4fe4bbfa8f0d34af9e57e37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/finer-139.py in cache at /root/.cache/huggingface/datasets/downloads/a5fec3087527d120b900829086bbc4d8e59ba573cb38feaf605c2deb09f39a45.81e852345f8ad63ed894c4683d8245865735f379658add909f748da831df90f2.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/finer-139.py in cache at /root/.cache/huggingface/datasets/downloads/a5fec3087527d120b900829086bbc4d8e59ba573cb38feaf605c2deb09f39a45.81e852345f8ad63ed894c4683d8245865735f379658add909f748da831df90f2.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/a5fec3087527d120b900829086bbc4d8e59ba573cb38feaf605c2deb09f39a45.81e852345f8ad63ed894c4683d8245865735f379658add909f748da831df90f2.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/a5fec3087527d120b900829086bbc4d8e59ba573cb38feaf605c2deb09f39a45.81e852345f8ad63ed894c4683d8245865735f379658add909f748da831df90f2.py\n",
            "https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/6522ce87565d0ff0d9c96d2955847214619b9655753105e29033512409f6512d.0c11b76f6b98fa7750ca92f7e3c85fe34138a9597dff3b8e83e679565acf526b.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/6522ce87565d0ff0d9c96d2955847214619b9655753105e29033512409f6512d.0c11b76f6b98fa7750ca92f7e3c85fe34138a9597dff3b8e83e679565acf526b.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/15.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9d69a9bcd2f4eaf8eea31db00e3331d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/6522ce87565d0ff0d9c96d2955847214619b9655753105e29033512409f6512d.0c11b76f6b98fa7750ca92f7e3c85fe34138a9597dff3b8e83e679565acf526b\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/6522ce87565d0ff0d9c96d2955847214619b9655753105e29033512409f6512d.0c11b76f6b98fa7750ca92f7e3c85fe34138a9597dff3b8e83e679565acf526b\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/6522ce87565d0ff0d9c96d2955847214619b9655753105e29033512409f6512d.0c11b76f6b98fa7750ca92f7e3c85fe34138a9597dff3b8e83e679565acf526b\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/6522ce87565d0ff0d9c96d2955847214619b9655753105e29033512409f6512d.0c11b76f6b98fa7750ca92f7e3c85fe34138a9597dff3b8e83e679565acf526b\n",
            "https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2ee93f905eda81763dc68760c00d6cffc70a2ce8e4f052b496333517b6cf2cd8.d5e853aa8948c6cccd2a8eb1c6ba85f5483087d9c9525e8d780e6f3594ae9139.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2ee93f905eda81763dc68760c00d6cffc70a2ce8e4f052b496333517b6cf2cd8.d5e853aa8948c6cccd2a8eb1c6ba85f5483087d9c9525e8d780e6f3594ae9139.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/9.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2d393d146434ccba6141c4de3177670"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/2ee93f905eda81763dc68760c00d6cffc70a2ce8e4f052b496333517b6cf2cd8.d5e853aa8948c6cccd2a8eb1c6ba85f5483087d9c9525e8d780e6f3594ae9139\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/nlpaueb/finer-139/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/2ee93f905eda81763dc68760c00d6cffc70a2ce8e4f052b496333517b6cf2cd8.d5e853aa8948c6cccd2a8eb1c6ba85f5483087d9c9525e8d780e6f3594ae9139\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/2ee93f905eda81763dc68760c00d6cffc70a2ce8e4f052b496333517b6cf2cd8.d5e853aa8948c6cccd2a8eb1c6ba85f5483087d9c9525e8d780e6f3594ae9139\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/2ee93f905eda81763dc68760c00d6cffc70a2ce8e4f052b496333517b6cf2cd8.d5e853aa8948c6cccd2a8eb1c6ba85f5483087d9c9525e8d780e6f3594ae9139\n",
            "No config specified, defaulting to the single config: finer-139/finer-139\n",
            "INFO:datasets.builder:No config specified, defaulting to the single config: finer-139/finer-139\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/nlpaueb--finer-139/5f5a8eb2a38e8b142bb8ca63f3f9600634cc6c8963e4c982926cf2b48e4e55ff\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/nlpaueb--finer-139/5f5a8eb2a38e8b142bb8ca63f3f9600634cc6c8963e4c982926cf2b48e4e55ff\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from nlpaueb/finer-139 validation\n",
            "take 17 from nlpaueb/finer-139 train\n",
            "Done getting streams/reloading from nlpaueb/finer-139\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying squad initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/squad/resolve/main/squad.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/86cbb67316ccaf9f769f141ddcba24adb96d8adde79e68aab51ec4a80b08b6af.121650427388673ffe2b913edcacf8f9873edf1c4d19761102687f28484e39a5.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/squad/resolve/main/squad.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/86cbb67316ccaf9f769f141ddcba24adb96d8adde79e68aab51ec4a80b08b6af.121650427388673ffe2b913edcacf8f9873edf1c4d19761102687f28484e39a5.py.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa681087d04342db816bf7871e46dcf3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/squad/resolve/main/squad.py in cache at /root/.cache/huggingface/datasets/downloads/86cbb67316ccaf9f769f141ddcba24adb96d8adde79e68aab51ec4a80b08b6af.121650427388673ffe2b913edcacf8f9873edf1c4d19761102687f28484e39a5.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/squad/resolve/main/squad.py in cache at /root/.cache/huggingface/datasets/downloads/86cbb67316ccaf9f769f141ddcba24adb96d8adde79e68aab51ec4a80b08b6af.121650427388673ffe2b913edcacf8f9873edf1c4d19761102687f28484e39a5.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/86cbb67316ccaf9f769f141ddcba24adb96d8adde79e68aab51ec4a80b08b6af.121650427388673ffe2b913edcacf8f9873edf1c4d19761102687f28484e39a5.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/86cbb67316ccaf9f769f141ddcba24adb96d8adde79e68aab51ec4a80b08b6af.121650427388673ffe2b913edcacf8f9873edf1c4d19761102687f28484e39a5.py\n",
            "https://huggingface.co/datasets/squad/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/e7830d4cb0750ec97f15dc68a057421d47be7b87942399068020c2a738d5691f.dbf664a8a4fbbcee29722cc663e703085eae5022d24daefc08d5cfcbe4085c0a.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/squad/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/e7830d4cb0750ec97f15dc68a057421d47be7b87942399068020c2a738d5691f.dbf664a8a4fbbcee29722cc663e703085eae5022d24daefc08d5cfcbe4085c0a.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.36k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67ea2c4aaab7448f89606660d35f561a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/squad/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/e7830d4cb0750ec97f15dc68a057421d47be7b87942399068020c2a738d5691f.dbf664a8a4fbbcee29722cc663e703085eae5022d24daefc08d5cfcbe4085c0a\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/squad/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/e7830d4cb0750ec97f15dc68a057421d47be7b87942399068020c2a738d5691f.dbf664a8a4fbbcee29722cc663e703085eae5022d24daefc08d5cfcbe4085c0a\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/e7830d4cb0750ec97f15dc68a057421d47be7b87942399068020c2a738d5691f.dbf664a8a4fbbcee29722cc663e703085eae5022d24daefc08d5cfcbe4085c0a\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/e7830d4cb0750ec97f15dc68a057421d47be7b87942399068020c2a738d5691f.dbf664a8a4fbbcee29722cc663e703085eae5022d24daefc08d5cfcbe4085c0a\n",
            "https://huggingface.co/datasets/squad/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/94fe703883a1850055695505cee42dcb38fbdbecd11abd45ef317f8650ecd86e.4810d3cc74275fb6a7b58ede6680c4b0bd760c8c0f507d71121fd6f66b8d68b9.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/squad/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/94fe703883a1850055695505cee42dcb38fbdbecd11abd45ef317f8650ecd86e.4810d3cc74275fb6a7b58ede6680c4b0bd760c8c0f507d71121fd6f66b8d68b9.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.67k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e27d08cc8224206b0f86bbc81c0a167"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/squad/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/94fe703883a1850055695505cee42dcb38fbdbecd11abd45ef317f8650ecd86e.4810d3cc74275fb6a7b58ede6680c4b0bd760c8c0f507d71121fd6f66b8d68b9\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/squad/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/94fe703883a1850055695505cee42dcb38fbdbecd11abd45ef317f8650ecd86e.4810d3cc74275fb6a7b58ede6680c4b0bd760c8c0f507d71121fd6f66b8d68b9\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/94fe703883a1850055695505cee42dcb38fbdbecd11abd45ef317f8650ecd86e.4810d3cc74275fb6a7b58ede6680c4b0bd760c8c0f507d71121fd6f66b8d68b9\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/94fe703883a1850055695505cee42dcb38fbdbecd11abd45ef317f8650ecd86e.4810d3cc74275fb6a7b58ede6680c4b0bd760c8c0f507d71121fd6f66b8d68b9\n",
            "No config specified, defaulting to the single config: squad/plain_text\n",
            "INFO:datasets.builder:No config specified, defaulting to the single config: squad/plain_text\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/squad/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/squad/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from squad validation\n",
            "take 26 from squad train\n",
            "Done getting streams/reloading from squad\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Pavithree/askHistorians initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/Pavithree/askHistorians/resolve/9603afe1e507fdc70f80ab3c532872fb217c7cc5/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7ec44ec396acd9ad13c3cdd6c95b3c15db399a5069b7a74995cd7a3a85fa1559.1d3d831df91fe91f2f89ca74f20f86b288cde58f4be1328c21c11155f35f83d0.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/Pavithree/askHistorians/resolve/9603afe1e507fdc70f80ab3c532872fb217c7cc5/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7ec44ec396acd9ad13c3cdd6c95b3c15db399a5069b7a74995cd7a3a85fa1559.1d3d831df91fe91f2f89ca74f20f86b288cde58f4be1328c21c11155f35f83d0.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2449243b56243e7bd3ae7bc2f4cde37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/Pavithree/askHistorians/resolve/9603afe1e507fdc70f80ab3c532872fb217c7cc5/README.md in cache at /root/.cache/huggingface/datasets/downloads/7ec44ec396acd9ad13c3cdd6c95b3c15db399a5069b7a74995cd7a3a85fa1559.1d3d831df91fe91f2f89ca74f20f86b288cde58f4be1328c21c11155f35f83d0\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/Pavithree/askHistorians/resolve/9603afe1e507fdc70f80ab3c532872fb217c7cc5/README.md in cache at /root/.cache/huggingface/datasets/downloads/7ec44ec396acd9ad13c3cdd6c95b3c15db399a5069b7a74995cd7a3a85fa1559.1d3d831df91fe91f2f89ca74f20f86b288cde58f4be1328c21c11155f35f83d0\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/7ec44ec396acd9ad13c3cdd6c95b3c15db399a5069b7a74995cd7a3a85fa1559.1d3d831df91fe91f2f89ca74f20f86b288cde58f4be1328c21c11155f35f83d0\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/7ec44ec396acd9ad13c3cdd6c95b3c15db399a5069b7a74995cd7a3a85fa1559.1d3d831df91fe91f2f89ca74f20f86b288cde58f4be1328c21c11155f35f83d0\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n",
            "Using custom data configuration default-3fe30420f15a402c\n",
            "INFO:datasets.builder:Using custom data configuration default-3fe30420f15a402c\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from Pavithree/askHistorians validation\n",
            "take 10 from Pavithree/askHistorians train\n",
            "Done getting streams/reloading from Pavithree/askHistorians\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Isotonic/human_assistant_conversation initialization (shuffling through 3 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/Isotonic/human_assistant_conversation/resolve/eefe292fe4eec3bcc82a59c662bb8380510356cf/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/fe95c9902b07c6b2cb2d2edf583bbc21e15a8fb4ca50eba9d074802440406657.6aecf67d425d2fce014536356acafbab7380a685f31a9847397474162e187ac2.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/Isotonic/human_assistant_conversation/resolve/eefe292fe4eec3bcc82a59c662bb8380510356cf/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/fe95c9902b07c6b2cb2d2edf583bbc21e15a8fb4ca50eba9d074802440406657.6aecf67d425d2fce014536356acafbab7380a685f31a9847397474162e187ac2.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b74c9d9355a4bf19152b5a41e999a34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/Isotonic/human_assistant_conversation/resolve/eefe292fe4eec3bcc82a59c662bb8380510356cf/README.md in cache at /root/.cache/huggingface/datasets/downloads/fe95c9902b07c6b2cb2d2edf583bbc21e15a8fb4ca50eba9d074802440406657.6aecf67d425d2fce014536356acafbab7380a685f31a9847397474162e187ac2\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/Isotonic/human_assistant_conversation/resolve/eefe292fe4eec3bcc82a59c662bb8380510356cf/README.md in cache at /root/.cache/huggingface/datasets/downloads/fe95c9902b07c6b2cb2d2edf583bbc21e15a8fb4ca50eba9d074802440406657.6aecf67d425d2fce014536356acafbab7380a685f31a9847397474162e187ac2\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/fe95c9902b07c6b2cb2d2edf583bbc21e15a8fb4ca50eba9d074802440406657.6aecf67d425d2fce014536356acafbab7380a685f31a9847397474162e187ac2\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/fe95c9902b07c6b2cb2d2edf583bbc21e15a8fb4ca50eba9d074802440406657.6aecf67d425d2fce014536356acafbab7380a685f31a9847397474162e187ac2\n",
            "Using custom data configuration default-357d28bd1fcd172c\n",
            "INFO:datasets.builder:Using custom data configuration default-357d28bd1fcd172c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from Isotonic/human_assistant_conversation validation\n",
            "take 17 from Isotonic/human_assistant_conversation training\n",
            "Done getting streams/reloading from Isotonic/human_assistant_conversation\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying albertvillanova/legal_contracts initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/albertvillanova--legal_contracts/fdb450d43ecae9e66d9f6dcf189b79a6b75059ce81f948673512b81b5146bfc1\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/albertvillanova--legal_contracts/fdb450d43ecae9e66d9f6dcf189b79a6b75059ce81f948673512b81b5146bfc1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 1 from albertvillanova/legal_contracts validation\n",
            "take 17 from albertvillanova/legal_contracts train\n",
            "Done getting streams/reloading from albertvillanova/legal_contracts\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "Done collecting streaming data\n",
            "saving streamed validation data: cache_val_mlm.pkl\n",
            "saving streamed training for epoch 1: cache_train_mlm_001.pkl\n"
          ]
        }
      ],
      "source": [
        "data_streaming_config_mlm = {\n",
        "    'files':mlm_files,\n",
        "    'val_size':10, #2000,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':2000,\n",
        "    'max_chunk_start':1000000,\n",
        "    \"seed\":42,\n",
        "}\n",
        "\n",
        "#!rm cache_*\n",
        "dataset_static_mlm = initialize_and_get_mlm_streaming_datasets(\n",
        "    data_streaming_config=data_streaming_config_mlm,\n",
        "    streaming_cleaning_functions=mlm_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=1,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_mlm.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_mlm_%03g.pkl',\n",
        "    do_check_english = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr9pqs6AmG3D",
        "outputId": "3ae6d527-bb61-4a7f-94b3-036312063f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "   \"EleutherAI/the_pile_deduplicated\": 0.1413,\n",
            "   \"tiiuae/falcon-refinedweb\": 0.1142,\n",
            "   \"Skylion007/openwebtext\": 0.0395,\n",
            "   \"Cohere/wikipedia-22-12\": 0.123,\n",
            "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 0.0796,\n",
            "   \"nRuaif/book2-lite-cleaned\": 0.0744,\n",
            "   \"macrocosm/arxiv_abstracts\": 0.0199,\n",
            "   \"big_patent\": 0.0059,\n",
            "   \"pile-of-law/pile-of-law/euro_parl\": 0.0144,\n",
            "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 0.0222,\n",
            "   \"pile-of-law/pile-of-law/r_legaladvice\": 0.0101,\n",
            "   \"pile-of-law/pile-of-law/exam_outlines\": 0.0069,\n",
            "   \"pile-of-law/pile-of-law/cc_casebooks\": 0.0209,\n",
            "   \"eloukas/edgar-corpus\": 0.0516,\n",
            "   \"Rahmaa/ElsevieR_ClEaN\": 0.0477,\n",
            "   \"ashraq/financial-news-articles\": 0.0065,\n",
            "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 0.0173,\n",
            "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 0.0176,\n",
            "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 0.0206,\n",
            "   \"launch/gov_report\": 0.0186,\n",
            "   \"izumi-lab/open-text-books\": 0.0173,\n",
            "   \"Skelebor/book_titles_and_descriptions\": 0.0098,\n",
            "   \"joelito/legal_case_document_summarization\": 0.0144,\n",
            "   \"joelito/legal-mc4/en\": 0.0199,\n",
            "   \"Hellisotherpeople/DebateSum\": 0.0134,\n",
            "   \"lukesjordan/worldbank-project-documents\": 0.0134,\n",
            "   \"64bits/lex_fridman_podcast_for_llm_vicuna\": 0.0069,\n",
            "   \"nid989/EssayFroum-Dataset\": 0.0042,\n",
            "   \"nlpaueb/finer-139\": 0.0039,\n",
            "   \"squad\": 0.0088,\n",
            "   \"Pavithree/askHistorians\": 0.0082,\n",
            "   \"Isotonic/human_assistant_conversation\": 0.0049,\n",
            "   \"albertvillanova/legal_contracts\": 0.0228\n",
            "}\n",
            "TRAIN\n",
            "{\n",
            "   \"EleutherAI/the_pile_deduplicated\": 428,\n",
            "   \"tiiuae/falcon-refinedweb\": 349,\n",
            "   \"Skylion007/openwebtext\": 119,\n",
            "   \"Cohere/wikipedia-22-12\": 376,\n",
            "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 238,\n",
            "   \"nRuaif/book2-lite-cleaned\": 226,\n",
            "   \"macrocosm/arxiv_abstracts\": 60,\n",
            "   \"big_patent\": 13,\n",
            "   \"pile-of-law/pile-of-law/euro_parl\": 41,\n",
            "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 68,\n",
            "   \"pile-of-law/pile-of-law/r_legaladvice\": 30,\n",
            "   \"pile-of-law/pile-of-law/exam_outlines\": 14,\n",
            "   \"pile-of-law/pile-of-law/cc_casebooks\": 57,\n",
            "   \"eloukas/edgar-corpus\": 157,\n",
            "   \"Rahmaa/ElsevieR_ClEaN\": 145,\n",
            "   \"ashraq/financial-news-articles\": 19,\n",
            "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 52,\n",
            "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 51,\n",
            "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 56,\n",
            "   \"launch/gov_report\": 50,\n",
            "   \"izumi-lab/open-text-books\": 52,\n",
            "   \"Skelebor/book_titles_and_descriptions\": 29,\n",
            "   \"joelito/legal_case_document_summarization\": 43,\n",
            "   \"joelito/legal-mc4/en\": 54,\n",
            "   \"Hellisotherpeople/DebateSum\": 40,\n",
            "   \"lukesjordan/worldbank-project-documents\": 34,\n",
            "   \"64bits/lex_fridman_podcast_for_llm_vicuna\": 19,\n",
            "   \"nid989/EssayFroum-Dataset\": 12,\n",
            "   \"nlpaueb/finer-139\": 11,\n",
            "   \"squad\": 26,\n",
            "   \"Pavithree/askHistorians\": 23,\n",
            "   \"Isotonic/human_assistant_conversation\": 15,\n",
            "   \"albertvillanova/legal_contracts\": 64\n",
            "}\n",
            "VAL\n",
            "{\n",
            "   \"EleutherAI/the_pile_deduplicated\": 5,\n",
            "   \"tiiuae/falcon-refinedweb\": 1,\n",
            "   \"Skylion007/openwebtext\": 2,\n",
            "   \"Cohere/wikipedia-22-12\": 1,\n",
            "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 6,\n",
            "   \"nRuaif/book2-lite-cleaned\": 2,\n",
            "   \"macrocosm/arxiv_abstracts\": 1,\n",
            "   \"big_patent\": 5,\n",
            "   \"pile-of-law/pile-of-law/euro_parl\": 3,\n",
            "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 0,\n",
            "   \"pile-of-law/pile-of-law/r_legaladvice\": 1,\n",
            "   \"pile-of-law/pile-of-law/exam_outlines\": 7,\n",
            "   \"pile-of-law/pile-of-law/cc_casebooks\": 7,\n",
            "   \"eloukas/edgar-corpus\": 1,\n",
            "   \"Rahmaa/ElsevieR_ClEaN\": 1,\n",
            "   \"ashraq/financial-news-articles\": 1,\n",
            "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 1,\n",
            "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 3,\n",
            "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 7,\n",
            "   \"launch/gov_report\": 7,\n",
            "   \"izumi-lab/open-text-books\": 1,\n",
            "   \"Skelebor/book_titles_and_descriptions\": 1,\n",
            "   \"joelito/legal_case_document_summarization\": 1,\n",
            "   \"joelito/legal-mc4/en\": 7,\n",
            "   \"Hellisotherpeople/DebateSum\": 1,\n",
            "   \"lukesjordan/worldbank-project-documents\": 7,\n",
            "   \"64bits/lex_fridman_podcast_for_llm_vicuna\": 2,\n",
            "   \"nid989/EssayFroum-Dataset\": 1,\n",
            "   \"nlpaueb/finer-139\": 1,\n",
            "   \"squad\": 1,\n",
            "   \"Pavithree/askHistorians\": 2,\n",
            "   \"Isotonic/human_assistant_conversation\": 0,\n",
            "   \"albertvillanova/legal_contracts\": 6\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "sums = {}\n",
        "for setnm,setcnt in dataset_static_mlm['log_source'].items():\n",
        "    #if setnm=='train':\n",
        "    #    continue\n",
        "    for dnm,dcnt in setcnt.items():\n",
        "        if dnm not in sums: sums[dnm]=0\n",
        "        sums[dnm]+=dcnt\n",
        "print(json.dumps({k:round(v/sum([a for a in sums.values()]),4) for k,v in sums.items()},indent=3))\n",
        "\n",
        "#dataset_static_mlm['log_source']\n",
        "\n",
        "print('TRAIN')\n",
        "print(json.dumps(dataset_static_mlm['log_source']['train'],indent=3))\n",
        "print('VAL')\n",
        "print(json.dumps(dataset_static_mlm['log_source']['val'],indent=3))\n",
        "\n",
        "# epoch 0\n",
        "epoch_1 = {\n",
        "   \"EleutherAI/the_pile_deduplicated\": 0.1413,\n",
        "   \"tiiuae/falcon-refinedweb\": 0.1142,\n",
        "   \"Skylion007/openwebtext\": 0.0395,\n",
        "   \"Cohere/wikipedia-22-12\": 0.123,\n",
        "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 0.0796,\n",
        "   \"nRuaif/book2-lite-cleaned\": 0.0744,\n",
        "   \"macrocosm/arxiv_abstracts\": 0.0199,\n",
        "   \"big_patent\": 0.0059,\n",
        "   \"pile-of-law/pile-of-law/euro_parl\": 0.0144,\n",
        "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 0.0222,\n",
        "   \"pile-of-law/pile-of-law/r_legaladvice\": 0.0101,\n",
        "   \"pile-of-law/pile-of-law/exam_outlines\": 0.0069,\n",
        "   \"pile-of-law/pile-of-law/cc_casebooks\": 0.0209,\n",
        "   \"eloukas/edgar-corpus\": 0.0516,\n",
        "   \"Rahmaa/ElsevieR_ClEaN\": 0.0477,\n",
        "   \"ashraq/financial-news-articles\": 0.0065,\n",
        "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 0.0173,\n",
        "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 0.0176,\n",
        "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 0.0206,\n",
        "   \"launch/gov_report\": 0.0186,\n",
        "   \"izumi-lab/open-text-books\": 0.0173,\n",
        "   \"Skelebor/book_titles_and_descriptions\": 0.0098,\n",
        "   \"joelito/legal_case_document_summarization\": 0.0144,\n",
        "   \"joelito/legal-mc4/en\": 0.0199,\n",
        "   \"Hellisotherpeople/DebateSum\": 0.0134,\n",
        "   \"lukesjordan/worldbank-project-documents\": 0.0134,\n",
        "   \"64bits/lex_fridman_podcast_for_llm_vicuna\": 0.0069,\n",
        "   \"nid989/EssayFroum-Dataset\": 0.0042,\n",
        "   \"nlpaueb/finer-139\": 0.0039,\n",
        "   \"squad\": 0.0088,\n",
        "   \"Pavithree/askHistorians\": 0.0082,\n",
        "   \"Isotonic/human_assistant_conversation\": 0.0049,\n",
        "   \"albertvillanova/legal_contracts\": 0.0228\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nKlnrcC3G9n",
        "outputId": "22b00d79-2687-46f8-abb8-c60a6269ddb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Facts This memo relies on facts provided by the taxpayer and available in the public records.\n",
            " Taxpayer manufactures Product and i\n",
            "s based in City, State X. States X, Y, and Z filed suit against Taxpayer in the federal court accusing it of fixing a minimum pric\n",
            "e for one of its more sought-after products. According to the complaint, Taxpayer engaged in anti-competitive practices in order t\n",
            "o discourage price competition among retailers and keep prices higher than they otherwise would be. Taxpayer’s alleged policy expl\n",
            "icitly forbade retailers from advertising Product below a dictated price. If any retailer violated the price policy, they would lo\n",
            "se access to Taxpayer’s products for one year. This penalty was allegedly enforced against some retailers; however, Taxpayer often\n",
            " resumed its relationship with the retailers before the end of the one year embargo.\n",
            " The states alleged that this was an anti-com\n",
            "petitive practice, preventing customers from purchasing low-priced Products, and preventing vendors from setting prices that they \n",
            "wanted to set. The states sought an injunction against Taxpayer, as well as civil penalties.\n",
            " After the anti-trust suit was filed,\n",
            " the parties filed a consent decree and final judgment. In it, Taxpayer agreed to an injunction against dictating the price of its\n",
            " Products to retailers. It also agreed to pay $amount1 to the states, to be used in each state by its attorney general for anti-tr\n",
            "ust enforcement, a consumer protection fund, or any other function allowable under state law.\n",
            "  PREF-123891-07  Taxpayer had certa\n",
            "in additional duties, such as maintenance of certain sale records. The district court retained jurisdiction to enforce the decree,\n",
            " and Taxpayer admitted no true liability, claiming that the consent judgment could not be used in any other proceeding to show its\n",
            " guilt.\n",
            "  Analysis of Relevant Statutes Underlying the Payment I.R.C. § 162(a) allows a deduction for any ordinary and necessary b\n",
            "usiness expenses paid during the course of a taxable year. However, section 162(f) provides that fines and penalties paid to any g\n",
            "overnment for violation of the law are not a deductible expense. Courts generally differentiate between amounts paid as a fine and\n",
            " money paid as damages, with money paid as damages being deductible as an ordinary business expense. See, e.g., Schnadig Corp. v. \n",
            "Gaines Manufacturing Co., 620 F.2d 1166, 1169 n.7 (6th Cir. 1980); see also Treas. Reg. § 1.162-21, examples (1) and (3). Finally,\n",
            " the income tax regulations state that a fine or similar penalty includes any amount paid in settlement of the taxpayer’s conduct \n",
            "or potential liability for a fine or penalty, whether civil or criminal. Treas. Reg. § 1.162-21(b)(1).\n",
            " When a civil settlement pa\n",
            "yment is at issue, it is first necessary to determine whether the payment constitutes a fine or penalty, or some other type of dam\n",
            "ages.\n"
          ]
        }
      ],
      "source": [
        "#!rm *.pkl\n",
        "def insert_newlines(text, chars_per_line=130):\n",
        "    return '\\n'.join(text[i:i+chars_per_line] for i in range(0, len(text), chars_per_line))\n",
        "\n",
        "np.random.choice(dataset_static_mlm['train']['nextsentence'])\n",
        "print(insert_newlines(np.random.choice(dataset_static_mlm['train']['mlm'])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCG8JHCz3Xzp"
      },
      "source": [
        "\n",
        "### Q&A Triplets!\n",
        "\n",
        "Here I make a triplet dataset of query, positive answer, and negatives (if available)\n",
        "\n",
        "B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- DONE LLukas22/lfqa_preprocessed - question and answers 226k (from REDDIT)\n",
        "- DONE gbharti/finance-alpaca (like FIQA - finance Q&A) on 14k?\n",
        "- DONE embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- GONE the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- DONE donfu/oa-stackexchange - 6.3 million (AND GROWING -- must monitor)\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- DONE sciq - science questions - see question and support\n",
        "- DONE wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers\n",
        "- DONE JoBeer/eclassTrainST - can easily convert into question-answer pairs\n",
        "- DONE - dictinonary -\n",
        "- DONE POLICY QA - alzoubi36/policy_qa (has contracts and questions about contract)\n",
        "=ra)\n",
        "- DONE sc2qa/sc2q_commoncrawl - qa on common crawl with 45k\n",
        "- DONE: yahoo_answers_topics (filter for 6=business; 3=education; 9=govt)\n",
        "- TODO: wikihow:\n",
        "-- need to save locally, then I think it can be streamed. Need to follow it's internal instructions\n",
        "-- urllib.request.urlretrieve('https://public.boxcloud.com/d/1/b1!_xh0QGyf95mEUFLjiTuiMfD08KRjjfr5iLY8-codMzDJX8aMjQ4l8HqGYMVmT_OkhEHzS5cTD2PWy54NII7Egr9sotD9S17Pbf1ZmFeG7Rslpq-bLO7cpMBCHzDMUUahQqPX8bi42hrdxHBSIECK46tb1eum9GySp39bgzW5I0HckhGWzIPU3XeAdZ3IY38MVTVFqo5Y_CAfAwBbuN-ZSX7h3oJ3UzNqeGdCMfkBfQNcPgd0Hs283KDUEH0ZL4X7dwsakK5NyKcyiyZ5iwrCkTXzDksrf4ezJOPtRWlPVNsuq0PRuUOrLF-ynXQJglhqUtlXPwVPZ5FuhggADk5vCTDZRdBsIodyLdin8h8hwcYLEUTXBlMNKsrlmMmwsWluTxtlDoSbD41bp8YNW8bB50-dDBasJd6YjbKf7FpyH-RZh6LEr4VqJhX8BYwJD6jqKjtfKgY4QWqsczY1DN0W8aOkgRjqdUUjVNcM36Be-ueqP6fN0GkWC-jEEY7uwjp2imOQRd_CccvfEVvndJI2vhm4YSbwcnCWkX_-weiUtiebMBL-K8t7KLzw0J2frAZeKKKvLGwfZ3pactzK__XRMRiFwL5sRttWd2ctcgNs8VXGxd_XLxMBiyJutZtmdCyv00QuOL8H_t-Kld5n7dltppTU6h-b0zCoYDnM14yZYqDkQ-TSf1UVJUqwcyjLaHS357iFaJmRK5KwA5yc15sKZuh26KBmAia-XcElWfdoqbhzJhzDcBzdaPFWulYzTkdVY42sFBUI_ZBwKaMTDDddr1nMdagiJeTIPZ4XBJnEa8nLiXiozWB7wfn7Ce-aRoZ7Prf3chnflmiaI6dLP4LAYomD3EI9rtPzWmBCg6Gp9ASriydlLtHzmD_lHVacoax0y0Mft2EWf3ClyjhsQJo8cpL3vw0-69ol6MLvXgygOZWfEmhDBA5gClHuUjMRIVJnkc4sJryXi7Mnhjnx0B7uWKNWj-J2P-A8zEg4371Do6QJcrVvmCkGVxo71iErLfAjBU__KyZmSQ221vp9NJjqXJBTwivUtOXSF98sKoYfCC2AT0_Umq_qx4m3ucyYnwVeeV09_oMmtZOtnhcNV_cMNerTGk6qP54u9JlImevbd289CT5urlCxham79o8Aaxz1An__gofnL7_ZLF2lhT7X-S6e0gDMUjk73JusvbyWW8DhqbnUZ-obcI33qGl9AJzLM35nI5mO-WPEYgE-Z1DTKA../download', '/tmp/foo.zip')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413,
          "referenced_widgets": [
            "28bdf044d9024408a8b4a6f3cc505748",
            "34a8cfafe1bc4238a2a116174db03e1e",
            "c7604f7b41634f399d7fd9679d60249d",
            "80c60ec5370b43f6af463b423b2347ad",
            "fcc30c1acb1c4a56bbc8073ad62ebb28",
            "3f51615acde94be09f55514e093cf519",
            "75f170ac22714d0e99a7352ded1e1883",
            "e249071708804c639b98995cbb41b87a",
            "f3362036276142d0af7b51e1063a27ad",
            "488b10e044734b6caae8592d3ca26175",
            "f1290a1555b84986a0844537c8d12fb7",
            "181c013896b2460b93dc1448412aa33c",
            "de026e05560e4479b03704360b9b0a7f",
            "fec2aac9e79e41ee8666b5d9e5249a9f",
            "123672337d6a49fa9c22b12fa2d4cddf",
            "b482a226af9f4732aee7949a906c033c",
            "207580ca79744d03ae025e5978364a49",
            "94e74ba60c864870b85a63df3fed3795",
            "bd0230611a6242d68e7fd06ebf8f7e3a",
            "ab7968a49db04ce0afbcc0df78c9db41",
            "93ef3f004b2f4ff89c21d2b44cca05fa",
            "a4cd2c94997947a892a656afc0526b04"
          ]
        },
        "id": "q96FHzngk0FH",
        "outputId": "4f30a205-9686-4781-8320-e004dffac859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/gov_report_qs.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/c07298c715d56a2e2a365a9d17248c047537e0a20eb5395b6b5c876c5ee69c24.d6843a5e64f4465492599bbda4467dc6175d23754e2bd48960a09e13fa2421c0.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/gov_report_qs.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/c07298c715d56a2e2a365a9d17248c047537e0a20eb5395b6b5c876c5ee69c24.d6843a5e64f4465492599bbda4467dc6175d23754e2bd48960a09e13fa2421c0.py.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/13.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28bdf044d9024408a8b4a6f3cc505748"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/gov_report_qs.py in cache at /root/.cache/huggingface/datasets/downloads/c07298c715d56a2e2a365a9d17248c047537e0a20eb5395b6b5c876c5ee69c24.d6843a5e64f4465492599bbda4467dc6175d23754e2bd48960a09e13fa2421c0.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/gov_report_qs.py in cache at /root/.cache/huggingface/datasets/downloads/c07298c715d56a2e2a365a9d17248c047537e0a20eb5395b6b5c876c5ee69c24.d6843a5e64f4465492599bbda4467dc6175d23754e2bd48960a09e13fa2421c0.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/c07298c715d56a2e2a365a9d17248c047537e0a20eb5395b6b5c876c5ee69c24.d6843a5e64f4465492599bbda4467dc6175d23754e2bd48960a09e13fa2421c0.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/c07298c715d56a2e2a365a9d17248c047537e0a20eb5395b6b5c876c5ee69c24.d6843a5e64f4465492599bbda4467dc6175d23754e2bd48960a09e13fa2421c0.py\n",
            "https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/b8456fbad33d1aeb4d6ae6d786a851ebf9bfb8ab08c4f56d4c18c3f0835d5b1b.537ee53f0a040d3cfff696ab5e04fe3d5a351779417a4280df1a2c31d38e5eca.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/b8456fbad33d1aeb4d6ae6d786a851ebf9bfb8ab08c4f56d4c18c3f0835d5b1b.537ee53f0a040d3cfff696ab5e04fe3d5a351779417a4280df1a2c31d38e5eca.incomplete\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "181c013896b2460b93dc1448412aa33c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/b8456fbad33d1aeb4d6ae6d786a851ebf9bfb8ab08c4f56d4c18c3f0835d5b1b.537ee53f0a040d3cfff696ab5e04fe3d5a351779417a4280df1a2c31d38e5eca\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/launch/gov_report_qs/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/b8456fbad33d1aeb4d6ae6d786a851ebf9bfb8ab08c4f56d4c18c3f0835d5b1b.537ee53f0a040d3cfff696ab5e04fe3d5a351779417a4280df1a2c31d38e5eca\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/b8456fbad33d1aeb4d6ae6d786a851ebf9bfb8ab08c4f56d4c18c3f0835d5b1b.537ee53f0a040d3cfff696ab5e04fe3d5a351779417a4280df1a2c31d38e5eca\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/b8456fbad33d1aeb4d6ae6d786a851ebf9bfb8ab08c4f56d4c18c3f0835d5b1b.537ee53f0a040d3cfff696ab5e04fe3d5a351779417a4280df1a2c31d38e5eca\n",
            "No config specified, defaulting to: gov_report_qs/paragraph\n",
            "INFO:datasets.builder:No config specified, defaulting to: gov_report_qs/paragraph\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report_qs/bb5dd166005269e4124933219e1def95272a1197dde526383d05c88cc83548d2\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report_qs/bb5dd166005269e4124933219e1def95272a1197dde526383d05c88cc83548d2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doc_id': 'CRS_R43130', 'summary_paragraph_index': 3, 'document_sections': {'title': ['Politics and Governance Under President Zuma', 'Governance Challenges', 'Youth Population: Political Potential and Character'], 'paragraphs': [\"The ANC has held a large majority in the National Assembly (parliament) since the first universal suffrage elections in 1994, and currently holds a majority just shy of the two-thirds required to amend the constitution. The parliament elects the country's president and, as a result, the ANC has controlled the executive branch since 1994. The ANC customarily nominates its party president to serve as national president, with some exceptions (see textbox below). The assembly elected the incumbent ANC president, Jacob Zuma, to his first term as national president in 2009.\\nDespite rising criticism of Zuma and internal party challenges to his candidacy, Zuma mounted a carefully crafted, successful campaign to ensure his reelection as head of the ANC at a late 2012 ANC party congress. He easily thwarted a belated and reportedly ill-coordinated rival bid by his deputy, Kgalema Motlanthe. Zuma's election as head of the ANC means that he is almost certain to win a second term as South Africa's president.\", \"While the challenges identified and solutions offered by the NDP are the product of sober public policy analyses and planning, they also reflect a politically realistic self-assessment by the government; its findings dovetail with the views of many government and ANC critics. This is particularly true of unemployment, lack of educational and healthcare access, poor public service delivery, crime, and corruption, which are notable sources of widespread public anger. A wave of often violent mass labor strikes in 2012 was accompanied by a sharp rise in protests over inadequate township service delivery in 2012. At least 226 such protests occurred during the first eight months of 2012 and, as with labor protests, many were violent. Such protests have been common for many years but have steadily risen. Ineffective police responses or other actual or perceived failures by the criminal justice system have also often been the focus on local protests in recent years. In some instances, protests turn into acts of vigilante justice (e.g., lynchings and extra-judicial mob beatings or killings of suspected criminals).\\nCorruption by economic elites, including some senior ANC members, of policies aimed at reversing the economic inequalities of the apartheid era has also stirred resentment. The same is true of the ANC's reportedly often politicized management of public goods and services, which frequently appears to financially benefit its local or national leaders, their kin, or associates. Such practices and the local political violence that they may generate are a reflection of the dearth of economic opportunities for blacks. For blacks with limited education and job prospects, local government posts gained through party ties may be one of the few ways out of poverty. Such actions often breed antipathy, however. According to one writer:\\nLocal protests, in which [the ANC's] own members are participants, are increasingly hard to manage. While in the past, protestors symbolically burned public property, targets are now the homes, cars and persons of ANC councilors. ANC branch and regional politics has become dirty and violent, with some members carrying firearms to meetings and attacks and shootings of local leaders are not infrequent.\", 'Another long-term challenge for the ANC government stems from South Africa\\'s large youth population, especially those born after 1994. Dubbed the \"born free\" generation, they comprise about 38% of the population and have always lived in a democracy. Of this age cohort, nearly 2 million (almost 10% of the potential electorate) will be eligible to vote for the first time in the 2014 elections. The group will make up nearly 23% of eligible voters in the 2019 elections (when the entire generation will make up 48% of the population). Adults under 35 years of age suffer especially high unemployment rates, estimated at over 50%. The \"born-free\" group shares frustrations with older generations over corruption, lack of services, and poverty, but many are reportedly not party-affiliated and lack older generations\\' continuing allegiance and gratitude to the ANC for its role in ending apartheid. Generational rifts have recently been on display within the ANC Youth League (ANCYL) in relation to the ANC\\'s expulsion of the fiery, populist former ANCYL leader, Julius Malema. Youth also participate in more service protests than do older generations, but reportedly vote less often than their elders, which may attenuate their potential electoral influence. To cater to youth demands, political parties have vied to introduce state youth wage and jobs schemes (often in the face of union opposition), expanded skills training programs, and youth-friendly procurement and hiring preferences.'], 'depth': [1, 2, 3]}, 'question_summary_pairs': {'question': ['What did the ANC party do in late 2012?', 'What challenges does the ANC government face?', 'Why are youths dissatisfied with the ANC?', 'How is the government trying to address these challenges?'], 'summary': ['In late 2012, the governing African National Congress (ANC) party, despite some reported internal divisions, reelected as its president Jacob Zuma, ahead of the May 2014 national elections.', 'The ANC government faces the substantial challenges noted above, along with others, including labor unrest, rising dissatisfaction within key labor constituencies, and dissatisfaction among youths.', \"Youth populations face particularly high jobless rates and may lack older generations' continuing allegiance and gratitude to the ANC for helping to end apartheid.\", 'To address these diverse challenges, all of which are electoral issues, the government is investing billions of dollars to upgrade infrastructure and improve public service delivery, but is likely to face continuing challenges in meeting popular expectations.'], 'parent_pair_index': [-1, -1, 1, 1]}, 'query': 'what did the ANC party do in late 2012, what challenges does the ANC government face, and why are youths dissatisfied with the ANC?', 'positives': [\"In late 2012, the governing African National Congress (ANC) party, despite some reported internal divisions, reelected as its president Jacob Zuma, ahead of the May 2014 national elections. The ANC government faces the substantial challenges noted above, along with others, including labor unrest, rising dissatisfaction within key labor constituencies, and dissatisfaction among youths. Youth populations face particularly high jobless rates and may lack older generations' continuing allegiance and gratitude to the ANC for helping to end apartheid. To address these diverse challenges, all of which are electoral issues, the government is investing billions of dollars to upgrade infrastructure and improve public service delivery, but is likely to face continuing challenges in meeting popular expectations.\"], 'negatives': []}\n",
            "dict_keys(['doc_id', 'summary_paragraph_index', 'document_sections', 'question_summary_pairs', 'query', 'positives', 'negatives'])\n"
          ]
        }
      ],
      "source": [
        "#JoBeer/eclassTrainST\n",
        "#foo =  load_dataset('gart-labor/eclassTrainST',split='train',streaming=True).map(clean_eclassTrainST).remove_columns(['text', 'entailment', 'contradiction', 'label'])\n",
        "#foo =  load_dataset('gbharti/finance-alpaca',split='train',streaming=True)  # good, financial questions\n",
        "#foo =  load_dataset('gart-labor/eclassTrainST',split='train',streaming=True) # NAD; just for paraphrased questions, not for QA\n",
        "# foo =  load_dataset('parquet',data_files = 'https://huggingface.co/datasets/gart-labor/eclassTrainST/resolve/main/data/eval-00001-of-00001-d8aa08935841e6a9.parquet',split='train',streaming=False) # NAD; just for paraphrased questions, not for QA\n",
        "#foo =  load_dataset('wiki_qa',split='train',streaming=True) # excellent; with negatives and positives\n",
        "#foo =  load_dataset('THUDM/webglm-qa',split='train',streaming=True) # excellent; with negatives and positives\n",
        "#foo = load_dataset(\"sciq\",split='train',streaming=False) #\n",
        "#foo = load_dataset(\"LLukas22/lfqa_preprocessed\", split='train',streaming=True)\n",
        "\n",
        "def clean_govreportqa(x):\n",
        "    q_raw = x['question_summary_pairs']['question']\n",
        "    a_raw = x['question_summary_pairs']['summary']\n",
        "    if len(q_raw)==1:\n",
        "        q_concat = q_raw[0]\n",
        "        a_concat = a_raw[0]\n",
        "    elif len(q_raw)<=3 and len(q_raw)>1:\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    else:\n",
        "        q_raw = q_raw[:2] + [random.choice(q_raw[2:])]\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    x['query']=q_concat\n",
        "    x['positives']=[a_concat]\n",
        "    x['negatives']=[]\n",
        "    return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "RHB8cc5SmXFL"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data as torch_data\n",
        "from rank_bm25 import BM25Okapi\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABJazLSA3WTz",
        "outputId": "1d7fc76b-6ea8-4e75-e00b-0968aa5b81d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TODO:\n",
            "Blacks law: try streaming this CSV file (or just get it):\n",
            "https://raw.githubusercontent.com/LexPredict/lexpredict-legal-dictionary/master/sources/blacks_second_edition/blacks_second_edition_terms.csv\n",
            "And probably filter for length, add a context\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\"\"TODO:\n",
        "Blacks law: try streaming this CSV file (or just get it):\n",
        "https://raw.githubusercontent.com/LexPredict/lexpredict-legal-dictionary/master/sources/blacks_second_edition/blacks_second_edition_terms.csv\n",
        "And probably filter for length, add a context\n",
        "\"\"\") # nah it is really dirty\n",
        "\n",
        "def clean_govreportqa(x):\n",
        "    q_raw = x['question_summary_pairs']['question']\n",
        "    a_raw = x['question_summary_pairs']['summary']\n",
        "    if len(q_raw)==1:\n",
        "        q_concat = q_raw[0]\n",
        "        a_concat = a_raw[0]\n",
        "    elif len(q_raw)<=3 and len(q_raw)>1:\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    else:\n",
        "        q_raw = q_raw[:2] + [random.choice(q_raw[2:])]\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    x['query']=q_concat\n",
        "    x['positives']=[a_concat]\n",
        "    x['negatives']=[]\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "POLICYQA_PREPEND = [\n",
        "    \"Regarding the online Terms of Service and Data Protection policies: %s\",\n",
        "    \"Considering your data security, %s\",\n",
        "    \"With respect to user privacy guidelines, %s\",\n",
        "    \"As outlined in the data protection commitments, %s\",\n",
        "    \"Pertaining to the terms of service, %s\",\n",
        "    \"Addressing information usage, %s\",\n",
        "    \"Pertaining to data confidentiality, %s\",\n",
        "    \"In connection to your privacy assurance, %s\",\n",
        "    \"Touching upon online data policies, %s\",\n",
        "    \"In alignment with your user data safeguards, %s\",\n",
        "    \"Taking a closer look at data security, %s\",\n",
        "    \"In light of your user-information protocols, %s\",\n",
        "    \"Within the context of user data sharing, %s\",\n",
        "    \"In consideration for user data ownership, %s\",\n",
        "    \"In consideration of data securty and user-data protection, %s\",\n",
        "    \"In regards to your online services, %s\",\n",
        "    \"Regarding your data handling procedures and policies, %s\",\n",
        "    \"In the context of user information disclosure and privacy, %s\",\n",
        "    \"As per the information security policies, %s\",\n",
        "    \"In the context of the Terms of Service: %s\",\n",
        "    \"%s (in the context of your online Terms of Service)\"\n",
        "]\n",
        "\n",
        "STACKEXCHANGE_NONQUANT_DOMAINS = [\n",
        "    \"stackexchange-\"+k for k in [\n",
        "        \"academia\",\n",
        "        \"aviation\",\n",
        "        \"bicycles\",\n",
        "        \"biology\",\n",
        "        \"buddhism\",\n",
        "        \"chemistry\",\n",
        "        \"chess\",\n",
        "        \"christianity\",\n",
        "        \"coffee\",\n",
        "        \"cogsci\",\n",
        "        \"cooking\",\n",
        "        \"crafts\",\n",
        "        \"cseducators\",\n",
        "        \"diy\",\n",
        "        \"drones\",\n",
        "        \"earthscience\",\n",
        "        \"ebooks\",\n",
        "        \"electronics\",\n",
        "        \"english\",\n",
        "        \"expatriates\",\n",
        "        \"fitness\",\n",
        "        \"freelancing\",\n",
        "        \"gardening\",\n",
        "        \"gaming\",\n",
        "        \"genealogy\",\n",
        "        \"ham\",\n",
        "        \"hardwarerecs\",\n",
        "        \"health\",\n",
        "        \"hinduism\",\n",
        "        \"history\",\n",
        "        \"homebrew\",\n",
        "        \"hsm\",\n",
        "        \"interpersonal\",\n",
        "        \"iot\",\n",
        "        \"islam\",\n",
        "        \"judaism\",\n",
        "        \"law\",\n",
        "        \"lifehacks\",\n",
        "        \"linguistics\",\n",
        "        \"literature\",\n",
        "        \"martialarts\",\n",
        "        \"materials\",\n",
        "        \"mechanics\",\n",
        "        \"moderators\",\n",
        "        \"money\",\n",
        "        \"music\",\n",
        "        \"mythology\",\n",
        "        \"outdoors\",\n",
        "        \"parenting\",\n",
        "        \"patents\",\n",
        "        \"pets\",\n",
        "        \"philosophy\",\n",
        "        \"pm\",\n",
        "        \"politics\",\n",
        "        \"security\",\n",
        "        \"skeptics\",\n",
        "        \"softwarerecs\",\n",
        "        \"sustainability\",\n",
        "        \"travel\",\n",
        "        \"vegetarianism\",\n",
        "        \"woodworking\",\n",
        "        \"workplace\",\n",
        "        \"worldbuilding\",\n",
        "        \"writers\"\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "list_of_dictionary_paraphrases = [\n",
        "    \"Define the term: %s\",\n",
        "    \"What is the definition of the following word or expression: %s\",\n",
        "    \"Define the following term: %s\",\n",
        "    \"what does the following term mean: %s\",\n",
        "    \"What is the definition of the following word: %s\",\n",
        "    'Provide the definition for the term \"%s\".',\n",
        "    'Explain the meaning of the word \"%s\".',\n",
        "    'Elucidate the definition of \"%s\".',\n",
        "    'Clarify the term \"%s\".',\n",
        "    'What does the word \"%s\" signify?',\n",
        "    'Provide a definition for \"%s\".',\n",
        "    'How is the term \"%s\" defined?',\n",
        "    'What exactly is meant by \"%s\"?',\n",
        "    'Share the definition of \"%s\".',\n",
        "    'Offer a definition for word or expression \"%s\".',\n",
        "    'Explain what \"%s\" refers to.',\n",
        "    'Define the term \"%s\", please.',\n",
        "    'What\\'s the definition of \"%s\"?',\n",
        "    'Please elucidate \"%s\".',\n",
        "    'How is \"%s\" defined?',\n",
        "    'Explain the concept behind \"%s\".',\n",
        "    'What is meant by the word \"%s\"?',\n",
        "    'Can you give the definition of \"%s\"?',\n",
        "    'Could you provide the meaning of \"%s\"?',\n",
        "    'Please offer the definition of \"%s\".'\n",
        "]\n",
        "\n",
        "\n",
        "def filter_dictionary(x):\n",
        "    \"\"\"get definitions of only medium sized words with large definitions\"\"\"\n",
        "    if x['word'] is None:\n",
        "        return False\n",
        "    return len(x['definition'])>100 and len(x['word'].replace(\" \",''))>=4\n",
        "\n",
        "def clean_dictionary(x):\n",
        "    \"\"\"converts a dictionary term into a question, sampling randomly from 20 template questions\"\"\"\n",
        "    idx_random_question_template = ord(x['definition'].replace(' ','')[-6]) % len(list_of_dictionary_paraphrases)\n",
        "    question_template =list_of_dictionary_paraphrases[idx_random_question_template]\n",
        "    x['query'] = question_template % x['word']\n",
        "    x['positives'] = [x['definition']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_webglmqa(x):\n",
        "    x['query']=x['question']\n",
        "    x['positives'] = [x['answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_PAQ_pairs(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_finance_alpaca(x):\n",
        "    x['query'] = x['instruction']\n",
        "    x['positives'] = [x['output']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_wiki_qa(x):\n",
        "    x['query'] = x['question']\n",
        "    is_pos = x['label']\n",
        "    answer = x['answer']\n",
        "    pos = [answer] if is_pos else []\n",
        "    neg = [answer] if (not is_pos) else []\n",
        "    x['positives'] = pos\n",
        "    x['negatives'] = neg\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_oa_stackexchange(x):\n",
        "    x['query'] = x['INSTRUCTION']\n",
        "    x['positives'] = [x['RESPONSE']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_sciqa(x):\n",
        "    x['query'] = x['question']\n",
        "    x['positives'] = [x['support']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_lfqa(x):\n",
        "    x['query'] = x['question']\n",
        "    x['positives'] = [x['answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def filter_os_stackexchange(x):\n",
        "    return x['SOURCE'] in STACKEXCHANGE_NONQUANT_DOMAINS\n",
        "\n",
        "def get_name_and_description_eclassTrainST(text):\n",
        "    description, name = text.split(\"; Name:\")\n",
        "    return description.replace(\"Description: \",\"\").strip(), name.strip()\n",
        "\n",
        "def clean_eclassTrainST(x):\n",
        "    \"\"\"This set isn't really about entailment/contradiction; it is really a dictionary\"\"\"\n",
        "    description, name = get_name_and_description_eclassTrainST(x['text'])\n",
        "    pos, _ = get_name_and_description_eclassTrainST(x['entailment'])\n",
        "    extra, _ = get_name_and_description_eclassTrainST(x['contradiction'])\n",
        "    x['query'] = 'What is a \"%s\"?' % name\n",
        "    x['positives'] = [pos]\n",
        "    x['negatives'] = []\n",
        "    # add the entailment as positive, contradiction as negatives\n",
        "    if x['label'] == 'entailment':\n",
        "        x['positives'].append(extra)\n",
        "    else:\n",
        "        x['negatives'] = [extra]\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "# do to: alzoubi36/policy_qa - policy questions\n",
        "def clean_policyqa(x):\n",
        "    \"\"\"Adds more context to the questions about data security in the alzoubi36/policy_qa qa set \"\"\"\n",
        "    idx_random_question_template = ord(x['context'].replace(' ','')[-5]) % len(POLICYQA_PREPEND)\n",
        "    question_template =POLICYQA_PREPEND[idx_random_question_template]\n",
        "    q = x['question']\n",
        "    q = q[0].lower() + q[1:]\n",
        "    x['query'] = question_template % q # ['id', 'title', 'context', 'question', 'answers']\n",
        "    x['positives'] = [x['context']]\n",
        "    # fetch a negative from the negative corpus\n",
        "    negatives_random, _ = negative_example_generator.find_negative(x['context'], k = 1, skip=10)\n",
        "    x['negatives'] = negatives_random\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_sc2qa(x):\n",
        "    x['query'] = x['question']\n",
        "    x['positives'] = [x['article']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_yahooanswers(x):\n",
        "    x['query'] = (x['question_title'] + \" \" + x['question_content']).strip() # 'question_title', 'question_content'\n",
        "    x['positives'] = [x['best_answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def filter_yahooanswers(x):\n",
        "    \"\"\"Yahoo news filtering (filter for 6=business; 3=education; 9=govt)\"\"\"\n",
        "    return x['topic'] in [3,6,9] and len(x['question_title'])>10 and len(x['best_answer'])>10\n",
        "\n",
        "\n",
        "def clean_businessbook(x):\n",
        "    \"\"\"17k business books cleaning\"\"\"\n",
        "    x['query'] = x['question']\n",
        "    x['positives'] = [x['answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "#dict_keys(['question_id', 'question', 'document_title', 'answer', 'label'])\n",
        "qa_streaming_cleaning_functions = {\n",
        "    'embedding-data/PAQ_pairs':(clean_stream_PAQ_pairs, None, ['query','positives','negatives'],['set']),\n",
        "    'gbharti/finance-alpaca':(clean_stream_finance_alpaca,None, ['query','positives','negatives'],['input', 'output', 'text', 'instruction']),\n",
        "    'wiki_qa':(clean_stream_wiki_qa, None, ['query','positives','negatives'],['question_id', 'question', 'document_title', 'answer', 'label']),\n",
        "    'donfu/oa-stackexchange':(clean_stream_oa_stackexchange, filter_os_stackexchange, ['query','positives','negatives'], ['INSTRUCTION', 'RESPONSE', 'SOURCE', 'METADATA']),\n",
        "    'gart-labor/eclassTrainST':(clean_eclassTrainST, None, ['query','positives','negatives'], ['text', 'entailment', 'contradiction', 'label']),\n",
        "    'THUDM/webglm-qa':( clean_webglmqa, None, ['query','positives','negatives'], ['question','answer','references']),\n",
        "    'sciqa': (clean_stream_sciqa, None, ['query','positives','negatives'], ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support']),\n",
        "    'LLukas22/lfqa_preprocessed':(clean_lfqa, None, ['query','positives','negatives'], ['question','answer','context']), #REDDIT QUESTION ANSWERS (ASK historians, ask me like I'M FIVE)\n",
        "    'npvinHnivqn/EnglishDictionary':(clean_dictionary, filter_dictionary, ['query','positives','negatives'], ['word','definition']), # dictionaries\n",
        "    'alzoubi36/policy_qa':(clean_policyqa, None, ['query','positives','negatives'],  ['id', 'title', 'context', 'question', 'answers'] ), # PRIVACYGLUE\n",
        "    'sc2qa/sc2q_commoncrawl':(clean_sc2qa, None, ['query','positives','negatives'], ['question','article','url']),\n",
        "    'yahoo_answers_topics':(clean_yahooanswers, filter_yahooanswers, ['query','positives','negatives'], ['id', 'topic', 'question_title', 'question_content', 'best_answer']),\n",
        "    'launch/gov_report_qs':(clean_govreportqa, None, ['query','positives','negatives'],['doc_id', 'summary_paragraph_index', 'document_sections', 'question_summary_pairs']),\n",
        "    'theoldmandthesea/17k_business_book':(clean_businessbook, None, ['query','positives','negatives'], ['question','answer','book']),\n",
        "}\n",
        "\n",
        "DEFAULT_PROB_QA = 0.1\n",
        "qa_files = [\n",
        "    ('embedding-data/PAQ_pairs',None, DEFAULT_PROB_QA, 7.29*10**6, 'qa_triplet', False), # wikipedia pop culture pairs # get from 'set', 7.29*10**6\n",
        "    ('gbharti/finance-alpaca',None, DEFAULT_PROB_QA, 6.89*10**5, 'qa_triplet', False), # Stanford's Alpaca (https://github.com/tatsu-lab/stanford_alpaca) and FiQA (https://sites.google.com/view/fiqa/) with another 1.3k pairs custom generated using GPT3.5\n",
        "    ('wiki_qa',None, DEFAULT_PROB_QA, 20.4*10**3, 'qa_triplet', False), # Wiki Question Answering corpus from Microsoft. with multiple negatives that are similar!\n",
        "    ('donfu/oa-stackexchange',None, DEFAULT_PROB_QA*2, 6330000, 'qa_triplet', (14, int(6330000//14))), # stack-exchange question-answer pairs, across lots of domains; notice the original is 6.6 million, but there is a filter\n",
        "    ('gart-labor/eclassTrainST', None, 0.02, 450912, 'qa_triplet', False), # questions about trade / business stuff\n",
        "    ('THUDM/webglm-qa', None, DEFAULT_PROB_QA, 43600, 'qa_triplet', False),\n",
        "    ('sciq',None, DEFAULT_PROB_QA, 11679, 'qa_triplet', False), # science questions from Allenai, with a question and support\n",
        "    ('LLukas22/lfqa_preprocessed', None, DEFAULT_PROB_QA, 226000,'qa_triplet',False),# REDDIT QUESTION ANSWERS (ASK historians, ask me like I'M FIVE)\n",
        "    ('npvinHnivqn/EnglishDictionary',None, DEFAULT_PROB_QA/4, 30864, 'qa_triplet',False), # 0.05 original size: 11200, post-file 30865\n",
        "    ('alzoubi36/policy_qa', None, DEFAULT_PROB_QA/4, 17100,  'qa_triplet',False),\n",
        "    ('sc2qa/sc2q_commoncrawl',None, DEFAULT_PROB_QA, 44500, 'qa_triplet', False),\n",
        "    ('yahoo_answers_topics', None, DEFAULT_PROB_QA, 401357,'qa_triplet', False),\n",
        "    ('launch/gov_report_qs','paragraph', DEFAULT_PROB_QA/5, 4878, 'qa_triplet', False),\n",
        "    ('theoldmandthesea/17k_business_book', None, DEFAULT_PROB_QA/4, 17480, 'qa_triplet', False),\n",
        "]\n",
        "\n",
        "qadata_streaming_config = {\n",
        "    'files':qa_files,\n",
        "    'max_seq_length':512,\n",
        "    'prepend_q': 'query: ',\n",
        "    'prepend_a': 'passage: ',\n",
        "    'val_size':1000,\n",
        "    'train_chunk_size':5000,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "def initialize_qa_streaming_datasets(data_streaming_config, streaming_cleaning_functions):\n",
        "    files = data_streaming_config['files']\n",
        "    qa_streaming_datsets, qa_probabilities, qa_datasizes = [],[],[]\n",
        "    for (qa_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle) in files:\n",
        "\n",
        "        if prob ==0:\n",
        "            continue\n",
        "        # get cleaning & filter functions for streaming data / map & filters\n",
        "        clean_func, filter_func, feature_names, removefeature_names = streaming_cleaning_functions[qa_nm]\n",
        "\n",
        "        # arguments for the load_dataset (huggingface repos)\n",
        "        load_dataset_args = {\n",
        "            'path':qa_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "        }\n",
        "        # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "        if qa_nm.endswith('.jsonl') or qa_nm.endswith('.jsonl.zip') or qa_nm.endswith('.jsonl.zst'):\n",
        "            load_dataset_args.update({'path':'json','data_files':qa_nm})\n",
        "\n",
        "        print('trying %s' % qa_nm)\n",
        "        if filter_func is None:\n",
        "            dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "        else:\n",
        "            dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "\n",
        "        qa_streaming_datsets.append(dset_stream)\n",
        "        qa_probabilities.append(prob);\n",
        "        qa_datasizes.append(dataset_size)\n",
        "\n",
        "    print('done initializing the QA streaming datasets')\n",
        "    return qa_streaming_datsets, qa_probabilities, qa_datasizes\n",
        "\n",
        "def streaming_skip(skip, list_of_streaming_datasets, probabilities, datasizes, seed=42, convert_to_static = False):\n",
        "    \"\"\"Function loops through a list of streaming datasets, skips a first K values based on the probabilities, and returns them\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for dset, p, size in list_of_streaming_datasets, normalized_p, datasizes:\n",
        "        skip_in_this_set = max(0,int(p)*skip)\n",
        "        out.append(dset.skip(skip_in_this_set))\n",
        "    return out\n",
        "\n",
        "def streaming_take(skip, start_proportion, chunksize, list_of_streaming_datasets, probabilities, datasizes,  convert_to_static = False):\n",
        "    \"\"\"Takes some examples based on a starting point within the dataset, as a proportion of its total size\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for j, (dset, p, size) in enumerate(zip(list_of_streaming_datasets, normalized_p, datasizes)):\n",
        "        #print(type(dset))\n",
        "        #print(type(p))\n",
        "        #print(type(size))\n",
        "        # skip for valset\n",
        "        skip_in_this_set = int(round(p*skip))\n",
        "        # afterwards, where to start?\n",
        "        skip_to_start = int(start_proportion*(size-skip_in_this_set))\n",
        "        take_from_this_set = int(round(chunksize*p))\n",
        "        if skip_to_start>0:\n",
        "            dset_skipped = dset.skip(skip_in_this_set+skip_to_start).take(take_from_this_set)\n",
        "        else:\n",
        "            dset_skipped = dset.take(take_from_this_set)\n",
        "\n",
        "        if not convert_to_static:\n",
        "            # option to return the streaming dataset\n",
        "            out.append(dset_skipped)\n",
        "        else:\n",
        "            # option just to convert the streaming dataset to static outputs\n",
        "            for example in dset_skipped:\n",
        "                example['source_id'] = j\n",
        "                out.append(example)\n",
        "        print('done %d' % j)\n",
        "    return out\n",
        "\n",
        "def train_test_splits_from_stream_qa(\n",
        "    streaming_dataset,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    path_to_val_cache = 'val_qa_cache.pkl',\n",
        "    probabilities = None,\n",
        "    datasizes = None,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"\n",
        "    val_size = 2000, number of streaming-iter to skip, reserved for the val-sze\n",
        "    epoch = 0, epoch will change the seed when sampling the chunk idx for making the training set\n",
        "    chunk_size = 5000, # number of streaming-iter to select the training data chunk\n",
        "    max_chunk_start = 2000000, # randomly sample within this interval for streaming chunks\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path_to_val_cache):\n",
        "        print('RELOADING VAL-QA SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            val_corpus_list = pickle.load(pcon)\n",
        "        print('VAL-QA SET SIZE: %d' % len(val_corpus_list))\n",
        "    else:\n",
        "        # stream validation set\n",
        "        print('STREAMING VAL-QA DATA: %d' % val_size)\n",
        "        val_corpus_list = streaming_take(\n",
        "            skip=0,\n",
        "            start_proportion=0,\n",
        "            chunksize=val_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "        print('REALIZED VAL-QA DATA: %d' % len(val_corpus_list))\n",
        "        # save the validation corpus\n",
        "        print('SAVING VAL-QA SET: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(val_corpus_list, pcon)\n",
        "\n",
        "    # take a random interger to start the streaming of training data\n",
        "    # starts at a random position\n",
        "    train_start_proportion = np.random.RandomState(seed + epoch).random()*0.99\n",
        "    print(train_start_proportion)\n",
        "\n",
        "    # stream training data\n",
        "    print('STREAMING TRAIN QA-DATA: %d STARTING AT: %0.3f' % (chunk_size,train_start_proportion))\n",
        "    train_corpus_list = streaming_take(\n",
        "            skip=val_size,\n",
        "            start_proportion=train_start_proportion,\n",
        "            chunksize=chunk_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "\n",
        "    print('REALISED TRAIN QA-DATA SIZE: %d' % len(train_corpus_list))\n",
        "    return {\n",
        "        'train':train_corpus_list,\n",
        "        'val':val_corpus_list,\n",
        "        'epoch':0,\n",
        "        'index_stream':train_start_proportion\n",
        "    }\n",
        "\n",
        "def initialize_and_get_triplet_streaming_datasets(\n",
        "    data_streaming_config,\n",
        "    streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_qa.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_qa_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'QA' #\n",
        "):\n",
        "    \"\"\"Converts stream of unlabelled text data into static datasets for: for Triplet data tasks (QA-task/IR-task)\"\"\"\n",
        "    # list of files to stream\n",
        "    print('Initializing the streaming-QA to static-dataset procedure...')\n",
        "    files = data_streaming_config['files']\n",
        "    # number of examples to take from stream for validation set\n",
        "    val_size = data_streaming_config['val_size']\n",
        "    # number of examples to take from stream for training set\n",
        "    train_chunk_size = data_streaming_config['train_chunk_size']\n",
        "    min_seq_len = data_streaming_config.get('min_seq_length', 48)\n",
        "    # normalization constant for normalizing the weights into probabilities\n",
        "    probability_normalization_const = sum([x[2] for x in files])\n",
        "\n",
        "    # where to initialize start-stream for training data\n",
        "    if start_proportion is None:\n",
        "        start_proportion = np.random.RandomState(seed+epoch).uniform()*0.99\n",
        "\n",
        "    # reload cached files\n",
        "    path_to_train_cache = None if not '%03g' in path_to_train_cache_epoch else path_to_train_cache_epoch % epoch\n",
        "    do_make_valset = not os.path.isfile(path_to_val_cache)\n",
        "    do_make_trainset = not os.path.isfile(path_to_train_cache)\n",
        "    if not do_make_valset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            datalist_val_triplet_static = pickle.load(pcon)\n",
        "        print(f'VAL-{name} SET SIZE: %d' % len(datalist_val_triplet_static))\n",
        "    else:\n",
        "        datalist_val_triplet_static = []\n",
        "    if not do_make_trainset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_train_cache,'rb') as pcon:\n",
        "            datalist_train_triplet_static = pickle.load(pcon)\n",
        "        print(f'TRAIN-{name} EPOCH-%d SET SIZE: %d' % (epoch, len(datalist_train_triplet_static)))\n",
        "    else:\n",
        "        datalist_train_triplet_static = []\n",
        "\n",
        "    if (do_make_trainset or do_make_valset):\n",
        "\n",
        "        # loop through datasets\n",
        "        for (data_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle), dataset_key in zip(\n",
        "            files, streaming_cleaning_functions.keys()\n",
        "        ):\n",
        "            if prob ==0:\n",
        "                continue\n",
        "            prob /= probability_normalization_const\n",
        "\n",
        "            # get cleaning & filter functions for streaming data functionality\n",
        "            clean_func, filter_func, feature_names, removefeature_names = streaming_cleaning_functions[dataset_key]\n",
        "\n",
        "            # set arguments for the load_dataset (huggingface repos)\n",
        "            load_dataset_args = {\n",
        "                'path':data_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "            }\n",
        "            # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "            if data_nm.endswith('.jsonl') or data_nm.endswith('.jsonl.zip') or data_nm.endswith('.jsonl.zst'):\n",
        "                load_dataset_args.update({'path':'json','data_files':data_nm})\n",
        "\n",
        "            # special proecssing of datasets with multiple partitions\n",
        "            if bool(partition_shuffle): # or str(epoch)=='val':\n",
        "\n",
        "                n_files, n_per_file = partition_shuffle\n",
        "                dataset_size = n_per_file\n",
        "                print('trying %s initialization (shuffling through %d files)' % (data_nm, n_files))\n",
        "\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func)\n",
        "\n",
        "                # validation set\n",
        "                if do_make_valset:\n",
        "                    # take from stream\n",
        "                    n_valset_take = max(int(prob*val_size), 1)\n",
        "                    if n_valset_take==1:\n",
        "                        print(prob)\n",
        "                        print(val_size)\n",
        "                    print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert stream to a static set and do check\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "                # training set\n",
        "                if do_make_trainset:\n",
        "                    # randomly skip a bunch from this set\n",
        "                    skip_to_start = int(start_proportion*n_per_file)\n",
        "                    take_from_this_set = max(int(round(train_chunk_size*prob)),1)\n",
        "                    print('take %d from %s training'% (take_from_this_set, data_nm))\n",
        "                    # shuffle: take a random data partition (from the dataset's list of files)\n",
        "                    dset_stream_train = dset_stream_val.shuffle(\n",
        "                        seed = seed+epoch, buffer_size = skip_to_start+take_from_this_set,\n",
        "                    )\n",
        "                    dset_stream_train = dset_stream_train.skip(\n",
        "                        skip_to_start # random skip through dataset to new start position\n",
        "                    ).take(\n",
        "                        take_from_this_set # take this amount for the training ste\n",
        "                    ).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert training to static dataset\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "            else:\n",
        "                # regular streaming\n",
        "                print('trying %s initialization' % data_nm)\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "                # take from stream\n",
        "                n_valset_take = max(int(prob*val_size), 1) # size of valset\n",
        "                if n_valset_take==1:\n",
        "                    print(prob)\n",
        "                    print(val_size)\n",
        "                print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                skip_to_start = int(start_proportion*(dataset_size-n_valset_take)) # random point to skip to\n",
        "                n_train_take = max(int(round(train_chunk_size*prob)),1) # size of train set\n",
        "                print('take %d from %s train'% (n_train_take, data_nm))\n",
        "                if do_make_valset:\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take)\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "                if do_make_trainset:\n",
        "                    dset_stream_train = dset_stream.skip(n_valset_take+skip_to_start).take(n_train_take)\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "            print('Done getting streams/reloading from %s' % data_nm)\n",
        "            # check language, chunk sentences\n",
        "            if do_make_valset:\n",
        "                # discard non-english\n",
        "                dset_static_val_thisset =[\n",
        "                    e for e in dset_static_val_thisset if check_language(e['query'])[0] #detect(e['query'][:200]+\" hello\")=='en'\n",
        "                ]\n",
        "                print('done val language check')\n",
        "                # add to val set\n",
        "                datalist_val_triplet_static.extend(dset_static_val_thisset)\n",
        "\n",
        "            # check language, chunk sentences\n",
        "            if do_make_trainset:\n",
        "                # discard non-english\n",
        "                dset_static_train_thisset =[\n",
        "                    e for e in dset_static_train_thisset if check_language(e['query'])[0] #detect(e['query'][:200] +\" hello\")=='en'\n",
        "                ]\n",
        "                print('done train language check')\n",
        "\n",
        "                # ensure that none of the examples in the traning set are in the validation set\n",
        "                if do_make_valset:\n",
        "                    val_queries = set([q['query'] for q in dset_static_val_thisset])\n",
        "                    dset_static_train_thisset = [\n",
        "                        s for s in dset_static_train_thisset if s['query'] not in val_queries\n",
        "                    ]\n",
        "\n",
        "                # add to training set\n",
        "                datalist_train_triplet_static.extend(dset_static_train_thisset)\n",
        "\n",
        "        print(f'Done collecting {name} streaming data')\n",
        "\n",
        "    if do_make_valset:\n",
        "        print('saving streamed %s validation data: %s' % (name, path_to_val_cache))\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_val_triplet_static, pcon)\n",
        "\n",
        "    if do_make_trainset:\n",
        "        print('saving streamed %s training for epoch %d: %s' % (name, epoch, path_to_train_cache))\n",
        "        with open(path_to_train_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_train_triplet_static, pcon)\n",
        "\n",
        "    return {\n",
        "        'train':datalist_train_triplet_static,\n",
        "        'val':datalist_val_triplet_static,\n",
        "        'epoch':epoch,\n",
        "        'index_stream':start_proportion\n",
        "    }\n",
        "\n",
        "\n",
        "class DatasetTriplets(torch_data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        list_of_data=None,\n",
        "        n_negatives= 3,\n",
        "        topk_negatives_discard = 15, # get top kth most-similar results, discard first k, to use as negative\n",
        "        focal_text_name ='query',\n",
        "        positives_text_name ='positives',\n",
        "        negativess_text_name ='negatives',\n",
        "        seed = 32,\n",
        "        negative_corpus_method = 'bm25', # how to sample (pseudo)negatives internally\n",
        "        label_processor_class = None # (optional) function to process negatives\n",
        "    ):\n",
        "        self.n_negatives = n_negatives\n",
        "        self.topk_negatives_discard = topk_negatives_discard\n",
        "        self.data = {}\n",
        "        self.focal_text_name =focal_text_name\n",
        "        self.positives_text_name = positives_text_name\n",
        "        self.negativess_text_name = negativess_text_name\n",
        "        self.seed = 42\n",
        "        self.random = np.random.RandomState(self.seed)\n",
        "        self.label_processor_class = label_processor_class\n",
        "        self.negative_corpus_method = negative_corpus_method\n",
        "        assert negative_corpus_method in ['bm25','ann-tfidf']\n",
        "\n",
        "        if list_of_data is not None and len(list_of_data)>0:\n",
        "\n",
        "            # loop through the data and add each triplets: export a panda df as final data\n",
        "            self.df = self.process(list_of_data)\n",
        "\n",
        "    def process(self, list_of_data):\n",
        "        \"\"\"Makes (query,pos,neg)-triplets, converts samples to dataframe for pytorch iteration\"\"\"\n",
        "\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(\n",
        "            list_of_data = list_of_data\n",
        "        )\n",
        "\n",
        "        # add positives to self.data\n",
        "        self._find_positives_and_add_to_data()\n",
        "\n",
        "        # add negatives to self.data\n",
        "        self._find_negatives_and_add_to_data()\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        df = self.sample_data_and_make_static_dataframe(self.data)\n",
        "        return df\n",
        "\n",
        "    def _loop_through_list_of_data_and_add_to_selfdata(\n",
        "        self,\n",
        "        list_of_data\n",
        "    ):\n",
        "        \"\"\"loops through and adds the positive/focal texts and negatives\"\"\"\n",
        "        for raw_example in list_of_data:\n",
        "            # add each element to the data\n",
        "            self._add_triplet_to_data(\n",
        "                focal_texts=raw_example[self.focal_text_name],\n",
        "                positve_texts=raw_example[self.positives_text_name],\n",
        "                negative_texts=raw_example[self.negativess_text_name],\n",
        "            )\n",
        "        self.focal_texts_as_keys = list(self.data.keys())\n",
        "\n",
        "    def _add_triplet_to_data(\n",
        "        self,\n",
        "        focal_texts,\n",
        "        positve_texts,\n",
        "        negative_texts\n",
        "    ):\n",
        "        \"\"\"add focal text to the data\"\"\"\n",
        "        do_add_focals = False\n",
        "        if isinstance(focal_texts,list):\n",
        "            focal_text = sort(focal_texts)[0]\n",
        "            do_add_focals = True\n",
        "        elif isinstance(focal_texts, str):\n",
        "            focal_text = focal_texts\n",
        "        if focal_text not in self.data.keys():\n",
        "            self.data[focal_text] = {'positives':[], 'negatives':[]}\n",
        "        self.data[focal_text]['positives'] += [p for p in positve_texts if p not in self.data[focal_text]['positives']]\n",
        "        #if negative_texts is None:\n",
        "        #    print(focal_texts)\n",
        "        #    print(positve_texts)\n",
        "        #    print(negative_texts)\n",
        "        self.data[focal_text]['negatives'] += negative_texts if (negative_texts is not None) else []\n",
        "        if do_add_focals:\n",
        "            self.data[focal_text]['positives'] += focal_texts[1:]\n",
        "\n",
        "    def _build_corpus_of_potential_negatives(self):\n",
        "        # grab positives as default negatives\n",
        "        potential_corpus = [\n",
        "            self.data[k]['positives'][:1] for k in self.focal_texts_as_keys\n",
        "        ]\n",
        "        # insert NEGATIVE if empty for an entry\n",
        "        potential_corpus = [\n",
        "            'NEGATIVE' if (not bool(s)) else s[0] for s in potential_corpus\n",
        "        ]\n",
        "\n",
        "        # negatives by BM25\n",
        "        if self.negative_corpus_method == 'bm25':\n",
        "\n",
        "            # tokenize for BM25\n",
        "            print('building negatives via BM25')\n",
        "            tokenized_corpus = [s.lower().split(\" \") for s in potential_corpus]\n",
        "            # compile BM25 corpus\n",
        "            bm25 = BM25Okapi(tokenized_corpus)\n",
        "            return {'retriever':bm25, 'corpus':potential_corpus}\n",
        "\n",
        "        elif self.negative_corpus_method == 'ann-tfidf':\n",
        "            print('building negatives via ANN-TFIDF')\n",
        "            potential_corpus = [\n",
        "                s for s in potential_corpus\n",
        "                if len(s)>40 and len(s.split(\" \"))>10\n",
        "            ]\n",
        "            negative_example_generator= NegativeExampleGenerator(\n",
        "                n_reps = 1, #\n",
        "                tfidf_nfeatures = 4000,\n",
        "                nchar_max_paragraph=3000,\n",
        "                nword_max=100,\n",
        "                nchar_max_word=4,\n",
        "                save_cache = 'negative_sampler_%d-%s.pkl' % (len(potential_corpus), potential_corpus[0][0]),\n",
        "                corpus = potential_corpus\n",
        "            )\n",
        "            return {'retriever':negative_example_generator, 'corpus':potential_corpus}\n",
        "\n",
        "    def _find_negative(\n",
        "        self,\n",
        "        focal_text_as_query,\n",
        "        positive_examples=None,\n",
        "        use_focal_text = True,\n",
        "        use_positives=True,\n",
        "        neg_retriever=None,\n",
        "        corpus = None\n",
        "    ):\n",
        "        \"\"\"Given a query, uses BM25 to find similar but wrong answers, to serve as triplet negatives; for a single query\"\"\"\n",
        "        bmquery = (focal_text_as_query if use_focal_text else \"\") + \" \" + (\"\" if (not use_positives) else positive_examples[0])\n",
        "        bmquery = bmquery.strip()\n",
        "        if self.negative_corpus_method == 'bm25':\n",
        "            # make the query tokens\n",
        "            bmquery_tokenized = bmquery.lower().split(\" \")\n",
        "            # search by BM25\n",
        "            top_results = neg_retriever.get_top_n(\n",
        "                bmquery_tokenized, corpus, n=self.topk_negatives_discard + self.n_negatives\n",
        "            )\n",
        "        elif self.negative_corpus_method == 'ann-tfidf':\n",
        "            # query the ANN index\n",
        "            top_results,_ = neg_retriever.find_negative(\n",
        "                bmquery, k=self.n_negatives+2, skip=self.topk_negatives_discard\n",
        "            )\n",
        "\n",
        "        top_results = [\n",
        "            s for s in top_results\n",
        "            if (\n",
        "                s not in positive_examples+[focal_text_as_query]\n",
        "            )\n",
        "        ]\n",
        "        # remove any text that is equivalent to the query / focal texts\n",
        "        potential_negatives = top_results[-1*self.n_negatives:]\n",
        "        return potential_negatives\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"For data that has a label, this can be used to artifically find and create synthetic positives\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "        \"\"\"Uses BM25 to find similar but wrong answers, to serve as triplet negatives; loop over data\"\"\"\n",
        "\n",
        "        # build bm25 corpus or tfidf-ANN index\n",
        "        neg_corpus = self._build_corpus_of_potential_negatives()\n",
        "\n",
        "        # loop through data, find examples which don't have negatives\n",
        "        for k,d in self.data.items():\n",
        "            if not bool(d['negatives']):\n",
        "                negatives = self._find_negative(\n",
        "                    focal_text_as_query=k,\n",
        "                    positive_examples=d['positives'],\n",
        "                    use_focal_text = True,\n",
        "                    use_positives=bool(d['positives']),\n",
        "                    neg_retriever=neg_corpus['retriever'],\n",
        "                    corpus = neg_corpus['corpus']\n",
        "                )\n",
        "                d['negatives']+= negatives\n",
        "        print('done finding negatives')\n",
        "\n",
        "    def sample_data_and_make_static_dataframe(self, seed = 42):\n",
        "        focals =[]\n",
        "        pos =[]\n",
        "        neg = []\n",
        "        for query,d in self.data.items():\n",
        "            for j in range(min(self.n_negatives, len(d['negatives']))):\n",
        "                if len(d['positives'])==0:\n",
        "                    continue\n",
        "                elif len(d['positives'])==1:\n",
        "                    pos+=d['positives']\n",
        "                elif len(d['positives'])>1:\n",
        "                    pos.append(self.random.choice(d['positives']))\n",
        "                neg.append(d['negatives'][j])\n",
        "                focals.append(query)\n",
        "        df = pd.DataFrame({'query':focals, 'pos':pos, 'neg':neg})\n",
        "        return df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        #key = self.focal_texts_as_keys[idx]\n",
        "        #return {**{'query':key}, **self.data[key]}\n",
        "        return self.df.iloc[idx].to_dict()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "7NF5JtWPn-7T",
        "outputId": "ba39bad4-d9ff-4bbe-87c5-b8304803efdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing the streaming-QA to static-dataset procedure...\n",
            "trying embedding-data/PAQ_pairs initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-f55751402dbf0730\n",
            "INFO:datasets.builder:Using custom data configuration default-f55751402dbf0730\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.7204670875786356e-06\n",
            "2000\n",
            "take 1 from embedding-data/PAQ_pairs validation\n",
            "take 1 from embedding-data/PAQ_pairs train\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-271-a1bd15700d91>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# !rm cache_*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m qa_statics_datsets = initialize_and_get_triplet_streaming_datasets(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdata_streaming_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqadata_streaming_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstreaming_cleaning_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_streaming_cleaning_functions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-270-4d52eeea16f8>\u001b[0m in \u001b[0;36minitialize_and_get_triplet_streaming_datasets\u001b[0;34m(data_streaming_config, streaming_cleaning_functions, start_proportion, epoch, seed, path_to_val_cache, path_to_train_cache_epoch, do_check_english, name)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdo_make_trainset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                     \u001b[0mdset_stream_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_valset_take\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mskip_to_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_take\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     dset_static_train_thisset = [\n\u001b[0m\u001b[1;32m    600\u001b[0m                         \u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdset_stream_train\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\w+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                     ]\n",
            "\u001b[0;32m<ipython-input-270-4d52eeea16f8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdo_make_trainset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                     \u001b[0mdset_stream_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_valset_take\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mskip_to_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_take\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     dset_static_train_thisset = [\n\u001b[0m\u001b[1;32m    600\u001b[0m                         \u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdset_stream_train\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\w+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0;31m# `IterableDataset` automatically fills missing columns with None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle_data_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"TakeExamplesIterable\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle_data_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SkipExamplesIterable\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mArrowExamplesIterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_arrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;31m# If not batched, we can apply the transform and yield the example directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# first copy the example, since we might drop some keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mArrowExamplesIterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_arrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;31m# If not batched, we can apply the transform and yield the example directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# first copy the example, since we might drop some keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_tables_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpa_subtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mARROW_READER_BATCH_SIZE_IN_DATASET_ITER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mformatted_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_subtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json/json.py\u001b[0m in \u001b[0;36m_generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     )\n\u001b[1;32m    106\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/streaming_download_manager.py\u001b[0m in \u001b[0;36mread_with_retries\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mClientError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# Read a chunk of data from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1788\u001b[0m             \u001b[0;31m# don't even bother calling fetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/caching.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# new block replaces old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36m_fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;34mf\"{self.fs.endpoint}/{REPO_TYPES_URL_PREFIXES.get(self.resolved_path.repo_type, '') + self.resolved_path.repo_id}/resolve/{safe_quote(self.resolved_path.revision)}/{safe_quote(self.resolved_path.path_in_repo)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         )\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AMZN_TRACE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    791\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "qadata_streaming_config = {\n",
        "    'files':qa_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':2000,\n",
        "    'train_chunk_size':5000,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "# !rm cache_*\n",
        "qa_statics_datsets = initialize_and_get_triplet_streaming_datasets(\n",
        "    data_streaming_config = qadata_streaming_config,\n",
        "    streaming_cleaning_functions = qa_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_qa.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_qa_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'QA' #\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVO8t6irLjYO"
      },
      "outputs": [],
      "source": [
        "print(qa_statics_datsets.keys())\n",
        "#qa_statics_datsets['train']\n",
        "\n",
        "for i,e in enumerate(qa_statics_datsets['train'][::100]):\n",
        "    if i>200:\n",
        "        break\n",
        "    print(\"-------\\nQ:%s\\nA:%s\" % (e['query'], e['positives'][0].replace(\"\\n\",\" \") if bool(e['positives']) else e['negatives'][0].replace(\"\\n\",\" \")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Vmko2SmxHe",
        "outputId": "76580bd4-9403-4620-eeb0-1b143548722e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 1662\n",
            "finished building the ANN index\n",
            "done finding negatives\n",
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 3041\n",
            "finished building the ANN index\n",
            "done finding negatives\n"
          ]
        }
      ],
      "source": [
        "# this takes a long time to query for negatives (maybe I should just use the other negaitve generator)\n",
        "\n",
        "NEGATIVE_CORPUS_METHOD_QA = 'ann-tfidf' #'bm25'\n",
        "qa_torchdataset_val = DatasetTriplets(\n",
        "    list_of_data = qa_statics_datsets['val'],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "    negative_corpus_method = NEGATIVE_CORPUS_METHOD_QA\n",
        ")\n",
        "\n",
        "#\n",
        "if True:\n",
        "    qa_torchdataset_train = DatasetTriplets(\n",
        "        list_of_data = qa_statics_datsets['train'],\n",
        "        n_negatives= 3,\n",
        "        focal_text_name ='query',\n",
        "        positives_text_name ='positives',\n",
        "        negativess_text_name ='negatives',\n",
        "        topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "        negative_corpus_method = NEGATIVE_CORPUS_METHOD_QA\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mje7yyhqniKU",
        "outputId": "e6e6a817-017c-4e7c-980f-c1fd1ad4cea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9151\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': \"How do they make 3D movies? Why do we have to wear glasses? What's their role?\",\n",
              " 'pos': '3D movies use a variety of technologies to create the illusion of depth and realism. Specialty glasses are used to create the 3D effect by allowing each eye to receive different images. The glasses use either shutters, color filters, or polarized lenses to receive the images so that your brain can put the 3D effect together. Without the glasses, the 3D movie will look blurred and may be too uncomfortable for some people to watch[2]. The glasses also enhance the depth perception of the images so that they seem more lifelike and as if they are leaping from the screen[3]. There are several different types of 3D technologies in use today, but they all work together to send each eye different perspectives of the same image[5].',\n",
              " 'neg': 'Looking directly at the sun can cause a condition called solar retinopathy, which is when solar radiation damages the eyes and can even lead to permanent blind spots or distortions in your vision[2][3]. The sun’s light is so intense that even a small sliver of exposed light is enough to cause irreversible damage[3]. The only safe way to look directly at the sun is through specifically designed solar filters, such as “eclipse glasses” or in solar eclipse viewers[4][5].'}"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(qa_torchdataset_train))\n",
        "qa_torchdataset_train[2700]\n",
        "\n",
        "# WORKS: done with the QA sets (need to expand amount of data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_ZSsSvhIBMY"
      },
      "source": [
        "### A) Retrieval Tasks\n",
        "In general, what loss would I use for the QA & retrieval tasks? Distillation is obvious, but what about\n",
        "- SQUAD - has QA pairs - squad_v2\n",
        "    - good for distillation\n",
        "- ORCA - has GPT-like prompting QA pairs: https://huggingface.co/datasets/Open-Orca/OpenOrca/viewer/Open-Orca--OpenOrca/train?row=29\n",
        "- DONE Simple-Wiki https://huggingface.co/datasets/embedding-data/simple-wiki - has paraphrases\n",
        "- DONE embedding-data/coco_captions_quintets - multiple captions as paraphrases\n",
        "- DONE embedding-data/simple-wiki - pairs of paraphrases from wikipedia\n",
        "- DONE embedding-data/SPECTER - triplets of {anchor, pos, neg}, small headline-like snippets in technical /statistical /science fields\n",
        "- https://huggingface.co/embedding-data - has a lot of retrieval tasks\n",
        "- LLukas22/scidocs - titles and abstracts\n",
        "- DONE allenai/scirepeval - cite_prediction - has query,pos, neg based on citations\n",
        "- DONE - LEDGAR - can possible do triplets on same label\n",
        "- Rahmaa/ElsevieR_ClEaN - possible relation between title and abstract\n",
        "- embedding-data/WikiAnswers - 25 question paraphrases (maybe no answers)\n",
        "- cnn_dailymail - summarization possiblility 287k (beware |||?)\n",
        "- multi_news - another summarization 45k (beware |||?)\n",
        "- DONE xsum - BBC extreme summarization 204k\n",
        "- DONE lighteval/legal_summarization - legal summization of bills (BillSum 18.8k)\n",
        "- gigaword - small paraphrases\n",
        "- SKIP launch/gov_report # this could be used for LONG document summaries/retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqTVMjmNIWpx"
      },
      "outputs": [],
      "source": [
        "#foo =  load_dataset(\"embedding-data/simple-wiki\",split='train',streaming=True)\n",
        "#foo =  load_dataset(\"embedding-data/coco_captions_quintets\",split='train',streaming=True).take(2000)\n",
        "#foo =  load_dataset(\"embedding-data/SPECTER\",split='train',streaming=True)\n",
        "#foo = load_dataset(**{'path': 'embedding-data/SPECTER', 'name':None, 'split':'train', 'streaming':True})\n",
        "#foo =  load_dataset(\"paws\",'labeled_final',split='train',streaming=True)\n",
        "#foo =  load_dataset(\"embedding-data/QQP_triplets\",None,split='train',streaming=True)\n",
        "#foo =  load_dataset(\"\",None,split='train',streaming=True)\n",
        "#foo =  load_dataset(\"\",None,split='train',streaming=True)\n",
        "#foo = load_dataset(\"allenai/scirepeval\", 'cite_prediction',None, split='train',streaming=True)\n",
        "# foo = load_dataset(**{'path': 'allenai/scirepeval', 'name':'cite_prediction', 'split':'train', 'streaming':True})\n",
        "#foo = load_dataset('json', data_files=\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", split=\"train\", streaming=False)\n",
        "#foo = load_dataset(**{'path': 'json', 'name':None, 'data_files':'https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip', 'split':'train', 'streaming':True})\n",
        "foo =  load_dataset(\"lighteval/legal_summarization\",\"BillSum\",split='train',streaming=True)\n",
        "\n",
        "if True:\n",
        "    # embedding-data/WikiAnswers\n",
        "    for j,e in enumerate(foo):\n",
        "        print(e)\n",
        "        #print(len(e['set']))\n",
        "        if j > 100:\n",
        "            break\n",
        "    print(e.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFNfy-uRIDzD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def clean_legalsum(x):\n",
        "    MAX_CHAR_LEN_BILLSUM = int(6.7*600)\n",
        "    text = x['article'][:MAX_CHAR_LEN_BILLSUM]\n",
        "    if 'SEC. 2.' in text:\n",
        "        text = \".\".join(text.split('SEC. 2.')[1].split('.')[1:])\n",
        "    else:\n",
        "        if 'SHORT TITLE' in text:\n",
        "             text = text.split('SHORT TITLE')[1]\n",
        "    x['query'] = x['summary']\n",
        "    x['positives'] = [text.strip()]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_xsum(x):\n",
        "    x['query'] = x['summary']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = [x['document']]\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_eurlex(x):\n",
        "    x['query'] = x['text']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = []\n",
        "    x['type'] = 'sts_by_textlabel'\n",
        "    x['label'] = x['eurovoc_concepts']\n",
        "    return x\n",
        "\n",
        "def clean_allenai_citeprediction(x):\n",
        "    x['query'] = x['query']['abstract']\n",
        "    pos = x['pos']['abstract']\n",
        "    x['positives'] = [pos] if pos is not None else []\n",
        "    neg = x['neg']['abstract']\n",
        "    x['negatives'] = [neg] if neg is not None else []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_simple_wiki(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_coco_captions_quintets(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = x['set'][1:]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_specter(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = [x['set'][2]]\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_paws(x):\n",
        "    x['query'] = x['sentence1']\n",
        "    x['positives'] = [x['sentence2']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_qqp(x):\n",
        "    x['query'] = x['set']['query']\n",
        "    x['positives'] = x['set']['pos']\n",
        "    x['negatives'] = x['set']['neg']\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_ledgarlabelled(x):\n",
        "    x['query'] = x['provision']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = []\n",
        "    x['type'] = 'sts_by_textlabel'\n",
        "    return x\n",
        "\n",
        "\n",
        "def clean_debatesum(x):\n",
        "    x['query'] = x['Abstract']\n",
        "    x['positives'] = [x['Extract']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "\n",
        "def filter_chatgptparaphrases(x):\n",
        "    return x['category']=='sentence'\n",
        "\n",
        "def clean_chatgptparaphrases(x):\n",
        "    x['query'] = x['text']\n",
        "    x['positives'] = eval(x['paraphrases'])\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_gigaword(x):\n",
        "    x['query'] = x['summary']\n",
        "    x['positives'] = [x['document']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "#dict_keys(['question_id', 'question', 'document_title', 'answer', 'label'])\n",
        "sts_streaming_cleaning_functions = {\n",
        "    'xsum':(clean_xsum, None, ['query','positives','negatives'],['summary','id','document']),\n",
        "    'embedding-data/simple-wiki':(clean_simple_wiki, None, ['query','positives','negatives'],['set']),\n",
        "    'embedding-data/coco_captions_quintets':(clean_coco_captions_quintets,None, ['query','positives','negatives'],['set']),\n",
        "    'embedding-data/SPECTER':(clean_specter,None, ['query','positives','negatives'],['set']),\n",
        "    'paws':(clean_paws,None, ['query','positives','negatives'],['id', 'sentence1', 'sentence2', 'label']),\n",
        "    'embedding-data/QQP_triplets':(clean_qqp,None, ['query','positives','negatives'],['set']),\n",
        "    \"allenai/scirepeval\":(clean_allenai_citeprediction, None,  ['query','positives','negatives'], ['pos','neg']),\n",
        "    \"lighteval/legal_summarization\":(clean_legalsum, None, ['query','positives','negatives'], ['article', 'summary']),\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\":(\n",
        "        clean_ledgarlabelled, None, ['query','label'], ['provision','source']\n",
        "    ),\n",
        "    \"eurlex\":(clean_eurlex, None,  ['query','positives','negatives'], ['celex_id', 'title', 'text', 'eurovoc_concepts']),\n",
        "    'humarin/chatgpt-paraphrases':(clean_chatgptparaphrases, filter_chatgptparaphrases, ['query','positives','negatives'], ['text','paraphrases','category','source']),\n",
        "    'gigaword':(clean_gigaword, None, ['query','positives','negatives'], ['document','summary'])\n",
        "}\n",
        "\n",
        "DEFAULT_PROB = 1.0\n",
        "sts_files = [\n",
        "    # dataset name, subset, take_probability, dataset size\n",
        "    ('xsum', None, DEFAULT_PROB, 204000, 'sts_by_triplet', False),\n",
        "    ('embedding-data/simple-wiki',None, DEFAULT_PROB, 102000, 'sts_by_triplet', False), # wikipedia paraphrases\n",
        "    ('embedding-data/coco_captions_quintets',None, DEFAULT_PROB,82800, 'sts_by_triplet', False), # caption paraphrases\n",
        "    ('embedding-data/SPECTER',None, DEFAULT_PROB,684000, 'sts_by_triplet', False), # ?\n",
        "    ('paws','labeled_final',DEFAULT_PROB, 49400, 'sts_by_triplet', False), # paws paraphrases\n",
        "    ('embedding-data/QQP_triplets',None,DEFAULT_PROB, 102000, 'sts_by_triplet', False), # quora?\n",
        "    (\"allenai/scirepeval\", 'cite_prediction_new', DEFAULT_PROB, 1300000, 'sts_by_triplet', False), # ?\n",
        "    (\"lighteval/legal_summarization\",\"BillSum\", DEFAULT_PROB, 18900, 'sts_by_triplet', False),\n",
        "    ('https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip', None, DEFAULT_PROB, 1000000, 'sts_by_label', False),\n",
        "    ('eurlex', None, DEFAULT_PROB, 45000, 'sts_by_label', False),\n",
        "    ('humarin/chatgpt-paraphrases',None, DEFAULT_PROB, 172059, 'sts_by_triplet', False),\n",
        "    ('gigaword', None, DEFAULT_PROB, 2000000, 'sts_by_triplet',False),\n",
        "]\n",
        "\n",
        "stsdata_streaming_config = {\n",
        "    'files':sts_files,\n",
        "    'max_seq_length':512,\n",
        "    'prepend_q': 'passage: ',\n",
        "    'prepend_a': 'passage: ',\n",
        "    'val_size':100,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LamNdWbR0P8e",
        "outputId": "426e4a63-3155-4d0e-ce47-aabd49600f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing the streaming-QA to static-dataset procedure...\n",
            "RELOADING VAL-STS SET: iter=cache_val_sts.pkl\n",
            "VAL-STS SET SIZE: 196\n",
            "trying humarin/chatgpt-paraphrases initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-81f2c6c048238397\n",
            "INFO:datasets.builder:Using custom data configuration default-81f2c6c048238397\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 200 from humarin/chatgpt-paraphrases validation\n",
            "take 500 from humarin/chatgpt-paraphrases train\n",
            "Done getting streams/reloading from humarin/chatgpt-paraphrases\n",
            "done train language check\n",
            "Done collecting STS streaming data\n",
            "saving streamed STS training for epoch 0: cache_train_sts2_000.pkl\n"
          ]
        }
      ],
      "source": [
        "stsdata_streaming_config = {\n",
        "    'files':sts_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':200,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "sts_statics_datsets = initialize_and_get_triplet_streaming_datasets(\n",
        "    data_streaming_config = stsdata_streaming_config,\n",
        "    streaming_cleaning_functions = sts_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_sts.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_sts_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'STS' #\n",
        ")\n",
        "\n",
        "\n",
        "if False:\n",
        "    print('old functions')\n",
        "    # initialize streaming data for sts tasks\n",
        "    sts_streaming_datsets, sts_probabilities, sts_datasizes = initialize_qa_streaming_datasets(\n",
        "        stsdata_streaming_config,\n",
        "        sts_streaming_cleaning_functions\n",
        "    )\n",
        "\n",
        "    # split and make-static (train and val sets, non-streaming)\n",
        "    sts_statics_datsets = train_test_splits_from_stream_qa(\n",
        "        streaming_dataset=sts_streaming_datsets,\n",
        "        val_size = 100,#2000,\n",
        "        epoch = 0,\n",
        "        chunk_size = 2000,#6000,\n",
        "        path_to_val_cache = 'val_sts_cache.pkl',\n",
        "        probabilities = sts_probabilities,\n",
        "        datasizes = sts_datasizes,\n",
        "        seed=stsdata_streaming_config['seed']\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcFQO9CMc533"
      },
      "outputs": [],
      "source": [
        "for i,e in enumerate(sts_statics_datsets['train'][::24]):\n",
        "  if i>20:\n",
        "    break\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPXgARu-hLn3",
        "outputId": "d88642d1-e658-48e3-f7eb-dc4a8af840a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Speaker Martin concluded that Eisenhower worked too much through subordinates in dealing with Congress, with results, \"often the reverse of what he has desired\" because Members of Congress, \"resent having some young fellow who was picked up by the White House without ever having been elected to office himself coming around and telling them \\'The Chief wants this\\'.',\n",
              " 'positives': '[\\'Speaker Martin stated that Eisenhower relied heavily on subordinates to handle Congress, leading to outcomes that were often contrary to his intentions. This was due to the fact that Members of Congress disliked being instructed by inexperienced individuals who were appointed by the White House and had never been elected to office themselves.\\', \"According to Speaker Martin, Eisenhower\\'s approach to dealing with Congress involved delegating too much responsibility to subordinates, resulting in outcomes that were frequently the opposite of what he had intended. This was due to the fact that Members of Congress resented being told what to do by young individuals who had been handpicked by the White House and had no prior experience in elected office.\", \"Speaker Martin concluded that Eisenhower\\'s strategy for managing Congress relied too heavily on subordinates, resulting in outcomes that were often the opposite of what he had hoped for. This was due to the fact that Members of Congress were unhappy with being instructed by inexperienced individuals who had been appointed by the White House and had never been elected to office themselves.\", \"Eisenhower\\'s tendency to rely on subordinates to handle Congress was criticized by Speaker Martin, who argued that this approach frequently led to outcomes that were contrary to the President\\'s intentions. This was due to the fact that Members of Congress were unhappy with being instructed by young individuals who had been appointed by the White House and had no prior experience in elected office.\", \"Speaker Martin\\'s assessment of Eisenhower\\'s approach to dealing with Congress was that he relied too heavily on subordinates, resulting in outcomes that were often the opposite of what he had intended. This was due to the fact that Members of Congress were unhappy with being instructed by inexperienced individuals who had been appointed by the White House and had never been elected to office themselves.\"]',\n",
              " 'negatives': [],\n",
              " 'type': 'sts_triplet'}"
            ]
          },
          "execution_count": 396,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sts_statics_datsets['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p9YPJwhkt3h",
        "outputId": "c0ce8e39-ad09-488e-b1f4-6c657295cd50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from multiprocessing import Pool\n",
        "# Download stopwords and lemmatization resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "#lemmatizer = WordNetLemmatizer()\n",
        "#stemmer = PorterStemmer()\n",
        "#stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LLn5zFf0i2E"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LabelProcesser:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pos_thres = 0.97,\n",
        "        neg_thres = 0.9,\n",
        "        min_similarity_matrix_pos =0.34,\n",
        "        max_similarity_matrix_pos = 0.30,\n",
        "        examples=None, seed=42, textname='text',labelname='label'\n",
        "    ):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this\n",
        "        #self.lemmatizer = WordNetLemmatizer()\n",
        "        #self.stemmer = PorterStemmer()\n",
        "        #self.stop_words = set(stopwords.words('english'))\n",
        "        #self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def jaccard_similarity(tokens1, tokens2):\n",
        "        set1 = set(tokens1)\n",
        "        set2 = set(tokens2)\n",
        "        intersection = set1.intersection(set2)\n",
        "        union = set1.union(set2)\n",
        "        similarity_score = len(intersection) / len(union)\n",
        "        return similarity_score\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _compute_similarity_for_processor_func(self, pair):\n",
        "        \"\"\"to be used internally with Pool map similarity functions\"\"\"\n",
        "        idx, j, tokens1, tokens2 = pair\n",
        "        return idx, j, self.jaccard_similarity(tokens1, tokens2)\n",
        "\n",
        "    def compute_similarity_matrix(self, corpus):\n",
        "        \"\"\"Csompute similarity using calculate_similarity\"\"\"\n",
        "        corpus_size = len(corpus)\n",
        "\n",
        "        # Create an empty similarity matrix\n",
        "        similarity_matrix = np.zeros((corpus_size, corpus_size))\n",
        "\n",
        "        # Generate all pairwise combinations of indices and texts\n",
        "        pairs = [(i, j, corpus[i], corpus[j]) for i in range(corpus_size) for j in range(i + 1, corpus_size)]\n",
        "\n",
        "        # Use parallel processing to compute similarities efficiently\n",
        "        with Pool() as pool:\n",
        "            results = pool.map(self._compute_similarity_for_processor_func, pairs)\n",
        "\n",
        "        # Fill in the similarity matrix\n",
        "        for i,j, similarity in results:\n",
        "            #i, j = divmod(idx, corpus_size)\n",
        "            similarity_matrix[i, j] = similarity\n",
        "            similarity_matrix[j, i] = similarity\n",
        "\n",
        "        # threshold the similarity matrx -- no, because that will creat positives in the negatives\n",
        "        return similarity_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def is_in(tuple1, tuple2):\n",
        "        \"\"\"is a in b or b in a\"\"\"\n",
        "        s1=set(tuple1); s2 = set(tuple2)\n",
        "        if not bool(s1.difference(s2)):\n",
        "            return True\n",
        "        return not bool(s2.difference(s1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _quick_text_hash(text):\n",
        "        return re.sub(\"\\W+\",\"\",text.lower())\n",
        "\n",
        "    def find_positive(\n",
        "        self,\n",
        "        query_text, # text of anchor/query (used to ensure not too similar, like an exact match)\n",
        "        query_labelstem, # processed label (often a multi-label)\n",
        "        corpus_keys, # corpus keys of other labels to find matches\n",
        "        max_candidates=15\n",
        "    ):\n",
        "        \"\"\"find positive match, based on best overlap of multi-label\"\"\"\n",
        "        # first, check if there are other text with same label\n",
        "        query_label_hash = self._quick_text_hash(query_text)\n",
        "\n",
        "        # get all text with same label\n",
        "        best_candidates_text = [\n",
        "            s for s in self.label_corpus[query_labelstem] if self._quick_text_hash(s)!=query_label_hash\n",
        "        ]\n",
        "        if len(best_candidates_text)==0:\n",
        "            # no similar text: need to find text with overlapping labelss\n",
        "            kidx = corpus_keys.index(query_labelstem)\n",
        "            # get similarities with other keys\n",
        "            k_similarities = self.SimMat[kidx]\n",
        "            if k_similarities.max()==0:\n",
        "                #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                return []\n",
        "            else:\n",
        "                idx_bests = np.argsort(-1*k_similarities)[:max_candidates]\n",
        "                # get most similar labels\n",
        "                label_candidates = [\n",
        "                    corpus_keys[j] for j in idx_bests if k_similarities[j]>= self.min_similarity_matrix\n",
        "                ]\n",
        "                # assert that the labels are AT LEAST inside of each other -- otherwise, no match\n",
        "                label_candidates = [\n",
        "                    lab for lab in label_candidates if self.is_in(lab, query_labelstem)\n",
        "                ]\n",
        "                if len(label_candidates)==0:\n",
        "                    #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                    return []\n",
        "\n",
        "                # get the text of the top candidate text\n",
        "                best_candidates_text = [subs for s in [\n",
        "                    self.label_corpus[lab] for lab in label_candidates\n",
        "                ] for subs in s][:100]\n",
        "\n",
        "                # ensure candidate texts are not the same\n",
        "                best_candidates_text = [\n",
        "                  s for s in self.label_corpus[query_labelstem] if self._quick_text_hash(s)!=query_label_hash\n",
        "                ]\n",
        "                if len(best_candidates_text)==0:\n",
        "                    #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                    return []\n",
        "\n",
        "        # grab first candidate text htat is NOT a high jaccard similarity\n",
        "        best_candidates_text = best_candidates_text[::-1]\n",
        "        top_match = None\n",
        "        query_text_tokenized = [w for w in query_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "        while top_match is None and len(best_candidates_text)>0:\n",
        "            candidate_text = best_candidates_text.pop()\n",
        "            # check that they aren't too similar in text\n",
        "            candidate_text_tokenized = [w for w in candidate_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "            candidate_sim_score = self.jaccard_similarity(query_text_tokenized, candidate_text_tokenized)\n",
        "            if candidate_sim_score < self.pos_thres:\n",
        "                top_match = candidate_text\n",
        "                return [top_match]\n",
        "        #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "        #print('Its candidate pool was:')\n",
        "        #print(best_candidates_text[:4])\n",
        "        return []\n",
        "\n",
        "    def find_positives(self, examples):\n",
        "        if True:\n",
        "            # find positives\n",
        "            for idx, example in enumerate(examples):\n",
        "                pos = self.find_positive(\n",
        "                    query_text=example[self.textname],\n",
        "                    query_labelstem=self.label2stem[tuple(example[self.labelname])],\n",
        "                    corpus_keys = list(self.label_corpus.keys()),\n",
        "                )\n",
        "                example.update({'positives':pos})\n",
        "                examples[idx] = example\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def find_negative(self, query_text, query_labelstem, corpus_keys, max_candidates=15, n_negatives=1):\n",
        "        # first, check if there are other text with same label\n",
        "        query_label_hash = self._quick_text_hash(query_text)\n",
        "        # get similarities with other keys\n",
        "        kidx = corpus_keys.index(query_labelstem)\n",
        "        k_similarities = self.SimMat[kidx]\n",
        "        if k_similarities.max()==0:\n",
        "            best_candidate_label = query_labelstem\n",
        "            while best_candidate_label == query_labelstem:\n",
        "                best_candidate_label = self.random.choice(corpus_keys)\n",
        "        else:\n",
        "            idx_bests = np.argsort(-1*k_similarities)[:max_candidates]\n",
        "            # get most similar labels\n",
        "            label_candidates = [\n",
        "                corpus_keys[j] for j in idx_bests if (k_similarities[j]!=0 and k_similarities[j] <= self.max_similarity_matrix)\n",
        "            ]\n",
        "            # assert that the labels have some disjoint labels\n",
        "            label_candidates = [\n",
        "                lab for lab in label_candidates if not self.is_in(lab, query_labelstem)\n",
        "            ] # disjoint entirely\n",
        "            # sample randomly from candidate labels\n",
        "            if len(label_candidates)>0:\n",
        "                best_candidate_label_idx = self.random.choice(np.arange(len(label_candidates)))\n",
        "                best_candidate_label = label_candidates[best_candidate_label_idx]\n",
        "            # sample randomly from entire corpus\n",
        "            elif len(label_candidates)==0:\n",
        "                # pick random\n",
        "                best_candidate_label = query_labelstem\n",
        "                while best_candidate_label == query_labelstem:\n",
        "                    best_candidate_label_idx = self.random.choice(np.arange(len(corpus_keys)))\n",
        "                    best_candidate_label = corpus_keys[best_candidate_label_idx]\n",
        "\n",
        "        # grab best text\n",
        "        best_candidates_text = self.label_corpus[best_candidate_label]\n",
        "        if len(best_candidates_text)==0:\n",
        "            return []\n",
        "\n",
        "        # ensure texts and query are not the same\n",
        "        best_candidates_text = [\n",
        "            s for s in best_candidates_text if self._quick_text_hash(s)!=query_label_hash\n",
        "        ]\n",
        "        if len(best_candidates_text)==0:\n",
        "            return []\n",
        "\n",
        "        # ensure texts are not very similar\n",
        "        top_matches = []\n",
        "        query_text_tokenized = [w for w in query_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "        while len(top_matches) < n_negatives and len(best_candidates_text)>0:\n",
        "            candidate_text = best_candidates_text.pop()\n",
        "            # check that they aren't too similar in text\n",
        "            candidate_text_tokenized = [w for w in candidate_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "            candidate_sim_score = self.jaccard_similarity(query_text_tokenized, candidate_text_tokenized)\n",
        "            if candidate_sim_score < self.neg_thres:\n",
        "                top_matches.append(candidate_text)\n",
        "                if len(top_matches)==n_negatives:\n",
        "                    return top_matches\n",
        "        # no matches\n",
        "        return []\n",
        "\n",
        "    def find_negatives(self, examples, n_negatives=1):\n",
        "        if True:\n",
        "            # find negatives\n",
        "            for idx, example in enumerate(examples):\n",
        "                neg = self.find_negative(\n",
        "                    query_text=example[self.textname],\n",
        "                    query_labelstem=self.label2stem[tuple(example[self.labelname])],\n",
        "                    corpus_keys = list(self.label_corpus.keys()),\n",
        "                    n_negatives=1\n",
        "                )\n",
        "                example.update({'negatives':neg})\n",
        "                examples[idx] = example\n",
        "\n",
        "        return examples\n",
        "\n",
        "\n",
        "class LabelProcesserLedgar(LabelProcesser):\n",
        "    \"\"\"Preprocesses labels of LEDGAR for semantic similarity, as well as functionality for finding positive and negative pairs\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pos_thres = 0.97,\n",
        "        neg_thres = 0.9,\n",
        "        min_similarity_matrix_pos =0.33,\n",
        "        max_similarity_matrix_neg=0.3,\n",
        "        examples=None,\n",
        "        seed=42,\n",
        "        textname='text',\n",
        "        labelname='label'\n",
        "    ):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this, else 0\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "        #print(self.preprocess_label(\"The Borrowers’ obligation\"))\n",
        "        #print(self.preprocess_label(\"The Borrower's obligations\"))\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        if isinstance(text,str):\n",
        "            tokens = word_tokenize(text.lower())\n",
        "            # Remove stop words\n",
        "            filtered_tokens = [token for token in tokens if token not in self.stop_words]\n",
        "            # Perform lemmatization and stemming\n",
        "            processed_tokens = [self.lemmatizer.lemmatize(self.stemmer.stem(token)) for token in filtered_tokens]\n",
        "            processed_tokens = [w for w in processed_tokens if w not in [\"'\", \"’\", \"’s\", \"'s\", \"(\",\")\", \",\", \".\"]]\n",
        "            # Return the lemmatized and stop word-free tokens as a string\n",
        "            return sorted(processed_tokens)\n",
        "\n",
        "        elif isinstance(text,list):\n",
        "            if len(text)==1:\n",
        "                return self.preprocess_label(text[0])\n",
        "            all_labels = [self.preprocess_label(l) for l in text]\n",
        "            return sorted([subl for l in all_labels for subl in l])\n",
        "        else:\n",
        "            raise NotImplementedError(text)\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        label_corpus = {}\n",
        "        label2lem = {}\n",
        "        for example in list_of_dict_with_labels_and_text:\n",
        "            label = example[self.labelname]\n",
        "            s = example[self.textname]\n",
        "            if tuple(label) not in label2lem:\n",
        "                labelstemmed = tuple(self.preprocess_label(label))\n",
        "                label2lem[tuple(label)] = labelstemmed\n",
        "            else:\n",
        "                labelstemmed = label2lem[tuple(label)]\n",
        "            if labelstemmed not in label_corpus.keys():\n",
        "                label_corpus[labelstemmed] = []\n",
        "            if s not in label_corpus[labelstemmed]:\n",
        "                label_corpus[labelstemmed].append(s)\n",
        "\n",
        "        # next, calculate the similarities between all pairs of keys\n",
        "        return label_corpus, label2lem\n",
        "\n",
        "\n",
        "class DatasetTripletsSimilarityByCoLabel(DatasetTriplets):\n",
        "\n",
        "    def process(self, list_of_data):\n",
        "        \"\"\"Makes (query,pos,neg)-triplets, converts samples to dataframe for pytorch iteration\"\"\"\n",
        "\n",
        "        # initialize the LabelProcessor\n",
        "        label_processor = self.label_processor_class(\n",
        "            examples = list_of_data,\n",
        "            textname = self.focal_text_name\n",
        "        )\n",
        "\n",
        "        # find positives\n",
        "        list_of_data = label_processor.find_positives(list_of_data)\n",
        "\n",
        "        # only do ones with positives (otherwise no point)\n",
        "        #list_of_data = [example for example in list_of_data if len(example['positives'])>0]\n",
        "        #print(len(list_of_data))\n",
        "\n",
        "        # find negatives\n",
        "        list_of_data = label_processor.find_negatives(list_of_data, n_negatives=self.n_negatives)\n",
        "        print(len(list_of_data))\n",
        "\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(list_of_data = list_of_data)\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        df = self.sample_data_and_make_static_dataframe(self.data)\n",
        "        return df #pd.DataFrame({})\n",
        "\n",
        "    def _build_corpus_of_potential_negatives(self):\n",
        "        pass\n",
        "\n",
        "    def _find_negative(self):\n",
        "        pass\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"For data that has a label, this can be used to artifically find and create synthetic positives\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "       pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rw5n61iayhm",
        "outputId": "4d83ea72-e846-47d3-efd1-dea5cafc9305"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': \"A man who tried to cut the throat of his estranged wife's aunt has been jailed for 22 years.\",\n",
              " 'negatives': [],\n",
              " 'positives': ['Farai Kambarani, 26, was convicted of the attempted murder of social worker Ruth Nayamazana, who he wrongly blamed for not letting him see his child.\\nLuton Crown Court heard his victim, who he also punched in the head 10 to 20 times, still lives in fear.\\nKambarani was given a 22-year jail sentence with a three-year extension on licence.\\nThe court heard Kambarani, from Wolverhampton, shunted a car into the back of Ruth Nayamazana\\'s vehicle in Saxon Gate car park in Milton Keynes on 22 August last year.\\nWhen she got out, he repeatedly punched her in the head.\\nIn the witness box, the 34-year-old said he pulled out a small knife and used it against the side of her throat.\\nShe said: \"I was screaming. I thought he was going to cut my throat. The blood started gushing out.\"\\nKambarani, a former carer for elderly people, was also convicted criminal damage and stalking his former partner.\\nThe court heard Kambarani fled to the UK from Zimbabwe in November 2014 after being arrested and tortured. He began a relationship with another woman in Wolverhampton.\\nLater his wife and child moved to the UK. In June last year, he became angry when she moved in with her uncle and his wife in Milton Keynes.\\nSebastian Gardiner, defending, said: \"Fortunately, her life was not endangered. She spent three days in hospital and made a full recovery.\"\\nHe accepted the attack had caused serious psychological difficulties for the victim.\\nJudge Philip Bartle said: \"You became fixated with Ruth and saw her as an obstacle to you seeing your daughter. There was no justification for that.\"'],\n",
              " 'type': 'sts_triplet'}"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sts_statics_datsets['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhnPR4rraJV5"
      },
      "outputs": [],
      "source": [
        "class LabelProcesserEurlex(LabelProcesser):\n",
        "    \"\"\"Preprocesses labels of EURLEX for semantic similarity, as well as functionality for finding positive and negative pairs\"\"\"\n",
        "\n",
        "    def __init__(self, pos_thres = 0.97, neg_thres = 0.9, min_similarity_matrix_pos =0.33, max_similarity_matrix_neg =0.30,  examples=None, seed=42, textname='text',labelname='label'):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this, else 0\n",
        "        self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "        #print(self.preprocess_label(\"The Borrowers’ obligation\"))\n",
        "        #print(self.preprocess_label(\"The Borrower's obligations\"))\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        # eurlex labels are already \"tokenized\" into integers of concepts\n",
        "        if isinstance(text,str):\n",
        "            return text\n",
        "        elif isinstance(text,list):\n",
        "            if len(text)==1:\n",
        "                return text\n",
        "            return sorted(list(set(text)))\n",
        "        else:\n",
        "            raise NotImplementedError(text)\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        label_corpus = {}\n",
        "        label2lem = {}\n",
        "        for example in list_of_dict_with_labels_and_text:\n",
        "            label = example[self.labelname]\n",
        "            s = example[self.textname]\n",
        "            if tuple(label) not in label2lem:\n",
        "                labelstemmed = tuple(self.preprocess_label(label))\n",
        "                label2lem[tuple(label)] = labelstemmed\n",
        "            else:\n",
        "                labelstemmed = label2lem[tuple(label)]\n",
        "            if labelstemmed not in label_corpus.keys():\n",
        "                label_corpus[labelstemmed] = []\n",
        "            if s not in label_corpus[labelstemmed]:\n",
        "                label_corpus[labelstemmed].append(s)\n",
        "\n",
        "        # next, calculate the similarities between all pairs of keys\n",
        "        return label_corpus, label2lem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuLbI2CLakZh"
      },
      "outputs": [],
      "source": [
        "sts_statics_datsets['train'][0]\n",
        "\n",
        "label_processer_eurlex = LabelProcesserEurlex(\n",
        "    pos_thres = 0.97,\n",
        "    neg_thres = 0.9,\n",
        "    min_similarity_matrix_pos =0.33,\n",
        "    examples=sts_statics_datsets['train'],\n",
        "    seed=42,\n",
        "    textname='query',\n",
        "    labelname='label'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owGqWwzDW0q5"
      },
      "outputs": [],
      "source": [
        "sts_statics_datsets['train'] = label_processer_eurlex.find_positives(sts_statics_datsets['train'])\n",
        "\n",
        "sts_statics_datsets['train'] = label_processer_eurlex.find_negatives(sts_statics_datsets['train'], n_negatives=3)\n",
        "#print(len(list_of_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWrPGhgneRiN"
      },
      "outputs": [],
      "source": [
        "foo = [e for e in sts_statics_datsets['train'] if bool(e['positives'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q9NBIBYey4K",
        "outputId": "ab5276cf-5abf-40d3-86ce-d376f93a2932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-52-01dc088b8e40>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        }
      ],
      "source": [
        "sts_torchdataset_train_eurlex = DatasetTripletsSimilarityByCoLabel(\n",
        "    list_of_data=[\n",
        "        example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    seed = 42,\n",
        "    label_processor_class = LabelProcesserEurlex\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNoFf6aTUiuQ",
        "outputId": "e20ab990-2e8d-45a9-f0d3-5cd2caad3901"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-58-c010377498b5>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "sts_torchdataset_train_ledgar = DatasetTripletsSimilarityByCoLabel(\n",
        "    list_of_data=[\n",
        "        example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    seed = 42,\n",
        "    label_processor_class = LabelProcesserLedgar\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z6vZNuhaWyf",
        "outputId": "1a21d46f-e22d-40b0-87bf-5f2454f4bc32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Seller has not received any written notice of any pending or threatened condemnation of any portion of the Properties.',\n",
              " 'pos': 'If the whole or any substantial (more than 25%) part of the Premises shall be condemned by eminent domain for any public or quasi-public purpose, this Lease shall terminate on the date of the vesting of title, and Tenant shall have no claim against Landlord for the value of any unexpired portion of the term of the Lease, nor shall Tenant be entitled to any part of the condemnation award. If less than a substantial part of the Premises is condemned, this Lease shall not terminate, but Rent shall abate in proportion to the portion of the Premises condemned.',\n",
              " 'neg': \"Tenant has inspected the Premises prior to entering this Lease and hereby accepts the Premises in its “As Is” condition. Landlord shall keep the foundation, outer walls, roof and buried conduits of the Premises in good repair except the Landlord shall not be called on to make any such repairs occasioned by the negligence of the Tenant, its agents, invitees or employees. Tenant shall at Tenant’s sole cost and expense take good care of and maintain in a good condition the Premises and the fixtures, equipment and furnishings therein, and make all repairs necessary to keep them clean, in good working order and condition. It is Tenant's sole responsibility to maintain, repair and replace, whether interior or exterior, all glass and doors in or on the Premises. The heating and air conditioning system shall be under the control of Tenant and Tenant agrees that all operation and upkeep will be at Tenant's expense. Landlord shall be under no obligation, however, to bring any action or proceeding against its insurer or warrantor should the insurer or warrantor deny that such repair or replacement falls within the insurance or warranty coverage, in which event Tenant shall pay the costs of the repair or replacement. Should the repair or replacement be made by Landlord’s warrantor or insurer, Tenant shall pay upon demand to Landlord any deductible or other cost Landlord incurs for such repair or replacement. During the term of this Lease and any extension thereof, Tenant shall enter into and maintain a service agreement with a licensed air-conditioning contractor, providing routine maintenance to the air conditioning equipment. A copy of this maintenance agreement shall be provided to Landlord within thirty (30) days after the commencement of the term of this Lease. Provided Tenant maintains the service agreement with a licensed air conditioning contractor, Landlord shall be responsible for the major repair or replacement of the HVAC system provided such replacement was not caused by Tenant’s negligence. Landlord shall have the right, but not the obligation, to make repairs necessitated by the fault or negligence of Tenant, or that of Tenant's agents, employees, contractors, consultants or invitees, and Tenant shall immediately reimburse Landlord for all expenses and costs for such repairs upon demand of Landlord. Tenant shall not make any alterations, additions or improvements to the Premises without the prior written consent of the Landlord.\"}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sts_torchdataset_train_eurlex[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15D5Lf1Xp7tF"
      },
      "outputs": [],
      "source": [
        "for example in sts_statics_datsets['train']:\n",
        "    if example['type']=='sts_by_textlabel':\n",
        "        assert 'label' in example.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA27NcTqDNvL",
        "outputId": "efedfd24-fb0a-4959-ece3-c8c98b8d9f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['borrow', 'oblig']\n",
            "['borrow', 'oblig']\n",
            "0.4376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-1451465b933c>:204: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "labelprocessor = LabelProcesserLedgar(examples = [\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "foopos = labelprocessor.find_positives([\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "print(sum([bool(d['positives']) for d in foopos])/len(foopos))\n",
        "\n",
        "fooneg = labelprocessor.find_negatives([\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "print(sum([bool(d['negatives']) for d in fooneg])/len(fooneg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAP4wenTovCw",
        "outputId": "c1806b00-0a4c-4e09-d993-5c993aa59cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 111\n",
            "finished building the ANN index\n",
            "done finding negatives\n",
            "STS DatasetTriplet\n",
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 286\n",
            "finished building the ANN index\n",
            "done finding negatives\n"
          ]
        }
      ],
      "source": [
        "NEGATIVE_CORPUS_METHOD_STS ='ann-tfidf'\n",
        "# convert to torch dataset (val)\n",
        "sts_torchdataset_val = DatasetTriplets(\n",
        "    list_of_data = [\n",
        "       x for x in sts_statics_datsets['val'] if x.get('type','na') == 'sts_triplet'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "    negative_corpus_method = NEGATIVE_CORPUS_METHOD_STS\n",
        "\n",
        ")\n",
        "# convert to torch dataset (train)\n",
        "print('STS DatasetTriplet')\n",
        "sts_torchdataset_train = DatasetTriplets(\n",
        "    list_of_data = [\n",
        "       x for x in sts_statics_datsets['train'] if x.get('type','na')== 'sts_triplet'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "    negative_corpus_method = NEGATIVE_CORPUS_METHOD_STS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISaK7WFF8rTM",
        "outputId": "2abebcdc-00bb-4d38-d88b-f3f7d7386465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Elaine Sullivan Act - Amends title XVIII (Medicare) of the Social Security Act to require emergency departments to contact family members, a specified healthcare agent, or a surrogate decisionmaker of an incapacitated patient within 24 hours of arrival at the emergency department. Authorizes the Secretary of Health and Human Services to make grants to qualified not-for-profit organizations for the purpose of assisting them to establish and operate voluntary next of kin registries.',\n",
              " 'pos': \"(a) In General.--Section 1866(a)(1) of the Social Security Act (42 U.S.C. 1395cc(a)(1)) is amended-- (1) in subparagraph (U), by striking ``and'' at the end; (2) in subparagraph (V), by striking the period at the end and inserting ``, and''; and (3) by inserting after subparagraph (V) the following new subparagraph: ``(W) in the case of a hospital (as defined in section 1861(e)) with an emergency department, to adopt and enforce a policy to ensure compliance with the requirements of subsection (k) (relating to requirements to make reasonable efforts to contact certain individuals in the case of a patient who is unconscious or physically unable to communicate with staff of the hospital).''. (b) Requirement to Contact Family Members or Other Individuals With Authority to Make Health Care Decisions.--Section 1866 of such Act (42 U.S.C. 1395cc) is amended by adding at the end the following new subsection: ``(k)(1)(A) In the case of a hospital (as defined in section 1861(e)) with an emergency department, if any individual arrives at the emergency department requiring medical treatment and is unconscious or otherwise unable to communicate with a health care professional of the department, the hospital shall take reasonable measures (described in paragraph (3)) to identify and contact a person the hospital reasonably believes has the authority to make health care decisions on behalf of the individual. ``(B) A person referred to in subparagraph (A) is any of the following: ``(i) An immediate family member. ``(ii) A person authorized to make health care decisions for the individual under a durable power of attorney for health care, recognized under State law (whether by statute or as recognized by the courts of the State). ``(2)(A) The hospital shall take the reasonable measures as soon as practicable, but, subject to subparagraph (B), in no case later than the end of the 24-hour period that begins at the point in time that a health care professional of the emergency department of the hospital determines that the individual is unconscious or otherwise unable to communicate. ``(B)(i) The 24-hour period under subparagraph (A) shall not apply during any period in which the hospital implements a disaster and mass casualty program or a fire and internal disaster program, or during a declared state of emergency (as defined in clause (ii)) or other local mass casualty situation. ``(ii) For purposes of clause (i), the term `declared state of emergency' means an officially designated state of emergency that has been declared by the Federal Government or a State or local government official having authority to declare that the State, county, municipality, or locality is in a state of emergency. ``(3) Reasonable measures referred to in paragraph (1) include the following: ``(A) Contacting the emergency contact, family member, surrogate decisionmaker, or other health care agent identified from personal effects of the individual. ``(B) Examining medical records in the hospital's possession, including a review of any verbal or written report made by emergency medical technicians or the police with respect to the individual. ``(C) Insofar as actions under subparagraphs (A) and (B) are unsuccessful, contacting the hospital's social service department or the appropriate local law enforcement agency. ``(4) The provisions of this subsection do not preempt any State or local law requirement, except to the extent that the requirement directly conflicts with a requirement of this subsection.''. (c) Effective Date.--The amendments made by this section shall apply to hospitals as of the date that is one year after the date of the enactment of this Act. SEC. 3. GRANT PROGRAM FOR THE ESTABLISHMENT\",\n",
              " 'neg': \"(a) Grants Authorized.--The Secretary of Homeland Security may make a grant of financial assistance to any State or local government or Indian tribe in order to reimburse the State or local government or tribe for costs incurred by the State or local government or tribe as a result of a call or order to active duty of one or more Reserves who are first responder personnel of the State or local government or tribe if the call or order to duty is issued under the authority of a provision of law referred to in section 101(a)(13)(B) of title 10, United States Code. (b) First Responder Personnel.--For purposes of this section, the term ``first responder personnel''-- (1) means police, fire, rescue, emergency medical service, and emergency hazardous material disposal personnel; and (2) includes such other personnel as the Secretary may specify in regulations prescribed under this section. (c) Covered Costs.--(1) The costs that may be reimbursed by a grant under subsection (a) to a State or local government or Indian tribe in connection with a call or order of first responder personnel of the State or local government or tribe to active duty are any costs incurred by the State or local government or tribe as follows: (A) Costs (including salary and benefits) of hiring first responder personnel to replace the first responder personnel called or ordered to active duty. (B) Costs of overtime pay for other first responder personnel of the State or local government or tribe. (C) Any other costs that the Secretary specifies in regulations prescribed under this section. (2) Costs of a State or local government or tribe may be reimbursed by a grant under subsection (a) only if the State or local government or tribe would not have incurred such costs but for the absence of first responder personnel pursuant to a call or order to active duty described in that subsection. (3) In seeking reimbursement for costs under subsection (a), a State or local government or tribe shall deduct from the costs for which reimbursement is sought the amounts, if any, saved by the State or local government or tribe by reason of the absence of first responder personnel for active duty pursuant to a call or order to active duty described in that subsection. (d) Period Covered by Grant.--(1) Except as provided in paragraph (2), a grant under subsection (a) shall reimburse a State or local government or Indian tribe for costs incurred by the State or local government or tribe during the year preceding the year of the application for the grant under subsection (f). (2) If the active duty of a particular Reserve during a year is insufficient to meet the duty requirement in subsection (e) for such year, but when combined with active duty in the succeeding year is sufficient to meet the duty requirement for such succeeding year, a grant under subsection (a) for such succeeding year shall also reimburse the State or local government or tribe for costs incurred in connection with the active duty of the Reserve during such year. (e) Minimum Period of Duty for Reimbursement.--(1) Costs may be reimbursed by a grant under subsection (a) with respect to a particular Reserve only if the Reserve serves six or more consecutive months on active duty pursuant to a call or order to active duty issued under the authority of a provision of law referred to in subsection (a) at any time during the two calendar years preceding the application for the grant under subsection (f). (2) If a particular Reserve meets the duty requirement in paragraph (1) for a grant under subsection (a) for a year, costs reimbursable by the grant shall include any costs in connection with the active duty of the Reserve described in that paragraph during such\"}"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sts_torchdataset_train[-4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYbqWcsOtc5Q"
      },
      "source": [
        "### Pair Classifications Datasets\n",
        "- one datasets are naturally pair-based (NLI, cannot-datasets); some like the multi-label dataets can be made into a \"same class / different class\" binary dataset (ag_news, ; others like sentiment\n",
        "\n",
        "\n",
        "###### Datasets\n",
        "- DONE snli (550k, 1 file) - naturally pair classification  \n",
        "    - 3 labels: 0,1,2\n",
        "- DONE multi_nli - (393k, 1 file)\n",
        "- NO ag_news classification - (a couple of labels -- only 4)\n",
        "- DONE heegyu/news-category-dataset - (maybe multiple categories)\n",
        "- dbpedia_14 (560k, 1 file)- news classification or topic ? (~14 labels corresponding to art or building types)\n",
        "    - 14 classes\n",
        "- ccdv/patent-classification - 25k (abstract) (maybe skip)\n",
        "- fkdosilovic/docee-event-classification (21.9k, 1 file) - 59 labels (news-event like elections, diasters)\n",
        "- NO scholarly360/contracts-classification-instruction-llm-experiments - 6.05k (clauses) -- no, I think these are just the auto-labels from LEDGAR\n",
        "- NO 'rcds/swiss_judgment_prediction','mt_en', (59703 examples) (NO, it is autotranslated)\n",
        "- DONE **'tum-nlp/cannot-dataset'** - like entailment, but contains paraphrases & negations\n",
        "- NO sentiment analysis -- ?\n",
        "- NO samchain/BIS_Speeches_97_23 - next sentence prediction\n",
        "- next sentence prediction from MLM\n",
        "\n",
        "MASKING: a mask vector will be used to focus the loss only on the appropriate dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6fDrV6r75Ib",
        "outputId": "9f4e9552-02cb-416d-93cf-ae64146996b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'B-AccrualForEnvironmentalLossContingencies', 'B-AcquiredFiniteLivedIntangibleAssetsWeightedAverageUsefulLife', 'I-AcquiredFiniteLivedIntangibleAssetsWeightedAverageUsefulLife', 'B-AllocatedShareBasedCompensationExpense', 'B-AmortizationOfFinancingCosts', 'B-AmortizationOfIntangibleAssets', 'I-AmortizationOfIntangibleAssets', 'B-AntidilutiveSecuritiesExcludedFromComputationOfEarningsPerShareAmount', 'I-AntidilutiveSecuritiesExcludedFromComputationOfEarningsPerShareAmount', 'B-AreaOfRealEstateProperty', 'I-AreaOfRealEstateProperty', 'B-AssetImpairmentCharges', 'B-BusinessAcquisitionEquityInterestsIssuedOrIssuableNumberOfSharesIssued', 'B-BusinessAcquisitionPercentageOfVotingInterestsAcquired', 'I-BusinessAcquisitionPercentageOfVotingInterestsAcquired', 'B-BusinessCombinationAcquisitionRelatedCosts', 'B-BusinessCombinationConsiderationTransferred1', 'B-BusinessCombinationContingentConsiderationLiability', 'B-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibleAssetsOtherThanGoodwill', 'B-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibles', 'B-CapitalizedContractCostAmortization', 'B-CashAndCashEquivalentsFairValueDisclosure', 'B-ClassOfWarrantOrRightExercisePriceOfWarrantsOrRights1', 'B-CommonStockCapitalSharesReservedForFutureIssuance', 'B-CommonStockDividendsPerShareDeclared', 'B-CommonStockParOrStatedValuePerShare', 'B-CommonStockSharesAuthorized', 'I-CommonStockSharesAuthorized', 'B-CommonStockSharesOutstanding', 'B-ConcentrationRiskPercentage1', 'B-ContractWithCustomerLiability', 'B-ContractWithCustomerLiabilityRevenueRecognized', 'B-CumulativeEffectOfNewAccountingPrincipleInPeriodOfAdoption', 'B-DebtInstrumentBasisSpreadOnVariableRate1', 'B-DebtInstrumentCarryingAmount', 'B-DebtInstrumentConvertibleConversionPrice1', 'B-DebtInstrumentFaceAmount', 'I-DebtInstrumentFaceAmount', 'B-DebtInstrumentFairValue', 'B-DebtInstrumentInterestRateEffectivePercentage', 'B-DebtInstrumentInterestRateStatedPercentage', 'B-DebtInstrumentMaturityDate', 'I-DebtInstrumentMaturityDate', 'B-DebtInstrumentRedemptionPricePercentage', 'B-DebtInstrumentTerm', 'I-DebtInstrumentTerm', 'B-DebtInstrumentUnamortizedDiscount', 'B-DebtWeightedAverageInterestRate', 'B-DeferredFinanceCostsGross', 'B-DeferredFinanceCostsNet', 'B-DefinedBenefitPlanContributionsByEmployer', 'B-DefinedContributionPlanCostRecognized', 'B-Depreciation', 'B-DerivativeFixedInterestRate', 'B-DerivativeNotionalAmount', 'B-DisposalGroupIncludingDiscontinuedOperationConsideration', 'B-EffectiveIncomeTaxRateContinuingOperations', 'B-EffectiveIncomeTaxRateReconciliationAtFederalStatutoryIncomeTaxRate', 'B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognized', 'B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedPeriodForRecognition1', 'I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedPeriodForRecognition1', 'B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedShareBasedAwardsOtherThanOptions', 'B-EmployeeServiceShareBasedCompensationTaxBenefitFromCompensationExpense', 'B-EquityMethodInvestmentOwnershipPercentage', 'I-EquityMethodInvestmentOwnershipPercentage', 'B-EquityMethodInvestments', 'B-FiniteLivedIntangibleAssetUsefulLife', 'I-FiniteLivedIntangibleAssetUsefulLife', 'B-GainsLossesOnExtinguishmentOfDebt', 'B-Goodwill', 'B-GoodwillImpairmentLoss', 'B-GuaranteeObligationsMaximumExposure', 'B-IncomeLossFromEquityMethodInvestments', 'B-IncomeTaxExpenseBenefit', 'B-InterestExpense', 'B-InterestExpenseDebt', 'B-LeaseAndRentalExpense', 'B-LesseeOperatingLeaseRenewalTerm', 'I-LesseeOperatingLeaseRenewalTerm', 'B-LesseeOperatingLeaseTermOfContract', 'I-LesseeOperatingLeaseTermOfContract', 'B-LettersOfCreditOutstandingAmount', 'B-LineOfCredit', 'B-LineOfCreditFacilityCommitmentFeePercentage', 'B-LineOfCreditFacilityCurrentBorrowingCapacity', 'B-LineOfCreditFacilityInterestRateAtPeriodEnd', 'B-LineOfCreditFacilityMaximumBorrowingCapacity', 'B-LineOfCreditFacilityRemainingBorrowingCapacity', 'B-LineOfCreditFacilityUnusedCapacityCommitmentFeePercentage', 'B-LongTermDebt', 'B-LongTermDebtFairValue', 'B-LossContingencyAccrualAtCarryingValue', 'B-LossContingencyDamagesSoughtValue', 'B-LossContingencyEstimateOfPossibleLoss', 'B-LossContingencyPendingClaimsNumber', 'I-LossContingencyPendingClaimsNumber', 'B-MinorityInterestOwnershipPercentageByNoncontrollingOwners', 'B-MinorityInterestOwnershipPercentageByParent', 'B-NumberOfOperatingSegments', 'B-NumberOfRealEstateProperties', 'I-NumberOfRealEstateProperties', 'B-NumberOfReportableSegments', 'B-OperatingLeaseCost', 'B-OperatingLeaseExpense', 'B-OperatingLeaseLiability', 'B-OperatingLeasePayments', 'B-OperatingLeaseRightOfUseAsset', 'B-OperatingLeaseWeightedAverageDiscountRatePercent', 'B-OperatingLeaseWeightedAverageRemainingLeaseTerm1', 'I-OperatingLeaseWeightedAverageRemainingLeaseTerm1', 'B-OperatingLeasesRentExpenseNet', 'B-OperatingLossCarryforwards', 'B-PaymentsToAcquireBusinessesGross', 'B-PaymentsToAcquireBusinessesNetOfCashAcquired', 'B-PreferredStockDividendRatePercentage', 'B-PreferredStockSharesAuthorized', 'I-PreferredStockSharesAuthorized', 'B-ProceedsFromIssuanceOfCommonStock', 'B-PropertyPlantAndEquipmentUsefulLife', 'I-PropertyPlantAndEquipmentUsefulLife', 'B-PublicUtilitiesRequestedRateIncreaseDecreaseAmount', 'B-RelatedPartyTransactionAmountsOfTransaction', 'I-RelatedPartyTransactionAmountsOfTransaction', 'B-RelatedPartyTransactionExpensesFromTransactionsWithRelatedParty', 'I-RelatedPartyTransactionExpensesFromTransactionsWithRelatedParty', 'B-RepaymentsOfDebt', 'B-RestructuringAndRelatedCostExpectedCost1', 'B-RestructuringCharges', 'B-RevenueFromContractWithCustomerExcludingAssessedTax', 'B-RevenueFromContractWithCustomerIncludingAssessedTax', 'B-RevenueFromRelatedParties', 'B-RevenueRemainingPerformanceObligation', 'B-Revenues', 'B-SaleOfStockNumberOfSharesIssuedInTransaction', 'I-SaleOfStockNumberOfSharesIssuedInTransaction', 'B-SaleOfStockPricePerShare', 'B-ShareBasedCompensation', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardAwardVestingPeriod1', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardAwardVestingPeriod1', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriod', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriod', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriodWeightedAverageGrantDateFairValue', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedNumber', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodTotalFairValue', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAuthorized', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAuthorized', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAvailableForGrant', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodTotalIntrinsicValue', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodGross', 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageGrantDateFairValue', 'B-SharePrice', 'B-SharebasedCompensationArrangementBySharebasedPaymentAwardAwardVestingRightsPercentage', 'I-SharebasedCompensationArrangementBySharebasedPaymentAwardAwardVestingRightsPercentage', 'B-SharebasedCompensationArrangementBySharebasedPaymentAwardExpirationPeriod', 'I-SharebasedCompensationArrangementBySharebasedPaymentAwardExpirationPeriod', 'B-StockIssuedDuringPeriodSharesNewIssues', 'I-StockIssuedDuringPeriodSharesNewIssues', 'B-StockRepurchaseProgramAuthorizedAmount1', 'B-StockRepurchaseProgramRemainingAuthorizedRepurchaseAmount1', 'B-StockRepurchasedAndRetiredDuringPeriodShares', 'B-StockRepurchasedDuringPeriodShares', 'I-StockRepurchasedDuringPeriodShares', 'B-SupplementalInformationForPropertyCasualtyInsuranceUnderwritersPriorYearClaimsAndClaimsAdjustmentExpense', 'B-TreasuryStockAcquiredAverageCostPerShare', 'B-TreasuryStockSharesAcquired', 'I-TreasuryStockSharesAcquired', 'B-TreasuryStockValueAcquiredCostMethod', 'B-UnrecognizedTaxBenefits', 'B-UnrecognizedTaxBenefitsThatWouldImpactEffectiveTaxRate', 'I-DeferredFinanceCostsGross', 'I-CommonStockParOrStatedValuePerShare', 'I-LossContingencyEstimateOfPossibleLoss', 'I-DefinedContributionPlanCostRecognized', 'I-DebtInstrumentFairValue', 'I-ContractWithCustomerLiabilityRevenueRecognized', 'I-RevenueRemainingPerformanceObligation', 'I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognized', 'I-DebtInstrumentInterestRateStatedPercentage', 'I-OperatingLossCarryforwards', 'I-MinorityInterestOwnershipPercentageByNoncontrollingOwners', 'I-InterestExpense', 'I-LongTermDebt', 'I-ShareBasedCompensation', 'I-DebtWeightedAverageInterestRate', 'I-DebtInstrumentCarryingAmount', 'I-DebtInstrumentConvertibleConversionPrice1', 'I-IncomeTaxExpenseBenefit', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageGrantDateFairValue', 'I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedShareBasedAwardsOtherThanOptions', 'I-EquityMethodInvestments', 'I-DebtInstrumentUnamortizedDiscount', 'I-GainsLossesOnExtinguishmentOfDebt', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAvailableForGrant', 'I-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibleAssetsOtherThanGoodwill', 'I-PreferredStockDividendRatePercentage', 'I-RevenueFromContractWithCustomerIncludingAssessedTax', 'I-OperatingLeaseWeightedAverageDiscountRatePercent', 'I-LineOfCredit', 'I-LineOfCreditFacilityMaximumBorrowingCapacity', 'I-EffectiveIncomeTaxRateReconciliationAtFederalStatutoryIncomeTaxRate', 'I-LineOfCreditFacilityCommitmentFeePercentage', 'I-BusinessCombinationConsiderationTransferred1', 'I-CommonStockDividendsPerShareDeclared', 'I-DebtInstrumentBasisSpreadOnVariableRate1', 'I-DisposalGroupIncludingDiscontinuedOperationConsideration', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodGross', 'I-CommonStockSharesOutstanding', 'I-AmortizationOfFinancingCosts', 'I-LineOfCreditFacilityCurrentBorrowingCapacity', 'I-TreasuryStockValueAcquiredCostMethod', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedNumber', 'I-DebtInstrumentInterestRateEffectivePercentage', 'I-SaleOfStockPricePerShare', 'I-CapitalizedContractCostAmortization', 'I-RestructuringCharges', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodTotalFairValue', 'I-AccrualForEnvironmentalLossContingencies', 'I-CashAndCashEquivalentsFairValueDisclosure', 'I-ProceedsFromIssuanceOfCommonStock', 'I-Revenues', 'I-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibles', 'I-LettersOfCreditOutstandingAmount', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriodWeightedAverageGrantDateFairValue', 'I-OperatingLeasePayments', 'I-LineOfCreditFacilityRemainingBorrowingCapacity', 'I-PaymentsToAcquireBusinessesGross', 'I-TreasuryStockAcquiredAverageCostPerShare', 'I-DeferredFinanceCostsNet', 'I-StockRepurchaseProgramAuthorizedAmount1', 'I-InterestExpenseDebt', 'I-ContractWithCustomerLiability', 'I-OperatingLeaseExpense', 'I-Depreciation', 'I-AllocatedShareBasedCompensationExpense', 'I-LossContingencyAccrualAtCarryingValue', 'I-LineOfCreditFacilityUnusedCapacityCommitmentFeePercentage', 'I-SupplementalInformationForPropertyCasualtyInsuranceUnderwritersPriorYearClaimsAndClaimsAdjustmentExpense', 'I-OperatingLeaseLiability', 'I-RevenueFromRelatedParties', 'I-PaymentsToAcquireBusinessesNetOfCashAcquired', 'I-BusinessCombinationContingentConsiderationLiability', 'I-LossContingencyDamagesSoughtValue', 'I-NumberOfOperatingSegments', 'I-BusinessAcquisitionEquityInterestsIssuedOrIssuableNumberOfSharesIssued', 'I-OperatingLeaseRightOfUseAsset', 'I-BusinessCombinationAcquisitionRelatedCosts', 'I-UnrecognizedTaxBenefits', 'I-GuaranteeObligationsMaximumExposure', 'I-RestructuringAndRelatedCostExpectedCost1', 'I-DefinedBenefitPlanContributionsByEmployer', 'I-OperatingLeaseCost', 'I-DerivativeFixedInterestRate', 'I-Goodwill', 'I-GoodwillImpairmentLoss', 'I-CommonStockCapitalSharesReservedForFutureIssuance', 'I-StockRepurchasedAndRetiredDuringPeriodShares', 'I-EmployeeServiceShareBasedCompensationTaxBenefitFromCompensationExpense', 'I-IncomeLossFromEquityMethodInvestments', 'I-NumberOfReportableSegments', 'I-LongTermDebtFairValue', 'I-RepaymentsOfDebt', 'I-ConcentrationRiskPercentage1', 'I-DebtInstrumentRedemptionPricePercentage', 'I-CumulativeEffectOfNewAccountingPrincipleInPeriodOfAdoption', 'I-SharePrice', 'I-UnrecognizedTaxBenefitsThatWouldImpactEffectiveTaxRate', 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodTotalIntrinsicValue', 'I-EffectiveIncomeTaxRateContinuingOperations', 'I-RevenueFromContractWithCustomerExcludingAssessedTax', 'I-StockRepurchaseProgramRemainingAuthorizedRepurchaseAmount1', 'I-LineOfCreditFacilityInterestRateAtPeriodEnd', 'I-ClassOfWarrantOrRightExercisePriceOfWarrantsOrRights1', 'I-OperatingLeasesRentExpenseNet', 'I-LeaseAndRentalExpense', 'I-PublicUtilitiesRequestedRateIncreaseDecreaseAmount', 'I-MinorityInterestOwnershipPercentageByParent', 'I-AssetImpairmentCharges', 'I-DerivativeNotionalAmount']\n"
          ]
        }
      ],
      "source": [
        "#from datasets import load_dataset\n",
        "foo =load_dataset(\"nlpaueb/finer-139\", split=\"train\") # very big, maybe just download the val\n",
        "\n",
        "# these can be converted to a smaller subset by stripping the B- and I-\n",
        "tag_names_full = foo.features[\"ner_tags\"].feature.names\n",
        "print(tag_names_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnt-qYtg8m9v",
        "outputId": "09cf6f3d-f767-477d-a23f-79591e463675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['example_id', 'citing_prompt', 'holding_0', 'holding_1', 'holding_2', 'holding_3', 'holding_4', 'label'])\n"
          ]
        }
      ],
      "source": [
        "labels = set()\n",
        "for i,e in enumerate(foo):\n",
        "    labels |= {e['label']}\n",
        "    if i > 2:\n",
        "        break\n",
        "\n",
        "print(e.keys())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmaObS_dP0HK",
        "outputId": "ef45c535-72a1-4201-caf0-5d70390dc3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['snli|||snli', 'multi_nli|||multi_nli', 'tum-nlp/cannot-dataset|||tum-nlp/cannot-dataset', 'kiddothe2b/contract-nli|||kiddothe2b/contract-nli/contractnli_a', 'kiddothe2b/contract-nli|||kiddothe2b/contract-nli/contractnli_b', 'heegyu/news-category-dataset|||heegyu/news-category-dataset', 'fkdosilovic/docee-event-classification|||fkdosilovic/docee-event-classification', 'DeveloperOats/DBPedia_Classes|||DeveloperOats/DBPedia_Classes_level2', 'DeveloperOats/DBPedia_Classes|||DeveloperOats/DBPedia_Classes_level3', 'casehold/casehold|||casehold/casehold_positives', 'casehold/casehold|||casehold/casehold_negatives', 'mteb/mtop_intent|||mteb/mtop_intent']\n"
          ]
        }
      ],
      "source": [
        "DEFAULT_COLUMNS = ['pair1','pair2','label','type','cls_id','n_labels']\n",
        "\n",
        "DBPEDIA_L2 = {\n",
        "    'Tower': 0, 'NaturalPlace': 1, 'Presenter': 2, 'RacingDriver': 3, 'FloweringPlant': 4, 'SportFacility': 5, 'Venue': 6, 'Database': 7,\n",
        "    'EducationalInstitution': 8, 'Olympics': 9, 'Race': 10, 'VolleyballPlayer': 11, 'Infrastructure': 12, 'MusicalWork': 13, 'Genre': 14, 'ComicsCharacter': 15,\n",
        "    'Song': 16, 'MusicalArtist': 17, 'Settlement': 18, 'Tournament': 19, 'Engine': 20, 'Politician': 21, 'Coach': 22, 'SocietalEvent': 23, 'Person': 24,\n",
        "    'LegalCase': 25, 'AmusementParkAttraction': 26, 'GridironFootballPlayer': 27, 'Cleric': 28, 'FootballLeagueSeason': 29, 'MotorcycleRider': 30, 'SportsTeam': 31,\n",
        "    'SportsEvent': 32, 'Satellite': 33, 'Eukaryote': 34, 'RaceTrack': 35, 'Boxer': 36, 'Wrestler': 37, 'Scientist': 38, 'Building': 39, 'Actor': 40, 'Plant': 41,\n",
        "    'Cartoon': 42, 'NaturalEvent': 43, 'SportsLeague': 44, 'RouteOfTransportation': 45, 'OrganisationMember': 46, 'FictionalCharacter': 47, 'Horse': 48,\n",
        "    'ClericalAdministrativeRegion': 49, 'PeriodicalLiterature': 50, 'WrittenWork': 51, 'Writer': 52, 'CelestialBody': 53, 'WinterSportPlayer': 54,\n",
        "    'SportsTeamSeason': 55, 'Company': 56, 'Animal': 57, 'Broadcaster': 58, 'BritishRoyalty': 59, 'Organisation': 60, 'Athlete': 61, 'Group': 62, 'Stream': 63,\n",
        "    'Artist': 64, 'Station': 65, 'SportsManager': 66, 'BodyOfWater': 67, 'Software': 68, 'Comic': 69, 'other': 70\n",
        "}\n",
        "\n",
        "DBPEDIA_L3 = {\n",
        "    'TelevisionStation': 0, 'NetballPlayer': 1, 'FigureSkater': 2, 'BadmintonPlayer': 3, 'School': 4, 'River': 5, 'WomensTennisAssociationTournament': 6,\n",
        "    'ShoppingMall': 7, 'GreenAlga': 8, 'Winery': 9, 'Religious': 10, 'SumoWrestler': 11, 'Planet': 12, 'Swimmer': 13, 'Curler': 14, 'Astronaut': 15,\n",
        "    'MemberOfParliament': 16, 'MythologicalFigure': 17, 'CanadianFootballTeam': 18, 'OlympicEvent': 19, 'Senator': 20, 'Album': 21, 'PublicTransitSystem': 22,\n",
        "    'Photographer': 23, 'Library': 24, 'Village': 25, 'Play': 26, 'Legislature': 27, 'AdultActor': 28, 'Lake': 29, 'Earthquake': 30,\n",
        "    'SupremeCourtOfTheUnitedStatesCase': 31, 'Airline': 32, 'Road': 33, 'SoccerPlayer': 34, 'BaseballSeason': 35, 'CultivatedVariety': 36, 'Judge': 37,\n",
        "    'PlayboyPlaymate': 38, 'GolfPlayer': 39, 'RadioHost': 40, 'WrestlingEvent': 41, 'Theatre': 42, 'Saint': 43, 'CollegeCoach': 44, 'VideoGame': 45,\n",
        "    'NCAATeamSeason': 46, 'Museum': 47, 'GolfCourse': 48, 'ComicsCreator': 49, 'Cycad': 50, 'Bird': 51, 'Stadium': 52, 'Magazine': 53, 'Manga': 54,\n",
        "    'Newspaper': 55, 'BaseballPlayer': 56, 'Reptile': 57, 'Diocese': 58, 'ChessPlayer': 59, 'SoccerLeague': 60, 'Grape': 61, 'Architect': 62, 'Monarch': 63,\n",
        "    'Cave': 64, 'Skater': 65, 'HorseRace': 66, 'RadioStation': 67, 'MilitaryPerson': 68, 'EurovisionSongContestEntry': 69, 'Fish': 70,\n",
        "    'NationalFootballLeagueSeason': 71, 'PoliticalParty': 72, 'Single': 73, 'Skier': 74, 'MixedMartialArtsEvent': 75, 'Philosopher': 76,\n",
        "    'Hospital': 77, 'BasketballTeam': 78, 'Mountain': 79, 'RailwayStation': 80, 'Comedian': 81, 'Galaxy': 82, 'AmericanFootballPlayer': 83,\n",
        "    'Cardinal': 84, 'Mollusca': 85, 'Journalist': 86, 'OfficeHolder': 87, 'Glacier': 88, 'Rower': 89, 'Baronet': 90, 'RollerCoaster': 91,\n",
        "    'BaseballLeague': 92, 'ArtificialSatellite': 93, 'Dam': 94, 'MilitaryUnit': 95, 'Engineer': 96, 'Restaurant': 97, 'HockeyTeam': 98,\n",
        "    'GaelicGamesPlayer': 99, 'Hotel': 100, 'Publisher': 101, 'Fungus': 102, 'AutomobileEngine': 103, 'Moss': 104, 'FormulaOneRacer': 105,\n",
        "    'Cricketer': 106, 'IceHockeyPlayer': 107, 'Mayor': 108, 'MartialArtist': 109, 'RaceHorse': 110, 'Canoeist': 111, 'BeachVolleyballPlayer': 112,\n",
        "    'RecordLabel': 113, 'Musical': 114, 'BusinessPerson': 115, 'ArtistDiscography': 116, 'SoccerClubSeason': 117, 'Ambassador': 118, 'Gymnast': 119,\n",
        "    'RailwayLine': 120, 'Town': 121, 'CyclingTeam': 122, 'LacrossePlayer': 123, 'HollywoodCartoon': 124, 'MilitaryConflict': 125, 'RugbyClub': 126,\n",
        "    'Racecourse': 127, 'Pope': 128, 'RoadTunnel': 129, 'Economist': 130, 'University': 131, 'President': 132, 'Bodybuilder': 133, 'DartsPlayer': 134,\n",
        "    'Canal': 135, 'CricketGround': 136, 'Crustacean': 137, 'SpeedwayRider': 138, 'Cyclist': 139, 'MusicGenre': 140, 'Volcano': 141, 'Medician': 142,\n",
        "    'Castle': 143, 'Anime': 144, 'BasketballPlayer': 145, 'Model': 146, 'SoccerManager': 147, 'Chef': 148, 'SportsTeamMember': 149, 'Convention': 150,\n",
        "    'Airport': 151, 'HandballTeam': 152, 'FootballMatch': 153, 'ClassicalMusicComposition': 154, 'Conifer': 155, 'RugbyLeague': 156, 'Fern': 157,\n",
        "    'HistoricBuilding': 158, 'ChristianBishop': 159, 'BusCompany': 160, 'VoiceActor': 161, 'SoccerTournament': 162, 'GolfTournament': 163, 'HorseRider': 164,\n",
        "    'SolarEclipse': 165, 'Prison': 166, 'CyclingRace': 167, 'AustralianRulesFootballPlayer': 168, 'BasketballLeague': 169, 'Bridge': 170, 'Noble': 171,\n",
        "    'Arachnid': 172, 'ComicStrip': 173, 'AnimangaCharacter': 174, 'Bank': 175, 'Amphibian': 176, 'Poet': 177, 'LawFirm': 178, 'NascarDriver': 179,\n",
        "    'Congressman': 180, 'FashionDesigner': 181, 'BiologicalDatabase': 182, 'CricketTeam': 183, 'HandballPlayer': 184, 'MountainPass': 185, 'Band': 186,\n",
        "    'Brewery': 187, 'AcademicJournal': 188, 'Insect': 189, 'Jockey': 190, 'ClassicalMusicArtist': 191, 'Governor': 192, 'PokerPlayer': 193, 'Poem': 194,\n",
        "    'TennisPlayer': 195, 'Historian': 196, 'ScreenWriter': 197, 'MusicFestival': 198, 'TennisTournament': 199, 'TradeUnion': 200, 'BeautyQueen': 201,\n",
        "    'AustralianFootballTeam': 202, 'AmateurBoxer': 203, 'SquashPlayer': 204, 'Painter': 205, 'RugbyPlayer': 206, 'MountainRange': 207, 'Lighthouse': 208,\n",
        "    'TableTennisPlayer': 209, 'SoapCharacter': 210, 'IceHockeyLeague': 211, 'HorseTrainer': 212, 'Election': 213, 'GrandPrix': 214, 'PrimeMinister': 215,\n",
        "    'Entomologist': 216, 'BroadcastNetwork': 217, 'FilmFestival': 218, 'other': 219\n",
        "    }\n",
        "\n",
        "DOCEEEVENTS = {\n",
        "    'Famous Person - Death': 0, 'Strike': 1, 'Awards ceremony': 2, 'Road Crash': 3, 'Famous Person - Commit Crime - Accuse': 4, 'New wonders in nature': 5,\n",
        "    'Droughts': 6, 'Mudslides': 7, 'Shipwreck': 8, 'Government Policy Changes': 9, 'Famous Person - Commit Crime - Sentence': 10, 'Tsunamis': 11,\n",
        "    'Insect Disaster': 12, 'Government Job change - Election': 13, 'Famous Person - Sick': 14, 'Train collisions': 15, 'Financial Crisis': 16, 'Earthquakes': 17,\n",
        "    'Protest_Online Condemnation': 18, 'Tear Up Agreement': 19, 'Famine': 20, 'Organization Established': 21, 'Gas explosion': 22, 'Military Exercise': 23,\n",
        "    'Sign Agreement': 24, 'Armed Conflict': 25, 'Famous Person - Commit Crime - Arrest': 26, 'Withdraw from an Organization': 27,\n",
        "    'Famous Person - Give a speech': 28, 'Organization Closed': 30, 'Famous Person - Commit Crime - Release': 31, 'Fire': 32, 'Financial Aid': 33,\n",
        "    'Bank Robbery': 34, 'Disease Outbreaks': 35, 'Riot': 36, 'Hurricanes_Tornado_Storm_Blizzard': 37, 'Air crash': 38,\n",
        "    'Government Job change - Appoint_Inauguration': 39, 'Famous Person - Recovered': 40, 'Break historical records': 41, 'Join in an Organization': 42,\n",
        "    'Famous Person - Marriage': 43, 'Diplomatic Talks _ Diplomatic_Negotiation_ Summit Meeting': 44, 'Organization Fine': 45, 'Floods': 46,\n",
        "    'Sports Competition': 47, 'Volcano Eruption': 48, 'New achievements in aerospace': 49, 'Regime Change': 50, 'Government Job change - Resignation_Dismissal': 51,\n",
        "    'Mine Collapses': 52, 'Famous Person - Divorce': 53, 'Mass Poisoning': 54, 'New archeological discoveries': 55, 'Famous Person - Commit Crime - Investigate': 56,\n",
        "    'Diplomatic Visit': 57, 'Organization Merge': 58, 'Environment Pollution': 59, 'other': 60,\n",
        "}\n",
        "\n",
        "# categories for news categories\n",
        "NEWSCATEGORIES = {\n",
        "    'WORLDPOST': 0, 'PARENTS': 1, 'COMEDY': 2,'MONEY': 3, 'WOMEN': 4,'GOOD NEWS': 5,'WEIRD NEWS': 6,'TECH': 8,'ARTS & CULTURE': 9,\n",
        "    'WEDDINGS': 10,'EDUCATION': 11,'CRIME': 13,'FIFTY': 14,'STYLE': 15,'SPORTS': 16,'TASTE': 17,'COLLEGE': 18,'THE WORLDPOST': 19,'WORLD NEWS': 20,\n",
        "    'GREEN': 21,'CULTURE & ARTS': 22,'POLITICS': 23, 'WELLNESS': 24,'HOME & LIVING': 25,'MEDIA': 26,'SCIENCE': 27,'HEALTHY LIVING': 28,\n",
        "    'U.S. NEWS': 29,'ARTS': 30,'FOOD & DRINK': 31,'ENTERTAINMENT': 32,'ENVIRONMENT': 33,'IMPACT': 34,'RELIGION': 35,\n",
        "    'PARENTING': 36,'STYLE & BEAUTY': 37,'BUSINESS': 38,'TRAVEL': 39,'OTHER':40\n",
        "}\n",
        "\n",
        "def clean_snli(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'snli'\n",
        "    x['n_labels'] = 3\n",
        "    return x\n",
        "\n",
        "def clean_contractnli(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'contractnli'\n",
        "    x['n_labels'] = 3\n",
        "    return x\n",
        "\n",
        "def clean_mnli(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    #x['label'] = []\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'mnli'\n",
        "    x['n_labels'] = 3\n",
        "    return x\n",
        "\n",
        "def clean_cannotdatast(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'cannotdataset'\n",
        "    x['n_labels'] = 2\n",
        "    return x\n",
        "\n",
        "def clean_newscategory(x):\n",
        "    x['pair1'] = x['headline'] + \". \" + x['short_description']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = NEWSCATEGORIES.get(x['category'],NEWSCATEGORIES['OTHER'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'newscategory'\n",
        "    x['n_labels'] = 40\n",
        "    return x\n",
        "\n",
        "def clean_doceeevents(x):\n",
        "    x['pair1'] = x['text']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = DOCEEEVENTS.get(x['event_type'],DOCEEEVENTS['other'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'doceeevents'\n",
        "    x['n_labels'] = 61\n",
        "    return x\n",
        "\n",
        "def clean_dbpedia_l2(x):\n",
        "    x['pair1'] = x['text']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = DBPEDIA_L2.get(x['l2'],DBPEDIA_L2['other'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'dbpedia_l2'\n",
        "    x['n_labels'] = 71 # 219\n",
        "    return x\n",
        "\n",
        "def clean_dbpedia_l3(x):\n",
        "    x['pair1'] = x['text']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = DBPEDIA_L3.get(x['l3'],DBPEDIA_L3['other'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'dbpedia_l3'\n",
        "    x['n_labels'] = 220\n",
        "    return x\n",
        "\n",
        "def clean_casehold_positives(x):\n",
        "    x['pair1'] = x['citing_prompt'].split('(<HOLDING>)')[0]\n",
        "    correct_holding_id = int(x['label'])\n",
        "    correct_holding_text = x['holding_%d' % correct_holding_id]\n",
        "    x['pair2'] = correct_holding_text\n",
        "    x['label'] = 1\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'casehold'\n",
        "    x['n_labels'] = 2\n",
        "    return x\n",
        "\n",
        "def clean_casehold_negatives(x):\n",
        "    x['pair1'] = x['citing_prompt'].split('(<HOLDING>)')[0]\n",
        "    correct_holding_id = int(x['label'])\n",
        "    incorrect_holding_id = (correct_holding_id+1) % 4\n",
        "    incorrect_holding_text = x['holding_%d' % incorrect_holding_id]\n",
        "    x['pair2'] = incorrect_holding_text\n",
        "    x['label'] = 0\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'casehold'\n",
        "    x['n_labels'] = 2\n",
        "    return x\n",
        "\n",
        "def filter_snli(x):\n",
        "    return x['label']!=-1\n",
        "\n",
        "def filter_newscategory(x):\n",
        "    return x['category'] not in ['LATINO VOICES',\"QUEER VOICES\", \"BLACK VOICES\"]\n",
        "\n",
        "def clean_mtopintent(x):\n",
        "    # id (int64)\ttext (string)\tlabel (int32)\tlabel_text (string)\n",
        "    x['pair1'] = x['text']\n",
        "    x['pair2'] = None\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'mtopintent'\n",
        "    x['n_labels'] = 113\n",
        "    return x\n",
        "\n",
        "cls_streaming_cleaning_functions = {\n",
        "    'snli':(clean_snli, filter_snli, DEFAULT_COLUMNS,['hypothesis','premise']),\n",
        "    'multi_nli':(clean_mnli, None, DEFAULT_COLUMNS, ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_binary_parse','hypothesis_parse','genre']),\n",
        "    'tum-nlp/cannot-dataset':(clean_cannotdatast, None, DEFAULT_COLUMNS,['hypothesis','premise']),\n",
        "    'kiddothe2b/contract-nli/contractnli_a':(clean_contractnli, None, DEFAULT_COLUMNS, ['premise','hypothesis']),\n",
        "    'kiddothe2b/contract-nli/contractnli_b':(clean_contractnli, None, DEFAULT_COLUMNS, ['premise','hypothesis']),\n",
        "    'heegyu/news-category-dataset':(clean_newscategory, filter_newscategory, DEFAULT_COLUMNS, ['category', 'headline', 'authors', 'link', 'short_description', 'date']),\n",
        "    'fkdosilovic/docee-event-classification':(clean_doceeevents, None, DEFAULT_COLUMNS, ['title', 'text', 'event_type', 'date', 'metadata']),\n",
        "    'DeveloperOats/DBPedia_Classes_level2':(clean_dbpedia_l2, None, DEFAULT_COLUMNS, ['text','l1','l2','l3']),\n",
        "    'DeveloperOats/DBPedia_Classes_level3':(clean_dbpedia_l3, None, DEFAULT_COLUMNS, ['text','l1','l2','l3']),\n",
        "    'casehold/casehold_positives':(clean_casehold_positives, None, DEFAULT_COLUMNS, ['example_id', 'citing_prompt', 'holding_0', 'holding_1', 'holding_2', 'holding_3', 'holding_4']),\n",
        "    'casehold/casehold_negatives':(clean_casehold_negatives, None, DEFAULT_COLUMNS, ['example_id', 'citing_prompt', 'holding_0', 'holding_1', 'holding_2', 'holding_3', 'holding_4']),\n",
        "    'mteb/mtop_intent':(clean_mtopintent, None, DEFAULT_COLUMNS, ['label_text','id','text']),\n",
        "}\n",
        "\n",
        "DEFAULT_PROB = 1.0\n",
        "print('TODO use the FINER-149 dataset')\n",
        "cls_files = [\n",
        "    # dataset name, subset, take_probability, dataset size\n",
        "    ('snli', None, DEFAULT_PROB/2, 550000, 'pair_classification', False),\n",
        "    ('multi_nli', None, DEFAULT_PROB, 393000, 'pair_classification', False),\n",
        "    ('tum-nlp/cannot-dataset', None, DEFAULT_PROB, 77400, 'pair_classification', False),\n",
        "    ('kiddothe2b/contract-nli','contractnli_a', DEFAULT_PROB//3, 6200, 'pair_classification', False),\n",
        "    ('kiddothe2b/contract-nli','contractnli_b', DEFAULT_PROB//3, 7190, 'pair_classification', False),\n",
        "    ('heegyu/news-category-dataset', None, DEFAULT_PROB/2, 210000, 'classification', False),\n",
        "    ('fkdosilovic/docee-event-classification', None, DEFAULT_PROB/2, 21949, 'classification', False),\n",
        "    ('DeveloperOats/DBPedia_Classes', None, DEFAULT_PROB/2, 241000, 'classification', False),\n",
        "    ('DeveloperOats/DBPedia_Classes', None, DEFAULT_PROB/2, 241000,'classification', False),\n",
        "    ('casehold/casehold', 'all', DEFAULT_PROB/2, 53100, 'pair_classification', False),\n",
        "    ('casehold/casehold', 'all', DEFAULT_PROB/2, 53100, 'pair_classification', False),\n",
        "    ('mteb/mtop_intent', 'en',DEFAULT_PROB, 15700, 'classification',False)\n",
        "]\n",
        "\n",
        "clsdata_streaming_config = {\n",
        "    'files':cls_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':500,\n",
        "    'train_chunk_size':1000,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "print([k1[0]+\"|||\"+k2 for k1,k2 in zip(cls_files, list(cls_streaming_cleaning_functions.keys()))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVZo2_49P0Em"
      },
      "outputs": [],
      "source": [
        "def initialize_and_get_classification_streaming_datasets(\n",
        "    data_streaming_config,\n",
        "    streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_cls.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_cls_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'CLS' #\n",
        "):\n",
        "    \"\"\"Converts stream of unlabelled text data into static datasets for: pair-classification tasks\"\"\"\n",
        "    # list of files to stream\n",
        "    files = data_streaming_config['files']\n",
        "    # number of examples to take from stream for validation set\n",
        "    val_size = data_streaming_config['val_size']\n",
        "    # number of examples to take from stream for training set\n",
        "    train_chunk_size = data_streaming_config['train_chunk_size']\n",
        "    min_seq_len = data_streaming_config.get('min_seq_length', 48)\n",
        "    # normalization constant for normalizing the weights into probabilities\n",
        "    probability_normalization_const = sum([x[2] for x in files])\n",
        "\n",
        "    # where to initialize start-stream for training data\n",
        "    if start_proportion is None:\n",
        "        start_proportion = np.random.RandomState(seed+epoch).uniform()*0.99\n",
        "\n",
        "    # reload cached files\n",
        "    path_to_train_cache = None if not '%03g' in path_to_train_cache_epoch else path_to_train_cache_epoch % epoch\n",
        "    do_make_valset = not os.path.isfile(path_to_val_cache)\n",
        "    do_make_trainset = not os.path.isfile(path_to_train_cache)\n",
        "    if not do_make_valset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            datalist_val_triplet_static = pickle.load(pcon)\n",
        "        print(f'VAL-{name} SET SIZE: %d' % len(datalist_val_triplet_static))\n",
        "    else:\n",
        "        datalist_val_triplet_static = []\n",
        "    if not do_make_trainset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_train_cache,'rb') as pcon:\n",
        "            datalist_train_triplet_static = pickle.load(pcon)\n",
        "        print(f'TRAIN-{name} EPOCH-%d SET SIZE: %d' % (epoch, len(datalist_train_triplet_static)))\n",
        "    else:\n",
        "        datalist_train_triplet_static = []\n",
        "\n",
        "    if (do_make_trainset or do_make_valset):\n",
        "\n",
        "        # loop through datasets\n",
        "        for (data_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle), dataset_key in zip(\n",
        "            files, streaming_cleaning_functions.keys()\n",
        "        ):\n",
        "            if prob ==0:\n",
        "                continue\n",
        "            prob /= probability_normalization_const\n",
        "\n",
        "            # get cleaning & filter functions for streaming data functionality\n",
        "            clean_func, filter_func, feature_names, removefeature_names = streaming_cleaning_functions[dataset_key]\n",
        "\n",
        "            # set arguments for the load_dataset (huggingface repos)\n",
        "            load_dataset_args = {\n",
        "                'path':data_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "            }\n",
        "            # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "            if data_nm.endswith('.jsonl') or data_nm.endswith('.jsonl.zip') or data_nm.endswith('.jsonl.zst'):\n",
        "                load_dataset_args.update({'path':'json','data_files':data_nm})\n",
        "\n",
        "            # special proecssing of datasets with multiple partitions\n",
        "            if bool(partition_shuffle): # or str(epoch)=='val':\n",
        "\n",
        "                n_files, n_per_file = partition_shuffle\n",
        "                dataset_size = n_per_file\n",
        "                print('trying %s initialization (shuffling through %d files)' % (data_nm, n_files))\n",
        "\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func)\n",
        "\n",
        "                # validation set\n",
        "                if do_make_valset:\n",
        "                    # take from stream\n",
        "                    n_valset_take = max(int(prob*val_size), 1)\n",
        "                    print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert stream to a static set and do check\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "                # training set\n",
        "                if do_make_trainset:\n",
        "                    # randomly skip a bunch from this set\n",
        "                    skip_to_start = int(start_proportion*n_per_file)\n",
        "                    take_from_this_set = max(int(round(train_chunk_size*prob)),1)\n",
        "                    print('take %d from %s training'% (take_from_this_set, data_nm))\n",
        "                    # shuffle: take a random data partition (from the dataset's list of files)\n",
        "                    dset_stream_train = dset_stream_val.shuffle(\n",
        "                        seed = seed+epoch, buffer_size = skip_to_start+take_from_this_set,\n",
        "                    )\n",
        "                    dset_stream_train = dset_stream_train.skip(\n",
        "                        skip_to_start # random skip through dataset to new start position\n",
        "                    ).take(\n",
        "                        take_from_this_set # take this amount for the training ste\n",
        "                    ).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert training to static dataset\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "            else:\n",
        "                # regular streaming\n",
        "                print('trying %s initialization' % data_nm)\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "                # take from stream\n",
        "                n_valset_take = max(int(prob*val_size), 1) # size of valset\n",
        "                print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                skip_to_start = int(start_proportion*(dataset_size-n_valset_take)) # random point to skip to\n",
        "                n_train_take = max(int(round(train_chunk_size*prob)),1) # size of train set\n",
        "                print('take %d from %s train'% (n_train_take, data_nm))\n",
        "                if do_make_valset:\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take)\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "                if do_make_trainset:\n",
        "                    dset_stream_train = dset_stream.skip(n_valset_take+skip_to_start).take(n_train_take)\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "            print('Done getting streams/reloading from %s' % data_nm)\n",
        "            # check language\n",
        "            if do_make_valset:\n",
        "                # discard non-english\n",
        "                dset_static_val_thisset =[\n",
        "                    e for e in dset_static_val_thisset if check_language(e['pair1'])[0] #detect(e['pair1'][:200]+\" hello\")=='en'\n",
        "                ]\n",
        "                print('done val language check')\n",
        "                # add to val set\n",
        "                datalist_val_triplet_static.extend(dset_static_val_thisset)\n",
        "\n",
        "            # check language\n",
        "            if do_make_trainset:\n",
        "                # discard non-english\n",
        "                dset_static_train_thisset =[\n",
        "                    e for e in dset_static_train_thisset if check_language(e['pair1'])[0]\n",
        "                ]\n",
        "                print('done train language check')\n",
        "\n",
        "                # ensure that none of the examples in the traning set are in the validation set\n",
        "                def hashtest(text1,text2):\n",
        "                    texthash = text1.lower()\n",
        "                    texthash+= \"\" if text2 is None else text2[:1000].lower()\n",
        "                    return texthash\n",
        "\n",
        "                if do_make_valset:\n",
        "                    val_queries = set([hashtest(q['pair1'],q['pair2']) for q in dset_static_val_thisset])\n",
        "                    dset_static_train_thisset = [\n",
        "                        s for s in dset_static_train_thisset if hashtest(s['pair1'],s['pair2']) not in val_queries\n",
        "                    ]\n",
        "\n",
        "                # add to training set\n",
        "                datalist_train_triplet_static.extend(dset_static_train_thisset)\n",
        "\n",
        "        print(f'Done collecting {name} streaming data')\n",
        "\n",
        "    if do_make_valset:\n",
        "        print('saving streamed %s validation data: %s' % (name, path_to_val_cache))\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_val_triplet_static, pcon)\n",
        "\n",
        "    if do_make_trainset:\n",
        "        print('saving streamed %s training for epoch %d: %s' % (name, epoch, path_to_train_cache))\n",
        "        with open(path_to_train_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_train_triplet_static, pcon)\n",
        "\n",
        "    return {\n",
        "        'train':datalist_train_triplet_static,\n",
        "        'val':datalist_val_triplet_static,\n",
        "        'epoch':epoch,\n",
        "        'index_stream':start_proportion\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9d6b311c522f479dbf3e6ac6d0558a31",
            "5b7bb6ffc45947798e64147e55fd5ace",
            "f5dbea136bc8437daea9205f86a0222d",
            "634b144054f44d44945b547da14fc7cb",
            "199f448fddf34260ae259d77a8df6849",
            "4896a7b0880641519a93d24ceaa01f04",
            "b1478e1351cc4d9cb407e7ca86726e5c",
            "140d521dd6334490abed5fb1c2c1d245",
            "947f138f8aef463e8f3852b167587614",
            "c4c104c3dd39406c9345d7d9bde52386",
            "9b509e480979428d8b4c9b1b6909fdd4",
            "8d65399ec30e44af888334b8ed0a0fc1",
            "b68564469cae4918bfe78edfe46f9bbd",
            "bf6d6ac360f2412c81aedaa1502d0d52",
            "7fd3d3a3aab24adcac4748b5639fc485",
            "c19a787e4cac4c908602096d6c7fb352",
            "664c5d6fcfd347fdaf01c0d9bd4da14f",
            "e2d27436463f41aa83609422efc3dbe4",
            "c5378e14b0bc47cfae83e93cda9c511e",
            "c3bb372606c1478296ef48e89fc3570e",
            "baa7d573777144cbbb8df6ddc7b57673",
            "129141d5fdb84754a0d1b1ae65a7eeb3"
          ]
        },
        "id": "qyCUlurNP0CY",
        "outputId": "629b0cfe-2aab-471c-f14c-aeea0c205470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trying snli initialization\n",
            "take 38 from snli validation\n",
            "take 154 from snli train\n",
            "Done getting streams/reloading from snli\n",
            "done val language check\n",
            "done train language check\n",
            "trying multi_nli initialization\n",
            "take 76 from multi_nli validation\n",
            "take 308 from multi_nli train\n",
            "Done getting streams/reloading from multi_nli\n",
            "done val language check\n",
            "done train language check\n",
            "trying tum-nlp/cannot-dataset initialization\n",
            "take 76 from tum-nlp/cannot-dataset validation\n",
            "take 308 from tum-nlp/cannot-dataset train\n",
            "Done getting streams/reloading from tum-nlp/cannot-dataset\n",
            "done val language check\n",
            "done train language check\n",
            "trying heegyu/news-category-dataset initialization\n",
            "take 38 from heegyu/news-category-dataset validation\n",
            "take 154 from heegyu/news-category-dataset train\n",
            "Done getting streams/reloading from heegyu/news-category-dataset\n",
            "done val language check\n",
            "done train language check\n",
            "trying fkdosilovic/docee-event-classification initialization\n",
            "take 38 from fkdosilovic/docee-event-classification validation\n",
            "take 154 from fkdosilovic/docee-event-classification train\n",
            "Done getting streams/reloading from fkdosilovic/docee-event-classification\n",
            "done val language check\n",
            "done train language check\n",
            "trying DeveloperOats/DBPedia_Classes initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d6b311c522f479dbf3e6ac6d0558a31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 38 from DeveloperOats/DBPedia_Classes validation\n",
            "take 154 from DeveloperOats/DBPedia_Classes train\n",
            "Done getting streams/reloading from DeveloperOats/DBPedia_Classes\n",
            "done val language check\n",
            "done train language check\n",
            "trying DeveloperOats/DBPedia_Classes initialization\n",
            "take 38 from DeveloperOats/DBPedia_Classes validation\n",
            "take 154 from DeveloperOats/DBPedia_Classes train\n",
            "Done getting streams/reloading from DeveloperOats/DBPedia_Classes\n",
            "done val language check\n",
            "done train language check\n",
            "trying casehold/casehold initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d65399ec30e44af888334b8ed0a0fc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 38 from casehold/casehold validation\n",
            "take 154 from casehold/casehold train\n",
            "Done getting streams/reloading from casehold/casehold\n",
            "done val language check\n",
            "done train language check\n",
            "trying casehold/casehold initialization\n",
            "take 38 from casehold/casehold validation\n",
            "take 154 from casehold/casehold train\n",
            "Done getting streams/reloading from casehold/casehold\n",
            "done val language check\n",
            "done train language check\n",
            "trying mteb/mtop_intent initialization\n",
            "take 76 from mteb/mtop_intent validation\n",
            "take 308 from mteb/mtop_intent train\n",
            "Done getting streams/reloading from mteb/mtop_intent\n",
            "done val language check\n",
            "done train language check\n",
            "Done collecting CLS streaming data\n",
            "saving streamed CLS validation data: cache_val_cls.pkl\n",
            "saving streamed CLS training for epoch 0: cache_train_cls_000.pkl\n"
          ]
        }
      ],
      "source": [
        "clsdata_streaming_config = {\n",
        "    'files':cls_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':500,\n",
        "    'train_chunk_size':2000,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "cls_statics_datsets = initialize_and_get_classification_streaming_datasets(\n",
        "    data_streaming_config=clsdata_streaming_config,\n",
        "    streaming_cleaning_functions=cls_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_cls.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_cls_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'CLS' #\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioHTHynKZ4Zq"
      },
      "outputs": [],
      "source": [
        "!rm *.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4-gXxVquzJZ"
      },
      "outputs": [],
      "source": [
        "# TODO - make dataloaders for pair_classification, classification, and next-sentence-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F92fGv0NTmT6"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as torch_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3tDKE1QPz9q"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DatasetPairClassification(torch_data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        list_of_data=None,\n",
        "        text1_name ='pair1',\n",
        "        text2_name ='pair2',\n",
        "        label_name = 'label',\n",
        "        datasetname_name = 'cls_id',\n",
        "        classificationtype_name = 'type',\n",
        "        nlabels_name = 'n_labels',\n",
        "        seed = 42\n",
        "    ):\n",
        "        self.data = {} # internal data preprocessed\n",
        "        self.datasets = [] # list of names of datasets in Dataset class\n",
        "        self.label2int = {} #maps {label:int} dictionary\n",
        "        self.label2dataset = {} #maps {label:mask}\n",
        "        self.label2mask = {}\n",
        "        self.dataset_classification_types = {} # dataset types (pair-classification, classificaiton)\n",
        "        self.text1_name = text1_name\n",
        "        self.text2_name = text2_name\n",
        "        self.label_name = label_name#'label',\n",
        "        self.datasetname_name = datasetname_name #'cls_id',\n",
        "        self.classificationtype_name = classificationtype_name#'type',\n",
        "        self.nlabels_name = nlabels_name #'n_labels'\n",
        "        self.seed = seed\n",
        "\n",
        "        # random state\n",
        "        self.np_random = np.random.RandomState(seed)\n",
        "\n",
        "        if list_of_data is not None and len(list_of_data)>0:\n",
        "\n",
        "            # loop through the data and add each triplets: export a panda df as final data\n",
        "            self.df = self.process(list_of_data, False)\n",
        "\n",
        "    def process(self, list_of_data, inplace=True):\n",
        "        \"\"\"convert the raw examples to dataset\"\"\"\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(\n",
        "            list_of_data = list_of_data\n",
        "        )\n",
        "\n",
        "        # add positives to self.data\n",
        "        self._find_positives_and_add_to_data()\n",
        "\n",
        "        # add negatives to self.data\n",
        "        self._find_negatives_and_add_to_data()\n",
        "\n",
        "        # make mask for loss function\n",
        "        self._convert_labelint_to_vectors()\n",
        "\n",
        "        # make mask for loss function\n",
        "        self._make_mask()\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        data_flatten = self.flatten_data(self.data)\n",
        "        if not inplace:\n",
        "            return data_flatten\n",
        "        self.df = data_flatten\n",
        "\n",
        "    def _loop_through_list_of_data_and_add_to_selfdata(\n",
        "            self,\n",
        "            list_of_data\n",
        "        ):\n",
        "        \"\"\"loops through and adds the text pair and label\"\"\"\n",
        "        for raw_example in list_of_data:\n",
        "\n",
        "            # add each element to the data\n",
        "            self._add_unit_to_data(\n",
        "                text1 = raw_example[self.text1_name],\n",
        "                text2= raw_example[self.text2_name],\n",
        "                label= raw_example[self.label_name],\n",
        "                n_labels= raw_example[self.nlabels_name],\n",
        "                dataset_name= raw_example[self.datasetname_name],\n",
        "                method = raw_example[self.classificationtype_name]\n",
        "            )\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"Finds data with the same label, and adds them as positives\"\"\"\n",
        "        which_clsdatasets_lack_positives = [\n",
        "            datasetname for datasetname, datasettype\n",
        "            in self.dataset_classification_types.items()\n",
        "            if datasettype == 'classification'\n",
        "        ]\n",
        "        for datasetname in which_clsdatasets_lack_positives:\n",
        "\n",
        "            # all unique labels in subdataset\n",
        "            ulabels_in_clsdataset = sorted(list(set([\n",
        "                (d['class'],d['label']) for d in self.data[datasetname]\n",
        "                if d['label'] == self.label2int['%s_%d' % (datasetname, 1)]\n",
        "            ])))\n",
        "\n",
        "            # loop through label classes\n",
        "            for labelclass,label in ulabels_in_clsdataset:\n",
        "\n",
        "                # other samples with the same class (and positive)\n",
        "                # `class` is the original dataset class, label = {different, same}\n",
        "                idx_this_class = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] == labelclass and d['label']==label\n",
        "                ]\n",
        "\n",
        "                idx_this_class_need_positives = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] == labelclass and d['label']==label\n",
        "                    and d['text2'] is None\n",
        "                ]\n",
        "\n",
        "                # subsample within by permutation\n",
        "                idx_sample_within = self.np_random.permutation(idx_this_class)\n",
        "\n",
        "                # get text of permuted-indicies, assign as positive for each sample\n",
        "                for i,j in zip(idx_this_class_need_positives, idx_sample_within[:len(idx_this_class_need_positives)]):\n",
        "\n",
        "                    self.data[datasetname][i]['text2'] = self.data[datasetname][j]['text1']\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "        \"\"\"Finds data with the same label, and adds them as positives\"\"\"\n",
        "        which_clsdatasets_lack_negatives = [\n",
        "            datasetname for datasetname, datasettype\n",
        "            in self.dataset_classification_types.items()\n",
        "            if datasettype == 'classification'\n",
        "        ]\n",
        "        for datasetname in which_clsdatasets_lack_negatives:\n",
        "\n",
        "            # all unique labels in subdataset\n",
        "            ulabels_in_clsdataset = sorted(list(set([\n",
        "                (d['class'],d['label']) for d in self.data[datasetname]\n",
        "                if d['label'] == self.label2int['%s_%d' % (datasetname, 0)]\n",
        "            ])))\n",
        "\n",
        "            # loop through label classes\n",
        "            for labelclass,label in ulabels_in_clsdataset:\n",
        "\n",
        "                # other samples with the same class (and positive)\n",
        "                # `class` is the original dataset class, label = {different, same}\n",
        "                idx_this_class = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] == labelclass and d['label']==label\n",
        "                ]\n",
        "                # indices of all other data\n",
        "                idx_this_other_class = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] != labelclass\n",
        "                ]\n",
        "\n",
        "                # subsample within by permutation\n",
        "                idx_sample_otherlabels= self.np_random.choice(idx_this_other_class, size =len(idx_this_class))\n",
        "\n",
        "                # get text of permuted-indicies, assign as positive for each sample\n",
        "                for i,j in zip(idx_this_class, idx_sample_otherlabels):\n",
        "\n",
        "                    self.data[datasetname][i]['text2'] = self.data[datasetname][j]['text1']\n",
        "\n",
        "    def _convert_labelint_to_vectors(self):\n",
        "        \"\"\"Loops through data and converts each labelinteger into a vector for multi-label loss\"\"\"\n",
        "        for datasetname, dataset in self.data.items():\n",
        "            for example in dataset:\n",
        "                example.update({\n",
        "                    'labelvector':self._convert_labelint_to_vector([example['label']])\n",
        "                })\n",
        "\n",
        "    def _convert_labelint_to_vector(self, labelints):\n",
        "        \"\"\"Loops through data and converts each labelinteger into a vector for multi-label loss\"\"\"\n",
        "        v = np.zeros(len(self.label2int))\n",
        "        for labelint in labelints:\n",
        "            v[labelint]=1\n",
        "        return v\n",
        "\n",
        "    def _make_mask(self):\n",
        "        \"\"\"for each sample, the loss should only pertain to labels within the same dataset, not other datasets -- by masking\"\"\"\n",
        "        if (\n",
        "            len(self.label2mask)!=self.label2dataset\n",
        "        ) or bool(\n",
        "            set(list(self.label2mask.keys())).symmetric_differnce(set(list(self.label2dataset.keys())))\n",
        "        ):\n",
        "            # make the self.label2mask\n",
        "            for label,dataset in self.label2dataset.items():\n",
        "                #\n",
        "                self.label2mask[self.label2int[label]] = self._convert_labelint_to_vector([\n",
        "                    self.label2int[l] for l,dset in self.label2dataset.items() if dset==dataset\n",
        "                ])\n",
        "\n",
        "        # loop through data and insert mask into each sample\n",
        "        for datasetname, dataset in self.data.items():\n",
        "            for example in dataset:\n",
        "                example.update({\n",
        "                    'mask':self.label2mask[example['label']]\n",
        "                })\n",
        "\n",
        "    def _add_labels_to_label2int(self, dataset_labels_as_globalname, dataset_name):\n",
        "        for globallabel in dataset_labels_as_globalname:\n",
        "            if globallabel not in self.label2int.keys():\n",
        "                next_label_int = len(self.label2int)\n",
        "                self.label2int[globallabel] = next_label_int\n",
        "                self.label2dataset[globallabel] = dataset_name\n",
        "\n",
        "    def _add_unit_to_data(\n",
        "        self,\n",
        "        text1,\n",
        "        text2,\n",
        "        label,\n",
        "        n_labels,\n",
        "        dataset_name,\n",
        "        method\n",
        "    ):\n",
        "        \"\"\"Adds one unit of processed data to the internal self.data\"\"\"\n",
        "        if method == 'pair_classification':\n",
        "\n",
        "            # pair classification: two texts with a label of the relationship between pair\n",
        "            self._add_text_pair_to_data(\n",
        "                text1,\n",
        "                text2,\n",
        "                label,\n",
        "                n_labels,\n",
        "                dataset_name\n",
        "            )\n",
        "\n",
        "        elif method == 'classification':\n",
        "\n",
        "            # classification: single texts, with negatives needing to be deduced later\n",
        "            self._add_textclass_to_data(\n",
        "                text1,\n",
        "                label,\n",
        "                dataset_name\n",
        "            )\n",
        "\n",
        "    def _add_text_pair_to_data(\n",
        "        self,\n",
        "        text1,\n",
        "        text2,\n",
        "        label,\n",
        "        n_labels,\n",
        "        dataset_name\n",
        "    ):\n",
        "        \"\"\"add a text pair to the self data: specifically for pair_classification\"\"\"\n",
        "        if dataset_name not in self.data.keys():\n",
        "            print('encountered new dataset for pair-classification: %s' % dataset_name)\n",
        "            self.data[dataset_name] = []\n",
        "            self.datasets += [dataset_name]\n",
        "            self.dataset_classification_types[dataset_name] = 'pair_classification'\n",
        "\n",
        "            # common naming for all labels across all datasets\n",
        "            dataset_labels_as_globalname = [\n",
        "                \"%s_%d\" % (dataset_name, l) for l in range(n_labels)\n",
        "            ]\n",
        "\n",
        "            self._add_labels_to_label2int(dataset_labels_as_globalname, dataset_name)\n",
        "\n",
        "        if text2 is not None:\n",
        "\n",
        "            self.data[dataset_name].append({\n",
        "                'text1':text1,\n",
        "                'text2':text2,\n",
        "                'label':self.label2int[\"%s_%d\" % (dataset_name, label)],\n",
        "                'mask':None\n",
        "            })\n",
        "\n",
        "    def _add_textclass_to_data(\n",
        "        self,\n",
        "        text,\n",
        "        classlabel,\n",
        "        dataset_name\n",
        "    ):\n",
        "        \"\"\"add a text to the self data: specifically for classification\"\"\"\n",
        "        if dataset_name not in self.data.keys():\n",
        "            print('encountered new dataset for classification: %s' % dataset_name)\n",
        "            self.data[dataset_name] = []\n",
        "            # register dataset to list of datasets\n",
        "            self.datasets += [dataset_name]\n",
        "            # map datset classification types\n",
        "            self.dataset_classification_types[dataset_name] = 'classification'\n",
        "\n",
        "            # common naming for all labels across all datasets\n",
        "            dataset_labels_as_globalname = [\n",
        "                \"%s_%d\" % (dataset_name, l) for l in [0,1]\n",
        "            ]\n",
        "\n",
        "            self._add_labels_to_label2int(dataset_labels_as_globalname, dataset_name)\n",
        "\n",
        "        # positives and negatives must be added seperately (same label, different label)\n",
        "        for label in [0,1]:\n",
        "\n",
        "            self.data[dataset_name].append({\n",
        "                'text1':text,\n",
        "                'text2':None,\n",
        "                'mask':None,\n",
        "                'label':self.label2int[\"%s_%d\" % (dataset_name, label)],\n",
        "                'class':classlabel\n",
        "            })\n",
        "\n",
        "    def flatten_data(self, data):\n",
        "        \"\"\"Converts data to a giant list\"\"\"\n",
        "        data_all_flat = []\n",
        "        for datasetname, subdataset in self.data.items():\n",
        "            data_all_flat += subdataset\n",
        "        return data_all_flat\n",
        "\n",
        "    def integrate_another_dataset(\n",
        "        self,\n",
        "        list_of_newdata,\n",
        "        function_to_reformatdata,\n",
        "        dataset_name\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Adds new data to the existing self.df\n",
        "        Arguments:\n",
        "        :param list_of_newdata: list of data to integrate/add\n",
        "        :function_to_reformatdata: function that converts the data in list_of_newdata[idx]\n",
        "        \"\"\"\n",
        "        # check that the unit of data has the required fields\n",
        "        newtestdata = function_to_reformatdata(list_of_newdata[0])\n",
        "        assert isinstance(newtestdata, list), 'function_to_reformatdata must output a list of reformated data'\n",
        "        assert not bool(set(['text1','text2','class']).difference(set(newtestdata[0].keys()))), 'new data must have `text1`, `text2`,`class`'\n",
        "        classlabels = set()\n",
        "        newdata_converted_all = []\n",
        "\n",
        "        # loop through and convert all data to acceptable format for internal datasets\n",
        "        for newdata in list_of_newdata:\n",
        "            newdata_converted = function_to_reformatdata(newdata)\n",
        "            for unit in newdata_converted:\n",
        "                classlabels |= set([unit['class']])\n",
        "            newdata_converted_all += newdata_converted\n",
        "\n",
        "        # loop through and ingest all converted data into the self.data internal dataset\n",
        "        for unit in newdata_converted_all:\n",
        "            self._add_text_pair_to_data(\n",
        "                text1=unit['text1'],\n",
        "                text2=unit['text2'],\n",
        "                label=unit['class'],\n",
        "                n_labels=len(classlabels),\n",
        "                dataset_name=dataset_name\n",
        "            )\n",
        "        # remake the mask for ALL data, given the new label sets\n",
        "        self._convert_labelint_to_vectors()\n",
        "        # make mask for loss function\n",
        "        self._make_mask()\n",
        "        # harden the dataset to pandas dataframe\n",
        "        data_flatten = self.flatten_data(self.data)\n",
        "        self.df = data_flatten\n",
        "        print('done integrating new dataset %s' % dataset_name)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.df[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7itnwQwZYPh",
        "outputId": "fcb64d14-9b8a-48ad-8dd8-041a84164129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encountered new dataset for pair-classification: snli\n",
            "encountered new dataset for pair-classification: mnli\n",
            "encountered new dataset for pair-classification: cannotdataset\n",
            "encountered new dataset for classification: newscategory\n",
            "encountered new dataset for classification: doceeevents\n",
            "encountered new dataset for classification: dbpedia_l2\n",
            "encountered new dataset for classification: dbpedia_l3\n",
            "encountered new dataset for pair-classification: casehold\n",
            "encountered new dataset for classification: mtopintent\n",
            "Size of pair-classification dataset 2862\n"
          ]
        }
      ],
      "source": [
        "# initialize the (empty) CLS-dataset\n",
        "dataset_paircls = DatasetPairClassification(\n",
        "    list_of_data=None,\n",
        "    text1_name ='pair1',\n",
        "    text2_name ='pair2',\n",
        "    label_name = 'label',\n",
        "    datasetname_name = 'cls_id',\n",
        "    classificationtype_name = 'type',\n",
        "    nlabels_name = 'n_labels',\n",
        "    seed = 42\n",
        ")\n",
        "\n",
        "# add the data to empty datas\n",
        "dataset_paircls.process(cls_statics_datsets['train'], inplace=True)\n",
        "\n",
        "print('Size of pair-classification dataset %d' % len(dataset_paircls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3iyAQPEc8JR",
        "outputId": "6d811ad7-5cbd-4b69-cbfa-4d212a79cef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text1': 'with “intentionally and knowingly” causing the death of a police officer. The trial court’s charge to the jury authorized conviction upon a finding that he “intentionally or knowingly” caused such result. In his first point of error, appellant complains that the trial judge improperly permitted conviction on a theory other than that alleged in the indictment. This Court has long approved the practice of prosecuting authorities to plead culpable mental states conjunctively and submit them for jury consideration disjunctively whenever the statutory language is disjunctive. Ely v. State, 582 S.W.2d 416, 421 (Tex.Cr.App.1979) (on original submission); Cowan v. State, 562 S.W.2d 236, 240 (Tex.Cr.App.1978) (rehearing denied en banc). But cf. Hunter v. State, 576 S.W.2d 395 (Tex.Cr.App.1979) ',\n",
              " 'text2': 'recognizing by citing several cases that diametric opposing lines of case law authority exist with one line suggesting that information need not allege each element of offense charged because notice pleading is sufficient distinguishing pleading elements from pleading facts',\n",
              " 'label': 16,\n",
              " 'mask': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        1., 0., 0.]),\n",
              " 'labelvector': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0.])}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_paircls[2211]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsnUJOGkPz33",
        "outputId": "560bd200-a95c-4a40-f5cd-0e7ea4266d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done integrating new dataset nextsentence\n",
            "Size of pair-classification dataset 7986\n",
            "types of datasets in classification task:\n",
            "{'snli': 'pair_classification', 'mnli': 'pair_classification', 'cannotdataset': 'pair_classification', 'newscategory': 'classification', 'doceeevents': 'classification', 'dbpedia_l2': 'classification', 'dbpedia_l3': 'classification', 'casehold': 'pair_classification', 'nextsentence': 'pair_classification'}\n"
          ]
        }
      ],
      "source": [
        "## integrate the nextsentence data\n",
        "def function_to_reformatnextsentence(x):\n",
        "    \"\"\"reformats a triplet into one positive pair and one negative pair\"\"\"\n",
        "    return [\n",
        "        {\"text1\":x['anchor'], \"text2\":x['next'], \"class\":1},\n",
        "        {\"text1\":x['anchor'], \"text2\":x['opposite'], \"class\":0},\n",
        "    ]\n",
        "\n",
        "# integrate the next sentence data\n",
        "dataset_paircls.integrate_another_dataset(\n",
        "    list_of_newdata = dataset_static_mlm['train']['nextsentence'],\n",
        "    function_to_reformatdata = function_to_reformatnextsentence,\n",
        "    dataset_name = 'nextsentence'\n",
        ")\n",
        "\n",
        "print('Size of pair-classification dataset %d' % len(dataset_paircls))\n",
        "\n",
        "print('types of datasets in classification task:')\n",
        "print(dataset_paircls.dataset_classification_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o7-J10UglUG",
        "outputId": "040f7b21-25c1-4522-9d33-94464ffc98c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text1': \"Breathe Easy, Jar Jar Binks Won't Be In 'Star Wars: The Force Awakens'. Crisis averted.\",\n",
              " 'text2': 'Omarion Wasn\\'t Happy About Grammy Nomination Snub. \"As an artist you look forward to being acknowledged by the game.\"',\n",
              " 'mask': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.]),\n",
              " 'label': 9,\n",
              " 'class': 32,\n",
              " 'labelvector': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.])}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_paircls[1006]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81QaRC0Pg34D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZcP7hL9J/4yjXm+LayH7C"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00001f9f055045f9ae35f94f76be8fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16dd57325504698b35f155d1bd040b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7950d803ab5b4c4ab10dc9e0902e34b1",
            "value": 1
          }
        },
        "0003c5e497294b5abf83ff5edbf90261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28542ed3d1b443c9a7ba7074825ee208",
              "IPY_MODEL_7c01fc1aabb0486f9f1f0674b46b5481",
              "IPY_MODEL_6b349f8f7890488eaa05b156ec971bf6"
            ],
            "layout": "IPY_MODEL_1602c7712db64b829a6ed1fa73367a1e"
          }
        },
        "000f6133e191461c893cffdc6783a5f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "00c7829ca16746089c8896865f374b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ef066e53974658a59443c917b2c615",
            "placeholder": "​",
            "style": "IPY_MODEL_98bd45b05dda4319adf853b5104f0a0a",
            "value": " 1725/1725 [00:00&lt;00:00, 3472.08 examples/s]"
          }
        },
        "01ac22caf29c4b2baf0ebc428f3398b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f4a70e089f4fe5abb0d9246aeee403": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01fa51a473a6472da89d47bf1116e575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02191a5509094a0abcf8862d3a8ee4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029adddbce024f50bc5d7a06d304632d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0322aeeda2bd42c1b8ce348bd56424eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5398b51140574840979cfe9ae2640c96",
            "placeholder": "​",
            "style": "IPY_MODEL_d6012c2d60024501a1bd8c529bf055e6",
            "value": "Generating validation_matched split:  99%"
          }
        },
        "0381ff6309df4052bb0ce823e7ff741b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a6cc127c8c4f03bab0b31bb3a1721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ccd976679e45fcbf6d6b5d06360ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_f6c454dc6dcb4528b7b05b83c72640fc",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "03a8f530cfb0469998f56dcca5f00803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cafc757655d74a2697f4ba566b3623ee",
              "IPY_MODEL_46cd1079cad04e7ea04959e14225b7fb",
              "IPY_MODEL_c508e67d54c24888b82b66108681da19"
            ],
            "layout": "IPY_MODEL_b08eba43d39846869bdd9050836be1cb"
          }
        },
        "0457dfcb462c4173bbfb7890bb043c97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04db53bae1ea4e81a1acbad7401cd331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81afc2262c8545dab41aacde91066b7d",
              "IPY_MODEL_b96a361475c947e5a0f9e5f0f867ced7",
              "IPY_MODEL_f697e928e02f405d99c43c4b1fd890c9"
            ],
            "layout": "IPY_MODEL_6da885f236a24cf5a09add7c9927db76"
          }
        },
        "052465580f854b15be0d29e9dc59125b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05fd99843ed746d1baf705e6c31881f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08c60bb508854cc9b6772ab78502b6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497aad7b9ab34f158382033f65d9a8c9",
            "placeholder": "​",
            "style": "IPY_MODEL_814c0fc7e64c49bfa85d5087d1e07cb4",
            "value": " 383/383 [00:00&lt;00:00, 8.70kB/s]"
          }
        },
        "08fbdead6ab540d4a1d2d8f06879e417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029adddbce024f50bc5d7a06d304632d",
            "max": 314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a8de725a934927b52792351e0d5099",
            "value": 314
          }
        },
        "09a93d25cd25426e9c60222b29321889": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a024ed7f3514fd6a544804a8bee0d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a320f7b8bba47ddb97d2aff966e162f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0c4175d283414ab014c95269b4421b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17a0dd6bd24481e8e597415bfc02c87",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c43b4c9b58842acaf321862c3a1625d",
            "value": 1725
          }
        },
        "0cbd831de3c64f4aa269776dc73c5e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4848184b58645b2a572c6e1a1231f05",
            "placeholder": "​",
            "style": "IPY_MODEL_92d450929c8e45539c2726eaf96d5ddb",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "0db15040be1242378220fa56a21aba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e215f7f87fc48bfbb3e74c9c97b23a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ea16b4f2c6d428191dd7d31d21ad659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f331a136adf425f87a1a35682256cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f2289d8f6c460892864f1ef5ad8e08",
            "max": 392702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f81a1dd1a8b547b39297478219b41c81",
            "value": 392702
          }
        },
        "1034a93ce59f439bb128b6c096eefdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c225230ea12f4f90bd461485f300580e",
            "placeholder": "​",
            "style": "IPY_MODEL_4d3b7432f11a4a4b9eb444743d158c0d",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "11db36da26a94bae9ad00e99a10d8c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5323c16a9ca4decbe25c651a14517de",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "value": 408
          }
        },
        "1290569b6a4d490fbfc8ca3915983263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "129141d5fdb84754a0d1b1ae65a7eeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140d521dd6334490abed5fb1c2c1d245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1602c7712db64b829a6ed1fa73367a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "16501e0f5de84fc7bbbdcc9b37f61d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1672001c1d7e449f9cc0ce76fcf50fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "169e8fa7a73d4797945e98ccba4cd10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b072faf11c504e39939d1ad4534f9112",
              "IPY_MODEL_f3707c74969e4f6c84d6a36b59d6fa9e",
              "IPY_MODEL_32184fc9b099416a8d49ef3c3f8c3a2e"
            ],
            "layout": "IPY_MODEL_2b95b44611524401ac7826dab5a21aa8"
          }
        },
        "177dee7aa0754c7db2b595f83a4eb105": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "195b549a3cd745ffbe55e24f5865b1da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199f448fddf34260ae259d77a8df6849": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e70f5c3ae04d4b8b4a86c1233418be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7fcfc2727db445695b908ffd3370feb",
              "IPY_MODEL_546b278b05e643a4905055d1d7ffeea5",
              "IPY_MODEL_289aa49d154a496d9804cf30545bc5fc"
            ],
            "layout": "IPY_MODEL_f54be5e820704ad2b31b6b7a6b946181"
          }
        },
        "1a3234bae89d4c1eb7e84da16675cde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c50e41b12ab40ae88db5a68806a5287",
              "IPY_MODEL_9a675022c08043438f0288c2dc3d1692",
              "IPY_MODEL_42ed4267878a46a9a1a1de7f63006ab4"
            ],
            "layout": "IPY_MODEL_a587d42c581c4f75984a189ebe1b1831"
          }
        },
        "1a7dd0c3112945959e9908425fcaa8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1aea1f6de91a43a4b491c82ffc1522be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c00f260ca44415c9c2cc342c9cab470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c5678cdeb204d21b94526ccdab34d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0381ff6309df4052bb0ce823e7ff741b",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd79d8ce5e28404c988f4965873a2f2c",
            "value": 440449768
          }
        },
        "1d322e088a6a4904a0b99740d8d4e45c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d567e39c5ac4b9f8d9908111b04100f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1deae35c0489408fa7e374cd93cca642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7d06e9df9b4a88a003bbba433c1cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d151de5a1862426f9d3ab2aaae73f4d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3963ddae09b14417abf20a566ce82a03",
            "value": " 441k/? [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "1eb78591c14840daaf6741730f2280f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f65726d2e20471e99928e5dc96726c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454aeb5a95b94bb580698d8d2f62f43f",
            "placeholder": "​",
            "style": "IPY_MODEL_a417b74f6fdb4dedbd6bf3408d0dea69",
            "value": " 392000/392702 [01:52&lt;00:00, 7530.77 examples/s]"
          }
        },
        "20402646761d4cf3975763fc130d6ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20ae65dc26cb4ab98a9637dfa2bd5a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2137d76adc0b4235bcf4e52ab94ae445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2166426a7a224f1da2065f3221463693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216e1650231e471fa0d88e3d73bf6da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2bbd67afcb9463cb0f78d7a24c5f126",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9c165248ef4e0b9c357316b95f66af",
            "value": "Downloading data: "
          }
        },
        "21f6c046574b4badbf5dac2bd4989d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235afab600844a9f8ef8f45cdba142e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e977d511bd4f03bc8d730cd4c86027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2b4543fdb94a1d9153de7f18d108be",
            "placeholder": "​",
            "style": "IPY_MODEL_da3eb201a16240aaa91baf19b49d4209",
            "value": " 5.14k/5.14k [00:00&lt;00:00, 173kB/s]"
          }
        },
        "251219f28bd54de9a608686672dddf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e61f641028148e988678a2ecbe24a21",
            "placeholder": "​",
            "style": "IPY_MODEL_df8de4914b3f4c51b4e048f053a0e009",
            "value": " 9703/9815 [00:01&lt;00:00, 7528.70 examples/s]"
          }
        },
        "260f38a6c52d464999f74443c04cdc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2750de9a4c5740b080f5a8145de41111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282f350bdadd41fa82b37f527ffe8a63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283065bbec654b89a6be726e3fe790fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28542ed3d1b443c9a7ba7074825ee208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72812af3cd8475f8a76a8ff3ec236e9",
            "placeholder": "​",
            "style": "IPY_MODEL_40731cc8e1a245868c9bf6d0972c0467",
            "value": "Map: 100%"
          }
        },
        "289aa49d154a496d9804cf30545bc5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c0e136fa3f400bab5deec7a0aff11f",
            "placeholder": "​",
            "style": "IPY_MODEL_bcee86d4105743f5a69c595029994bc8",
            "value": " 116M/116M [00:03&lt;00:00, 35.9MB/s]"
          }
        },
        "292c0b150eb84f06a012e2084b035350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2958b232a65d47d7950e040ddd583898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82db512ae4ce4b1fbde3aed3d893e032",
              "IPY_MODEL_8b3982acce834b95a6f318dfb78add1c",
              "IPY_MODEL_3df2e72406454de7ade25cfe0fca7295"
            ],
            "layout": "IPY_MODEL_979449deb4254629b80f0089584c851a"
          }
        },
        "29e9e92bc30c4b2f89416481b4fb1455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34433ff3b52491fb5829b9f1522e162",
            "placeholder": "​",
            "style": "IPY_MODEL_5250f6a6e5c34894adb20a9120388ba0",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2a7388d890b2460c86be4cd32187f319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38b91d162c304c6eaad444f0abffa931",
              "IPY_MODEL_0f331a136adf425f87a1a35682256cd9",
              "IPY_MODEL_1f65726d2e20471e99928e5dc96726c7"
            ],
            "layout": "IPY_MODEL_dae9d080adfc4bfbba896820bbf57c3b"
          }
        },
        "2b5f6a6687b34036bd5a87c8b61dc2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d265db9a419d4edfbdb91e4bd8f78846",
            "placeholder": "​",
            "style": "IPY_MODEL_aae2a30b7f474dbcbf55aa677b9518f9",
            "value": "Downloading metadata: 100%"
          }
        },
        "2b95b44611524401ac7826dab5a21aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c148a8aa9fe4f30a69392f10a350eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c43b4c9b58842acaf321862c3a1625d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fe3c4d6e4774be691e7c0551fd334ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f6111712e2491198ac03400ef0ce7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312b0a411cf7451d845fae7b77dff7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "31fef27ae4d44fa691185c3fa750756a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa205a1da88e418a881efb0963042e9d",
            "placeholder": "​",
            "style": "IPY_MODEL_30f6111712e2491198ac03400ef0ce7d",
            "value": "Generating validation split:  73%"
          }
        },
        "32184fc9b099416a8d49ef3c3f8c3a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2137d76adc0b4235bcf4e52ab94ae445",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb506371e6e4cd2947988d6c7050809",
            "value": " 232k/232k [00:00&lt;00:00, 6.89MB/s]"
          }
        },
        "326c1c104f254d1189c78c6abd318451": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f65d2703c048929de10720219fdf53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33088ffab85f4898bc39a1167e70388c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3312caf3fc76420ead7f4945675df52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3315267c32f24d29804c12af760956aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31fef27ae4d44fa691185c3fa750756a",
              "IPY_MODEL_11db36da26a94bae9ad00e99a10d8c5a",
              "IPY_MODEL_f4bb56cde5b042e8821ee26d25da4ea2"
            ],
            "layout": "IPY_MODEL_312b0a411cf7451d845fae7b77dff7d6"
          }
        },
        "33ae5a6ee9244aeea02e10990e8dd3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f1b9961c6b14a1a92f3cb2c82883a17",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd3f1f64d81471083416a3e4ca6aa60",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "36c0e136fa3f400bab5deec7a0aff11f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3751db7e581847efa6c224dd50c9b7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "377a7fa0ebce4c8a96a55c6e1c08403f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff3a2b6be1f4220b0e3c055fc587c7e",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af816340aae74a81a6eaf63a1933f5bf",
            "value": 1340616616
          }
        },
        "37e0abc511f04624986368ef45b50131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33088ffab85f4898bc39a1167e70388c",
            "placeholder": "​",
            "style": "IPY_MODEL_1672001c1d7e449f9cc0ce76fcf50fc8",
            "value": " 2.88k/2.88k [00:00&lt;00:00, 139kB/s]"
          }
        },
        "38b91d162c304c6eaad444f0abffa931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef72b344a964832bd2b19140d230f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_b719af868833401c86d45d2ae059c868",
            "value": "Generating train split: 100%"
          }
        },
        "3963ddae09b14417abf20a566ce82a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3988d9e57bc841b49a5079130f071dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c45e6794f974b4199098bcd87765e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c54d6fd6a004ed98c1cb595a0bb84a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3df2e72406454de7ade25cfe0fca7295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7834f7deaa3b43669cd0de893fa62448",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa5b162648c4abca773a478c3e3beb9",
            "value": " 227M/227M [00:07&lt;00:00, 30.8MB/s]"
          }
        },
        "3e72971bf9804c3688c24e0a3eca0da7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2b4543fdb94a1d9153de7f18d108be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb4b68eda9f481abbc7b2456644e16b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40731cc8e1a245868c9bf6d0972c0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422ac21cdb1d45a8a0814ef00c9769ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "429379eb4c4f452d94a52521911811a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68c38cc7bf84db2ab1540ca985599e2",
            "max": 8671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "value": 8671
          }
        },
        "42c13d8f7c694c6599c0a2e10ca0765f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0322aeeda2bd42c1b8ce348bd56424eb",
              "IPY_MODEL_c0908ccc452b42e681765c37a139e878",
              "IPY_MODEL_251219f28bd54de9a608686672dddf0d"
            ],
            "layout": "IPY_MODEL_e982215023c24a3caf881dd3986cca86"
          }
        },
        "42ed4267878a46a9a1a1de7f63006ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba76516f42224f79a9dfe8a36385bb22",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b2dc48588b482f80e9a2473dc5b452",
            "value": " 28.8k/28.8k [00:00&lt;00:00, 619kB/s]"
          }
        },
        "4326c46139fd4b6882d864400e35a9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e76cddc6d7d04d3fb01c11225ec1b6a2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ad1276e945e4915a079e97e06048ee9",
            "value": 570
          }
        },
        "44ce4959b2bc410a8b455eb2adb7ffc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d07abd85374cca92698119139b140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1deae35c0489408fa7e374cd93cca642",
            "placeholder": "​",
            "style": "IPY_MODEL_260f38a6c52d464999f74443c04cdc03",
            "value": "Downloading data: "
          }
        },
        "454aeb5a95b94bb580698d8d2f62f43f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46cd1079cad04e7ea04959e14225b7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef504e4ab1384063bff714e1649e0aa3",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b387dec327543f79f957f81fb651cc7",
            "value": 3668
          }
        },
        "46f2289d8f6c460892864f1ef5ad8e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ff0481a7a94abb9cea91aaacd1ea29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470a84311bbf40c6ae6322d6edc353ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9568bdb74f3e450f91b3558cf5ad5da1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7b946e1ad95455b818512986f83f7cd",
            "value": 231508
          }
        },
        "476c5672e7784cda8255af2049de1ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73e2bfea29de4c47b0c60590deff9771",
              "IPY_MODEL_4326c46139fd4b6882d864400e35a9bc",
              "IPY_MODEL_a53d537c8c0e48d1a77fbc22e5c41402"
            ],
            "layout": "IPY_MODEL_4eba976ecf5145e0a60cc8a838bff5c9"
          }
        },
        "4818654025b94f38a631b2bcdf36014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48729429682c4b37a624ba2eb55d1966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4896a7b0880641519a93d24ceaa01f04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497aad7b9ab34f158382033f65d9a8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a90c227b9342ddbb670c9fe85591cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a1ecdd97d194a9ab63a15980d1e2e31",
            "placeholder": "​",
            "style": "IPY_MODEL_5dd1df4079d44b1aad849b4a0a5e3b55",
            "value": " 8.67k/8.67k [00:00&lt;00:00, 296kB/s]"
          }
        },
        "4a16335de26a43c09d578cbbe20e98d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d567e39c5ac4b9f8d9908111b04100f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f619ea2b062a4eacb80ade328d56c2aa",
            "value": 231508
          }
        },
        "4b35ff0e35ca4e6088f2f1f687ff924c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4dae6b5bd5474491e1c86a6e462ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3b7432f11a4a4b9eb444743d158c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d798a40b2a24c4f8ce823023d75ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10d3cde2d7b4121971d8e19e3362b30",
            "placeholder": "​",
            "style": "IPY_MODEL_4818654025b94f38a631b2bcdf36014c",
            "value": "Downloading readme: 100%"
          }
        },
        "4eba976ecf5145e0a60cc8a838bff5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef3bcbd56164ddaac3068fb93a66630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cbd831de3c64f4aa269776dc73c5e28",
              "IPY_MODEL_d947bfe9101646c9a7222ada482d4455",
              "IPY_MODEL_8e9137be11744d329bceecd548d91025"
            ],
            "layout": "IPY_MODEL_326c1c104f254d1189c78c6abd318451"
          }
        },
        "4fe04dcab6654d0594a56109e7eb6805": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5183ef3eec0d4bdfbcc5544b0fec573b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5250f6a6e5c34894adb20a9120388ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5398b51140574840979cfe9ae2640c96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546b278b05e643a4905055d1d7ffeea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195b549a3cd745ffbe55e24f5865b1da",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe156388571b4c63b5fc5f5ca857e522",
            "value": 116252865
          }
        },
        "5589d685cbc94ea0a045dcba0e69a7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600bc8f5877547aca898f8c85902040e",
            "placeholder": "​",
            "style": "IPY_MODEL_b65ef6da8ad34e2285813544d00bf3e5",
            "value": " 711k/711k [00:00&lt;00:00, 10.2MB/s]"
          }
        },
        "560c716068a645d596cc2fe9b886c0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235afab600844a9f8ef8f45cdba142e0",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7537c19825a49cd8f3343c153fe56ef",
            "value": 383
          }
        },
        "573b3112cbee4ba581c18884df0a269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc799bb2e34741fabc79181ea30ee78f",
            "placeholder": "​",
            "style": "IPY_MODEL_a78c45e4929847f0a635988d1ef9d78f",
            "value": " 232k/232k [00:00&lt;00:00, 2.46MB/s]"
          }
        },
        "595530337aab40f6b5cc24d69b3ebaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab64a9556124cf892f33cc9973240ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b7bb6ffc45947798e64147e55fd5ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4896a7b0880641519a93d24ceaa01f04",
            "placeholder": "​",
            "style": "IPY_MODEL_b1478e1351cc4d9cb407e7ca86726e5c",
            "value": "Downloading readme: 100%"
          }
        },
        "5bd4908665db4c8baac9d52a40a1c28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46ff0481a7a94abb9cea91aaacd1ea29",
            "placeholder": "​",
            "style": "IPY_MODEL_05fd99843ed746d1baf705e6c31881f6",
            "value": " 9832/9832 [00:01&lt;00:00, 7725.02 examples/s]"
          }
        },
        "5c69e45579f54fc6b2415ebbad4da477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c96dd4ef67f4900af004f322706921f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd1df4079d44b1aad849b4a0a5e3b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5df7aa079833485bbde65e4658b496e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283065bbec654b89a6be726e3fe790fd",
            "max": 28682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebf0c7ac01e441d68a38cac5fed89d00",
            "value": 28682
          }
        },
        "5e1a387877054dacbb6bf1fa32b08d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed5174d9d6c4680bb7cc1e803184102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91bcf74809894d39b5199ca23691f00f",
            "placeholder": "​",
            "style": "IPY_MODEL_85a35c16364f4c6880dbbecf061faf44",
            "value": " 1.34G/1.34G [00:17&lt;00:00, 83.7MB/s]"
          }
        },
        "5f0512fb3607471f817b5c215d94e4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd68849bd0a44238fbb9bec129b0511",
            "placeholder": "​",
            "style": "IPY_MODEL_3312caf3fc76420ead7f4945675df52a",
            "value": " 314/314 [00:00&lt;00:00, 4.38kB/s]"
          }
        },
        "5f1b9961c6b14a1a92f3cb2c82883a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdca1f2b388437fac7624c0eca1ec26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600bc8f5877547aca898f8c85902040e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "619bcc47eac24a098ac5908bddc4297d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "634b144054f44d44945b547da14fc7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c104c3dd39406c9345d7d9bde52386",
            "placeholder": "​",
            "style": "IPY_MODEL_9b509e480979428d8b4c9b1b6909fdd4",
            "value": " 1.77k/1.77k [00:00&lt;00:00, 69.1kB/s]"
          }
        },
        "638f36ef35ec4ec88ba057c63093eca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a2424581894ab48ad61b9f38cc882e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641fd37171904fb590b7877d8403aeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8f710e2dcfc40398ce16a4ac265cc26",
              "IPY_MODEL_377a7fa0ebce4c8a96a55c6e1c08403f",
              "IPY_MODEL_5ed5174d9d6c4680bb7cc1e803184102"
            ],
            "layout": "IPY_MODEL_2c148a8aa9fe4f30a69392f10a350eac"
          }
        },
        "656cb0e3b85c4a57936749caa02f664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "664c5d6fcfd347fdaf01c0d9bd4da14f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686aaeb98c1a4e688af5030963b8525e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68db1531b9574e72a2ff0d52995a7347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694f0df64a4b433aa22afef48d968090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d264b002cc4c3889089fe28f6cfa80",
              "IPY_MODEL_f6a686a076954e0c9c5d11429a14d582",
              "IPY_MODEL_9f512b3c83bf4fcaa1640cf5cdbea8c8"
            ],
            "layout": "IPY_MODEL_282f350bdadd41fa82b37f527ffe8a63"
          }
        },
        "6b349f8f7890488eaa05b156ec971bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3537b58aca04f398663d6a8f6bd7cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_0ea16b4f2c6d428191dd7d31d21ad659",
            "value": " 1725/1725 [00:03&lt;00:00, 758.62 examples/s]"
          }
        },
        "6baecbf668bc4a6f93be03e5f671b76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d322e088a6a4904a0b99740d8d4e45c",
            "placeholder": "​",
            "style": "IPY_MODEL_20402646761d4cf3975763fc130d6ff5",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "6da885f236a24cf5a09add7c9927db76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eeb3579c2b644a6b8501cc246083c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f102144e4fd4840b77808f1e6ff7697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff3a2b6be1f4220b0e3c055fc587c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70225a6a843d4ccf87d1b43d4cf1895b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7081369f016f46ec9ad16edcedd027b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e2bfea29de4c47b0c60590deff9771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2750de9a4c5740b080f5a8145de41111",
            "placeholder": "​",
            "style": "IPY_MODEL_ecf9c5705a7b491c82d4e8b5cbd8c439",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "755e3809aa3043f99d3664955a3a2c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d07abd85374cca92698119139b140e",
              "IPY_MODEL_00001f9f055045f9ae35f94f76be8fe4",
              "IPY_MODEL_1e7d06e9df9b4a88a003bbba433c1cae"
            ],
            "layout": "IPY_MODEL_a87f8ff9f575436da0dcf9a31642f7b7"
          }
        },
        "75d264b002cc4c3889089fe28f6cfa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052465580f854b15be0d29e9dc59125b",
            "placeholder": "​",
            "style": "IPY_MODEL_619bcc47eac24a098ac5908bddc4297d",
            "value": "Downloading data files: 100%"
          }
        },
        "75d76bf886514ba5ac9fedee0fcfba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fd0e5e6b8f47c6a4c9557f127ef73b",
            "placeholder": "​",
            "style": "IPY_MODEL_b963a45c28d1437f86109f283a370f38",
            "value": " 384/384 [00:00&lt;00:00, 3.58kB/s]"
          }
        },
        "77d712d32c0f491cb9a58df33b012b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7834f7deaa3b43669cd0de893fa62448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78608a4a3a8f4c119d9a0128153a39eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48729429682c4b37a624ba2eb55d1966",
            "placeholder": "​",
            "style": "IPY_MODEL_6eeb3579c2b644a6b8501cc246083c97",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7950d803ab5b4c4ab10dc9e0902e34b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b387dec327543f79f957f81fb651cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bdb5cce9c364437970f01220e5f0aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e72971bf9804c3688c24e0a3eca0da7",
            "placeholder": "​",
            "style": "IPY_MODEL_d36c80ffd8824fdb8e1e344f41fa3669",
            "value": "Downloading metadata: 100%"
          }
        },
        "7c01fc1aabb0486f9f1f0674b46b5481": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f102144e4fd4840b77808f1e6ff7697",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82084929de714135a363f5693f4a0aac",
            "value": 1725
          }
        },
        "7c1ea655a2844e0e81c89529f95acb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fca62c132b4b9c9af64955480ac905",
            "placeholder": "​",
            "style": "IPY_MODEL_7081369f016f46ec9ad16edcedd027b0",
            "value": "Generating validation_mismatched split: 100%"
          }
        },
        "7c50e41b12ab40ae88db5a68806a5287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aea1f6de91a43a4b491c82ffc1522be",
            "placeholder": "​",
            "style": "IPY_MODEL_3c45e6794f974b4199098bcd87765e63",
            "value": "Downloading builder script: 100%"
          }
        },
        "7e61f641028148e988678a2ecbe24a21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f511160291e4a4a82f8694772449ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd3d3a3aab24adcac4748b5639fc485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa7d573777144cbbb8df6ddc7b57673",
            "placeholder": "​",
            "style": "IPY_MODEL_129141d5fdb84754a0d1b1ae65a7eeb3",
            "value": " 8.71k/8.71k [00:00&lt;00:00, 312kB/s]"
          }
        },
        "808dad49922a431d9c43faf48478a069": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80fd0e5e6b8f47c6a4c9557f127ef73b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814c0fc7e64c49bfa85d5087d1e07cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81afc2262c8545dab41aacde91066b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638f36ef35ec4ec88ba057c63093eca2",
            "placeholder": "​",
            "style": "IPY_MODEL_4b35ff0e35ca4e6088f2f1f687ff924c",
            "value": "100%"
          }
        },
        "82084929de714135a363f5693f4a0aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "825fb9aa19594a61b2a779837eb230b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686aaeb98c1a4e688af5030963b8525e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a024ed7f3514fd6a544804a8bee0d78",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "82db512ae4ce4b1fbde3aed3d893e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd748fe04232441abb30f153e54f9890",
            "placeholder": "​",
            "style": "IPY_MODEL_8eda2864b2774815bd6d860c1fdf2625",
            "value": "Downloading data: 100%"
          }
        },
        "82f1dc2ca5ef4e45818a2b9107732d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae32d0dd19e40e8a0fc4b04b325abd6",
            "placeholder": "​",
            "style": "IPY_MODEL_20ae65dc26cb4ab98a9637dfa2bd5a62",
            "value": " 616/616 [00:00&lt;00:00, 9.58kB/s]"
          }
        },
        "843d11a2271246f49dbabe80fc4762d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a35c16364f4c6880dbbecf061faf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85aa23b715f248248204a2bdf3e5f7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8631f393c12e4ebaa57838a4f1c1efb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868c8d0c5a4a4535a00dd833ad0dbb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1ea655a2844e0e81c89529f95acb4c",
              "IPY_MODEL_f4a51d5c122645a5a58acfbadb0cf752",
              "IPY_MODEL_5bd4908665db4c8baac9d52a40a1c28e"
            ],
            "layout": "IPY_MODEL_000f6133e191461c893cffdc6783a5f9"
          }
        },
        "8974203b2bde4395b3144ffe61596643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdca1f2b388437fac7624c0eca1ec26",
            "placeholder": "​",
            "style": "IPY_MODEL_1c00f260ca44415c9c2cc342c9cab470",
            "value": " 232k/232k [00:00&lt;00:00, 9.15MB/s]"
          }
        },
        "8a0851189dae4fbdb953f6afe6f3ba29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1ecdd97d194a9ab63a15980d1e2e31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae32d0dd19e40e8a0fc4b04b325abd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3982acce834b95a6f318dfb78add1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a93d25cd25426e9c60222b29321889",
            "max": 226850426,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0db15040be1242378220fa56a21aba28",
            "value": 226850426
          }
        },
        "8c45ce351a9b45dda4359b706ea36aba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d65399ec30e44af888334b8ed0a0fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b68564469cae4918bfe78edfe46f9bbd",
              "IPY_MODEL_bf6d6ac360f2412c81aedaa1502d0d52",
              "IPY_MODEL_7fd3d3a3aab24adcac4748b5639fc485"
            ],
            "layout": "IPY_MODEL_c19a787e4cac4c908602096d6c7fb352"
          }
        },
        "8dbb1fccc920458cbffc7029953e5363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29e9e92bc30c4b2f89416481b4fb1455",
              "IPY_MODEL_1c5678cdeb204d21b94526ccdab34d32",
              "IPY_MODEL_dea6b34486294d388d68aa9ef3aaa281"
            ],
            "layout": "IPY_MODEL_e34566724c6e4598860e77d6b710faf8"
          }
        },
        "8e9137be11744d329bceecd548d91025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c45ce351a9b45dda4359b706ea36aba",
            "placeholder": "​",
            "style": "IPY_MODEL_9e2644d3c3bb40aa9eba632e756112a3",
            "value": " 125/125 [00:00&lt;00:00, 3.05kB/s]"
          }
        },
        "8ea68f6b18c342938de8be19d3896038": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42f3b105ff645dcb58805289594baad",
            "placeholder": "​",
            "style": "IPY_MODEL_d4214693adb54e44b31fd40e549802b8",
            "value": "Generating test split: 100%"
          }
        },
        "8eda2864b2774815bd6d860c1fdf2625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1bf2df4214449483a37dc84d9f3c43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91738a91e20344f1b848ccc39bd0b686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d88bd9fdda49bcbf01366f8fe6fab2",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5cfab63b2d47869f69b772f9801d69",
            "value": "Downloading data: "
          }
        },
        "91bcf74809894d39b5199ca23691f00f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91de7341a97a4415b5656ee33fe6395f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1bf2df4214449483a37dc84d9f3c43",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9afa2b87f4a94a58b7c639a0a7f63813",
            "value": 616
          }
        },
        "91eebca40ce344039704522c4570353c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "928bc9d9e240469298d2a267fe3b9e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595530337aab40f6b5cc24d69b3ebaf9",
            "max": 5145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85aa23b715f248248204a2bdf3e5f7ec",
            "value": 5145
          }
        },
        "92d450929c8e45539c2726eaf96d5ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "947f138f8aef463e8f3852b167587614": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9568bdb74f3e450f91b3558cf5ad5da1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e7d97dc8f44c7d873060a89f82ce0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979449deb4254629b80f0089584c851a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bd45b05dda4319adf853b5104f0a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99ef066e53974658a59443c917b2c615": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a675022c08043438f0288c2dc3d1692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff58b4945b004e9996568c228986d287",
            "max": 28751,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1290569b6a4d490fbfc8ca3915983263",
            "value": 28751
          }
        },
        "9ad1276e945e4915a079e97e06048ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9afa2b87f4a94a58b7c639a0a7f63813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b509e480979428d8b4c9b1b6909fdd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c8b871e03af41ada7990e7b76084f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ae5a6ee9244aeea02e10990e8dd3da",
              "IPY_MODEL_470a84311bbf40c6ae6322d6edc353ae",
              "IPY_MODEL_8974203b2bde4395b3144ffe61596643"
            ],
            "layout": "IPY_MODEL_d4ea11ee38044f7cb7ffe1a5b018bda7"
          }
        },
        "9d6b311c522f479dbf3e6ac6d0558a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b7bb6ffc45947798e64147e55fd5ace",
              "IPY_MODEL_f5dbea136bc8437daea9205f86a0222d",
              "IPY_MODEL_634b144054f44d44945b547da14fc7cb"
            ],
            "layout": "IPY_MODEL_199f448fddf34260ae259d77a8df6849"
          }
        },
        "9e2644d3c3bb40aa9eba632e756112a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ef72b344a964832bd2b19140d230f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f512b3c83bf4fcaa1640cf5cdbea8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab64a9556124cf892f33cc9973240ea",
            "placeholder": "​",
            "style": "IPY_MODEL_656cb0e3b85c4a57936749caa02f664d",
            "value": " 3/3 [00:01&lt;00:00,  2.26it/s]"
          }
        },
        "a2bbd67afcb9463cb0f78d7a24c5f126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33ab96c585c411ab148d76865b848f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5183ef3eec0d4bdfbcc5544b0fec573b",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3751db7e581847efa6c224dd50c9b7bb",
            "value": 711396
          }
        },
        "a417b74f6fdb4dedbd6bf3408d0dea69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4848184b58645b2a572c6e1a1231f05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53d537c8c0e48d1a77fbc22e5c41402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02191a5509094a0abcf8862d3a8ee4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_5c69e45579f54fc6b2415ebbad4da477",
            "value": " 570/570 [00:00&lt;00:00, 6.61kB/s]"
          }
        },
        "a587d42c581c4f75984a189ebe1b1831": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5967030d5aa4581b66d319588b92db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6baecbf668bc4a6f93be03e5f671b76a",
              "IPY_MODEL_a33ab96c585c411ab148d76865b848f2",
              "IPY_MODEL_5589d685cbc94ea0a045dcba0e69a7e5"
            ],
            "layout": "IPY_MODEL_01ac22caf29c4b2baf0ebc428f3398b3"
          }
        },
        "a6770d150cfa459780d5adb12fc7c7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78608a4a3a8f4c119d9a0128153a39eb",
              "IPY_MODEL_91de7341a97a4415b5656ee33fe6395f",
              "IPY_MODEL_82f1dc2ca5ef4e45818a2b9107732d58"
            ],
            "layout": "IPY_MODEL_5e1a387877054dacbb6bf1fa32b08d7a"
          }
        },
        "a78c45e4929847f0a635988d1ef9d78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a87f8ff9f575436da0dcf9a31642f7b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f66a8eed1443d099d0fadab83d02e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa099b9c51d6447a9a22fb13b103cb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a6cc127c8c4f03bab0b31bb3a1721b",
              "IPY_MODEL_08fbdead6ab540d4a1d2d8f06879e417",
              "IPY_MODEL_5f0512fb3607471f817b5c215d94e4d8"
            ],
            "layout": "IPY_MODEL_0457dfcb462c4173bbfb7890bb043c97"
          }
        },
        "aae2a30b7f474dbcbf55aa677b9518f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8bf4aa34c5452d8c6d01df44402eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9c165248ef4e0b9c357316b95f66af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc06005b98c44f0a6308cbd4f6a3527": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "addf3619a835489f8d9f3ce4498daf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adef362bc525401c8b657d33dfec55ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae85f3dd9b864de7897e02a2313c8093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea00ba0feb164981bdb521803fd29049",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16501e0f5de84fc7bbbdcc9b37f61d85",
            "value": 1
          }
        },
        "af816340aae74a81a6eaf63a1933f5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afd68f4512e045c2bfaa46eb36d4ab5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f387685057a6405f86292bd9ce5df000",
            "max": 27887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_808dad49922a431d9c43faf48478a069",
            "value": 27887
          }
        },
        "b0546b4b929f4fe3927af49ab119d99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df31cc0682014cdb881817de1c02288f",
            "max": 2877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01fa51a473a6472da89d47bf1116e575",
            "value": 2877
          }
        },
        "b072faf11c504e39939d1ad4534f9112": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb4b68eda9f481abbc7b2456644e16b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c54d6fd6a004ed98c1cb595a0bb84a0",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b076eddbd7a74d5495615776c26a6f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f230ba518eed434fb107f97c66293470",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a7dd0c3112945959e9908425fcaa8b8",
            "value": 384
          }
        },
        "b08eba43d39846869bdd9050836be1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b1478e1351cc4d9cb407e7ca86726e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b17a0dd6bd24481e8e597415bfc02c87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34433ff3b52491fb5829b9f1522e162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42f3b105ff645dcb58805289594baad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fca62c132b4b9c9af64955480ac905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65ef6da8ad34e2285813544d00bf3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b68564469cae4918bfe78edfe46f9bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_664c5d6fcfd347fdaf01c0d9bd4da14f",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d27436463f41aa83609422efc3dbe4",
            "value": "Downloading builder script: 100%"
          }
        },
        "b70156e5cb144e75b97697a2439d9a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b719af868833401c86d45d2ae059c868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7b946e1ad95455b818512986f83f7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b963a45c28d1437f86109f283a370f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b96a361475c947e5a0f9e5f0f867ced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c9ec9890384cb4b17139a7335e371e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adef362bc525401c8b657d33dfec55ce",
            "value": 1
          }
        },
        "ba76516f42224f79a9dfe8a36385bb22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa7d573777144cbbb8df6ddc7b57673": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc799bb2e34741fabc79181ea30ee78f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7e0e6c4b154e55875c6fddc0aac6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcee86d4105743f5a69c595029994bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd79d8ce5e28404c988f4965873a2f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc7642ca3e748069974df4a510470ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1034a93ce59f439bb128b6c096eefdf2",
              "IPY_MODEL_4a16335de26a43c09d578cbbe20e98d1",
              "IPY_MODEL_573b3112cbee4ba581c18884df0a269e"
            ],
            "layout": "IPY_MODEL_4fe04dcab6654d0594a56109e7eb6805"
          }
        },
        "be7af49d0afe4ecdaa800be969d5a3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2166426a7a224f1da2065f3221463693",
            "placeholder": "​",
            "style": "IPY_MODEL_77d712d32c0f491cb9a58df33b012b0c",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "bf6d6ac360f2412c81aedaa1502d0d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5378e14b0bc47cfae83e93cda9c511e",
            "max": 8711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3bb372606c1478296ef48e89fc3570e",
            "value": 8711
          }
        },
        "c0908ccc452b42e681765c37a139e878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74fd39704b44cea8f012402e7449a80",
            "max": 9815,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5e5dd22e0b24a30a485b54dbdacf1cf",
            "value": 9815
          }
        },
        "c16dd57325504698b35f155d1bd040b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c19a787e4cac4c908602096d6c7fb352": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1ad349038c94c1f9ec7b1d0d7245699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c225230ea12f4f90bd461485f300580e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3bb372606c1478296ef48e89fc3570e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4c104c3dd39406c9345d7d9bde52386": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c508e67d54c24888b82b66108681da19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71e718353ac40788febf07676b3cb25",
            "placeholder": "​",
            "style": "IPY_MODEL_addf3619a835489f8d9f3ce4498daf36",
            "value": " 3668/3668 [00:01&lt;00:00, 2844.62 examples/s]"
          }
        },
        "c519b80ce005494caf41456ec90111bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5323c16a9ca4decbe25c651a14517de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5378e14b0bc47cfae83e93cda9c511e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5adcad970e4455cbf797f14e2e5303e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f6c046574b4badbf5dac2bd4989d67",
            "placeholder": "​",
            "style": "IPY_MODEL_e844aa942c604f17b61375f59aad56f3",
            "value": "Downloading builder script: 100%"
          }
        },
        "c6b2dc48588b482f80e9a2473dc5b452": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7537c19825a49cd8f3343c153fe56ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d86dc22b0747dba72d6aa5fd899df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7fcfc2727db445695b908ffd3370feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0851189dae4fbdb953f6afe6f3ba29",
            "placeholder": "​",
            "style": "IPY_MODEL_01f4a70e089f4fe5abb0d9246aeee403",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "ca5cfab63b2d47869f69b772f9801d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafc757655d74a2697f4ba566b3623ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1837578698f426d8c65a40770a3488c",
            "placeholder": "​",
            "style": "IPY_MODEL_fdf37a5ac48c477d99318631238a5756",
            "value": "Generating train split: 100%"
          }
        },
        "cd748fe04232441abb30f153e54f9890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa5b162648c4abca773a478c3e3beb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d151de5a1862426f9d3ab2aaae73f4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1837578698f426d8c65a40770a3488c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1dafb9eb15541489d740cbf202fac2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc06005b98c44f0a6308cbd4f6a3527",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eace7bc2187b4dd0af47dbee9327903a",
            "value": 1
          }
        },
        "d265db9a419d4edfbdb91e4bd8f78846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a8de725a934927b52792351e0d5099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d365ebcd816a44da80bc74870dd008bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36c80ffd8824fdb8e1e344f41fa3669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4214693adb54e44b31fd40e549802b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4ccb21f87954a31ab7ab0fd7e11a8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4ea11ee38044f7cb7ffe1a5b018bda7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6012c2d60024501a1bd8c529bf055e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ccd976679e45fcbf6d6b5d06360ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71e718353ac40788febf07676b3cb25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72812af3cd8475f8a76a8ff3ec236e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74fd39704b44cea8f012402e7449a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87e9ee37dfe44bcad7b97ccfef0f5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ce4959b2bc410a8b455eb2adb7ffc9",
            "placeholder": "​",
            "style": "IPY_MODEL_422ac21cdb1d45a8a0814ef00c9769ff",
            "value": "Downloading readme: 100%"
          }
        },
        "d947bfe9101646c9a7222ada482d4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a90b08aaec44d9962e8c090b8d0baa",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70225a6a843d4ccf87d1b43d4cf1895b",
            "value": 125
          }
        },
        "d9a90b08aaec44d9962e8c090b8d0baa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9bcbb8cd61d4fa5b9e0b95304f8969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea68f6b18c342938de8be19d3896038",
              "IPY_MODEL_0b0c4175d283414ab014c95269b4421b",
              "IPY_MODEL_00c7829ca16746089c8896865f374b1f"
            ],
            "layout": "IPY_MODEL_f9f77be1c3044483bbd3714a5a45e2ad"
          }
        },
        "da3eb201a16240aaa91baf19b49d4209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab6a9ff832540bfae51a3f0dcfedfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5adcad970e4455cbf797f14e2e5303e",
              "IPY_MODEL_928bc9d9e240469298d2a267fe3b9e65",
              "IPY_MODEL_24e977d511bd4f03bc8d730cd4c86027"
            ],
            "layout": "IPY_MODEL_4b4dae6b5bd5474491e1c86a6e462ebf"
          }
        },
        "dae9d080adfc4bfbba896820bbf57c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "db1f664494c94faf8998df1f25718b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c96dd4ef67f4900af004f322706921f",
            "placeholder": "​",
            "style": "IPY_MODEL_c519b80ce005494caf41456ec90111bf",
            "value": " 27.9k/27.9k [00:00&lt;00:00, 587kB/s]"
          }
        },
        "dcd68849bd0a44238fbb9bec129b0511": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea6b34486294d388d68aa9ef3aaa281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70156e5cb144e75b97697a2439d9a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_96e7d97dc8f44c7d873060a89f82ce0e",
            "value": " 440M/440M [00:05&lt;00:00, 85.0MB/s]"
          }
        },
        "df31cc0682014cdb881817de1c02288f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8de4914b3f4c51b4e048f053a0e009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfd3f1f64d81471083416a3e4ca6aa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c9ec9890384cb4b17139a7335e371e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d27436463f41aa83609422efc3dbe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2f772d1181b417e8f3bc2feee4f6e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825fb9aa19594a61b2a779837eb230b4",
              "IPY_MODEL_b076eddbd7a74d5495615776c26a6f3e",
              "IPY_MODEL_75d76bf886514ba5ac9fedee0fcfba8d"
            ],
            "layout": "IPY_MODEL_e9685ee9b4aa47fcb5a3a79261ca87c7"
          }
        },
        "e34566724c6e4598860e77d6b710faf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e362a74248d24aa28ab7dd3500c9d303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f66a8eed1443d099d0fadab83d02e9",
            "placeholder": "​",
            "style": "IPY_MODEL_292c0b150eb84f06a012e2084b035350",
            "value": " 1.05M/? [00:00&lt;00:00, 3.55MB/s]"
          }
        },
        "e3712984d7774865be2c1e97faf82d57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76cddc6d7d04d3fb01c11225ec1b6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bd0a23537441b6a41373c7db399423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bdb5cce9c364437970f01220e5f0aa3",
              "IPY_MODEL_5df7aa079833485bbde65e4658b496e0",
              "IPY_MODEL_e9149263e2264fe6b5e5cb50f67d55c2"
            ],
            "layout": "IPY_MODEL_e3712984d7774865be2c1e97faf82d57"
          }
        },
        "e84136de295d4d39b44c908ff2458ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e844aa942c604f17b61375f59aad56f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e891d996e42f425cb2b31d563dfc77ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216e1650231e471fa0d88e3d73bf6da0",
              "IPY_MODEL_d1dafb9eb15541489d740cbf202fac2f",
              "IPY_MODEL_e362a74248d24aa28ab7dd3500c9d303"
            ],
            "layout": "IPY_MODEL_1eb78591c14840daaf6741730f2280f8"
          }
        },
        "e8f710e2dcfc40398ce16a4ac265cc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177dee7aa0754c7db2b595f83a4eb105",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe3c4d6e4774be691e7c0551fd334ff",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "e9149263e2264fe6b5e5cb50f67d55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8bf4aa34c5452d8c6d01df44402eea",
            "placeholder": "​",
            "style": "IPY_MODEL_c1ad349038c94c1f9ec7b1d0d7245699",
            "value": " 28.7k/28.7k [00:00&lt;00:00, 559kB/s]"
          }
        },
        "e9685ee9b4aa47fcb5a3a79261ca87c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97d23572a21475fa4b5b9fa4454d4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68db1531b9574e72a2ff0d52995a7347",
            "placeholder": "​",
            "style": "IPY_MODEL_eeafa1a037dd42a88774f76ea6275360",
            "value": " 6.22k/? [00:00&lt;00:00, 91.2kB/s]"
          }
        },
        "e982215023c24a3caf881dd3986cca86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ea00ba0feb164981bdb521803fd29049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "eace7bc2187b4dd0af47dbee9327903a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb0aa78ac5ed4e8189871f2dcb7b68d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebf0c7ac01e441d68a38cac5fed89d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecf9c5705a7b491c82d4e8b5cbd8c439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeafa1a037dd42a88774f76ea6275360": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef504e4ab1384063bff714e1649e0aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10d3cde2d7b4121971d8e19e3362b30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f230ba518eed434fb107f97c66293470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3537b58aca04f398663d6a8f6bd7cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3707c74969e4f6c84d6a36b59d6fa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f511160291e4a4a82f8694772449ea8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91eebca40ce344039704522c4570353c",
            "value": 231508
          }
        },
        "f387685057a6405f86292bd9ce5df000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a51d5c122645a5a58acfbadb0cf752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8631f393c12e4ebaa57838a4f1c1efb0",
            "max": 9832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7e0e6c4b154e55875c6fddc0aac6f0",
            "value": 9832
          }
        },
        "f4bb56cde5b042e8821ee26d25da4ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe8145192c34433b3140f05b5b2528f",
            "placeholder": "​",
            "style": "IPY_MODEL_3988d9e57bc841b49a5079130f071dfc",
            "value": " 296/408 [00:00&lt;00:00, 1064.07 examples/s]"
          }
        },
        "f53073dd81bf427188a9cfde75c18bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b5f6a6687b34036bd5a87c8b61dc2c3",
              "IPY_MODEL_b0546b4b929f4fe3927af49ab119d99a",
              "IPY_MODEL_37e0abc511f04624986368ef45b50131"
            ],
            "layout": "IPY_MODEL_d365ebcd816a44da80bc74870dd008bd"
          }
        },
        "f54be5e820704ad2b31b6b7a6b946181": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5912ed9e9c944e5ae35be20f0634165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5dbea136bc8437daea9205f86a0222d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_140d521dd6334490abed5fb1c2c1d245",
            "max": 1766,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_947f138f8aef463e8f3852b167587614",
            "value": 1766
          }
        },
        "f5e5dd22e0b24a30a485b54dbdacf1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f619ea2b062a4eacb80ade328d56c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f68c38cc7bf84db2ab1540ca985599e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f697e928e02f405d99c43c4b1fd890c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5912ed9e9c944e5ae35be20f0634165",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d86dc22b0747dba72d6aa5fd899df0",
            "value": " 1/1 [00:00&lt;00:00, 33.60it/s]"
          }
        },
        "f6a686a076954e0c9c5d11429a14d582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a320f7b8bba47ddb97d2aff966e162f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e215f7f87fc48bfbb3e74c9c97b23a8",
            "value": 3
          }
        },
        "f6c454dc6dcb4528b7b05b83c72640fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7ca459667fe48c2a54d0ca13ccfe114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91738a91e20344f1b848ccc39bd0b686",
              "IPY_MODEL_ae85f3dd9b864de7897e02a2313c8093",
              "IPY_MODEL_e97d23572a21475fa4b5b9fa4454d4cc"
            ],
            "layout": "IPY_MODEL_32f65d2703c048929de10720219fdf53"
          }
        },
        "f81a1dd1a8b547b39297478219b41c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9d88bd9fdda49bcbf01366f8fe6fab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f77be1c3044483bbd3714a5a45e2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fa205a1da88e418a881efb0963042e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb064cacf0e243299a2d092facae8c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7af49d0afe4ecdaa800be969d5a3e7",
              "IPY_MODEL_560c716068a645d596cc2fe9b886c0ad",
              "IPY_MODEL_08c60bb508854cc9b6772ab78502b6fb"
            ],
            "layout": "IPY_MODEL_e84136de295d4d39b44c908ff2458ba9"
          }
        },
        "fc2d3eb4b1304b97bf336245736983ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d798a40b2a24c4f8ce823023d75ea6a",
              "IPY_MODEL_429379eb4c4f452d94a52521911811a8",
              "IPY_MODEL_49a90c227b9342ddbb670c9fe85591cc"
            ],
            "layout": "IPY_MODEL_843d11a2271246f49dbabe80fc4762d4"
          }
        },
        "fc40e712ccca489e8cb2eaadbc47aa54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87e9ee37dfe44bcad7b97ccfef0f5ff",
              "IPY_MODEL_afd68f4512e045c2bfaa46eb36d4ab5a",
              "IPY_MODEL_db1f664494c94faf8998df1f25718b9f"
            ],
            "layout": "IPY_MODEL_63a2424581894ab48ad61b9f38cc882e"
          }
        },
        "fcb506371e6e4cd2947988d6c7050809": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf37a5ac48c477d99318631238a5756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe156388571b4c63b5fc5f5ca857e522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff58b4945b004e9996568c228986d287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe8145192c34433b3140f05b5b2528f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd84482d10704f60adbc647cfb47b95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ff7579aaccc469c81597b9600121114",
              "IPY_MODEL_2e7e744df0a94152a01a659d0ddc5d9d",
              "IPY_MODEL_b60a8ec2aea74e30abf3266c33ff5cf2"
            ],
            "layout": "IPY_MODEL_fa3f0c50db6c4a189932059908bb5b56"
          }
        },
        "9ff7579aaccc469c81597b9600121114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007ff759ee214271b5ae7440474e3917",
            "placeholder": "​",
            "style": "IPY_MODEL_2e298213e70f4e7caf7bbfe4f210699f",
            "value": "Downloading readme: 100%"
          }
        },
        "2e7e744df0a94152a01a659d0ddc5d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e29f42f9692e4ac1bdd6ae11295c7dd0",
            "max": 4246,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21093f9c444f44dca7b7ad4c8f7d3968",
            "value": 4246
          }
        },
        "b60a8ec2aea74e30abf3266c33ff5cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d533792a09ba47469c8183bb47589bd6",
            "placeholder": "​",
            "style": "IPY_MODEL_e75725f396d94906b61978bb61639dc3",
            "value": " 4.25k/4.25k [00:00&lt;00:00, 125kB/s]"
          }
        },
        "fa3f0c50db6c4a189932059908bb5b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007ff759ee214271b5ae7440474e3917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e298213e70f4e7caf7bbfe4f210699f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e29f42f9692e4ac1bdd6ae11295c7dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21093f9c444f44dca7b7ad4c8f7d3968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d533792a09ba47469c8183bb47589bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75725f396d94906b61978bb61639dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c43238e777524e35aeaef39563f826e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0afd506237e4827b18342517efe57c2",
              "IPY_MODEL_48bb2ed3d83e4478a54e91ba139c5e00",
              "IPY_MODEL_c1b45bd7bb5441ae8351484e31220759"
            ],
            "layout": "IPY_MODEL_3a922b09e0434f5a83b30283e292c1b0"
          }
        },
        "e0afd506237e4827b18342517efe57c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297d52865a7040c98c75eda8db8a66b0",
            "placeholder": "​",
            "style": "IPY_MODEL_9128f342fa6f40ddaf96c76479def9e0",
            "value": "Resolving data files: 100%"
          }
        },
        "48bb2ed3d83e4478a54e91ba139c5e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49e8ab3a33b84fa0927e70de97b68eff",
            "max": 1650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67ed3e714bb546939ef59e3c3b1a46ef",
            "value": 1650
          }
        },
        "c1b45bd7bb5441ae8351484e31220759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0126d9955004e67859e2408793c3701",
            "placeholder": "​",
            "style": "IPY_MODEL_3d179887256d4468a241726c7a29fb8f",
            "value": " 1650/1650 [00:06&lt;00:00, 454.18it/s]"
          }
        },
        "3a922b09e0434f5a83b30283e292c1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297d52865a7040c98c75eda8db8a66b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9128f342fa6f40ddaf96c76479def9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49e8ab3a33b84fa0927e70de97b68eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ed3e714bb546939ef59e3c3b1a46ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0126d9955004e67859e2408793c3701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d179887256d4468a241726c7a29fb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b4127c09ddb41c1991b93d5078f4c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb80343332eb4fdaa7fafdece8f32a6a",
              "IPY_MODEL_0573a106e0444bd89fa1313eb7c26367",
              "IPY_MODEL_5548f2ecaf504a1eb3ef99ff409dd98a"
            ],
            "layout": "IPY_MODEL_23e9342a3beb41a690427a8e86392b15"
          }
        },
        "eb80343332eb4fdaa7fafdece8f32a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b46b750f04142779145773b00c249f1",
            "placeholder": "​",
            "style": "IPY_MODEL_b098cade41154470814779005282469f",
            "value": "Resolving data files: 100%"
          }
        },
        "0573a106e0444bd89fa1313eb7c26367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160e0b74b9fe48979e428d553235cf0b",
            "max": 5534,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_224cfe84583b4a3881bb003755d4fccc",
            "value": 5534
          }
        },
        "5548f2ecaf504a1eb3ef99ff409dd98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ea1273931a4f6a9c3f0b1617ae1909",
            "placeholder": "​",
            "style": "IPY_MODEL_f12cef0d863749faa4558bece58e2aeb",
            "value": " 5534/5534 [00:04&lt;00:00, 88.57it/s]"
          }
        },
        "23e9342a3beb41a690427a8e86392b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b46b750f04142779145773b00c249f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b098cade41154470814779005282469f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "160e0b74b9fe48979e428d553235cf0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224cfe84583b4a3881bb003755d4fccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14ea1273931a4f6a9c3f0b1617ae1909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12cef0d863749faa4558bece58e2aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb08200519154d5381a5715cc29707b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e166f9ef4ba4be5a27a2ec9f4fbc673",
              "IPY_MODEL_38c4fabce8694b89b18712d4b39815dd",
              "IPY_MODEL_19c6e423258e4a42bf71de3a8060cd97"
            ],
            "layout": "IPY_MODEL_448e8344500040408be758becd00f4a6"
          }
        },
        "1e166f9ef4ba4be5a27a2ec9f4fbc673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1e28e6f4c864e82822526d444cdf78e",
            "placeholder": "​",
            "style": "IPY_MODEL_e7345f9a6e3e480fa02a0ac049e8fb88",
            "value": "Resolving data files: 100%"
          }
        },
        "38c4fabce8694b89b18712d4b39815dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe15b58e99f84aeda754a4bcda6c9e5c",
            "max": 816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f97391ce1a914eb7b82348d974f8a8a5",
            "value": 816
          }
        },
        "19c6e423258e4a42bf71de3a8060cd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af1200c003dd4a0aa844cb14b36496c2",
            "placeholder": "​",
            "style": "IPY_MODEL_8a352fc0efd44e438533a8a263efdd7b",
            "value": " 816/816 [00:01&lt;00:00, 420.29it/s]"
          }
        },
        "448e8344500040408be758becd00f4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e28e6f4c864e82822526d444cdf78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7345f9a6e3e480fa02a0ac049e8fb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe15b58e99f84aeda754a4bcda6c9e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97391ce1a914eb7b82348d974f8a8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af1200c003dd4a0aa844cb14b36496c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a352fc0efd44e438533a8a263efdd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8d2c2bd16d24bd2a9ec2df58a9cf3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ea1d19a194e49e88dd90042297277af",
              "IPY_MODEL_fd5e89c8d6854e9a96a972a13e3096bc",
              "IPY_MODEL_13a4626956e4467e9fdbdffab367b3af"
            ],
            "layout": "IPY_MODEL_8cb11f382c8d4fbb94616b72e99da66d"
          }
        },
        "0ea1d19a194e49e88dd90042297277af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7539e5355a40c69e86226be61285a8",
            "placeholder": "​",
            "style": "IPY_MODEL_8a991feecc3a4895a67df0ec38443f94",
            "value": "Resolving data files: 100%"
          }
        },
        "fd5e89c8d6854e9a96a972a13e3096bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3467a336a1844a7c996cbebe5deac8a4",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26e2834b1cf444c38c0f42d70ba49740",
            "value": 24
          }
        },
        "13a4626956e4467e9fdbdffab367b3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd818c8682c14a338008db4e5fe42b8c",
            "placeholder": "​",
            "style": "IPY_MODEL_b6d39bda64dc4c0b82bd00f031a4e581",
            "value": " 24/24 [00:00&lt;00:00,  1.79it/s]"
          }
        },
        "8cb11f382c8d4fbb94616b72e99da66d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7539e5355a40c69e86226be61285a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a991feecc3a4895a67df0ec38443f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3467a336a1844a7c996cbebe5deac8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e2834b1cf444c38c0f42d70ba49740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd818c8682c14a338008db4e5fe42b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d39bda64dc4c0b82bd00f031a4e581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b916d718a6544daa5965a3a619e1728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caa1e364a3544af7a34c1d0bef26d16d",
              "IPY_MODEL_272f34f0ca354f4f9a90b6bbd5c6d851",
              "IPY_MODEL_fb3e27581b984a679b1508c856d6a358"
            ],
            "layout": "IPY_MODEL_f0844bdd8e8d4caa8a4f459d0f548a6d"
          }
        },
        "caa1e364a3544af7a34c1d0bef26d16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c00eeb575ce5464887956b0ff0ede32e",
            "placeholder": "​",
            "style": "IPY_MODEL_d297c38ad8d24e77a6c875c6377864c0",
            "value": "Downloading builder script: 100%"
          }
        },
        "272f34f0ca354f4f9a90b6bbd5c6d851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1ecfc23fcd44a54bc6b75fec187a031",
            "max": 20903,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c2c7840e6e4bc7bfeff9f81e954be7",
            "value": 20903
          }
        },
        "fb3e27581b984a679b1508c856d6a358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d975a33184e4d63bb6f525407983792",
            "placeholder": "​",
            "style": "IPY_MODEL_26085109203d4b398e4966ccc379aa3a",
            "value": " 20.9k/20.9k [00:00&lt;00:00, 845kB/s]"
          }
        },
        "f0844bdd8e8d4caa8a4f459d0f548a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00eeb575ce5464887956b0ff0ede32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d297c38ad8d24e77a6c875c6377864c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1ecfc23fcd44a54bc6b75fec187a031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c2c7840e6e4bc7bfeff9f81e954be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d975a33184e4d63bb6f525407983792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26085109203d4b398e4966ccc379aa3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14eba8c9409c473096dec47c8a186d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d95088402554b039e0977e123ae4217",
              "IPY_MODEL_2bb64f37a0c5460e8a0d851bfc6bf89b",
              "IPY_MODEL_a2297235480a4003a13872b54af61181"
            ],
            "layout": "IPY_MODEL_fc3a5e9bf99f4e3f9f32de8138346e62"
          }
        },
        "2d95088402554b039e0977e123ae4217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7c0c9fff4e8438298a2aab83fd7c53a",
            "placeholder": "​",
            "style": "IPY_MODEL_666454f8106d4e57888e04642c41b8cb",
            "value": "Downloading readme: 100%"
          }
        },
        "2bb64f37a0c5460e8a0d851bfc6bf89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_874a62a373984e9393bb7859e246593e",
            "max": 25624,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_495456125b5f47b69486c166a1e5d5fe",
            "value": 25624
          }
        },
        "a2297235480a4003a13872b54af61181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bedea9cba199496dae77c0ce91b04cb2",
            "placeholder": "​",
            "style": "IPY_MODEL_b0b7d45a4c744c17b88a4e7a25c508b6",
            "value": " 25.6k/25.6k [00:00&lt;00:00, 1.21MB/s]"
          }
        },
        "fc3a5e9bf99f4e3f9f32de8138346e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c0c9fff4e8438298a2aab83fd7c53a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666454f8106d4e57888e04642c41b8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "874a62a373984e9393bb7859e246593e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "495456125b5f47b69486c166a1e5d5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bedea9cba199496dae77c0ce91b04cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b7d45a4c744c17b88a4e7a25c508b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afe6880488e64eab812601ef388eca2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8109862e59a4e058d6713be8415e762",
              "IPY_MODEL_bae28893878d4fb58b0051f1571ff12e",
              "IPY_MODEL_95c067ece86a48548ee1d2b334d87925"
            ],
            "layout": "IPY_MODEL_3b0b9e2af2764af59e4ae9fd813d0284"
          }
        },
        "b8109862e59a4e058d6713be8415e762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719321cb029240d1b38b94f6d75a0f6e",
            "placeholder": "​",
            "style": "IPY_MODEL_ae0fa1ccfe124196bcb6692339c14334",
            "value": "Downloading builder script: 100%"
          }
        },
        "bae28893878d4fb58b0051f1571ff12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2aade6602744914bffc54454af15de0",
            "max": 4644,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66f9eb352d20486f80100dc14d326e95",
            "value": 4644
          }
        },
        "95c067ece86a48548ee1d2b334d87925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e9433317d546ee820335ceee7adf0b",
            "placeholder": "​",
            "style": "IPY_MODEL_577cc621be9f406fb22ef6fa1abfb49c",
            "value": " 4.64k/4.64k [00:00&lt;00:00, 250kB/s]"
          }
        },
        "3b0b9e2af2764af59e4ae9fd813d0284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719321cb029240d1b38b94f6d75a0f6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae0fa1ccfe124196bcb6692339c14334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2aade6602744914bffc54454af15de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f9eb352d20486f80100dc14d326e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06e9433317d546ee820335ceee7adf0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577cc621be9f406fb22ef6fa1abfb49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ca4ee24afc04298add4e206e5a53605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dc6c33bc73446849848863fea619e33",
              "IPY_MODEL_fa37d5ff022942ff9d32644d9d76b05e",
              "IPY_MODEL_f8080e1384084a189666337dfe8f44e4"
            ],
            "layout": "IPY_MODEL_40c4f9b712c842caba16fa5918923071"
          }
        },
        "8dc6c33bc73446849848863fea619e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d0c74b4ca3849ef973af8fba5b47101",
            "placeholder": "​",
            "style": "IPY_MODEL_964d92d06550458483ce5d067cc61ce4",
            "value": "Downloading readme: 100%"
          }
        },
        "fa37d5ff022942ff9d32644d9d76b05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b70384de334fcba234fd3bfceb7e02",
            "max": 43705,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff08c86e7cc0462880f28c798e4ffb8e",
            "value": 43705
          }
        },
        "f8080e1384084a189666337dfe8f44e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e6e5f5f02a4ba5bd9a11d5ccab0fd2",
            "placeholder": "​",
            "style": "IPY_MODEL_a4029b791f9e47918a8cdeb184bc2a1e",
            "value": " 43.7k/43.7k [00:00&lt;00:00, 138kB/s]"
          }
        },
        "40c4f9b712c842caba16fa5918923071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d0c74b4ca3849ef973af8fba5b47101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964d92d06550458483ce5d067cc61ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3b70384de334fcba234fd3bfceb7e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff08c86e7cc0462880f28c798e4ffb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22e6e5f5f02a4ba5bd9a11d5ccab0fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4029b791f9e47918a8cdeb184bc2a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72567b16e1984c428e7368926fea768b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c7061ab398f450d8d495012dc95a496",
              "IPY_MODEL_c27d7d7ea5c741eaaf61cac62bab7cad",
              "IPY_MODEL_e43626722ac74d02ae8690a21fdcaca9"
            ],
            "layout": "IPY_MODEL_79cae125ecf64c1ead7f98249fdf496d"
          }
        },
        "4c7061ab398f450d8d495012dc95a496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0981d02b28842efa959c9a0935fb427",
            "placeholder": "​",
            "style": "IPY_MODEL_758dd0e6f0d54287bb45ade05c50b135",
            "value": "Downloading readme: 100%"
          }
        },
        "c27d7d7ea5c741eaaf61cac62bab7cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120cf4a2275e4b019f24cb176558e903",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2a29e82e80e4b22aa079c425c8f04b4",
            "value": 26
          }
        },
        "e43626722ac74d02ae8690a21fdcaca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b97ca997494945b3d99f68406ba678",
            "placeholder": "​",
            "style": "IPY_MODEL_0c691ed21baa46b197239590f3ae3a38",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.52kB/s]"
          }
        },
        "79cae125ecf64c1ead7f98249fdf496d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0981d02b28842efa959c9a0935fb427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758dd0e6f0d54287bb45ade05c50b135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "120cf4a2275e4b019f24cb176558e903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a29e82e80e4b22aa079c425c8f04b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40b97ca997494945b3d99f68406ba678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c691ed21baa46b197239590f3ae3a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ee4c88368574473b7c5e2e894c4d1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dac1de01da14074a85b8cf7bcd49a1e",
              "IPY_MODEL_4e8b7112975a4bdc8d8b3708de285270",
              "IPY_MODEL_ff95d0ac8fe54b059e793969a0fc9c73"
            ],
            "layout": "IPY_MODEL_5d9164e3a4f64fda8bf69f66ead6f55f"
          }
        },
        "2dac1de01da14074a85b8cf7bcd49a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea7ccd32f674b888ba89786a99bba11",
            "placeholder": "​",
            "style": "IPY_MODEL_c05f9a6948e1471495722d39a47df80f",
            "value": "Downloading readme: 100%"
          }
        },
        "4e8b7112975a4bdc8d8b3708de285270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd5882fa65374a4bafa3754c391e2e91",
            "max": 543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04dc945f096c466dba2aff03e85109a7",
            "value": 543
          }
        },
        "ff95d0ac8fe54b059e793969a0fc9c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65f0fcb8b52b496fbb9eacc7e3fbc09b",
            "placeholder": "​",
            "style": "IPY_MODEL_6803b0c7867542629accd9594aba8320",
            "value": " 543/543 [00:00&lt;00:00, 25.7kB/s]"
          }
        },
        "5d9164e3a4f64fda8bf69f66ead6f55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea7ccd32f674b888ba89786a99bba11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05f9a6948e1471495722d39a47df80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd5882fa65374a4bafa3754c391e2e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04dc945f096c466dba2aff03e85109a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65f0fcb8b52b496fbb9eacc7e3fbc09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6803b0c7867542629accd9594aba8320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "955441547db940c68eafd6edbb24f2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33b94ff78b774c0bb396764214faae15",
              "IPY_MODEL_c51c0aec84d34d8795230b826c0e506c",
              "IPY_MODEL_33b8304d91a742c88594e9a243c69d90"
            ],
            "layout": "IPY_MODEL_93c388a0e311479aa3f9cb5cfd09c82a"
          }
        },
        "33b94ff78b774c0bb396764214faae15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b33d5b31cfd6458e9f4e2f225ceb563b",
            "placeholder": "​",
            "style": "IPY_MODEL_8f5968e4b8384018bfe3888af7ac62eb",
            "value": "Downloading builder script: 100%"
          }
        },
        "c51c0aec84d34d8795230b826c0e506c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3bb043811d46ccb5117ee7ce232a21",
            "max": 10127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f481b94794cd4fdc9a0ed71c6c38f9d7",
            "value": 10127
          }
        },
        "33b8304d91a742c88594e9a243c69d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04375298c8424abdbaf0b5bcc94e489e",
            "placeholder": "​",
            "style": "IPY_MODEL_af2015e115a1433ca9e41558643f014a",
            "value": " 10.1k/10.1k [00:00&lt;00:00, 366kB/s]"
          }
        },
        "93c388a0e311479aa3f9cb5cfd09c82a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33d5b31cfd6458e9f4e2f225ceb563b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f5968e4b8384018bfe3888af7ac62eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f3bb043811d46ccb5117ee7ce232a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f481b94794cd4fdc9a0ed71c6c38f9d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04375298c8424abdbaf0b5bcc94e489e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2015e115a1433ca9e41558643f014a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd0caf5d91fc40309873b71a45a1cd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4385d67e0f1d4168a9dd96885985f758",
              "IPY_MODEL_d34082f569d84c3fa29bfc3c66cea638",
              "IPY_MODEL_9c639b77ca884d6aba8945c0a92aad94"
            ],
            "layout": "IPY_MODEL_f520a638e72643089418892b9b5ab94a"
          }
        },
        "4385d67e0f1d4168a9dd96885985f758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9002759dd55a40f798648710e92db520",
            "placeholder": "​",
            "style": "IPY_MODEL_54dcf39846c24c6f87cf1a07780ccc4f",
            "value": "Downloading readme: 100%"
          }
        },
        "d34082f569d84c3fa29bfc3c66cea638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf14d365c4424c849a4d898e8072157d",
            "max": 6694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5478b2c60e034b44bfa207fa1e3b7f8f",
            "value": 6694
          }
        },
        "9c639b77ca884d6aba8945c0a92aad94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c49b91924fa4eea914de60e9f988692",
            "placeholder": "​",
            "style": "IPY_MODEL_b2ee39a1e0584d8c88e4c3e7cee9b37f",
            "value": " 6.69k/6.69k [00:00&lt;00:00, 214kB/s]"
          }
        },
        "f520a638e72643089418892b9b5ab94a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9002759dd55a40f798648710e92db520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54dcf39846c24c6f87cf1a07780ccc4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf14d365c4424c849a4d898e8072157d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5478b2c60e034b44bfa207fa1e3b7f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c49b91924fa4eea914de60e9f988692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ee39a1e0584d8c88e4c3e7cee9b37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90da2949a0f541d9ad3fa4f78fc8f7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24e09036434943a1bce7ef46550bc5bd",
              "IPY_MODEL_67a2cce9f2404056b681165ac17678a5",
              "IPY_MODEL_d651c8426f454582a32f3acb37da0a63"
            ],
            "layout": "IPY_MODEL_069f474a6c4f464da9972305e58c72a8"
          }
        },
        "24e09036434943a1bce7ef46550bc5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ffe62ef08a944cfaf3c6fe0fd9c4ce5",
            "placeholder": "​",
            "style": "IPY_MODEL_ca194b931bfa4f8a875f15bad42b0fa3",
            "value": "Downloading readme: 100%"
          }
        },
        "67a2cce9f2404056b681165ac17678a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d020cc432f244c33a97d4eefc9865b68",
            "max": 488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_780bfecb2dac4de786aa086c2af3d81c",
            "value": 488
          }
        },
        "d651c8426f454582a32f3acb37da0a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_528bce053b854342b240faafa39b2cc7",
            "placeholder": "​",
            "style": "IPY_MODEL_1a53607085ee488caf12759c72a461ff",
            "value": " 488/488 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "069f474a6c4f464da9972305e58c72a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffe62ef08a944cfaf3c6fe0fd9c4ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca194b931bfa4f8a875f15bad42b0fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d020cc432f244c33a97d4eefc9865b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780bfecb2dac4de786aa086c2af3d81c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "528bce053b854342b240faafa39b2cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a53607085ee488caf12759c72a461ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "200a9c0022b84f65a00e46d83026947b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2a80d6f02be4de7a88a58fe5de9d752",
              "IPY_MODEL_1d8488d7777e4ae1962ee8be12873903",
              "IPY_MODEL_618f705d86a14639976b6709cc290217"
            ],
            "layout": "IPY_MODEL_717505a3082d4dcab5b0f33987a5937e"
          }
        },
        "f2a80d6f02be4de7a88a58fe5de9d752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7908eef16524107a7e86cc81e91059e",
            "placeholder": "​",
            "style": "IPY_MODEL_85dccac58992488585353f8d041d514a",
            "value": "Downloading metadata: 100%"
          }
        },
        "1d8488d7777e4ae1962ee8be12873903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90b51900386436295455f234fbced72",
            "max": 1198,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7082e615a8844a38925e855f99683ec",
            "value": 1198
          }
        },
        "618f705d86a14639976b6709cc290217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d57c838ae6a435bbe0438bf68e5e6ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6d8a520ea349445cb9204396b11693fc",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 55.1kB/s]"
          }
        },
        "717505a3082d4dcab5b0f33987a5937e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7908eef16524107a7e86cc81e91059e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85dccac58992488585353f8d041d514a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e90b51900386436295455f234fbced72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7082e615a8844a38925e855f99683ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d57c838ae6a435bbe0438bf68e5e6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8a520ea349445cb9204396b11693fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfe8a82fffee4e23ba904d825078528c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8582f481238f44a2b8e0eef31a32bae6",
              "IPY_MODEL_13ce480e479f40c2818c42246458950f",
              "IPY_MODEL_48f06e02aed645cf9867835ac2ec3b94"
            ],
            "layout": "IPY_MODEL_e990bc95b57c4d6fb4ec5cd6a323d86c"
          }
        },
        "8582f481238f44a2b8e0eef31a32bae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f559109a6d0f4ab3bee2f4e8b8416627",
            "placeholder": "​",
            "style": "IPY_MODEL_98128518f73f45b4903d4c63f071b304",
            "value": "Downloading readme: 100%"
          }
        },
        "13ce480e479f40c2818c42246458950f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1aac8c47fd4625b70e0fb489778ad4",
            "max": 2596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1badb046f624314ab85ab3d89c10815",
            "value": 2596
          }
        },
        "48f06e02aed645cf9867835ac2ec3b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b68d260c4f48809fc0f747a1fe365e",
            "placeholder": "​",
            "style": "IPY_MODEL_ed966cab67a84ea789d607f86620b17e",
            "value": " 2.60k/2.60k [00:00&lt;00:00, 84.0kB/s]"
          }
        },
        "e990bc95b57c4d6fb4ec5cd6a323d86c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f559109a6d0f4ab3bee2f4e8b8416627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98128518f73f45b4903d4c63f071b304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b1aac8c47fd4625b70e0fb489778ad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1badb046f624314ab85ab3d89c10815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66b68d260c4f48809fc0f747a1fe365e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed966cab67a84ea789d607f86620b17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cb3a81901894e7f82870d74ddb55da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f21c95352d84be18e7631e0052c59a2",
              "IPY_MODEL_ecf69f2a875e4d98a18cad2f42bf5db8",
              "IPY_MODEL_76f8a367981f4eeea2b495d04e47dec8"
            ],
            "layout": "IPY_MODEL_a4f81bc6e3db4967a47e29bf03b67a02"
          }
        },
        "1f21c95352d84be18e7631e0052c59a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36805fe4947441d9d63a417e54b7d22",
            "placeholder": "​",
            "style": "IPY_MODEL_5d7f7c36954d4e8f986a0accb5b9396e",
            "value": "Downloading builder script: 100%"
          }
        },
        "ecf69f2a875e4d98a18cad2f42bf5db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d6faf821044a72842bbc436aa8b09e",
            "max": 4311,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7769b11c7e94a3281ee10e9f39e8024",
            "value": 4311
          }
        },
        "76f8a367981f4eeea2b495d04e47dec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaf3cc4af5c949d9bf46aae7daf1009a",
            "placeholder": "​",
            "style": "IPY_MODEL_3249bf189c2d465e8f0ea6c2afdb59d7",
            "value": " 4.31k/4.31k [00:00&lt;00:00, 204kB/s]"
          }
        },
        "a4f81bc6e3db4967a47e29bf03b67a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36805fe4947441d9d63a417e54b7d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7f7c36954d4e8f986a0accb5b9396e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08d6faf821044a72842bbc436aa8b09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7769b11c7e94a3281ee10e9f39e8024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaf3cc4af5c949d9bf46aae7daf1009a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3249bf189c2d465e8f0ea6c2afdb59d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2443766ea4b74d13b94486abeee250f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f5e250391cf44f49274098a70d35567",
              "IPY_MODEL_3487dc3b86664dfb8bb1fc0e2b84c11d",
              "IPY_MODEL_cb53243191084bae8f9a4ef972a7b3b7"
            ],
            "layout": "IPY_MODEL_dcd78d7361fb4b22bdc1be87c291df0e"
          }
        },
        "8f5e250391cf44f49274098a70d35567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8772173f7b142fcb7b7e0908ba6f12c",
            "placeholder": "​",
            "style": "IPY_MODEL_b0793cf7a10f4f10b58cf64d0e7ab0c7",
            "value": "Downloading readme: 100%"
          }
        },
        "3487dc3b86664dfb8bb1fc0e2b84c11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d265b9410fa34feda6509183e7a621f4",
            "max": 12335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474d1c3f82ec4444ae3e7748e0e75425",
            "value": 12335
          }
        },
        "cb53243191084bae8f9a4ef972a7b3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9f60888a214a67bbc783a577bbc492",
            "placeholder": "​",
            "style": "IPY_MODEL_08ae4d41f85d4e1d97ce027ad5bb7920",
            "value": " 12.3k/12.3k [00:00&lt;00:00, 503kB/s]"
          }
        },
        "dcd78d7361fb4b22bdc1be87c291df0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8772173f7b142fcb7b7e0908ba6f12c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0793cf7a10f4f10b58cf64d0e7ab0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d265b9410fa34feda6509183e7a621f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474d1c3f82ec4444ae3e7748e0e75425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce9f60888a214a67bbc783a577bbc492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ae4d41f85d4e1d97ce027ad5bb7920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f72b84448df4eb28a591049f8bb087c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec4e69abb86e46b99f48d91c111dcf31",
              "IPY_MODEL_09a1e9b08eda42a59395451ca0dd28f4",
              "IPY_MODEL_5a06cd8312b047db93988f1adeb3face"
            ],
            "layout": "IPY_MODEL_472bd9d2df9946b7a3fb7293bdeb7439"
          }
        },
        "ec4e69abb86e46b99f48d91c111dcf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c4a53e9dea2405f8ee219138db63cea",
            "placeholder": "​",
            "style": "IPY_MODEL_a358ef20b2874bcfb8a5e103b2a66776",
            "value": "Downloading readme: 100%"
          }
        },
        "09a1e9b08eda42a59395451ca0dd28f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9a8885756c4e08b003e8e2bc3d6498",
            "max": 4246,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30bb71ba18904f628908b5ee5e2e5449",
            "value": 4246
          }
        },
        "5a06cd8312b047db93988f1adeb3face": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e536b2f5ad84aa3bb43fe5f62ac294e",
            "placeholder": "​",
            "style": "IPY_MODEL_dda8a43130d142a582df5141c4c5a5de",
            "value": " 4.25k/4.25k [00:00&lt;00:00, 155kB/s]"
          }
        },
        "472bd9d2df9946b7a3fb7293bdeb7439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4a53e9dea2405f8ee219138db63cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a358ef20b2874bcfb8a5e103b2a66776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f9a8885756c4e08b003e8e2bc3d6498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30bb71ba18904f628908b5ee5e2e5449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e536b2f5ad84aa3bb43fe5f62ac294e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda8a43130d142a582df5141c4c5a5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9434269dd2934fe69b952e54f030bc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72038bf8a3cc481099de6c3f447e1b69",
              "IPY_MODEL_0485bd9ab4af4809916700c1cdaa6f45",
              "IPY_MODEL_308fcd2c63f845ab9ee763f8244d3bb8"
            ],
            "layout": "IPY_MODEL_49e1b9ceae9a4948b7eb139427b02087"
          }
        },
        "72038bf8a3cc481099de6c3f447e1b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbc6ad6edd04b48b02b5435ccaed987",
            "placeholder": "​",
            "style": "IPY_MODEL_0ee1bdf4892c4b46aee6611c074d2498",
            "value": "Downloading readme: 100%"
          }
        },
        "0485bd9ab4af4809916700c1cdaa6f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0bcaa390871497692127229045408b3",
            "max": 4628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c09b488a64c484cafe81da5df728600",
            "value": 4628
          }
        },
        "308fcd2c63f845ab9ee763f8244d3bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25faac3263c948d29af93d16b771dc6a",
            "placeholder": "​",
            "style": "IPY_MODEL_29493556a8a44d54898b7dd5d31f2f39",
            "value": " 4.63k/4.63k [00:00&lt;00:00, 198kB/s]"
          }
        },
        "49e1b9ceae9a4948b7eb139427b02087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbc6ad6edd04b48b02b5435ccaed987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee1bdf4892c4b46aee6611c074d2498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0bcaa390871497692127229045408b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c09b488a64c484cafe81da5df728600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25faac3263c948d29af93d16b771dc6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29493556a8a44d54898b7dd5d31f2f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087cabed0b364060bf7d072a0e4666ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a98757727be426bb3ab922c560c68a4",
              "IPY_MODEL_cfdd33227b9f4feaa349607e63a7fa21",
              "IPY_MODEL_39a05751596e4dd48d74db3920d03294"
            ],
            "layout": "IPY_MODEL_31ef123f5006445cb367a1437afeb3b8"
          }
        },
        "7a98757727be426bb3ab922c560c68a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23598ee5e6543368976eb061fa0ad4d",
            "placeholder": "​",
            "style": "IPY_MODEL_ab66db253fa24e179c36780a46ad37af",
            "value": "Downloading readme: 100%"
          }
        },
        "cfdd33227b9f4feaa349607e63a7fa21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c706eef058c4dbb9d0ac870752d12ad",
            "max": 1973,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc417ba68cf54f67aae4ff0af7221960",
            "value": 1973
          }
        },
        "39a05751596e4dd48d74db3920d03294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321bcb07ce24410bbfe621e37b8a60ec",
            "placeholder": "​",
            "style": "IPY_MODEL_c653d0ec04c443d385f3ac2739723824",
            "value": " 1.97k/1.97k [00:00&lt;00:00, 104kB/s]"
          }
        },
        "31ef123f5006445cb367a1437afeb3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23598ee5e6543368976eb061fa0ad4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab66db253fa24e179c36780a46ad37af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c706eef058c4dbb9d0ac870752d12ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc417ba68cf54f67aae4ff0af7221960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "321bcb07ce24410bbfe621e37b8a60ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c653d0ec04c443d385f3ac2739723824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a39f9264f89740d2b4087fbbb184019f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25985ae5820443b6bc43ea5f1b0affd1",
              "IPY_MODEL_2a5a7200841a45a1a507f9b1adca18b1",
              "IPY_MODEL_e825483e96574238aabfcd793ff08b5d"
            ],
            "layout": "IPY_MODEL_5f35a5d79c0f4d8cae3800a4573d7c8b"
          }
        },
        "25985ae5820443b6bc43ea5f1b0affd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552e363453ff48e59f58c8df67e4d8e6",
            "placeholder": "​",
            "style": "IPY_MODEL_22928eaf7a034396aabc94de6af991b1",
            "value": "Downloading readme: 100%"
          }
        },
        "2a5a7200841a45a1a507f9b1adca18b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6e0b3bf4be46cf80d47b1303d14703",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd99c4f0bba1468aad56dd501840db01",
            "value": 28
          }
        },
        "e825483e96574238aabfcd793ff08b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a97c29bf89343e4b712ea77aac38726",
            "placeholder": "​",
            "style": "IPY_MODEL_ba205a2067154511bb5739a67b602bc0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.27kB/s]"
          }
        },
        "5f35a5d79c0f4d8cae3800a4573d7c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552e363453ff48e59f58c8df67e4d8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22928eaf7a034396aabc94de6af991b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a6e0b3bf4be46cf80d47b1303d14703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd99c4f0bba1468aad56dd501840db01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a97c29bf89343e4b712ea77aac38726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba205a2067154511bb5739a67b602bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49d66e5bf4fe4bbfa8f0d34af9e57e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec6c762ac89e4c91bf1bfd228976a3a6",
              "IPY_MODEL_b8b3be37b1d94aaaab723c190cb81644",
              "IPY_MODEL_1c8112c1a6804c0384bcb47f8124ef4a"
            ],
            "layout": "IPY_MODEL_ee1eb3b787324a02a4f9eaff02be1d6b"
          }
        },
        "ec6c762ac89e4c91bf1bfd228976a3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37c0585e68142b8aedf3d21f4105d81",
            "placeholder": "​",
            "style": "IPY_MODEL_9e93fa146d4c4800a3b775c952c07b94",
            "value": "Downloading builder script: 100%"
          }
        },
        "b8b3be37b1d94aaaab723c190cb81644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c66057d62c4e979c40065bfb203f7f",
            "max": 19110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_623f8e18e31f4c6c9b82d13588e53640",
            "value": 19110
          }
        },
        "1c8112c1a6804c0384bcb47f8124ef4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d695949d3ca943f18556617cd6e24ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_1989a88e7a5f427c88895c3a50a75ff9",
            "value": " 19.1k/19.1k [00:00&lt;00:00, 986kB/s]"
          }
        },
        "ee1eb3b787324a02a4f9eaff02be1d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d37c0585e68142b8aedf3d21f4105d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e93fa146d4c4800a3b775c952c07b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5c66057d62c4e979c40065bfb203f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623f8e18e31f4c6c9b82d13588e53640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d695949d3ca943f18556617cd6e24ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1989a88e7a5f427c88895c3a50a75ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9d69a9bcd2f4eaf8eea31db00e3331d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b48b8103cc48422da880bed80c4b5844",
              "IPY_MODEL_43484f23ef104b73b156453d3c8b48b2",
              "IPY_MODEL_8a6827861c3044e0b8875c104f0c3f7d"
            ],
            "layout": "IPY_MODEL_49b35a44d15d4ec7bbbc20915689baa1"
          }
        },
        "b48b8103cc48422da880bed80c4b5844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d9e1027d9343a3a81dd6441080d514",
            "placeholder": "​",
            "style": "IPY_MODEL_cf98b06559384d88b559c4702798c42d",
            "value": "Downloading metadata: 100%"
          }
        },
        "43484f23ef104b73b156453d3c8b48b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a9880cdb8264ba8a53e16f80ef76fce",
            "max": 15860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f030abf2c75b45c4ab99848b0e6e52bb",
            "value": 15860
          }
        },
        "8a6827861c3044e0b8875c104f0c3f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bf315cbf5bf4650ac975ad38cc7c63f",
            "placeholder": "​",
            "style": "IPY_MODEL_441bce894af6474799b5151fd0dc0290",
            "value": " 15.9k/15.9k [00:00&lt;00:00, 873kB/s]"
          }
        },
        "49b35a44d15d4ec7bbbc20915689baa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d9e1027d9343a3a81dd6441080d514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf98b06559384d88b559c4702798c42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a9880cdb8264ba8a53e16f80ef76fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f030abf2c75b45c4ab99848b0e6e52bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bf315cbf5bf4650ac975ad38cc7c63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "441bce894af6474799b5151fd0dc0290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2d393d146434ccba6141c4de3177670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3af39c16fe4d46828afb28e16bfc3343",
              "IPY_MODEL_b56beaf76c474f0f8e7a6a774d6ff5b1",
              "IPY_MODEL_e6f48556674c4bb4bd08cd2a206b792c"
            ],
            "layout": "IPY_MODEL_b2eb3d7f0b934382b45e3424bd74326c"
          }
        },
        "3af39c16fe4d46828afb28e16bfc3343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_441bb0efdd77486ba5056c07435e9038",
            "placeholder": "​",
            "style": "IPY_MODEL_259472e0b6b4432bb37fc036b9860eec",
            "value": "Downloading readme: 100%"
          }
        },
        "b56beaf76c474f0f8e7a6a774d6ff5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_277ef151fbcd4f72b0083ef50ff7556d",
            "max": 9553,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8e54f24dc854c8a9d5cf54b4f7eaccf",
            "value": 9553
          }
        },
        "e6f48556674c4bb4bd08cd2a206b792c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f85dc1c0ad9942f38e3d9c8a10c5921b",
            "placeholder": "​",
            "style": "IPY_MODEL_586a901aeb7846dc8012f962eba33dde",
            "value": " 9.55k/9.55k [00:00&lt;00:00, 475kB/s]"
          }
        },
        "b2eb3d7f0b934382b45e3424bd74326c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "441bb0efdd77486ba5056c07435e9038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259472e0b6b4432bb37fc036b9860eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "277ef151fbcd4f72b0083ef50ff7556d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e54f24dc854c8a9d5cf54b4f7eaccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f85dc1c0ad9942f38e3d9c8a10c5921b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586a901aeb7846dc8012f962eba33dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa681087d04342db816bf7871e46dcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_937c333aeb1e459c83369464f7d52157",
              "IPY_MODEL_979c6a06e2364605ab52a60ca0805bbc",
              "IPY_MODEL_496fe7d431e54dd7b221eeb1cbf5445f"
            ],
            "layout": "IPY_MODEL_c2ecf01731ba4f9fb4ef9b2bc10eac0f"
          }
        },
        "937c333aeb1e459c83369464f7d52157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aafe0c198644ab5905926a2bc2cffd3",
            "placeholder": "​",
            "style": "IPY_MODEL_3ee86ab306a54dfcb11907386b2804a3",
            "value": "Downloading builder script: 100%"
          }
        },
        "979c6a06e2364605ab52a60ca0805bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c24fe2e0a174981ac838a00e15f0742",
            "max": 5274,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02eba717388548bb84467b89b298cbdd",
            "value": 5274
          }
        },
        "496fe7d431e54dd7b221eeb1cbf5445f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13fc6b3e48374cfe85ea43e9588cd179",
            "placeholder": "​",
            "style": "IPY_MODEL_e980fc0205024032ae0c73eb41373de0",
            "value": " 5.27k/5.27k [00:00&lt;00:00, 199kB/s]"
          }
        },
        "c2ecf01731ba4f9fb4ef9b2bc10eac0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aafe0c198644ab5905926a2bc2cffd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee86ab306a54dfcb11907386b2804a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c24fe2e0a174981ac838a00e15f0742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02eba717388548bb84467b89b298cbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13fc6b3e48374cfe85ea43e9588cd179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e980fc0205024032ae0c73eb41373de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ea2c4aaab7448f89606660d35f561a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00783993887e41309e4ac21b9042b090",
              "IPY_MODEL_7bc19bbd312944b28fc2f7e2dc94a939",
              "IPY_MODEL_4ca0016c8aec4a898737d0980e37b732"
            ],
            "layout": "IPY_MODEL_078ccbed975b4c3195458a5366c62147"
          }
        },
        "00783993887e41309e4ac21b9042b090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9639a03dc49042368a0368fe42ac6bed",
            "placeholder": "​",
            "style": "IPY_MODEL_382b0231b7c749e2854e8fe3b38fc6b0",
            "value": "Downloading metadata: 100%"
          }
        },
        "7bc19bbd312944b28fc2f7e2dc94a939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c90a1a3791478dad529a7e86607931",
            "max": 2360,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3da7757910f543188bfe2b23a232e57b",
            "value": 2360
          }
        },
        "4ca0016c8aec4a898737d0980e37b732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c301024c62974346a719abb16cf59a55",
            "placeholder": "​",
            "style": "IPY_MODEL_033dfd6abf1a47a09e856595cdb40294",
            "value": " 2.36k/2.36k [00:00&lt;00:00, 118kB/s]"
          }
        },
        "078ccbed975b4c3195458a5366c62147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9639a03dc49042368a0368fe42ac6bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382b0231b7c749e2854e8fe3b38fc6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3c90a1a3791478dad529a7e86607931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da7757910f543188bfe2b23a232e57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c301024c62974346a719abb16cf59a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033dfd6abf1a47a09e856595cdb40294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e27d08cc8224206b0f86bbc81c0a167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db16132e0c904763a0afa0353a112fe4",
              "IPY_MODEL_e884470ccded4f91b299d2c212b2badc",
              "IPY_MODEL_f933fc623fdf44ba9ad91402ad00c45e"
            ],
            "layout": "IPY_MODEL_8d4884fec41949bcaa91e2b857e3e17c"
          }
        },
        "db16132e0c904763a0afa0353a112fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef3789139f743f3b2d271a57be8c969",
            "placeholder": "​",
            "style": "IPY_MODEL_12c2d06cd75a4d3eb7dc70cdb12e78a7",
            "value": "Downloading readme: 100%"
          }
        },
        "e884470ccded4f91b299d2c212b2badc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a020b971470409a87de9cda980368eb",
            "max": 7665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef62d5973471498b9d3609df1752f341",
            "value": 7665
          }
        },
        "f933fc623fdf44ba9ad91402ad00c45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551f253f04f5441cac92f4654cbf350a",
            "placeholder": "​",
            "style": "IPY_MODEL_6f560e5e02ad4272b5024c31ece49c8b",
            "value": " 7.67k/7.67k [00:00&lt;00:00, 431kB/s]"
          }
        },
        "8d4884fec41949bcaa91e2b857e3e17c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef3789139f743f3b2d271a57be8c969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c2d06cd75a4d3eb7dc70cdb12e78a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a020b971470409a87de9cda980368eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef62d5973471498b9d3609df1752f341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "551f253f04f5441cac92f4654cbf350a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f560e5e02ad4272b5024c31ece49c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2449243b56243e7bd3ae7bc2f4cde37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0bbdac5a518428283b9c2f0223bddb3",
              "IPY_MODEL_93789c8e4ab44608b55cac224abed8e5",
              "IPY_MODEL_d331b857fa504df4b1a56f99b7222951"
            ],
            "layout": "IPY_MODEL_de5d1956052149d4bcefef91833fe10c"
          }
        },
        "a0bbdac5a518428283b9c2f0223bddb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b99fcd896fb9447d9534df2b6572928f",
            "placeholder": "​",
            "style": "IPY_MODEL_4daaf8c90a9c49978feada1ebcdee2c1",
            "value": "Downloading readme: 100%"
          }
        },
        "93789c8e4ab44608b55cac224abed8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa166da33fa04214a7c7bc278a1bc4be",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fd20cd579e14f8b96285c9b1bbd127c",
            "value": 70
          }
        },
        "d331b857fa504df4b1a56f99b7222951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e3eff2eb8743f994b861ec9298ce9c",
            "placeholder": "​",
            "style": "IPY_MODEL_aae110daa26844dc9c4f7d10c6135f62",
            "value": " 70.0/70.0 [00:00&lt;00:00, 4.07kB/s]"
          }
        },
        "de5d1956052149d4bcefef91833fe10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b99fcd896fb9447d9534df2b6572928f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4daaf8c90a9c49978feada1ebcdee2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa166da33fa04214a7c7bc278a1bc4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd20cd579e14f8b96285c9b1bbd127c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17e3eff2eb8743f994b861ec9298ce9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae110daa26844dc9c4f7d10c6135f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b74c9d9355a4bf19152b5a41e999a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51c692ed7f424f45bbd154d6f1c1d441",
              "IPY_MODEL_6e28dffef1ff4c1395925437671013c3",
              "IPY_MODEL_13da363a292a4cec9f59866445718e5f"
            ],
            "layout": "IPY_MODEL_bb7dab0e54af4529b2d55eca3fbe295b"
          }
        },
        "51c692ed7f424f45bbd154d6f1c1d441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98bc5ce28f784993b69620d3dc36bd6b",
            "placeholder": "​",
            "style": "IPY_MODEL_76cca9cc9a924d9589ec9f8da8b522ed",
            "value": "Downloading readme: 100%"
          }
        },
        "6e28dffef1ff4c1395925437671013c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa8573d5c6644988020545a3de1c7e9",
            "max": 473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b40873939bcf49d6b2a787162892838c",
            "value": 473
          }
        },
        "13da363a292a4cec9f59866445718e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bbb2edd7eee420b9a8ae487ba7a0679",
            "placeholder": "​",
            "style": "IPY_MODEL_97f685ef70ca4b0ebd07d08ac8ef63dc",
            "value": " 473/473 [00:00&lt;00:00, 25.2kB/s]"
          }
        },
        "bb7dab0e54af4529b2d55eca3fbe295b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bc5ce28f784993b69620d3dc36bd6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76cca9cc9a924d9589ec9f8da8b522ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aa8573d5c6644988020545a3de1c7e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40873939bcf49d6b2a787162892838c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bbb2edd7eee420b9a8ae487ba7a0679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f685ef70ca4b0ebd07d08ac8ef63dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28bdf044d9024408a8b4a6f3cc505748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34a8cfafe1bc4238a2a116174db03e1e",
              "IPY_MODEL_c7604f7b41634f399d7fd9679d60249d",
              "IPY_MODEL_80c60ec5370b43f6af463b423b2347ad"
            ],
            "layout": "IPY_MODEL_fcc30c1acb1c4a56bbc8073ad62ebb28"
          }
        },
        "34a8cfafe1bc4238a2a116174db03e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f51615acde94be09f55514e093cf519",
            "placeholder": "​",
            "style": "IPY_MODEL_75f170ac22714d0e99a7352ded1e1883",
            "value": "Downloading builder script: 100%"
          }
        },
        "c7604f7b41634f399d7fd9679d60249d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e249071708804c639b98995cbb41b87a",
            "max": 13349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3362036276142d0af7b51e1063a27ad",
            "value": 13349
          }
        },
        "80c60ec5370b43f6af463b423b2347ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_488b10e044734b6caae8592d3ca26175",
            "placeholder": "​",
            "style": "IPY_MODEL_f1290a1555b84986a0844537c8d12fb7",
            "value": " 13.3k/13.3k [00:00&lt;00:00, 588kB/s]"
          }
        },
        "fcc30c1acb1c4a56bbc8073ad62ebb28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f51615acde94be09f55514e093cf519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f170ac22714d0e99a7352ded1e1883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e249071708804c639b98995cbb41b87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3362036276142d0af7b51e1063a27ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "488b10e044734b6caae8592d3ca26175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1290a1555b84986a0844537c8d12fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "181c013896b2460b93dc1448412aa33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de026e05560e4479b03704360b9b0a7f",
              "IPY_MODEL_fec2aac9e79e41ee8666b5d9e5249a9f",
              "IPY_MODEL_123672337d6a49fa9c22b12fa2d4cddf"
            ],
            "layout": "IPY_MODEL_b482a226af9f4732aee7949a906c033c"
          }
        },
        "de026e05560e4479b03704360b9b0a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207580ca79744d03ae025e5978364a49",
            "placeholder": "​",
            "style": "IPY_MODEL_94e74ba60c864870b85a63df3fed3795",
            "value": "Downloading readme: 100%"
          }
        },
        "fec2aac9e79e41ee8666b5d9e5249a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0230611a6242d68e7fd06ebf8f7e3a",
            "max": 8162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab7968a49db04ce0afbcc0df78c9db41",
            "value": 8162
          }
        },
        "123672337d6a49fa9c22b12fa2d4cddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ef3f004b2f4ff89c21d2b44cca05fa",
            "placeholder": "​",
            "style": "IPY_MODEL_a4cd2c94997947a892a656afc0526b04",
            "value": " 8.16k/8.16k [00:00&lt;00:00, 405kB/s]"
          }
        },
        "b482a226af9f4732aee7949a906c033c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207580ca79744d03ae025e5978364a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e74ba60c864870b85a63df3fed3795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd0230611a6242d68e7fd06ebf8f7e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7968a49db04ce0afbcc0df78c9db41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93ef3f004b2f4ff89c21d2b44cca05fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cd2c94997947a892a656afc0526b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}