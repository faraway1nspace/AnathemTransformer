{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faraway1nspace/AnathemTransformer/blob/main/dev/notebooks/dev_anathem_transformer_base_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcFatBIhzdu"
      },
      "source": [
        "## Development Notebook: build and test base layers for Anathem Transformer (aka Silo'd Transformer)\n",
        "\n",
        "### Notes\n",
        "- the google-minature models have the same vocab size and heads as bert-large-ucased\n",
        "- the minature-google papers discusses the classification and distallation tasks & corpus's including:\n",
        "    - *NLI* (Natural language inference involves classifying pairs of sentences (a premise and a hypothesis) as entailment, contradiction, or neutral. This task is representative of the scenario in which proxy data is non-trivial to gather (Gururangan et al., 2018). We chose MNLI (Williams et al., 2018) as our target dataset. Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "    - *sentiment analysis* -\n",
        "- the MTEB leader best model is e5-large (24 layers) which uses the CLS token. It is also \"instruction fine-tuned\", requiring query and passage prefixes.\n",
        "- distillation example: https://github.com/philschmid/knowledge-distillation-transformers-pytorch-sagemaker/blob/master/knowledge-distillation.ipynb\n",
        "    - they set temperature to 2: which results in a flatter probability distribution. I could make this dynamic -> start 0.5 progress to 1\n",
        "    - they set alpha to 0.5, which balances label-loss vs distil-loss\n",
        "\n",
        "#### Loss MLM - hf example:\n",
        "- https://github.com/huggingface/transformers/blob/601ac5b1dc1438f00d09696588f2deb0f045ae3b/src/transformers/modeling_bert.py#L1001-L1004\n",
        "    - notice that when initializing CrossEntropyLoss, the ignore index is -100, so, when I make the masked-token objective, I can compute the loss by masking out all -100?\n",
        "\n",
        "\n",
        "#### DataCollator for Masked MLM - hf example\n",
        "- https://github.com/huggingface/transformers/blob/ee88ae59940fd4b2c8fc119373143d7a1175c651/src/transformers/data/data_collator.py#L607\n",
        "\n",
        "\n",
        "# Dataset specifics\n",
        "\n",
        "### From the Google mini-architectures:\n",
        "- with labels: Williams 2018 (NLI-task): citation: https://aclanthology.org/N18-1101/; available at https://huggingface.co/datasets/multi_nli  \n",
        "    - how should I process these? [sep] or sentence pairs? or both?\n",
        "    - I could do sentence-pairs for teaching & labels, I guess (why not)\n",
        "    - I could also include concatenated text, stricly with labels (what would be the point of this though? Better sub-sectioning the input data, not so much a sentence-vector thing\n",
        "- with no-labels, used for teaching: Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "\n",
        "### 1) MLM Tasks\n",
        "- Pile (multi-domain, books, wiki, law, and more) - curate and remove twitter  \n",
        "    - see urls at: https://github.com/EleutherAI/the-pile/blob/master/the_pile/datasets.py\n",
        "    - https://the-eye.eu/public/AI/pile_preliminary_components/\n",
        "- Supplements to pile:  \n",
        "    - https://huggingface.co/datasets/him1411/EDGAR10-Q - numeric filings\n",
        "    - eloukas/edgar-corpus - annual reports (but it is in weird sections)\n",
        "    - LEDGAR .jsonl https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A - this can be streamed too\n",
        "    - Pile of Law - https://huggingface.co/datasets/pile-of-law/pile-of-law - but cannot be streamed\n",
        "- JanosAudran/financial-reports-sec - SEC financial reports in small sentences\n",
        "- RefinedWeb - a competitor to Pile, curated common-crawl - https://arxiv.org/abs/2306.01116\n",
        "- CNN_dailymail? ag_news?\n",
        "\n",
        "### A) Retrieval Tasks\n",
        "In general, what loss would I use for the QA & retrieval tasks? Distillation is obvious, but what about\n",
        "- SQUAD - has QA pairs - squad_v2\n",
        "    - good for distillation\n",
        "- ORCA - has GPT-like prompting QA pairs: https://huggingface.co/datasets/Open-Orca/OpenOrca/viewer/Open-Orca--OpenOrca/train?row=29\n",
        "- Simple-Wiki https://huggingface.co/datasets/embedding-data/simple-wiki - has paraphrases\n",
        "- embedding-data/coco_captions_quintets - multiple captions as paraphrases\n",
        "- embedding-data/simple-wiki - pairs of paraphrases from wikipedia\n",
        "- embedding-data/SPECTER - triplets of {anchor, pos, neg}, small headline-like snippets in technical /statistical /science fields\n",
        "- https://huggingface.co/embedding-data - has a lot of retrieval tasks\n",
        "- LLukas22/scidocs - titles and abstracts\n",
        "- LEDGAR - can possible do triplets on same label\n",
        "- Rahmaa/ElsevieR_ClEaN - possible relation between title and abstract\n",
        "- embedding-data/WikiAnswers - 25 question paraphrases (maybe no answers)\n",
        "\n",
        "### B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- LLukas22/lfqa_preprocessed - question and answers 226k\n",
        "- gbharti/finance-alpaca (like FIQA - finance Q&A)\n",
        "- embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- sciq - science questions - see question and support\n",
        "- wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers\n",
        "\n",
        "# Teacher Models\n",
        "\n",
        "## Embeddings\n",
        "Mteb leaderboard\n",
        "\n",
        "- instructor-xl / large - this does best, but it prepends instructions that are domain specific (like science this, or wikipedia that.... it could be possible to do that with the Pile dataset, possible) https://huggingface.co/hkunlp/instructor-xl\n",
        "- https://huggingface.co/intfloat/e5-large-v2 - winner otherwise\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6mZMauZ9KW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XS2jBKoMmMn"
      },
      "source": [
        "#### Playing Around with novel architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQy_iTw-1g8O",
        "outputId": "9d600274-b3cf-4065-bd6e-2439901bce80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 huggingface-hub-0.16.4 multiprocess-0.70.14 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897,
          "referenced_widgets": [
            "39b9b4412ee54145aa8f08501c482d3f",
            "5afcf9de549f4903988f816da0784c00",
            "af678d1c5903451f8b1c1f29b82c273f",
            "9b95627c2d0a43399ac929b330a0d46b",
            "b48bbd953c50443ca2e4b3681909dd94",
            "515c53eaeaeb4b90a9e7f0987aa8e295",
            "c5fae6b0606d485989a18194ab3a7827",
            "129cece6d8ff4bd9b0137be0486c23e2",
            "cb3e6c6677af4a15b4230a59de58c8fc",
            "cb83a4e946fb4c78b556a06784f8b2c0",
            "85cfc6e8aa8b4da4b7f487576e2d728a",
            "63f3c83e61b94b4db567e1ffb7057472",
            "4009b3c800c3490f98756696c133ed71",
            "3442f76ad9514478ab0e4a4b823dd68c",
            "9d936d10a67845f1baaf6bd502cfe51e",
            "afc1126d123d40018c1bbf4a8d32ade9",
            "93eed229a52c4ce8913649160c213212",
            "d9bc4736e2dd45d2963cad4ee1700641",
            "d2f75d5c8f4645b69028fca44c3505e6",
            "a96578d913114e78baf1950b0d7cd998",
            "735872b51d5a4042b1019254a2ada269",
            "5bb2391eeae9434fa3f11ffd1355ca6f",
            "18e3330d7fb94a7eba4bac113a03f5b2",
            "7b0b2d2e592742499214c71c17ea64d4",
            "a1d9e240e0064e94a841aab7ffa1f29f",
            "c914b0150b114044baff3381de264c3f",
            "6e53455a57dc45ac9afae3837147af06",
            "df984168f38140c09a952126a0822347",
            "2c5569a7006f4b87a645d6b8af39158b",
            "b789d00f1b274a09b7658456e8019df9",
            "c0c1ad987d1940f8af9048e533e62434",
            "596c6eda354b45bfa8e02c8359133217",
            "b645b146bc464646a8eca1b190322cd2"
          ]
        },
        "id": "bCv855u5Mlgr",
        "outputId": "7dcdc4b4-c04b-40cd-eb93-6b11fd2b1c9d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39b9b4412ee54145aa8f08501c482d3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63f3c83e61b94b4db567e1ffb7057472",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18e3330d7fb94a7eba4bac113a03f5b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/217M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 512)\n",
              "    (token_type_embeddings): Embedding(2, 512)\n",
              "    (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, DataSet\n",
        "from typing import List, Optional\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "\n",
        "model_string = 'google/bert_uncased_L-12_H-512_A-8' # 'distilroberta-base\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "basemod = AutoModel.from_pretrained(model_string)\n",
        "basemod.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tNKrJaiXDvA"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "eNfU7szJWwfh",
        "outputId": "afd7de82-dcac-45b0-f9a1-4b874b1f529b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-761fa45d06d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomTokenizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google/bert_uncased_L-12_H-512_A-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cls_prepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, model_string='google/bert_uncased_L-12_H-512_A-8', n_cls_prepend = 4, n_pad_to_multiple_of=4):\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not (k[0]=='_' or k=='tokenize' or k=='encode' or k=='build_inputs_with_special_tokens' or k == 'batch_encode_plus'):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "\n",
        "        # run through base tokenizer\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens, return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        #batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "\n",
        "\n",
        "# Note, if I use the vanilla LineByLineTextDataset, it just calls tokenizer.__call__ turns on the `use_special_tokens`, and it pads to a multiple of optional\n",
        "# .. so somehow I need to ensure that, whatever base function it calls as part of the tokenizer pipeline, it will continue using MY new function\n",
        "# the tokenizer.__call__ DOES NOT use `encode` nor `tokenize` otherwise my modifications would manifest\n",
        "# looks like `prepare_for_model` (and maybe `batch_prepare_for_model`) is what adds special tokens?\n",
        "# looks like `prepare_for_model` just calls `build_inputs_with_special_tokens`, so maybe intervene there?\n",
        "#         if add_special_tokens:\n",
        "#            sequence = self.build_inputs_with_special_tokens(ids, pair_ids)\n",
        "#            token_type_ids = self.create_token_type_ids_from_sequences(ids, pair_ids)\n",
        "# editing `build_inputs_with_special_tokens` didn't work either\n",
        "\n",
        "# FOOFU:\n",
        "# see how .pad works: https://github.com/huggingface/transformers/blob/c5454eba9eac00a3e7d0a46a3d25aacd43187f1e/src/transformers/tokenization_utils_base.py#L2887\n",
        "# notice the `self.model_input_names[0]` list for a tokenizer -> I should update this for my unique inputs\n",
        "# ... and there is also a ._pad function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te7PvCnbvX-E"
      },
      "outputs": [],
      "source": [
        "tokenizer2 = CustomTokenizer()\n",
        "tokenizer2.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjHCfFlda8w"
      },
      "outputs": [],
      "source": [
        "#toks = tokenizer2.encode(text[0], add_special_tokens=True)\n",
        "#print(len(toks)) # works\n",
        "#print(toks[:10])\n",
        "\n",
        "tokens = tokenizer2(text, padding='longest', return_tensors=None) # doesn't work, obviously\n",
        "#print(tokens)\n",
        "print(len(tokens['input_ids'][0]))\n",
        "print(len(tokens['attention_mask'][0]))\n",
        "\n",
        "print(len(tokens['input_ids'][1]))\n",
        "print(len(tokens['attention_mask'][1]))\n",
        "\n",
        "tokens\n",
        "\n",
        "#tokenizer2.batch_encode_plus(text, add_special_tokens=True) # doesn't work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo5BhFq0kuJH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DToaqxfoM6bR"
      },
      "outputs": [],
      "source": [
        "dir(basemod)\n",
        "# base embedding layers\n",
        "layer_emb = copy.deepcopy(basemod._modules['embeddings'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha_xqtWlNIfI"
      },
      "outputs": [],
      "source": [
        "# base trasnformers (full)\n",
        "layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9OMlauFNTPZ"
      },
      "outputs": [],
      "source": [
        "# text\n",
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with legal issues1.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, willful misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "import math\n",
        "\n",
        "#padding_length = int(math.ceil(max_length / 4)) * 4\n",
        "tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "input_shape = tokens['input_ids'].size()\n",
        "\n",
        "# change token padding to be multiple of 4\n",
        "#ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "#if input_shape[-1]!=ideal_length:\n",
        "#  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "#  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "tokens['token_type_ids'] = token_type_ids\n",
        "past_key_values_length =0\n",
        "\n",
        "# need to extend attention mask\n",
        "extended_attention_mask = basemod.get_extended_attention_mask(tokens['attention_mask'], input_shape)\n",
        "tokens['extended_attention_mask'] = extended_attention_mask\n",
        "print(tokens.keys())\n",
        "print(tokens['input_ids'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4DF2F2y3WVs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIisgmAC3SgY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_PXX-SRjd7Mv",
        "outputId": "9be41735-2875-4ac5-ee8e-d0be3fbf3a2b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c65df7c427ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m silo_dimensions = {0:basemod.config.hidden_size,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   }\n\u001b[1;32m      5\u001b[0m \u001b[0mreintegration_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'basemod' is not defined"
          ]
        }
      ],
      "source": [
        "silo_dimensions = {0:basemod.config.hidden_size,\n",
        "                  1:basemod.config.hidden_size//2,\n",
        "                  2:basemod.config.hidden_size//4,\n",
        "                  }\n",
        "reintegration_dim = silo_dimensions[1] + silo_dimensions[2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XuMY6iaRNpOc",
        "outputId": "a9e272e9-2e80-4b29-dc62-536f42bd1334"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-40b0ed09dca5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_output = layer_emb(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'position_ids'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_emb' is not defined"
          ]
        }
      ],
      "source": [
        "embedding_output = layer_emb(\n",
        "            input_ids=tokens['input_ids'],\n",
        "            position_ids=tokens.get('position_ids',None),\n",
        "            token_type_ids=tokens['token_type_ids'],\n",
        "            inputs_embeds=None,\n",
        "            past_key_values_length=past_key_values_length\n",
        ")\n",
        "print(embedding_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3kgUzTJsO_1i",
        "outputId": "5d16b103-4d99-40de-8c0c-039faefd0e64"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-40a2b2d12b51>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# basemodel transformer outputs: *full bert model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m out_l1 = layer_basetransformer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extended_attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#tokens['attention_mask'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_basetransformer' is not defined"
          ]
        }
      ],
      "source": [
        "# basemodel transformer outputs: *full bert model\n",
        "out_l1 = layer_basetransformer(\n",
        "    hidden_states = embedding_output,\n",
        "    attention_mask = tokens['extended_attention_mask'],#tokens['attention_mask'],\n",
        "    head_mask=None,\n",
        "    encoder_hidden_states=None,\n",
        "    encoder_attention_mask=None,\n",
        "    #past_key_values=0,\n",
        "    #use_cache=None,\n",
        "    output_attentions=True,\n",
        "    #output_hidden_states=True,\n",
        "    #return_dict=True\n",
        ")\n",
        "\n",
        "hidden_states_l1 = out_l1[0]\n",
        "self_attention_l1 = out_l1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvj_XlNsTYXt"
      },
      "outputs": [],
      "source": [
        "# Next Layer:\n",
        "# Query -> max pool and reduce  hidden dimension // 2\n",
        "# Key -> reduce hidden_dim // 2\n",
        "# value -> reduce hidden_dim //2\n",
        "#maxpool_l2 = nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "maxpool_l2 = nn.Sequential(\n",
        "    nn.Dropout(0.05),\n",
        "    nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True),\n",
        ")\n",
        "\n",
        "maxpool_l2_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ5xAaELVuwk",
        "outputId": "b5dbf2f4-277d-4b55-97ac-0453fed2908d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n",
            "torch.Size([2, 24, 768])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 48])\n",
            "torch.Size([2, 1, 1, 48])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "# reduce dimension of hidden states\n",
        "hiddens_states_l1_reduced = maxpool_l2(hidden_states_l1)\n",
        "print(hidden_states_l1.shape)\n",
        "print(hiddens_states_l1_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l1_reduced = maxpool_l2_attn(tokens['attention_mask'].float())\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "print(input_shape)\n",
        "extended_attention_mask_l1_reduced = basemod.get_extended_attention_mask(attention_mask_l1_reduced, attention_mask_l1_reduced.shape)\n",
        "print(tokens['extended_attention_mask'].shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AcdIY3shHWN"
      },
      "outputs": [],
      "source": [
        "# Try to do Multi Headed attenion with differently sized query and value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYHtEQNFgh7U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "import copy\n",
        "\n",
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "bertlayer_l2_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")\n",
        "\n",
        "bertlayer_l3_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size // 2,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03mPp6aHgh9Y",
        "outputId": "e19aaf75-0247-498f-d967-2777f6f6df2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2 = bertlayer_l2_reduction(\n",
        "        hidden_states = hiddens_states_l1_reduced,\n",
        "        attention_mask = extended_attention_mask_l1_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l1,\n",
        "        encoder_attention_mask= tokens['extended_attention_mask'],\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "hidden_states_l2 = out_l2[0]\n",
        "print(hidden_states_l2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlN5aOsYgh_z",
        "outputId": "29b499c5-25ab-4dfb-de8e-ffc76c316e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12])\n",
            "torch.Size([2, 1, 1, 12])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Next dimension reduction:\n",
        "hiddens_states_l2_reduced = maxpool_l2(hidden_states_l2)\n",
        "print(hidden_states_l2.shape)\n",
        "print(hiddens_states_l2_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l2_reduced = maxpool_l2_attn(attention_mask_l1_reduced.float())\n",
        "print(attention_mask_l2_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "extended_attention_mask_l2_reduced = basemod.get_extended_attention_mask(attention_mask_l2_reduced, attention_mask_l2_reduced.shape)\n",
        "print(extended_attention_mask_l2_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  out_l3 = bertlayer_l3_reduction(\n",
        "        hidden_states = hiddens_states_l2_reduced, # input has been maxpooled\n",
        "        attention_mask = extended_attention_mask_l2_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l2,\n",
        "        encoder_attention_mask= extended_attention_mask_l1_reduced,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "  hidden_states_l3 = out_l3[0]\n",
        "  print(hidden_states_l3.shape)\n",
        "\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q-GTg2fgiCB",
        "outputId": "c44f4175-70a0-4e38-e774-ee10df37de88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"_name_or_path\": \"distilroberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.29.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "\n",
        "config_lowres_encoder = copy.deepcopy(basemod.config)\n",
        "config_lowres_encoder.hidden_size = config_lowres_encoder.hidden_size//4\n",
        "config_lowres_encoder.num_hidden_layers = 3\n",
        "print(config_lowres_encoder)\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "encoder_lowres = BertEncoder(config_lowres_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIN07S24_qp",
        "outputId": "bd44c178-932e-4c56-bfc8-56363ef9bff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "out_encoder_lowres = encoder_lowres(\n",
        "    hidden_states=hidden_states_l3,\n",
        "    attention_mask=extended_attention_mask_l2_reduced,\n",
        "    head_mask = None,\n",
        "    return_dict=True,\n",
        ")\n",
        "hidden_states_lowres = out_encoder_lowres[0]\n",
        "print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM75xap8L5cB"
      },
      "outputs": [],
      "source": [
        "## Upresolution Layer: up-resolution from dim-3 to dim-2 is as follows:\n",
        "# hs_l3 -> upsampled sequence-length as hs-l2\n",
        "# -> could have another attention-based mechanism that expands dimension of hs-l2\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "#hidden_states_upscaled_3to2_nearest = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='nearest').transpose(-2,-1)\n",
        "#hidden_states_upscaled_3to2_linear = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='linear').transpose(-2,-1)\n",
        "\n",
        "upscaler_x2 = InterpolateCombo(scale_factor=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfpn9mEsPPCf"
      },
      "outputs": [],
      "source": [
        "hidden_states_upscaled3to2 = upscaler_x2(hidden_states_lowres)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GXB-9waPBv_"
      },
      "outputs": [],
      "source": [
        "## BertAttentiveIntegrator\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edzAlaOIPDa5"
      },
      "outputs": [],
      "source": [
        "bertlayer_l3_to_l2_crossattn = BertCrossAttention(\n",
        "        config=basemod.config,\n",
        "        hidden_size=silo_dimensions[1],\n",
        "        hidden_size_query=silo_dimensions[2],\n",
        "        position_embedding_type=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMmeXSBoipPv",
        "outputId": "ffce4e9c-101b-4d90-c31e-ea81ce0828be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 192])\n",
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "print(hidden_states_upscaled3to2.shape)\n",
        "print(hidden_states_l2.shape)\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVMll5RTQyVh",
        "outputId": "5ac82f6c-dd52-4295-9534-159d0dd26ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2_postencode = bertlayer_l3_to_l2_crossattn(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "hidden_states_l2_postencode = out_l2_postencode[0]\n",
        "print(hidden_states_l2_postencode.shape)\n",
        "assert hidden_states_l2_postencode.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5HD6Rc7POU",
        "outputId": "17ff76a1-827c-4945-9ae6-92535113b493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n",
            "3072\n",
            "4.0\n"
          ]
        }
      ],
      "source": [
        "print(basemod.config.hidden_size)\n",
        "print(basemod.config.intermediate_size)\n",
        "print(basemod.config.intermediate_size/basemod.config.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_ElURFHWk3B"
      },
      "outputs": [],
      "source": [
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = query_hidden_states,\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeJysFTAgZm_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from low-res to mid-res\n",
        "bert_integrative_layer_midres = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[2],\n",
        "    intermediate_size=silo_dimensions[1]*4,\n",
        ")\n",
        "\n",
        "# from mid-res to high-res\n",
        "bert_integrative_layer_hires = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[0],\n",
        "    hidden_size_query=reintegration_dim,\n",
        "    intermediate_size=silo_dimensions[0]*4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcZ3MU-4hFN3",
        "outputId": "c521b9fe-1ccc-4e49-d8df-75f4801f795b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "hidden_states_midres = bert_integrative_layer_midres(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "print(hidden_states_midres.shape)\n",
        "assert hidden_states_midres.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iavtqpUohJAs",
        "outputId": "272bdcee-3341-41ea-bd80-87a1b6d0fe8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 576])\n"
          ]
        }
      ],
      "source": [
        "# upscale the l2 and l3 to the full dimension\n",
        "upscaler_x4 = InterpolateCombo(scale_factor=4)\n",
        "hidden_states_upscaled3to1 = upscaler_x4(hidden_states_lowres)\n",
        "hidden_states_upscaled2to1 = upscaler_x2(hidden_states_midres)\n",
        "\n",
        "hidden_states_upscaled = torch.cat(\n",
        "    (hidden_states_upscaled2to1, hidden_states_upscaled3to1),\n",
        "    axis=2)\n",
        "\n",
        "print(hidden_states_upscaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gDwXueYhJ1B",
        "outputId": "ed02eb22-18ea-4bce-91b2-bfc5ccf3ccd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n"
          ]
        }
      ],
      "source": [
        "# final layer to bring it up to full dimension\n",
        "hidden_states_hires = bert_integrative_layer_hires(\n",
        "    hidden_states = hidden_states_l1,\n",
        "    attention_mask = extended_attention_mask,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled,\n",
        "    query_attention_mask = extended_attention_mask\n",
        ")\n",
        "print(hidden_states_hires.shape)\n",
        "assert hidden_states_hires.shape == hidden_states_l1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv4ZVcYORoL_",
        "outputId": "df6aca9a-68c3-4cc4-c579-7fa0e8518c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_states_hires.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJQJVvdMle3v",
        "outputId": "3e4830ce-7b1c-4d9b-c584-947339137ee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 24])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_mask_l1_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Z0KGMfm-Mn"
      },
      "source": [
        "### The Reduce and Integrate layer:\n",
        "- this is like a Transformer block, but:\n",
        "- does dimension reduction along sequence and embedding-dim\n",
        "- includes a skip connection from previous hidden-states of the same dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExGOdKwWm_46"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# this is the layer that just does cross-attention between a seq-reduced query and full-size value and key\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "\n",
        "BertReduceAddIntegrativeLayer\n",
        "inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkiZo9Npm_xi"
      },
      "outputs": [],
      "source": [
        "# initialize the mid-resolution BertReduceAndIntegrate layer\n",
        "bert_reduce_add_integrate_midres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[1], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[0],\n",
        "    hidden_size_query=silo_dimensions[0],\n",
        "    intermediate_size=silo_dimensions[1]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")\n",
        "\n",
        "bert_reduce_add_integrate_lowres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[2], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[1],\n",
        "    intermediate_size=silo_dimensions[2]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxtTomiPxQn8",
        "outputId": "0d221d7e-a51b-4a93-af5f-a7f23af07e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_hires_reduced = maxpool_l2(hidden_states_hires)\n",
        "assert hidden_states_hires_reduced.shape[1] == hidden_states_midres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres.shape)\n",
        "hidden_states_midres = bert_reduce_add_integrate_midres(\n",
        "    inputs = hidden_states_hires, # from highres outputs previous layer (key, values)\n",
        "    hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask=None,\n",
        "    query_hidden_states = hidden_states_hires_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        ")\n",
        "print(hidden_states_midres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPGNtX3KxQuY",
        "outputId": "9a5d53a5-acf3-4255-b624-7aa38bf0ad9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12, 192])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_midres_reduced = maxpool_l2(hidden_states_midres)\n",
        "assert hidden_states_midres_reduced.shape[1] == hidden_states_lowres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  print(hidden_states_lowres.shape)\n",
        "  hidden_states_lowres = bert_reduce_add_integrate_lowres(\n",
        "      inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "      hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "      attention_mask = extended_attention_mask_l2_reduced,\n",
        "      head_mask=None,\n",
        "      query_hidden_states = hidden_states_midres_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        "  )\n",
        "  print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFdByXbYAz2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJAHT_SyxQwK"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from transformers.modeling_utiles import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQPJPPkpmibK"
      },
      "source": [
        "### Base-Layer nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbBLQZJJlu6n"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 2, # number of transformer stacks\n",
        "    scale_ratio2 = 0.5, # reduce sequence-length by X, from high-res to mid-res\n",
        "    scale_ratio3 = 0.25, # reduce sequence-length by Y, from high-res to low-res\n",
        "    multipler_intermediate2 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    multipler_intermediate3 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05, # dropout when performing downscaling from one-sequence length to next\n",
        "    use_cheap_integrator_for_stacks = [],\n",
        "    do_mlm=False,# whether to output MLM token predictions\n",
        "    do_cls=False,# whether to output a pooled sentence-vector for sequence classification\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config,'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks',num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multipler_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multipler_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", use_cheap_integrator_for_stacks)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        # cheap (non-transformer) method to integrate high- and mid-res hidden states\n",
        "        bert_integrative_layer_1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        # full Transformer layer as mid-to-highres upscaling\n",
        "        BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1//2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    bert_integrative_layer_1 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size,\n",
        "        hidden_size_query=config.query_size1,\n",
        "        intermediate_size=config.intermediate_size_l1\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_l1\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"attention\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled3to2        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_highres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_highres\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "class BertClassificationHead(nn.Module):\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "def tokenize_anathem(text, device=device):\n",
        "    #padding_length = int(math.ceil(max_length / 4)) *\n",
        "    tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "    input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    # change token padding to be multiple of 4\n",
        "    #ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "    #if input_shape[-1]!=ideal_length:\n",
        "    #  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "    #  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "    tokens['token_type_ids'] = token_type_ids\n",
        "    for k,v in tokens.items():\n",
        "        tokens[k] = v.to(device)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdRq7bM3pQhp",
        "outputId": "452ade89-f3b4-4404-ab8f-8442de7689bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#config = make_config('distilroberta-base')\n",
        "#config = make_config('t5-small') # can't use t5 because it uses relative\n",
        "config = make_config('google/bert_uncased_L-12_H-512_A-8') #\n",
        "\n",
        "if False:\n",
        "  (tokenizer,basemod,layer_embedding,layer_basetransformer,maxpool,maxpool_attn,bert_reducer_l2,\n",
        "   bert_reducer_l3,bert_encoder_lowres,upscaler_x2,upscaler_x4,bert_integrative_layer_2,bert_integrative_layer_1) = initialize(config)\n",
        "\n",
        "# make the basemod and tokenizer\n",
        "basemod = AutoModel.from_pretrained(config.model_string)\n",
        "basemod.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgEOUtHYoB-I"
      },
      "outputs": [],
      "source": [
        "# the Anathem encoder includes the embeddings and first transformer block\n",
        "anathem_encoder1 = AnathemBaseModule(config, basemod, tokenizer)\n",
        "anathem_encoder2 = AnathemMidModule(config, basemod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87RTY9a059mQ"
      },
      "outputs": [],
      "source": [
        "cls_head = BertClassificationHead(config, n_classes = 3, activation = 'none',device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-1aZOdgB_g8"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"* Welcome home to this gorgeously upgraded, beautifully maintained, three-bedroom home with double attached garage. Drive up to this quiet cul-de-sac and let the experience begin. On the main floor, you’ll notice the abundance of natural light. There is a separate office with view over the front of the property. The layout was customized, with a great open living space. The kitchen is a chef’s dream, with a breakfast bar, granite countertops, stainless steel appliance package, a pantry, and a view out to the sunny west facing yard.\",\n",
        "    \"There’s room for formal dining and the family room has a gas fireplace to relax by on the cooler nights. Out back, there’s a stunner of a deck, perfect for BBQ season! Upstairs, you’ll find a massive bonus room with tons of windows. There are two, secondary bedrooms and the master suite is amazing\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbt_zlrlCVEU"
      },
      "outputs": [],
      "source": [
        "tokens = tokenize_anathem(text,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XpXyV6YW4DI",
        "outputId": "6e4777a3-d95c-48ce-d799-2b761e72213c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#stack 1\n",
        "out1 = anathem_encoder1(\n",
        "      input_ids = tokens['input_ids'],\n",
        "      attention_mask = tokens['attention_mask'],\n",
        "      token_type_ids = tokens['token_type_ids']\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A87nQ24Ccoh",
        "outputId": "bbf75272-c1db-4da1-9543-acfe3832812b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.8376, -0.3891, -0.6668],\n",
              "        [-0.8747, -0.3621, -0.7735]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stack2\n",
        "out2 = anathem_encoder2(\n",
        "      hidden_states_highres = hidden_states[0],\n",
        "      hidden_states_midres = hidden_states[1],\n",
        "      hidden_states_lowres = hidden_states[2],\n",
        "      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out2\n",
        "\n",
        "cls_head(hidden_states[0], tokens['attention_mask'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQ9ABhkU8pE",
        "outputId": "76b0b2cb-196f-44c5-9079-4b9992a9835d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out1[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBi1G7ay63nr"
      },
      "outputs": [],
      "source": [
        "####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2L-jYJ6u4qd"
      },
      "outputs": [],
      "source": [
        "## Next steps, do something simple like sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLHCo5vZ-brJ"
      },
      "outputs": [],
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from scipy.special import softmax\n",
        "#datasets_list = list_datasets()\n",
        "#[k for k in datasets_list if 'phrasebank' in k]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "04db53bae1ea4e81a1acbad7401cd331",
            "81afc2262c8545dab41aacde91066b7d",
            "b96a361475c947e5a0f9e5f0f867ced7",
            "f697e928e02f405d99c43c4b1fd890c9",
            "6da885f236a24cf5a09add7c9927db76",
            "638f36ef35ec4ec88ba057c63093eca2",
            "4b35ff0e35ca4e6088f2f1f687ff924c",
            "e1c9ec9890384cb4b17139a7335e371e",
            "adef362bc525401c8b657d33dfec55ce",
            "f5912ed9e9c944e5ae35be20f0634165",
            "c7d86dc22b0747dba72d6aa5fd899df0"
          ]
        },
        "id": "rvjAv19p1Un6",
        "outputId": "a84e2ae7-d09e-49f8-b454-00f8c494fd17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset financial_phrasebank (/root/.cache/huggingface/datasets/financial_phrasebank/sentences_75agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04db53bae1ea4e81a1acbad7401cd331",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#[k for k in datasets_list if 'phrasebank' in k]\n",
        "\n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_75agree')\n",
        "\n",
        "# split\n",
        "idx_train, idx_val = train_test_split(np.arange(len(dataset['train']['sentence'])), test_size=0.1)\n",
        "dataset_train = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]}  for idx in idx_train]\n",
        "dataset_val = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]} for idx in idx_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_fRokuwB1h9",
        "outputId": "cbbc64cc-0bad-42bd-987c-aec7460b3960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3107\n",
            "346\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset_train)); print(len(dataset_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B86BY_m_x12"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"torch dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.data = dataset\n",
        "        self.n = len(self.data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        unit = self.data[idx]\n",
        "        return unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh3NKKrZ_xuX"
      },
      "outputs": [],
      "source": [
        "ds_train = MyDataset(dataset_train)\n",
        "ds_val = MyDataset(dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn4rR8QqEiS3"
      },
      "outputs": [],
      "source": [
        "batch_size_train = 12\n",
        "batch_size_val = 36\n",
        "lr = 0.00005\n",
        "eval_iter = 20\n",
        "n_epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9JPB6miBpQ9"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(ds_train, batch_size=batch_size_train, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=batch_size_val, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbhvjxbeKHh9"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(list(anathem_encoder1.parameters()) + list(anathem_encoder2.parameters()) + list(cls_head.parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "fPmQOT5OEnEY",
        "outputId": "cd172411-6a85-4bce-f076-9d03d8dc276f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:19: f1:0.402 (0.000); prec:0.352 (0.000); rec:0.469 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:39: f1:0.326 (0.000); prec:0.400 (0.000); rec:0.372 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:59: f1:0.459 (0.158); prec:0.531 (0.405); rec:0.485 (0.095)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:79: f1:0.506 (0.305); prec:0.583 (0.450); rec:0.494 (0.231)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:99: f1:0.499 (0.190); prec:0.555 (0.383); rec:0.551 (0.116)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:119: f1:0.552 (0.280); prec:0.663 (0.568); rec:0.534 (0.179)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:139: f1:0.661 (0.469); prec:0.708 (0.600); rec:0.636 (0.385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-d95d13a5603a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "optimizer.zero_grad()\n",
        "anathem_encoder1.train()\n",
        "anathem_encoder2.train()\n",
        "cls_head.train()\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "\n",
        "      # tokenize the batch\n",
        "      tokens = tokenize_anathem(batch['text'],device)\n",
        "      target = batch['label'].to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      out1 = anathem_encoder1(\n",
        "        input_ids = tokens['input_ids'],\n",
        "        attention_mask = tokens['attention_mask'],\n",
        "        token_type_ids = tokens['token_type_ids']\n",
        "      )\n",
        "      (hidden_states, extended_attention_masks) = out1\n",
        "\n",
        "      features,_ = anathem_encoder2(\n",
        "          hidden_states_highres = hidden_states[0],\n",
        "          hidden_states_midres = hidden_states[1],\n",
        "          hidden_states_lowres = hidden_states[2],\n",
        "          extended_attention_mask_highres = extended_attention_masks[0],\n",
        "          extended_attention_mask_midres = extended_attention_masks[1],\n",
        "          extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "      )\n",
        "\n",
        "      # prediction\n",
        "      preds = cls_head(features[0], tokens['attention_mask'])\n",
        "\n",
        "      # loss\n",
        "      loss = nn.functional.cross_entropy(preds, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # do evaluation\n",
        "      if ((iteration+1) % eval_iter)==0:\n",
        "          anathem_encoder1.eval()\n",
        "          anathem_encoder2.eval()\n",
        "          cls_head.eval()\n",
        "          # tokenize the eval\n",
        "          eval_logits = []\n",
        "          eval_targets = []\n",
        "          for i, batch_eval in enumerate(tqdm(dl_val, disable=True)):\n",
        "              with torch.no_grad():\n",
        "                  # tokenize the batch\n",
        "                  tokens_eval = tokenize_anathem(batch_eval['text'], device)\n",
        "                  labels_eval = batch_eval['label'].to(device)\n",
        "                  out_eval1 = anathem_encoder1(\n",
        "                      input_ids = tokens_eval['input_ids'],\n",
        "                      attention_mask = tokens_eval['attention_mask'],\n",
        "                      token_type_ids = tokens_eval['token_type_ids']\n",
        "                  )\n",
        "                  (hidden_states, extended_attention_masks) = out_eval1\n",
        "                  features,_ = anathem_encoder2(\n",
        "                      hidden_states_highres = hidden_states[0],\n",
        "                      hidden_states_midres = hidden_states[1],\n",
        "                      hidden_states_lowres = hidden_states[2],\n",
        "                      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "                  )\n",
        "                  # prediction\n",
        "                  batch_logits = cls_head(features[0], tokens_eval['attention_mask'])\n",
        "                  eval_logits+=batch_logits.detach().tolist()\n",
        "                  eval_targets+=labels_eval.detach().tolist()\n",
        "\n",
        "          eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)\n",
        "          print('E:%d; i:%d: f1:%0.3f (%0.3f); prec:%0.3f (%0.3f); rec:%0.3f (%0.3f)' % (epoch, iteration, eval_f1.mean(), eval_f1.min(), eval_prec.mean(), eval_prec.min(), eval_recall.mean(), eval_recall.min()))\n",
        "          cls_head.train()\n",
        "          anathem_encoder1.train()\n",
        "          anathem_encoder2.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVZ7tZ7JYSO",
        "outputId": "60a71e09-6d52-49f5-f42d-bf6cb36c9d2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZugKHbocDR0"
      },
      "source": [
        "## Test performance speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chS7dYV4cA2a",
        "outputId": "97dccd81-d967-42a4-de00-278241cc1dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for anathem: 33283328\n"
          ]
        }
      ],
      "source": [
        "# how many parameters in the model in total\n",
        "from math import prod\n",
        "nparam = 0\n",
        "for encoder in [anathem_encoder1, anathem_encoder2]:\n",
        "    for na,l in encoder.named_parameters():\n",
        "        nparam+=prod(l.data.shape)\n",
        "print('Number of parameters for anathem: %d' % nparam)\n",
        "# 33676544"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOKuhoSQgN28",
        "outputId": "118fbf58-b22a-4e63-ee9a-b5382eba30f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# compare this to distilbert\n",
        "#other_mod = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "other_mod = AutoModel.from_pretrained('google/bert_uncased_L-12_H-512_A-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNPeFA5gg-3u",
        "outputId": "c58db76c-2e88-4cf8-d1e1-ddc3ee70b194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for other-mod: 53982720\n"
          ]
        }
      ],
      "source": [
        "nparam = 0\n",
        "for na,l in other_mod.named_parameters():\n",
        "    nparam+=prod(l.data.shape)\n",
        "\n",
        "print('Number of parameters for other-mod: %d' % nparam)\n",
        "\n",
        "# number of parameters for anathem-trans: 33676544 (google/bert_uncased_L-12_H-512_A-8)\n",
        "# number of parametres for anathem-trans: 78973824 (includng 2 more mid-res encoders)\n",
        "# number of parameters for anathem-trans: 73062528 (with a 768 dimension)\n",
        "# Number of parameters for distilroberta: 82118400 (with a 768 dimension)\n",
        "# Number of parameters  all-MiniLM-L6-v2: 22713216\n",
        "# Number of parameters google/bert_uncased_L-12_H-512_A-8: 53982720 (512 dim, 12L)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En8rgr4mSNBt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIeQesGRSOKl"
      },
      "source": [
        "## Test Performance Speed at inference (CPU)\n",
        "- distilroberta-base: 10 batches: 23.517s , CPU\n",
        "- oogle/bert_uncased_L-12_H-512_A-8: 10 batches: 12.44s, CPU\n",
        "- anathem (distilroberta-768): 10 batches, 23.23s,\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 10 batches, ~7.5s, CPU\n",
        "\n",
        "## Test Performance Speed at inference (GPU)\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 30 batches, 0.79s, GPU\n",
        "- google/bert_uncased_L-12_H-512_A-8: 30 batches: 0.8 GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwXj277YTa71"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiKeaFEQKLUg",
        "outputId": "db5c7019-151b-4bc7-de75-6bacfd6d2e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8027215003967285\n"
          ]
        }
      ],
      "source": [
        "time1 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time2 = time.time()\n",
        "        print(time2-time1)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        (hidden_states, extended_attention_masks) = anathem_encoder1(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )\n",
        "        features,_ = anathem_encoder2(\n",
        "            hidden_states_highres = hidden_states[0],\n",
        "            hidden_states_midres = hidden_states[1],\n",
        "            hidden_states_lowres = hidden_states[2],\n",
        "            extended_attention_mask_highres = extended_attention_masks[0],\n",
        "            extended_attention_mask_midres = extended_attention_masks[1],\n",
        "            extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaHOImksIE4s",
        "outputId": "e25c00cc-a643-46ff-ed4f-a54be0b86c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7066085338592529\n"
          ]
        }
      ],
      "source": [
        "time3 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time4 = time.time()\n",
        "        print(time4-time3)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        out = basemod(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpDJu4TrGJme",
        "outputId": "3223ab06-d6db-4c25-da03-b33c72689884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.86464646, 0.52173913])"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kO-XYGLFCuk"
      },
      "outputs": [],
      "source": [
        "eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcAhKojQOKOt"
      },
      "source": [
        "## Variant: Possibly Faster Integrative Layer\n",
        "\n",
        "The above version uses a BertIntegrativeLayer that uses the high-res hidden-states as the key/values, and the upscaled-low res as the query\n",
        "\n",
        "This variant flips it: the high-res is the query (thereby upscaling via attention) and the low-res are the value and keys\n",
        "\n",
        "#### Varient #2 has slightly fewer parameters: 33283328 vs 336"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVu2yPrYDJrr",
        "outputId": "d790c978-c641-49d1-dc88-b3566f1e93df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 huggingface-hub-0.16.4 multiprocess-0.70.14 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxVyqa3vNlYc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForMaskedLM\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "import math\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, Optional, Sequence, Tuple, Union\n",
        "from transformers.utils import PaddingStrategy\n",
        "\n",
        "EncodedInput = List[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RILlmtI3NxD8"
      },
      "outputs": [],
      "source": [
        "class CustomTokenizer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    ):\n",
        "        # initialize the tokenizer from the base model\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        # how many cls tokens to prepend to the fullsize data\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not ((k[0]=='_') or (k in ['tokenize','encode','build_inputs_with_special_tokens','batch_encode_plus','encode_plus','pad'])):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "        self.downscale_multiple = downscale_multiple\n",
        "        # downscale attention\n",
        "        self.maxpool_attn = nn.MaxPool1d(\n",
        "            (self.downscale_multiple), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True\n",
        "        )\n",
        "\n",
        "        # ensure excess_token_ids are included for .pad operations\n",
        "        if 'excess_cls_ids' not in self.base_tokenizer.model_input_names:\n",
        "            self.base_tokenizer.model_input_names += ['excess_cls_ids']\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._batch_prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        # downscale the attention, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='excess_cls_ids'\n",
        "        )\n",
        "        return tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_tokenizer)\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [self.cls_token_id]*(n_cls_prepend-1)+tokens['input_ids'] + [self.pad_token_id]*self._num_pad_tokens(tokens['input_ids'])\n",
        "        tokens['excess_cls_ids'] = [0]*(n_cls_prepend)+tokens['attention_mask'][1:] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        tokens['attention_mask'] = [1]*(n_cls_prepend-1)+tokens['attention_mask'] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                tokens['token_type_ids'][0]\n",
        "            ]*(n_cls_prepend-1) + tokens['token_type_ids'] + [tokens['token_type_ids'][-1]]*self._num_pad_tokens(tokens['token_type_ids'])\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def _batch_prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['excess_cls_ids'] = [\n",
        "            [0]*(n_cls_prepend)+attnmask[1:] +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                # we use the token_type_ids\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def encode_plus(self, text, add_special_tokens=True, return_tensors=None, *args, **kwargs):\n",
        "        tokens = self.base_tokenizer.encode_plus(text, add_special_tokens=add_special_tokens, return_tensors=return_tensors, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "        return tokens\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "    def downscale_attention(self, tokens, downscale_multiple=None, name = 'attention_mask'):\n",
        "        \"\"\"\n",
        "        Reduces the sequence-dimenion by self.downscale_multiple using nn.maxpool\n",
        "        Adds the downscale attention to the tokens dictionary\n",
        "        \"\"\"\n",
        "        if downscale_multiple is None:\n",
        "            downscale_multiple = [self.downscale_multiple, self.downscale_multiple]\n",
        "\n",
        "        # fullsize attention\n",
        "        attn = tokens[name]\n",
        "        if not isinstance(attn, torch.Tensor):\n",
        "            attn = torch.Tensor(attn)\n",
        "\n",
        "        for i, mult in enumerate(downscale_multiple):\n",
        "            name_of_downsized_attn = '%s_l%d' % (name, i+2)\n",
        "            with torch.no_grad():\n",
        "                attn = self.maxpool_attn(attn.float())\n",
        "            tokens[name_of_downsized_attn] = attn\n",
        "        return tokens\n",
        "\n",
        "    def pad(\n",
        "        self,\n",
        "        encoded_inputs,\n",
        "        pad_to_multiple_of=4,\n",
        "        return_tensors=None,\n",
        "        padding: Union[bool, str, PaddingStrategy] = True,\n",
        "        max_length: Optional[int] = None,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Pad a list of tokenized-inputs to the same batch-length, with special processing of Anathem-specific inputs\"\"\"\n",
        "\n",
        "        # which are conventional inputs and which are anathem specific\n",
        "        conventional_input_nm = [k for k in encoded_inputs[0].keys() if k in ['input_ids', 'token_type_ids','attention_mask']]\n",
        "        unconventional_input_nm = [k for k in encoded_inputs[0].keys() if k not in conventional_input_nm]\n",
        "\n",
        "        # pad the vanilla inputs\n",
        "        conventional_encoded_inputs = self.base_tokenizer.pad([\n",
        "                {k:v for k,v in encoded_input.items() if k in conventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "            ], pad_to_multiple_of=pad_to_multiple_of, return_tensors=return_tensors, padding=padding, max_length=max_length, *args, **kwargs\n",
        "        )\n",
        "\n",
        "        # deal with the remaining inputs\n",
        "        padding_strategy, _, max_length, _ = self.base_tokenizer._get_padding_truncation_strategies(\n",
        "            padding=padding, max_length=max_length, verbose=False\n",
        "        )\n",
        "\n",
        "        #required_input = encoded_inputs[][self.model_input_names[0]]\n",
        "        # this is stupid, I need to pad each input in batch individually\n",
        "        special_anathem_inputs = [\n",
        "                {k:v for k,v in encoded_input.items() if k in unconventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "        ]\n",
        "        special_anathem_encoded_inputs = self.pad_special_anathem_inputs(\n",
        "            special_anathem_inputs=special_anathem_inputs,\n",
        "            encoded_inputs=conventional_encoded_inputs,\n",
        "            max_length=max_length,\n",
        "            padding_strategy=padding_strategy,#: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "            pad_to_multiple_of=pad_to_multiple_of,\n",
        "            return_tensors=return_tensors\n",
        "        )\n",
        "        # let's see if I can just insert into the conventional_encode_inputs\n",
        "        conventional_encoded_inputs.update(special_anathem_encoded_inputs) # apparently I can just append..\n",
        "\n",
        "        # downscale the attention and add to inputs\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='excess_cls_ids'\n",
        "        )\n",
        "        return conventional_encoded_inputs\n",
        "\n",
        "    def pad_special_anathem_inputs(\n",
        "        self,\n",
        "        special_anathem_inputs,\n",
        "        encoded_inputs,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None,\n",
        "        return_tensors=None,\n",
        "    ):\n",
        "        required_input = encoded_inputs[self.model_input_names[0]]\n",
        "        batch_size,max_length = required_input.shape\n",
        "        #print(batch_size,max_length)\n",
        "        assert batch_size == len(special_anathem_inputs)\n",
        "        assert isinstance(special_anathem_inputs, list)\n",
        "        padding_strategy = PaddingStrategy.MAX_LENGTH\n",
        "        special_anathem_batch_outputs = {}\n",
        "        for i in range(batch_size):\n",
        "            inputs = special_anathem_inputs[i] #{k: v[i] for k, v in special_anathem_inputs.items()}\n",
        "            assert isinstance(inputs, dict)\n",
        "            outputs = self._pad_special_anathem_input(\n",
        "                inputs,\n",
        "                max_length=max_length,\n",
        "                padding_strategy=padding_strategy,\n",
        "                pad_to_multiple_of=pad_to_multiple_of\n",
        "            )\n",
        "            for key, value in outputs.items():\n",
        "                if key not in special_anathem_batch_outputs:\n",
        "                    special_anathem_batch_outputs[key] = []\n",
        "                special_anathem_batch_outputs[key].append(value)\n",
        "\n",
        "        return BatchEncoding(special_anathem_batch_outputs, tensor_type=return_tensors) # returning because of failure\n",
        "\n",
        "    def _pad_special_anathem_input(\n",
        "        self,\n",
        "        special_anathem_input,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Pad encoded Anathem-specific inputs (on left/right and up to predefined length or max length in the batch)\n",
        "        \"\"\"\n",
        "        assert isinstance(special_anathem_input, dict)\n",
        "        len_required_input = len(special_anathem_input[list(special_anathem_input.keys())[0]])\n",
        "        if max_length is not None and pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
        "            max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
        "\n",
        "        needs_to_be_padded = padding_strategy != PaddingStrategy.DO_NOT_PAD and len_required_input != max_length\n",
        "\n",
        "        # Initialize attention mask if not present\n",
        "        if needs_to_be_padded:\n",
        "            special_anathem_outputs = dict.fromkeys(special_anathem_input.keys())\n",
        "            difference = max_length - len_required_input\n",
        "            if self.padding_side == \"right\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = special_anathem_input[k] + [0] * difference\n",
        "            elif self.padding_side == \"left\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = [0] * difference + special_anathem_input[k]\n",
        "            else:\n",
        "                raise ValueError(\"Invalid padding strategy:\" + str(self.padding_side))\n",
        "\n",
        "            return special_anathem_outputs\n",
        "        return special_anathem_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e2f772d1181b417e8f3bc2feee4f6e16",
            "825fb9aa19594a61b2a779837eb230b4",
            "b076eddbd7a74d5495615776c26a6f3e",
            "75d76bf886514ba5ac9fedee0fcfba8d",
            "e9685ee9b4aa47fcb5a3a79261ca87c7",
            "686aaeb98c1a4e688af5030963b8525e",
            "0a024ed7f3514fd6a544804a8bee0d78",
            "f230ba518eed434fb107f97c66293470",
            "1a7dd0c3112945959e9908425fcaa8b8",
            "80fd0e5e6b8f47c6a4c9557f127ef73b",
            "b963a45c28d1437f86109f283a370f38",
            "bdc7642ca3e748069974df4a510470ce",
            "1034a93ce59f439bb128b6c096eefdf2",
            "4a16335de26a43c09d578cbbe20e98d1",
            "573b3112cbee4ba581c18884df0a269e",
            "4fe04dcab6654d0594a56109e7eb6805",
            "c225230ea12f4f90bd461485f300580e",
            "4d3b7432f11a4a4b9eb444743d158c0d",
            "1d567e39c5ac4b9f8d9908111b04100f",
            "f619ea2b062a4eacb80ade328d56c2aa",
            "bc799bb2e34741fabc79181ea30ee78f",
            "a78c45e4929847f0a635988d1ef9d78f"
          ]
        },
        "id": "8TRaTA1dDv10",
        "outputId": "1b1d9054-f164-49ea-eb1e-300eb4223758"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f772d1181b417e8f3bc2feee4f6e16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc7642ca3e748069974df4a510470ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = CustomTokenizer(\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qTUF85MsPkS",
        "outputId": "ef24d6fc-34fa-4865-cbe4-800035ff05e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.base_tokenizer.model_input_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6pmDZa6D22L"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrb_tyIFXoz",
        "outputId": "388102cd-666c-41fd-c565-bdf683e416bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids 40\n",
            "input_ids [101, 101, 101, 101, 1037, 3115, 103, 11075, 2003, 1037, 23701, 6299, 11075, 2008, 2163, 2008, 2028, 2283, 2180, 1005, 1056, 2907, 1996, 2060, 20090, 2005, 12394, 1010, 6409, 1010, 2030, 5366, 3378, 2007, 3314, 1012, 102, 0, 0, 0]\n",
            "token_type_ids 40\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 40\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "excess_cls_ids 40\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "input_ids 48\n",
            "input_ids [101, 101, 101, 101, 2009, 2788, 3774, 1997, 2048, 3787, 1024, 1037, 9495, 2724, 2030, 25652, 1998, 1037, 103, 14987, 1012, 1996, 9495, 2724, 2030, 25652, 2003, 1996, 103, 1997, 1996, 3820, 1010, 23337, 1010, 2030, 27988, 1997, 1996, 27427, 6633, 3490, 14116, 2283, 2030, 2049, 18460, 102]\n",
            "token_type_ids 48\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 48\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "excess_cls_ids 48\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "---\n",
            "CONVENTIONAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "SPECIAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "input_ids 2\n",
            "48\n",
            "48\n",
            "token_type_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask 2\n",
            "48\n",
            "48\n",
            "excess_cls_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask_l2 2\n",
            "24\n",
            "24\n",
            "attention_mask_l3 2\n",
            "12\n",
            "12\n",
            "excess_cls_ids_l2 2\n",
            "24\n",
            "24\n",
            "excess_cls_ids_l3 2\n",
            "12\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "# FOOFU\n",
        "# in the vanilla DataCollatorForLanguageModelling, if the data is pretokenized (unpadded)\n",
        "#    then collator will simply \"pad\", the input_ids and the attention_mask (but not the generated excess_cls_ids, nor the attention_mask_l2 or l3)\n",
        "#    ... but, I created these _l2,_l3 assuming that everything was already padded properly\n",
        "# so, adding excess_token_ids to _model_names_inputs (or whatev, doesn't automatically cause the behaviour I wanted)\n",
        "# the error is because the _pad specifically only handles special_token_ids and token_type_ids in a very specific way\n",
        "#... there is no generic list_of_names to enforce padding of generic inputs.\n",
        "\n",
        "# options:\n",
        "# --- make an updated \"pad\" function for the tokenizer, that will likewise apply padding\n",
        "tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "\n",
        "for tok in tokens:\n",
        "    for k,v in tok.items():\n",
        "        print(k,len(v))\n",
        "        print(k,v)\n",
        "print('---')\n",
        "\n",
        "pad_out = tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt')\n",
        "print('CONVENTIONAL')\n",
        "print(pad_out)\n",
        "\n",
        "#for k,v in tokenizer.base_tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt').items():\n",
        "print('SPECIAL')\n",
        "print(pad_out)\n",
        "for k,v in pad_out.items():\n",
        "    print(k, len(v))\n",
        "    for j in v:\n",
        "        print(len(j))\n",
        "\n",
        "\n",
        "# still need to do: reduce attention_mask\n",
        "# return as tensor\n",
        "# merge and make a BatchEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxawLdRdHStR",
        "outputId": "e76fe1b0-3584-48a0-db64-806542ac0c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pad_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3WljX9NzSW"
      },
      "outputs": [],
      "source": [
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n",
        "try:\n",
        "    from transformers.modeling_utils import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbXNphafOX2i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size= self.hidden_size, # high dim output\n",
        "            hidden_size_query = self.hidden_size_query, # high dim query\n",
        "            hidden_size_keyvalue = self.hidden_size_keyvalues, # low-dim keyvalues\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        keyvalue_hidden_states: torch.Tensor=None, # low-res hidden-states (1/2 seq-dim) used for key-value pairs\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to query\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = keyvalue_hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = torch.cat((hidden_states, query_to_concat_hidden_states),axis=2),\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "        assert cross_hidden_states.shape[1]==hidden_states.shape[1], f\"{cross_hidden_states.shape[1]},{cross_hidden_states.shape[2]} vs {hidden_states.shape[1]},{hidden_states[2]}\"\n",
        "        assert cross_hidden_states.shape[2]==hidden_states.shape[2]\n",
        "\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.output_attn(cross_hidden_states)\n",
        "        cross_hidden_states = self.dropout_attn(cross_hidden_states)\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        intermediate_states = self.intermediate(intermediate_states)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        out_states = self.output_intm(intermediate_states)\n",
        "        out_states = self.dropout_intm(out_states)\n",
        "        out_states = self.lnorm_intm(out_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOl85thAOiu3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class CheapMLPIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Cheap (non-transformer) Integrator layer that merges a (low-res) layers with higher-res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues=None, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        if hidden_size_keyvalues is None:\n",
        "            hidden_size_keyvalues = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(2*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # expand hidden-size to a multiple\n",
        "        self.dense_expander = nn.Linear(\n",
        "            self.hidden_size_query,\n",
        "            self.intermediate_size\n",
        "        ) # deflate back to same size as hidden-state\n",
        "        self.dense_deflator = nn.Linear(\n",
        "            self.intermediate_size,\n",
        "            self.hidden_size\n",
        "        )\n",
        "\n",
        "        # intermediate activation function\n",
        "        self.intermediate_act_fn = nn.RReLU(0.0625, 0.125)\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.lnorm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask = None, # ignored\n",
        "        head_mask = None, # ignored\n",
        "        keyvalue_hidden_states =None, # ignored\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to hidden_states\n",
        "        query_attention_mask = None, # ignored\n",
        "        past_key_value = None, # ignored\n",
        "        output_attentions = False, # ignored\n",
        "    ) -> torch.Tensor:\n",
        "\n",
        "        # concat (lowres) to hidden-states\n",
        "        inputs = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        # expand x2 dimension\n",
        "        intermediate_states = self.dense_expander(inputs)\n",
        "        # activation (leaky relue)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        # like BertOutput\n",
        "        out_states = self.dense_deflator(intermediate_states)\n",
        "        # dropout\n",
        "        out_states = self.dropout(out_states)\n",
        "        # combine with hidden-state inputs\n",
        "        out_states = self.lnorm(out_states + hidden_states)\n",
        "\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo-LWT_jOFNa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    sequence_classification_intermediate_dim = None, # default is the same as the basemodel hidden-dim\n",
        "    sequence_classification_out_dim = None, # default is x2 same as the basemodel hidden-dim\n",
        "    do_mlm =False,\n",
        "    do_cls = False\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config, 'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks', num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multiplier_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multiplier_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", do_cheap_integrator)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # hidden dimension\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_intermediate_dim\",\n",
        "        sequence_classification_intermediate_dim  if sequence_classification_intermediate_dim is not None else [\n",
        "            int(base_config.hidden_size*s)\n",
        "            for s in [1, scale_ratio2, scale_ratio3]\n",
        "        ]\n",
        "    )\n",
        "    # final dimension outputed for sequence classification\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_out_dim\",\n",
        "        sequence_classification_out_dim  if sequence_classification_out_dim is not None else base_config.hidden_size*2\n",
        "    )\n",
        "\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None, stack_id=1):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: from low-res to mide-res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    if not do_cheap_integrator:\n",
        "        # from mid-res to high-res\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "\n",
        "def initialize_finaltransformerlayers(config, basemod=None, tokenizer=None, names_encoder_module = 'encoder', stack_id=3):\n",
        "    \"\"\"Initializes the final BertLayer before output, but copying the final BertLayer from `Basemod`\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    assert basemod is not None, \"`initialize_finaltransformerlayers` requires the basemod to instantiate the final transformer block\"\n",
        "\n",
        "    # get the Encoder stacks\n",
        "    assert names_encoder_module in basemod._modules.keys(), 'expected %s in basemod._modules' % names_encoder_module\n",
        "    basemod_encoder_stack = get_to_bertlayer(basemod, target_layer_name = names_encoder_module)\n",
        "\n",
        "    # get the name of the final transformer block (-1) in encoder\n",
        "    names_of_final_transformer_block = list(basemod_encoder_stack._modules['layer']._modules.keys())[-1]\n",
        "\n",
        "    # get the final transformer block (NN weights pretrained)\n",
        "    bert_finaltransformer_block = basemod_encoder_stack._modules['layer']._modules[\n",
        "        names_of_final_transformer_block\n",
        "    ]\n",
        "\n",
        "    return copy.deepcopy(bert_finaltransformer_block)\n",
        "\n",
        "def get_to_bertlayer(basemod, target_layer_name = 'encoder', model_string = None):\n",
        "    \"\"\"Clumsily locates a particular layer within a pretrained bert model\"\"\"\n",
        "    if  target_layer_name in basemod._modules.keys():\n",
        "        return basemod._modules[target_layer_name]\n",
        "    elif target_layer_name in basemod._modules['bert']._modules.keys():\n",
        "        return basemod._modules['bert']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L79IXfrOKEs"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None,\n",
        "            stack_id=0\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer, stack_id=0)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        self.stack_id = 0\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l3,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        #hidden_states_upscaled = torch.cat((\n",
        "        #    hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        #),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l2,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1,\n",
        "            query_attention_mask = extended_attention_mask_l2\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "                (attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"extended_attention_masks\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "            \"attention_masks\":(attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "            stack_id = 1\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer, stack_id)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_lowres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2\n",
        "        )\n",
        "        #hidden_states_midres = self.bert_integrative_layer_2(\n",
        "        #    hidden_states = hidden_states_l2,\n",
        "        #    attention_mask = extended_attention_mask_midres,\n",
        "        #    head_mask = None,\n",
        "        #    query_hidden_states = hidden_states_upscaled3to2)\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        #hidden_states_upscaled = torch.cat((hidden_states_upscaled2to1, hidden_states_upscaled3to1),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_midres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1\n",
        "        )\n",
        "\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemEncoder(nn.Module):\n",
        "    \"\"\"Anathem cores stacks of layers, from embeddings to final transformer block\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # initialize embedings and first stack\n",
        "        self.anathem_base_stack = AnathemBaseModule(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            past_key_values_length,\n",
        "            device,\n",
        "        )\n",
        "\n",
        "        # initialize all subsequence stacks\n",
        "        self.anathem_mid_stack = nn.ModuleList([\n",
        "            AnathemMidModule(\n",
        "                config,\n",
        "                basemod,\n",
        "                tokenizer,\n",
        "                past_key_values_length,\n",
        "                device,\n",
        "                stack_id = i\n",
        "            ) for i in range(1, self.config.num_transformer_stacks)\n",
        "        ])\n",
        "\n",
        "        # initialize the final transformer modules\n",
        "        self.final_transformer_block = initialize_finaltransformerlayers(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            stack_id=self.config.num_transformer_stacks+1\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = False,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        output_hidden_states: Optional[bool] = False,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # embed and run through first stack of transformers\n",
        "        hidden_states, extended_attention_masks, attention_masks = self.anathem_base_stack(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2,\n",
        "            attention_mask_l3=attention_mask_l3,\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "\n",
        "        # middle stack of transformers\n",
        "        for i, anathem_stack in enumerate(self.anathem_mid_stack):\n",
        "\n",
        "            # run through each stack (1-2)\n",
        "            hidden_states, extended_attention_masks = anathem_stack(\n",
        "                hidden_states_highres = hidden_states[0],\n",
        "                hidden_states_midres = hidden_states[1],\n",
        "                hidden_states_lowres = hidden_states[2],\n",
        "                extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "            )\n",
        "\n",
        "        # hidden states (high,med,low resolution)\n",
        "        hidden_states_highres, hidden_states_midres, hidden_states_lowres = hidden_states\n",
        "\n",
        "        # run through final transformer block (pretrained)\n",
        "        out_final = self.final_transformer_block(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_masks[0],\n",
        "            head_mask=None,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        #print(type(out_final))\n",
        "        #print(len(out_final))\n",
        "        hidden_states_highres = out_final[0]\n",
        "        if not output_attentions:\n",
        "            return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks\n",
        "\n",
        "        attention_final = out_final[1]\n",
        "        return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks, attention_final\n",
        "\n",
        "\n",
        "class BertGenericClassificationHead(nn.Module):\n",
        "    \"\"\"Instantiates a basic classification head that takes the CLS token and mean of the final layer for classification\"\"\"\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "class AnathemMultiSiloPooler(nn.Module):\n",
        "    \"\"\"\n",
        "    Pools the token-embeddings along the sequence dimenions for a final sentence-vector.\n",
        "    The pooling occuras across all three 'silos'\n",
        "    The pooling consists of the CLS token as well as mean pooling, concatenated token\n",
        "    Use the pooling outputs prior to any sequenceClassification\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        dim_out = None,\n",
        "        mean_activation = nn.Tanhshrink,\n",
        "        out_activation = None,\n",
        "        dims_in = None,\n",
        "        p_dropout=None,\n",
        "        device=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # dimensions of the hiddens states being processed as inputs\n",
        "        if dims_in is None:\n",
        "            try:\n",
        "                dims_in = config.sequence_classification_intermediate_dim\n",
        "            except:\n",
        "                dims_in = [dim_out, dim_out//2, dim_out//4]\n",
        "        self.dims_in = dims_in\n",
        "        self.dim_in = sum(dims_in)\n",
        "        self.hidden_size = config.hidden_size\n",
        "        if dim_out is None:\n",
        "            try:\n",
        "                dim_out = config.sequence_classification_out_dim\n",
        "            except:\n",
        "                dim_out = config.hidden_size*2\n",
        "        self.dim_out = dim_out\n",
        "        self.mean_activation = mean_activation\n",
        "\n",
        "        #self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if out_activation == 'none' or out_activation is None:\n",
        "            self.activation = lambda x: x\n",
        "        elif out_activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif out_activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif out_activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "        # linear layer operating on the concatenated CLS tokens from all silos\n",
        "        self.cls_pooler = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            nn.Linear(self.dim_in, int(self.hidden_size)),\n",
        "        )\n",
        "\n",
        "        # pre-mean-pooling (one for each silo)\n",
        "        #self.pre_poolers = [nn.Sequential(\n",
        "        #    nn.Dropout(p_dropout),\n",
        "        #    nn.Linear(dim,dim)\n",
        "        #    ) for dim in self.dims_in\n",
        "        # ]\n",
        "        self.pre_poolers = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            self.mean_activation\n",
        "        )\n",
        "\n",
        "        # sequential layer to concatenate the mean tokens from multiple tokens\n",
        "        self.mean_pooler = nn.Linear(self.dim_in, self.hidden_size)\n",
        "\n",
        "    def forward(self, hidden_states, attention_masks, excess_cls_ids=None) -> torch.Tensor:\n",
        "        \"\"\"Combines CLS token and mean-pooling for the sentence-vectorization\"\"\"\n",
        "\n",
        "        # CLS/first-tokens from all silos, all concatenated together\n",
        "        first_token_tensors = self._get_cls_tokens_all_silos(hidden_states)\n",
        "\n",
        "        # mean pooling\n",
        "        mean_pooled_tensors = self._mean_pool_all_silos(hidden_states, attention_masks, excess_cls_ids)\n",
        "\n",
        "        # concatenate CLS and mean\n",
        "        pooled_output = torch.concat((first_token_tensors, mean_pooled_tensors), axis=1)\n",
        "\n",
        "        return self.activation(pooled_output)\n",
        "\n",
        "    def _get_cls_token(self, hidden_state):\n",
        "        \"\"\"Grabs the CLS token from a hidden-states\"\"\"\n",
        "        return hidden_state[:, 0]\n",
        "\n",
        "    def _get_cls_tokens_all_silos(self, hidden_states):\n",
        "        \"\"\"Grabs the CLS token from all hidden_states\"\"\"\n",
        "        first_tokens = [\n",
        "            self._get_cls_token(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "        # concat all first tokens\n",
        "        all_first_tokens_cat = torch.cat(first_tokens,axis=1)\n",
        "        # run the concatenated first-tokens through Dense\n",
        "        all_first_tokens_out = self.cls_pooler(all_first_tokens_cat)\n",
        "        return all_first_tokens_out\n",
        "\n",
        "    def _mean_pool(self, hidden_state, attention_mask=None, excess_cls_id=None):\n",
        "        \"\"\"Pool along a sequence dimension (for just one silo)\"\"\"\n",
        "        if excess_cls_id is None:\n",
        "            excess_cls_id = attention_mask\n",
        "        input_mask_expanded = excess_cls_id.unsqueeze(-1).expand(hidden_state.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        return sum_embeddings / sum_mask\n",
        "\n",
        "    def _mean_pool_all_silos(self, hidden_states, attention_masks=None, excess_cls_ids=None):\n",
        "        \"\"\"Pool along a sequence dimension (for all silos)\"\"\"\n",
        "        if excess_cls_ids is None:\n",
        "            excess_cls_ids = attention_masks\n",
        "\n",
        "        # pre-pool: dense-layer before pooling\n",
        "        hidden_states = [\n",
        "            self.pre_poolers(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "\n",
        "        # mean pool each silo\n",
        "        mean_pooled_states = [\n",
        "            self._mean_pool(\n",
        "                hidden_state=hidden_state, excess_cls_id=excess_cls_id\n",
        "            ) for hidden_state, excess_cls_id\n",
        "            in zip(hidden_states, excess_cls_ids)\n",
        "        ]\n",
        "\n",
        "        # concat all mean-pooled states\n",
        "        all_mean_pooled_states = torch.cat(mean_pooled_states,axis=1)\n",
        "        # run the concatenated meanpooled states through Dense\n",
        "        all_mean_pooled_states = self.mean_pooler(all_mean_pooled_states)\n",
        "        return all_mean_pooled_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J18VNXqTYNY2"
      },
      "outputs": [],
      "source": [
        "class AnathemTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=None,\n",
        "        device=None,\n",
        "        do_mlm = None,\n",
        "        do_cls = None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # default config\n",
        "        if config is None:\n",
        "            config = make_config()\n",
        "        self.config = config\n",
        "        self.do_mlm = config.do_mlm if do_mlm is None else do_mlm\n",
        "        self.do_cls = config.do_cls if do_cls is None else do_cls\n",
        "\n",
        "        # device\n",
        "        if device is None:\n",
        "            if torch.cuda.is_available():\n",
        "                device = torch.device('cuda')\n",
        "            else:\n",
        "                device = torch.device('cpu')\n",
        "        self.device= device\n",
        "\n",
        "        # get the basemodel (and its masked LM head\n",
        "        self.model_string = self.config.model_string\n",
        "        basemodelLM_pretrained = AutoModelForMaskedLM.from_pretrained(self.model_string)\n",
        "\n",
        "        # get the Pretrained BertEncoder\n",
        "        basemod_pretrained = get_to_bertlayer(\n",
        "            basemodelLM_pretrained,\n",
        "            target_layer_name = 'encoder'\n",
        "        )\n",
        "\n",
        "        # make the tokenizer (based on pretrained)\n",
        "        self.tokenizer = CustomTokenizer(\n",
        "            model_string=self.config.model_string,\n",
        "            n_cls_prepend = int(1/config.scale_ratio3),\n",
        "            n_pad_to_multiple_of= int(1/config.scale_ratio3)\n",
        "        )\n",
        "\n",
        "        # make the Embedding and first layers (pretrained)\n",
        "        self.encoder = AnathemEncoder(\n",
        "            self.config,\n",
        "            basemod=basemod_pretrained,\n",
        "            tokenizer=self.tokenizer ,\n",
        "            past_key_values_length = None,\n",
        "            device=self.device,\n",
        "        )\n",
        "\n",
        "        # get the Pretrained maskedLM head\n",
        "        if self.do_mlm:\n",
        "            # perform maskedLM\n",
        "            self.mlm = get_to_bertlayer(\n",
        "                basemodelLM_pretrained,\n",
        "                target_layer_name = 'cls'\n",
        "            )\n",
        "        else:\n",
        "            self.mlm = lambda x : x\n",
        "\n",
        "        # make the sequence-classification head\n",
        "        if self.do_cls:\n",
        "            self.pooler = AnathemMultiSiloPooler(\n",
        "                config=self.config,\n",
        "                mean_activation = nn.Tanhshrink(),\n",
        "                dims_in = self.config.sequence_classification_intermediate_dim,\n",
        "                p_dropout=self.config.hidden_dropout_prob,\n",
        "                device=self.device\n",
        "            )\n",
        "\n",
        "    def _get_name(self):\n",
        "        return 'ANATHEM_MODEL_FOR_MLM'\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l2: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l3: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # run through base-layer (embeddings, transformer-block, 1 anathem stack)\n",
        "        outputs_encoder = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2, # optional downsized attention mask for sequence-dim 1/2\n",
        "            attention_mask_l3=attention_mask_l3, # optional downsized attention mask for sequence-dim 1/4\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=False\n",
        "        )\n",
        "        if output_attentions:\n",
        "            hidden_states, extended_attention_masks, attention = outputs_encoder\n",
        "        else:\n",
        "            hidden_states, extended_attention_masks = outputs_encoder\n",
        "            attention = None\n",
        "\n",
        "        out_mlm = {'logits':None}\n",
        "        out_pooled_vector = None\n",
        "        hidden_states_highres, hidden_states_midres, hiddenstates_lowres = hidden_states\n",
        "\n",
        "        # MLM outputs\n",
        "        if self.do_mlm:\n",
        "            out_mlm = self.mlm(hidden_states_highres)\n",
        "\n",
        "        # sequence pooling (for classification)\n",
        "        if self.do_cls:\n",
        "            out_pooled_vector = self.pooler(\n",
        "                hidden_states=hidden_states,\n",
        "                attention_masks=(attention_mask, attention_mask_l2, attention_mask_l3),\n",
        "                excess_cls_ids=(excess_cls_ids, excess_cls_ids_l2, excess_cls_ids_l3)\n",
        "            )\n",
        "        #\n",
        "        if return_dict:\n",
        "            return {\n",
        "                'hidden_states':(hidden_states_highres, hidden_states_midres, hiddenstates_lowres),\n",
        "                'pooled':out_pooled_vector,\n",
        "                'logits':out_mlm['logits'],\n",
        "                'attention':attention,\n",
        "                'extended_attention_masks':extended_attention_masks\n",
        "            }\n",
        "        return hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fb064cacf0e243299a2d092facae8c79",
            "be7af49d0afe4ecdaa800be969d5a3e7",
            "560c716068a645d596cc2fe9b886c0ad",
            "08c60bb508854cc9b6772ab78502b6fb",
            "e84136de295d4d39b44c908ff2458ba9",
            "2166426a7a224f1da2065f3221463693",
            "77d712d32c0f491cb9a58df33b012b0c",
            "235afab600844a9f8ef8f45cdba142e0",
            "c7537c19825a49cd8f3343c153fe56ef",
            "497aad7b9ab34f158382033f65d9a8c9",
            "814c0fc7e64c49bfa85d5087d1e07cb4"
          ]
        },
        "id": "jYu06BPCY1Oz",
        "outputId": "a8d0df70-d7a6-47ac-ab3a-e6377dd18a37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb064cacf0e243299a2d092facae8c79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelstring_teacher_mlm = 'bert-base-uncased'\n",
        "model_string = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "\n",
        "config = make_config(\n",
        "    modelstring = model_string,\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    do_mlm=True,\n",
        "    do_cls=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496,
          "referenced_widgets": [
            "19e70f5c3ae04d4b8b4a86c1233418be",
            "c7fcfc2727db445695b908ffd3370feb",
            "546b278b05e643a4905055d1d7ffeea5",
            "289aa49d154a496d9804cf30545bc5fc",
            "f54be5e820704ad2b31b6b7a6b946181",
            "8a0851189dae4fbdb953f6afe6f3ba29",
            "01f4a70e089f4fe5abb0d9246aeee403",
            "195b549a3cd745ffbe55e24f5865b1da",
            "fe156388571b4c63b5fc5f5ca857e522",
            "36c0e136fa3f400bab5deec7a0aff11f",
            "bcee86d4105743f5a69c595029994bc8",
            "9c8b871e03af41ada7990e7b76084f84",
            "33ae5a6ee9244aeea02e10990e8dd3da",
            "470a84311bbf40c6ae6322d6edc353ae",
            "8974203b2bde4395b3144ffe61596643",
            "d4ea11ee38044f7cb7ffe1a5b018bda7",
            "5f1b9961c6b14a1a92f3cb2c82883a17",
            "dfd3f1f64d81471083416a3e4ca6aa60",
            "9568bdb74f3e450f91b3558cf5ad5da1",
            "b7b946e1ad95455b818512986f83f7cd",
            "5fdca1f2b388437fac7624c0eca1ec26",
            "1c00f260ca44415c9c2cc342c9cab470",
            "476c5672e7784cda8255af2049de1ecd",
            "73e2bfea29de4c47b0c60590deff9771",
            "4326c46139fd4b6882d864400e35a9bc",
            "a53d537c8c0e48d1a77fbc22e5c41402",
            "4eba976ecf5145e0a60cc8a838bff5c9",
            "2750de9a4c5740b080f5a8145de41111",
            "ecf9c5705a7b491c82d4e8b5cbd8c439",
            "e76cddc6d7d04d3fb01c11225ec1b6a2",
            "9ad1276e945e4915a079e97e06048ee9",
            "02191a5509094a0abcf8862d3a8ee4cd",
            "5c69e45579f54fc6b2415ebbad4da477",
            "8dbb1fccc920458cbffc7029953e5363",
            "29e9e92bc30c4b2f89416481b4fb1455",
            "1c5678cdeb204d21b94526ccdab34d32",
            "dea6b34486294d388d68aa9ef3aaa281",
            "e34566724c6e4598860e77d6b710faf8",
            "b34433ff3b52491fb5829b9f1522e162",
            "5250f6a6e5c34894adb20a9120388ba0",
            "0381ff6309df4052bb0ce823e7ff741b",
            "bd79d8ce5e28404c988f4965873a2f2c",
            "b70156e5cb144e75b97697a2439d9a5d",
            "96e7d97dc8f44c7d873060a89f82ce0e",
            "aa099b9c51d6447a9a22fb13b103cb41",
            "03a6cc127c8c4f03bab0b31bb3a1721b",
            "08fbdead6ab540d4a1d2d8f06879e417",
            "5f0512fb3607471f817b5c215d94e4d8",
            "0457dfcb462c4173bbfb7890bb043c97",
            "d6ccd976679e45fcbf6d6b5d06360ea6",
            "f6c454dc6dcb4528b7b05b83c72640fc",
            "029adddbce024f50bc5d7a06d304632d",
            "d2a8de725a934927b52792351e0d5099",
            "dcd68849bd0a44238fbb9bec129b0511",
            "3312caf3fc76420ead7f4945675df52a",
            "169e8fa7a73d4797945e98ccba4cd10c",
            "b072faf11c504e39939d1ad4534f9112",
            "f3707c74969e4f6c84d6a36b59d6fa9e",
            "32184fc9b099416a8d49ef3c3f8c3a2e",
            "2b95b44611524401ac7826dab5a21aa8",
            "3fb4b68eda9f481abbc7b2456644e16b",
            "3c54d6fd6a004ed98c1cb595a0bb84a0",
            "7f511160291e4a4a82f8694772449ea8",
            "91eebca40ce344039704522c4570353c",
            "2137d76adc0b4235bcf4e52ab94ae445",
            "fcb506371e6e4cd2947988d6c7050809",
            "a5967030d5aa4581b66d319588b92db4",
            "6baecbf668bc4a6f93be03e5f671b76a",
            "a33ab96c585c411ab148d76865b848f2",
            "5589d685cbc94ea0a045dcba0e69a7e5",
            "01ac22caf29c4b2baf0ebc428f3398b3",
            "1d322e088a6a4904a0b99740d8d4e45c",
            "20402646761d4cf3975763fc130d6ff5",
            "5183ef3eec0d4bdfbcc5544b0fec573b",
            "3751db7e581847efa6c224dd50c9b7bb",
            "600bc8f5877547aca898f8c85902040e",
            "b65ef6da8ad34e2285813544d00bf3e5",
            "4ef3bcbd56164ddaac3068fb93a66630",
            "0cbd831de3c64f4aa269776dc73c5e28",
            "d947bfe9101646c9a7222ada482d4455",
            "8e9137be11744d329bceecd548d91025",
            "326c1c104f254d1189c78c6abd318451",
            "a4848184b58645b2a572c6e1a1231f05",
            "92d450929c8e45539c2726eaf96d5ddb",
            "d9a90b08aaec44d9962e8c090b8d0baa",
            "70225a6a843d4ccf87d1b43d4cf1895b",
            "8c45ce351a9b45dda4359b706ea36aba",
            "9e2644d3c3bb40aa9eba632e756112a3",
            "a6770d150cfa459780d5adb12fc7c7b8",
            "78608a4a3a8f4c119d9a0128153a39eb",
            "91de7341a97a4415b5656ee33fe6395f",
            "82f1dc2ca5ef4e45818a2b9107732d58",
            "5e1a387877054dacbb6bf1fa32b08d7a",
            "48729429682c4b37a624ba2eb55d1966",
            "6eeb3579c2b644a6b8501cc246083c97",
            "8f1bf2df4214449483a37dc84d9f3c43",
            "9afa2b87f4a94a58b7c639a0a7f63813",
            "8ae32d0dd19e40e8a0fc4b04b325abd6",
            "20ae65dc26cb4ab98a9637dfa2bd5a62",
            "641fd37171904fb590b7877d8403aeea",
            "e8f710e2dcfc40398ce16a4ac265cc26",
            "377a7fa0ebce4c8a96a55c6e1c08403f",
            "5ed5174d9d6c4680bb7cc1e803184102",
            "2c148a8aa9fe4f30a69392f10a350eac",
            "177dee7aa0754c7db2b595f83a4eb105",
            "2fe3c4d6e4774be691e7c0551fd334ff",
            "6ff3a2b6be1f4220b0e3c055fc587c7e",
            "af816340aae74a81a6eaf63a1933f5bf",
            "91bcf74809894d39b5199ca23691f00f",
            "85a35c16364f4c6880dbbecf061faf44"
          ]
        },
        "id": "Y7HRRYhrfm18",
        "outputId": "0fc7cf35-f252-47f1-a9a0-3b2ef5615da2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e70f5c3ae04d4b8b4a86c1233418be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c8b871e03af41ada7990e7b76084f84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "476c5672e7784cda8255af2049de1ecd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dbb1fccc920458cbffc7029953e5363",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa099b9c51d6447a9a22fb13b103cb41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "169e8fa7a73d4797945e98ccba4cd10c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5967030d5aa4581b66d319588b92db4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ef3bcbd56164ddaac3068fb93a66630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6770d150cfa459780d5adb12fc7c7b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "641fd37171904fb590b7877d8403aeea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "anamod = AnathemTransformer(\n",
        "        config=config,\n",
        "        device=None,\n",
        "        do_mlm = True,\n",
        "        do_cls = True\n",
        "    )\n",
        "\n",
        "teacher_mlm = AutoModelForMaskedLM.from_pretrained(modelstring_teacher_mlm)\n",
        "\n",
        "\n",
        "from torch import Tensor\n",
        "class TeacherEmbedder:\n",
        "\n",
        "    def __init__(self, pretrained_name = 'intfloat/e5-large-v2'):\n",
        "        self.pretrained_name = pretrained_name\n",
        "        self.teacher_tokenizer = AutoTokenizer.from_pretrained(pretrained_name)\n",
        "        self.teacher_embedder = AutoModel.from_pretrained(pretrained_name)\n",
        "\n",
        "    @staticmethod\n",
        "    def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "    def forward(self, input_text, prepend = 'passage: '):\n",
        "        input_text = [prepend + s for s in input_text]\n",
        "        with torch.no_grad():\n",
        "            batch_dict = self.teacher_tokenizer(input_text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "            outputs = self.teacher_embedder(**batch_dict)\n",
        "            embeddings = self.average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "        return embeddings\n",
        "\n",
        "    def __call__(self, input_text, prepend = 'passage: '):\n",
        "        return self.forward(input_text)\n",
        "\n",
        "\n",
        "teacher_emb = TeacherEmbedder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_BdVwTUsWj1",
        "outputId": "2e956c25-393b-4fc3-996e-5b18796b9e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertOnlyMLMHead(\n",
            "  (predictions): BertLMPredictionHead(\n",
            "    (transform): BertPredictionHeadTransform(\n",
            "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (transform_act_fn): GELUActivation()\n",
            "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(anamod.mlm) # MLM head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PaoAjDffxVd",
        "outputId": "868f0300-5add-4258-da89-da358ddf8b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids', 'attention_mask_l2', 'attention_mask_l3', 'excess_cls_ids_l2', 'excess_cls_ids_l3'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 512])\n",
            "torch.Size([2, 24, 256])\n",
            "torch.Size([2, 12, 128])\n",
            "torch.Size([2, 1024])\n",
            "torch.Size([2, 48, 30522])\n",
            "torch.Size([2, 48, 30522])\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'a', 'standard', 'liability', 'clause', 'is', 'a', 'wai', '##ver', 'clause', 'that', 'states', 'that', 'one', 'party', 'won', \"'\", 't', 'hold', 'the', 'other', 'liable', 'for', 'damages', ',', 'losses', ',', 'or', 'costs', 'associated', 'with', 'issues', '.', 's', '.', '.', 'it', '.', 'the', 'it', 'it', 'it', 'parties', 'one', 'party']\n",
            "Anamod\n",
            "['-', 'the', '-', '-', 'a', '-', '-', '-', '.', 'a', '-', '-', '.', '.', 'is', '.', 'the', '.', '-', \"'\", 's', '.', 'the', 'other', ',', 'for', 'me', ',', 'my', ',', 'or', 'the', '-', 'with', 'the', '.', 'the', 'he', 'he', 'he', '-', '-', ',', ',', ',', 'the', '-', ',']\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'it', 'usually', 'consists', 'of', 'two', 'elements', ':', 'a', 'trigger', 'event', 'or', 'circumstance', 'and', 'a', 'trigger', 'obligation', '.', 'the', 'trigger', 'event', 'or', 'circumstance', 'is', 'the', 'violation', 'of', 'the', 'agreement', ',', 'misconduct', ',', 'or', 'negligence', 'of', 'the', 'ind', '##em', '##ni', '##fying', 'party', 'or', 'its', '.', 's']\n",
            "Anamod\n",
            "['-', 'the', 'the', '-', 'it', 'or', 'the', 'of', 'two', 'of', ':', 'a', 'the', ',', 'or', ',', 'and', 'a', '-', 'of', '.', 'the', 'trigger', '-', 'or', '-', 'is', 'the', 'part', 'of', 'the', 'or', ',', 'the', ',', 'or', ',', 'of', 'the', 'ind', '##em', ',', ',', ',', 'or', 'the', '-', 'the']\n",
            "torch.Size([4, 1024])\n"
          ]
        }
      ],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "inputs = anamod.tokenizer(text, add_special_tokens=True, return_tensors='pt', padding='longest')\n",
        "\n",
        "print(inputs.keys())\n",
        "inputs\n",
        "\n",
        "outputs = anamod.forward(\n",
        "    input_ids = inputs['input_ids'],\n",
        "    attention_mask = inputs['attention_mask'],\n",
        "    attention_mask_l2 = inputs['attention_mask_l2'],\n",
        "    attention_mask_l3 = inputs['attention_mask_l3'],\n",
        "    excess_cls_ids = inputs['excess_cls_ids'],\n",
        "    excess_cls_ids_l2 = inputs['excess_cls_ids_l2'],\n",
        "    excess_cls_ids_l3 = inputs['excess_cls_ids_l3']\n",
        ")\n",
        "# hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "\n",
        "outputs_teacher_mlm = teacher_mlm(input_ids = inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "\n",
        "print(outputs[0][0].shape) # full hidden state sequence\n",
        "print(outputs[0][1].shape) # mid hidden state sequence\n",
        "print(outputs[0][2].shape) # small hidden state sequence\n",
        "print(outputs[1].shape) # sentencevector\n",
        "print(outputs[2].shape) # mlm outputs\n",
        "\n",
        "#\n",
        "print(outputs_teacher_mlm['logits'].shape) # Teacher shape mlm\n",
        "\n",
        "predicted_token_ids1 = outputs_teacher_mlm[0][0].argmax(dim=-1)\n",
        "predicted_token_ids2 = outputs[2][0].argmax(dim=-1)\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][0].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][0].argmax(dim=-1)))\n",
        "\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][1].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][1].argmax(dim=-1)))\n",
        "\n",
        "# try to embed text with the teacher_emb\n",
        "text2 = input_texts = [\n",
        "    'query: how much protein should a female eat',\n",
        "    'query: summit define',\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"\n",
        "]\n",
        "sentence_embeddings = teacher_emb(text2)\n",
        "print(sentence_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzb5l9wymf4D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "1a3234bae89d4c1eb7e84da16675cde8",
            "7c50e41b12ab40ae88db5a68806a5287",
            "9a675022c08043438f0288c2dc3d1692",
            "42ed4267878a46a9a1a1de7f63006ab4",
            "a587d42c581c4f75984a189ebe1b1831",
            "1aea1f6de91a43a4b491c82ffc1522be",
            "3c45e6794f974b4199098bcd87765e63",
            "ff58b4945b004e9996568c228986d287",
            "1290569b6a4d490fbfc8ca3915983263",
            "ba76516f42224f79a9dfe8a36385bb22",
            "c6b2dc48588b482f80e9a2473dc5b452",
            "e7bd0a23537441b6a41373c7db399423",
            "7bdb5cce9c364437970f01220e5f0aa3",
            "5df7aa079833485bbde65e4658b496e0",
            "e9149263e2264fe6b5e5cb50f67d55c2",
            "e3712984d7774865be2c1e97faf82d57",
            "3e72971bf9804c3688c24e0a3eca0da7",
            "d36c80ffd8824fdb8e1e344f41fa3669",
            "283065bbec654b89a6be726e3fe790fd",
            "ebf0c7ac01e441d68a38cac5fed89d00",
            "ab8bf4aa34c5452d8c6d01df44402eea",
            "c1ad349038c94c1f9ec7b1d0d7245699",
            "fc40e712ccca489e8cb2eaadbc47aa54",
            "d87e9ee37dfe44bcad7b97ccfef0f5ff",
            "afd68f4512e045c2bfaa46eb36d4ab5a",
            "db1f664494c94faf8998df1f25718b9f",
            "63a2424581894ab48ad61b9f38cc882e",
            "44ce4959b2bc410a8b455eb2adb7ffc9",
            "422ac21cdb1d45a8a0814ef00c9769ff",
            "f387685057a6405f86292bd9ce5df000",
            "808dad49922a431d9c43faf48478a069",
            "5c96dd4ef67f4900af004f322706921f",
            "c519b80ce005494caf41456ec90111bf",
            "694f0df64a4b433aa22afef48d968090",
            "75d264b002cc4c3889089fe28f6cfa80",
            "f6a686a076954e0c9c5d11429a14d582",
            "9f512b3c83bf4fcaa1640cf5cdbea8c8",
            "282f350bdadd41fa82b37f527ffe8a63",
            "052465580f854b15be0d29e9dc59125b",
            "619bcc47eac24a098ac5908bddc4297d",
            "0a320f7b8bba47ddb97d2aff966e162f",
            "0e215f7f87fc48bfbb3e74c9c97b23a8",
            "5ab64a9556124cf892f33cc9973240ea",
            "656cb0e3b85c4a57936749caa02f664d",
            "f7ca459667fe48c2a54d0ca13ccfe114",
            "91738a91e20344f1b848ccc39bd0b686",
            "ae85f3dd9b864de7897e02a2313c8093",
            "e97d23572a21475fa4b5b9fa4454d4cc",
            "32f65d2703c048929de10720219fdf53",
            "f9d88bd9fdda49bcbf01366f8fe6fab2",
            "ca5cfab63b2d47869f69b772f9801d69",
            "ea00ba0feb164981bdb521803fd29049",
            "16501e0f5de84fc7bbbdcc9b37f61d85",
            "68db1531b9574e72a2ff0d52995a7347",
            "eeafa1a037dd42a88774f76ea6275360",
            "e891d996e42f425cb2b31d563dfc77ef",
            "216e1650231e471fa0d88e3d73bf6da0",
            "d1dafb9eb15541489d740cbf202fac2f",
            "e362a74248d24aa28ab7dd3500c9d303",
            "1eb78591c14840daaf6741730f2280f8",
            "a2bbd67afcb9463cb0f78d7a24c5f126",
            "ad9c165248ef4e0b9c357316b95f66af",
            "adc06005b98c44f0a6308cbd4f6a3527",
            "eace7bc2187b4dd0af47dbee9327903a",
            "a9f66a8eed1443d099d0fadab83d02e9",
            "292c0b150eb84f06a012e2084b035350",
            "755e3809aa3043f99d3664955a3a2c03",
            "44d07abd85374cca92698119139b140e",
            "00001f9f055045f9ae35f94f76be8fe4",
            "1e7d06e9df9b4a88a003bbba433c1cae",
            "a87f8ff9f575436da0dcf9a31642f7b7",
            "1deae35c0489408fa7e374cd93cca642",
            "260f38a6c52d464999f74443c04cdc03",
            "c16dd57325504698b35f155d1bd040b5",
            "7950d803ab5b4c4ab10dc9e0902e34b1",
            "d151de5a1862426f9d3ab2aaae73f4d9",
            "3963ddae09b14417abf20a566ce82a03",
            "03a8f530cfb0469998f56dcca5f00803",
            "cafc757655d74a2697f4ba566b3623ee",
            "46cd1079cad04e7ea04959e14225b7fb",
            "c508e67d54c24888b82b66108681da19",
            "b08eba43d39846869bdd9050836be1cb",
            "d1837578698f426d8c65a40770a3488c",
            "fdf37a5ac48c477d99318631238a5756",
            "ef504e4ab1384063bff714e1649e0aa3",
            "7b387dec327543f79f957f81fb651cc7",
            "d71e718353ac40788febf07676b3cb25",
            "addf3619a835489f8d9f3ce4498daf36",
            "3315267c32f24d29804c12af760956aa",
            "31fef27ae4d44fa691185c3fa750756a",
            "11db36da26a94bae9ad00e99a10d8c5a",
            "f4bb56cde5b042e8821ee26d25da4ea2",
            "312b0a411cf7451d845fae7b77dff7d6",
            "fa205a1da88e418a881efb0963042e9d",
            "30f6111712e2491198ac03400ef0ce7d",
            "c5323c16a9ca4decbe25c651a14517de",
            "eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "ffe8145192c34433b3140f05b5b2528f",
            "3988d9e57bc841b49a5079130f071dfc",
            "d9bcbb8cd61d4fa5b9e0b95304f8969c",
            "8ea68f6b18c342938de8be19d3896038",
            "0b0c4175d283414ab014c95269b4421b",
            "00c7829ca16746089c8896865f374b1f",
            "f9f77be1c3044483bbd3714a5a45e2ad",
            "b42f3b105ff645dcb58805289594baad",
            "d4214693adb54e44b31fd40e549802b8",
            "b17a0dd6bd24481e8e597415bfc02c87",
            "2c43b4c9b58842acaf321862c3a1625d",
            "99ef066e53974658a59443c917b2c615",
            "98bd45b05dda4319adf853b5104f0a0a",
            "0003c5e497294b5abf83ff5edbf90261",
            "28542ed3d1b443c9a7ba7074825ee208",
            "7c01fc1aabb0486f9f1f0674b46b5481",
            "6b349f8f7890488eaa05b156ec971bf6",
            "1602c7712db64b829a6ed1fa73367a1e",
            "d72812af3cd8475f8a76a8ff3ec236e9",
            "40731cc8e1a245868c9bf6d0972c0467",
            "6f102144e4fd4840b77808f1e6ff7697",
            "82084929de714135a363f5693f4a0aac",
            "f3537b58aca04f398663d6a8f6bd7cf8",
            "0ea16b4f2c6d428191dd7d31d21ad659"
          ]
        },
        "id": "b2ueft2IwxIr",
        "outputId": "4d0bdc1a-4261-4233-cfc0-d686ea8b1e84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a3234bae89d4c1eb7e84da16675cde8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7bd0a23537441b6a41373c7db399423",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc40e712ccca489e8cb2eaadbc47aa54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset glue/mrpc to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "694f0df64a4b433aa22afef48d968090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7ca459667fe48c2a54d0ca13ccfe114",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e891d996e42f425cb2b31d563dfc77ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "755e3809aa3043f99d3664955a3a2c03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03a8f530cfb0469998f56dcca5f00803",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3315267c32f24d29804c12af760956aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9bcbb8cd61d4fa5b9e0b95304f8969c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0003c5e497294b5abf83ff5edbf90261",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHq4Udecy1S6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSdXchNStSMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "pQXS1wenz68U",
        "outputId": "09fec374-2e3b-47d5-d4eb-02ab69561b78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f52e91588ea352bb.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-055028f389e5>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hit %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m: hit 19"
          ]
        }
      ],
      "source": [
        "\n",
        "## Test a batched inference routine: including loss calculations\n",
        "## steps:\n",
        "## 1) tokenize inputs internal to a torch dataset (encode_plus?)\n",
        "## 2) loop through dataloader, with a MLM collator also set?\n",
        "## 3) do inference using teacher\n",
        "## 5) do inference using anathem\n",
        "## 6) loss\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# load dummy dataset\n",
        "dataset_glue = load_dataset('glue', 'mrpc', split='test') # small set\n",
        "\n",
        "# tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "# tokenize\n",
        "dataset_glue = dataset_glue.map(lambda e: tokenizer.encode_plus(e['sentence1'], add_special_tokens=True))\n",
        "print(dataset_glue.features)\n",
        "dataset_glue = dataset_glue.remove_columns(column_names = ['sentence1','sentence2','idx','label'])\n",
        "print(dataset_glue.features)\n",
        "_ = \"\"\"\n",
        "{'sentence1': Value(dtype='string', id=None),\n",
        " 'sentence2': Value(dtype='string', id=None),\n",
        " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
        " 'idx': Value(dtype='int32', id=None),\n",
        " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
        " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
        " \"\"\"\n",
        "\n",
        "# MLM collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")\n",
        "\n",
        "# MLM distillation loss function (kl-divergence between teacher and student outputs)\n",
        "loss_fn_mlm_distil = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "loss_fn_mlm_labels = nn.CrossEntropyLoss(ignore_index=-100) # non-masked tokens have -100\n",
        "weights_mlm_distil = 0.5\n",
        "weights_mlm_labels = (1-weights_mlm_distil)\n",
        "\n",
        "# dataloader with MLM collator\n",
        "dl_mlm = DataLoader(dataset_glue, collate_fn=data_collator, batch_size=4)\n",
        "\n",
        "# optimizer\n",
        "optimizer = AdamW(anamod.parameters(), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "\n",
        "for step_i, batch in enumerate(dl_mlm):\n",
        "\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    # label loss\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "    optimizer.zero_grad()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    #\n",
        "    optimizer.step()\n",
        "\n",
        "    if ((step_i+1) % 20) ==0:\n",
        "        raise NotImplementedError('hit %d' % step_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyCvyxgiqAdm"
      },
      "source": [
        "## MultiTask Training: adapted from s-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "dab6a9ff832540bfae51a3f0dcfedfba",
            "c5adcad970e4455cbf797f14e2e5303e",
            "928bc9d9e240469298d2a267fe3b9e65",
            "24e977d511bd4f03bc8d730cd4c86027",
            "4b4dae6b5bd5474491e1c86a6e462ebf",
            "21f6c046574b4badbf5dac2bd4989d67",
            "e844aa942c604f17b61375f59aad56f3",
            "595530337aab40f6b5cc24d69b3ebaf9",
            "85aa23b715f248248204a2bdf3e5f7ec",
            "3f2b4543fdb94a1d9153de7f18d108be",
            "da3eb201a16240aaa91baf19b49d4209",
            "f53073dd81bf427188a9cfde75c18bff",
            "2b5f6a6687b34036bd5a87c8b61dc2c3",
            "b0546b4b929f4fe3927af49ab119d99a",
            "37e0abc511f04624986368ef45b50131",
            "d365ebcd816a44da80bc74870dd008bd",
            "d265db9a419d4edfbdb91e4bd8f78846",
            "aae2a30b7f474dbcbf55aa677b9518f9",
            "df31cc0682014cdb881817de1c02288f",
            "01fa51a473a6472da89d47bf1116e575",
            "33088ffab85f4898bc39a1167e70388c",
            "1672001c1d7e449f9cc0ce76fcf50fc8",
            "fc2d3eb4b1304b97bf336245736983ec",
            "4d798a40b2a24c4f8ce823023d75ea6a",
            "429379eb4c4f452d94a52521911811a8",
            "49a90c227b9342ddbb670c9fe85591cc",
            "843d11a2271246f49dbabe80fc4762d4",
            "f10d3cde2d7b4121971d8e19e3362b30",
            "4818654025b94f38a631b2bcdf36014c",
            "f68c38cc7bf84db2ab1540ca985599e2",
            "d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "8a1ecdd97d194a9ab63a15980d1e2e31",
            "5dd1df4079d44b1aad849b4a0a5e3b55",
            "2958b232a65d47d7950e040ddd583898",
            "82db512ae4ce4b1fbde3aed3d893e032",
            "8b3982acce834b95a6f318dfb78add1c",
            "3df2e72406454de7ade25cfe0fca7295",
            "979449deb4254629b80f0089584c851a",
            "cd748fe04232441abb30f153e54f9890",
            "8eda2864b2774815bd6d860c1fdf2625",
            "09a93d25cd25426e9c60222b29321889",
            "0db15040be1242378220fa56a21aba28",
            "7834f7deaa3b43669cd0de893fa62448",
            "cfa5b162648c4abca773a478c3e3beb9",
            "2a7388d890b2460c86be4cd32187f319",
            "38b91d162c304c6eaad444f0abffa931",
            "0f331a136adf425f87a1a35682256cd9",
            "1f65726d2e20471e99928e5dc96726c7",
            "dae9d080adfc4bfbba896820bbf57c3b",
            "9ef72b344a964832bd2b19140d230f7b",
            "b719af868833401c86d45d2ae059c868",
            "46f2289d8f6c460892864f1ef5ad8e08",
            "f81a1dd1a8b547b39297478219b41c81",
            "454aeb5a95b94bb580698d8d2f62f43f",
            "a417b74f6fdb4dedbd6bf3408d0dea69",
            "42c13d8f7c694c6599c0a2e10ca0765f",
            "0322aeeda2bd42c1b8ce348bd56424eb",
            "c0908ccc452b42e681765c37a139e878",
            "251219f28bd54de9a608686672dddf0d",
            "e982215023c24a3caf881dd3986cca86",
            "5398b51140574840979cfe9ae2640c96",
            "d6012c2d60024501a1bd8c529bf055e6",
            "d74fd39704b44cea8f012402e7449a80",
            "f5e5dd22e0b24a30a485b54dbdacf1cf",
            "7e61f641028148e988678a2ecbe24a21",
            "df8de4914b3f4c51b4e048f053a0e009",
            "868c8d0c5a4a4535a00dd833ad0dbb6f",
            "7c1ea655a2844e0e81c89529f95acb4c",
            "f4a51d5c122645a5a58acfbadb0cf752",
            "5bd4908665db4c8baac9d52a40a1c28e",
            "000f6133e191461c893cffdc6783a5f9",
            "b5fca62c132b4b9c9af64955480ac905",
            "7081369f016f46ec9ad16edcedd027b0",
            "8631f393c12e4ebaa57838a4f1c1efb0",
            "bc7e0e6c4b154e55875c6fddc0aac6f0",
            "46ff0481a7a94abb9cea91aaacd1ea29",
            "05fd99843ed746d1baf705e6c31881f6"
          ]
        },
        "id": "1C-THFy0tPik",
        "outputId": "5118abac-4cb3-47f3-d368-683d051edb47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab6a9ff832540bfae51a3f0dcfedfba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f53073dd81bf427188a9cfde75c18bff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.88k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc2d3eb4b1304b97bf336245736983ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset multi_nli/default to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2958b232a65d47d7950e040ddd583898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a7388d890b2460c86be4cd32187f319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42c13d8f7c694c6599c0a2e10ca0765f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "868c8d0c5a4a4535a00dd833ad0dbb6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset multi_nli downloaded and prepared to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "### Normal label-based losses (MLI\n",
        "# -- https://huggingface.co/datasets/multi_nli\n",
        "dataset_nli3 = load_dataset('multi_nli', split='train') # 383k examples\n",
        "\n",
        "# I think I should keep the text untokenize for the multi-task, maybe use the default collator from sbert\n",
        "dataset_nli3 = dataset_nli3.remove_columns(\n",
        "    column_names = ['promptID', 'pairID', 'premise_binary_parse', 'premise_parse','hypothesis_binary_parse', 'hypothesis_parse', 'genre']\n",
        ")\n",
        "\n",
        "dl_mli3 = DataLoader(dataset_nli3, batch_size=4, shuffle=True)\n",
        "\n",
        "\n",
        "# make a classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZRIJYI8eBBC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClassifierMNLI3(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size = 512,\n",
        "        do_subtract = True,\n",
        "        dropout = 0.1,\n",
        "        n_labels = 3\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.do_subtract = do_subtract\n",
        "        self.dropout_p = dropout\n",
        "        self.n_labels = n_labels\n",
        "        self.size_of_concatenated_inputs = self.hidden_size*2*2 + self.do_subtract*self.hidden_size*2\n",
        "\n",
        "        # final output\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Dropout(self.dropout_p),\n",
        "            nn.Linear(self.size_of_concatenated_inputs, self.n_labels)\n",
        "        )\n",
        "    def forward(self, input1, input2):\n",
        "        features_concat = torch.concat((\n",
        "            input1,\n",
        "            input2,\n",
        "            torch.sub(input1,input2)\n",
        "        ),axis=1)\n",
        "        return self.layer(features_concat)\n",
        "\n",
        "\n",
        "# Make classifier for MNLI labelled data\n",
        "classifier_mnli3 = ClassifierMNLI3(\n",
        "    hidden_size = anamod.config.hidden_size,\n",
        "    n_labels=3\n",
        ")\n",
        "classifier_mnli3.train()\n",
        "anamod.train()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(anamod.encoder.parameters()) +  list(anamod.pooler.parameters()) + list(classifier_mnli3.parameters()),\n",
        "    lr=0.0001\n",
        ")\n",
        "\n",
        "# make loss function (3 labels)\n",
        "loss_fn_nmli3 = nn.CrossEntropyLoss()\n",
        "weights_mnli_distil = 0.5\n",
        "weights_mnli_labels = (1-weights_mnli_distil)\n",
        "\n",
        "loss_fn_mnli3_distil = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "rBSnisaFT-3O",
        "outputId": "7fa6b430-8619-400b-cf57-20a3c5e76fd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6361832022666931\n",
            "0.5656223297119141\n",
            "0.3880550265312195\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1cec90a56f65>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# NEXT do distillation loss with teacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfeature_teacher_nmli1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mfeature_teacher_nmli2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hypothesis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# MNLI distillation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, batch_mnli in enumerate(dl_mli3):\n",
        "    optimizer.zero_grad()\n",
        "    # get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # mnli predictions n labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # mnli binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label']) * weights_nmli_labels\n",
        "    #loss_cls_nmli3.backward()\n",
        "\n",
        "    # NEXT do distillation loss with teacher\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%3 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "had3LEY4a5rT",
        "outputId": "6e2912df-f412-446d-f31a-f3a8710cbe98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3287630081176758\n",
            "1.1084638833999634\n",
            "1.1774473190307617\n",
            "1.0645709037780762\n",
            "1.091556429862976\n",
            "1.1649658679962158\n",
            "1.319928765296936\n",
            "1.1654601097106934\n",
            "0.9826673865318298\n",
            "1.1563453674316406\n",
            "1.0446501970291138\n",
            "1.1165382862091064\n",
            "1.1049705743789673\n",
            "0.9217707514762878\n",
            "1.14559006690979\n",
            "1.1429061889648438\n",
            "0.9149771928787231\n",
            "1.207316279411316\n",
            "1.1845396757125854\n",
            "1.2629420757293701\n",
            "0.9769338369369507\n",
            "1.0895546674728394\n",
            "1.0898280143737793\n",
            "1.1648684740066528\n",
            "0.9611557126045227\n",
            "1.044935703277588\n",
            "1.144046425819397\n",
            "1.099448561668396\n",
            "1.0884103775024414\n",
            "1.142393946647644\n",
            "1.0853071212768555\n",
            "1.1239224672317505\n",
            "1.0658488273620605\n",
            "1.1993112564086914\n",
            "0.9642707109451294\n",
            "1.182077407836914\n",
            "1.3221166133880615\n",
            "1.1279082298278809\n",
            "1.0723700523376465\n",
            "1.1399314403533936\n",
            "1.0013256072998047\n",
            "1.1049387454986572\n",
            "1.0147031545639038\n",
            "1.2314361333847046\n",
            "1.0651648044586182\n",
            "1.1327135562896729\n",
            "0.9887092709541321\n",
            "1.0250582695007324\n",
            "1.1199613809585571\n",
            "1.094027042388916\n",
            "1.091330885887146\n",
            "1.098750114440918\n",
            "1.1193275451660156\n",
            "1.1657143831253052\n",
            "1.0800719261169434\n",
            "1.152091383934021\n",
            "1.1550073623657227\n",
            "1.0005279779434204\n",
            "1.063902497291565\n",
            "1.0364967584609985\n",
            "1.0193161964416504\n",
            "1.1669244766235352\n",
            "1.055404543876648\n",
            "1.2059553861618042\n",
            "1.1156867742538452\n",
            "1.1356735229492188\n",
            "1.1261953115463257\n",
            "1.0520744323730469\n",
            "1.0741896629333496\n",
            "1.0739905834197998\n",
            "1.1333951950073242\n",
            "1.0113921165466309\n",
            "1.1244165897369385\n",
            "1.1339558362960815\n",
            "1.125321626663208\n",
            "1.0819061994552612\n",
            "1.1043788194656372\n",
            "1.108479380607605\n",
            "1.148271083831787\n",
            "1.0951212644577026\n",
            "1.1449416875839233\n",
            "1.0795189142227173\n",
            "1.1403652429580688\n",
            "1.086578130722046\n",
            "1.0184922218322754\n",
            "1.1535804271697998\n",
            "1.0355476140975952\n",
            "1.120854377746582\n"
          ]
        }
      ],
      "source": [
        "# Combine the teacher training with classification\n",
        "optimizer = AdamW(list(anamod.parameters()) + list(classifier_mnli3.parameters()), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "for i,(batch_mlm, batch_mnli) in enumerate(zip(dl_mlm, dl_mli3)):\n",
        "    optimizer.zero_grad()\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # mlm teacher outputs\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "        # to do this, I'd need to have the original text, and NOT pre-tokenized text\n",
        "        #teacher_emb(input_text=batch['premise'], prepend = 'passage: ')\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    #loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    #loss_mlm_distil.backward()\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "\n",
        "    # loss on paragraph embedding\n",
        "\n",
        "    # BACKPROP MLM label loss and distilloss\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "\n",
        "    # NLI task: get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label'])\n",
        "    #loss_cls_nmli3.backward()\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%4 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "NWWBkB_gqEkE",
        "outputId": "6a69aabe-43c8-42bc-dd5f-f15a8840b73d"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8c7bf2d1f796>\"\u001b[0;36m, line \u001b[0;32m319\u001b[0m\n\u001b[0;31m    self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "class TrainerMultiTask:\n",
        "    \"\"\"Adapted from the uklab/sentence-transformers .fit() function\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            do_reload = True,\n",
        "            epochs_total_lifetime = 5,\n",
        "            scheduler: str = 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            output_path: str = None,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = False,\n",
        "            checkpoint_path: str = 'checkpoint.pt',\n",
        "            checkpoint_path_optimizer: str = 'checkpoint_optimizer.pt',\n",
        "            checkpoint_path_scheduler: str = 'checkpoint_scheduler.pt',\n",
        "            checkpoint_path_trainer_state: str = 'checkpoint_trainer_state.json',\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 0,\n",
        "            do_minimize_global_objective: Int = 1\n",
        "        ):\n",
        "            self.epochs_global = -1 # track the total number of epochs\n",
        "            self.epochs_total_lifetime = epochs_total_lifetime # total number of epochs over lifetime\n",
        "            self.global_step = 0 # track the toatl number of steps\n",
        "            self.do_minimize = do_minimize_global_objective\n",
        "            self.best_score = 9999999 if self.do_minimize else -9999999\n",
        "            self.output_path = output_path\n",
        "            self.checkpoint_path = checkpoint_path\n",
        "            self.checkpoint_path_optimizer = checkpoint_path_optimizer\n",
        "            self.checkpoint_path_scheduler = checkpoint_path_scheduler\n",
        "            self.checkpoint_path_trainer_state = checkpoint_path_trainer_state\n",
        "            self.scheduler_state_dict = None\n",
        "            self.optimizer_state_dict = None\n",
        "            self.trainer_state = None\n",
        "            self.loss_models_states = None\n",
        "            if do_reload:\n",
        "                print('attempting to reload cached model, optimizer, scheduler, and saved trainer sate')\n",
        "                model_state, loss_models_states = self.load_saved_model(self.checkpoint_path)\n",
        "                self.model_state = model_state\n",
        "                self.loss_models_states = loss_models_states\n",
        "                self.scheduler_state_dicts = self.load_saved_scheduler(self.checkpoint_path_scheduler)\n",
        "                self.optimizer_state_dicts = self.load_saved_optimizer(self.checkpoint_path_optimizer)\n",
        "                self.trainer_state = self.load_saved_trainer_state(self.checkpoint_path_trainer_state)\n",
        "\n",
        "    def fit(self,\n",
        "            train_objectives: Iterable[Tuple[DataLoader, nn.Module]],\n",
        "            model=None,\n",
        "            weights_train_objectives:List = None,\n",
        "            teachers: List = None,\n",
        "            evaluator: SentenceEvaluator = None,\n",
        "            epochs: int = 1,\n",
        "            epochs_total_lifetime = None,\n",
        "            steps_per_epoch = None,\n",
        "            scheduler: str = None, # 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = True,\n",
        "            checkpoint_path = None,\n",
        "            checkpoint_path_optimizer= None,\n",
        "            checkpoint_path_scheduler= None,\n",
        "            checkpoint_path_trainer_config= None,\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 2\n",
        "            ):\n",
        "        \"\"\"\n",
        "        Train the model with the given training objective\n",
        "        Each training objective is sampled in turn for one batch.\n",
        "        We sample only as many batches from each objective as there are in the smallest one\n",
        "        to make sure of equal training with each dataset.\n",
        "\n",
        "        :param train_objectives: Tuples of (DataLoader, LossFunction). Pass more than one for multi-task learning\n",
        "        :param evaluator: An evaluator (sentence_transformers.evaluation) evaluates the model performance during training on held-out dev data. It is used to determine the best model that is saved to disc.\n",
        "        :param epochs: Number of epochs for training\n",
        "        :param steps_per_epoch: Number of training steps per epoch. If set to None (default), one epoch is equal the DataLoader size from train_objectives.\n",
        "        :param scheduler: Learning rate scheduler. Available schedulers: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        :param warmup_steps: Behavior depends on the scheduler. For WarmupLinear (default), the learning rate is increased from o up to the maximal learning rate. After these many training steps, the learning rate is decreased linearly back to zero.\n",
        "        :param optimizer_class: Optimizer\n",
        "        :param optimizer_params: Optimizer parameters\n",
        "        :param weight_decay: Weight decay for model parameters\n",
        "        :param evaluation_steps: If > 0, evaluate the model using evaluator after each number of training steps\n",
        "        :param output_path: Storage path for the model and evaluation files\n",
        "        :param save_best_model: If true, the best model (according to evaluator) is stored at output_path\n",
        "        :param max_grad_norm: Used for gradient normalization.\n",
        "        :param use_amp: Use Automatic Mixed Precision (AMP). Only for Pytorch >= 1.6.0\n",
        "        :param callback: Callback function that is invoked after each evaluation.\n",
        "                It must accept the following three parameters in this order:\n",
        "                `score`, `epoch`, `steps`\n",
        "        :param show_progress_bar: If True, output a tqdm progress bar\n",
        "        :param checkpoint_path: Folder to save checkpoints during training\n",
        "        :param checkpoint_save_steps: Will save a checkpoint after so many steps\n",
        "        :param checkpoint_save_total_limit: Total number of checkpoints to store\n",
        "        \"\"\"\n",
        "        if self.model_state is not None:\n",
        "            print('reloading saved model state into model')\n",
        "            model.load_state_dict(self.model_state)\n",
        "            self.model = model\n",
        "\n",
        "        # paths (optional update)\n",
        "        self.checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        self.checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        self.checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        self.checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "        self._target_device = model.device\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.weight_decay = weight_decay\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.optimizer_params = optimizer_params\n",
        "        self.evaluation_steps = evaluation_steps\n",
        "\n",
        "        if use_amp:\n",
        "            from torch.cuda.amp import autocast\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        #self.to(self._target_device)\n",
        "\n",
        "        dataloaders = [dataloader for dataloader, _ in train_objectives]\n",
        "\n",
        "        # Use smart batching\n",
        "        if len(collators)==0 or collators is None:\n",
        "            print('using default batch collators')\n",
        "        for dli, dataloader in enumerate(dataloaders):\n",
        "            if dataloader.collate_fn is None:\n",
        "                print('using default batch collators for dataloader %d' % dli)\n",
        "                dataloader.collate_fn = self.smart_batching_collate\n",
        "\n",
        "        loss_models = [loss for _, loss in train_objectives]\n",
        "        for midx, loss_model in enumerate(loss_models):\n",
        "            if self.loss_models_states is not None:\n",
        "                # reload each loss_model.classifier's saved states\n",
        "                if hassattr(loss_model, 'classifier'):\n",
        "                    loss_model.classifier.load_state_dict(self.loss_models_states[midx])\n",
        "            loss_model.to(self._target_device)\n",
        "\n",
        "        if steps_per_epoch is None or steps_per_epoch == 0:\n",
        "            steps_per_epoch = min([len(dataloader) for dataloader in dataloaders])\n",
        "\n",
        "        if epochs_total_lifetime is None:\n",
        "            epochs_total_lifetime = self.epochs_total_lifetime\n",
        "        num_train_steps = int(steps_per_epoch * epochs_total_lifetime)\n",
        "\n",
        "        # Prepare optimizers\n",
        "        #optimizers = []\n",
        "        #schedulers = []\n",
        "        #for model_idx, loss_model in enumerate(loss_models):\n",
        "        #    param_optimizer = list(loss_model.named_parameters())#\n",
        "        #    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        #    optimizer_grouped_parameters = [\n",
        "        #        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "        #        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        #    ]\n",
        "        #    optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        #    scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        #    if self.optimizer_state_dicts is not None:\n",
        "        #        # reload optimizer states\n",
        "        #        optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "        #    if self.scheduler_state_dicts is not None:\n",
        "        #        # relead scheduler states\n",
        "        #        scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "        #    optimizers.append(optimizer)\n",
        "        #    schedulers.append(scheduler_obj)\n",
        "\n",
        "        # from: https://stackoverflow.com/questions/46377599/when-to-use-individual-optimizers-in-pytorch\n",
        "        optimizer_parameters = set()\n",
        "        for model_idx, loss_model in enumerate(loss_models):\n",
        "            optimizer_parameters |= loss_model.named_parameters()\n",
        "\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in optimizer_parameters if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in optimizer_parameters if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        if self.optimizer_state_dicts is not None:\n",
        "            # reload optimizer states\n",
        "            #optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "            optimizer.load_state_dict(self.optimizer_state_dicts)\n",
        "        if self.scheduler_state_dicts is not None:\n",
        "            # relead scheduler states\n",
        "            #scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "            scheduler_obj.load_state_dict(self.scheduler_state_dicts)\n",
        "\n",
        "        global_step = self.global_step\n",
        "        data_iterators = [iter(dataloader) for dataloader in dataloaders]\n",
        "\n",
        "        num_train_objectives = len(train_objectives)\n",
        "\n",
        "        for epoch in trange(epochs, desc=\"Epoch\", disable=not show_progress_bar):\n",
        "            self.epochs_global += epoch\n",
        "            training_steps = 0\n",
        "\n",
        "            for loss_model in loss_models:\n",
        "                loss_model.zero_grad()\n",
        "                loss_model.train()\n",
        "\n",
        "            for _ in trange(steps_per_epoch, desc=\"Iteration\", smoothing=0.05, disable=not show_progress_bar):\n",
        "\n",
        "                # loop through multiple tasks\n",
        "                for train_idx in range(num_train_objectives):\n",
        "                    loss_model = loss_models[train_idx]\n",
        "                    loss_weight = weights_train_objectives[train_idx]\n",
        "                    teacher = teachers[train_idx]\n",
        "                    optimizer = optimizers[train_idx]\n",
        "                    scheduler = schedulers[train_idx]\n",
        "                    data_iterator = data_iterators[train_idx]\n",
        "\n",
        "                    try:\n",
        "                        data = next(data_iterator)\n",
        "                    except StopIteration:\n",
        "                        data_iterator = iter(dataloaders[train_idx])\n",
        "                        data_iterators[train_idx] = data_iterator\n",
        "                        data = next(data_iterator)\n",
        "\n",
        "                    features, labels = data\n",
        "                    features = list(map(lambda batch: batch_to_device(batch, self._target_device), features))\n",
        "                    if labels is not None:\n",
        "                        labels = labels.to(self._target_device)\n",
        "\n",
        "                    loss_value = loss_model(features, labels, teacher=teacher)\n",
        "                    loss_value *= loss_weight\n",
        "                    loss_value.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad_norm)\n",
        "                optimizers.step()\n",
        "                optimizers.zero_grad()\n",
        "                schedulers.step()\n",
        "\n",
        "                # TODO: integrate amp: https://discuss.pytorch.org/t/ddp-amp-gradient-accumulation-calling-optimizer-step-leads-to-nan-loss/162624\n",
        "                training_steps += 1\n",
        "                global_step += 1\n",
        "                self.global_step = global_step\n",
        "\n",
        "                if evaluation_steps > 0 and training_steps % evaluation_steps == 0:\n",
        "                    self._eval_during_training(evaluator, output_path, save_best_model, epoch, training_steps, callback)\n",
        "\n",
        "                    for loss_model in loss_models:\n",
        "                        loss_model.zero_grad()\n",
        "                        loss_model.train()\n",
        "\n",
        "                if self.checkpoint_path is not None and checkpoint_save_steps is not None and checkpoint_save_steps > 0 and global_step % checkpoint_save_steps == 0:\n",
        "                    self._save_checkpoint(\n",
        "                        model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "                    )\n",
        "\n",
        "            self._eval_during_training(evaluator, output_path, save_best_model, epoch, -1, callback)\n",
        "\n",
        "        #if evaluator is None and output_path is not None:   #No evaluator, but output path: save final model version\n",
        "        #    self.save(output_path)\n",
        "\n",
        "        if checkpoint_path is not None:\n",
        "            self._save_checkpoint(\n",
        "                model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "            )\n",
        "\n",
        "    def evaluate(self, evaluator: SentenceEvaluator, output_path: str = None):\n",
        "        \"\"\"\n",
        "        Evaluate the model\n",
        "\n",
        "        :param evaluator:\n",
        "            the evaluator\n",
        "        :param output_path:\n",
        "            the evaluator can write the results to this path\n",
        "        \"\"\"\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "        return evaluator(self, output_path)\n",
        "\n",
        "    def _eval_during_training(self, evaluator, output_path, save_best_model, epoch, steps, callback):\n",
        "        \"\"\"Runs evaluation during the training\"\"\"\n",
        "        eval_path = output_path\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "            eval_path = os.path.join(output_path, \"eval\")\n",
        "            os.makedirs(eval_path, exist_ok=True)\n",
        "\n",
        "        if evaluator is not None:\n",
        "            score = evaluator(self, output_path=eval_path, epoch=epoch, steps=steps)\n",
        "            if callback is not None:\n",
        "                callback(score, epoch, steps)\n",
        "            if score > self.best_score:\n",
        "                self.best_score = score\n",
        "                if save_best_model:\n",
        "                    self.save(output_path)\n",
        "\n",
        "    def _save_checkpoint(\n",
        "        self,\n",
        "        model,\n",
        "        optimizers,\n",
        "        schedulers,\n",
        "        loss_models,\n",
        "        checkpoint_save_total_limit,\n",
        "        step,\n",
        "        checkpoint_path = None,\n",
        "        checkpoint_path_optimizer = None,\n",
        "        checkpoint_path_scheduler = None,\n",
        "        checkpoint_path_trainer_state =None\n",
        "    ):\n",
        "        # Store new checkpoint\n",
        "        checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "\n",
        "        # model states\n",
        "        self.model_state = model.state_dict()\n",
        "        self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'model_state_dict':self.model_state,\n",
        "            'loss_models_state_dicts':self.loss_models_states,\n",
        "        }, \"%s-%08g\" % (checkpoint_path, step))\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer_state_dicts = optimizers.state_dict() #[opt.state_dict() for opt in optimizers],\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'optimizer_state_dicts':self.optimizer_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_optimizer, step))\n",
        "\n",
        "        # scheduler\n",
        "        self.scheduler_state_dicts = schedulers.state_dict() #[scheduler.state_dict() for scheduler in schedulers]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'scheduler_state_dicts':self.scheduler_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_scheduler, step))\n",
        "\n",
        "        # trainer info\n",
        "        with open(checkpoint_path_trainer_state, 'w') as jcon:\n",
        "            trainer_objs_to_save = {\n",
        "                'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "                'max_grad_norm':self.max_grad_norm,\n",
        "                'weight_decay':self.weight_decay,\n",
        "                'warmup_steps':self.warmup_steps,\n",
        "                'optimizer_params':self.optimizer_params,\n",
        "                'evaluation_steps':self.evaluation_steps,\n",
        "                'checkpoint_path_optimizer': \"%s-%08g\" % (checkpoint_path_optimizer, step),\n",
        "                'checkpoint_path_scheduler': \"%s-%08g\" % (checkpoint_path_scheduler, step),\n",
        "            }\n",
        "            json.dump(trainer_objs_to_save, jcon)\n",
        "\n",
        "        # Delete old checkpoints\n",
        "        if checkpoint_save_total_limit is not None and checkpoint_save_total_limit > 0:\n",
        "            old_checkpoints = []\n",
        "            dir_to_checkpoints = \"/\".join(checkpoint_path.split('/')[:-1])\n",
        "            for f in os.listdir(dir_to_checkpoints):\n",
        "                if bool(re.search('(\\-[0-9]+$',f)) & (checkpoint_path in f):\n",
        "                    # get step of saved checkpoint\n",
        "                    old_pt_step = int(re.search('(?<=\\-)[0-9]+$',f).group())\n",
        "                    old_checkpoints.append({\n",
        "                        'step': old_pt_step, 'path': os.path.join(dir_to_checkpoints, f)\n",
        "                    })\n",
        "\n",
        "            if len(old_checkpoints) > checkpoint_save_total_limit:\n",
        "                old_checkpoints = sorted(old_checkpoints, key=lambda x: x['step'])\n",
        "                oldest_step = old_checkpoints[0]['step']\n",
        "                for old_checkpoint in old_checkpoints:\n",
        "                    if old_checkpoint['step']==oldest_step:\n",
        "                        print('deleting old checkpoint: %s' % old_checkpoint['path'])\n",
        "                        shutil.rmtree(old_checkpoint['path'])\n",
        "\n",
        "    def _grab_loss_states(loss_model):\n",
        "        \"\"\"Gets the loss_model.state_dict() for a model embedded in a loss function\"\"\"\n",
        "        return loss_model.classifier.state_dict()\n",
        "\n",
        "    def load_saved_model(checkpoint_path=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path = self.checkpoint_path if checkpoint_path is None else checkpoint_path\n",
        "        saved_dict = torch.load(checkpoint_path)\n",
        "        return saved_dict['model_state_dict'], saved_dict['loss_models_state_dicts']\n",
        "\n",
        "    def load_saved_scheduler(checkpoint_path_scheduler=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_scheduler = self.checkpoint_path_scheduler if checkpoint_path_scheduler is None else checkpoint_path_scheduler\n",
        "        saved_dict = torch.load(checkpoint_path_scheduler)\n",
        "        return saved_dict['scheduler_state_dicts']\n",
        "\n",
        "    def load_saved_optimizer(checkpoint_path_optimizer=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_optimizer = self.checkpoint_path_optimizer if checkpoint_path_optimizer is None else checkpoint_path_optimizer\n",
        "        saved_dict = torch.load(checkpoint_path_optimizer)\n",
        "        return saved_dict['optimizer_state_dicts']\n",
        "\n",
        "    def load_saved_trainer_state(checkpoint_path_trainer_state):\n",
        "        checkpoint_path_trainer_state = self.checkpoint_path_trainer_state if checkpoint_path_trainer_state is None else checkpoint_path_trainer_state\n",
        "        with open(checkpoint_path_trainer_state, 'r') as jcon:\n",
        "            trainer_state = json.load(jcon)\n",
        "        self.epochs_global = trainer_state['epochs_global']\n",
        "        self.global_step = trainer_state['global_step']\n",
        "        self.step = trainer_state['step']\n",
        "        self.max_grad_norm = trainer_state['max_grad_norm']\n",
        "        self.weight_decay = trainer_state['weight_decay']\n",
        "        self.warmup_steps = trainer_state['warmup_steps']\n",
        "        self.optimizer_params = trainer_state['optimizer_params']\n",
        "        self.evaluation_steps = trainer_state['evaluation_steps']\n",
        "\n",
        "    def _load_auto_model(self, model_name_or_path):\n",
        "        \"\"\"\n",
        "        Creates a simple Transformer + Mean Pooling model and returns the modules\n",
        "        \"\"\"\n",
        "        logger.warning(\"No sentence-transformers model found with name {}. Creating a new one with MEAN pooling.\".format(model_name_or_path))\n",
        "        transformer_model = Transformer(model_name_or_path)\n",
        "        pooling_model = Pooling(transformer_model.get_word_embedding_dimension(), 'mean')\n",
        "        return [transformer_model, pooling_model]\n",
        "\n",
        "    def _load_sbert_model(self, model_path):\n",
        "        \"\"\"\n",
        "        Loads a full sentence-transformers model\n",
        "        \"\"\"\n",
        "        # Check if the config_sentence_transformers.json file exists (exists since v2 of the framework)\n",
        "        config_sentence_transformers_json_path = os.path.join(model_path, 'config_sentence_transformers.json')\n",
        "        if os.path.exists(config_sentence_transformers_json_path):\n",
        "            with open(config_sentence_transformers_json_path) as fIn:\n",
        "                self._model_config = json.load(fIn)\n",
        "\n",
        "            if '__version__' in self._model_config and 'sentence_transformers' in self._model_config['__version__'] and self._model_config['__version__']['sentence_transformers'] > __version__:\n",
        "                logger.warning(\"You try to use a model that was created with version {}, however, your version is {}. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\\n\\n\\n\".format(self._model_config['__version__']['sentence_transformers'], __version__))\n",
        "\n",
        "        # Check if a readme exists\n",
        "        model_card_path = os.path.join(model_path, 'README.md')\n",
        "        if os.path.exists(model_card_path):\n",
        "            try:\n",
        "                with open(model_card_path, encoding='utf8') as fIn:\n",
        "                    self._model_card_text = fIn.read()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Load the modules of sentence transformer\n",
        "        modules_json_path = os.path.join(model_path, 'modules.json')\n",
        "        with open(modules_json_path) as fIn:\n",
        "            modules_config = json.load(fIn)\n",
        "\n",
        "        modules = OrderedDict()\n",
        "        for module_config in modules_config:\n",
        "            module_class = import_from_string(module_config['type'])\n",
        "            module = module_class.load(os.path.join(model_path, module_config['path']))\n",
        "            modules[module_config['name']] = module\n",
        "\n",
        "        return modules\n",
        "\n",
        "    @staticmethod\n",
        "    def load(input_path):\n",
        "        return SentenceTransformer(input_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_scheduler(optimizer, scheduler: str, warmup_steps: int, t_total: int):\n",
        "        \"\"\"\n",
        "        Returns the correct learning rate scheduler. Available scheduler: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        \"\"\"\n",
        "        scheduler = scheduler.lower()\n",
        "        if scheduler == 'constantlr':\n",
        "            return transformers.get_constant_schedule(optimizer)\n",
        "        elif scheduler == 'warmupconstant':\n",
        "            return transformers.get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
        "        elif scheduler == 'warmuplinear':\n",
        "            return transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosine':\n",
        "            return transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosinewithhardrestarts':\n",
        "            return transformers.get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown scheduler {}\".format(scheduler))\n",
        "\n",
        "    @property\n",
        "    def device(self) -> device:\n",
        "        \"\"\"\n",
        "        Get torch.device from module, assuming that the whole module has one device.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return next(self.parameters()).device\n",
        "        except StopIteration:\n",
        "            # For nn.DataParallel compatibility in PyTorch 1.5\n",
        "\n",
        "            def find_tensor_attributes(module: nn.Module) -> List[Tuple[str, Tensor]]:\n",
        "                tuples = [(k, v) for k, v in module.__dict__.items() if torch.is_tensor(v)]\n",
        "                return tuples\n",
        "\n",
        "            gen = self._named_members(get_members_fn=find_tensor_attributes)\n",
        "            first_tuple = next(gen)\n",
        "            return first_tuple[1].device\n",
        "\n",
        "    @property\n",
        "    def tokenizer(self):\n",
        "        \"\"\"\n",
        "        Property to get the tokenizer that is used by this model\n",
        "        \"\"\"\n",
        "        return self.model.tokenizer\n",
        "\n",
        "    #@tokenizer.setter\n",
        "    #def tokenizer(self, value):\n",
        "    #    self._first_module().tokenizer = value\n",
        "\n",
        "    @property\n",
        "    def max_seq_length(self):\n",
        "        \"\"\"\n",
        "        Property to get the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        return self.model._first_module().max_seq_length\n",
        "\n",
        "    @max_seq_length.setter\n",
        "    def max_seq_length(self, value):\n",
        "        \"\"\"\n",
        "        Property to set the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        self.model._first_module().max_seq_length = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2hwROspo0uI"
      },
      "source": [
        "### Load a Standard Dataset for MLM task\n",
        "\n",
        "Also need to grab datasets here: https://arxiv.org/pdf/1908.08962.pdf\n",
        "\n",
        "```\n",
        "    The Pile dataset looks good: https://pile.eleuther.ai/\n",
        "    https://arxiv.org/abs/2101.00027\n",
        "    PubMed Central, ArXiv, GitHub, the FreeLaw Project, Stack Exchange, the US\n",
        "    Patent and Trademark Office, PubMed, Ubuntu IRC, HackerNews, YouTube, PhilPapers, and NIH ExPorter.\n",
        "    We also introduce OpenWebText2 and\n",
        "    BookCorpus2, which are extensions of the original\n",
        "    OpenWebText (Gokaslan and Cohen, 2019) and\n",
        "    BookCorpus (Zhu et al., 2015; Kobayashi, 2018)\n",
        "    datasets, respectively.\n",
        "    In addition, we incorporate several existing highquality datasets: Books3 (Presser, 2020), Project Gutenberg (PG-19) (Rae et al., 2019), OpenSubtitles (Tiedemann, 2016), English Wikipedia, DM Mathematics (Saxton et al., 2019), EuroParl\n",
        "    (Koehn, 2005), and\n",
        "\n",
        "    ABout the law:\n",
        "    and other metadata, we focused specifically on\n",
        "    court opinions due to an abundance of full-text\n",
        "    entries. This data is entirely within the public domain.\n",
        "\n",
        "```\n",
        "\n",
        "Scientific Papers: You can use the scientific_papers dataset, which includes a large collection of scientific papers from various domains. It covers research articles from fields such as computer science, physics, biology, and more.\n",
        "\n",
        "Patents: The patent_citations dataset contains patent text data along with citation information, making it suitable for training language models with a focus on technical and scientific domains.\n",
        "\n",
        "ArXiv: The arxiv dataset includes research papers from the arXiv repository, covering a wide range of scientific disciplines. It can be used to enhance the exposure of your model to academic literature.\n",
        "\n",
        "PubMed: The pubmed dataset consists of abstracts from biomedical research articles indexed in PubMed. It is a valuable resource if you want to incorporate biomedical and life sciences content into your MLM pretraining.\n",
        "\n",
        "joelito/Multi_Legal_Pile - use subset `en_all` to access EU-courts, and other datasets\n",
        "\n",
        "\n",
        "Looks like streaming data is available:\n",
        "https://huggingface.co/learn/nlp-course/chapter5/4?fw=pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-boy1-ZoqWI",
        "outputId": "355c1d10-6292-4c91-c52e-15e48b1b270b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "### Load a standard dataset\n",
        "%pip install transformers datasets zstandard rank_bm25\n",
        "# need the zstandard to use the streaming data function from huggingface datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0KGmDMqKlxC4"
      },
      "outputs": [],
      "source": [
        "import lzma\n",
        "from datasets import load_dataset\n",
        "from itertools import islice\n",
        "from datasets import interleave_datasets # for interweaving streaming datasets\n",
        "#from transformers import BertTokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "import re\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_vZTlRD7QML",
        "outputId": "39cbe581-8c3c-403e-e727-395ba7b03702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "#import zstandard maybe not necessary\n",
        "# Notes on Pile\n",
        "# the largest ones are tarred and cannoted be loaded (like openwebtext2), but some are already available on huggingface anyway\n",
        "\"\"\"dataset4 = load_dataset(\"the_pile_openwebtext2\",split='train',streaming=True)\"\"\" # load like THIS!!\n",
        "# 'the_pile_books3',\n",
        "# 'the_pile_stack_exchange'\n",
        "# 'the_pile_openwebtext2'\n",
        "# 'Cohere/wikipedia-22-12'\n",
        "# 'tiiuae/falcon-refinedweb' # see also google's C4\n",
        "# see more under conceptofmind/pile\n",
        "\n",
        "# base_url = \"https://the-eye.eu/public/AI/pile/\"\n",
        "data_files = [\n",
        "     (\"tiiuae/falcon-refinedweb\",None, 18.11),# CC\n",
        "     ('Cohere/wikipedia-22-12','en', 14.40), # see also: conceptofmind/pile_wikipedia_en\n",
        "     (\"the_pile_books3\", None, 12.07), # alternative? bookcorpusopen (no); RyokoExtra/books2-1.2-lite?\n",
        "     (\"the_pile_openwebtext2\",None, 10.01),\n",
        "     (\"macrocosm/arxiv_abstracts\",None, 3.75), # just the abstracts k: abstract\n",
        "     (\"ccdv/pubmed-summarization\",None, 3.75),# PMC # I should reduce this, use wikipedia instead\n",
        "     ('https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst',None,  3.0), # freelaw THE EYE DELETED THE ORIGINAL DATA\n",
        "     ('the_pile_stack_exchange',None,  5.13),\n",
        "     (\"conceptofmind/pile_uspto_backgrounds\",None, 3.00),\n",
        "     (\"https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\",None,  3.07),\n",
        "     #\"pg19\", 0.1, # project gutenberg FAILS\n",
        "     #(\"https://the-eye.eu/public/AI/pile_v2/data/EuroParliamentProceedings_1996_2011.jsonl.zst\", None, 0.73), # NON ENGLISH\n",
        "     #('https://the-eye.eu/public/AI/pile_preliminary_components/EuroParliamentProceedings_1996_2011.jsonl.zst',None, 0.73), # NON ENGLISH\n",
        "     (\"pile-of-law/pile-of-law\",'euro_parl',1),\n",
        "     (\"conceptofmind/pile_hacker_news\", None,2),\n",
        "     #(\"https://the-eye.eu/public/AI/pile_preliminary_components/PhilArchive.jsonl.zst\", None, 0.38), #(( philosophy papers -- its taking too long?\n",
        "     ('https://the-eye.eu/public/AI/pile_v2/data/PhilArchive.jsonl.zst', None, 0.38), # does this work better?\n",
        "     (\"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\",None, 0.30),\n",
        "     (\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", None, 5.0),# ledgar worked\n",
        "     (\"pile-of-law/pile-of-law\",'r_legaladvice', 1.0),\n",
        "     (\"pile-of-law/pile-of-law\",'exam_outlines',0.5),\n",
        "     (\"pile-of-law/pile-of-law\",'cc_casebooks',0.5),\n",
        "     (\"eloukas/edgar-corpus\",None, 4.0),\n",
        "     #(\"orieg/elsevier-oa-cc-by\",None,3.75) fails (takes too long)\n",
        "     (\"Rahmaa/ElsevieR_ClEaN\",None,3.75),#\n",
        "     ('ashraq/financial-news-articles', None, 1.0),\n",
        "     ('pile-of-law/pile-of-law','courtlistener_opinions',  3.0), # freelaw THE EYE DELETED THE ORIGINAL DATA\n",
        "     ('suolyer/pile_nih-exporter',['validation','test'], 0.30/2),\n",
        "     ('EleutherAI/pile','all',10.01 + 5.13 + 3.07) # backup for openweb3 and stackexchange and  and pubmed abstracts\n",
        "    #\"https://huggingface.co/datasets/pile-of-law/pile-of-law/blob/main/data/train.edgar.jsonl.xz\"\n",
        "]\n",
        "\n",
        "print(len(data_files))\n",
        "\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files,\n",
        "    'val_size':2000,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':6000,\n",
        "    'max_chunk_start':1000000,\n",
        "    \"seed\":42,\n",
        "    \"do_cc\":True,\n",
        "    \"do_wikipedia\":True,\n",
        "    \"do_book3\":False, # delated from pile, no backup -- maybe book corpus and bookcorpus2?\n",
        "    \"do_openwebtext2\":False, # delated from pile, see pilebackup\n",
        "    \"do_arxiv\":True,\n",
        "    \"do_pmc-articles\":True,\n",
        "    \"do_freelawopinions\":False, # deleted from https://pile.eleuther.ai/\n",
        "    \"do_stackexchange\":False, # delated from pile, see pilebackup\n",
        "    \"do_upto\":True,\n",
        "    \"do_pubmed-abstracts\":False, # deleted from https://pile.eleuther.ai/ see pilebackup\n",
        "    \"do_EuroParliamentProceedings_1996_2011\":True,\n",
        "    \"do_hackernews\":True,\n",
        "    \"do_philpapers\":False, # this crashes my computer\n",
        "    \"do_NIH_ExPORTER_awarded_grant\":True, # deleted from pile.eleuther.ai, opps, looks like it is restored\n",
        "    \"do_ledgar\":True,\n",
        "    \"do_r_legaladvice\":True,\n",
        "    \"do_legalexams\":True,\n",
        "    \"do_casetexts\":True,\n",
        "    \"do_edgar\":True,\n",
        "    \"do_elseiver\":True,\n",
        "    'do_financialnews':True,\n",
        "    'do_pilelawopinions_sub':True,\n",
        "    'do_nih-backup':False,\n",
        "    'do_pilebackupfiltered':True, # backup pile, filtered : nope, it depend on pile.eleuther.ai\n",
        "}\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files,\n",
        "    'val_size':200,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':300,\n",
        "    'max_chunk_start':6000,\n",
        "    \"seed\":42,\n",
        "    \"do_cc\":True,\n",
        "    \"do_wikipedia\":True,\n",
        "    \"do_book3\":False, # delated from pile, no backup -- maybe book corpus and bookcorpus2?\n",
        "    \"do_openwebtext2\":False, # delated from pile, see pilebackup\n",
        "    \"do_arxiv\":False,\n",
        "    \"do_pmc-articles\":False,\n",
        "    \"do_freelawopinions\":False, # deleted from https://pile.eleuther.ai/\n",
        "    \"do_stackexchange\":False, # delated from pile, see pilebackup\n",
        "    \"do_upto\":False,\n",
        "    \"do_pubmed-abstracts\":False, # deleted from https://pile.eleuther.ai/ see pilebackup\n",
        "    \"do_EuroParliamentProceedings_1996_2011\":False,\n",
        "    \"do_hackernews\":False,\n",
        "    \"do_philpapers\":False, # this crashes my computer\n",
        "    \"do_NIH_ExPORTER_awarded_grant\":False, # deleted from pile.eleuther.ai, opps, looks like it is restored\n",
        "    \"do_ledgar\":False,\n",
        "    \"do_r_legaladvice\":False,\n",
        "    \"do_legalexams\":False,\n",
        "    \"do_casetexts\":False,\n",
        "    \"do_edgar\":True,\n",
        "    \"do_elseiver\":False,\n",
        "    'do_financialnews':False,\n",
        "    'do_pilelawopinions_sub':False,\n",
        "    'do_nih-backup':False,\n",
        "    'do_pilebackupfiltered':True, # backup pile, filtered : nope, it depend on pile.eleuther.ai\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HZfwOl0Uh20l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "a60adef6-2a2f-4a5c-fa2c-3cb4fa37c531"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "EmptyDatasetError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDatasetError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bb6424108c06>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#foo = load_dataset('the_pile_books3',split='train',streaming=True) # fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#foo = load_dataset('bookcorpusopen',split='train',streaming=True) # fails: FileNotFoundError: https://the-eye.eu/public/AI/pile_preliminary_components/books1.tar.gz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hieule/vie-book-v2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m    \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   1786\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_auth_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1515\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1223\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't reach the Hugging Face Hub for dataset '{path}': {e1}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmptyDatasetError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m                     raise FileNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                     \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                     \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                 ).get_module()\n\u001b[0m\u001b[1;32m   1216\u001b[0m         except (\n\u001b[1;32m   1217\u001b[0m             \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns_in_dataset_repository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhfh_dataset_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m         )\n\u001b[1;32m    782\u001b[0m         data_files = DataFilesDict.from_hf_repo(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mget_data_patterns_in_dataset_repository\u001b[0;34m(dataset_info, base_path)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_data_files_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         raise EmptyDatasetError(\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;34mf\"The dataset repository at '{dataset_info.id}' doesn't contain any data files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         ) from None\n",
            "\u001b[0;31mEmptyDatasetError\u001b[0m: The dataset repository at 'hieule/vie-book-v2' doesn't contain any data files"
          ]
        }
      ],
      "source": [
        "# no longer works: the_pile_books3: maybe SaylorTwift/the_pile_books3_minus_gutenberg\n",
        "# the_pile_stack_exchange : is down, maybe use: donfu/oa-stackexchange (but it is badly sorted) or # teven/stackexchange (but it has other languages)\n",
        "# openwebtext2 : vietgpt/the_pile_openwebtext2\n",
        "# 'EleutherAI/pile','pubmed_central' dead\n",
        "# 'EleutherAI/pile','free_law' failes\n",
        "# 'EleutherAI/pile','nih_exporter', dead\n",
        "# 'EleutherAI/pile','hacker_news', dead\n",
        "#foo = load_dataset('json',data_files = \"https://the-eye.eu/public/AI/pile_neox/data/PhilPapersDataset_text_document.bin\",split='train') # fails\n",
        "\n",
        "# still works with all; # \"EleutherAI/pile\", split=\"\"\n",
        "#foo = load_dataset('json',data_files= \"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\", split=\"train\", streaming=True)\n",
        "#foo = load_dataset('text',data_files = \"https://the-eye.eu/public/AI/pile_neox/data/PhilPapersDataset_text_document.bin\",split='train', encoding='latin-1',streaming=True)\n",
        "#foo = load_dataset('the_pile_books3',split='train',streaming=True) # fails\n",
        "#foo = load_dataset('bookcorpusopen',split='train',streaming=True) # fails: FileNotFoundError: https://the-eye.eu/public/AI/pile_preliminary_components/books1.tar.gz\n",
        "foo =  load_dataset('hieule/vie-book-v2',split='train',streaming=True) # fails\n",
        "for e in foo:\n",
        "   break\n",
        "\n",
        "print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MULDJS_QVqid"
      },
      "outputs": [],
      "source": [
        "def make_streaming_datasets(data_streaming_config, streaming_datasets = None):\n",
        "    \"\"\"Makes the streaming dataset, like Pile but includes others\"\"\"\n",
        "\n",
        "    print('consider adding: ashraq/financial-news-articles, for finacial news')\n",
        "\n",
        "    def casetext_skip_first_k_char(example):\n",
        "        example['text'] = example['text'][120000:].replace('\\n',\" \")\n",
        "        return example\n",
        "\n",
        "    def edgar_consolidate_sections(example):\n",
        "        example['text'] = example['section_1'] + \"\\n\" + example['section_2'] + \"\\n\" + example['section_3'] + \"\\n\" + example['section_7']\n",
        "        return example\n",
        "\n",
        "    def clean_elseiver_mlm(example):\n",
        "        example['text'] = example['Clean_Title'] + \" - \" + example['Clean_Summary'] + \"\\n\" + example['Clean_Text']\n",
        "        return example\n",
        "\n",
        "    def clean_financial_news(example):\n",
        "        example['text'] = example['title'] + \"\\n\" + example['text']\n",
        "        return example\n",
        "\n",
        "    if streaming_datasets is None:\n",
        "        streaming_datasets = []\n",
        "\n",
        "    # new probabilities\n",
        "    probabilities = []\n",
        "\n",
        "    data_files = data_streaming_config['files']\n",
        "\n",
        "    if data_streaming_config['do_cc']:\n",
        "        # CommonCraw\n",
        "        j = 0\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['url', 'timestamp', 'dump', 'segment', 'image_urls']).rename_column('content','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_wikipedia']:\n",
        "        # wikipedia\n",
        "        j = 1\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[1][1], data_files[5][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['id', 'title', 'url', 'wiki_id', 'views', 'paragraph_id', 'langs'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_book3']:\n",
        "        # the_pile_books3: need to figure out how to skip a certain amount of tokens\n",
        "        j = 2\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[2][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['title'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_openwebtext2']:\n",
        "        # the_pile_openwebtext2:\n",
        "        j = 3\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[3][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['title','reddit_scores'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_arxiv']:\n",
        "        # arxiv_abstracts:\n",
        "        j = 4\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[4][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['embeddings', 'doi']).rename_column('abstract','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_pmc-articles']:\n",
        "        # PMC articles\n",
        "        j = 5\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[5][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['abstract']).rename_column('article','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_freelawopinions']:\n",
        "        # Freelaw opinions\n",
        "        j = 6\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_stackexchange']:\n",
        "        j = 7\n",
        "        # stackexchange\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(path=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['domain'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_upto']:\n",
        "        j = 8\n",
        "        # upto\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(path=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_pubmed-abstracts']:\n",
        "        j = 9\n",
        "        # pubmed abstracts\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_EuroParliamentProceedings_1996_2011']:\n",
        "        j = 10\n",
        "        #EuroParliamentProceedings_1996_2011\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_hackernews']:\n",
        "        j = 11\n",
        "        # hackernews discusions\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_philpapers']:\n",
        "        j = 12\n",
        "        # philosophy papers / philpapers\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_NIH_ExPORTER_awarded_grant']:\n",
        "        j = 13\n",
        "        # NIH_ExPORTER_awarded_grant_text\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_ledgar']:\n",
        "        j = 14\n",
        "        # LEDGAR_2016\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['label', 'source']).rename_column('provision','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_r_legaladvice']:\n",
        "        j = 15\n",
        "        # r_legaladvice\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])#.rename_column('provision','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_legalexams']:\n",
        "        j = 16\n",
        "        # legal exams\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])#.rename_column('provision','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_casetexts']:\n",
        "        j = 17\n",
        "        # case text books\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url']).map(casetext_skip_first_k_char)\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "\n",
        "    if data_streaming_config['do_edgar']:\n",
        "        j = 18\n",
        "        # edgar corpus\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].map(edgar_consolidate_sections).remove_columns([\n",
        "            'filename', 'cik', 'year', 'section_1A', 'section_1B', 'section_4', 'section_1', 'section_2', 'section_3', 'section_7',\n",
        "            'section_5', 'section_6', 'section_8', 'section_9', 'section_10', 'section_7A', 'section_9A', 'section_9B',\n",
        "            'section_11', 'section_12', 'section_13', 'section_14', 'section_15' #\n",
        "        ])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_elseiver']:\n",
        "        j = 19\n",
        "        # elseiver\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], None, split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].map(clean_elseiver_mlm).remove_columns(['Unnamed: 0', 'Clean_Title', 'Clean_Text', 'Clean_Summary'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_financialnews']:\n",
        "        j = 20\n",
        "        # financial_news\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], None, split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].map(clean_financial_news).remove_columns(['title','url'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_pilelawopinions_sub']:\n",
        "        j = 21\n",
        "        # SUBSTITUTE: pile-of-law opinions\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    # do_nih-backup\n",
        "    if data_streaming_config['do_nih-backup']:\n",
        "        j = 22\n",
        "        # SUBSTITUTE: pile-of-law opinions\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=data_files[j][1][0], streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=data_files[j][1][1], streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    # backup using the pile's 'all' filtered {'ArXiv','FreeLaw', 'Github','NIH ExPorter','OpenWebText2','Pile-CC','PubMed Abstracts','PubMed Central','StackExchange',\n",
        "    #'USPTO Backgrounds', 'Wikipedia (en)'}\n",
        "    if data_streaming_config['do_pilebackupfiltered']:\n",
        "        j = 23\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split='train',streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].filter(\n",
        "            lambda x: x['meta']['pile_set_name'] in ['NIH ExPorter','OpenWebText2','PubMed Abstracts','StackExchange','Wikipedia (en)']\n",
        "        ).remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    assert len(streaming_datasets)==len(probabilities)\n",
        "    return streaming_datasets, probabilities\n",
        "\n",
        "def fetch_and_combine_streaming_mlm_data(\n",
        "    data_streaming_config,\n",
        "    stopping_strategy ='all_exhausted',\n",
        "):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "\n",
        "    # make all the streaming datsets\n",
        "    datasets_to_stream, dataset_probabilities = make_streaming_datasets(\n",
        "        data_streaming_config, streaming_datasets = None\n",
        "    )\n",
        "    # normalize the probabilities\n",
        "    dataset_probabilities = [\n",
        "        p/sum(dataset_probabilities) for p in dataset_probabilities\n",
        "    ]\n",
        "\n",
        "    print('DONE initializing streaming datasets')\n",
        "    #return datasets_to_stream\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy = stopping_strategy,\n",
        "        probabilities = dataset_probabilities,\n",
        "        seed = data_streaming_config['seed']\n",
        "    )\n",
        "    return datasets_combined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGLBNn8i1_Ak"
      },
      "outputs": [],
      "source": [
        "# no longer works: the_pile_books3: maybe SaylorTwift/the_pile_books3_minus_gutenberg\n",
        "# the_pile_stack_exchange : is down, maybe use: donfu/oa-stackexchange (but it is badly sorted) or # teven/stackexchange (but it has other languages)\n",
        "# openwebtext2 : vietgpt/the_pile_openwebtext2\n",
        "if False:\n",
        "    foo = load_dataset('the_pile_stack_exchange',split='train',streaming=True)\n",
        "    for i,e in enumerate(foo):\n",
        "        if (i+1)%10:\n",
        "            print(e['text'])\n",
        "        if i>100:\n",
        "          lkjlkjlkj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wc9F9QTMhEbU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30h2nnzWnDpz",
        "outputId": "a1446fbc-dd8c-4e25-8978-f67c51797b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "['Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy\\'s capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Red-faced, the Army Air Corps commanders sought to minimize the attack\\'s results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell\\'s carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game\\'s umpires sided with the Army. Their report made no mention of Yarnell\\'s attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy\\'s victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**As the aircraft approached Pearl Harbor, the weather cleared, as if on cue.', 'This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy\\'s capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Red-faced, the Army Air Corps commanders sought to minimize the attack\\'s results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell\\'s carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game\\'s umpires sided with the Army. Their report made no mention of Yarnell\\'s attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy\\'s victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected.', '## **THE DAWN OF BLITZKRIEG**As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy\\'s capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Red-faced, the Army Air Corps commanders sought to minimize the attack\\'s results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell\\'s carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game\\'s umpires sided with the Army. Their report made no mention of Yarnell\\'s attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not.', 'As Admiral Chester W. Nimitz, the architect of the Navy\\'s victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy\\'s capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Red-faced, the Army Air Corps commanders sought to minimize the attack\\'s results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell\\'s carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game\\'s umpires sided with the Army. Their report made no mention of Yarnell\\'s attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not.', 'Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy\\'s victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy\\'s capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Red-faced, the Army Air Corps commanders sought to minimize the attack\\'s results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell\\'s carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game\\'s umpires sided with the Army. Their report made no mention of Yarnell\\'s attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly.', 'The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy\\'s victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy\\'s capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _ Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy\\'s ships still sitting at anchor. Red-faced, the Army Air Corps commanders sought to minimize the attack\\'s results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell\\'s carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game\\'s umpires sided with the Army. Their report made no mention of Yarnell\\'s attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force.', 'Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not.']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "CHAR_PER_WORD = 6.36\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "config = {\n",
        "    'max_seq_length':512,\n",
        "    'min_seq_length':48,\n",
        "    'max_chunk_size':6,\n",
        "    'seed':42\n",
        "}\n",
        "\n",
        "class ExampleProcessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=config,\n",
        "        char_per_word = CHAR_PER_WORD,\n",
        "        nlp =nlp,\n",
        "    ):\n",
        "        self.nlp = nlp\n",
        "        self.char_per_word = char_per_word\n",
        "        self.max_seq_length = config.get('max_seq_length', 512)\n",
        "        self.min_seq_length = config.get('min_seq_length', 128)\n",
        "        self.max_chunk_size = config.get('max_chunk_size', 5)\n",
        "        self.seed = config.get('seed', 42)\n",
        "        self.max_chunk_length = self.max_chunk_size * self.max_seq_length\n",
        "        self.max_chunk_length_char = int(self.max_chunk_length*self.char_per_word)\n",
        "        self.min_seq_length_char = int(self.min_seq_length*self.char_per_word)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_into_chunks(text, chunk_char_size, overlapping_size = 50):\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        end = chunk_char_size + overlapping_size\n",
        "        while start < len(text):\n",
        "            chunk = text[start:end]\n",
        "            period_index = chunk.find(\". \")\n",
        "            if period_index != -1:\n",
        "                chunk = chunk[period_index + 1:]\n",
        "            else:\n",
        "                first_space_index = chunk.find(\" \")\n",
        "                if first_space_index != -1:\n",
        "                    chunk = chunk[first_space_index + 1:]\n",
        "            # Check if the chunk has been split and contains more than one word\n",
        "            #if start > 0 and \" \" in chunk:\n",
        "            if end < len(text) and \" \" in chunk and chunk[-1]!=\" \":\n",
        "                last_space_index = chunk.rfind(\" \")\n",
        "                chunk = chunk[:last_space_index]\n",
        "            chunks.append(chunk)\n",
        "            start += chunk_char_size\n",
        "            end += chunk_char_size\n",
        "        return chunks\n",
        "\n",
        "    def split_chunk_into_sentences(self, chunk, discard_first_sentence=True, discard_last_sentence=True ):\n",
        "        doc = self.nlp(chunk)\n",
        "        MAX_CHAR_LEN = int(self.max_seq_length*self.char_per_word)\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        if discard_first_sentence:\n",
        "            sentences = sentences[1:]\n",
        "        if discard_last_sentence:\n",
        "            sentences = sentences[:-1]\n",
        "        super_list = []\n",
        "        buffer = []\n",
        "        buffer_len = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_len = len(sentence)\n",
        "\n",
        "            if buffer_len + sentence_len > MAX_CHAR_LEN:\n",
        "                super_list.append(\" \".join(buffer))\n",
        "                buffer = []\n",
        "                buffer_len = 0\n",
        "\n",
        "            buffer.append(sentence)\n",
        "            buffer_len += sentence_len\n",
        "\n",
        "        if buffer:  # If there are any remaining sentences in the buffer\n",
        "            super_list.append(\" \".join(buffer))\n",
        "\n",
        "        return super_list\n",
        "\n",
        "    def _sample_chunk_span(self, text, max_chunk_length_char):\n",
        "        chunks = self.split_into_chunks(text, max_chunk_length_char)\n",
        "        # randomly sample from the chunks\n",
        "        #FOOBAR SAMPLE FROM CHUNKS\n",
        "        return random.choice(chunks)\n",
        "\n",
        "    def is_too_small_quickcheck(self, text, textlen=None):\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.min_seq_length_char*0.9\n",
        "\n",
        "    def is_too_small(self, nwords):\n",
        "        return nwords < self.min_seq_length\n",
        "\n",
        "    def is_larger_than_max_chunk_quickcheck(self, text, textlen):\n",
        "        \"\"\"if it is larger than a chunksize, then we need to sample chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen > self.max_chunk_length_char\n",
        "\n",
        "    def is_short_than_a_chunk(self, text, textlen):\n",
        "        \"\"\"if it is shorter than a chunk, then we'll take all text, in chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.max_chunk_length_char\n",
        "\n",
        "    def is_smaller_than_two_paragraphs(self, text):\n",
        "        charlen = len(text)\n",
        "        if charlen < (1.5*self.max_seq_length*self.char_per_word):\n",
        "            return True, re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        if charlen > (2.5*self.max_seq_length*self.char_per_word):\n",
        "            return False, None\n",
        "        # inbetween cases, split and calculate the number of words\n",
        "        textsplit = re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        nwords = len(textsplit)\n",
        "        if nwords < 1.2*self.max_seq_length:\n",
        "            return True, textsplit\n",
        "        return False, textsplit\n",
        "\n",
        "    def process(self, text):\n",
        "        # TODO: a quick chunk sampler\n",
        "        # a chunk splitter based on the sentencizer\n",
        "\n",
        "        charlen = len(text.strip())\n",
        "\n",
        "        # DISCARD if it is too small for copus\n",
        "        if self.is_too_small_quickcheck(text, charlen):\n",
        "\n",
        "            return [], False\n",
        "\n",
        "        # sample span of chunks: if it larger than our max chunk size\n",
        "        if self.is_larger_than_max_chunk_quickcheck(text, charlen):\n",
        "            text_span_chunks = self._sample_chunk_span(text, self.max_chunk_length_char)\n",
        "        else:\n",
        "            text_span_chunks = text\n",
        "\n",
        "        # check if it smaller, than 1.5 seqlen, then we just accept it all as one unit to truncate later in tokenizer\n",
        "        is_smaller_than_2_paras, textsplit = self.is_smaller_than_two_paragraphs(text_span_chunks)\n",
        "\n",
        "        if is_smaller_than_2_paras:\n",
        "\n",
        "            # check if less than minsize\n",
        "            if self.is_too_small(len(textsplit)):\n",
        "                # if too small, return nothing\n",
        "                return [],False\n",
        "\n",
        "            # return text to be truncated\n",
        "            return [text_span_chunks], True\n",
        "\n",
        "        # leftover cases: text that needs to be chunked into ~512 / max_seq_len\n",
        "        return (self.split_chunk_into_sentences(text_span_chunks), True)\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.process(text)\n",
        "\n",
        "example_processor = ExampleProcessor(config=data_streaming_config, char_per_word = CHAR_PER_WORD, nlp =nlp)\n",
        "text = \"\"\"As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy's capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor.Red-faced, the Army Air Corps commanders sought to minimize the attack's results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell's carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game's umpires sided with the Army. Their report made no mention of Yarnell's attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy's victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**\"\"\"\n",
        "text += text\n",
        "text += text\n",
        "text += text\n",
        "text += text\n",
        "foo,is_good = example_processor(text = text)\n",
        "print(is_good)\n",
        "print(foo)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSP-Hmb8vUm_"
      },
      "source": [
        "#### A Sample of 1000 will have...\n",
        "... approximately 1523 samples of 512-long examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UmhZQWnl1EUQ"
      },
      "outputs": [],
      "source": [
        "# FUNCTIONS TO MAKE THE TRAINING AND VAL SETs\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "## convert the streaming dataset in a static dataset\n",
        "def convert_streaming_dataset_to_static_corpus(streaming_dataset, skip=0, take=1000):\n",
        "    \"\"\"Takes a streaming_dataset and converts it into a list of examples\"\"\"\n",
        "    if skip !=0:\n",
        "        dataset_to_make_static = streaming_dataset.skip(skip).take(take)\n",
        "    else:\n",
        "        dataset_to_make_static = streaming_dataset.take(take)\n",
        "\n",
        "    examples_static = []\n",
        "    for i, example in enumerate(dataset_to_make_static):\n",
        "        example_parsed,is_good = example_processor(text = example['text'])\n",
        "        if is_good:\n",
        "            examples_static.extend(example_parsed)\n",
        "        if (i+1)%100==0:\n",
        "            print(\"...streaming size: \" % len(examples_static))\n",
        "\n",
        "    return examples_static\n",
        "\n",
        "\n",
        "def train_test_splits_from_stream(\n",
        "    streaming_dataset,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    max_chunk_start = 1000000,\n",
        "    path_to_val_cache = 'val_mlm_cache.pkl'\n",
        "):\n",
        "    \"\"\"\n",
        "    val_size = 2000, number of streaming-iter to skip, reserved for the val-sze\n",
        "    epoch = 0, epoch will change the seed when sampling the chunk idx for making the training set\n",
        "    chunk_size = 5000, # number of streaming-iter to select the training data chunk\n",
        "    max_chunk_start = 2000000, # randomly sample within this interval for streaming chunks\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path_to_val_cache):\n",
        "        print('RELOADING VAL SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            val_corpus_list = pickle.load(pcon)\n",
        "        print('VAL SET SIZE: %d' % len(val_corpus_list))\n",
        "    else:\n",
        "        # stream validation set\n",
        "        print('STREAMING VAL DATA: %d' % val_size)\n",
        "        val_corpus_list = convert_streaming_dataset_to_static_corpus(\n",
        "            streaming_dataset, skip=0, take=val_size\n",
        "        )\n",
        "        # save the validation corpus\n",
        "        print('SAVING VAL SET: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(val_corpus_list, pcon)\n",
        "\n",
        "    # take a random interger to start the streaming of training data\n",
        "    skip_to_start_streaming_training_data = np.random.RandomState(\n",
        "        42 + epoch\n",
        "    ).randint(val_size, max_chunk_start)\n",
        "\n",
        "    # stream training data\n",
        "    print('STREAMING TRAIN DATA: %d STARTING AT: %d' % (chunk_size,skip_to_start_streaming_training_data))\n",
        "    train_corpus_list = convert_streaming_dataset_to_static_corpus(\n",
        "        streaming_dataset,\n",
        "        skip=skip_to_start_streaming_training_data,\n",
        "        take=chunk_size\n",
        "    )\n",
        "    print('TRAIN SET SIZE: %d' % len(train_corpus_list))\n",
        "    return {\n",
        "        'train':train_corpus_list,\n",
        "        'val':val_corpus_list,\n",
        "        'epoch':0,\n",
        "        'index_stream':skip_to_start_streaming_training_data\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5TqK9885td5",
        "outputId": "16e64f2c-a3a9-4a95-9a21-736fb65b5de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "consider adding: ashraq/financial-news-articles, for finacial news\n",
            "Trying 'tiiuae/falcon-refinedweb\n",
            "Trying 'Cohere/wikipedia-22-12\n",
            "Trying 'eloukas/edgar-corpus\n",
            "Trying 'EleutherAI/pile\n",
            "DONE initializing streaming datasets\n",
            "STREAMING VAL DATA: 200\n",
            "132\n",
            "265\n",
            "SAVING VAL SET: val_mlm_cache.pkl\n",
            "STREAMING TRAIN DATA: 300 STARTING AT: 1060\n",
            "138\n",
            "284\n",
            "410\n",
            "TRAIN SET SIZE: 410\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# stream and combine the MLM datasets\n",
        "datasets_mlm_streaming_combined = fetch_and_combine_streaming_mlm_data(\n",
        "    data_streaming_config, #stopping_strategy ='all_exhausted'\n",
        ")\n",
        "\n",
        "\n",
        "# create the training set and validation set (save and reload later)\n",
        "datasets_static = train_test_splits_from_stream(\n",
        "    datasets_mlm_streaming_combined,\n",
        "    val_size = data_streaming_config['val_size'],#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size =  data_streaming_config['train_chunk_size'],#6000,\n",
        "    max_chunk_start = data_streaming_config['max_chunk_start'],#1000000,\n",
        "    path_to_val_cache = 'val_mlm_cache.pkl'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r51a5BrXzKZA"
      },
      "outputs": [],
      "source": [
        "for s in datasets_static['train']:\n",
        "    print(s.replace('\\n',' ')[:150] + \"\\n----\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Done making the MLM streaming dataset (although I still need a book corpus)"
      ],
      "metadata": {
        "id": "6IYVkevC3Vwf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q&A Triplets!\n",
        "\n",
        "Here I make a triplet dataset of query, positive answer, and negatives (if available)\n",
        "\n",
        "B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- LLukas22/lfqa_preprocessed - question and answers 226k\n",
        "- DONE gbharti/finance-alpaca (like FIQA - finance Q&A)\n",
        "- DONE embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- GONE the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- donfu/oa-stackexchange - 6.3 million!\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- sciq - science questions - see question and support\n",
        "- DONE wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers"
      ],
      "metadata": {
        "id": "PCG8JHCz3Xzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#foo =  load_dataset('embedding-data/PAQ_pairs',split='train',streaming=True) # good\n",
        "#foo =  load_dataset('gbharti/finance-alpaca',split='train',streaming=True)  # good, financial questions\n",
        "#foo =  load_dataset('embedding-data/WikiAnswers',split='train',streaming=True) # NAD; just for paraphrased questions, not for QA\n",
        "#foo =  load_dataset('wiki_qa',split='train',streaming=True) # excellent; with negatives and positives\n",
        "#foo =  load_dataset('donfu/oa-stackexchange',split='train',streaming=True).skip(1000).take(300) # excellent; with negatives and positives\n",
        "\n",
        "if False:\n",
        "    # embedding-data/WikiAnswers\n",
        "    for j,e in enumerate(foo):\n",
        "        print(e)\n",
        "        if j > 10:\n",
        "          break\n",
        "\n",
        "    print(e)\n",
        "    print(e.keys())"
      ],
      "metadata": {
        "id": "0s1uF47m3WRf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_stream_PAQ_pairs(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = []\n",
        "    return x\n",
        "\n",
        "def clean_stream_finance_alpaca(x):\n",
        "    x['query'] = x['instruction']\n",
        "    x['positives'] = [x['output']]\n",
        "    x['negatives'] = []\n",
        "    return x\n",
        "\n",
        "def clean_stream_wiki_qa(x):\n",
        "    x['query'] = x['question']\n",
        "    is_pos = x['label']\n",
        "    answer = x['answer']\n",
        "    pos = [answer] if is_pos else []\n",
        "    neg = [answer] if (not is_pos) else []\n",
        "    x['positives'] = pos\n",
        "    x['negatives'] = neg\n",
        "    return x\n",
        "\n",
        "def clean_stream_oa_stackexchange(x):\n",
        "    x['query'] = x['INSTRUCTION']\n",
        "    x['positives'] = [x['RESPONSE']]\n",
        "    x['negatives'] = []\n",
        "    return x\n",
        "\n",
        "def filter_os_stackexchange(x):\n",
        "    return x['SOURCE'] not in [\n",
        "        'stackexchange-japanese','stackexchange-math','stackexchange-ru_stackoverflow',\n",
        "        \"stackexchange-portuguese\",\"stackexchange-chinese\",\n",
        "        'stackexchange-french',\n",
        "        'stackexchange-russian',\n",
        "        'stackexchange-spanish',\n",
        "        'stackexchange-korean',\n",
        "        'stackexchange-ukrainian',\n",
        "        'stackexchange-italian',\n",
        "        'stackexchange-german',\n",
        "        'stackexchange-es_stackoverflow',\n",
        "        'stackexchange-esperanto',\n",
        "        'stackexchange-rus',\n",
        "        'stackexchange-ja_stackoverflow',\n",
        "        'stackexchange-pt_stackoverflow',\n",
        "        # french, chinese,russian,spanish,ukrainian,'korean','italian','german','esperanto','es_stackoverflow'\n",
        "    ]\n",
        "\n",
        "#dict_keys(['question_id', 'question', 'document_title', 'answer', 'label'])\n",
        "qa_streaming_cleaning_functions = {\n",
        "    'embedding-data/PAQ_pairs':(clean_stream_PAQ_pairs,None, ['query','positives','negatives'],['set']),\n",
        "    'gbharti/finance-alpaca':(clean_stream_finance_alpaca,None, ['query','positives','negatives'],['input', 'output', 'text', 'instruction']),\n",
        "    'wiki_qa':(clean_stream_wiki_qa, None, ['query','positives','negatives'],['question_id', 'question', 'document_title', 'answer', 'label']),\n",
        "    'donfu/oa-stackexchange':(clean_stream_oa_stackexchange, filter_os_stackexchange, ['query','positives','negatives'], ['INSTRUCTION', 'RESPONSE', 'SOURCE', 'METADATA']),\n",
        "}\n",
        "\n",
        "qa_files = [\n",
        "    ('embedding-data/PAQ_pairs',None, 0.1, 7.29*10**6), # wikipedia pop culture pairs # get from 'set'\n",
        "    ('gbharti/finance-alpaca',None, 0.1, 6.89*10**5), # Stanford's Alpaca (https://github.com/tatsu-lab/stanford_alpaca) and FiQA (https://sites.google.com/view/fiqa/) with another 1.3k pairs custom generated using GPT3.5\n",
        "    ('wiki_qa',None, 0.1, 20.4*10**3), # Wiki Question Answering corpus from Microsoft. with multiple negatives that are similar!\n",
        "    ('donfu/oa-stackexchange',None, 0.1, 1600000) # stack-exchange question-answer pairs, across lots of domains; notice the original is 3.3 million, but there is a filter\n",
        "]\n",
        "\n",
        "qadata_streaming_config = {\n",
        "    'files':qa_files,\n",
        "    'max_seq_length':512,\n",
        "    'prepend_q': 'query: ',\n",
        "    'prepend_a': 'passage:',\n",
        "    'val_size':100,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "def initialize_qa_streaming_datasets(qadata_streaming_config):\n",
        "    files = qadata_streaming_config['files']\n",
        "    qa_streaming_datsets, qa_probabilities, qa_datasizes = [],[],[]\n",
        "    for qa_nm, set_nm, prob, dataset_size in files:\n",
        "\n",
        "        if prob ==0:\n",
        "            continue\n",
        "\n",
        "        clean_func, filter_func, feature_names, removefeature_names = qa_streaming_cleaning_functions[qa_nm]\n",
        "\n",
        "        print('trying %s' % qa_nm)\n",
        "        if filter_func is None:\n",
        "            dset_stream = load_dataset(qa_nm, set_nm, split='train',streaming=True).map(clean_func).remove_columns(removefeature_names)\n",
        "        else:\n",
        "            dset_stream = load_dataset(qa_nm, set_nm, split='train',streaming=True).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "\n",
        "        qa_streaming_datsets.append(dset_stream)\n",
        "        qa_probabilities.append(prob);\n",
        "        qa_datasizes.append(dataset_size)\n",
        "\n",
        "    print('done initializing the QA streaming datasets')\n",
        "    return qa_streaming_datsets, qa_probabilities, qa_datasizes\n",
        "\n",
        "def streaming_skip(skip, list_of_streaming_datasets, probabilities, datasizes, seed=42, convert_to_static = False):\n",
        "    \"\"\"Function loops through a list of streaming datasets, skips a first K values based on the probabilities, and returns them\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for dset, p, size in list_of_streaming_datasets, normalized_p, datasizes:\n",
        "        skip_in_this_set = max(0,int(p)*skip)\n",
        "        out.append(dset.skip(skip_in_this_set))\n",
        "    return out\n",
        "\n",
        "def streaming_take(skip, start_proportion, chunksize, list_of_streaming_datasets, probabilities, datasizes,  convert_to_static = False):\n",
        "    \"\"\"Takes some examples based on a starting point within the dataset, as a proportion of its total size\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for j, (dset, p, size) in enumerate(zip(list_of_streaming_datasets, normalized_p, datasizes)):\n",
        "        #print(type(dset))\n",
        "        #print(type(p))\n",
        "        #print(type(size))\n",
        "        # skip for valset\n",
        "        skip_in_this_set = int(round(p*skip))\n",
        "        # afterwards, where to start?\n",
        "        skip_to_start = int(start_proportion*(size-skip_in_this_set))\n",
        "        take_from_this_set = int(round(chunksize*p))\n",
        "        if skip_to_start>0:\n",
        "            dset_skipped = dset.skip(skip_in_this_set+skip_to_start).take(take_from_this_set)\n",
        "        else:\n",
        "            dset_skipped = dset.take(take_from_this_set)\n",
        "\n",
        "        if not convert_to_static:\n",
        "            # option to return the streaming dataset\n",
        "            out.append(dset_skipped)\n",
        "        else:\n",
        "            # option just to convert the streaming dataset to static outputs\n",
        "            for example in dset_skipped:\n",
        "                example['source_id'] = j\n",
        "                out.append(example)\n",
        "        print('done %d' % j)\n",
        "    return out\n",
        "\n",
        "def train_test_splits_from_stream_qa(\n",
        "    streaming_dataset,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    path_to_val_cache = 'val_qa_cache.pkl',\n",
        "    probabilities = None,\n",
        "    datasizes = None,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"\n",
        "    val_size = 2000, number of streaming-iter to skip, reserved for the val-sze\n",
        "    epoch = 0, epoch will change the seed when sampling the chunk idx for making the training set\n",
        "    chunk_size = 5000, # number of streaming-iter to select the training data chunk\n",
        "    max_chunk_start = 2000000, # randomly sample within this interval for streaming chunks\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path_to_val_cache):\n",
        "        print('RELOADING VAL-QA SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            val_corpus_list = pickle.load(pcon)\n",
        "        print('VAL-QA SET SIZE: %d' % len(val_corpus_list))\n",
        "    else:\n",
        "        # stream validation set\n",
        "        print('STREAMING VAL-QA DATA: %d' % val_size)\n",
        "        val_corpus_list = streaming_take(\n",
        "            skip=0,\n",
        "            start_proportion=0,\n",
        "            chunksize=val_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "        print('REALIZED VAL-QA DATA: %d' % len(val_corpus_list))\n",
        "        # save the validation corpus\n",
        "        print('SAVING VAL-QA SET: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(val_corpus_list, pcon)\n",
        "\n",
        "    # take a random interger to start the streaming of training data\n",
        "    # starts at a random position\n",
        "    train_start_proportion = np.random.RandomState(seed + epoch).random()*0.99\n",
        "    print(train_start_proportion)\n",
        "\n",
        "    # stream training data\n",
        "    print('STREAMING TRAIN QA-DATA: %d STARTING AT: %0.3f' % (chunk_size,train_start_proportion))\n",
        "    train_corpus_list = streaming_take(\n",
        "            skip=val_size,\n",
        "            start_proportion=train_start_proportion,\n",
        "            chunksize=chunk_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "\n",
        "    print('REALISED TRAIN QA-DATA SIZE: %d' % len(train_corpus_list))\n",
        "    return {\n",
        "        'train':train_corpus_list,\n",
        "        'val':val_corpus_list,\n",
        "        'epoch':0,\n",
        "        'index_stream':train_start_proportion\n",
        "    }"
      ],
      "metadata": {
        "id": "ABJazLSA3WTz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# intialize the qa streaming dataset (QA)\n",
        "qa_streaming_datsets, qa_probabilities, qa_datasizes = initialize_qa_streaming_datasets(qadata_streaming_config)\n",
        "\n",
        "qa_statics_datsets = train_test_splits_from_stream_qa(\n",
        "    streaming_dataset=qa_streaming_datsets,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    path_to_val_cache = 'val_qa_cache.pkl',\n",
        "    probabilities = qa_probabilities,\n",
        "    datasizes = qa_datasizes,\n",
        "    seed=qadata_streaming_config['seed']\n",
        ")\n",
        "\n",
        "if False:\n",
        "    # starts at a random position\n",
        "    datasets_static_qa_val = streaming_take(\n",
        "        skip=0,\n",
        "        start_proportion=0,\n",
        "        chunksize=100,\n",
        "        list_of_streaming_datasets=qa_streaming_datsets,\n",
        "        probabilities=qa_probabilities,\n",
        "        datasizes=qa_datasizes,\n",
        "        convert_to_static = True\n",
        "\n",
        "    )\n",
        "\n",
        "    epoch = 0\n",
        "    # starts at a random position\n",
        "    train_start_proportion = np.random.RandomState(qadata_streaming_config['seed'] + epoch).random()*0.99\n",
        "    print(train_start_proportion)\n",
        "\n",
        "    # take: training chunk random for this epoch\n",
        "    datasets_static_qa_train = streaming_take(\n",
        "        skip=100,\n",
        "        start_proportion=train_start_proportion,\n",
        "        chunksize=400,\n",
        "        list_of_streaming_datasets=qa_streaming_datsets,\n",
        "        probabilities=qa_probabilities,\n",
        "        datasizes=qa_datasizes,\n",
        "        convert_to_static = True\n",
        "    )\n",
        "\n",
        "    datasets_static_qa = train_test_splits_from_stream_qa(\n",
        "        datasets_mlm_streaming_combined,\n",
        "        val_size = data_streaming_config['val_size'],#2000,\n",
        "        epoch = 0,\n",
        "        chunk_size =  data_streaming_config['train_chunk_size'],#6000,\n",
        "        max_chunk_start = data_streaming_config['max_chunk_start'],#1000000,\n",
        "        path_to_val_cache = 'val_qacache.pkl'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVO8t6irLjYO",
        "outputId": "d3cad831-f0fc-4a5a-e50c-0cb36eab3f7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying embedding-data/PAQ_pairs\n",
            "trying gbharti/finance-alpaca\n",
            "trying wiki_qa\n",
            "trying donfu/oa-stackexchange\n",
            "done initializing the QA streaming datasets\n",
            "STREAMING VAL-QA DATA: 100\n",
            "done 0\n",
            "done 1\n",
            "done 2\n",
            "done 3\n",
            "REALIZED VAL-QA DATA: 100\n",
            "SAVING VAL-QA SET: val_qa_cache.pkl\n",
            "0.3707947176588889\n",
            "STREAMING TRAIN QA-DATA: 500 STARTING AT: 0.371\n",
            "done 0\n",
            "done 1\n",
            "done 2\n",
            "done 3\n",
            "REALISED TRAIN QA-DATA SIZE: 375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,e in enumerate(qa_statics_datsets['val']):\n",
        "    if i<20:\n",
        "        continue\n",
        "    print(\"-------\\nQ:%s\\nA:%s\" % (e['query'], e['positives'][0].replace(\"\\n\",\" \") if bool(e['positives']) else e['negatives'][0].replace(\"\\n\",\" \")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HotkvzyKC0m-",
        "outputId": "42b493f2-f3cf-494d-ceb4-f21b9ca27689"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------\n",
            "Q:the exhaustive concordance of the bible is known as\n",
            "A:Higher Critical movement and with the Westcott-Hort version of the Greek text. Strong, a Methodist layman and college professor, was acceptable to the committee, but one cannot assume he shared all of its views. Strong's Concordance The Exhaustive Concordance of the Bible, generally known as Strong's Concordance, is a Bible concordance, an index of every word in the King James Version (KJV), constructed under the direction of James Strong. Strong first published his \"Concordance\" in 1890, while professor of exegetical theology at Drew Theological Seminary. The purpose of \"Strong's Concordance\" is not to provide content or commentary about the Bible,\n",
            "-------\n",
            "Q:when did episode 8 of humans come out\n",
            "A:Series 1, Episode 8 (Humans) without her and without Fred. The Hawkins return home. After Karen leaves, she is met by Pete and they reluctantly go off together. The final scene shows Niska on a train, with a copy of the programme. On 2 August 2015, \"Episode 8\" aired on Channel 4 in the UK to a viewership of 3.997 million. A further 491,000 households watched the episode on Channel 4 +1. On both channels, \"Humans\" was the highest rated show that week. UK reviews were positive. Michael Hogan of \"The Telegraph\" gave the episode 5 out of 5 stars, praising both the \"uniformly excellent\"\n",
            "-------\n",
            "Q:where is the city of lewisville in idaho\n",
            "A:Lewisville, Idaho Lewisville is a city in Jefferson County, Idaho, United States. The population was 458 at the 2010 census. Lewisville is part of the Idaho Falls Metropolitan Statistical Area. Lewisville was established in 1882. In 1960, Lewisville became the corporate headquarters of Idahoan Foods, a producer of dehydrated potato products such as instant mashed potatoes, potato casserole, and hash browns. In 2011, the headquarters was moved to Idaho Falls, south, though it still maintains its main plant in Lewisville. For the city's important role in Idaho's potato industry, Governor Butch Otter proclaimed August 11, 2007 \"Lewisville Day\" statewide. Lewisville\n",
            "-------\n",
            "Q:who gets the highest roller in monopoly junior\n",
            "A:most properties wins. The rules of the original \"Monopoly Junior\" game are very similar to the modern rules. Players are dealt $31 at the beginning of the game: five $1 notes, four $2, three $3, one $4 and one $5. Players take turns in order, with the initial player determined by chance before the game: players roll the die, and the highest roller goes first. A typical turn begins with the rolling of the die and the player advancing their token clockwise around the board the corresponding number of spaces. When the player lands on a vacant amusement they must\n",
            "-------\n",
            "Q:the ape foundation was founded by which two people\n",
            "A:APE Foundation APE Foundation The Association for Protection of the Environment (APE) is a non-governmental organization working on issues regarding the conservation, and restoration of the environment, education about permaculture and agroforestry among other things. The group says its mission is \"to protect the existing forest and wildlife, particularly in Khao Nor Chuchi Lowland Forest and to increase biodiversity in the area\". Among other issues, it is also concerned with endangered species, deforestation and climate change. APE was started in 2010 by a Thai and British group of conservation workers and volunteers who come from biology, forestry, design and teaching\n",
            "-------\n",
            "Q:For a car, what scams can be plotted with 0% financing vs rebate?\n",
            "A:The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.\n",
            "-------\n",
            "Q:Why does it matter if a Central Bank has a negative rather than 0% interest rate?\n",
            "A:That is kind of the point, one of the hopes is that it incentivizes banks to stop storing money and start injecting it into the economy themselves. Compared to the European Central Bank investing directly into the economy the way the US central bank has been doing. (The Federal Reserve buying mortgage backed securities) On a country level, individual European countries have tried this before in recent times with no noticeable effect.\n",
            "-------\n",
            "Q:Where should I be investing my money?\n",
            "A:Pay off your debt.  As you witnessed, no \"investment\" % is guaranteed.  But your debt payments are... so if you have cash, the best way to \"invest\" it is to pay off your debt.  Since your car is depreciating while your house may be appreciating (don't know but it's possible) you should pay off your car loan first.  You're losing money in more than one way on that investment.\n",
            "-------\n",
            "Q:Specifically when do options expire?\n",
            "A:Equity options, at least those traded in the American exchanges, actually expire the Saturday after the 3rd Friday of the month.  However, the choice to trade or exercise the options must be specified by the 3rd Friday. This is outlined by the CBOE, who oversees the exchange of equity options.  Their FAQ regarding option expiration can be found at http://www.cboe.com/LearnCenter/Concepts/Beyond/expiration.aspx.\n",
            "-------\n",
            "Q:Negative Balance from Automatic Options Exercise. What to do?\n",
            "A:Automatic exercisions can be extremely risky, and the closer to the money the options are, the riskier their exercisions are. It is unlikely that the entire account has negative equity since a responsible broker would forcibly close all positions and pursue the holder for the balance of the debt to reduce solvency risk.  Since the broker has automatically exercised a near the money option, it's solvency policy is already risky. Regardless of whether there is negative equity or simply a liability, the least risky course of action is to sell enough of the underlying to satisfy the loan by closing all other positions if necessary as soon as possible. If there is a negative equity after trying to satisfy the loan, the account will need to be funded for the balance of the loan to pay for purchases of the underlying to fully satisfy the loan. Since the underlying can move in such a way to cause this loan to increase, the account should also be funded as soon as possible if necessary. Accounts after exercise For deep in the money exercised options, a call turns into a long underlying on margin while a put turns into a short underlying. The next decision should be based upon risk and position selection.  First, if the position is no longer attractive, it should be closed.  Since it's deep in the money, simply closing out the exposure to the underlying should extinguish the liability as cash is not marginable, so the cash received from the closing out of the position will repay any margin debt. If the position in the underlying is still attractive then the liability should be managed according to one's liability policy and of course to margin limits. In a margin account, closing the underlying positions on the same day as the exercise will only be considered a day trade.  If the positions are closed on any business day after the exercision, there will be no penalty or restriction. Cash option accounts While this is possible, many brokers force an upgrade to a margin account, and the ShareBuilder Options Account Agreement seems ambiguous, but their options trading page implies the upgrade. In a cash account, equities are not marginable, so any margin will trigger a margin call.  If the margin debt did not trigger a margin call then it is unlikely that it is a cash account as margin for any security in a cash account except for certain options trades is 100%. Equities are convertible to cash presumably at the bid, so during a call exercise, the exercisor or exercisor's broker pays cash for the underlying at the exercise price, and any deficit is financed with debt, thus underlying can be sold to satisfy that debt or be sold for cash as one normally would. To preempt a forced exercise as a call holder, one could short the underlying, but this will be more expensive, and since probably no broker allows shorting against the box because of its intended use to circumvent capital gains taxes by fraud.  The least expensive way to trade out of options positions is to close them themselves rather than take delivery.\n",
            "-------\n",
            "Q:Approximation of equity value for company in default\n",
            "A:Generally \"default\" means that the company cannot pay off their debts, and since debt holders get paid before equity holders, their equity would be effectively worthless. That said, companies can emerge from Chapter 11 bankruptcy (reorganization) and retain equity value, but it is rare. Most times, stocks are de-listed or frozen on stock exchanges, and company's reorganization plan will cancel all existing equity shares, instead focusing all of their attention on paying back as much debt as possible. If the company issues new equity after reorganizing, it might provide a way for holders of the original equity to exchange their shares for the new equity, but it is rare, and the value is usually significantly less that the value of the original equity.\n",
            "-------\n",
            "Q:Is it true that 90% of investors lose their money?\n",
            "A:The game is not zero sum. When a friend and I chop down a tree, and build a house from it, the house has value, far greater than the value of a standing tree. Our labor has turned into something of value.  In theory, a company starts from an idea, and offers either a good or service to create value. There are scams that make it seem like a Vegas casino. There are times a stock will trade for well above what it should. When I buy the S&P index at a fair price for 1000 (through an etf or fund) and years later it's 1400, the gain isn't out of someone else's pocket, else the amount of wealth in the world would be fixed and that's not the case. Over time, investors lag the market return for multiple reasons, trading costs, bad timing, etc. Statements such as \"90% lose money\" are hyperbole meant to separate you from your money. A self fulfilling prophesy.   The question of lagging the market is another story - I have no data to support my observation, but I'd imagine that well over 90% lag the broad market. A detailed explanation is too long for this forum, but simply put, there are trading costs. If I invest in an S&P ETF that costs .1% per year, I'll see a return of say 9.9% over decades if the market return is 10%. Over 40 years, this is 4364% compounded, vs the index 4526% compounded, a difference of less than 4% in final wealth. There are load funds that charge more than this just to buy in (5% anyone?).  Lagging by a small fraction is a far cry from 'losing money.'  There is an annual report by a company named Dalbar that tracks investor performance. For the 20 year period ending 12/31/10 the S&P returned 9.14% and Dalbar calculates the average investor had an average return of 3.83%. Pretty bad, but not zero. Since you don't cite a particular article or source, there may be more to the story. Day traders are likely to lose. As are a series of other types of traders in other markets, Forex for one.  While your question may be interesting, its premise of \"many experts say....\" without naming even one leaves room for doubt.  Note - I've updated the link for the 2015 report. And 4 years later, I see that when searching on that 90% statistic, the articles are about day traders. That actually makes sense to me.\n",
            "-------\n",
            "Q:Can a company charge you for services never requested or received?\n",
            "A:In general, you can only be charged for services if there is some kind of contract. The contract doesn't have to be written, but you have to have agreed to it somehow. However, it is possible that you entered into a contract due to some clause in the home purchase contract or the contract with the home owners' association. There are also sometimes services you are legally required to get, such as regular inspection of heating furnaces (though I don't think this translates to automatic contracts). But in any case you would not be liable for services rendered before you entered into the contract, which sounds like it's the case here.\n",
            "-------\n",
            "Q:Working out if I should be registered as self-employed in the UK\n",
            "A:Being self employed just means you fill out some more forms in your annual self assessment for your \"profit\" from being self employed.  Profit = all the money you receive, minus any tax deductible cost that you spent for making that money (and all the cost must be documented, which means you have a folder with all the receipts and keep it safe). You pay normal income tax on all the profit, which means it is just added to your taxable income. What you do with the profit is up to you; you don't pay yourself a salary, just take the money (make sure you leave enough to pay your taxes).\n",
            "-------\n",
            "Q:About eToro investments\n",
            "A:For eToro, just like any other brokerage firm, you can lose your entire capital. I suggest that you invest in one or more exchange-traded funds that track major indexes.  If not, just put your money in fixed deposit accounts; gain a bit of interest and establish an emergency fund first before investing money that you feel you are able to lose.\n",
            "-------\n",
            "Q:Pay off car loan entirely or leave $1 until the end of the loan period?\n",
            "A:Not sure if it is the same in the States as it is here in the UK (or possibly even depends on the lender) but if you have any amount outstanding on the loan then you wouldn't own the vehicle, the loan company would. This often offers extra protection if something goes wrong with the vehicle - a loan company talking to the manufacturer to get it resolved carries more weight than an individual. The laon company will have an army of lawyers (should it get that far) and a lot more resources to deal with anything, they may also throw in a courtesy car etc.\n",
            "-------\n",
            "Q:Including the region where you live in your investment portfolio?\n",
            "A:Diversification is a risk-mitigation strategy. When you invest in equities, you generally get a higher rate of return than a fixed income investment. But you have risks... a single company's market value can decline for all sorts of reasons, including factors outside of the control of management. Diversification lets you spread risk and concentrate on sectors that you feel offer the best value. Investing outside of your currency zone allows you to diversify more, but also introduces currency risks, which require a whole other level of understanding. Today, investing in emerging markets is very popular for US investors because these economies are booming and US monetary policy has been weakening the dollar for some time. A major bank failure in China or a flip to a strong dollar policy could literally implode those investments overnight. At the end of the day, invest in what you understand. Know the factors that can lower your investment value.\n",
            "-------\n",
            "Q:Are there any rules against penalizing consumers for requesting accurate credit reporting?\n",
            "A:The Fair Credit Reporting Act specifies in some detail on pages 50-54 (as labeled in the footer, 55-59 as pages in pdf) the process that occurs when a consumer initiates a dispute.  The safe outcome for the reporting agency is to remove the information in dispute  from reports within 30 days if the reporting party does not certify the information is complete and accurate (with other statutory timelines for communication to the customer and the reporter).   If you initiate a dispute, then the agency is following the law by deleting the reported information, outside new input from the furnisher.  If this is unsatisfactory, you have the following statutory right within § 611. Procedure in case of disputed accuracy [15 U.S.C. § 1681i (d) Notification of deletion of disputed information. Following any deletion of   information which is found to be inaccurate or whose accuracy can no longer   be verified or any notation as to disputed information, the consumer   reporting agency shall, at the request of the consumer, furnish notification   that the item has been deleted or the statement, codification or summary   pursuant to subsection (b) or (c) of this section to any person specifically   designated by the consumer who has within two years prior thereto received   a consumer report for employment purposes, or within six months   prior thereto received a consumer report for any other purpose, which   contained the deleted or disputed information.  The section that binds furnishers of information (§ 623. Responsibilities of furnishers of information to consumer reporting agencies [15 U.S.C. § 1681s-2], starting on page 78 in the footer) places on them the following specific duties: (B) Reporting information after notice and confirmation of errors.   A person shall not furnish information relating to a consumer to   any consumer reporting agency if   (i) the person has been notified by the consumer, at the address   specified by the person for such notices, that specific   information is inaccurate; and   (ii) the information is, in fact, inaccurate. ... (2) Duty to correct and update information. A person who   (A) regularly and in the ordinary course of business furnishes information   to one or more consumer reporting agencies about the   person’s transactions or experiences with any consumer; and   (B) has furnished to a consumer reporting agency information   that the person determines is not complete or accurate, shall   promptly notify the consumer reporting agency of that determination   and provide to the agency any corrections to that information,   or any additional information, that is necessary to make   the information provided by the person to the agency complete   and accurate, and shall not thereafter furnish to the agency any   of the information that remains not complete or accurate. So there you have it: they have to stop reporting inaccurate information, and \"promptly\" notify the credit agency once they've determined what is incomplete or inaccurate. I note no specific statutory timeline for this investigation.\n",
            "-------\n",
            "Q:What are the reasons to get more than one credit card?\n",
            "A:Another good reason: if you have to replace a card due to damage, loss, or identity theft it's nice to have a backup you can use until the new card for your primary account arrives. I know folks who use a secondary card for online purchases specifically so they can kill it if necessary without impacting their other uses, online arguably being at more risk. If there's no yearly fee, and if you're already paying the bill in full every month, a second card/account is mostly harmless. If you have trouble restraining yourself with one card, a second could be dangerous.\n",
            "-------\n",
            "Q:Why is economic growth so important?\n",
            "A:One of the best answers to this question that I've ever read is in a paper published by Robert Lucas in the Journal of Economic Perspectives. That journal is meant to a be a place for experts to write about their area of expertise (in economics) for a general but still technically-minded audience. They recently opened up the journal as free to the public, which is a fantastic resource -- you no longer need a subscription to JSTOR (or whatever) to read it.  You can read the abstract to the paper, and find a link to it, here. One of the things that I like a lot about this paper is that it strips out absolutely everything even slightly unnecessary to thinking about a macroeconomy, and just discusses what one can arrive at with a very very simple model. Of course, with great simplicity come sacrifice about details. However, it does a great job of answering your question, \"why do people care about growth?\" A quick note: the key to understanding the answer to your question is to think about things in terms of \"the long term\"  -- not even looking forward to the future, because we'll be dead by then, but looking back to the past. The key to the importance of growth is that, for the last ~200 years, the US has, on average, had maybe 2-3% \"real growth\" per year (I'm pulling these numbers out of my head; I think much better numbers are in that paper somewhere). On average, over that period of time, this growth has meant that the quality of life that one has, if one lives in a country experiencing this growth, is enormous compared to countries that do not experience this average growth over that period.  Statistically speaking, growth is also somewhat auto-correlated. Roughly speaking, if it was low the last few periods, you can expect it to be low the next period. Same thing if it's high.   Then, the reason we care about growth right now: if you have too many periods of low growth, pretty soon the average \"over the long term\" growth will be pulled down -- and then quality of life can't be higher in the future (which quickly becomes someone's \"present\"). The paper above makes this point with a very simple model. Of course, none of this touches on distributional issues, which are another issue entirely. With respect to, \"The economy needs to grow to just keep up with its debt repayments,\" I think the answer is along the lines of, \"sometimes countries get into debt expecting that growth will increase their resources in the future, and thus they can pay back their debt.\" That strategy is, of course, the strategy that anyone borrowing (\"taking out a loan\") should be employing -- you should expect that your future income will be enough to pay back your interest+principle on a loan you took. Otherwise you're irresponsible. At the aggregate level, production is the nation's \"income\" -- it is what you have, all that you have (as a nation) to pay back any debt you've incurred at the national level.\n",
            "-------\n",
            "Q:Investment strategy for retired couple\n",
            "A:You need to have them consult with a financial adviser that has a focus on issues for seniors. This is because they are beyond the saving for retirement phase and are now in the making-their-money-last phase. They also have issues related to health insurance, IRA RMDs, long term care insurance. The adviser will need to review what they have and determine how to make sure it is what they need. It is great idea for you to go along with them so you can understand what needs to be done. You will want an adviser that charges you a fee for making the plan, not one that makes a commission based on what products you buy or invest in.\n",
            "-------\n",
            "Q:What is the US Fair Tax?\n",
            "A:You asked about the challenges. The transition itself is the biggest one. For people to get used to the tax at the register vs at their paycheck. For a great number of people to find new work. I don't know the numbers, but anyone involved with personal income taxes would be out of work. Sales tax is already part of the process in most states, bumping it to a federal tax wont add too much in overhead.  I make no moral judgment, but consider, most prostitutes and drug dealers are avoiding income tax, but they still are buying the same goods in stores you and I are. This proposed tax reduces the collection noncompliance, and brings more people into \"the system\".  Another factor some may not like is the ability to affect behavior by picking and choosing what to promote, via deductions, such as home buying or charity.\n",
            "-------\n",
            "Q:Does bull/bear market actually make a difference?\n",
            "A:If you know what you are doing, bear markets offer fantastic trading opportunities. I'm a futures and futures options trader, and am equally comfortable trading long or short, although I have a slight preference for the short side, in that moves are typically much quicker to the down side.\n",
            "-------\n",
            "Q:Does Tennessee have anything like a principal residence exemption?\n",
            "A:There's no homestead property tax exemption in TN. According to the TN comptroller site: Exemptions Exemptions are available for religious, charitable, scientific, and   nonprofit educational uses, governmental property, and cemeteries.   Most nongovernmental exemptions require a one-time application and   approval by the State Board of Equalization (615/401-7883) and there   is a May 20 application deadline. There is no \"homestead\" exemption,   but low income elderly and disabled persons and disabled veterans may   qualify for a rebate of taxes on a specified portion of the value of   property used as their residence. Business inventories held for sale   or exchange by merchants subject to the business gross receipts tax,   are not assessable. Farm and residential tangible personal property   are not assessable.\n",
            "-------\n",
            "Q:How can it be possible that only ~10% of options expire worthless, and only ~10% are exercised?\n",
            "A:Consider the futures market. Traders buy and sell gold futures, but very few contracts, relatively speaking, result in delivery. The contracts are sold, and \"Open interest\" dwindles to near zero most months as the final date approaches. The seller buys back his short position, the buyer sells off his longs.  When I own a call, and am 'winning,' say the option that cost me $1 is now worth $2, I'd rather sell that option for even $1.95 than to buy 100 shares of a $148 stock. The punchline is that very few option buyers actually hope to own the stock in the end. Just like the futures, open interest falls as expiration approaches.\n",
            "-------\n",
            "Q:Will capital gains affect my tax bracket?\n",
            "A:I'm not sure where you are, but in the United States capital gains are taxed at a lower rate than other types of income. On the 1040, captial gains income is separated from earned income, and income tax is calculated just on earned income. Then capital gains tax is calculated on capital gains income, and then added to income tax afterward.\n",
            "-------\n",
            "Q:Can I sell a stock immediately?\n",
            "A:You can*, if the market is open, in a normal trading phase (no auction phase), works, and there is an existing bid or offer on the product you want to trade, at the time the market learns of your order. Keep in mind there are 2 prices: bid and offer. If the current bid and current offer were the same, it would immediately result in a trade, and thus the bid and offer are no longer the same. Market Makers are paid / given lower fees in order to maintain buy and sell prices (called quotes) at most times. These conditions are usually all true, but commonly fail for these reasons: Most markets have an order type of market order that says buy/sell at any price. There are still sanity checks put in place on the price, with the exact rules for valid prices depending on the stock, so unless it's a penny stock you won't suddenly pay ten times a stock's value. *The amount you can buy sell is limited by the quantity that exists on the bid and offer. If there is a bid or offer, the quantity is always at least 1.\n",
            "-------\n",
            "Q:What can a CPA do that an EA cannot, and vice versa?\n",
            "A:Enrolled Agents typically specialize only in tax matters.  Their status allows them to represent clients before the IRS (which a CPA can also do) See the IRS site regarding Enrolled Agents Their focus is much narrower than a CPA and you would only hire them for advice or representation with tax related matters.  (e.g. you'd not hire an enrolled agent to do an external audit)  A CPA is a much broader certification, covering accounting in general, of which taxes are only a portion. A CPA may or may not specialize in tax matters, so if you have a tax related issue, especially an audit, review or appeal, you may want to query a prospective CPA as to their experience with tax matters and representing clients, appeals, etc. You would likely be better off with an EA than a CPA who eschews tax work and specializes in other things such as financial auditsOn the other hand if you have need of advice that is more generalized to accounting, audits, etc then you'd want to talk with a CPA as opposed to an EA\n",
            "-------\n",
            "Q:Is my stock gone forever from a reverse split / bought by another company?\n",
            "A:GT BIOPHARMA, INC. ANNOUNCES REVERSE STOCK SPILT AS PART OF OXIS-GEORGETOWN PLANNED MERGER LOS ANGELES, CA / ACCESSWIRE / August 21, 2017 / GT Biopharma Inc.   (formerly known as Oxis International, Inc.) announced today a   1-for-300 reverse stock split. Shareholders of GT Biopharma Inc.   (OTCQB: OXIS and Euronext Paris: OXI.PA) will be issued 1 share of   common stock for every 300 shares common stock that they owned. If you owned fewer than 300 shares, they cashed you out.\n",
            "-------\n",
            "Q:Why does quantitative easing negatively affect stocks?\n",
            "A:Can you isolate the market impact to just the Fed's quantitative easing?  Can you rule out the future economic predictions of low growth and that there are reasons why the Fed has kept rates low and is trying its best to stimulate the economy?  Just something to consider here. The key is to understand what is the greater picture here as well as the question of which stock market index are you looking at that has done so badly.  Some stocks may be down and others may be up so it isn't necessarily bad for all equally.\n",
            "-------\n",
            "Q:how are glacier caves formed?\n",
            "A:A partly submerged glacier cave on Perito Moreno Glacier .\n",
            "-------\n",
            "Q:how are glacier caves formed?\n",
            "A:The ice facade is approximately 60 m high\n",
            "-------\n",
            "Q:how are glacier caves formed?\n",
            "A:Ice formations in the Titlis glacier cave\n",
            "-------\n",
            "Q:how are glacier caves formed?\n",
            "A:A glacier cave is a cave formed within the ice of a glacier .\n",
            "-------\n",
            "Q:how are glacier caves formed?\n",
            "A:Glacier caves are often called ice caves , but this term is properly used to describe bedrock caves that contain year-round ice.\n",
            "-------\n",
            "Q:How are the directions of the velocity and force vectors related in a circular motion\n",
            "A:In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.\n",
            "-------\n",
            "Q:How are the directions of the velocity and force vectors related in a circular motion\n",
            "A:It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.\n",
            "-------\n",
            "Q:How are the directions of the velocity and force vectors related in a circular motion\n",
            "A:The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.\n",
            "-------\n",
            "Q:How are the directions of the velocity and force vectors related in a circular motion\n",
            "A:The equations of motion describe the movement of the center of mass of a body.\n",
            "-------\n",
            "Q:How are the directions of the velocity and force vectors related in a circular motion\n",
            "A:Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.\n",
            "-------\n",
            "Q:How are the directions of the velocity and force vectors related in a circular motion\n",
            "A:Since the object's velocity vector is constantly changing direction, the moving object is undergoing acceleration by a centripetal force in the direction of the center of rotation.\n",
            "-------\n",
            "Q:How are the directions of the velocity and force vectors related in a circular motion\n",
            "A:Without this acceleration, the object would move in a straight line, according to Newton's laws of motion .\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:Apollo Creed is a fictional character from the Rocky films , initially portrayed as the Undisputed Heavyweight Champion of the World.\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:He was played by Carl Weathers .\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:Creed had multiple nicknames, including The Master of Disaster, The King of Sting, The Dancing Destroyer, The Prince of Punch, The One and Only and The Count of Monte Fisto.\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:Urban legend states that Apollo Creed's name is a wordplay on the Apostles' Creed , a statement of belief used in Christian churches.\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:All of Apollo's championship fights were scheduled for the 15 round distance.\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:Championship fights did not convert from 15 rounds to 12 rounds until 1987.\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:Rocky Balboa is often wrongly credited with popularizing the red, white, and blue trunks; Creed was the first man to wear them (latterly worn by Rocky Balboa in the 3rd and 4th installments and finally by Tommy \"The Machine\" Gunn ( Tommy Morrison ) in the 5th installment) although normally he wore red and white, as seen in Rocky II.\n",
            "-------\n",
            "Q:how did apollo creed die\n",
            "A:Balboa's signature colors were black and gold—colors he used in the latest movie .\n",
            "-------\n",
            "Q:how long is the term for federal judges\n",
            "A:In the United States, the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution .\n",
            "-------\n",
            "Q:how long is the term for federal judges\n",
            "A:In addition to the Supreme Court of the United States , whose existence and some aspects of whose jurisdiction are beyond the constitutional power of Congress to alter, acts of Congress have established 13 courts of appeals (also called \"circuit courts\") with appellate jurisdiction over different regions of the United States, and 94 United States district courts .\n",
            "-------\n",
            "Q:how long is the term for federal judges\n",
            "A:Every judge appointed to such a court may be categorized as a federal judge; such positions include the Chief Justice and Associate Justices of the Supreme Court, Circuit Judges of the courts of appeals, and district judges of the United States district courts .\n",
            "-------\n",
            "Q:how long is the term for federal judges\n",
            "A:All of these judges described thus far are referred to sometimes as \"Article III judges\" because they exercise the judicial power vested in the judicial branch of the federal government by Article III of the U.S. Constitution.\n",
            "-------\n",
            "Q:how long is the term for federal judges\n",
            "A:In addition, judges of the Court of International Trade exercise judicial power pursuant to Article III.\n",
            "-------\n",
            "Q:Did the Greeks build temples for all of the children of Cronus?\n",
            "I know that the Ancient Greeks built temples for a lot of the children of Cronus, such as the Temple of Zeus and the Temple of Hera. Were temples built for all of the children of Cronus, or were they only built for the major ones? If some were left out, is there any indication of why?\n",
            "A:According to the traditional geneaology of the Greek Gods, Cronus had six children with Rhea: Hestia, Zeus, Hera, Poseidon, Hades and Demeter. All children were part of at least one major variation of the Twelve Olympians and - with the exception of Hestia - had temples honouring them. Hestia was Cronus firstborn and her sanctuary was the hearth of the Prytaneion, the political and religious center of the community. Also, Hestia was thought of as being present in every offering fire in all temples and received first offering in sacrifices. Thus, she didn't need temples of her own.Of course there may have been temples honouring Hestia that we simply don't know about. After all, absence of evidence is not evidence of absence.\n",
            "-------\n",
            "Q:Was the Minotaur a single being, or a race?\n",
            "In the legend of Theseus and the Minotaur, we know that the Minotaur dwelled at the center of the maze built by Daedalus. However, the creature itself (part man, part bull) doesn't appear to show up in any other well-known legends.\n",
            "\n",
            "Was this Minotaur the only being like him, or was he part of a larger \"race\" of creatures?\n",
            "A:In Greek Mythology, the Minotaur was a singular creature, the man/bull hybrid offspring of King Minos' wife. Minotaur is a proper noun meaning \"bull of Minos\", while the creature itself was known as Asterion in its native Crete. The use of Minotaur as a _species_ name, and the idea that more of these creatures exist, is a purely 20th Century concept, exampled in such works as _The Lion, the Witch, and the Wardrobe_ and Thomas Burnett Swann's _Minotaur Trilogy_. In Dante's _Inferno_ (14th C) he is still very much the singular Minotaur. See here for various references from Classical sources about the Minotaur as a singular creature.\n",
            "-------\n",
            "Q:Did Zeus have any male lovers?\n",
            "Many of the Greek gods were bisexual. Did Zeus have any male lovers?\n",
            "A:While the vast majority of Zeus's lovers were female, one of Zeus's lovers was the mortal Ganymede. Ganymede is noted as the only one of Zeus's lovers to whom he granted immortality.\n",
            "-------\n",
            "Q:Why did Egyptian Gods have animal heads?\n",
            "Most Egyptian gods have animal heads. Why is that?\n",
            "A:Egyptian gods were often depicted in therianthrophic – part human, part animal form, to depict the personality of that particular god/ess in a symbolic way. For example, Sekhmet, goddess of ferocious war, was sometimes shown with the head a lioness, as lions are ferocious creatures. Similarly Anubis was shown with a jackal head because the jackal was associated with the necropolis and Anubis was a god of the dead. There are also theriomorphic depictions, where gods are shown entirely in animal form. These are quite common, and in fact were the most common representations of gods in the very earliest periods of Egyptian history. For example, Anubis as a black jackal, or Thoth as either an ibis or a white baboon. Taweret was even a hybrid of hippo, crocodile and lioness. It is the same reasoning behind why Christians equate Jesus with the lamb, or why we give angels wings.\n",
            "-------\n",
            "Q:Who gave Hermes his winged shoes?\n",
            "Many tools and weapons were given to the gods as gifts in order to perform their daily tasks. However there is no mention about how Hermes got his fabled shoes. So were they crafted or given as a gift? How did Hermes get his winged shoes?\n",
            "A:Zeus did that. Hermes was the son of Zeus, but he grew up very quickly and one day he decided to seek out adventure. The first thing he thought of was to steal Apollon's oxes and he actually did that. Apollon didn't know who it was at first, but he soon found out that Hermes stole the oxes and took Hermes to Olympus on trial. Hermes confessed the crime and made a deal with Zeus which made him the messenger of the gods. After that, Zeus gave Hermes a wand, a round hat and the Sandals.> When Zeus called Hermes to Olympus to chide him for stealing and lying, Hermes promised he would never again lie if Zeus named him as his messenger and herald. Zeus quickly accepted this offer, and told his son that his duties would also include protecting travelers, promoting trade, and negotiating treaties.> > To ensure rapid delivery of his messages, Zeus presented Hermes with golden winged sandals as swift as the wind> > The Little Rascal: Hermes\n",
            "-------\n",
            "Q:Why are Kore and Persephone interchangeable in the myth regarding Hades wife?\n",
            "In Greek mythology, Kore and Persephone were interchangeable as Hades' wife. Which is it? Kore or Persephone?\n",
            "A:Kore was the Ancient Greek word for young girl, the equivalent of our maiden, and Persephone was often referred to as such to highlight her innocence.\n",
            "-------\n",
            "Q:What is the River Styx?\n",
            "The River Styx is mentioned quite a lot when a Greek hero meets his demise. \n",
            "\n",
            "However is this really a body of water in Hades? \n",
            "\n",
            "Is it made out of something else? \n",
            "\n",
            "What is the River Styx?\n",
            "A:## The River Styx is one of the five rivers of the Greek Underworld, rivers that separate Hades from the land of the living.During the Titanomachy (the Titan war), which was fought between the Titans) and the Olympians, the goddess Styx sided with the Olympians.Once the war was won, Zeus, king of the Olympians, promised that every oath be sworn on Styx's name, as a sign of the greatest respect.He also proceeded to name the River Styx after her.Achilles was dipped in it as a child and was rewarded with invulnerability, except for his heel, which was where his mother was holding him, hence the term : Achilles' heel.The full list of rivers surrounding Hades :  1. Acheron \\- the river of woe  2. Cocytus \\- the river of lamentation  3. Phlegethon \\- the river of fire  4. Lethe \\- the river of forgetfulness  5. Styx \\- the river of hate\n",
            "-------\n",
            "Q:Was the Mjölnir usable by only the worthy?\n",
            "Present works of fiction present Mjölnir as a hammer of unbelievable power, which can only be used by the worthy.\n",
            "\n",
            "But, when the Mjölnir is given to Thor, its properties are described:\n",
            "\n",
            "> Then he gave the hammer to Thor, and said that Thor might smite as hard as he desired, whatsoever might be before him, and the hammer would not fail; and if he threw it at anything, it would never miss, and never fly so far as not to return to his hand; and if be desired, he might keep it in his sark, it was so small; but indeed it was a flaw in the hammer that the fore-haft was somewhat short.\n",
            "\n",
            "It says nothing of the \"worthiness\" of the weilder. Is there any significant evidence in Norse mythology about the Mjölnir and the worthiness of its user?\n",
            "A:As your quote shows, the story of it's creation makes no such specification. If stealing it qualifies as \"using\" (I believe, in the the Marvel universe, simply lifting the hammer qualifies), the Þrymskviða from the Poetic Edda tells the story of the giant Þrymr stealing Mjollnir, in order to extort the gods into giving him Freyja as his wife. > \"I have Hloritha's  >  Hammer hidden:  >  Under eight miles  >  of earth it lies,  >  And such no one  >  shall see again  >  Save he first bring me  >  Freyja to wife!\" It does depend on your definition of \"worthy\", but I think Þrymr's intentions disqualify him by most reasonable definitions. Seems to indicate that the worthiness requirement is a Marvel invention.\n",
            "-------\n",
            "Q:Is there any explanation in greek mythology for the creation of Uranus and Gaea?\n",
            "I was just wondering because there never seems to be a beginning. Greek mythology always seems to start with just there being Uranus and Gaea with no events before that. Is there a beginning before the beginning?\n",
            "A:Well, before Gaea and Uranus there were a few gods, but not many. In the Greek story of creation it says> In the beginning there was only Chaos. Then out of the void appeared Erebus, the unknowable place where death dwells, and Night. All else was empty, silent, endless, dark. Then, Love was born bringing along the beginning of order. From Love emerged Light, followed by Gaea, the earth.So before Gaea, there was Chaos, Erebus, Night, and Love. Love then created Light, which in turn had Gaea. Then, Erebus and Night has Ether and Day, heavenly and earthly light respectively and Night alone had \"all things that dwell in the darkness haunting mankind.\" This includes Death, Fate, and Sleep. Gaea then gave birth to Uranus, who she then married.So, there were powerful beings before Gaea and Uranus. How these beings came into existence is less clear, but it seems that how it all starts with Chaos is similar to the creation story for Christians. Chaos was just there.\n",
            "-------\n",
            "Q:What exactly did Apollo do with respect to the Sun?\n",
            "My understanding is that Helios (a Titan) was actually the one who drove the Sun Chariot across the sky every day. But why, then, was Apollo the god of the Sun?\n",
            "\n",
            "Am I correct in this understanding? Was Apollo (as a son of Zeus) sort of Helios's boss? He could ride the chariot if he wanted to, but he was also free to mate with Daphne, Cyrene and so forth, and otherwise meddle in human affairs, while Helios had to drive the bus every day? Or did it work another way?\n",
            "A:Apollo didn't have any solar properties in Homeric times, and he and Helios were clearly distinct entities. Helios is extensively discussed in Book XII of the Odyssey, for example. From the 5th century BCE and onwards Helios started to be identified with Apollo. An early reference to the fusion of the two beings can be found in fragment 781 of Euripidis' Faethon, where the poet tells us that Helios is \"rightly called Apollo\": > ὦ καλλιφεγγὲς Ἥλι᾿, ὥς μ᾿ ἀπώλεσας καὶ τόνδ᾿ Ἀπόλλων δ᾿ ἐν βροτοῖς ὀρθῶς καλῇ, ὅστις τὰ σιγῶντ᾿ ἀνόματ᾿ οἶδε δαιμόνων. The association became a lot more commonplace during Hellenistic times.\n",
            "-------\n",
            "Q:What happened to Medusa's sisters?\n",
            "It is fairly well known that Medusa, the snake-headed Gorgon, had two sisters, Stheno and Euryale. \n",
            "\n",
            "While the story of Medusa is concluded when Perseus beheads her, in modern retellings and versions, we don't hear about her sisters. What happens to the other two Gorgons? Are they immortal? Do they seek revenge?\n",
            "A:In pseudo-Apollodorus' version, Medusa's sisters sought revenge on Perseus, who escaped them by using the Cap of Hades (which rendered its wearer invisible):> So Perseus put the head of Medusa in the wallet (kibisis) and went back again; but the Gorgons started up from their slumber and pursued Perseus: but they could not see him on account of the cap, for he was hidden by it.> > Source: Apollod. 2.4.3Also, at least according to Hesiod, Medusa's sister were immortal:> And again, Ceto bore to Phorcys the fair-cheeked Graiae, sisters grey from their birth: and both deathless gods and men who walk on earth call them Graiae, Pemphredo well-clad, and saffron-robed Enyo, and the Gorgons who dwell beyond glorious Ocean in the frontier land towards Night where are the clear-voiced Hesperides, Sthenno, and Euryale, and Medusa who suffered a woeful fate: she was mortal, but the two were undying and grew not old.> > Source: Hes. Th. 275\n",
            "-------\n",
            "Q:How did Gilgamesh die?\n",
            "Do we know how and in which circumstances Gilgamesh died?\n",
            "\n",
            "According to these answers seems that The Epic of Gilgamesh doesn't mention that, however Wikipedia page mention something about Sumerian poem - The Death of Gilgamesh.\n",
            "A:According to **The Electronic Text Corpus of Sumerian Literature** , my best guess from reading the translated text provided is he died of old age :> ..... hero ...... has lain down and is never to rise again. ...... has lain down and is never to rise again. He of well-proportioned limbs ...... has lain down and is never to rise again. ...... has lain down and is never to rise again. He who ...... wickedness has lain down and is never to rise again. The young man ...... has lain down and is never to rise again. He who was perfect in ...... and feats of strength has lain down and is never to rise again. ......It doesn't give an specific explanation for his death, but the text is fragmentary at best and several parts are missing.\n",
            "-------\n",
            "Q:Importance of Dionysos/Bacchus in Orphism\n",
            "How did Dionysus/Bacchus become the central figure of Orphism, given the relatively modest importance he has in classical Greek and Roman mythology?\n",
            "\n",
            "From a semi-god of Wine in the latter, he becomes in the former the central character of a metempsychosis-centered, mystical cult prescribing an \"ascetic\"(!) way of life. \n",
            "\n",
            "In Ovid's Metamorphosis he is even depicted as quite a powerful and vengeful god.  \n",
            "There seems to be quite a mismatch between both visions of the supposedly same character: is it possible the Orphic cult was in fact worshiping another imported character, foreign to the Greek/Roman pantheon, that was later assimilated to Dionysus?\n",
            "A:Dionysus was a mortal that was raised to divinity. While he is most well known for wine and revelry, his portfolio also grew to include:  * festivals  * fertility  * the wilds  * crops  * sanityThese are centrally important to the daily lives of average citizens for the time. Sure Zeus is the king, and sure Poseidon is incredibly powerful, but I need my crops to grow, sons to help me run the farm and carry on my name and lets face it an opportunity to drown my sorrows once in a while. Orphism espouses the idea of an immortal soul and in a similar fashion to Hindu reincarnation the goal of the follower is to exit a cyclical pattern of death and rebirth in human bodies to become one with the gods.Who better to worship and lead such a 'religion' than a man who became a god himself.\n",
            "-------\n",
            "Q:Were Sirens humans or Monsters?\n",
            "I can't seem to figure out if the Sirens) were, like, half human-half bird monsters, attracting men with their magical song...\n",
            "\n",
            "!Wikipedia Bird Image\n",
            "\n",
            "or if they were also very beautiful women.\n",
            "\n",
            "!Wikipedia Siren Image\n",
            "\n",
            "Were they humans with magical abilities / harps? Or did they have power derived from the blood of gods? Is the latter interpretation a (relatively) modern revision?\n",
            "A:There are a lot of different stories about the Sirens'nature, looks, number and parentage. One that keeps coming back is that initially they were indeed beautiful sea nymphs/ demi-godesses, able to lure seamen purely with the beauty of their song. They were also Persephone's handmaidens. When Persephone was abducted by Hades, Demeter gave them the bodies of birds so that they could assist in the search for the girl (in some versions they requested this, in others , e.g. that of Ovid, they were punished by Demeter because she held them responsible for Persephone's abduction - due to negligence).Check out this link: it has a lot of information gathered on the sirens from different sources.\n",
            "-------\n",
            "Q:Was Eurystheus a lover of Heracles? Did Heracles have any other male lovers?\n",
            "In some versions of the 12 labors of Heracles, Eurystheus is a lover of Heracles and he undertook the 12 labors for Eurystheus' love. Did Heracles have any other male lovers?\n",
            "A:Heracles had a number of male lovers. Plutarch's Dialogue sur l'amour (Eroticos) mentions that the number of Heracles' male lovers were beyond counting. Hence, the list of lovers presented here is incomplete (most probably):  * Abderus  * Admetus   * Adonis  * Corythus  * Diomus  * Elacatas  * Euphemus  * Hylas   * Iolaus  * Iphitus  * Jason  * Nestor  * Nireus  * Perithoas  * Philoctetes  * Phrix  * SostratusNowhere it is mentioned that Eurystheus and Heracles were lovers, neigh, had feeling for each other. Hence the probability of Eurystheus being one of Heracles' lovers is ruled out.sources:  Wikipedia  Hellenica\n",
            "-------\n",
            "Q:What was the Plant of Everlasting Youth?\n",
            "In which story we can find information about the Plant of Everlasting Youth and what kind of plant it was?\n",
            "\n",
            "Did it give immortality or something else?\n",
            "A:The information about the _Plant of Everlasting Youth_ form the Sumerian mythos can be found on the second half of **The Epic of Gilgamesh**.In the _Tablet eleven_ Utnapishtim's wife asks her husband to offer a parting gift to Gilgamesh, so he learns that > at the bottom of the sea there lives a boxthorn-like plant that will make **him young again**(Note: there is already a related question with an answer that states that this plant _was most probably a species of Rhamnus_ ).The _Tablen eleven_ states that > if you can possess this plant, you'll be again as you were in your youth [...] with it a man can regain his vigourand that Gilgamesh was planing to test this plant on a man of old age to see it the plan would rejuvenate him.The epic explains how Gilgamesh loses the plant, so he can never make use of it. It is not described if it rejuvenating effects ara permanent or just a work-only-once-per-take property.\n",
            "-------\n",
            "Q:What items were made by the dwarves for the Norse gods?\n",
            "On the Wikipage of Mjölnir, it is said to be made by the dwarves Eitri and Brokkr. Wikipedia also states that they created other items for the gods. Those items being: Skidbladnir, the ship of Freyr, Mjölnir, Draupnir and Gungnir.\n",
            "\n",
            "Wiki Quotes:\n",
            "\n",
            "> \"the Sons of Ivaldi are a group of dwarfs who fashion Skidbladnir, the ship of Freyr, and the Gungnir, the spear of Odin, as well as golden hair for Sif to replace what Loki had cut off.\"\n",
            "> \n",
            "> \"Eitri succeeded in making the golden boar Gullinbursti, the golden ring Draupnir, and the hammer Mjöllnir.\"\n",
            "\n",
            "My question being, are there any other items that the dwarves made for the gods of the Norse mythology?\n",
            "A:The objects mentioned in your question were created by Eitri and Brokkr, and the Sons of Ivaldi. However, there are more objects that exist which were crafted by the dwarves. You can find a list of objects belonging to Norse deities here:## **Viking Mythology**## **Timeless Myth**Most of the objects mentioned in the list were created by the Dwarf craftsmen.\n",
            "-------\n",
            "Q:How many Annunaki were living on Earth at the peak of their time?\n",
            "The Anunnaki were a group of deities in ancient Mesopotamian culture.\n",
            "\n",
            "How many of them were there at the peak time (which we know about)?\n",
            "\n",
            "For example on Wikipedia page we can read:\n",
            "\n",
            "> In the Epic of Creation, it is said that there are 300 lgigu of heaven.\n",
            "A:Based on excavation and digs we have currently found over 560 deities. However scientist believe that there could be as many as 750.According to Bottéro's book titled: _Religion in Ancient Mesopotamia_> A Sumerian list of around 560 deities that did this was uncovered at Fâra and Tell Abû Ṣalābīkh and dated to circa 2600 BCE, ranking five primary deities as being of particular importance.\n",
            "-------\n",
            "Q:How are future apocalyptic events detailed so greatly?\n",
            "For example, \n",
            "\n",
            "From Wikipedia article on Ragnarök (emphasis mine):\n",
            "\n",
            "> In Norse mythology, Ragnarök is a series of **future events** , including a great battle foretold to ultimately result in the death of a number of major figures (including the gods Odin, Thor, Týr, Freyr, Heimdallr, and Loki), the occurrence of various natural disasters, and the subsequent submersion of the world in water. Afterward, the world will resurface anew and fertile, the surviving and returning gods will meet, and the world will be repopulated by two human survivors . Ragnarök is an important event in the Norse canon, and has been the subject of scholarly discourse and theory.\n",
            "\n",
            "Not wanting to make the question broad, I'm putting it in scope of the Norse mythology and it becomes: **If the events of Ragnarok are set in the future, how is it that it is detailed so greatly at present?**\n",
            "A:In the Völuspa (part of the poetic Edda), the tale is told to Odin as a prophecy by a völva who tell him both the story of earth creation and destruction. In the Gylfaginning (part of the prose Edda), which quotes extensively the latter, the tale is told by three characters in Ásgard (Hárr, the king, Janhárr and Thridi). Presumably in the first case it is a vision that the völva had while in the second case the characters are, I think, meant to be omniscient. Alternatively, an interesting theory is the one argued by Rudolf Simek (in _Lexikon der germanischen Mythologie_ ), according to which the norse timeline is a palingenesis (i.e. time is cyclical): Ragnarokr being, according to him, a prelude to the creation myth. In this case these events would be set both in the future and in the past, which would explain how the völva and the three characters from Ásgard can recount it as if it already happened.\n",
            "-------\n",
            "Q:What did the Labyrinth look like?\n",
            "Did the Labyrinth have concentric circular walls with passages blocked by radials or it did it have rectangular lines? Or do we simply not know?\n",
            "A:### It is a commonly held belief that The Labyrinth is in fact the Palace of KnossosThe Labyrinth has been described as :> ... a maze-like building of winding corridors and complicated twists and turns, which confused anyone who entered it so much that he could not find the way out.Which could be considered an apt description of the palace.!enter image description here The Palace of KnossosAnd according to legend :> Knossos itself was built by the architect Daedalus!enter image description hereThe Minoan building complex at Knossos, from the excavations of Arthur Evans (1851 – 1941)\n",
            "-------\n",
            "Q:How did the ranking system for the Sumerian pantheon work?\n",
            "According to this source, the gods had some numerical ranks as below:\n",
            "\n",
            "  1. Anu (ranking #60)\n",
            "  2. Antu (ranking #55)\n",
            "  3. Enlil (ranking #50)\n",
            "  4. Ninlil / Sud (ranking #45)\n",
            "  5. Enki / EA (ranking #40)\n",
            "  6. Ninki / Damkina (ranking #35)\n",
            "  7. Nanna / Nannar / Sin / El (ranking #30)\n",
            "  8. Ningal (ranking #25)\n",
            "  9. Utu / Shamash / Allah (ranking #20)\n",
            "  10. Inanna / Ishtar (ranking #15)\n",
            "  11. Adad / Ishkur (ranking #10)\n",
            "  12. Ninhursag / Ninmah / Ninti (ranking #5)\n",
            "\n",
            "\n",
            "\n",
            "How did this system work?\n",
            "A:The ranking system (which I believe to be a little off) seem to be how powerful the god was according to the people and priests.Anu is the top dog while his wife Antu is 5 below symbolizing that man was considered higher than women.As you can see the system is based on 5's with every male in the 10's and their spouses 5 below.\n",
            "-------\n",
            "Q:What is the meaning of the star symbols appearing on seal VA 243?\n",
            "Here is the picture of cylinder seal VA/243.\n",
            "\n",
            "!cylinder seal VA/243\n",
            "\n",
            "Image credits: Z. Sitchin\n",
            "\n",
            "This seal was named like that because it is number 243 in the collection of the Vorderasiatische Museum in Berlin.\n",
            "\n",
            "What is the correct meaning of the star symbol (including 11 dots around) shown below?\n",
            "\n",
            "!cylinder seal VA/243 - star symbols\n",
            "\n",
            "So in total 12 mysterious objects (I guess).\n",
            "\n",
            "This is I guess explained in A Brief Analysis of Cylinder Seal VA 243, however it's still not clear for me.\n",
            "\n",
            "And the star in the middle, is it our Sun or it's not?\n",
            "\n",
            "If it's not, is it referring to some specific constellation?\n",
            "A:My name is Emerson C Velloso, and this is my archaeoastronomical contribution to Professor Michael S Heiser:The man seated is Ninurta, He's not only the God of the Farmers and Plow, He is also the God of War, related to the planet Saturn!The big star in the center is Saturn.![Ninurta - the God of the Farmers and Plow, the God of War, planet Saturn](These Akkadian representations are not realistic, but only systematic... even so, the astronomical order is right: the planets on the ecliptic trajectory passes between Betelgeuse/Aldebaran and the Pleiades.![star symbol of cylinder seal VA/243 - Orion, Betelgeuse, Pleiades, Saturn, Aldebaran](\n",
            "-------\n",
            "Q:Why did Charon collect a toll at the River Styx\n",
            "Charon is known as the ferryman of the River Styx, letting certain people cross the river with a fee. Charon himself is well known for helping many significant heroes in multiple Greek legends.\n",
            "\n",
            "He always seems to collect a toll from those who cross the River Styx with his assisstance. What exactly does Charon do with the toll money he receives from his passengers? And why exactly does he need to collect a toll?\n",
            "A:Coins (specifically a type called an obol or obolos) were left on the body or placed in the mouths of the dead.The dead give Charon the coin, which shows they have had proper funeral rites and therefore deserve to be transported to Hades.The Aenid by Vergil, Chapter 6 has this to say> Why some were ferried o'er, and some refus'd. \"Son of Anchises, offspring of the gods,\" The Sibyl said, \"you see the Stygian floods, The sacred stream which heav'n's imperial state Attests in oaths, and fears to violate. The ghosts rejected are th' unhappy crew Depriv'd of sepulchers and fun'ral due: The boatman, Charon; those, the buried host, He ferries over to the farther coast;Despite having neither coin, nor being dead, Heracles managed to cross as did Orpheus and various other heroes.\n",
            "-------\n",
            "Q:Did ancient Greek religion ever become monotheistic?\n",
            "Unlike modern monotheistic religions that only accept one, omnipotent and omniscient god, ancient Greek religion has a pantheon of fallible gods. Yet it was also well developed, where the pantheon has hierarchy (Zeus, king of gods) and lineage.\n",
            "\n",
            "Was there ever a time and place where the religion evolved into a monotheistic form? That is, only accepting one god, rejecting the others as false ones or manifestations of the one true god. For example, ancient Egyptian religion briefly gave rise to Atenism, the offshoot religion that states the sun-disc _Aten_ was the only god.\n",
            "\n",
            "Did a similar thing happen to Greek religion? If so, which god became the one? Or was it an amalgam?\n",
            "A:No, at least not that we know of. If there was a monotheistic cult in ancient Greece, it certainly wasn't as popular as Atenism. There are traces of monotheistic thought in Platonism (e.g. the Euthyphro dilemma), but that's more about philosophy than religion.There's one theory, put forth by Elizabeth Kessler in _Dionysian Monotheism in Nea Paphos_ that \"two monotheistic religions, Dionysian and Christian, existed contemporaneously in Nea Paphos during the 4th century C.E.\". The only evidence cited, however, is a mosaic where Dionysus is the central figure, so I'd take this with a grain of salt.\n",
            "-------\n",
            "Q:Are there any points of mythology/religion that all Native Americans have in common?\n",
            "I have been exposed to some different Native American mythologies and there seem to be many differences. Are there any beliefs or stories that they all share?\n",
            "A:The idea of the Coyote Trickster god is pretty widespread. My copy of The Book of the Navajo contains \"The Tale of Coyote, the Troublemaker\". The Coyote is also known to the Apache in the \"Badger carries Darkness: Coyote and Bobcat scratch each other\"A Cheyenne tale called \"How he got tongue\"And a Blackfoot Coyote tale called \"Little Friend Coyote\"He's known to the Sioux, the Caddo in Why Coyote Stopped Imitating His Friends and the Cherokee in How the Bluebeard and the Coyote got their ColorA list of other tribes and legends can be found here\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "MFH_5u9q9EW4"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data as torch_data\n",
        "from rank_bm25 import BM25Okapi\n",
        "import pandas as pd\n",
        "\n",
        "class DatasetQAtriplets(torch_data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        list_of_data=None,\n",
        "        n_negatives= 3,\n",
        "        topk_negatives_discard = 5,\n",
        "        focal_text_name ='query',\n",
        "        positives_text_name ='positives',\n",
        "        negativess_text_name ='negatives',\n",
        "        seed = 32\n",
        "    ):\n",
        "        self.n_negatives = n_negatives\n",
        "        self.topk_negatives_discard = topk_negatives_discard\n",
        "        self.data = {}\n",
        "        self.focal_text_name =focal_text_name\n",
        "        self.positives_text_name = positives_text_name\n",
        "        self.negativess_text_name = negativess_text_name\n",
        "        self.seed = 42\n",
        "        self.random = np.random.RandomState(self.seed)\n",
        "\n",
        "        if list_of_data is not None and len(list_of_data)>0:\n",
        "\n",
        "            # loop through the data and add each triplets\n",
        "            self._loop_through_list_of_data_and_add_to_selfdata(\n",
        "                list_of_data = list_of_data\n",
        "            )\n",
        "\n",
        "            # build bm25 corpus\n",
        "            bm25_for_finding_negatives = self._build_corpus_of_potential_negatives()\n",
        "\n",
        "            # add negatives to self.data\n",
        "            self._find_negatives_and_add_to_data(\n",
        "                bm25_corpus=bm25_for_finding_negatives['bm25'],\n",
        "                corpus = bm25_for_finding_negatives['corpus']\n",
        "            )\n",
        "\n",
        "            # harden the dataset to pandas dataframe\n",
        "            self.df = self.sample_data_and_make_static_dataframe(self.data)\n",
        "\n",
        "    def _loop_through_list_of_data_and_add_to_selfdata(\n",
        "        self,\n",
        "        list_of_data\n",
        "    ):\n",
        "        \"\"\"loops through and adds the positive/focal texts and negatives\"\"\"\n",
        "        for raw_example in list_of_data:\n",
        "            # add each element to the data\n",
        "            self._add_triplet_to_data(\n",
        "                focal_texts=raw_example[self.focal_text_name],\n",
        "                positve_texts=raw_example[self.positives_text_name],\n",
        "                negative_texts=raw_example[self.negativess_text_name],\n",
        "            )\n",
        "        self.focal_texts_as_keys = list(self.data.keys())\n",
        "\n",
        "    def _add_triplet_to_data(\n",
        "        self,\n",
        "        focal_texts,\n",
        "        positve_texts,\n",
        "        negative_texts\n",
        "    ):\n",
        "        \"\"\"add focal text to the data\"\"\"\n",
        "        do_add_focals = False\n",
        "        if isinstance(focal_texts,list):\n",
        "            focal_text = sort(focal_texts)[0]\n",
        "            do_add_focals = True\n",
        "        elif isinstance(focal_texts, str):\n",
        "            focal_text = focal_texts\n",
        "        if focal_text not in self.data.keys():\n",
        "            self.data[focal_text] = {'positives':[], 'negatives':[]}\n",
        "        self.data[focal_text]['positives'] += positve_texts\n",
        "        self.data[focal_text]['negatives'] += negative_texts\n",
        "        if do_add_focals:\n",
        "            self.data[focal_text]['positives'] += focal_texts[1:]\n",
        "\n",
        "    def _build_corpus_of_potential_negatives(self):\n",
        "        potential_corpus = [\n",
        "            self.data[k]['positives'][:1] for k in self.focal_texts_as_keys\n",
        "        ]\n",
        "        potential_corpus = [\n",
        "            'NEGATIVE' if (not bool(s)) else s[0] for s in potential_corpus\n",
        "        ]\n",
        "        tokenized_corpus = [s.lower().split(\" \") for s in potential_corpus]\n",
        "        bm25 = BM25Okapi(tokenized_corpus)\n",
        "        return {'bm25':bm25, 'corpus':potential_corpus}\n",
        "\n",
        "    def _find_negative(\n",
        "        self,\n",
        "        focal_text_as_query,\n",
        "        positive_examples=None,\n",
        "        use_focal_text = True,\n",
        "        use_positives=True,\n",
        "        bm25_corpus=None,\n",
        "        corpus = None\n",
        "    ):\n",
        "        \"\"\"Uses BM25 to find similar but wrong answers, to serve as triplet negatives; for single focal text\"\"\"\n",
        "        bmquery = (focal_text_as_query if use_focal_text else \"\") + \" \" + (\"\" if (not use_positives) else positive_examples[0])\n",
        "        bmquery = bmquery.strip()\n",
        "        bmquery_tokenized = bmquery.lower().split(\" \")\n",
        "        top_results = bm25_corpus.get_top_n(bmquery_tokenized, corpus, n=self.topk_negatives_discard + self.n_negatives)\n",
        "        top_results = [\n",
        "            s for s in top_results\n",
        "            if (\n",
        "                s not in positive_examples+[focal_text_as_query]\n",
        "            )\n",
        "        ]\n",
        "        # remove any text that is equivalent to the query / focal texts\n",
        "        potential_negatives = top_results[-1*self.n_negatives:]\n",
        "        return potential_negatives\n",
        "\n",
        "    def _find_negatives_and_add_to_data(\n",
        "        self,\n",
        "        bm25_corpus=None,\n",
        "        corpus = None\n",
        "    ):\n",
        "        \"\"\"Uses BM25 to find similar but wrong answers, to serve as triplet negatives; loop over data\"\"\"\n",
        "        # loop through data, find examples which don't have negatives\n",
        "        for k,d in self.data.items():\n",
        "            if not bool(d['negatives']):\n",
        "                negatives = self._find_negative(\n",
        "                    focal_text_as_query=k,\n",
        "                    positive_examples=d['positives'],\n",
        "                    use_focal_text = True,\n",
        "                    use_positives=bool(d['positives']),\n",
        "                    bm25_corpus=bm25_corpus,\n",
        "                    corpus = corpus\n",
        "                )\n",
        "                d['negatives']+= negatives\n",
        "        print('done finding negatives')\n",
        "\n",
        "    def sample_data_and_make_static_dataframe(self, seed = 42):\n",
        "        focals =[]\n",
        "        pos =[]\n",
        "        neg = []\n",
        "        for query,d in self.data.items():\n",
        "            for j in range(min(self.n_negatives, len(d['negatives']))):\n",
        "                if len(d['positives'])==0:\n",
        "                    print(d)\n",
        "                    print('this is missing a positive example')\n",
        "                    continue\n",
        "                elif len(d['positives'])==1:\n",
        "                    pos+=d['positives']\n",
        "                elif len(d['positives'])>1:\n",
        "                    pos.append(self.random.choice(d['positives']))\n",
        "                neg.append(d['negatives'][j])\n",
        "                focals.append(query)\n",
        "        df = pd.DataFrame({'query':focals, 'pos':pos, 'neg':neg})\n",
        "        return df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        #key = self.focal_texts_as_keys[idx]\n",
        "        #return {**{'query':key}, **self.data[key]}\n",
        "        return self.df.iloc[idx].to_dict()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_torchdataset_val = DatasetQAtriplets(\n",
        "    list_of_data = qa_statics_datsets['val'],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        ")\n",
        "qa_torchdataset_train = DatasetQAtriplets(\n",
        "    list_of_data = qa_statics_datsets['train'],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Vmko2SmxHe",
        "outputId": "ed45d96b-dbed-4b60-a7d7-0983945a7ee2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done finding negatives\n",
            "{'positives': [], 'negatives': ['In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.', 'It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.', 'The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.', 'The equations of motion describe the movement of the center of mass of a body.', 'Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.', \"Since the object's velocity vector is constantly changing direction, the moving object is undergoing acceleration by a centripetal force in the direction of the center of rotation.\", \"Without this acceleration, the object would move in a straight line, according to Newton's laws of motion .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.', 'It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.', 'The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.', 'The equations of motion describe the movement of the center of mass of a body.', 'Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.', \"Since the object's velocity vector is constantly changing direction, the moving object is undergoing acceleration by a centripetal force in the direction of the center of rotation.\", \"Without this acceleration, the object would move in a straight line, according to Newton's laws of motion .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.', 'It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.', 'The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.', 'The equations of motion describe the movement of the center of mass of a body.', 'Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.', \"Since the object's velocity vector is constantly changing direction, the moving object is undergoing acceleration by a centripetal force in the direction of the center of rotation.\", \"Without this acceleration, the object would move in a straight line, according to Newton's laws of motion .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Apollo Creed is a fictional character from the Rocky films , initially portrayed as the Undisputed Heavyweight Champion of the World.', 'He was played by Carl Weathers .', 'Creed had multiple nicknames, including The Master of Disaster, The King of Sting, The Dancing Destroyer, The Prince of Punch, The One and Only and The Count of Monte Fisto.', \"Urban legend states that Apollo Creed's name is a wordplay on the Apostles' Creed , a statement of belief used in Christian churches.\", \"All of Apollo's championship fights were scheduled for the 15 round distance.\", 'Championship fights did not convert from 15 rounds to 12 rounds until 1987.', 'Rocky Balboa is often wrongly credited with popularizing the red, white, and blue trunks; Creed was the first man to wear them (latterly worn by Rocky Balboa in the 3rd and 4th installments and finally by Tommy \"The Machine\" Gunn ( Tommy Morrison ) in the 5th installment) although normally he wore red and white, as seen in Rocky II.', \"Balboa's signature colors were black and gold—colors he used in the latest movie .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Apollo Creed is a fictional character from the Rocky films , initially portrayed as the Undisputed Heavyweight Champion of the World.', 'He was played by Carl Weathers .', 'Creed had multiple nicknames, including The Master of Disaster, The King of Sting, The Dancing Destroyer, The Prince of Punch, The One and Only and The Count of Monte Fisto.', \"Urban legend states that Apollo Creed's name is a wordplay on the Apostles' Creed , a statement of belief used in Christian churches.\", \"All of Apollo's championship fights were scheduled for the 15 round distance.\", 'Championship fights did not convert from 15 rounds to 12 rounds until 1987.', 'Rocky Balboa is often wrongly credited with popularizing the red, white, and blue trunks; Creed was the first man to wear them (latterly worn by Rocky Balboa in the 3rd and 4th installments and finally by Tommy \"The Machine\" Gunn ( Tommy Morrison ) in the 5th installment) although normally he wore red and white, as seen in Rocky II.', \"Balboa's signature colors were black and gold—colors he used in the latest movie .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Apollo Creed is a fictional character from the Rocky films , initially portrayed as the Undisputed Heavyweight Champion of the World.', 'He was played by Carl Weathers .', 'Creed had multiple nicknames, including The Master of Disaster, The King of Sting, The Dancing Destroyer, The Prince of Punch, The One and Only and The Count of Monte Fisto.', \"Urban legend states that Apollo Creed's name is a wordplay on the Apostles' Creed , a statement of belief used in Christian churches.\", \"All of Apollo's championship fights were scheduled for the 15 round distance.\", 'Championship fights did not convert from 15 rounds to 12 rounds until 1987.', 'Rocky Balboa is often wrongly credited with popularizing the red, white, and blue trunks; Creed was the first man to wear them (latterly worn by Rocky Balboa in the 3rd and 4th installments and finally by Tommy \"The Machine\" Gunn ( Tommy Morrison ) in the 5th installment) although normally he wore red and white, as seen in Rocky II.', \"Balboa's signature colors were black and gold—colors he used in the latest movie .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In the United States, the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution .', 'In addition to the Supreme Court of the United States , whose existence and some aspects of whose jurisdiction are beyond the constitutional power of Congress to alter, acts of Congress have established 13 courts of appeals (also called \"circuit courts\") with appellate jurisdiction over different regions of the United States, and 94 United States district courts .', 'Every judge appointed to such a court may be categorized as a federal judge; such positions include the Chief Justice and Associate Justices of the Supreme Court, Circuit Judges of the courts of appeals, and district judges of the United States district courts .', 'All of these judges described thus far are referred to sometimes as \"Article III judges\" because they exercise the judicial power vested in the judicial branch of the federal government by Article III of the U.S. Constitution.', 'In addition, judges of the Court of International Trade exercise judicial power pursuant to Article III.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In the United States, the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution .', 'In addition to the Supreme Court of the United States , whose existence and some aspects of whose jurisdiction are beyond the constitutional power of Congress to alter, acts of Congress have established 13 courts of appeals (also called \"circuit courts\") with appellate jurisdiction over different regions of the United States, and 94 United States district courts .', 'Every judge appointed to such a court may be categorized as a federal judge; such positions include the Chief Justice and Associate Justices of the Supreme Court, Circuit Judges of the courts of appeals, and district judges of the United States district courts .', 'All of these judges described thus far are referred to sometimes as \"Article III judges\" because they exercise the judicial power vested in the judicial branch of the federal government by Article III of the U.S. Constitution.', 'In addition, judges of the Court of International Trade exercise judicial power pursuant to Article III.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In the United States, the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution .', 'In addition to the Supreme Court of the United States , whose existence and some aspects of whose jurisdiction are beyond the constitutional power of Congress to alter, acts of Congress have established 13 courts of appeals (also called \"circuit courts\") with appellate jurisdiction over different regions of the United States, and 94 United States district courts .', 'Every judge appointed to such a court may be categorized as a federal judge; such positions include the Chief Justice and Associate Justices of the Supreme Court, Circuit Judges of the courts of appeals, and district judges of the United States district courts .', 'All of these judges described thus far are referred to sometimes as \"Article III judges\" because they exercise the judicial power vested in the judicial branch of the federal government by Article III of the U.S. Constitution.', 'In addition, judges of the Court of International Trade exercise judicial power pursuant to Article III.']}\n",
            "this is missing a positive example\n",
            "done finding negatives\n",
            "{'positives': [], 'negatives': ['This is an overview of the regular, recurring, and other characters of the TV series NCIS .']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Far East Movement (stylized as Far★East Movement or abbreviated FM) is an American hip hop band quartet based in Los Angeles .', 'The group formed in 2003 and consists of Kev Nish (Kevin Nishimura), Prohgress (James Roh), J-Splif (Jae Choung), and DJ Virman (Virman Coquia).', 'Far East Movement\\'s first claim to fame was their song \"Round Round\" featured in the Hollywood movie, The Fast and the Furious: Tokyo Drift , and its subsequent soundtrack , video game and DVD.', 'Since \"Round Round\", the group has been featured on various network shows including , , Entourage , Gossip Girl , and Finishing the Game (a featured film at Sundance 2007).', 'Their single \" Like a G6 \" hit number one on the Billboard Hot 100 Chart and on iTunes as well in late October 2010.', 'Far East Movement also has the distinction of being the first Asian-American group to earn a #1 hit on the Billboard Hot 100 in the United States.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Far East Movement (stylized as Far★East Movement or abbreviated FM) is an American hip hop band quartet based in Los Angeles .', 'The group formed in 2003 and consists of Kev Nish (Kevin Nishimura), Prohgress (James Roh), J-Splif (Jae Choung), and DJ Virman (Virman Coquia).', 'Far East Movement\\'s first claim to fame was their song \"Round Round\" featured in the Hollywood movie, The Fast and the Furious: Tokyo Drift , and its subsequent soundtrack , video game and DVD.', 'Since \"Round Round\", the group has been featured on various network shows including , , Entourage , Gossip Girl , and Finishing the Game (a featured film at Sundance 2007).', 'Their single \" Like a G6 \" hit number one on the Billboard Hot 100 Chart and on iTunes as well in late October 2010.', 'Far East Movement also has the distinction of being the first Asian-American group to earn a #1 hit on the Billboard Hot 100 in the United States.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Far East Movement (stylized as Far★East Movement or abbreviated FM) is an American hip hop band quartet based in Los Angeles .', 'The group formed in 2003 and consists of Kev Nish (Kevin Nishimura), Prohgress (James Roh), J-Splif (Jae Choung), and DJ Virman (Virman Coquia).', 'Far East Movement\\'s first claim to fame was their song \"Round Round\" featured in the Hollywood movie, The Fast and the Furious: Tokyo Drift , and its subsequent soundtrack , video game and DVD.', 'Since \"Round Round\", the group has been featured on various network shows including , , Entourage , Gossip Girl , and Finishing the Game (a featured film at Sundance 2007).', 'Their single \" Like a G6 \" hit number one on the Billboard Hot 100 Chart and on iTunes as well in late October 2010.', 'Far East Movement also has the distinction of being the first Asian-American group to earn a #1 hit on the Billboard Hot 100 in the United States.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['U.S. debt from 1940 to 2011.', 'Red lines indicate the \"debt held by the public\" and black lines indicate the total national debt or gross public debt.', 'The difference is the \"intragovernmental debt,\" which includes obligations to government programs such as Social Security.', 'Stated as a formula, National Debt = Debt held by the Public + Intragovernmental Debt.', 'The second panel shows the two debt figures as a percentage of U.S. GDP (dollar value of U.S. economic production for that year).', 'The top panel is deflated so every year is in 2010 dollars.', 'The United States public debt is the money borrowed by the federal government of the United States through the issuing of securities by the Treasury and other federal government agencies.', 'US public debt consists of two components:', 'Debt held by the public includes Treasury securities held by investors outside the federal government, including that held by individuals, corporations, the Federal Reserve System and foreign, state and local governments.', 'Debt held by government accounts or intragovernmental debt includes non-marketable Treasury securities held in accounts administered by the federal government that are owed to program beneficiaries, such as the Social Security Trust Fund .', 'Debt held by government accounts represents the cumulative surpluses, including interest earnings, of these accounts that have been invested in Treasury securities.', 'Public debt increases or decreases as a result of the annual unified budget deficit or surplus.', 'The federal government budget deficit or surplus is the difference between government receipts and spending, ignoring intra-governmental transfers.', 'However, some spending that is excluded from the deficit (supplemental appropriations) also adds to the debt.', 'Historically, the US public debt as a share of GDP increased during wars and recessions, and subsequently declined.', 'For example, debt held by the public as a share of GDP peaked just after World War II (113% of GDP in 1945), but then fell over the following 30 years.', \"In recent decades, however, large budget deficits and the resulting increases in debt have led to concern about the long-term sustainability of the federal government's fiscal policies.\", 'On 2 April 2013, debt held by the public was approximately $11.959 trillion or about 75% of GDP.', 'Intragovernmental holdings stood at $4.846 trillion, giving a combined total public debt of $16.805 trillion.', \"As of January 2013, $5.6 trillion or approximately 47% of the debt held by the public was owned by foreign investors, the largest of which were the People's Republic of China and Japan at just over $1.1 trillion each.\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['U.S. debt from 1940 to 2011.', 'Red lines indicate the \"debt held by the public\" and black lines indicate the total national debt or gross public debt.', 'The difference is the \"intragovernmental debt,\" which includes obligations to government programs such as Social Security.', 'Stated as a formula, National Debt = Debt held by the Public + Intragovernmental Debt.', 'The second panel shows the two debt figures as a percentage of U.S. GDP (dollar value of U.S. economic production for that year).', 'The top panel is deflated so every year is in 2010 dollars.', 'The United States public debt is the money borrowed by the federal government of the United States through the issuing of securities by the Treasury and other federal government agencies.', 'US public debt consists of two components:', 'Debt held by the public includes Treasury securities held by investors outside the federal government, including that held by individuals, corporations, the Federal Reserve System and foreign, state and local governments.', 'Debt held by government accounts or intragovernmental debt includes non-marketable Treasury securities held in accounts administered by the federal government that are owed to program beneficiaries, such as the Social Security Trust Fund .', 'Debt held by government accounts represents the cumulative surpluses, including interest earnings, of these accounts that have been invested in Treasury securities.', 'Public debt increases or decreases as a result of the annual unified budget deficit or surplus.', 'The federal government budget deficit or surplus is the difference between government receipts and spending, ignoring intra-governmental transfers.', 'However, some spending that is excluded from the deficit (supplemental appropriations) also adds to the debt.', 'Historically, the US public debt as a share of GDP increased during wars and recessions, and subsequently declined.', 'For example, debt held by the public as a share of GDP peaked just after World War II (113% of GDP in 1945), but then fell over the following 30 years.', \"In recent decades, however, large budget deficits and the resulting increases in debt have led to concern about the long-term sustainability of the federal government's fiscal policies.\", 'On 2 April 2013, debt held by the public was approximately $11.959 trillion or about 75% of GDP.', 'Intragovernmental holdings stood at $4.846 trillion, giving a combined total public debt of $16.805 trillion.', \"As of January 2013, $5.6 trillion or approximately 47% of the debt held by the public was owned by foreign investors, the largest of which were the People's Republic of China and Japan at just over $1.1 trillion each.\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['U.S. debt from 1940 to 2011.', 'Red lines indicate the \"debt held by the public\" and black lines indicate the total national debt or gross public debt.', 'The difference is the \"intragovernmental debt,\" which includes obligations to government programs such as Social Security.', 'Stated as a formula, National Debt = Debt held by the Public + Intragovernmental Debt.', 'The second panel shows the two debt figures as a percentage of U.S. GDP (dollar value of U.S. economic production for that year).', 'The top panel is deflated so every year is in 2010 dollars.', 'The United States public debt is the money borrowed by the federal government of the United States through the issuing of securities by the Treasury and other federal government agencies.', 'US public debt consists of two components:', 'Debt held by the public includes Treasury securities held by investors outside the federal government, including that held by individuals, corporations, the Federal Reserve System and foreign, state and local governments.', 'Debt held by government accounts or intragovernmental debt includes non-marketable Treasury securities held in accounts administered by the federal government that are owed to program beneficiaries, such as the Social Security Trust Fund .', 'Debt held by government accounts represents the cumulative surpluses, including interest earnings, of these accounts that have been invested in Treasury securities.', 'Public debt increases or decreases as a result of the annual unified budget deficit or surplus.', 'The federal government budget deficit or surplus is the difference between government receipts and spending, ignoring intra-governmental transfers.', 'However, some spending that is excluded from the deficit (supplemental appropriations) also adds to the debt.', 'Historically, the US public debt as a share of GDP increased during wars and recessions, and subsequently declined.', 'For example, debt held by the public as a share of GDP peaked just after World War II (113% of GDP in 1945), but then fell over the following 30 years.', \"In recent decades, however, large budget deficits and the resulting increases in debt have led to concern about the long-term sustainability of the federal government's fiscal policies.\", 'On 2 April 2013, debt held by the public was approximately $11.959 trillion or about 75% of GDP.', 'Intragovernmental holdings stood at $4.846 trillion, giving a combined total public debt of $16.805 trillion.', \"As of January 2013, $5.6 trillion or approximately 47% of the debt held by the public was owned by foreign investors, the largest of which were the People's Republic of China and Japan at just over $1.1 trillion each.\"]}\n",
            "this is missing a positive example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(qa_torchdataset_train))\n",
        "qa_torchdataset_train[400]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mje7yyhqniKU",
        "outputId": "56a68779-2601-4482-b62b-7b3cfce47024"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Determine Current Controller in Use for Kohana\\nWhat is the best way to determine which Controller class a Kohana application is presently using?\\n\\nExamples:\\n\\n  * ` \\\\- `_defaultControllerName_`\\n  * ` \\\\- \"frontpage\"\\n  * ` \\\\- \"contact\"',\n",
              " 'pos': '**_The following applies to Kohana 2 instances..._**\\n\\nYou can do this by using the Router library. By default, this library is located in `/system/libraries/Router.php` \\\\- go ahead and copy it into `/application/libraries` as is the standard practice for all libraries being used.\\n\\nNow, from within your application you can get the controller value from the static Router class:\\n    \\n    \\n    print Router::$controller; // outputs current Controller\\n    \\n\\nDocumentation',\n",
              " 'neg': \"No, a `StringBuilder` is a purely managed resource. You should just get rid of all references to it. Everything else is taken care of by the garbage collector:\\n    \\n    \\n    StringBuilder sb = ...;\\n    // ... do work\\n    sb = null; // or simply let it go out of scope.\\n    \\n\\nIn .NET, there's no deterministic `delete` (like C++, where you free up memory allocated to a single object.) Only GC can free memory. By forfeiting all references to an object, you'll let GC be able to deallocate the object if it wants to. You can force a garbage collection by calling the `System.GC.Collect` method. However, it's not recommended to manipulate with GC unless you really know what you are doing. GC is smart. It's rarely beneficial to force it.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "jUjM10o64Jl6",
        "outputId": "98d355a0-59c2-4fc5-b206-0b237cb772b6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-27beb5425bc6>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# streaming datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdatasets_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_streaming_mlm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_streaming_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-27beb5425bc6>\u001b[0m in \u001b[0;36mprocess_streaming_mlm_data\u001b[0;34m(data_config)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_streaming_mlm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdataset_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'dataset_probabilities'"
          ]
        }
      ],
      "source": [
        "\n",
        "## Need a function to randomly\n",
        "# ... function takes the first 5000 entries as the dev set\n",
        "# ... then skips 5000 to make the starting position for the train set\n",
        "# ... then randomly takes another start position to cycle trhough all the data\n",
        "# ... then what? Hardens it and converts it into 512 chunks? filters out small segments (<200)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nwords(sentence):\n",
        "    return len([w for w in sentence.split(' ') if len(w)>0])\n",
        "\n",
        "def process_streaming_mlm_data(data_config):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "    if data_config['dataset_probabilities'] is not None:\n",
        "        dataset_probabilities = [a/sum(data_config['dataset_probabilities']) for a in data_config['dataset_probabilities']]\n",
        "    else:\n",
        "        dataset_probabilities = [1.0/len(data_config['files']) for _ in range(len(data_config['files']))]\n",
        "\n",
        "    # concatenate list of streaming datasets\n",
        "    datasets_to_stream = []\n",
        "    for file_to_stream in data_config['files']:\n",
        "        dataset_to_stream = load_dataset(\"json\", data_files=file_to_stream, split=\"train\", streaming=True)\n",
        "        datasets_to_stream.append(dataset_to_stream.remove_columns(\"meta\"))\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy ='all_exhausted',\n",
        "        probabilities = dataset_probabilities\n",
        "    )\n",
        "    return datasets_combined\n",
        "\n",
        "# streaming datasets\n",
        "datasets_combined = process_streaming_mlm_data(data_streaming_config)\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MLMDataset(Dataset):\n",
        "    \"\"\"Do I want to pre-tokenize? If so, then the Collator will call .pad\"\"\"\n",
        "    def __init__(self, input_text, tokenizer, max_seq_length=512, min_seq_length=200):\n",
        "        self.data = []\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        for text in input_text:\n",
        "            word_count = nwords(text)\n",
        "            if word_count <= self.max_seq_length and word_count >= self.min_seq_length:\n",
        "                self.data.append(text)\n",
        "            elif word_count > self.max_seq_length:\n",
        "                text_split = text.split(\" \")\n",
        "                chunks = [\n",
        "                    text_split[i:i+self.max_seq_length] for i in range(0, word_count, 512)\n",
        "                ]\n",
        "                chunks = [\" \".join(s) for s in chunks if len(s)>=self.min_seq_length]\n",
        "                self.texts.extend(chunks)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MNnOqVW4ng5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wai8-2BMVp7Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset1 = load_dataset(\"json\", data_files=data_files[0], split=\"train\", streaming=True)\n",
        "print(next(iter(dataset1)))\n",
        "\n",
        "dataset2 = load_dataset(\"json\", data_files=data_files[1], split=\"train\", streaming=True)\n",
        "dataset3 = load_dataset(\"json\", data_files=data_files[2], split=\"train\",streaming=True)\n",
        "\n",
        "# streaming datasets\n",
        "streaming_datasets = [\n",
        "    dataset1.remove_columns(\"meta\"),\n",
        "    dataset2.remove_columns(\"meta\"),\n",
        "    dataset3.remove_columns([\"label\",\"source\"]).rename_column('provision','text') # ledgar\n",
        "]\n",
        "\n",
        "combined_dataset = interleave_datasets(streaming_datasets)\n",
        "combined_dataset = combined_dataset.skip(10001)\n",
        "next(iter(combined_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEObDHvhkHSZ",
        "outputId": "7b632de6-7471-458e-c70e-c3856cef5728"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        }
      ],
      "source": [
        "dataset4 = load_dataset(\"pile-of-law/pile-of-law\",'euro_parl',split='train',streaming=True)\n",
        "dataset4 = dataset4.skip(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5zaHGuuQwt6",
        "outputId": "d14ac12b-5b66-4eff-eb9f-287b7e343795"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.builder:Using custom data configuration default-de993bbf5aabe685\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        }
      ],
      "source": [
        "# can I load ledgar\n",
        "dataset3 = load_dataset(\"json\", data_files=data_files[2], split=\"train\",streaming=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512,
          "referenced_widgets": [
            "90cd613da6d54fa881f325d531f371c6",
            "8f8f8bd06e8b4ce7bb74b30a5a2e68b4",
            "0491c321ae9344ff98592968423dccd3",
            "84949f4ae0b6402aaca1326d124436b3",
            "8e856b6e5ce74a4fa9b35ae801df4d31",
            "af00aa1a3bd64be9ad8f4df3e3c5f942",
            "11a1247638b6426c961fa4705dc85fee",
            "b6f9c6c1ac8a4eec97466e0f2108ce39",
            "ea3b3bc369804d85b562e7b83bc34804",
            "3650364038714617bd315e4fcd23d3bd",
            "f6823010dba245d1843a2f324e00c382",
            "ad8df595bb704a599d9abd994aa65691",
            "516b1796b208442ca32a48c8611b35fe",
            "e8db7bdb8bf04011874e6bb31570d763",
            "6679251fa0b64c59ab34bf7a811e0ae0",
            "c03bf64ecd204abab3d1b97eb32e0fdf",
            "5cd0803047b8426eb76e8412d6cf976a",
            "6b6b3265e630457aac2433dea92348e9",
            "a31311fbeb1d49c1a34ce41c4b01c22f",
            "3ba6ff0046c843679c0581a44ec69e1c",
            "6fdb79deb808435caba9e231f98118f0",
            "7bac298bf1954016a76ce82ab5842870",
            "a03e87f36c0240e0afd87ff4ebc334a2",
            "cfa3fef5ad8743228d10e60238d91449",
            "fd04d23b69a545d4acab01dd3046b44a",
            "f6eac59aef894d88bcae4654df6ef1b2",
            "ea4024140d39477884175e9aa9c2f796",
            "5d276b68035e42d79ec3d6c3600cd125",
            "dbe7e052a2994aadac7b883a020cd42f",
            "01bc3f5cd2ec4435b5a97c1dbbe7a86e",
            "5ef185dc852646fbb92d1eb31981bed0",
            "08187ae67b63489bba4a7b9c10d4d719",
            "379f64826a714ae89a85c265b4937902",
            "bf4d157f4fc041fca5718cdd41e73c10",
            "ab4bf3b1267743a8960deeeafcd0fcee",
            "ecaeab95cff44076a0a84cca103b6b60",
            "3cfadb1af62b45e1b6cf9f3243a281d5",
            "b5641641fc6e4f72b58c505565e16367",
            "f216f345dde54c35abaff30dac041c89",
            "e7cd7488f7264496be788107804bc9e8",
            "5dc68509c6494c6ebdd22c30ea632bfb",
            "7ad09b3ac2d5406caa626954d7dc4b92",
            "a51c61ff30d4474080167a38356ca402",
            "a6f38b1623f14bc9bea9b812f9102fce",
            "98371c9b595a4354a51020081c8adaa6",
            "d25f24f6c4464900af0369a1d34197af",
            "cf24681dbccd42f59ffda006ca4cdac6",
            "afbc002e8eed45b78884f7c4ccd6f37f",
            "12371b67bb334b2786c3809702b7bac7",
            "e3b7f6b62b45464db85df430da2ab97f",
            "dda17487487843c7a86152cde6220a6b",
            "f48649787c3d4f0f8de5d5eb8fdfc31b",
            "ca59bd8ff338413c8514ab0eee2d8ec3",
            "e779447c8d8e4578bd3a7747941bfbeb",
            "928685f89f3e40ddbf9b97a5281bb86f",
            "499cfcd99b96406383ff92126cab7c5d",
            "0787d9b7b9c649c9a8a70dd37d645a11",
            "a18b3a57972c42e1b061e2ada2c7858e",
            "f5a25f48fd7045d092d4b4b1a66f296c",
            "dbbeb2e4f0ca4e3b831fc5f58b883cf7",
            "e2dfbd412e2c4420931223730a476148",
            "9977be2298704813a37ed7c23e31d840",
            "610680918453400fba82622926af1b56",
            "933e94b11adf415abb0b16cad1201e93",
            "de941ef06f9a4974ba4e4075d96d5637",
            "4b242512f1ca473793bf144e5d062a9b"
          ]
        },
        "id": "ocINPgQyb84H",
        "outputId": "f9fd5a2b-b1a8-4540-8374-7fef089314fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.builder:Generating dataset pile-of-law (/root/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60)\n",
            "INFO:datasets.builder:Dataset not on Hf google storage. Downloading and preparing it from source\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset pile-of-law/r_legaladvice to /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90cd613da6d54fa881f325d531f371c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.r_legaldvice.jsonl.xz not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/3401aa15961b3081a5a04646851c71451f98bc46a642f049a73b5bf2e7ce9876.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad8df595bb704a599d9abd994aa65691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/61.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.r_legaldvice.jsonl.xz in cache at /root/.cache/huggingface/datasets/downloads/3401aa15961b3081a5a04646851c71451f98bc46a642f049a73b5bf2e7ce9876\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/3401aa15961b3081a5a04646851c71451f98bc46a642f049a73b5bf2e7ce9876\n",
            "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
            "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a03e87f36c0240e0afd87ff4ebc334a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/validation.r_legaldvice.jsonl.xz not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf4d157f4fc041fca5718cdd41e73c10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/validation.r_legaldvice.jsonl.xz in cache at /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8\n",
            "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
            "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
            "INFO:datasets.builder:Generating train split\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98371c9b595a4354a51020081c8adaa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.builder:Generating validation split\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "499cfcd99b96406383ff92126cab7c5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error reading file: /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8\n",
            "Dataset pile-of-law downloaded and prepared to /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60. Subsequent calls will reuse this data.\n",
            "{'text': 'Title: Landlord broke lease agreement, what are my rights? (Chicago, IL)\\nQuestion:Our landlord has been promising us a washer/dryer unit since we moved in (July 2015). When we resigned the lease August 2016, we wrote into the lease that an in-unit washer and dryer would be installed by September 30th 2016.\\n\\nSince September 30th, there have been continuous delays in getting the W/D installed. Since it has now been almost a month past the date the W/D was supposed to be installed, I am wondering what types of rights as a tenant I have? \\n\\nThanks ahead of time for any and all advice given.\\nAnswer #1: You can let your landlord know in writing that he is in default under the current lease agreement and give him a reasonable timeframe to cure his default.  \\n\\nIf he fails to correct the default, you can likely end your lease and move.', 'created_timestamp': '10-25-2016', 'downloaded_timestamp': '11-09-2021', 'url': 'https://www.reddit.com/r/legaladvice/comments/59cv5x/landlord_broke_lease_agreement_what_are_my_rights/'}\n"
          ]
        }
      ],
      "source": [
        "# these pile datasets cannot be streamed, but then can be loaded individually\n",
        "all_pile_datasets = ['r_legaladvice', 'courtlistener_docket_entry_documents', 'atticus_contracts', 'courtlistener_opinions', 'federal_register',\n",
        "           'bva_opinions', 'us_bills', 'cc_casebooks', 'tos', 'euro_parl', 'nlrb_decisions', 'scotus_oral_arguments', 'cfr', 'state_codes',\n",
        "           'scotus_filings', 'exam_outlines', 'edgar', 'cfpb_creditcard_contracts', 'constitutions', 'congressional_hearings', 'oig',\n",
        "           'olc_memos', 'uscode', 'founding_docs', 'ftc_advisory_opinions', 'echr', 'eurlex', 'tax_rulings', 'un_debates', 'fre', 'frcp',\n",
        "           'canadian_decisions', 'eoir', 'dol_ecab', 'icj-pcij', 'uspto_office_actions', 'ed_policy_guidance', 'acus_reports', 'hhs_alj_opinions',\n",
        "           'sec_administrative_proceedings', 'fmshrc_bluebooks', 'resource_contracts', 'medicaid_policy_guidance', 'irs_legal_advice_memos', 'doj_guidance_documents'\n",
        "    ]\n",
        "\n",
        "dataset3 = load_dataset('pile-of-law/pile-of-law',all_pile_datasets[0],split='train')\n",
        "\n",
        "print(next(iter(dataset3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDdE_WK7_hlH",
        "outputId": "f883cb06-2457-46f6-918d-ace90091e8e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': '543 U.S. 1079\\nBARNESv.UNITED STATES.\\nNo. 04-7550.\\nSupreme Court of United States.\\nJanuary 10, 2005.\\n\\n1\\nC. A. 8th Cir. Certiorari denied. Reported below: 374 F. 3d 601.\\n\\n'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(streaming_datasets[1])) # works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BOAAaYO9F4p"
      },
      "outputs": [],
      "source": [
        "#dataset_head = pubmed_dataset_streamed.skip(10000) # skipping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZLuqQNU_PMO",
        "outputId": "2d82aadf-52d6-4cec-feb1-4f314538d1da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': '\\n517 U.S. 706 (1996)\\nQUACKENBUSH, CALIFORNIA INSURANCE COMMISSIONER\\nv.\\nALLSTATE INSURANCE CO.\\nNo. 95-244.\\nUnited States Supreme Court.\\nArgued February 20, 1996.\\nDecided June 3, 1996.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*708 *708 O\\'Connor, J., delivered the opinion for a unanimous Court. Scalia, J., post, p. 731, and Kennedy, J., post, p. 733, filed concurring opinions.\\nKarl L. Rubinstein argued the cause for petitioner. With him on the briefs were Dana Carli Brooks, Melissa S. Kooistra, William W. Palmer, and David L. Shapiro. \\nDonald Francis Donovan argued the cause for respondent. With him on the brief were Carl Micarelli, Joseph D. Lee, and James G. Sporleder.[*]\\n*709 Justice O\\'Connor, delivered the opinion of the Court.\\nIn this case, we consider whether an abstention-based remand order is appealable as a final order under 28 U. S. C. § 1291, and whether the abstention doctrine first recognized in Burford v. Sun Oil Co., 319 U. S. 315 (1943), can be applied in a common-law suit for damages.\\n\\nI\\nPetitioner, the Insurance Commissioner for the State of California, was appointed trustee over the assets of the Mission Insurance Company and its affiliates (Mission companies) in 1987, after those companies were ordered into liquidation by a California court. In an effort to gather the assets of the defunct Mission companies, the Commissioner filed the instant action against respondent Allstate Insurance Company in state court, seeking contract and tort damages for Allstate\\'s alleged breach of certain reinsurance agreements, as well as a general declaration of Allstate\\'s obligations under those agreements.\\nAllstate removed the action to federal court on diversity grounds and filed a motion to compel arbitration under the Federal Arbitration Act, 9 U. S. C. § 1 et seq. (1988 ed. and Supp. V). The Commissioner sought remand to state court, arguing that the District Court should abstain from hearing the case under Burford, supra, because its resolution might interfere with California\\'s regulation of the Mission insolvency. Specifically, the Commissioner indicated that Allstate would be asserting its right to set off its own contract claims against the Commissioner\\'s recovery under the contract, that the viability of these setoff claims was a hotly disputed question of state law, and that this question was currently pending before the state courts in another case arising out of the Mission insolvency.\\nThe District Court observed that \"California has an overriding interest in regulating insurance insolvencies and liquidations in a uniform and orderly manner,\" and that in this *710 case \"this important state interest could be undermined by inconsistent rulings from the federal and state courts.\" App. to Pet. for Cert. 34a. Based on these observations, and its determination that the setoff question should be resolved in state court, the District Court concluded this case was an appropriate one for the exercise of Burford abstention. The District Court did not stay its hand pending the California courts\\' resolution of the setoff issue, but instead remanded the entire case to state court. The District Court entered this remand order without ruling on Allstate\\'s motion to compel arbitration.\\nAfter determining that appellate review of the District Court\\'s remand order was not barred by 28 U. S. C. § 1447(d), see Garamendi v. Allstate Ins. Co., 47 F. 3d 350, 352 (CA9 1995) (citing Thermtron Products, Inc. v. Hermansdorfer,  423 U. S. 336 (1976)), and that the remand order was appealable under 28 U. S. C. § 1291 as a final collateral order, see 47 F. 3d, at 353-354 (citing Moses H. Cone Memorial Hospital  v. Mercury Constr. Corp., 460 U. S. 1 (1983)), the Court of Appeals for the Ninth Circuit vacated the District Court\\'s decision and ordered the case sent to arbitration. The Ninth Circuit concluded that federal courts can abstain from hearing a case under Burford only when the relief being sought is equitable in nature, and therefore held that abstention was inappropriate in this case because the Commissioner purported to be seeking only legal relief. 47 F. 3d, at 354-356; App. to Pet. for Cert. 35a\\x9737a (order denying petition for rehearing because Commissioner had waived any argument that this case involved a request for equitable relief).\\nThe Ninth Circuit\\'s holding that abstention-based remand orders are appealable conflicts with the decisions of other Courts of Appeals, see Doughty v. Underwriters at Lloyd\\'s, London, 6 F. 3d 856, 865 (CA1 1993) (order not appealable); Corcoran v. Ardra Insurance Co., Ltd., 842 F. 2d 31, 34 (CA2 1988) (same); In re Burns & Wilcox, Ltd., 54 F. 3d 475, 477, *711 n. 7 (CA8 1995) (same); but see Minot v. Eckardt-Minot, 13 F. 3d 590, 593 (CA2 1994) (order appealable under collateral order doctrine), as does its determination that Burford abstention can only be exercised in cases in which equitable relief is sought, see Lac D\\'Amiante du Quebec, Ltee v. American Home Assurance Co., 864 F. 2d 1033, 1045 (CA3 1988) (Burford abstention appropriate in case seeking declaratory relief); Brandenburg v. Seidel, 859 F. 2d 1179, 1192, n. 17 (CA4 1988) (Burford abstention appropriate in action for damages); Wolfson v. Mutual Benefit Life Ins. Co., 51 F. 3d 141, 147 (CA8 1995) (same); but see Fragoso v. Lopez, 991 F. 2d 878, 882 (CA1 1993) (federal court can abstain under Burford only if it is \"sitting in equity\"); University of Maryland v. Peat Marwick Main & Co., 923 F. 2d 265, 272 (CA3 1991) (same); Baltimore Bank for Cooperatives v. Farmer\\'s Cheese Cooperative, 583 F. 2d 104, 111 (CA3 1978) (same). We granted certiorari to resolve these conflicts, 516 U. S. 929 (1995), and now affirm on grounds different from those provided by the Ninth Circuit.\\n\\nII\\nWe first consider whether the Court of Appeals had jurisdiction to hear Allstate\\'s appeal under 28 U. S. C. § 1291, which confers jurisdiction over appeals from \"final decisions\" of the district courts, and 28 U. S. C. § 1447(d), which provides that \"[a]n order remanding a case to the State court from which it was removed is not reviewable on appeal or otherwise.\"\\nWe agree with the Ninth Circuit and the parties that § 1447(d) interposes no bar to appellate review of the remand order at issue in this case. See 47 F. 3d, at 352; Brief for Petitioner 29-30; Brief for Respondent 13-14, n. 12. As we held in Thermtron Products, Inc. v. Hermansdorfer, supra, at 345-346, and reiterated this Term in Things Remembered, Inc. v. Petrarca, 516 U. S. 124, 127 (1995), \"§ 1447(d) must be read in pari materia with § 1447(c), so *712 that only remands based on grounds specified in § 1447(c) are immune from review under § 1447(d).\" This gloss renders § 1447(d) inapplicable here: The District Court\\'s abstentionbased remand order does not fall into either category of remand order described in § 1447(c), as it is not based on lack of subject matter jurisdiction or defects in removal procedure.\\nFinding no affirmative bar to appellate review of the District Court\\'s remand order, we must determine whether that review may be obtained by appeal under § 1291. The general rule is that \"a party is entitled to a single appeal, to be deferred until final judgment has been entered, in which claims of district court error at any stage of the litigation may be ventilated.\" Digital Equipment Corp. v. Desktop Direct, Inc., 511 U. S. 863, 868 (1994) (citations omitted). Accordingly, we have held that a decision is ordinarily considered final and appealable under § 1291 only if it \"ends the litigation on the merits and leaves nothing for the court to do but execute the judgment.\" Catlin v. United States, 324 U. S. 229, 233 (1945); see also Digital, supra, at 867 (quoting this standard). We have also recognized, however, a narrow class of collateral orders which do not meet this definition of finality, but which are nevertheless immediately appealable under § 1291 because they \"`conclusively determine [a] disputed question\\' \" that is \"`completely separate from the merits of the action,\\' \" \"`effectively unreviewable on appeal from a final judgment,\\' \" Richardson-Merrell Inc. v. Koller, 472 U. S. 424, 431 (1985) (quoting Coopers & Lybrand v. Livesay,  437 U. S. 463, 468 (1978)), and \"too important to be denied review,\" Cohen v. Beneficial Industrial Loan Corp., 337 U. S. 541, 546 (1949).\\nThe application of these principles to the appealability of the remand order before us is controlled by our decision in Moses H. Cone Memorial Hospital v. Mercury Constr. Corp., supra. The District Court in that case entered an order under Colorado River Water Conservation Dist. v. United States, 424 U. S. 800 (1976), staying a federal diversity suit *713 pending the completion of a declaratory judgment action that had been filed in state court. The Court of Appeals held that this stay order was appealable under § 1291, and we affirmed that determination on two independent grounds.\\nWe first concluded that the abstention-based stay order was appealable as a \"final decision\" under § 1291 because it put the litigants \"`effectively out of court,\\' \" 460 U. S., at 11, n. 11 (quoting Idlewild Bon Voyage Liquor Corp. v. Epstein,  370 U. S. 713, 715, n. 2 (1962) (per curiam) ), and because its effect was \"precisely to surrender jurisdiction of a federal suit to a state court,\" 460 U. S., at 11, n. 11. These standards do not reflect our oft-repeated definition of finality, see supra, at 712 (citing Catlin, supra, at 233); see, e. g., Digital, supra, at 867 (citing the Catlin definition); Lauro Lines s.r.l.  v. Chasser, 490 U. S. 495, 497 (1989) (same); Van Cauwenberghe v. Biard, 486 U. S. 517, 521-522 (1988) (same), but in Moses H. Cone we found their application to be compelled by precedent, see 460 U. S., at 11, n. 11 (\"Idlewild `s reasoning is limited to cases where (under Colorado River, abstention, or a closely similar doctrine) the object of the stay is to require all or an essential part of the federal suit to be litigated in a state forum\").\\nAs an alternative to this reliance on Idlewild, we also held that the stay order at issue in Moses H. Cone was appealable under the collateral order doctrine. 460 U. S., at 11. We determined that a stay order based on the Colorado River  doctrine \"presents an important issue separate from the merits\" because it \"amounts to a refusal to adjudicate\" the case in federal court; that such orders could not be reviewed on appeal from a final judgment in the federal action because the district court would be bound, as a matter of res judicata, to honor the state court\\'s judgment; and that unlike other stay orders, which might readily be reconsidered by the district court, abstention-based stay orders of this ilk are \"conclusive\" because they are the practical equivalent of an order dismissing the case. 460 U. S., at 12.\\n*714 The District Court\\'s order remanding on grounds of Burford abstention is in all relevant respects indistinguishable from the stay order we found to be appealable in Moses H. Cone. No less than an order staying a federal court action pending adjudication of the dispute in state court, it puts the litigants in this case \"`effectively out of court,\\' \" Moses H. Cone, supra, at 11, n. 11 (quoting Idlewild Bon Voyage Liquor Corp. v. Epstein, supra, at 715, n. 2), and its effect is \"precisely to surrender jurisdiction of a federal suit to a state court,\" 460 U. S., at 11, n. 11. Indeed, the remand order is clearly more \"final\" than a stay order in this sense. When a district court remands a case to a state court, the district court disassociates itself from the case entirely, retaining nothing of the matter on the federal court\\'s docket.\\nThe District Court\\'s order is also indistinguishable from the stay order we considered in Moses H. Cone in that it conclusively determines an issue that is separate from the merits, namely, the question whether the federal court should decline to exercise its jurisdiction in the interest of comity and federalism. See infra, at 716-717, 727-728. In addition, the rights asserted on appeal from the District Court\\'s abstention decision are, in our view, sufficiently important to warrant an immediate appeal. See infra, at 716, 723-728 (describing interests weighed in decision to abstain under Burford ); cf.Digital, 511 U. S., at 878 (review under collateral order doctrine limited to those issues \"`too important to be denied review\\' \") (quoting Cohen, supra, at 546). And, like the stay order we found appealable in Moses H. Cone, the District Court\\'s remand order in this case will not be subsumed in any other appealable order entered by the District Court.\\nWe have previously stated that \"an order remanding a removed action does not represent a final judgment reviewable by appeal.\" Thermtron Products, Inc. v. Hermansdorfer,  423 U. S., at 352-353. Petitioner asks that we adhere to that statement and hold that appellate review of the District *715 Court\\'s remand order can only be obtained through a petition for writ of mandamus. To the extent Thermtron would require us to ignore the implications of our later holding in Moses H. Cone, however, we disavow it. Thermtron `s determination that remand orders are not reviewable \"final judgments\" doubtless was necessary to the resolution of that case, see 423 U. S., at 352 (posing the question whether mandamus was the appropriate vehicle), but our principal concern in Thermtron was the interpretation of the bar to appellate review embodied in 28 U. S. C. § 1447(d), see supra,  at 711-712, and our statement concerning the appropriate procedural vehicle for reviewing a district court\\'s remand order was peripheral to that concern. Moreover, the parties in Thermtron did not brief the question, our opinion does not refer to Catlin or its definition of \"final decisions,\" and our opinion nowhere addresses whether any class of remand order might be appealable under the collateral order doctrine. Indeed, the only support Thermtron cites for the proposition that remand orders are reviewable only by mandamus, not by appeal, is Railroad Co. v. Wiswall, 23 Wall. 507 (1875), the superannuated reasoning of which is of little vitality today, compare id., at 508 (deeming a \"writ of error to review what has been done\" an inappropriate vehicle for reviewing a court of appeals\\' \"refusal to hear and decide\"), with Moses H. Cone, 460 U. S., at 10-11, n. 11 (holding that a stay order is appealable because it amounts to a refusal to hear and decide a case).\\nAdmittedly, remand orders like the one entered in this case do not meet the traditional definition of finality\\x97they do not \"en[d] the litigation on the merits and leav[e] nothing for the court to do but execute the judgment,\" Catlin, 324 U. S., at 233. But because the District Court\\'s remand order is functionally indistinguishable from the stay order we found appealable in Moses H. Cone, see supra, at 714, we conclude that it is appealable, and turn to the merits of the Ninth Circuit\\'s decision respecting Burford abstention.\\n\\n\\n*716 III\\n\\nA\\nWe have often acknowledged that federal courts have a strict duty to exercise the jurisdiction that is conferred upon them by Congress. See, e. g., Colorado River, 424 U. S., at 821 (\"[F]ederal courts have a `virtually unflagging obligation. . . to exercise the jurisdiction given them\\' \"); England v. Louisiana Bd. of Medical Examiners, 375 U. S. 411, 415 (1964) (\"`When a federal court is properly appealed to in a case over which it has by law jurisdiction, it is its duty to take such jurisdiction\\' \") (quoting Willcox v. Consolidated Gas Co., 212 U. S. 19, 40 (1909)); Cohens v. Virginia, 6 Wheat. 264, 404 (1821) (federal courts \"have no more right to decline the exercise of jurisdiction which is given, than to usurp that which is not\"). This duty is not, however, absolute. See Canada Malting Co. v. Paterson S. S., Ltd., 285 U. S. 413, 422 (1932) (\"[T]he proposition that a court having jurisdiction must exercise it, is not universally true\"). Indeed, we have held that federal courts may decline to exercise their jurisdiction, in otherwise \"`exceptional circumstances,\\' \" where denying a federal forum would clearly serve an important countervailing interest, Colorado River, supra, at 813 (quoting County of Allegheny v. Frank Mashuda Co., 360 U. S. 185, 189 (1959)), for example, where abstention is warranted by considerations of \"proper constitutional adjudication,\" \"regard for federal-state relations,\" or \"wise judicial administration,\" Colorado River, supra, at 817 (internal quotation marks omitted).\\nWe have thus held that federal courts have the power to refrain from hearing cases that would interfere with a pending state criminal proceeding, see Younger v. Harris, 401 U. S. 37 (1971), or with certain types of state civil proceedings, see Huffman v. Pursue, Ltd., 420 U. S. 592 (1975); Juidice v. Vail, 430 U. S. 327 (1977); cases in which the resolution of a federal constitutional question might be obviated *717 if the state courts were given the opportunity to interpret ambiguous state law, see Railroad Comm\\'n of Tex. v. Pullman Co., 312 U. S. 496 (1941); cases raising issues \"intimately involved with [the States\\'] sovereign prerogative,\" the proper adjudication of which might be impaired by unsettled questions of state law, see Louisiana Power & Light Co. v. City of Thibodaux, 360 U. S. 25, 28 (1959); id., at 31 (Stewart, J., concurring); cases whose resolution by a federal court might unnecessarily interfere with a state system for the collection of taxes, see Great Lakes Dredge & Dock Co. v. Huffman, 319 U. S. 293 (1943); and cases which are duplicative of a pending state proceeding, see Colorado River Water Conservation Dist. v. United States, 424 U. S. 800 (1976); Pennsylvania v. Williams, 294 U. S. 176 (1935).\\nOur longstanding application of these doctrines reflects \"the common-law background against which the statutes conferring jurisdiction were enacted,\" New Orleans Public Service, Inc. v. Council of City of New Orleans, 491 U. S. 350, 359 (1989) (NOPSI) (citing Shapiro, Jurisdiction and Discretion, 60 N. Y. U. L. Rev. 543, 570-577 (1985)). And, as the Ninth Circuit correctly indicated, 47 F. 3d, at 354, it has long been established that a federal court has the authority to decline to exercise its jurisdiction when it \"is asked to employ its historic powers as a court of equity,\" Fair Assessment in Real Estate Assn., Inc. v. McNary, 454 U. S. 100, 120 (1981) (Brennan, J., concurring). This tradition informs our understanding of the jurisdiction Congress has conferred upon the federal courts, and explains the development of our abstention doctrines. In Pullman, for example, we explained the principle underlying our abstention doctrines as follows:\\n\". . . The history of equity jurisdiction is the history of regard for public consequences in employing the extraordinary remedy of the injunction. . . . Few public interests have a higher claim upon the discretion of a federal chancellor than the avoidance of needless friction *718 with state policies, whether the policy relates to the enforcement of the criminal law, or the administration of a specialized scheme for liquidating embarrassed business enterprises, or the final authority of a state court to interpret doubtful regulatory laws of the state. These cases reflect a doctrine of abstention appropriate to our federal system, whereby the federal courts, `exercising a wise discretion,\\' restrain their authority because of `scrupulous regard for the rightful independence of the state governments\\' and for the smooth working of the federal judiciary. This use of equitable powers is a contribution of the courts in furthering the harmonious relation between state and federal authority without the need of rigorous congressional restriction of those powers.\" 312 U. S., at 500-501 (citations omitted).\\nThough we have thus located the power to abstain in the historic discretion exercised by federal courts \"sitting in equity,\" we have not treated abstention as a \"technical rule of equity procedure.\" Thibodaux, supra, at 28. Rather, we have recognized that the authority of a federal court to abstain from exercising its jurisdiction extends to all cases in which the court has discretion to grant or deny relief. See NOPSI, supra, at 359 (mandate of federal jurisdiction \"does not eliminate . . . the federal courts\\' discretion in determining whether to grant certain types of relief\"). Accordingly, we have not limited the application of the abstention doctrines to suits for injunctive relief, but have also required federal courts to decline to exercise jurisdiction over certain classes of declaratory judgments, see, e. g., Huffman, 319 U. S., at 297 (federal court must abstain from hearing declaratory judgment action challenging constitutionality of a state tax); Samuels v. Mackell, 401 U. S. 66, 69-70, 72-73 (1971) (extending Younger abstention to declaratory judgment actions), the granting of which is generally committed to the courts\\' discretion, see Wilton v. Seven Falls Co.,  515 U. S. 277, 282 (1995) (federal courts have \"discretion in *719 determining whether and when to entertain an action under the Declaratory Judgment Act, even when the suit otherwise satisfies subject matter jurisdictional prerequisites\").\\nNevertheless, we have not previously addressed whether the principles underlying our abstention cases would support the remand or dismissal of a common-law action for damages. Cf. Deakins v. Monaghan, 484 U. S. 193, 202, and n. 6 (1988) (reserving the question whether Younger requires abstention in an action for damages); Ankenbrandt v. Richards, 504 U. S. 689 (1992) (discussing, without applying, Burford abstention in damages action). To be sure, we held in Fair Assessment in Real Estate Assn., Inc. v.McNary, supra,  that a federal court should not entertain a 42 U. S. C. § 1983 suit for damages based on the enforcement of a state tax scheme, see 454 U. S., at 115, but we have subsequently indicated that Fair Assessment was a case about the scope of the § 1983 cause of action, see National Private Truck Council, Inc. v. Oklahoma Tax Comm\\'n, 515 U. S. 582, 589-590 (1995), not the abstention doctrines. To the extent Fair Assessment does apply abstention principles, its holding is very limited. The damages action in that case was based on the unconstitutional application of a state tax law, and the award of damages turned first on a declaration that the state tax was in fact unconstitutional. We therefore drew an analogy to Huffman and other cases in which we had approved the application of abstention principles in declaratory judgment actions, and held that the federal court should decline to hear the action because \"[t]he recovery of damages under the Civil Rights Act first requires a `declaration\\' or determination of the unconstitutionality of a state tax scheme that would halt its operation.\" Fair Assessment, supra, at 115.\\nOtherwise, we have applied abstention principles to actions \"at law\" only to permit a federal court to enter a stay order that postpones adjudication of the dispute, not to dismiss the federal suit altogether. See, e. g., Thibodaux, supra, at 28-30 (approving stay order); Fornaris v. Ridge *720 Tool Co., 400 U. S. 41, 44 (1970) (per curiam) (directing District Court to \"hold its hand until the Puerto Rican Supreme Court has authoritatively ruled on the local law question in light of the federal claims\" (footnote omitted)) (emphasis added); United Gas Pipe Line Co. v. Ideal Cement Co., 369 U. S. 134, 135-136 (1962) (per curiam) (\"Wise judicial administration in this case counsels that decision of the federal question be deferred until the potentially controlling statelaw issue is authoritatively put to rest\"); Clay v. Sun Ins. Office Ltd., 363 U. S. 207, 212 (1960) (approving \"postponement of decision\" in damages suit).\\nOur decisions in Thibodaux and County of Allegheny v. Frank Mashuda Co., 360 U. S. 185 (1959), illustrate the distinction we have drawn between abstention-based remand orders or dismissals and abstention-based decisions merely to stay adjudication of a federal suit. In Thibodaux, a city in Louisiana brought an eminent domain proceeding in state court, seeking to condemn for public use certain property owned by a Florida corporation. After the corporation removed the action to federal court on diversity grounds, the Federal District Court decided on its own motion to stay the case, pending a state court\\'s determination whether the city could exercise the power of eminent domain under state law. The case did not arise within the \"equity\" jurisdiction of the federal courts, 360 U. S., at 28, because the suit sought compensation for a taking, and the District Court lacked discretion to deny relief on the corporation\\'s claim. Nonetheless, the issues in the suit were \"intimately involved with [the State\\'s] sovereign prerogative.\" Ibid. We concluded that \"[t]he considerations that prevailed in conventional equity suits for avoiding the hazards of serious disruption by federal courts of state government or needless friction between state and federal authorities are similarly appropriate in a state eminent domain proceeding brought in, or removed to, a federal court.\" Ibid. And based on that conclusion, we affirmed the District Court\\'s order staying the case.\\n*721 County of Allegheny was decided the same day as Thibodaux, and like Thibodaux it involved review of a District Court order abstaining from the exercise of diversity jurisdiction over a state law eminent domain action. Unlike in Thibodaux, however, the District Court in County of Allegheny had not merely stayed adjudication of the federal action pending the resolution of an issue in state court, but rather had dismissed the federal action altogether. Based in large measure on this distinction, we reversed the District Court\\'s order. See 360 U. S., at 190; Thibodaux, 360 U. S., at 31 (Stewart, J., concurring) (\"In Mashuda, the Court holds that it was error for the District Court to dismiss the complaint\" (emphasis added)).\\nWe were careful to note in Thibodaux that the District Court had only stayed the federal suit pending adjudication of the dispute in state court. Unlike the outright dismissal or remand of a federal suit, we held, an order merely staying the action \"does not constitute abnegation of judicial duty. On the contrary, it is a wise and productive discharge of it. There is only postponement of decision for its best fruition.\" Id., at 29. We have thus held that in cases where the relief being sought is equitable in nature or otherwise discretionary, federal courts not only have the power to stay the action based on abstention principles, but can also, in otherwise appropriate circumstances, decline to exercise jurisdiction altogether by either dismissing the suit or remanding it to state court. By contrast, while we have held that federal courts may stay actions for damages based on abstention principles, we have not held that those principles support the outright dismissal or remand of damages actions.\\nOne final line of cases bears mentioning. Though we deal here with our abstention doctrines, we have recognized that federal courts have discretion to dismiss damages actions, in certain narrow circumstances, under the common-law doctrine of forum non conveniens. The seminal case recognizing this authority is Gulf Oil Corp. v. Gilbert, 330 U. S. 501 *722 (1947), in which we considered whether a Federal District Court sitting in diversity in New York could dismiss a tort action for damages on the grounds that Virginia provided a more appropriate locale for adjudicating the dispute. Id., at 503. We conceded that the application of this doctrine should be \"rare,\" id., at 509, but also held that the exercise of forum non conveniens is not limited to actions in equity:\\n\"This Court[,] in recognizing and approving it by name has never indicated that it was rejecting application of the doctrine to law actions which had been an integral and necessary part of [the] evolution of the doctrine. Wherever it is applied in courts in other jurisdictions, its application does not depend on whether the action is at law or in equity.\" Id., at 505, n. 4 (citations omitted).\\nThe dispute in Gulf Oil was over venue, not jurisdiction, and the expectation was that after dismissal of the suit in New York the parties would refile in federal court, not the state courts of Virginia. This transfer of venue function of the forum non conveniens doctrine has been superseded by statute, see 28 U. S. C. § 1404(a); Piper Aircraft Co. v. Reyno,  454 U. S. 235, 253 (1981), and to the extent we have continued to recognize that federal courts have the power to dismiss damages actions under the common-law forum non conveniens doctrine, we have done so only in \"cases where the alternative forum is abroad.\" American Dredging Co. v. Miller, 510 U. S. 443, 449, n. 2 (1994); see, e. g., Piper, supra,  at 265-269 (dismissal of wrongful death action).\\nThe fact that we have applied the forum non conveniens  doctrine in this manner does not change our analysis in this case, where we deal with the scope of the Burford abstention doctrine. To be sure, the abstention doctrines and the doctrine of forum non conveniens proceed from a similar premise: In rare circumstances, federal courts can relinquish their jurisdiction in favor of another forum. But our abstention doctrine is of a distinct historical pedigree, and the traditional *723 considerations behind dismissal for forum non conveniens differ markedly from those informing the decision to abstain. Compare American Dredging, supra, at 448-449 (describing \"multifarious factors,\" including both public and private interests, which might allow a district court to dismiss a case under doctrine of forum non conveniens ), with Burford, 319 U. S., at 332-333 (describing \"federal-state conflict\" that requires a federal court to yield jurisdiction in favor of a state forum). Federal courts abstain out of deference to the paramount interests of another sovereign, and the concern is with principles of comity and federalism. See, e. g., ibid.; Younger, 401 U. S., at 44-45. Dismissal for forum non conveniens, by contrast, has historically reflected a far broader range of considerations, see Piper, supra, at 241, 257-262 (describing the interests which bear on forum non conveniens decision); Gulf Oil, supra, at 508-509 (same), most notably the convenience to the parties and the practical difficulties that can attend the adjudication of a dispute in a certain locality, see Piper, supra, at 257-259 (evidentiary problems, unavailability of witnesses, difficulty of coordinating multiple suits); Gulf Oil, supra, at 511 (availability of witnesses, need to interplead Virginia corporation, location of evidence).\\n\\nB\\nWith these background principles in mind, we consider the contours of the Burford doctrine. The principal issue presented in Burford was the \"reasonableness\" of an order issued by the Texas Railroad Commission, which granted \"a permit to drill four oil wells on a small plot of land in the East Texas oil field.\" 319 U. S., at 317. Due to the potentially overlapping claims of the many parties who might have an interest in a common pool of oil and the need for uniform regulation of the oil industry, Texas endowed the Railroad Commission with exclusive regulatory authority in the area. Texas also placed the authority to review the Commission\\'s *724 orders in a single set of state courts, \"[t]o prevent the confusion of multiple review,\" id., at 326, and to permit an experienced cadre of state judges to obtain \"specialized knowledge\" in the field, id., at 327. Though Texas had thus demonstrated its interest in maintaining uniform review of the Commission\\'s orders, the federal courts had, in the years preceding Burford, become increasingly involved in reviewing the reasonableness of the Commission\\'s orders, both under a constitutional standard imposed under the Due Process Clause, see, e. g., Railroad Comm\\'n of Tex. v. Rowan & Nichols Oil Co., 310 U. S. 573, 577 (1940), and under state law, which established a similar standard, see Burford, 319 U. S., at 317, 326.\\nViewing the case as \"a simple proceeding in equity to enjoin the enforcement of the Commissioner\\'s order,\" id., at 317, we framed the question presented in terms of the power of a federal court of equity to abstain from exercising its jurisdiction:\\n\"Although a federal equity court does have jurisdiction of a particular proceeding, it may, in its sound discretion, whether its jurisdiction is invoked on the ground of diversity of citizenship or otherwise, `refuse to enforce or protect legal rights, the exercise of which may be prejudicial to the public interest,\\' for it `is in the public interest that federal courts of equity should exercise their discretionary power with proper regard for the rightful independence of state governments in carrying out their domestic policy.\\' While many other questions are argued, we find it necessary to decide only one: Assuming that the federal district court had jurisdiction, should it, as a matter of sound equitable discretion, have declined to exercise that jurisdiction here?\" Id., at 317\\x97 318 (footnote omitted) (quoting United States ex rel. Greathouse v. Dern, 289 U. S. 352, 360 (1933), and Penn- sylvania v. Williams, 294 U. S., at 185).\\n*725 Having thus posed the question in terms of the District Court\\'s discretion, as a court sitting \"in equity,\" to decline jurisdiction, we approved the District Court\\'s dismissal of the complaint on a number of grounds that were unique to that case. We noted, for instance, the difficulty of the regulatory issues presented, stating that the \"order under consideration is part of the general regulatory system devised for the conservation of oil and gas in Texas, an aspect of `as thorny a problem as has challenged the ingenuity and wisdom of legislatures.\\' \" 319 U. S., at 318 (quoting Rowan, supra, at 579). We also stressed the demonstrated need for uniform regulation in the area, 319 U. S., at 318-319, citing the unified procedures Texas had established to \"prevent the confusion of multiple review,\" id., at 325-326, and the important state interests this uniform system of review was designed to serve, id., at 319-320. Most importantly, we also described the detrimental impact of ongoing federal court review of the Commission\\'s orders, which review had already led to contradictory adjudications by the state and federal courts. Id., at 327-328, 331-332.\\nWe ultimately concluded in Burford that dismissal was appropriate because the availability of an alternative, federal forum threatened to frustrate the purpose of the complex administrative system that Texas had established. See id.,  at 332 (\"The whole cycle of federal-state conflict cannot be permitted to begin again\"). We have since provided more generalized descriptions of the Burford doctrine, see, e. g., County of Allegheny, 360 U. S., at 189 (\"abstention on grounds of comity with the States where the exercise of jurisdiction by the federal court would disrupt a state administrative process\"); Colorado River, 424 U. S., at 814-816 (abstention where \"exercise of federal review of the question in a case and in similar cases would be disruptive of state efforts to establish a coherent policy with respect to a matter of substantial public concern\"), but with the exception of cases that rest only loosely on the Burford rationale, e. g., *726 Louisiana Power & Light Co. v. City of Thibodaux, 360 U. S. 25 (1959), we have revisited the decision only infrequently in the intervening 50 years. See NOPSI, 491 U. S. 350 (1989).\\nIn NOPSI, our most recent exposition of the Burford doctrine, we again located the power to dismiss based on abstention principles in the discretionary power of a federal court sitting in equity, and we again illustrated the narrow range of circumstances in which Burford can justify the dismissal of a federal action. The issue in NOPSI was pre-emption. A New Orleans utility that had been saddled by a decision of the Federal Energy Regulatory Commission (FERC) with part of the cost of building and operating a nuclear reactor sought approval of a rate increase from the Council of the City of New Orleans. The council denied the rate increase on the grounds that \"a public hearing was necessary to explore `the legality and prudency\\' [sic] \" of the expenses allocated to the utility under the FERC decision, 491 U. S., at 355, and the utility brought suit in federal court, seeking an injunction against enforcement of the council\\'s order and a declaration that the utility was entitled to a rate increase. The utility claimed that \"federal law required the Council to allow it to recover, through an increase in retail rates, its FERC-allocated share of the [cost of the reactor].\" Ibid.  The federal pre-emption question was the only issue raised in the case; there were no state law claims.\\nIn reversing the District Court\\'s decision to dismiss under Burford, we recognized \"the federal courts\\' discretion in determining whether to grant certain types of relief,\" 491 U. S., at 359, and we indicated, as we had previously in Alabama Pub. Serv. Comm\\'n v. Southern R. Co., 341 U. S. 341, 350-351 (1951), that Burford permits \"a federal court sitting in equity,\" 491 U. S., at 361, to dismiss a case only in extraordinary circumstances. We thus indicated that Burford allows a federal court to dismiss a case only if it presents \"`difficult questions of state law bearing on policy problems of substantial public import whose importance transcends the result in *727 the case then at bar,\\' \" or if its adjudication in a federal forum \"`would be disruptive of state efforts to establish a coherent policy with respect to a matter of substantial public concern.\\' \" 491 U. S., at 361 (quoting Colorado River, supra,  at 814).\\nWe ultimately held that Burford did not provide proper grounds for an abstention-based dismissal in NOPSI because the \"case [did] not involve a state-law claim, nor even an assertion that the federal claims [were] `in any way entangled in a skein of state law that must be untangled before the federal case can proceed,\\' \" 491 U. S., at 361 (quoting McNeese v. Board of Ed. for Community Unit School Dist. 187, 373 U. S. 668, 674 (1963)), and because there was no serious threat of conflict between the adjudication of the federal claim presented in the case and the State\\'s interest in ensuring uniformity in ratemaking decisions:\\n\"While Burford is concerned with protecting complex state administrative processes from undue federal influence, it does not require abstention whenever there exists such a process, or even in all cases where there is a `potential for conflict\\' with state regulatory law or policy. Here, NOPSI\\'s primary claim is that the Council is prohibited by federal law from refusing to provide reimbursement for FERC-allocated wholesale costs. Unlike a claim that a state agency has misapplied its lawful authority or has failed to take into consideration or properly weigh relevant state-law factors, federal adjudication of this sort of pre-emption claim would not disrupt the State\\'s attempt to ensure uniformity in the treatment of an `essentially local problem.\\' \" 491 U. S., at 362 (quoting Alabama Pub. Serv. Comm\\'n, supra, at 347) (citations omitted).\\nThese cases do not provide a formulaic test for determining when dismissal under Burford is appropriate, but they do demonstrate that the power to dismiss under the Burford *728 doctrine, as with other abstention doctrines, see supra, at 716-723 (describing the traditional application of the abstention doctrines), derives from the discretion historically enjoyed by courts of equity. They further demonstrate that exercise of this discretion must reflect \"principles of federalism and comity.\" Growe v. Emison, 507 U. S. 25, 32 (1993). Ultimately, what is at stake is a federal court\\'s decision, based on a careful consideration of the federal interests in retaining jurisdiction over the dispute and the competing concern for the \"independence of state action,\" Burford, 319 U. S., at 334, that the State\\'s interests are paramount and that a dispute would best be adjudicated in a state forum. See NOPSI, supra, at 363 (question under Burford is whether adjudication in federal court would \"unduly intrude into the processes of state government or undermine the State\\'s ability to maintain desired uniformity\"). This equitable decision balances the strong federal interest in having certain classes of cases, and certain federal rights, adjudicated in federal court, against the State\\'s interests in maintaining \"uniformity in the treatment of an `essentially local problem,\\' \" 491 U. S., at 362 (quoting Alabama Pub. Serv. Comm\\'n, supra, at 347), and retaining local control over \"difficult questions of state law bearing on policy problems of substantial public import,\" Colorado River, 424 U. S., at 814. This balance only rarely favors abstention, and the power to dismiss recognized in Burford represents an \"`extraordinary and narrow exception to the duty of the District Court to adjudicate a controversy properly before it.\\' \" Colorado River, supra, at 813 (quoting County of Allegheny, 360 U. S., at 188).\\n\\nC\\nWe turn, finally, to the application of Burford in this case. As in NOPSI, see 491 U. S., at 363, the federal interests in this case are pronounced, as Allstate\\'s motion to compel arbitration under the Federal Arbitration Act (FAA) implicates a substantial federal concern for the enforcement of arbitration *729 agreements. See Mitsubishi Motors Corp. v. Soler Chrysler-Plymouth, Inc., 473 U. S. 614, 631 (1985) (FAA reflects \"emphatic federal policy in favor of arbitral dispute resolution\"); cf. Moses H. Cone, 460 U. S., at 25-26 (in deciding whether to defer to state court adjudication under the Colorado River doctrine, \"the presence of federal-law issues must always be a major consideration weighing against surrender\"). With regard to the state interests, however, the case appears at first blush to present nothing more than a run-of-the-mill contract dispute. The Commissioner seeks damages from Allstate for Allstate\\'s failure to perform its obligations under a reinsurance agreement. What differentiates this case from other diversity actions seeking damages for breach of contract, if anything, is the impact federal adjudication of the dispute might have on the ongoing liquidation proceedings in state court: The Commissioner claims that any recovery by Allstate on its setoff claims would amount to an illegal \"preference\" under state law. This question appears now to have been conclusively answered by the California Supreme Court, see Prudential Reinsurance Co. v. Superior Court of Los Angeles Cty., 3 Cal. 4th 1118, 842 P. 2d 48 (1992) (permitting reinsurers to assert setoff claims in suits filed by the Commissioner in the Mission insolvency), although at the time the District Court ruled this question was still hotly contested.\\nThe Ninth Circuit concluded that the District Court\\'s remand order was inappropriate because \"Burford abstention does not apply to suits seeking solely legal relief.\" 47 F. 3d, at 354. Addressing our abstention cases, the Ninth Circuit held that the federal courts\\' power to abstain in certain cases is \"locat[ed] . . . in the unique powers of equitable courts,\" and that it derives from equity courts\\' \"`discretionary power to grant or withhold relief.\\' \" 47 F. 3d, at 355 (quoting Alabama Pub. Serv. Comm\\'n v. Southern R. Co., 341 U. S., at 350-351). The Ninth Circuit\\'s reversal of the District Court\\'s abstention\\x97based remand order in this case therefore *730 reflects the application of a per se rule: \"[T]he power of federal courts to abstain from exercising their jurisdiction, at least in Burford abstention cases, is founded upon a discretion they possess only in equitable cases.\" 47 F. 3d, at 355-356.\\nTo the extent the Ninth Circuit held only that a federal court cannot, under Burford, dismiss or remand an action when the relief sought is not discretionary, its judgment is consistent with our abstention cases. We have explained the power to dismiss or remand a case under the abstention doctrines in terms of the discretion federal courts have traditionally exercised in deciding whether to provide equitable or discretionary relief, see supra, at 717-719, 721-722, and the Commissioner appears to have conceded that the relief being sought in this case is neither equitable nor otherwise committed to the discretion of the court. See App. to Pet. for Cert. 35a\\x9737a (order denying petition for rehearing). In those cases in which we have applied traditional abstention principles to damages actions, we have only permitted a federal court to \"withhold action until the state proceedings have concluded,\" Growe, 507 U. S., at 32; that is, we have permitted federal courts applying abstention principles in damages actions to enter a stay, but we have not permitted them to dismiss the action altogether, see supra, at 719-721.\\nThe per se rule described by the Ninth Circuit is, however, more rigid than our precedents require. We have not strictly limited abstention to \"equitable cases,\" 47 F. 3d, at 356, but rather have extended the doctrine to all cases in which a federal court is asked to provide some form of discretionary relief. See Huffman, 319 U. S., at 297; Samuels, 401 U. S., at 69-70, 72-73; supra, at 718-719. Moreover, as demonstrated by our decision in Thibodaux, see supra, at 719\\x97 721, we have not held that abstention principles are completely inapplicable in damages actions. Burford might support a federal court\\'s decision to postpone adjudication of a damages action pending the resolution by the state courts *731 of a disputed question of state law. For example, given the situation the District Court faced in this case, a stay order might have been appropriate: The setoff issue was being decided by the state courts at the time the District Court ruled, see Prudential Reinsurance Co., supra, and in the interest of avoiding inconsistent adjudications on that point, the District Court might have been justified in entering a stay to await the outcome of the state court litigation.\\nLike the Ninth Circuit, we review only the remand order which was entered, and find it unnecessary to determine whether a more limited abstention-based stay order would have been warranted on the facts of this case. We have no occasion to resolve what additional authority to abstain might be provided under our decision in Fair Assessment,  see supra, at 719. Nor do we find it necessary to inquire fully as to whether this case presents the sort of \"exceptional circumstance\" in which Burford abstention or other grounds for yielding federal jurisdiction might be appropriate. Under our precedents, federal courts have the power to dismiss or remand cases based on abstention principles only where the relief being sought is equitable or otherwise discretionary. Because this was a damages action, we conclude that the District Court\\'s remand order was an unwarranted application of the Burford doctrine. The judgment is affirmed.\\nIt is so ordered. \\nJustice Scalia, concurring.\\nI join the opinion of the Court. I write separately only to respond to Justice Kennedy\\'s concurrence.\\nJustice Kennedy, while joining the opinion of the Court, says that he would \"not rule out . . . the possibility that a federal court might dismiss a suit for damages in a case where a serious affront to the interests of federalism could be averted in no other way,\" post, at 733. I would not have joined today\\'s opinion if I believed it left such discretionary *732 dismissal available. Such action is foreclosed, I think, by the Court\\'s holding, clearly summarized in the concluding sentences of the opinion: \"Under our precedents, federal courts have the power to dismiss or remand cases based on abstention principles only where the relief being sought is equitable or otherwise discretionary. Because this was a damages action, we conclude that the District Court\\'s remand order was an unwarranted application of the Burford  doctrine.\" Ante, at 731.\\nJustice Kennedy\\'s projected horrible of a \"serious affront to the interests of federalism\" cannot possibly materialize under the Court\\'s holding. There is no \"serious affront to the interests of federalism\" when Congress lawfully decides to pre-empt state action\\x97which is what our cases hold (and today\\'s opinion affirms) Congress does whenever it instructs federal courts to assert jurisdiction over matters as to which relief is not discretionary.\\nIf the Court today felt empowered to decide for itself when congressionally decreed jurisdiction constitutes a \"serious affront\" and when it does not, the opinion would have read much differently. Most pertinently, it would not have found it unnecessary \"to inquire fully as to whether this case presents the sort of `exceptional circumstance\\' in which Burford  abstention or other grounds for yielding federal jurisdiction might be appropriate.\" Ibid. There were certainly grounds for such an inquiry if we thought it relevant. The \"[then] unsettled but since resolved question of California law\" to which Justice Kennedy refers, post, at 733, was only part of the basis for the District Court\\'s decision to remand to state court; the court also pointed more generally to what it thought was the State\\'s \"overriding interest in regulating insurance insolvencies and liquidations in a uniform and orderly manner,\" App. to Pet. for Cert. 34a. As the Court\\'s opinion says, it is not necessary to inquire fully into that matter because this was a damages action.\\n*733 Justice Kennedy, concurring.\\nWhen this suit first was filed, it raised an unsettled but since resolved question of California law concerning the ability of companies in Allstate\\'s position to set off claims held against Mission. The principal reason for the District Court\\'s decision to dismiss the case was the threat posed to the state proceedings by different state and federal rulings on the question. The court\\'s concern was reasonable. States, as a matter of tradition and express federal consent, have an important interest in maintaining precise and detailed regulatory schemes for the insurance industry. See, e. g., the McCarran-Ferguson Act, 59 Stat. 33, as amended, 15 U. S. C. § 1011 et seq. The fact that a state court rather than an agency was chosen to implement California\\'s scheme provided more reason, not less, for the federal court to stay its hand.\\nAt the same time, however, we have not considered a case in which dismissal of a suit for damages by extension of the doctrine of Burford v. Sun Oil Co., 319 U. S. 315 (1943), was held to be authorized and necessary. As the Court explains, no doubt the preferred course in such circumstances is to resolve any serious potential for federal intrusion by staying the suit while retaining jurisdiction. We ought not rule out, though, the possibility that a federal court might dismiss a suit for damages in a case where a serious affront to the interests of federalism could be averted in no other way. We need not reach that question here.\\nAbstention doctrines are a significant contribution to the theory of federalism and to the preservation of the federal system in practice. They allow federal courts to give appropriate and necessary recognition to the role and authority of the States. The duty to take these considerations into account must inform the exercise of federal jurisdiction. Principles of equity thus are not the sole foundation for abstention rules; obligations of comity, and respect for the *734 appropriate balance between state and federal interests, are an important part of the justification and authority for abstention as well. See, e. g., id., at 334 (\"[A] sound respect for the independence of state action requires the federal equity court to stay its hand\"); Younger v. Harris, 401 U. S. 37, 44 (1971) (rooting abstention in \"a proper respect for state functions\" and \"sensitivity to the legitimate interests of both State and National Governments\"); Colorado River Water Conservation Dist. v. United States, 424 U. S. 800, 817 (1976) (abstention doctrines are based on \"considerations of proper constitutional adjudication and regard for federal-state relations\"). See also Shapiro, Jurisdiction and Discretion, 60 N. Y. U. L. Rev. 543, 551-552 (1985). The traditional role of discretion in the exercise of equity jurisdiction makes abstention easiest to justify in cases where equitable relief is sought, but abstention, including dismissal, is a possibility that may yet be addressed in a suit for damages, if fundamental concerns of federalism require us to face the issue.\\nWith these observations, I join the opinion of the Court.\\nNOTES\\n[*]   Richard Ruda and James I. Crowley filed a brief for the Council of State Governments et al. as amici curiae urging reversal.\\n\\nBriefs of amici curiae urging affirmance were filed for the Commonwealth of Massachusetts et al. by Scott Harshbarger, Attorney General of Massachusetts, and Thomas W. Rynard; for the National Association of Independent Insurers et al. by Charles Platto and Phillip Stano; and for the Reinsurance Association of America et al. by Maureen E. Mahoney. \\n'}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_dataset = interleave_datasets(streaming_datasets)\n",
        "combined_dataset = combined_dataset.skip(10001)\n",
        "next(iter(combined_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73jtIJvP__dj",
        "outputId": "b00d42e0-6a16-4b7c-9e1f-acdaa93874be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.builder:Using custom data configuration default-6e3092816c4f845b\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.builder:Using custom data configuration default-a1d9e8eaedd958cd\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.builder:Using custom data configuration default-de993bbf5aabe685\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-cb7569a16fd5>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# streaming datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdatasets_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_streaming_mlm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_streaming_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-cb7569a16fd5>\u001b[0m in \u001b[0;36mprocess_streaming_mlm_data\u001b[0;34m(data_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# combine the datasets to stream together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     datasets_combined = interleave_datasets(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mdatasets_to_stream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mstopping_strategy\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'all_exhausted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/combine.py\u001b[0m in \u001b[0;36minterleave_datasets\u001b[0;34m(datasets, probabilities, seed, info, split, stopping_strategy)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         return _interleave_iterable_datasets(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopping_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_interleave_iterable_datasets\u001b[0;34m(datasets, probabilities, seed, info, split, stopping_strategy)\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[0;32m-> 2309\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;31m# Perform checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[0;32m-> 2309\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;31m# Perform checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_resolve_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex_iterable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_features_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_head\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_examples_to_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_effective_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m                 \u001b[0;31m# `IterableDataset` automatically fills missing columns with None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle_data_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"TakeExamplesIterable\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mArrowExamplesIterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_arrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                         \u001b[0;32mdel\u001b[0m \u001b[0mtransformed_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'meta'"
          ]
        }
      ],
      "source": [
        "## Need a function to randomly\n",
        "# ... function takes the first 5000 entries as the dev set\n",
        "# ... then skips 5000 to make the starting position for the train set\n",
        "# ... then randomly takes another start position to cycle trhough all the data\n",
        "# ... then what? Hardens it and converts it into 512 chunks? filters out small segments (<200)\n",
        "data_files_streaming = [\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\",\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst\",\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", # ledgar worked\n",
        "\n",
        "]\n",
        "dataset_probabilities = [\n",
        "    14.40,\n",
        "    6.12,\n",
        "    6\n",
        "]\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files_streaming,\n",
        "    'val_size':10000,\n",
        "    'min_seq_length':200,\n",
        "    'max_seq_length':512,\n",
        "    'dataset_probabilities':dataset_probabilities\n",
        "}\n",
        "\n",
        "def nwords(sentence):\n",
        "    return len([w for w in sentence.split(' ') if len(w)>0])\n",
        "\n",
        "def process_streaming_mlm_data(data_config):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "    if data_config['dataset_probabilities'] is not None:\n",
        "        dataset_probabilities = [a/sum(data_config['dataset_probabilities']) for a in data_config['dataset_probabilities']]\n",
        "    else:\n",
        "        dataset_probabilities = [1.0/len(data_config['files']) for _ in range(len(data_config['files']))]\n",
        "\n",
        "    # concatenate list of streaming datasets\n",
        "    datasets_to_stream = []\n",
        "    for file_to_stream in data_config['files']:\n",
        "        dataset_to_stream = load_dataset(\"json\", data_files=file_to_stream, split=\"train\", streaming=True)\n",
        "        datasets_to_stream.append(dataset_to_stream.remove_columns(\"meta\"))\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy ='all_exhausted',\n",
        "        probabilities = dataset_probabilities\n",
        "    )\n",
        "    return datasets_combined\n",
        "\n",
        "# streaming datasets\n",
        "datasets_combined = process_streaming_mlm_data(data_streaming_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_9jBxe3_PEQ"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "\n",
        "    # make the dev set\n",
        "    datastream_for_dev = datasets_combined.take(data_config['val_size'])\n",
        "\n",
        "    # now what? harden the set?\n",
        "    dataslist_for_dev = list(datastream_for_dev)\n",
        "\n",
        "    # reject any sentences less thatn data_config['min_sentence_size]\n",
        "    dataslist_for_dev = [s['text'] for s in dataslist_for_dev if nwords(s['text']) > data_config['min_seq_length']]\n",
        "\n",
        "    # maybe use line by line\n",
        "    #dataset = LineByLineTextDataset(tokenizer=tokenizer, examples=openwebtext_dataset, block_size = 512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx8n9Ht1mow1"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Need a function to randomly\n",
        "# ... function takes the first 5000 entries as the dev set\n",
        "# ... then skips 5000 to make the starting position for the train set\n",
        "# ... then randomly takes another start position to cycle trhough all the data\n",
        "# ... then what? Hardens it and converts it into 512 chunks? filters out small segments (<200)\n",
        "data_files_streaming = [\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\",\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst\",\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", # ledgar worked\n",
        "\n",
        "]\n",
        "dataset_probabilities = [\n",
        "    14.40,\n",
        "    6.12,\n",
        "    6\n",
        "]\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files_streaming,\n",
        "    'val_size':10000,\n",
        "    'min_seq_length':200,\n",
        "    'max_seq_length':512,\n",
        "    'dataset_probabilities':dataset_probabilities\n",
        "}\n",
        "\n",
        "def nwords(sentence):\n",
        "    return len([w for w in sentence.split(' ') if len(w)>0])\n",
        "\n",
        "def process_streaming_mlm_data(data_config):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "    if data_config['dataset_probabilities'] is not None:\n",
        "        dataset_probabilities = [a/sum(data_config['dataset_probabilities']) for a in data_config['dataset_probabilities']]\n",
        "    else:\n",
        "        dataset_probabilities = [1.0/len(data_config['files']) for _ in range(len(data_config['files']))]\n",
        "\n",
        "    # concatenate list of streaming datasets\n",
        "    datasets_to_stream = []\n",
        "    for file_to_stream in data_config['files']:\n",
        "        dataset_to_stream = load_dataset(\"json\", data_files=file_to_stream, split=\"train\", streaming=True)\n",
        "        datasets_to_stream.append(dataset_to_stream.remove_columns(\"meta\"))\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy ='all_exhausted',\n",
        "        probabilities = dataset_probabilities\n",
        "    )\n",
        "    return datasets_combined\n",
        "\n",
        "# streaming datasets\n",
        "datasets_combined = process_streaming_mlm_data(data_streaming_config)\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MLMDataset(Dataset):\n",
        "    \"\"\"Do I want to pre-tokenize? If so, then the Collator will call .pad\"\"\"\n",
        "    def __init__(self, input_text, tokenizer, max_seq_length=512, min_seq_length=200):\n",
        "        self.data = []\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        for text in input_text:\n",
        "            word_count = nwords(text)\n",
        "            if word_count <= self.max_seq_length and word_count >= self.min_seq_length:\n",
        "                self.data.append(text)\n",
        "            elif word_count > self.max_seq_length:\n",
        "                text_split = text.split(\" \")\n",
        "                chunks = [\n",
        "                    text_split[i:i+self.max_seq_length] for i in range(0, word_count, 512)\n",
        "                ]\n",
        "                chunks = [\" \".join(s) for s in chunks if len(s)>=self.min_seq_length]\n",
        "                self.texts.extend(chunks)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRTYXoMV8TMY"
      },
      "outputs": [],
      "source": [
        "dataset_mlm_val = MLMDataset(texts = dataslist_for_dev, max_seq_length=data_config['max_seq_length'], min_seq_length=data_config['min_seq_length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw10KVdO8-54"
      },
      "outputs": [],
      "source": [
        "from transformers.data.data_collator import DataCollatorForLanguageModeling, Mapping\n",
        "collator_mlm = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm = True,\n",
        "    pad_to_multiple_of = 4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcvv6EivJjhW",
        "outputId": "8554a017-5386-4013-cf01-7e2cbb884832"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataslist_for_dev[7].split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bp5xbiSoqT0"
      },
      "outputs": [],
      "source": [
        "# Example of loading multiple datasets\n",
        "if False:\n",
        "    from datasets import load_dataset\n",
        "\n",
        "    # Download Wikipedia dataset\n",
        "    wikipedia_dataset = load_dataset('wikipedia', '20200501.en', split='train')\n",
        "\n",
        "    # Download OpenWebText dataset\n",
        "    openwebtext_dataset = load_dataset('openwebtext', split='train')\n",
        "\n",
        "    # Download BookCorpus dataset\n",
        "    bookcorpus_dataset = load_dataset('bookcorpus', split='train')\n",
        "\n",
        "    # Preprocess and tokenize the datasets\n",
        "    from transformers import BertTokenizer\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        return tokenizer(examples['text'], truncation=True, padding='max_length')\n",
        "\n",
        "    wikipedia_dataset = wikipedia_dataset.map(preprocess_function, batched=True)\n",
        "    openwebtext_dataset = openwebtext_dataset.map(preprocess_function, batched=True)\n",
        "    bookcorpus_dataset = bookcorpus_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "    # Combine the datasets\n",
        "    combined_dataset = wikipedia_dataset.concatenate(openwebtext_dataset)\n",
        "    combined_dataset = combined_dataset.concatenate(bookcorpus_dataset)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    combined_dataset = combined_dataset.shuffle()\n",
        "\n",
        "    # Split the dataset into training and validation sets\n",
        "    train_dataset = combined_dataset.train_test_split(test_size=0.1)['train']\n",
        "    val_dataset = combined_dataset.train_test_split(test_size=0.1)['test']\n",
        "\n",
        "    # Convert the datasets to PyTorch tensors\n",
        "    train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "    val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "    # Print some examples from the dataset\n",
        "    print(train_dataset[:5])\n",
        "    print(val_dataset[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "5d6d6c79117c4418ae920f3a3933ce8c",
            "c226f3cbc6c741749fdd62c73e6800c6",
            "66dffa1174af472cb6b6f7cdbb99d81a",
            "4dbe3181aa2f4fed8c105e0175bdf9a6",
            "849e8f1cbf6346eca2ec181e13ceb2b8",
            "ba8a7860db844d0e869d8d77c6e18d83",
            "9e4b3e23a0d94fbdace001eef383c56a",
            "69cf10a71fae487f8f1cc913f9214c98",
            "fe784053e3d047758731e6f99283d772",
            "6584e12814444c46be4fc1107d52b0ec",
            "d390110fecc7409291f79bc41e3e7c19",
            "037af811550e4536938e1fc2b2f60729",
            "c7255329fcf94a7dade2742f7407d41c",
            "db7e607a483e49d78b3c9491464490b5",
            "6e7c559006d24081b1ae338d3f443a8b",
            "c86fedd6bd374d4586e51c030cbfea1b",
            "7b56936ebd914109a0d5546c65fff0b3",
            "5b92dc1fae394c1f98221dc9762f5779",
            "24ab213f928c43b0a6fb840c03ec05a7",
            "677c94eab4d04efaba8770b32b6e82d5",
            "efb59704b56142dc82b819e7828ccaf4",
            "9d20832d687b4fe6bc280d912d203013"
          ]
        },
        "id": "5RkpXr8doqRX",
        "outputId": "87184feb-6e88-422f-c8fa-86628b00fcb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset openwebtext/plain_text to /root/.cache/huggingface/datasets/openwebtext/plain_text/1.0.0/6f68e85c16ccc770c0dd489f4008852ea9633604995addd0cd76e293aed9e521...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d6d6c79117c4418ae920f3a3933ce8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "037af811550e4536938e1fc2b2f60729",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset openwebtext downloaded and prepared to /root/.cache/huggingface/datasets/openwebtext/plain_text/1.0.0/6f68e85c16ccc770c0dd489f4008852ea9633604995addd0cd76e293aed9e521. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6f8f1a0a520a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# openwebtext_dataset = datasets.load_dataset('openwebtext') full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mopenwebtext_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openwebtext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'train[:{subset_size}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mis_small_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m     )\n\u001b[0;32m-> 1810\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m     \u001b[0;31m# Rename and cast features to match task schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# Create a dataset for each of the given splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         datasets = map_nested(\n\u001b[0m\u001b[1;32m   1146\u001b[0m             partial(\n\u001b[1;32m   1147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_single_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mdisable_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_tqdm\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_progress_bar_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, in_memory)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# Build base dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         ds = self._as_dataset(\n\u001b[0m\u001b[1;32m   1176\u001b[0m             \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[0;34m(self, split, in_memory)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \"\"\"\n\u001b[1;32m   1245\u001b[0m         \u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strip_protocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m         dataset_kwargs = ArrowReader(cache_dir, self.info).read(\n\u001b[0m\u001b[1;32m   1247\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0minstructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, name, instructions, split_infos, in_memory)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Instruction \"{instructions}\" corresponds to no data!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mget_file_instructions\u001b[0;34m(self, name, instruction, split_infos)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_file_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;34m\"\"\"Return list of dict {'filename': str, 'skip': int, 'take': int}\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         file_instructions = make_file_instructions(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiletype_suffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filetype_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mmake_file_instructions\u001b[0;34m(name, split_infos, instruction, filetype_suffix, prefix_path)\u001b[0m\n\u001b[1;32m    126\u001b[0m     }\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Create the absolute instruction (per split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mabsolute_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname2len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mfrom_spec\u001b[0;34m(cls, spec)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No instructions could be built out of {spec}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_str_to_read_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_str_to_read_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36m_str_to_read_instruction\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SUB_SPEC_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized instruction format: {spec}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_pct\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"to_pct\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"abs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     return ReadInstruction(\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized instruction format: train[:0.03]"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "import datasets\n",
        "# openwebtext_dataset = datasets.load_dataset('openwebtext') full dataset\n",
        "#openwebtext_dataset = datasets.load_dataset('openwebtext', split=f'train[:{0.03}]') # doesn't work\n",
        "\n",
        "pubmed_dataset_streamed = load_dataset(\n",
        "    \"json\", data_files=data_files, split=\"train\", streaming=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Mw-H31ooqNS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "dataset = LineByLineTextDataset(tokenizer=tokenizer, examples=openwebtext_dataset, block_size = 512)\n",
        "\n",
        "# Create a subset of the dataset with the desired number of samples\n",
        "subset_dataset = Subset(dataset, range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMawKzdFoqDj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "b6b5640287e64eaaa8d910072ea8a49b",
            "ec12f15c6abf453abab53377bc2e9ba7",
            "58221644a9f040cbaf0377564f066623",
            "c0ff005b169d428ba1930ab99f2ad5e2",
            "bc918c49557c428da985c29669a4ef59",
            "1a63b32a25944a0d9b407d8e113cc473",
            "39465c30a6d846f2a78d4016152041e4",
            "e46716dcab7c4e5f8477931b7e12ea6a",
            "80c9e2fa3d1d42f88f42e35e01cbfdc3",
            "328dedc4b7db45738e274196f66dabc6",
            "32d19b7f1d224f9fb2a0f2518c02e5bd"
          ]
        },
        "id": "w_Zygln6aW0G",
        "outputId": "7fa96ebc-005d-4064-db46-0de29d06e45f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6b5640287e64eaaa8d910072ea8a49b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "basemodelLM = AutoModelForMaskedLM.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gqsw72LkUAi",
        "outputId": "8bbcdefa-6be1-4c62-becc-529278f88a93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 512)\n",
              "      (token_type_embeddings): Embedding(2, 512)\n",
              "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basemodelLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "f90ae6d8c7e94e7a970a5b50c7721618",
            "12472278f82a48cfb84182a57092617e",
            "28118200f74e4935b8e87af4a20034c8",
            "4fc404853fe84976afd7674ab97d1533",
            "4617c5d3e4df42fe8e6d5220c94e443f",
            "800359cf35c04fb08fffcfe9de625e54",
            "a5adffec44744a10b0ac45f73eba6058",
            "7936aeb365f44e9685dce4015da9d5e9",
            "3dd36967afcc40329fcb44b346fdeebc",
            "eb77d7017bbd48f6937c38c219acc095",
            "666b0b8c335b4905baaf810735d244c9",
            "ca51f90211e14e13902200d819bfe447",
            "07b52d5502284df5b12b39c47d107310",
            "9cbd7c17733a4b01b8717c98c41ffee4",
            "ce050a2ed895498dba3347c1c4bb092d",
            "dbb5a92189d34f4d8571106c29dee036",
            "8e347cd029c24f57b55467966708d0eb",
            "743ba3957fde4d10935f4089f4da9aad",
            "c927ee3e4fa84190a00a29aea856bef8",
            "6c200c3e72394f20a570f130a707e9ad",
            "a94a510c49414b75818b4c1654394703",
            "6b62d7166e614b6ead8a0af96758cef1",
            "61455bbef8d645ec991263a9dfe13410",
            "5c1b6064c01a4f3981fe47abf757d31c",
            "c03bdfe1869d45a28466a072aa408ae0",
            "172cde34c43d40a68e2b80fad3ded0f4",
            "4b184b86f7814565936c60466ee24b32",
            "cd116c11c9cc4b56ab67ebc8649767bf",
            "562dc2a8529f4836b9afe3fcb405b27e",
            "16b987c8b2b449248ff874bc78eb39c5",
            "cb402bb1c4e14e859d55089494954a79",
            "2938bb3525c440efaec111b271dac957",
            "aad70e180d49469ca01ecfd84eb2225d"
          ]
        },
        "id": "UBP8eW-SE4Xh",
        "outputId": "ee9b721b-2b4a-47eb-a015-22ad58969e80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f90ae6d8c7e94e7a970a5b50c7721618",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca51f90211e14e13902200d819bfe447",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61455bbef8d645ec991263a9dfe13410",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['delivery', 'for', 'ex', '##w', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'reduce', 'all', 'risk', 'and', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'delivery', 'carrier', '.', 'is']\n",
            "['.', 'for', 'ex', 'works', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'assume', 'all', 'risk', ',', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'responsible', 'carrier', '.', '.']\n"
          ]
        }
      ],
      "source": [
        "## try to grab a MLM classification head\n",
        "## let's verify they have the same vocabulary\n",
        "# models from: https://arxiv.org/pdf/1908.08962.pdf\n",
        "from transformers import AutoModelForMaskedLM, AutoConfig\n",
        "modelstring_base = \"google/bert_uncased_L-12_H-512_A-8\" #\n",
        "modelstring_base = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "#modelstring_base = 'google/bert_uncased_L-6_H-512_A-8'\n",
        "basemod = AutoModelForMaskedLM.from_pretrained(modelstring_base)\n",
        "basemod_tokenizer = AutoTokenizer.from_pretrained(modelstring_base)\n",
        "# the minatoure googles have a vocab size of: 30522\n",
        "\n",
        "modelstring_lg = 'bert-large-uncased' # I think the google-team used this for the miniature models\n",
        "# bert-large uncased has a vocab size of: 30522\n",
        "#modelstring_lg = \"google/bert_uncased_L-12_H-768_A-12\"\n",
        "largmod = AutoModelForMaskedLM.from_pretrained(modelstring_lg) #\n",
        "largmod_tokenizer = AutoTokenizer.from_pretrained(modelstring_lg)#\"google/bert_uncased_L-12_H-768_A-12\")\n",
        "\n",
        "\n",
        "# note: which datasets used to train large\n",
        "# wikipedia\n",
        "# bookcorpus\n",
        "# ... but seem more about datasets and models from: https://arxiv.org/pdf/1908.08962.pdf\n",
        "\n",
        "\n",
        "text = \"For Ex Works (EXW) terms, the Supplier will [MASK] all risk and liability for the Delivered [MASK] up until delivering the goods to the nominated Carrier.\"\n",
        "with torch.no_grad():\n",
        "    inputs1 = basemod_tokenizer(text, return_tensors='pt')\n",
        "    outputs1 = basemod(**inputs1)\n",
        "    preds1 = outputs1.logits\n",
        "    inputs2 = largmod_tokenizer(text, return_tensors='pt')\n",
        "    outputs2 = largmod(**inputs2)\n",
        "    preds2 = outputs2.logits\n",
        "\n",
        "    assert (inputs1['input_ids']-inputs2['input_ids']).sum()==0, 'ids are different'\n",
        "\n",
        "    predicted_token_ids1 = preds1[0].argmax(dim=-1)\n",
        "    predicted_token_ids2 = preds2[0].argmax(dim=-1)\n",
        "\n",
        "    print(basemod_tokenizer.convert_ids_to_tokens(predicted_token_ids1))\n",
        "    print(basemod_tokenizer.convert_ids_to_tokens(predicted_token_ids2))\n",
        "\n",
        "\n",
        "# confirmation: the minature berts and the"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEOZ6zRDKivA",
        "outputId": "1f15aaa6-aa45-41a5-b0f4-24e249ecb81b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'for', 'ex', '##w', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'cover', 'all', 'risk', 'and', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'delivered', 'carrier', '.', '.']\n",
            "['.', 'for', 'ex', 'works', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'assume', 'all', 'risk', ',', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'responsible', 'carrier', '.', '.']\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUkcyKo7Mos3",
        "outputId": "64c43793-b93c-47f6-e7e4-4af099fd7f96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1996,  2005,  4654,  2860,  1006,  4654,  2860,  1007,  3408,  1010,\n",
              "         1996, 17024,  2097,  3104,  2035,  3891,  1998, 14000,  2005,  1996,\n",
              "         5359,  5350,  2039,  2127, 12771,  1996,  5350,  2000,  1996,  5359,\n",
              "         6839,  1012,  1012])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_token_ids1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr6SQ5lNMXgG",
        "outputId": "c027ad64-87f8-40d9-b672-a6e04f81fd81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs1['input_ids']-inputs2['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gal1ffFFAXn",
        "outputId": "1cd3d0ce-585c-48aa-ac94-9695056265a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertOnlyMLMHead(\n",
              "  (predictions): BertLMPredictionHead(\n",
              "    (transform): BertPredictionHeadTransform(\n",
              "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (transform_act_fn): GELUActivation()\n",
              "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basemod._modules['cls']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1on2GfKsWjxJ",
        "outputId": "7736eb78-5fff-4707-8355-544b3681e846"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "config = make_config('google/bert_uncased_L-12_H-512_A-8') #\n",
        "\n",
        "# make the basemod and tokenizer\n",
        "basemod = AutoModel.from_pretrained(config.model_string)\n",
        "basemod.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3sw0PbVXu8c"
      },
      "outputs": [],
      "source": [
        "anathem_encoder1 = AnathemBaseModule(config, basemod, tokenizer)\n",
        "anathem_encoder2 = AnathemMidModule(config, basemod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gaew7zT4XVQz",
        "outputId": "b1547ee9-319c-4290-d9d9-ec88883f959b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2566087245941162\n"
          ]
        }
      ],
      "source": [
        "time1 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time2 = time.time()\n",
        "        print(time2-time1)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        (hidden_states, extended_attention_masks) = anathem_encoder1(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )\n",
        "        features,_ = anathem_encoder2(\n",
        "            hidden_states_highres = hidden_states[0],\n",
        "            hidden_states_midres = hidden_states[1],\n",
        "            hidden_states_lowres = hidden_states[2],\n",
        "            extended_attention_mask_highres = extended_attention_masks[0],\n",
        "            extended_attention_mask_midres = extended_attention_masks[1],\n",
        "            extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_90_OeZ8YaQ7"
      },
      "outputs": [],
      "source": [
        "# the new method takes: 3.198051929473877 / 200 iterations (I can't really te)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlR61xS2Hn773Zr4+BdMu8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00001f9f055045f9ae35f94f76be8fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16dd57325504698b35f155d1bd040b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7950d803ab5b4c4ab10dc9e0902e34b1",
            "value": 1
          }
        },
        "0003c5e497294b5abf83ff5edbf90261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28542ed3d1b443c9a7ba7074825ee208",
              "IPY_MODEL_7c01fc1aabb0486f9f1f0674b46b5481",
              "IPY_MODEL_6b349f8f7890488eaa05b156ec971bf6"
            ],
            "layout": "IPY_MODEL_1602c7712db64b829a6ed1fa73367a1e"
          }
        },
        "000f6133e191461c893cffdc6783a5f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "00c7829ca16746089c8896865f374b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ef066e53974658a59443c917b2c615",
            "placeholder": "​",
            "style": "IPY_MODEL_98bd45b05dda4319adf853b5104f0a0a",
            "value": " 1725/1725 [00:00&lt;00:00, 3472.08 examples/s]"
          }
        },
        "01ac22caf29c4b2baf0ebc428f3398b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01bc3f5cd2ec4435b5a97c1dbbe7a86e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f4a70e089f4fe5abb0d9246aeee403": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01fa51a473a6472da89d47bf1116e575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02191a5509094a0abcf8862d3a8ee4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029adddbce024f50bc5d7a06d304632d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0322aeeda2bd42c1b8ce348bd56424eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5398b51140574840979cfe9ae2640c96",
            "placeholder": "​",
            "style": "IPY_MODEL_d6012c2d60024501a1bd8c529bf055e6",
            "value": "Generating validation_matched split:  99%"
          }
        },
        "037af811550e4536938e1fc2b2f60729": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7255329fcf94a7dade2742f7407d41c",
              "IPY_MODEL_db7e607a483e49d78b3c9491464490b5",
              "IPY_MODEL_6e7c559006d24081b1ae338d3f443a8b"
            ],
            "layout": "IPY_MODEL_c86fedd6bd374d4586e51c030cbfea1b"
          }
        },
        "0381ff6309df4052bb0ce823e7ff741b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a6cc127c8c4f03bab0b31bb3a1721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ccd976679e45fcbf6d6b5d06360ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_f6c454dc6dcb4528b7b05b83c72640fc",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "03a8f530cfb0469998f56dcca5f00803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cafc757655d74a2697f4ba566b3623ee",
              "IPY_MODEL_46cd1079cad04e7ea04959e14225b7fb",
              "IPY_MODEL_c508e67d54c24888b82b66108681da19"
            ],
            "layout": "IPY_MODEL_b08eba43d39846869bdd9050836be1cb"
          }
        },
        "0457dfcb462c4173bbfb7890bb043c97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0491c321ae9344ff98592968423dccd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f9c6c1ac8a4eec97466e0f2108ce39",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea3b3bc369804d85b562e7b83bc34804",
            "value": 1
          }
        },
        "04db53bae1ea4e81a1acbad7401cd331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81afc2262c8545dab41aacde91066b7d",
              "IPY_MODEL_b96a361475c947e5a0f9e5f0f867ced7",
              "IPY_MODEL_f697e928e02f405d99c43c4b1fd890c9"
            ],
            "layout": "IPY_MODEL_6da885f236a24cf5a09add7c9927db76"
          }
        },
        "052465580f854b15be0d29e9dc59125b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05fd99843ed746d1baf705e6c31881f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0787d9b7b9c649c9a8a70dd37d645a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2dfbd412e2c4420931223730a476148",
            "placeholder": "​",
            "style": "IPY_MODEL_9977be2298704813a37ed7c23e31d840",
            "value": "Generating validation split: "
          }
        },
        "07b52d5502284df5b12b39c47d107310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e347cd029c24f57b55467966708d0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_743ba3957fde4d10935f4089f4da9aad",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "08187ae67b63489bba4a7b9c10d4d719": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c60bb508854cc9b6772ab78502b6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497aad7b9ab34f158382033f65d9a8c9",
            "placeholder": "​",
            "style": "IPY_MODEL_814c0fc7e64c49bfa85d5087d1e07cb4",
            "value": " 383/383 [00:00&lt;00:00, 8.70kB/s]"
          }
        },
        "08fbdead6ab540d4a1d2d8f06879e417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029adddbce024f50bc5d7a06d304632d",
            "max": 314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a8de725a934927b52792351e0d5099",
            "value": 314
          }
        },
        "09a93d25cd25426e9c60222b29321889": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a024ed7f3514fd6a544804a8bee0d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a320f7b8bba47ddb97d2aff966e162f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0c4175d283414ab014c95269b4421b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17a0dd6bd24481e8e597415bfc02c87",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c43b4c9b58842acaf321862c3a1625d",
            "value": 1725
          }
        },
        "0cbd831de3c64f4aa269776dc73c5e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4848184b58645b2a572c6e1a1231f05",
            "placeholder": "​",
            "style": "IPY_MODEL_92d450929c8e45539c2726eaf96d5ddb",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "0db15040be1242378220fa56a21aba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e215f7f87fc48bfbb3e74c9c97b23a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ea16b4f2c6d428191dd7d31d21ad659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f331a136adf425f87a1a35682256cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f2289d8f6c460892864f1ef5ad8e08",
            "max": 392702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f81a1dd1a8b547b39297478219b41c81",
            "value": 392702
          }
        },
        "1034a93ce59f439bb128b6c096eefdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c225230ea12f4f90bd461485f300580e",
            "placeholder": "​",
            "style": "IPY_MODEL_4d3b7432f11a4a4b9eb444743d158c0d",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "11a1247638b6426c961fa4705dc85fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11db36da26a94bae9ad00e99a10d8c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5323c16a9ca4decbe25c651a14517de",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "value": 408
          }
        },
        "12371b67bb334b2786c3809702b7bac7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "12472278f82a48cfb84182a57092617e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_800359cf35c04fb08fffcfe9de625e54",
            "placeholder": "​",
            "style": "IPY_MODEL_a5adffec44744a10b0ac45f73eba6058",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "1290569b6a4d490fbfc8ca3915983263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "129cece6d8ff4bd9b0137be0486c23e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1602c7712db64b829a6ed1fa73367a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "16501e0f5de84fc7bbbdcc9b37f61d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1672001c1d7e449f9cc0ce76fcf50fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "169e8fa7a73d4797945e98ccba4cd10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b072faf11c504e39939d1ad4534f9112",
              "IPY_MODEL_f3707c74969e4f6c84d6a36b59d6fa9e",
              "IPY_MODEL_32184fc9b099416a8d49ef3c3f8c3a2e"
            ],
            "layout": "IPY_MODEL_2b95b44611524401ac7826dab5a21aa8"
          }
        },
        "16b987c8b2b449248ff874bc78eb39c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172cde34c43d40a68e2b80fad3ded0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2938bb3525c440efaec111b271dac957",
            "placeholder": "​",
            "style": "IPY_MODEL_aad70e180d49469ca01ecfd84eb2225d",
            "value": " 232k/232k [00:00&lt;00:00, 5.34MB/s]"
          }
        },
        "177dee7aa0754c7db2b595f83a4eb105": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e3330d7fb94a7eba4bac113a03f5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b0b2d2e592742499214c71c17ea64d4",
              "IPY_MODEL_a1d9e240e0064e94a841aab7ffa1f29f",
              "IPY_MODEL_c914b0150b114044baff3381de264c3f"
            ],
            "layout": "IPY_MODEL_6e53455a57dc45ac9afae3837147af06"
          }
        },
        "195b549a3cd745ffbe55e24f5865b1da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e70f5c3ae04d4b8b4a86c1233418be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7fcfc2727db445695b908ffd3370feb",
              "IPY_MODEL_546b278b05e643a4905055d1d7ffeea5",
              "IPY_MODEL_289aa49d154a496d9804cf30545bc5fc"
            ],
            "layout": "IPY_MODEL_f54be5e820704ad2b31b6b7a6b946181"
          }
        },
        "1a3234bae89d4c1eb7e84da16675cde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c50e41b12ab40ae88db5a68806a5287",
              "IPY_MODEL_9a675022c08043438f0288c2dc3d1692",
              "IPY_MODEL_42ed4267878a46a9a1a1de7f63006ab4"
            ],
            "layout": "IPY_MODEL_a587d42c581c4f75984a189ebe1b1831"
          }
        },
        "1a63b32a25944a0d9b407d8e113cc473": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7dd0c3112945959e9908425fcaa8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1aea1f6de91a43a4b491c82ffc1522be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c00f260ca44415c9c2cc342c9cab470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c5678cdeb204d21b94526ccdab34d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0381ff6309df4052bb0ce823e7ff741b",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd79d8ce5e28404c988f4965873a2f2c",
            "value": 440449768
          }
        },
        "1d322e088a6a4904a0b99740d8d4e45c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d567e39c5ac4b9f8d9908111b04100f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1deae35c0489408fa7e374cd93cca642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7d06e9df9b4a88a003bbba433c1cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d151de5a1862426f9d3ab2aaae73f4d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3963ddae09b14417abf20a566ce82a03",
            "value": " 441k/? [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "1eb78591c14840daaf6741730f2280f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f65726d2e20471e99928e5dc96726c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454aeb5a95b94bb580698d8d2f62f43f",
            "placeholder": "​",
            "style": "IPY_MODEL_a417b74f6fdb4dedbd6bf3408d0dea69",
            "value": " 392000/392702 [01:52&lt;00:00, 7530.77 examples/s]"
          }
        },
        "20402646761d4cf3975763fc130d6ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20ae65dc26cb4ab98a9637dfa2bd5a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2137d76adc0b4235bcf4e52ab94ae445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2166426a7a224f1da2065f3221463693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216e1650231e471fa0d88e3d73bf6da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2bbd67afcb9463cb0f78d7a24c5f126",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9c165248ef4e0b9c357316b95f66af",
            "value": "Downloading data: "
          }
        },
        "21f6c046574b4badbf5dac2bd4989d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235afab600844a9f8ef8f45cdba142e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ab213f928c43b0a6fb840c03ec05a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e977d511bd4f03bc8d730cd4c86027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2b4543fdb94a1d9153de7f18d108be",
            "placeholder": "​",
            "style": "IPY_MODEL_da3eb201a16240aaa91baf19b49d4209",
            "value": " 5.14k/5.14k [00:00&lt;00:00, 173kB/s]"
          }
        },
        "251219f28bd54de9a608686672dddf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e61f641028148e988678a2ecbe24a21",
            "placeholder": "​",
            "style": "IPY_MODEL_df8de4914b3f4c51b4e048f053a0e009",
            "value": " 9703/9815 [00:01&lt;00:00, 7528.70 examples/s]"
          }
        },
        "260f38a6c52d464999f74443c04cdc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2750de9a4c5740b080f5a8145de41111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28118200f74e4935b8e87af4a20034c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7936aeb365f44e9685dce4015da9d5e9",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dd36967afcc40329fcb44b346fdeebc",
            "value": 383
          }
        },
        "282f350bdadd41fa82b37f527ffe8a63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283065bbec654b89a6be726e3fe790fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28542ed3d1b443c9a7ba7074825ee208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72812af3cd8475f8a76a8ff3ec236e9",
            "placeholder": "​",
            "style": "IPY_MODEL_40731cc8e1a245868c9bf6d0972c0467",
            "value": "Map: 100%"
          }
        },
        "289aa49d154a496d9804cf30545bc5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c0e136fa3f400bab5deec7a0aff11f",
            "placeholder": "​",
            "style": "IPY_MODEL_bcee86d4105743f5a69c595029994bc8",
            "value": " 116M/116M [00:03&lt;00:00, 35.9MB/s]"
          }
        },
        "292c0b150eb84f06a012e2084b035350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2938bb3525c440efaec111b271dac957": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2958b232a65d47d7950e040ddd583898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82db512ae4ce4b1fbde3aed3d893e032",
              "IPY_MODEL_8b3982acce834b95a6f318dfb78add1c",
              "IPY_MODEL_3df2e72406454de7ade25cfe0fca7295"
            ],
            "layout": "IPY_MODEL_979449deb4254629b80f0089584c851a"
          }
        },
        "29e9e92bc30c4b2f89416481b4fb1455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34433ff3b52491fb5829b9f1522e162",
            "placeholder": "​",
            "style": "IPY_MODEL_5250f6a6e5c34894adb20a9120388ba0",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2a7388d890b2460c86be4cd32187f319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38b91d162c304c6eaad444f0abffa931",
              "IPY_MODEL_0f331a136adf425f87a1a35682256cd9",
              "IPY_MODEL_1f65726d2e20471e99928e5dc96726c7"
            ],
            "layout": "IPY_MODEL_dae9d080adfc4bfbba896820bbf57c3b"
          }
        },
        "2b5f6a6687b34036bd5a87c8b61dc2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d265db9a419d4edfbdb91e4bd8f78846",
            "placeholder": "​",
            "style": "IPY_MODEL_aae2a30b7f474dbcbf55aa677b9518f9",
            "value": "Downloading metadata: 100%"
          }
        },
        "2b95b44611524401ac7826dab5a21aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c148a8aa9fe4f30a69392f10a350eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c43b4c9b58842acaf321862c3a1625d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c5569a7006f4b87a645d6b8af39158b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe3c4d6e4774be691e7c0551fd334ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f6111712e2491198ac03400ef0ce7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312b0a411cf7451d845fae7b77dff7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "31fef27ae4d44fa691185c3fa750756a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa205a1da88e418a881efb0963042e9d",
            "placeholder": "​",
            "style": "IPY_MODEL_30f6111712e2491198ac03400ef0ce7d",
            "value": "Generating validation split:  73%"
          }
        },
        "32184fc9b099416a8d49ef3c3f8c3a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2137d76adc0b4235bcf4e52ab94ae445",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb506371e6e4cd2947988d6c7050809",
            "value": " 232k/232k [00:00&lt;00:00, 6.89MB/s]"
          }
        },
        "326c1c104f254d1189c78c6abd318451": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328dedc4b7db45738e274196f66dabc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d19b7f1d224f9fb2a0f2518c02e5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32f65d2703c048929de10720219fdf53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33088ffab85f4898bc39a1167e70388c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3312caf3fc76420ead7f4945675df52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3315267c32f24d29804c12af760956aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31fef27ae4d44fa691185c3fa750756a",
              "IPY_MODEL_11db36da26a94bae9ad00e99a10d8c5a",
              "IPY_MODEL_f4bb56cde5b042e8821ee26d25da4ea2"
            ],
            "layout": "IPY_MODEL_312b0a411cf7451d845fae7b77dff7d6"
          }
        },
        "33ae5a6ee9244aeea02e10990e8dd3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f1b9961c6b14a1a92f3cb2c82883a17",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd3f1f64d81471083416a3e4ca6aa60",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "3442f76ad9514478ab0e4a4b823dd68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f75d5c8f4645b69028fca44c3505e6",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a96578d913114e78baf1950b0d7cd998",
            "value": 231508
          }
        },
        "3650364038714617bd315e4fcd23d3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c0e136fa3f400bab5deec7a0aff11f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3751db7e581847efa6c224dd50c9b7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "377a7fa0ebce4c8a96a55c6e1c08403f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff3a2b6be1f4220b0e3c055fc587c7e",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af816340aae74a81a6eaf63a1933f5bf",
            "value": 1340616616
          }
        },
        "379f64826a714ae89a85c265b4937902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37e0abc511f04624986368ef45b50131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33088ffab85f4898bc39a1167e70388c",
            "placeholder": "​",
            "style": "IPY_MODEL_1672001c1d7e449f9cc0ce76fcf50fc8",
            "value": " 2.88k/2.88k [00:00&lt;00:00, 139kB/s]"
          }
        },
        "38b91d162c304c6eaad444f0abffa931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef72b344a964832bd2b19140d230f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_b719af868833401c86d45d2ae059c868",
            "value": "Generating train split: 100%"
          }
        },
        "39465c30a6d846f2a78d4016152041e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3963ddae09b14417abf20a566ce82a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3988d9e57bc841b49a5079130f071dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39b9b4412ee54145aa8f08501c482d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5afcf9de549f4903988f816da0784c00",
              "IPY_MODEL_af678d1c5903451f8b1c1f29b82c273f",
              "IPY_MODEL_9b95627c2d0a43399ac929b330a0d46b"
            ],
            "layout": "IPY_MODEL_b48bbd953c50443ca2e4b3681909dd94"
          }
        },
        "3ba6ff0046c843679c0581a44ec69e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c45e6794f974b4199098bcd87765e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c54d6fd6a004ed98c1cb595a0bb84a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cfadb1af62b45e1b6cf9f3243a281d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a51c61ff30d4474080167a38356ca402",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f38b1623f14bc9bea9b812f9102fce",
            "value": " 68.0/68.0 [00:00&lt;00:00, 1.39kB/s]"
          }
        },
        "3dd36967afcc40329fcb44b346fdeebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3df2e72406454de7ade25cfe0fca7295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7834f7deaa3b43669cd0de893fa62448",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa5b162648c4abca773a478c3e3beb9",
            "value": " 227M/227M [00:07&lt;00:00, 30.8MB/s]"
          }
        },
        "3e72971bf9804c3688c24e0a3eca0da7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2b4543fdb94a1d9153de7f18d108be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb4b68eda9f481abbc7b2456644e16b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4009b3c800c3490f98756696c133ed71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93eed229a52c4ce8913649160c213212",
            "placeholder": "​",
            "style": "IPY_MODEL_d9bc4736e2dd45d2963cad4ee1700641",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "40731cc8e1a245868c9bf6d0972c0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422ac21cdb1d45a8a0814ef00c9769ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "429379eb4c4f452d94a52521911811a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68c38cc7bf84db2ab1540ca985599e2",
            "max": 8671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "value": 8671
          }
        },
        "42c13d8f7c694c6599c0a2e10ca0765f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0322aeeda2bd42c1b8ce348bd56424eb",
              "IPY_MODEL_c0908ccc452b42e681765c37a139e878",
              "IPY_MODEL_251219f28bd54de9a608686672dddf0d"
            ],
            "layout": "IPY_MODEL_e982215023c24a3caf881dd3986cca86"
          }
        },
        "42ed4267878a46a9a1a1de7f63006ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba76516f42224f79a9dfe8a36385bb22",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b2dc48588b482f80e9a2473dc5b452",
            "value": " 28.8k/28.8k [00:00&lt;00:00, 619kB/s]"
          }
        },
        "4326c46139fd4b6882d864400e35a9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e76cddc6d7d04d3fb01c11225ec1b6a2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ad1276e945e4915a079e97e06048ee9",
            "value": 570
          }
        },
        "44ce4959b2bc410a8b455eb2adb7ffc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d07abd85374cca92698119139b140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1deae35c0489408fa7e374cd93cca642",
            "placeholder": "​",
            "style": "IPY_MODEL_260f38a6c52d464999f74443c04cdc03",
            "value": "Downloading data: "
          }
        },
        "454aeb5a95b94bb580698d8d2f62f43f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4617c5d3e4df42fe8e6d5220c94e443f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46cd1079cad04e7ea04959e14225b7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef504e4ab1384063bff714e1649e0aa3",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b387dec327543f79f957f81fb651cc7",
            "value": 3668
          }
        },
        "46f2289d8f6c460892864f1ef5ad8e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ff0481a7a94abb9cea91aaacd1ea29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470a84311bbf40c6ae6322d6edc353ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9568bdb74f3e450f91b3558cf5ad5da1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7b946e1ad95455b818512986f83f7cd",
            "value": 231508
          }
        },
        "476c5672e7784cda8255af2049de1ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73e2bfea29de4c47b0c60590deff9771",
              "IPY_MODEL_4326c46139fd4b6882d864400e35a9bc",
              "IPY_MODEL_a53d537c8c0e48d1a77fbc22e5c41402"
            ],
            "layout": "IPY_MODEL_4eba976ecf5145e0a60cc8a838bff5c9"
          }
        },
        "4818654025b94f38a631b2bcdf36014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48729429682c4b37a624ba2eb55d1966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497aad7b9ab34f158382033f65d9a8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499cfcd99b96406383ff92126cab7c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0787d9b7b9c649c9a8a70dd37d645a11",
              "IPY_MODEL_a18b3a57972c42e1b061e2ada2c7858e",
              "IPY_MODEL_f5a25f48fd7045d092d4b4b1a66f296c"
            ],
            "layout": "IPY_MODEL_dbbeb2e4f0ca4e3b831fc5f58b883cf7"
          }
        },
        "49a90c227b9342ddbb670c9fe85591cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a1ecdd97d194a9ab63a15980d1e2e31",
            "placeholder": "​",
            "style": "IPY_MODEL_5dd1df4079d44b1aad849b4a0a5e3b55",
            "value": " 8.67k/8.67k [00:00&lt;00:00, 296kB/s]"
          }
        },
        "4a16335de26a43c09d578cbbe20e98d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d567e39c5ac4b9f8d9908111b04100f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f619ea2b062a4eacb80ade328d56c2aa",
            "value": 231508
          }
        },
        "4b184b86f7814565936c60466ee24b32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b242512f1ca473793bf144e5d062a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b35ff0e35ca4e6088f2f1f687ff924c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4dae6b5bd5474491e1c86a6e462ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3b7432f11a4a4b9eb444743d158c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d798a40b2a24c4f8ce823023d75ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10d3cde2d7b4121971d8e19e3362b30",
            "placeholder": "​",
            "style": "IPY_MODEL_4818654025b94f38a631b2bcdf36014c",
            "value": "Downloading readme: 100%"
          }
        },
        "4dbe3181aa2f4fed8c105e0175bdf9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6584e12814444c46be4fc1107d52b0ec",
            "placeholder": "​",
            "style": "IPY_MODEL_d390110fecc7409291f79bc41e3e7c19",
            "value": " 21/21 [00:00&lt;00:00, 516.13it/s]"
          }
        },
        "4eba976ecf5145e0a60cc8a838bff5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef3bcbd56164ddaac3068fb93a66630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cbd831de3c64f4aa269776dc73c5e28",
              "IPY_MODEL_d947bfe9101646c9a7222ada482d4455",
              "IPY_MODEL_8e9137be11744d329bceecd548d91025"
            ],
            "layout": "IPY_MODEL_326c1c104f254d1189c78c6abd318451"
          }
        },
        "4fc404853fe84976afd7674ab97d1533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb77d7017bbd48f6937c38c219acc095",
            "placeholder": "​",
            "style": "IPY_MODEL_666b0b8c335b4905baaf810735d244c9",
            "value": " 383/383 [00:00&lt;00:00, 19.0kB/s]"
          }
        },
        "4fe04dcab6654d0594a56109e7eb6805": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515c53eaeaeb4b90a9e7f0987aa8e295": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516b1796b208442ca32a48c8611b35fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd0803047b8426eb76e8412d6cf976a",
            "placeholder": "​",
            "style": "IPY_MODEL_6b6b3265e630457aac2433dea92348e9",
            "value": "Downloading data: 100%"
          }
        },
        "5183ef3eec0d4bdfbcc5544b0fec573b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5250f6a6e5c34894adb20a9120388ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5398b51140574840979cfe9ae2640c96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546b278b05e643a4905055d1d7ffeea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195b549a3cd745ffbe55e24f5865b1da",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe156388571b4c63b5fc5f5ca857e522",
            "value": 116252865
          }
        },
        "5589d685cbc94ea0a045dcba0e69a7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600bc8f5877547aca898f8c85902040e",
            "placeholder": "​",
            "style": "IPY_MODEL_b65ef6da8ad34e2285813544d00bf3e5",
            "value": " 711k/711k [00:00&lt;00:00, 10.2MB/s]"
          }
        },
        "560c716068a645d596cc2fe9b886c0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235afab600844a9f8ef8f45cdba142e0",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7537c19825a49cd8f3343c153fe56ef",
            "value": 383
          }
        },
        "562dc2a8529f4836b9afe3fcb405b27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "573b3112cbee4ba581c18884df0a269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc799bb2e34741fabc79181ea30ee78f",
            "placeholder": "​",
            "style": "IPY_MODEL_a78c45e4929847f0a635988d1ef9d78f",
            "value": " 232k/232k [00:00&lt;00:00, 2.46MB/s]"
          }
        },
        "58221644a9f040cbaf0377564f066623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46716dcab7c4e5f8477931b7e12ea6a",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80c9e2fa3d1d42f88f42e35e01cbfdc3",
            "value": 116252865
          }
        },
        "595530337aab40f6b5cc24d69b3ebaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596c6eda354b45bfa8e02c8359133217": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab64a9556124cf892f33cc9973240ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5afcf9de549f4903988f816da0784c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_515c53eaeaeb4b90a9e7f0987aa8e295",
            "placeholder": "​",
            "style": "IPY_MODEL_c5fae6b0606d485989a18194ab3a7827",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "5b92dc1fae394c1f98221dc9762f5779": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bb2391eeae9434fa3f11ffd1355ca6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bd4908665db4c8baac9d52a40a1c28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46ff0481a7a94abb9cea91aaacd1ea29",
            "placeholder": "​",
            "style": "IPY_MODEL_05fd99843ed746d1baf705e6c31881f6",
            "value": " 9832/9832 [00:01&lt;00:00, 7725.02 examples/s]"
          }
        },
        "5c1b6064c01a4f3981fe47abf757d31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd116c11c9cc4b56ab67ebc8649767bf",
            "placeholder": "​",
            "style": "IPY_MODEL_562dc2a8529f4836b9afe3fcb405b27e",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "5c69e45579f54fc6b2415ebbad4da477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c96dd4ef67f4900af004f322706921f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd0803047b8426eb76e8412d6cf976a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d276b68035e42d79ec3d6c3600cd125": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6d6c79117c4418ae920f3a3933ce8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c226f3cbc6c741749fdd62c73e6800c6",
              "IPY_MODEL_66dffa1174af472cb6b6f7cdbb99d81a",
              "IPY_MODEL_4dbe3181aa2f4fed8c105e0175bdf9a6"
            ],
            "layout": "IPY_MODEL_849e8f1cbf6346eca2ec181e13ceb2b8"
          }
        },
        "5dc68509c6494c6ebdd22c30ea632bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd1df4079d44b1aad849b4a0a5e3b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5df7aa079833485bbde65e4658b496e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283065bbec654b89a6be726e3fe790fd",
            "max": 28682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebf0c7ac01e441d68a38cac5fed89d00",
            "value": 28682
          }
        },
        "5e1a387877054dacbb6bf1fa32b08d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed5174d9d6c4680bb7cc1e803184102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91bcf74809894d39b5199ca23691f00f",
            "placeholder": "​",
            "style": "IPY_MODEL_85a35c16364f4c6880dbbecf061faf44",
            "value": " 1.34G/1.34G [00:17&lt;00:00, 83.7MB/s]"
          }
        },
        "5ef185dc852646fbb92d1eb31981bed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f0512fb3607471f817b5c215d94e4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd68849bd0a44238fbb9bec129b0511",
            "placeholder": "​",
            "style": "IPY_MODEL_3312caf3fc76420ead7f4945675df52a",
            "value": " 314/314 [00:00&lt;00:00, 4.38kB/s]"
          }
        },
        "5f1b9961c6b14a1a92f3cb2c82883a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdca1f2b388437fac7624c0eca1ec26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600bc8f5877547aca898f8c85902040e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610680918453400fba82622926af1b56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "61455bbef8d645ec991263a9dfe13410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c1b6064c01a4f3981fe47abf757d31c",
              "IPY_MODEL_c03bdfe1869d45a28466a072aa408ae0",
              "IPY_MODEL_172cde34c43d40a68e2b80fad3ded0f4"
            ],
            "layout": "IPY_MODEL_4b184b86f7814565936c60466ee24b32"
          }
        },
        "619bcc47eac24a098ac5908bddc4297d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638f36ef35ec4ec88ba057c63093eca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a2424581894ab48ad61b9f38cc882e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f3c83e61b94b4db567e1ffb7057472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4009b3c800c3490f98756696c133ed71",
              "IPY_MODEL_3442f76ad9514478ab0e4a4b823dd68c",
              "IPY_MODEL_9d936d10a67845f1baaf6bd502cfe51e"
            ],
            "layout": "IPY_MODEL_afc1126d123d40018c1bbf4a8d32ade9"
          }
        },
        "641fd37171904fb590b7877d8403aeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8f710e2dcfc40398ce16a4ac265cc26",
              "IPY_MODEL_377a7fa0ebce4c8a96a55c6e1c08403f",
              "IPY_MODEL_5ed5174d9d6c4680bb7cc1e803184102"
            ],
            "layout": "IPY_MODEL_2c148a8aa9fe4f30a69392f10a350eac"
          }
        },
        "656cb0e3b85c4a57936749caa02f664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6584e12814444c46be4fc1107d52b0ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666b0b8c335b4905baaf810735d244c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6679251fa0b64c59ab34bf7a811e0ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fdb79deb808435caba9e231f98118f0",
            "placeholder": "​",
            "style": "IPY_MODEL_7bac298bf1954016a76ce82ab5842870",
            "value": " 61.5M/61.5M [00:02&lt;00:00, 25.4MB/s]"
          }
        },
        "66dffa1174af472cb6b6f7cdbb99d81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cf10a71fae487f8f1cc913f9214c98",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe784053e3d047758731e6f99283d772",
            "value": 21
          }
        },
        "677c94eab4d04efaba8770b32b6e82d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "686aaeb98c1a4e688af5030963b8525e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68db1531b9574e72a2ff0d52995a7347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694f0df64a4b433aa22afef48d968090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d264b002cc4c3889089fe28f6cfa80",
              "IPY_MODEL_f6a686a076954e0c9c5d11429a14d582",
              "IPY_MODEL_9f512b3c83bf4fcaa1640cf5cdbea8c8"
            ],
            "layout": "IPY_MODEL_282f350bdadd41fa82b37f527ffe8a63"
          }
        },
        "69cf10a71fae487f8f1cc913f9214c98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b349f8f7890488eaa05b156ec971bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3537b58aca04f398663d6a8f6bd7cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_0ea16b4f2c6d428191dd7d31d21ad659",
            "value": " 1725/1725 [00:03&lt;00:00, 758.62 examples/s]"
          }
        },
        "6b62d7166e614b6ead8a0af96758cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b6b3265e630457aac2433dea92348e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6baecbf668bc4a6f93be03e5f671b76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d322e088a6a4904a0b99740d8d4e45c",
            "placeholder": "​",
            "style": "IPY_MODEL_20402646761d4cf3975763fc130d6ff5",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "6c200c3e72394f20a570f130a707e9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6da885f236a24cf5a09add7c9927db76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e53455a57dc45ac9afae3837147af06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7c559006d24081b1ae338d3f443a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb59704b56142dc82b819e7828ccaf4",
            "placeholder": "​",
            "style": "IPY_MODEL_9d20832d687b4fe6bc280d912d203013",
            "value": " 8013685/8013769 [48:13&lt;00:00, 2131.36 examples/s]"
          }
        },
        "6eeb3579c2b644a6b8501cc246083c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f102144e4fd4840b77808f1e6ff7697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fdb79deb808435caba9e231f98118f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff3a2b6be1f4220b0e3c055fc587c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70225a6a843d4ccf87d1b43d4cf1895b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7081369f016f46ec9ad16edcedd027b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "735872b51d5a4042b1019254a2ada269": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e2bfea29de4c47b0c60590deff9771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2750de9a4c5740b080f5a8145de41111",
            "placeholder": "​",
            "style": "IPY_MODEL_ecf9c5705a7b491c82d4e8b5cbd8c439",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "743ba3957fde4d10935f4089f4da9aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "755e3809aa3043f99d3664955a3a2c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d07abd85374cca92698119139b140e",
              "IPY_MODEL_00001f9f055045f9ae35f94f76be8fe4",
              "IPY_MODEL_1e7d06e9df9b4a88a003bbba433c1cae"
            ],
            "layout": "IPY_MODEL_a87f8ff9f575436da0dcf9a31642f7b7"
          }
        },
        "75d264b002cc4c3889089fe28f6cfa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052465580f854b15be0d29e9dc59125b",
            "placeholder": "​",
            "style": "IPY_MODEL_619bcc47eac24a098ac5908bddc4297d",
            "value": "Downloading data files: 100%"
          }
        },
        "75d76bf886514ba5ac9fedee0fcfba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fd0e5e6b8f47c6a4c9557f127ef73b",
            "placeholder": "​",
            "style": "IPY_MODEL_b963a45c28d1437f86109f283a370f38",
            "value": " 384/384 [00:00&lt;00:00, 3.58kB/s]"
          }
        },
        "77d712d32c0f491cb9a58df33b012b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7834f7deaa3b43669cd0de893fa62448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78608a4a3a8f4c119d9a0128153a39eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48729429682c4b37a624ba2eb55d1966",
            "placeholder": "​",
            "style": "IPY_MODEL_6eeb3579c2b644a6b8501cc246083c97",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7936aeb365f44e9685dce4015da9d5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7950d803ab5b4c4ab10dc9e0902e34b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ad09b3ac2d5406caa626954d7dc4b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b0b2d2e592742499214c71c17ea64d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df984168f38140c09a952126a0822347",
            "placeholder": "​",
            "style": "IPY_MODEL_2c5569a7006f4b87a645d6b8af39158b",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "7b387dec327543f79f957f81fb651cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b56936ebd914109a0d5546c65fff0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bac298bf1954016a76ce82ab5842870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bdb5cce9c364437970f01220e5f0aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e72971bf9804c3688c24e0a3eca0da7",
            "placeholder": "​",
            "style": "IPY_MODEL_d36c80ffd8824fdb8e1e344f41fa3669",
            "value": "Downloading metadata: 100%"
          }
        },
        "7c01fc1aabb0486f9f1f0674b46b5481": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f102144e4fd4840b77808f1e6ff7697",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82084929de714135a363f5693f4a0aac",
            "value": 1725
          }
        },
        "7c1ea655a2844e0e81c89529f95acb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fca62c132b4b9c9af64955480ac905",
            "placeholder": "​",
            "style": "IPY_MODEL_7081369f016f46ec9ad16edcedd027b0",
            "value": "Generating validation_mismatched split: 100%"
          }
        },
        "7c50e41b12ab40ae88db5a68806a5287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aea1f6de91a43a4b491c82ffc1522be",
            "placeholder": "​",
            "style": "IPY_MODEL_3c45e6794f974b4199098bcd87765e63",
            "value": "Downloading builder script: 100%"
          }
        },
        "7e61f641028148e988678a2ecbe24a21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f511160291e4a4a82f8694772449ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800359cf35c04fb08fffcfe9de625e54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808dad49922a431d9c43faf48478a069": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80c9e2fa3d1d42f88f42e35e01cbfdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80fd0e5e6b8f47c6a4c9557f127ef73b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814c0fc7e64c49bfa85d5087d1e07cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81afc2262c8545dab41aacde91066b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638f36ef35ec4ec88ba057c63093eca2",
            "placeholder": "​",
            "style": "IPY_MODEL_4b35ff0e35ca4e6088f2f1f687ff924c",
            "value": "100%"
          }
        },
        "82084929de714135a363f5693f4a0aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "825fb9aa19594a61b2a779837eb230b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686aaeb98c1a4e688af5030963b8525e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a024ed7f3514fd6a544804a8bee0d78",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "82db512ae4ce4b1fbde3aed3d893e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd748fe04232441abb30f153e54f9890",
            "placeholder": "​",
            "style": "IPY_MODEL_8eda2864b2774815bd6d860c1fdf2625",
            "value": "Downloading data: 100%"
          }
        },
        "82f1dc2ca5ef4e45818a2b9107732d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae32d0dd19e40e8a0fc4b04b325abd6",
            "placeholder": "​",
            "style": "IPY_MODEL_20ae65dc26cb4ab98a9637dfa2bd5a62",
            "value": " 616/616 [00:00&lt;00:00, 9.58kB/s]"
          }
        },
        "843d11a2271246f49dbabe80fc4762d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84949f4ae0b6402aaca1326d124436b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3650364038714617bd315e4fcd23d3bd",
            "placeholder": "​",
            "style": "IPY_MODEL_f6823010dba245d1843a2f324e00c382",
            "value": " 1/1 [00:03&lt;00:00,  3.31s/it]"
          }
        },
        "849e8f1cbf6346eca2ec181e13ceb2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a35c16364f4c6880dbbecf061faf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85aa23b715f248248204a2bdf3e5f7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85cfc6e8aa8b4da4b7f487576e2d728a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8631f393c12e4ebaa57838a4f1c1efb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868c8d0c5a4a4535a00dd833ad0dbb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1ea655a2844e0e81c89529f95acb4c",
              "IPY_MODEL_f4a51d5c122645a5a58acfbadb0cf752",
              "IPY_MODEL_5bd4908665db4c8baac9d52a40a1c28e"
            ],
            "layout": "IPY_MODEL_000f6133e191461c893cffdc6783a5f9"
          }
        },
        "8974203b2bde4395b3144ffe61596643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdca1f2b388437fac7624c0eca1ec26",
            "placeholder": "​",
            "style": "IPY_MODEL_1c00f260ca44415c9c2cc342c9cab470",
            "value": " 232k/232k [00:00&lt;00:00, 9.15MB/s]"
          }
        },
        "8a0851189dae4fbdb953f6afe6f3ba29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1ecdd97d194a9ab63a15980d1e2e31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae32d0dd19e40e8a0fc4b04b325abd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3982acce834b95a6f318dfb78add1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a93d25cd25426e9c60222b29321889",
            "max": 226850426,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0db15040be1242378220fa56a21aba28",
            "value": 226850426
          }
        },
        "8c45ce351a9b45dda4359b706ea36aba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbb1fccc920458cbffc7029953e5363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29e9e92bc30c4b2f89416481b4fb1455",
              "IPY_MODEL_1c5678cdeb204d21b94526ccdab34d32",
              "IPY_MODEL_dea6b34486294d388d68aa9ef3aaa281"
            ],
            "layout": "IPY_MODEL_e34566724c6e4598860e77d6b710faf8"
          }
        },
        "8e347cd029c24f57b55467966708d0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e856b6e5ce74a4fa9b35ae801df4d31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9137be11744d329bceecd548d91025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c45ce351a9b45dda4359b706ea36aba",
            "placeholder": "​",
            "style": "IPY_MODEL_9e2644d3c3bb40aa9eba632e756112a3",
            "value": " 125/125 [00:00&lt;00:00, 3.05kB/s]"
          }
        },
        "8ea68f6b18c342938de8be19d3896038": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42f3b105ff645dcb58805289594baad",
            "placeholder": "​",
            "style": "IPY_MODEL_d4214693adb54e44b31fd40e549802b8",
            "value": "Generating test split: 100%"
          }
        },
        "8eda2864b2774815bd6d860c1fdf2625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1bf2df4214449483a37dc84d9f3c43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8f8bd06e8b4ce7bb74b30a5a2e68b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af00aa1a3bd64be9ad8f4df3e3c5f942",
            "placeholder": "​",
            "style": "IPY_MODEL_11a1247638b6426c961fa4705dc85fee",
            "value": "Downloading data files: 100%"
          }
        },
        "90cd613da6d54fa881f325d531f371c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f8f8bd06e8b4ce7bb74b30a5a2e68b4",
              "IPY_MODEL_0491c321ae9344ff98592968423dccd3",
              "IPY_MODEL_84949f4ae0b6402aaca1326d124436b3"
            ],
            "layout": "IPY_MODEL_8e856b6e5ce74a4fa9b35ae801df4d31"
          }
        },
        "91738a91e20344f1b848ccc39bd0b686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d88bd9fdda49bcbf01366f8fe6fab2",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5cfab63b2d47869f69b772f9801d69",
            "value": "Downloading data: "
          }
        },
        "91bcf74809894d39b5199ca23691f00f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91de7341a97a4415b5656ee33fe6395f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1bf2df4214449483a37dc84d9f3c43",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9afa2b87f4a94a58b7c639a0a7f63813",
            "value": 616
          }
        },
        "91eebca40ce344039704522c4570353c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "928685f89f3e40ddbf9b97a5281bb86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "928bc9d9e240469298d2a267fe3b9e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595530337aab40f6b5cc24d69b3ebaf9",
            "max": 5145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85aa23b715f248248204a2bdf3e5f7ec",
            "value": 5145
          }
        },
        "92d450929c8e45539c2726eaf96d5ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "933e94b11adf415abb0b16cad1201e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93eed229a52c4ce8913649160c213212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9568bdb74f3e450f91b3558cf5ad5da1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e7d97dc8f44c7d873060a89f82ce0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979449deb4254629b80f0089584c851a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98371c9b595a4354a51020081c8adaa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d25f24f6c4464900af0369a1d34197af",
              "IPY_MODEL_cf24681dbccd42f59ffda006ca4cdac6",
              "IPY_MODEL_afbc002e8eed45b78884f7c4ccd6f37f"
            ],
            "layout": "IPY_MODEL_12371b67bb334b2786c3809702b7bac7"
          }
        },
        "98bd45b05dda4319adf853b5104f0a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9977be2298704813a37ed7c23e31d840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99ef066e53974658a59443c917b2c615": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a675022c08043438f0288c2dc3d1692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff58b4945b004e9996568c228986d287",
            "max": 28751,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1290569b6a4d490fbfc8ca3915983263",
            "value": 28751
          }
        },
        "9ad1276e945e4915a079e97e06048ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9afa2b87f4a94a58b7c639a0a7f63813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b95627c2d0a43399ac929b330a0d46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb83a4e946fb4c78b556a06784f8b2c0",
            "placeholder": "​",
            "style": "IPY_MODEL_85cfc6e8aa8b4da4b7f487576e2d728a",
            "value": " 384/384 [00:00&lt;00:00, 4.15kB/s]"
          }
        },
        "9c8b871e03af41ada7990e7b76084f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ae5a6ee9244aeea02e10990e8dd3da",
              "IPY_MODEL_470a84311bbf40c6ae6322d6edc353ae",
              "IPY_MODEL_8974203b2bde4395b3144ffe61596643"
            ],
            "layout": "IPY_MODEL_d4ea11ee38044f7cb7ffe1a5b018bda7"
          }
        },
        "9cbd7c17733a4b01b8717c98c41ffee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c927ee3e4fa84190a00a29aea856bef8",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c200c3e72394f20a570f130a707e9ad",
            "value": 116252865
          }
        },
        "9d20832d687b4fe6bc280d912d203013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d936d10a67845f1baaf6bd502cfe51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_735872b51d5a4042b1019254a2ada269",
            "placeholder": "​",
            "style": "IPY_MODEL_5bb2391eeae9434fa3f11ffd1355ca6f",
            "value": " 232k/232k [00:00&lt;00:00, 1.65MB/s]"
          }
        },
        "9e2644d3c3bb40aa9eba632e756112a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e4b3e23a0d94fbdace001eef383c56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ef72b344a964832bd2b19140d230f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f512b3c83bf4fcaa1640cf5cdbea8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab64a9556124cf892f33cc9973240ea",
            "placeholder": "​",
            "style": "IPY_MODEL_656cb0e3b85c4a57936749caa02f664d",
            "value": " 3/3 [00:01&lt;00:00,  2.26it/s]"
          }
        },
        "a03e87f36c0240e0afd87ff4ebc334a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfa3fef5ad8743228d10e60238d91449",
              "IPY_MODEL_fd04d23b69a545d4acab01dd3046b44a",
              "IPY_MODEL_f6eac59aef894d88bcae4654df6ef1b2"
            ],
            "layout": "IPY_MODEL_ea4024140d39477884175e9aa9c2f796"
          }
        },
        "a18b3a57972c42e1b061e2ada2c7858e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610680918453400fba82622926af1b56",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_933e94b11adf415abb0b16cad1201e93",
            "value": 0
          }
        },
        "a1d9e240e0064e94a841aab7ffa1f29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b789d00f1b274a09b7658456e8019df9",
            "max": 217158475,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0c1ad987d1940f8af9048e533e62434",
            "value": 217158475
          }
        },
        "a2bbd67afcb9463cb0f78d7a24c5f126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31311fbeb1d49c1a34ce41c4b01c22f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33ab96c585c411ab148d76865b848f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5183ef3eec0d4bdfbcc5544b0fec573b",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3751db7e581847efa6c224dd50c9b7bb",
            "value": 711396
          }
        },
        "a417b74f6fdb4dedbd6bf3408d0dea69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4848184b58645b2a572c6e1a1231f05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51c61ff30d4474080167a38356ca402": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53d537c8c0e48d1a77fbc22e5c41402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02191a5509094a0abcf8862d3a8ee4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_5c69e45579f54fc6b2415ebbad4da477",
            "value": " 570/570 [00:00&lt;00:00, 6.61kB/s]"
          }
        },
        "a587d42c581c4f75984a189ebe1b1831": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5967030d5aa4581b66d319588b92db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6baecbf668bc4a6f93be03e5f671b76a",
              "IPY_MODEL_a33ab96c585c411ab148d76865b848f2",
              "IPY_MODEL_5589d685cbc94ea0a045dcba0e69a7e5"
            ],
            "layout": "IPY_MODEL_01ac22caf29c4b2baf0ebc428f3398b3"
          }
        },
        "a5adffec44744a10b0ac45f73eba6058": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6770d150cfa459780d5adb12fc7c7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78608a4a3a8f4c119d9a0128153a39eb",
              "IPY_MODEL_91de7341a97a4415b5656ee33fe6395f",
              "IPY_MODEL_82f1dc2ca5ef4e45818a2b9107732d58"
            ],
            "layout": "IPY_MODEL_5e1a387877054dacbb6bf1fa32b08d7a"
          }
        },
        "a6f38b1623f14bc9bea9b812f9102fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78c45e4929847f0a635988d1ef9d78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a87f8ff9f575436da0dcf9a31642f7b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94a510c49414b75818b4c1654394703": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a96578d913114e78baf1950b0d7cd998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9f66a8eed1443d099d0fadab83d02e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa099b9c51d6447a9a22fb13b103cb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a6cc127c8c4f03bab0b31bb3a1721b",
              "IPY_MODEL_08fbdead6ab540d4a1d2d8f06879e417",
              "IPY_MODEL_5f0512fb3607471f817b5c215d94e4d8"
            ],
            "layout": "IPY_MODEL_0457dfcb462c4173bbfb7890bb043c97"
          }
        },
        "aad70e180d49469ca01ecfd84eb2225d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aae2a30b7f474dbcbf55aa677b9518f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab4bf3b1267743a8960deeeafcd0fcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f216f345dde54c35abaff30dac041c89",
            "placeholder": "​",
            "style": "IPY_MODEL_e7cd7488f7264496be788107804bc9e8",
            "value": "Downloading data: 100%"
          }
        },
        "ab8bf4aa34c5452d8c6d01df44402eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8df595bb704a599d9abd994aa65691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_516b1796b208442ca32a48c8611b35fe",
              "IPY_MODEL_e8db7bdb8bf04011874e6bb31570d763",
              "IPY_MODEL_6679251fa0b64c59ab34bf7a811e0ae0"
            ],
            "layout": "IPY_MODEL_c03bf64ecd204abab3d1b97eb32e0fdf"
          }
        },
        "ad9c165248ef4e0b9c357316b95f66af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc06005b98c44f0a6308cbd4f6a3527": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "addf3619a835489f8d9f3ce4498daf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adef362bc525401c8b657d33dfec55ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae85f3dd9b864de7897e02a2313c8093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea00ba0feb164981bdb521803fd29049",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16501e0f5de84fc7bbbdcc9b37f61d85",
            "value": 1
          }
        },
        "af00aa1a3bd64be9ad8f4df3e3c5f942": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af678d1c5903451f8b1c1f29b82c273f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_129cece6d8ff4bd9b0137be0486c23e2",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb3e6c6677af4a15b4230a59de58c8fc",
            "value": 384
          }
        },
        "af816340aae74a81a6eaf63a1933f5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afbc002e8eed45b78884f7c4ccd6f37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e779447c8d8e4578bd3a7747941bfbeb",
            "placeholder": "​",
            "style": "IPY_MODEL_928685f89f3e40ddbf9b97a5281bb86f",
            "value": " 109429/0 [00:35&lt;00:00, 4036.36 examples/s]"
          }
        },
        "afc1126d123d40018c1bbf4a8d32ade9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd68f4512e045c2bfaa46eb36d4ab5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f387685057a6405f86292bd9ce5df000",
            "max": 27887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_808dad49922a431d9c43faf48478a069",
            "value": 27887
          }
        },
        "b0546b4b929f4fe3927af49ab119d99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df31cc0682014cdb881817de1c02288f",
            "max": 2877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01fa51a473a6472da89d47bf1116e575",
            "value": 2877
          }
        },
        "b072faf11c504e39939d1ad4534f9112": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb4b68eda9f481abbc7b2456644e16b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c54d6fd6a004ed98c1cb595a0bb84a0",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b076eddbd7a74d5495615776c26a6f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f230ba518eed434fb107f97c66293470",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a7dd0c3112945959e9908425fcaa8b8",
            "value": 384
          }
        },
        "b08eba43d39846869bdd9050836be1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b17a0dd6bd24481e8e597415bfc02c87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34433ff3b52491fb5829b9f1522e162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42f3b105ff645dcb58805289594baad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48bbd953c50443ca2e4b3681909dd94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5641641fc6e4f72b58c505565e16367": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fca62c132b4b9c9af64955480ac905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b645b146bc464646a8eca1b190322cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b65ef6da8ad34e2285813544d00bf3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b5640287e64eaaa8d910072ea8a49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec12f15c6abf453abab53377bc2e9ba7",
              "IPY_MODEL_58221644a9f040cbaf0377564f066623",
              "IPY_MODEL_c0ff005b169d428ba1930ab99f2ad5e2"
            ],
            "layout": "IPY_MODEL_bc918c49557c428da985c29669a4ef59"
          }
        },
        "b6f9c6c1ac8a4eec97466e0f2108ce39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70156e5cb144e75b97697a2439d9a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b719af868833401c86d45d2ae059c868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b789d00f1b274a09b7658456e8019df9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b946e1ad95455b818512986f83f7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b963a45c28d1437f86109f283a370f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b96a361475c947e5a0f9e5f0f867ced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c9ec9890384cb4b17139a7335e371e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adef362bc525401c8b657d33dfec55ce",
            "value": 1
          }
        },
        "ba76516f42224f79a9dfe8a36385bb22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8a7860db844d0e869d8d77c6e18d83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc799bb2e34741fabc79181ea30ee78f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7e0e6c4b154e55875c6fddc0aac6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc918c49557c428da985c29669a4ef59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcee86d4105743f5a69c595029994bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd79d8ce5e28404c988f4965873a2f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc7642ca3e748069974df4a510470ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1034a93ce59f439bb128b6c096eefdf2",
              "IPY_MODEL_4a16335de26a43c09d578cbbe20e98d1",
              "IPY_MODEL_573b3112cbee4ba581c18884df0a269e"
            ],
            "layout": "IPY_MODEL_4fe04dcab6654d0594a56109e7eb6805"
          }
        },
        "be7af49d0afe4ecdaa800be969d5a3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2166426a7a224f1da2065f3221463693",
            "placeholder": "​",
            "style": "IPY_MODEL_77d712d32c0f491cb9a58df33b012b0c",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "bf4d157f4fc041fca5718cdd41e73c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab4bf3b1267743a8960deeeafcd0fcee",
              "IPY_MODEL_ecaeab95cff44076a0a84cca103b6b60",
              "IPY_MODEL_3cfadb1af62b45e1b6cf9f3243a281d5"
            ],
            "layout": "IPY_MODEL_b5641641fc6e4f72b58c505565e16367"
          }
        },
        "c03bdfe1869d45a28466a072aa408ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b987c8b2b449248ff874bc78eb39c5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb402bb1c4e14e859d55089494954a79",
            "value": 231508
          }
        },
        "c03bf64ecd204abab3d1b97eb32e0fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0908ccc452b42e681765c37a139e878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74fd39704b44cea8f012402e7449a80",
            "max": 9815,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5e5dd22e0b24a30a485b54dbdacf1cf",
            "value": 9815
          }
        },
        "c0c1ad987d1940f8af9048e533e62434": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0ff005b169d428ba1930ab99f2ad5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328dedc4b7db45738e274196f66dabc6",
            "placeholder": "​",
            "style": "IPY_MODEL_32d19b7f1d224f9fb2a0f2518c02e5bd",
            "value": " 116M/116M [00:00&lt;00:00, 151MB/s]"
          }
        },
        "c16dd57325504698b35f155d1bd040b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c1ad349038c94c1f9ec7b1d0d7245699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c225230ea12f4f90bd461485f300580e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c226f3cbc6c741749fdd62c73e6800c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba8a7860db844d0e869d8d77c6e18d83",
            "placeholder": "​",
            "style": "IPY_MODEL_9e4b3e23a0d94fbdace001eef383c56a",
            "value": "Downloading data files: 100%"
          }
        },
        "c508e67d54c24888b82b66108681da19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71e718353ac40788febf07676b3cb25",
            "placeholder": "​",
            "style": "IPY_MODEL_addf3619a835489f8d9f3ce4498daf36",
            "value": " 3668/3668 [00:01&lt;00:00, 2844.62 examples/s]"
          }
        },
        "c519b80ce005494caf41456ec90111bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5323c16a9ca4decbe25c651a14517de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5adcad970e4455cbf797f14e2e5303e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f6c046574b4badbf5dac2bd4989d67",
            "placeholder": "​",
            "style": "IPY_MODEL_e844aa942c604f17b61375f59aad56f3",
            "value": "Downloading builder script: 100%"
          }
        },
        "c5fae6b0606d485989a18194ab3a7827": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6b2dc48588b482f80e9a2473dc5b452": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7255329fcf94a7dade2742f7407d41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b56936ebd914109a0d5546c65fff0b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5b92dc1fae394c1f98221dc9762f5779",
            "value": "Generating train split: 100%"
          }
        },
        "c7537c19825a49cd8f3343c153fe56ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d86dc22b0747dba72d6aa5fd899df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7fcfc2727db445695b908ffd3370feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0851189dae4fbdb953f6afe6f3ba29",
            "placeholder": "​",
            "style": "IPY_MODEL_01f4a70e089f4fe5abb0d9246aeee403",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "c86fedd6bd374d4586e51c030cbfea1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c914b0150b114044baff3381de264c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_596c6eda354b45bfa8e02c8359133217",
            "placeholder": "​",
            "style": "IPY_MODEL_b645b146bc464646a8eca1b190322cd2",
            "value": " 217M/217M [00:06&lt;00:00, 32.3MB/s]"
          }
        },
        "c927ee3e4fa84190a00a29aea856bef8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca51f90211e14e13902200d819bfe447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07b52d5502284df5b12b39c47d107310",
              "IPY_MODEL_9cbd7c17733a4b01b8717c98c41ffee4",
              "IPY_MODEL_ce050a2ed895498dba3347c1c4bb092d"
            ],
            "layout": "IPY_MODEL_dbb5a92189d34f4d8571106c29dee036"
          }
        },
        "ca59bd8ff338413c8514ab0eee2d8ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca5cfab63b2d47869f69b772f9801d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafc757655d74a2697f4ba566b3623ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1837578698f426d8c65a40770a3488c",
            "placeholder": "​",
            "style": "IPY_MODEL_fdf37a5ac48c477d99318631238a5756",
            "value": "Generating train split: 100%"
          }
        },
        "cb3e6c6677af4a15b4230a59de58c8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb402bb1c4e14e859d55089494954a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb83a4e946fb4c78b556a06784f8b2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd116c11c9cc4b56ab67ebc8649767bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd748fe04232441abb30f153e54f9890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce050a2ed895498dba3347c1c4bb092d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a94a510c49414b75818b4c1654394703",
            "placeholder": "​",
            "style": "IPY_MODEL_6b62d7166e614b6ead8a0af96758cef1",
            "value": " 116M/116M [00:03&lt;00:00, 41.3MB/s]"
          }
        },
        "cf24681dbccd42f59ffda006ca4cdac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f48649787c3d4f0f8de5d5eb8fdfc31b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca59bd8ff338413c8514ab0eee2d8ec3",
            "value": 1
          }
        },
        "cfa3fef5ad8743228d10e60238d91449": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d276b68035e42d79ec3d6c3600cd125",
            "placeholder": "​",
            "style": "IPY_MODEL_dbe7e052a2994aadac7b883a020cd42f",
            "value": "Downloading data files: 100%"
          }
        },
        "cfa5b162648c4abca773a478c3e3beb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d151de5a1862426f9d3ab2aaae73f4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1837578698f426d8c65a40770a3488c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1dafb9eb15541489d740cbf202fac2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc06005b98c44f0a6308cbd4f6a3527",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eace7bc2187b4dd0af47dbee9327903a",
            "value": 1
          }
        },
        "d25f24f6c4464900af0369a1d34197af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b7f6b62b45464db85df430da2ab97f",
            "placeholder": "​",
            "style": "IPY_MODEL_dda17487487843c7a86152cde6220a6b",
            "value": "Generating train split: "
          }
        },
        "d265db9a419d4edfbdb91e4bd8f78846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a8de725a934927b52792351e0d5099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2f75d5c8f4645b69028fca44c3505e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d365ebcd816a44da80bc74870dd008bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36c80ffd8824fdb8e1e344f41fa3669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d390110fecc7409291f79bc41e3e7c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4214693adb54e44b31fd40e549802b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4ccb21f87954a31ab7ab0fd7e11a8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4ea11ee38044f7cb7ffe1a5b018bda7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6012c2d60024501a1bd8c529bf055e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ccd976679e45fcbf6d6b5d06360ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71e718353ac40788febf07676b3cb25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72812af3cd8475f8a76a8ff3ec236e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74fd39704b44cea8f012402e7449a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87e9ee37dfe44bcad7b97ccfef0f5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ce4959b2bc410a8b455eb2adb7ffc9",
            "placeholder": "​",
            "style": "IPY_MODEL_422ac21cdb1d45a8a0814ef00c9769ff",
            "value": "Downloading readme: 100%"
          }
        },
        "d947bfe9101646c9a7222ada482d4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a90b08aaec44d9962e8c090b8d0baa",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70225a6a843d4ccf87d1b43d4cf1895b",
            "value": 125
          }
        },
        "d9a90b08aaec44d9962e8c090b8d0baa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9bc4736e2dd45d2963cad4ee1700641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9bcbb8cd61d4fa5b9e0b95304f8969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea68f6b18c342938de8be19d3896038",
              "IPY_MODEL_0b0c4175d283414ab014c95269b4421b",
              "IPY_MODEL_00c7829ca16746089c8896865f374b1f"
            ],
            "layout": "IPY_MODEL_f9f77be1c3044483bbd3714a5a45e2ad"
          }
        },
        "da3eb201a16240aaa91baf19b49d4209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab6a9ff832540bfae51a3f0dcfedfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5adcad970e4455cbf797f14e2e5303e",
              "IPY_MODEL_928bc9d9e240469298d2a267fe3b9e65",
              "IPY_MODEL_24e977d511bd4f03bc8d730cd4c86027"
            ],
            "layout": "IPY_MODEL_4b4dae6b5bd5474491e1c86a6e462ebf"
          }
        },
        "dae9d080adfc4bfbba896820bbf57c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "db1f664494c94faf8998df1f25718b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c96dd4ef67f4900af004f322706921f",
            "placeholder": "​",
            "style": "IPY_MODEL_c519b80ce005494caf41456ec90111bf",
            "value": " 27.9k/27.9k [00:00&lt;00:00, 587kB/s]"
          }
        },
        "db7e607a483e49d78b3c9491464490b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ab213f928c43b0a6fb840c03ec05a7",
            "max": 8013769,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_677c94eab4d04efaba8770b32b6e82d5",
            "value": 8013769
          }
        },
        "dbb5a92189d34f4d8571106c29dee036": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbeb2e4f0ca4e3b831fc5f58b883cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "dbe7e052a2994aadac7b883a020cd42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcd68849bd0a44238fbb9bec129b0511": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda17487487843c7a86152cde6220a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de941ef06f9a4974ba4e4075d96d5637": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea6b34486294d388d68aa9ef3aaa281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70156e5cb144e75b97697a2439d9a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_96e7d97dc8f44c7d873060a89f82ce0e",
            "value": " 440M/440M [00:05&lt;00:00, 85.0MB/s]"
          }
        },
        "df31cc0682014cdb881817de1c02288f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8de4914b3f4c51b4e048f053a0e009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df984168f38140c09a952126a0822347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd3f1f64d81471083416a3e4ca6aa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c9ec9890384cb4b17139a7335e371e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2dfbd412e2c4420931223730a476148": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f772d1181b417e8f3bc2feee4f6e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825fb9aa19594a61b2a779837eb230b4",
              "IPY_MODEL_b076eddbd7a74d5495615776c26a6f3e",
              "IPY_MODEL_75d76bf886514ba5ac9fedee0fcfba8d"
            ],
            "layout": "IPY_MODEL_e9685ee9b4aa47fcb5a3a79261ca87c7"
          }
        },
        "e34566724c6e4598860e77d6b710faf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e362a74248d24aa28ab7dd3500c9d303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f66a8eed1443d099d0fadab83d02e9",
            "placeholder": "​",
            "style": "IPY_MODEL_292c0b150eb84f06a012e2084b035350",
            "value": " 1.05M/? [00:00&lt;00:00, 3.55MB/s]"
          }
        },
        "e3712984d7774865be2c1e97faf82d57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b7f6b62b45464db85df430da2ab97f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46716dcab7c4e5f8477931b7e12ea6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76cddc6d7d04d3fb01c11225ec1b6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e779447c8d8e4578bd3a7747941bfbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bd0a23537441b6a41373c7db399423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bdb5cce9c364437970f01220e5f0aa3",
              "IPY_MODEL_5df7aa079833485bbde65e4658b496e0",
              "IPY_MODEL_e9149263e2264fe6b5e5cb50f67d55c2"
            ],
            "layout": "IPY_MODEL_e3712984d7774865be2c1e97faf82d57"
          }
        },
        "e7cd7488f7264496be788107804bc9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84136de295d4d39b44c908ff2458ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e844aa942c604f17b61375f59aad56f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e891d996e42f425cb2b31d563dfc77ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216e1650231e471fa0d88e3d73bf6da0",
              "IPY_MODEL_d1dafb9eb15541489d740cbf202fac2f",
              "IPY_MODEL_e362a74248d24aa28ab7dd3500c9d303"
            ],
            "layout": "IPY_MODEL_1eb78591c14840daaf6741730f2280f8"
          }
        },
        "e8db7bdb8bf04011874e6bb31570d763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31311fbeb1d49c1a34ce41c4b01c22f",
            "max": 61491876,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba6ff0046c843679c0581a44ec69e1c",
            "value": 61491876
          }
        },
        "e8f710e2dcfc40398ce16a4ac265cc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177dee7aa0754c7db2b595f83a4eb105",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe3c4d6e4774be691e7c0551fd334ff",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "e9149263e2264fe6b5e5cb50f67d55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8bf4aa34c5452d8c6d01df44402eea",
            "placeholder": "​",
            "style": "IPY_MODEL_c1ad349038c94c1f9ec7b1d0d7245699",
            "value": " 28.7k/28.7k [00:00&lt;00:00, 559kB/s]"
          }
        },
        "e9685ee9b4aa47fcb5a3a79261ca87c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97d23572a21475fa4b5b9fa4454d4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68db1531b9574e72a2ff0d52995a7347",
            "placeholder": "​",
            "style": "IPY_MODEL_eeafa1a037dd42a88774f76ea6275360",
            "value": " 6.22k/? [00:00&lt;00:00, 91.2kB/s]"
          }
        },
        "e982215023c24a3caf881dd3986cca86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ea00ba0feb164981bdb521803fd29049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ea3b3bc369804d85b562e7b83bc34804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea4024140d39477884175e9aa9c2f796": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eace7bc2187b4dd0af47dbee9327903a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb0aa78ac5ed4e8189871f2dcb7b68d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb77d7017bbd48f6937c38c219acc095": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf0c7ac01e441d68a38cac5fed89d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec12f15c6abf453abab53377bc2e9ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a63b32a25944a0d9b407d8e113cc473",
            "placeholder": "​",
            "style": "IPY_MODEL_39465c30a6d846f2a78d4016152041e4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "ecaeab95cff44076a0a84cca103b6b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc68509c6494c6ebdd22c30ea632bfb",
            "max": 68,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ad09b3ac2d5406caa626954d7dc4b92",
            "value": 68
          }
        },
        "ecf9c5705a7b491c82d4e8b5cbd8c439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeafa1a037dd42a88774f76ea6275360": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef504e4ab1384063bff714e1649e0aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb59704b56142dc82b819e7828ccaf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10d3cde2d7b4121971d8e19e3362b30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f216f345dde54c35abaff30dac041c89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f230ba518eed434fb107f97c66293470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3537b58aca04f398663d6a8f6bd7cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3707c74969e4f6c84d6a36b59d6fa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f511160291e4a4a82f8694772449ea8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91eebca40ce344039704522c4570353c",
            "value": 231508
          }
        },
        "f387685057a6405f86292bd9ce5df000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48649787c3d4f0f8de5d5eb8fdfc31b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f4a51d5c122645a5a58acfbadb0cf752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8631f393c12e4ebaa57838a4f1c1efb0",
            "max": 9832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7e0e6c4b154e55875c6fddc0aac6f0",
            "value": 9832
          }
        },
        "f4bb56cde5b042e8821ee26d25da4ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe8145192c34433b3140f05b5b2528f",
            "placeholder": "​",
            "style": "IPY_MODEL_3988d9e57bc841b49a5079130f071dfc",
            "value": " 296/408 [00:00&lt;00:00, 1064.07 examples/s]"
          }
        },
        "f53073dd81bf427188a9cfde75c18bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b5f6a6687b34036bd5a87c8b61dc2c3",
              "IPY_MODEL_b0546b4b929f4fe3927af49ab119d99a",
              "IPY_MODEL_37e0abc511f04624986368ef45b50131"
            ],
            "layout": "IPY_MODEL_d365ebcd816a44da80bc74870dd008bd"
          }
        },
        "f54be5e820704ad2b31b6b7a6b946181": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5912ed9e9c944e5ae35be20f0634165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a25f48fd7045d092d4b4b1a66f296c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de941ef06f9a4974ba4e4075d96d5637",
            "placeholder": "​",
            "style": "IPY_MODEL_4b242512f1ca473793bf144e5d062a9b",
            "value": " 0/0 [00:00&lt;?, ? examples/s]"
          }
        },
        "f5e5dd22e0b24a30a485b54dbdacf1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f619ea2b062a4eacb80ade328d56c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6823010dba245d1843a2f324e00c382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f68c38cc7bf84db2ab1540ca985599e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f697e928e02f405d99c43c4b1fd890c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5912ed9e9c944e5ae35be20f0634165",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d86dc22b0747dba72d6aa5fd899df0",
            "value": " 1/1 [00:00&lt;00:00, 33.60it/s]"
          }
        },
        "f6a686a076954e0c9c5d11429a14d582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a320f7b8bba47ddb97d2aff966e162f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e215f7f87fc48bfbb3e74c9c97b23a8",
            "value": 3
          }
        },
        "f6c454dc6dcb4528b7b05b83c72640fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6eac59aef894d88bcae4654df6ef1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08187ae67b63489bba4a7b9c10d4d719",
            "placeholder": "​",
            "style": "IPY_MODEL_379f64826a714ae89a85c265b4937902",
            "value": " 1/1 [00:00&lt;00:00,  1.53it/s]"
          }
        },
        "f7ca459667fe48c2a54d0ca13ccfe114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91738a91e20344f1b848ccc39bd0b686",
              "IPY_MODEL_ae85f3dd9b864de7897e02a2313c8093",
              "IPY_MODEL_e97d23572a21475fa4b5b9fa4454d4cc"
            ],
            "layout": "IPY_MODEL_32f65d2703c048929de10720219fdf53"
          }
        },
        "f81a1dd1a8b547b39297478219b41c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f90ae6d8c7e94e7a970a5b50c7721618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12472278f82a48cfb84182a57092617e",
              "IPY_MODEL_28118200f74e4935b8e87af4a20034c8",
              "IPY_MODEL_4fc404853fe84976afd7674ab97d1533"
            ],
            "layout": "IPY_MODEL_4617c5d3e4df42fe8e6d5220c94e443f"
          }
        },
        "f9d88bd9fdda49bcbf01366f8fe6fab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f77be1c3044483bbd3714a5a45e2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fa205a1da88e418a881efb0963042e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb064cacf0e243299a2d092facae8c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7af49d0afe4ecdaa800be969d5a3e7",
              "IPY_MODEL_560c716068a645d596cc2fe9b886c0ad",
              "IPY_MODEL_08c60bb508854cc9b6772ab78502b6fb"
            ],
            "layout": "IPY_MODEL_e84136de295d4d39b44c908ff2458ba9"
          }
        },
        "fc2d3eb4b1304b97bf336245736983ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d798a40b2a24c4f8ce823023d75ea6a",
              "IPY_MODEL_429379eb4c4f452d94a52521911811a8",
              "IPY_MODEL_49a90c227b9342ddbb670c9fe85591cc"
            ],
            "layout": "IPY_MODEL_843d11a2271246f49dbabe80fc4762d4"
          }
        },
        "fc40e712ccca489e8cb2eaadbc47aa54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87e9ee37dfe44bcad7b97ccfef0f5ff",
              "IPY_MODEL_afd68f4512e045c2bfaa46eb36d4ab5a",
              "IPY_MODEL_db1f664494c94faf8998df1f25718b9f"
            ],
            "layout": "IPY_MODEL_63a2424581894ab48ad61b9f38cc882e"
          }
        },
        "fcb506371e6e4cd2947988d6c7050809": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd04d23b69a545d4acab01dd3046b44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01bc3f5cd2ec4435b5a97c1dbbe7a86e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ef185dc852646fbb92d1eb31981bed0",
            "value": 1
          }
        },
        "fdf37a5ac48c477d99318631238a5756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe156388571b4c63b5fc5f5ca857e522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe784053e3d047758731e6f99283d772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff58b4945b004e9996568c228986d287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe8145192c34433b3140f05b5b2528f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}