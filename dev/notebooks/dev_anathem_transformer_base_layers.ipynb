{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faraway1nspace/AnathemTransformer/blob/main/dev/notebooks/dev_anathem_transformer_base_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcFatBIhzdu"
      },
      "source": [
        "## Development Notebook: build and test base layers for Anathem Transformer (aka Silo'd Transformer)\n",
        "\n",
        "### Notes\n",
        "- the google-minature models have the same vocab size and heads as bert-large-ucased\n",
        "- the minature-google papers discusses the classification and distallation tasks & corpus's including:\n",
        "    - *NLI* (Natural language inference involves classifying pairs of sentences (a premise and a hypothesis) as entailment, contradiction, or neutral. This task is representative of the scenario in which proxy data is non-trivial to gather (Gururangan et al., 2018). We chose MNLI (Williams et al., 2018) as our target dataset. Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "    - *sentiment analysis* -\n",
        "- the MTEB leader best model is e5-large (24 layers) which uses the CLS token. It is also \"instruction fine-tuned\", requiring query and passage prefixes.\n",
        "- distillation example: https://github.com/philschmid/knowledge-distillation-transformers-pytorch-sagemaker/blob/master/knowledge-distillation.ipynb\n",
        "    - they set temperature to 2: which results in a flatter probability distribution. I could make this dynamic -> start 0.5 progress to 1\n",
        "    - they set alpha to 0.5, which balances label-loss vs distil-loss\n",
        "\n",
        "#### Loss MLM - hf example:\n",
        "- https://github.com/huggingface/transformers/blob/601ac5b1dc1438f00d09696588f2deb0f045ae3b/src/transformers/modeling_bert.py#L1001-L1004\n",
        "    - notice that when initializing CrossEntropyLoss, the ignore index is -100, so, when I make the masked-token objective, I can compute the loss by masking out all -100?\n",
        "\n",
        "\n",
        "#### DataCollator for Masked MLM - hf example\n",
        "- https://github.com/huggingface/transformers/blob/ee88ae59940fd4b2c8fc119373143d7a1175c651/src/transformers/data/data_collator.py#L607\n",
        "\n",
        "\n",
        "# Dataset specifics\n",
        "\n",
        "### From the Google mini-architectures:\n",
        "- with labels: Williams 2018 (NLI-task): citation: https://aclanthology.org/N18-1101/; available at https://huggingface.co/datasets/multi_nli  \n",
        "    - how should I process these? [sep] or sentence pairs? or both?\n",
        "    - I could do sentence-pairs for teaching & labels, I guess (why not)\n",
        "    - I could also include concatenated text, stricly with labels (what would be the point of this though? Better sub-sectioning the input data, not so much a sentence-vector thing\n",
        "- with no-labels, used for teaching: Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "\n",
        "### 1) MLM Tasks\n",
        "- Pile (multi-domain, books, wiki, law, and more) - curate and remove twitter  \n",
        "    - see urls at: https://github.com/EleutherAI/the-pile/blob/master/the_pile/datasets.py\n",
        "    - https://the-eye.eu/public/AI/pile_preliminary_components/\n",
        "- Supplements to pile:  \n",
        "    - https://huggingface.co/datasets/him1411/EDGAR10-Q - numeric filings\n",
        "    - eloukas/edgar-corpus - annual reports (but it is in weird sections)\n",
        "    - LEDGAR .jsonl https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A - this can be streamed too\n",
        "    - Pile of Law - https://huggingface.co/datasets/pile-of-law/pile-of-law - but cannot be streamed\n",
        "- JanosAudran/financial-reports-sec - SEC financial reports in small sentences\n",
        "- RefinedWeb - a competitor to Pile, curated common-crawl - https://arxiv.org/abs/2306.01116\n",
        "- CNN_dailymail? ag_news?\n",
        "\n",
        "### A) Retrieval Tasks\n",
        "In general, what loss would I use for the QA & retrieval tasks? Distillation is obvious, but what about\n",
        "- SQUAD - has QA pairs - squad_v2\n",
        "    - good for distillation\n",
        "- ORCA - has GPT-like prompting QA pairs: https://huggingface.co/datasets/Open-Orca/OpenOrca/viewer/Open-Orca--OpenOrca/train?row=29\n",
        "- Simple-Wiki https://huggingface.co/datasets/embedding-data/simple-wiki - has paraphrases\n",
        "- embedding-data/coco_captions_quintets - multiple captions as paraphrases\n",
        "- embedding-data/simple-wiki - pairs of paraphrases from wikipedia\n",
        "- embedding-data/SPECTER - triplets of {anchor, pos, neg}, small headline-like snippets in technical /statistical /science fields\n",
        "- https://huggingface.co/embedding-data - has a lot of retrieval tasks\n",
        "- LLukas22/scidocs - titles and abstracts\n",
        "- LEDGAR - can possible do triplets on same label\n",
        "- Rahmaa/ElsevieR_ClEaN - possible relation between title and abstract\n",
        "- embedding-data/WikiAnswers - 25 question paraphrases (maybe no answers)\n",
        "\n",
        "### B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- LLukas22/lfqa_preprocessed - question and answers 226k\n",
        "- gbharti/finance-alpaca (like FIQA - finance Q&A)\n",
        "- embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- sciq - science questions - see question and support\n",
        "- wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers\n",
        "- EnglishDictionary - auto convert \"What is the definition of X'?\n",
        "\n",
        "## C) NER tasks\n",
        "- tner/ontonotes5 - has > 12 entities and 59.9k\n",
        "- tner/multinerd - 23 entiteis and 157k test set - see also tner/wikineural which has a 98.8k training set?\n",
        "-\n",
        "\n",
        "\n",
        "# Teacher Models\n",
        "\n",
        "## Embeddings\n",
        "Mteb leaderboard\n",
        "\n",
        "- instructor-xl / large - this does best, but it prepends instructions that are domain specific (like science this, or wikipedia that.... it could be possible to do that with the Pile dataset, possible) https://huggingface.co/hkunlp/instructor-xl\n",
        "- https://huggingface.co/intfloat/e5-large-v2 - winner otherwise\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6mZMauZ9KW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XS2jBKoMmMn"
      },
      "source": [
        "#### Playing Around with novel architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQy_iTw-1g8O",
        "outputId": "5defd8d5-5d2f-4593-f218-b29203825df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=5aa22ed39e3ce4e5222cff25705be123fe999c3d6f64822eea54c79e2e16273a\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, rank_bm25, langdetect, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 langdetect-1.0.9 multiprocess-0.70.15 rank_bm25-0.2.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0 xxhash-3.3.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25 langdetect\n",
        "#%pip install langdetect\n",
        "from langdetect import detect\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "bCv855u5Mlgr",
        "outputId": "1d562d9e-05a3-405e-fffa-e6301d59a2e2"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5f5cdcd6a5ec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataSet' from 'torch.utils.data' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, DataSet\n",
        "from typing import List, Optional\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "\n",
        "model_string = 'google/bert_uncased_L-12_H-512_A-8' # 'distilroberta-base\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "basemod = AutoModel.from_pretrained(model_string)\n",
        "basemod.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tNKrJaiXDvA"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "eNfU7szJWwfh",
        "outputId": "afd7de82-dcac-45b0-f9a1-4b874b1f529b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-761fa45d06d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomTokenizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google/bert_uncased_L-12_H-512_A-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cls_prepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, model_string='google/bert_uncased_L-12_H-512_A-8', n_cls_prepend = 4, n_pad_to_multiple_of=4):\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not (k[0]=='_' or k=='tokenize' or k=='encode' or k=='build_inputs_with_special_tokens' or k == 'batch_encode_plus'):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "\n",
        "        # run through base tokenizer\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens, return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        #batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "\n",
        "\n",
        "# Note, if I use the vanilla LineByLineTextDataset, it just calls tokenizer.__call__ turns on the `use_special_tokens`, and it pads to a multiple of optional\n",
        "# .. so somehow I need to ensure that, whatever base function it calls as part of the tokenizer pipeline, it will continue using MY new function\n",
        "# the tokenizer.__call__ DOES NOT use `encode` nor `tokenize` otherwise my modifications would manifest\n",
        "# looks like `prepare_for_model` (and maybe `batch_prepare_for_model`) is what adds special tokens?\n",
        "# looks like `prepare_for_model` just calls `build_inputs_with_special_tokens`, so maybe intervene there?\n",
        "#         if add_special_tokens:\n",
        "#            sequence = self.build_inputs_with_special_tokens(ids, pair_ids)\n",
        "#            token_type_ids = self.create_token_type_ids_from_sequences(ids, pair_ids)\n",
        "# editing `build_inputs_with_special_tokens` didn't work either\n",
        "\n",
        "# FOOFU:\n",
        "# see how .pad works: https://github.com/huggingface/transformers/blob/c5454eba9eac00a3e7d0a46a3d25aacd43187f1e/src/transformers/tokenization_utils_base.py#L2887\n",
        "# notice the `self.model_input_names[0]` list for a tokenizer -> I should update this for my unique inputs\n",
        "# ... and there is also a ._pad function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te7PvCnbvX-E"
      },
      "outputs": [],
      "source": [
        "tokenizer2 = CustomTokenizer()\n",
        "tokenizer2.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjHCfFlda8w"
      },
      "outputs": [],
      "source": [
        "#toks = tokenizer2.encode(text[0], add_special_tokens=True)\n",
        "#print(len(toks)) # works\n",
        "#print(toks[:10])\n",
        "\n",
        "tokens = tokenizer2(text, padding='longest', return_tensors=None) # doesn't work, obviously\n",
        "#print(tokens)\n",
        "print(len(tokens['input_ids'][0]))\n",
        "print(len(tokens['attention_mask'][0]))\n",
        "\n",
        "print(len(tokens['input_ids'][1]))\n",
        "print(len(tokens['attention_mask'][1]))\n",
        "\n",
        "tokens\n",
        "\n",
        "#tokenizer2.batch_encode_plus(text, add_special_tokens=True) # doesn't work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo5BhFq0kuJH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DToaqxfoM6bR"
      },
      "outputs": [],
      "source": [
        "dir(basemod)\n",
        "# base embedding layers\n",
        "layer_emb = copy.deepcopy(basemod._modules['embeddings'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha_xqtWlNIfI"
      },
      "outputs": [],
      "source": [
        "# base trasnformers (full)\n",
        "layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9OMlauFNTPZ"
      },
      "outputs": [],
      "source": [
        "# text\n",
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with legal issues1.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, willful misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "import math\n",
        "\n",
        "#padding_length = int(math.ceil(max_length / 4)) * 4\n",
        "tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "input_shape = tokens['input_ids'].size()\n",
        "\n",
        "# change token padding to be multiple of 4\n",
        "#ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "#if input_shape[-1]!=ideal_length:\n",
        "#  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "#  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "tokens['token_type_ids'] = token_type_ids\n",
        "past_key_values_length =0\n",
        "\n",
        "# need to extend attention mask\n",
        "extended_attention_mask = basemod.get_extended_attention_mask(tokens['attention_mask'], input_shape)\n",
        "tokens['extended_attention_mask'] = extended_attention_mask\n",
        "print(tokens.keys())\n",
        "print(tokens['input_ids'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4DF2F2y3WVs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIisgmAC3SgY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_PXX-SRjd7Mv",
        "outputId": "9be41735-2875-4ac5-ee8e-d0be3fbf3a2b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c65df7c427ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m silo_dimensions = {0:basemod.config.hidden_size,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   }\n\u001b[1;32m      5\u001b[0m \u001b[0mreintegration_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'basemod' is not defined"
          ]
        }
      ],
      "source": [
        "silo_dimensions = {0:basemod.config.hidden_size,\n",
        "                  1:basemod.config.hidden_size//2,\n",
        "                  2:basemod.config.hidden_size//4,\n",
        "                  }\n",
        "reintegration_dim = silo_dimensions[1] + silo_dimensions[2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XuMY6iaRNpOc",
        "outputId": "a9e272e9-2e80-4b29-dc62-536f42bd1334"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-40b0ed09dca5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_output = layer_emb(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'position_ids'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_emb' is not defined"
          ]
        }
      ],
      "source": [
        "embedding_output = layer_emb(\n",
        "            input_ids=tokens['input_ids'],\n",
        "            position_ids=tokens.get('position_ids',None),\n",
        "            token_type_ids=tokens['token_type_ids'],\n",
        "            inputs_embeds=None,\n",
        "            past_key_values_length=past_key_values_length\n",
        ")\n",
        "print(embedding_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3kgUzTJsO_1i",
        "outputId": "5d16b103-4d99-40de-8c0c-039faefd0e64"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-40a2b2d12b51>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# basemodel transformer outputs: *full bert model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m out_l1 = layer_basetransformer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extended_attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#tokens['attention_mask'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_basetransformer' is not defined"
          ]
        }
      ],
      "source": [
        "# basemodel transformer outputs: *full bert model\n",
        "out_l1 = layer_basetransformer(\n",
        "    hidden_states = embedding_output,\n",
        "    attention_mask = tokens['extended_attention_mask'],#tokens['attention_mask'],\n",
        "    head_mask=None,\n",
        "    encoder_hidden_states=None,\n",
        "    encoder_attention_mask=None,\n",
        "    #past_key_values=0,\n",
        "    #use_cache=None,\n",
        "    output_attentions=True,\n",
        "    #output_hidden_states=True,\n",
        "    #return_dict=True\n",
        ")\n",
        "\n",
        "hidden_states_l1 = out_l1[0]\n",
        "self_attention_l1 = out_l1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvj_XlNsTYXt"
      },
      "outputs": [],
      "source": [
        "# Next Layer:\n",
        "# Query -> max pool and reduce  hidden dimension // 2\n",
        "# Key -> reduce hidden_dim // 2\n",
        "# value -> reduce hidden_dim //2\n",
        "#maxpool_l2 = nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "maxpool_l2 = nn.Sequential(\n",
        "    nn.Dropout(0.05),\n",
        "    nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True),\n",
        ")\n",
        "\n",
        "maxpool_l2_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ5xAaELVuwk",
        "outputId": "b5dbf2f4-277d-4b55-97ac-0453fed2908d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n",
            "torch.Size([2, 24, 768])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 48])\n",
            "torch.Size([2, 1, 1, 48])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "# reduce dimension of hidden states\n",
        "hiddens_states_l1_reduced = maxpool_l2(hidden_states_l1)\n",
        "print(hidden_states_l1.shape)\n",
        "print(hiddens_states_l1_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l1_reduced = maxpool_l2_attn(tokens['attention_mask'].float())\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "print(input_shape)\n",
        "extended_attention_mask_l1_reduced = basemod.get_extended_attention_mask(attention_mask_l1_reduced, attention_mask_l1_reduced.shape)\n",
        "print(tokens['extended_attention_mask'].shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AcdIY3shHWN"
      },
      "outputs": [],
      "source": [
        "# Try to do Multi Headed attenion with differently sized query and value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYHtEQNFgh7U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "import copy\n",
        "\n",
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "bertlayer_l2_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")\n",
        "\n",
        "bertlayer_l3_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size // 2,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03mPp6aHgh9Y",
        "outputId": "e19aaf75-0247-498f-d967-2777f6f6df2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2 = bertlayer_l2_reduction(\n",
        "        hidden_states = hiddens_states_l1_reduced,\n",
        "        attention_mask = extended_attention_mask_l1_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l1,\n",
        "        encoder_attention_mask= tokens['extended_attention_mask'],\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "hidden_states_l2 = out_l2[0]\n",
        "print(hidden_states_l2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlN5aOsYgh_z",
        "outputId": "29b499c5-25ab-4dfb-de8e-ffc76c316e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12])\n",
            "torch.Size([2, 1, 1, 12])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Next dimension reduction:\n",
        "hiddens_states_l2_reduced = maxpool_l2(hidden_states_l2)\n",
        "print(hidden_states_l2.shape)\n",
        "print(hiddens_states_l2_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l2_reduced = maxpool_l2_attn(attention_mask_l1_reduced.float())\n",
        "print(attention_mask_l2_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "extended_attention_mask_l2_reduced = basemod.get_extended_attention_mask(attention_mask_l2_reduced, attention_mask_l2_reduced.shape)\n",
        "print(extended_attention_mask_l2_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  out_l3 = bertlayer_l3_reduction(\n",
        "        hidden_states = hiddens_states_l2_reduced, # input has been maxpooled\n",
        "        attention_mask = extended_attention_mask_l2_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l2,\n",
        "        encoder_attention_mask= extended_attention_mask_l1_reduced,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "  hidden_states_l3 = out_l3[0]\n",
        "  print(hidden_states_l3.shape)\n",
        "\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q-GTg2fgiCB",
        "outputId": "c44f4175-70a0-4e38-e774-ee10df37de88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"_name_or_path\": \"distilroberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.29.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "\n",
        "config_lowres_encoder = copy.deepcopy(basemod.config)\n",
        "config_lowres_encoder.hidden_size = config_lowres_encoder.hidden_size//4\n",
        "config_lowres_encoder.num_hidden_layers = 3\n",
        "print(config_lowres_encoder)\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "encoder_lowres = BertEncoder(config_lowres_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIN07S24_qp",
        "outputId": "bd44c178-932e-4c56-bfc8-56363ef9bff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "out_encoder_lowres = encoder_lowres(\n",
        "    hidden_states=hidden_states_l3,\n",
        "    attention_mask=extended_attention_mask_l2_reduced,\n",
        "    head_mask = None,\n",
        "    return_dict=True,\n",
        ")\n",
        "hidden_states_lowres = out_encoder_lowres[0]\n",
        "print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM75xap8L5cB"
      },
      "outputs": [],
      "source": [
        "## Upresolution Layer: up-resolution from dim-3 to dim-2 is as follows:\n",
        "# hs_l3 -> upsampled sequence-length as hs-l2\n",
        "# -> could have another attention-based mechanism that expands dimension of hs-l2\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "#hidden_states_upscaled_3to2_nearest = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='nearest').transpose(-2,-1)\n",
        "#hidden_states_upscaled_3to2_linear = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='linear').transpose(-2,-1)\n",
        "\n",
        "upscaler_x2 = InterpolateCombo(scale_factor=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfpn9mEsPPCf"
      },
      "outputs": [],
      "source": [
        "hidden_states_upscaled3to2 = upscaler_x2(hidden_states_lowres)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GXB-9waPBv_"
      },
      "outputs": [],
      "source": [
        "## BertAttentiveIntegrator\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edzAlaOIPDa5"
      },
      "outputs": [],
      "source": [
        "bertlayer_l3_to_l2_crossattn = BertCrossAttention(\n",
        "        config=basemod.config,\n",
        "        hidden_size=silo_dimensions[1],\n",
        "        hidden_size_query=silo_dimensions[2],\n",
        "        position_embedding_type=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMmeXSBoipPv",
        "outputId": "ffce4e9c-101b-4d90-c31e-ea81ce0828be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 192])\n",
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "print(hidden_states_upscaled3to2.shape)\n",
        "print(hidden_states_l2.shape)\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVMll5RTQyVh",
        "outputId": "5ac82f6c-dd52-4295-9534-159d0dd26ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2_postencode = bertlayer_l3_to_l2_crossattn(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "hidden_states_l2_postencode = out_l2_postencode[0]\n",
        "print(hidden_states_l2_postencode.shape)\n",
        "assert hidden_states_l2_postencode.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5HD6Rc7POU",
        "outputId": "17ff76a1-827c-4945-9ae6-92535113b493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n",
            "3072\n",
            "4.0\n"
          ]
        }
      ],
      "source": [
        "print(basemod.config.hidden_size)\n",
        "print(basemod.config.intermediate_size)\n",
        "print(basemod.config.intermediate_size/basemod.config.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_ElURFHWk3B"
      },
      "outputs": [],
      "source": [
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = query_hidden_states,\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeJysFTAgZm_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from low-res to mid-res\n",
        "bert_integrative_layer_midres = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[2],\n",
        "    intermediate_size=silo_dimensions[1]*4,\n",
        ")\n",
        "\n",
        "# from mid-res to high-res\n",
        "bert_integrative_layer_hires = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[0],\n",
        "    hidden_size_query=reintegration_dim,\n",
        "    intermediate_size=silo_dimensions[0]*4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcZ3MU-4hFN3",
        "outputId": "c521b9fe-1ccc-4e49-d8df-75f4801f795b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "hidden_states_midres = bert_integrative_layer_midres(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "print(hidden_states_midres.shape)\n",
        "assert hidden_states_midres.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iavtqpUohJAs",
        "outputId": "272bdcee-3341-41ea-bd80-87a1b6d0fe8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 576])\n"
          ]
        }
      ],
      "source": [
        "# upscale the l2 and l3 to the full dimension\n",
        "upscaler_x4 = InterpolateCombo(scale_factor=4)\n",
        "hidden_states_upscaled3to1 = upscaler_x4(hidden_states_lowres)\n",
        "hidden_states_upscaled2to1 = upscaler_x2(hidden_states_midres)\n",
        "\n",
        "hidden_states_upscaled = torch.cat(\n",
        "    (hidden_states_upscaled2to1, hidden_states_upscaled3to1),\n",
        "    axis=2)\n",
        "\n",
        "print(hidden_states_upscaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gDwXueYhJ1B",
        "outputId": "ed02eb22-18ea-4bce-91b2-bfc5ccf3ccd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n"
          ]
        }
      ],
      "source": [
        "# final layer to bring it up to full dimension\n",
        "hidden_states_hires = bert_integrative_layer_hires(\n",
        "    hidden_states = hidden_states_l1,\n",
        "    attention_mask = extended_attention_mask,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled,\n",
        "    query_attention_mask = extended_attention_mask\n",
        ")\n",
        "print(hidden_states_hires.shape)\n",
        "assert hidden_states_hires.shape == hidden_states_l1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv4ZVcYORoL_",
        "outputId": "df6aca9a-68c3-4cc4-c579-7fa0e8518c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_states_hires.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJQJVvdMle3v",
        "outputId": "3e4830ce-7b1c-4d9b-c584-947339137ee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 24])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_mask_l1_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Z0KGMfm-Mn"
      },
      "source": [
        "### The Reduce and Integrate layer:\n",
        "- this is like a Transformer block, but:\n",
        "- does dimension reduction along sequence and embedding-dim\n",
        "- includes a skip connection from previous hidden-states of the same dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExGOdKwWm_46"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# this is the layer that just does cross-attention between a seq-reduced query and full-size value and key\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "\n",
        "BertReduceAddIntegrativeLayer\n",
        "inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkiZo9Npm_xi"
      },
      "outputs": [],
      "source": [
        "# initialize the mid-resolution BertReduceAndIntegrate layer\n",
        "bert_reduce_add_integrate_midres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[1], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[0],\n",
        "    hidden_size_query=silo_dimensions[0],\n",
        "    intermediate_size=silo_dimensions[1]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")\n",
        "\n",
        "bert_reduce_add_integrate_lowres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[2], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[1],\n",
        "    intermediate_size=silo_dimensions[2]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxtTomiPxQn8",
        "outputId": "0d221d7e-a51b-4a93-af5f-a7f23af07e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_hires_reduced = maxpool_l2(hidden_states_hires)\n",
        "assert hidden_states_hires_reduced.shape[1] == hidden_states_midres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres.shape)\n",
        "hidden_states_midres = bert_reduce_add_integrate_midres(\n",
        "    inputs = hidden_states_hires, # from highres outputs previous layer (key, values)\n",
        "    hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask=None,\n",
        "    query_hidden_states = hidden_states_hires_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        ")\n",
        "print(hidden_states_midres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPGNtX3KxQuY",
        "outputId": "9a5d53a5-acf3-4255-b624-7aa38bf0ad9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12, 192])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_midres_reduced = maxpool_l2(hidden_states_midres)\n",
        "assert hidden_states_midres_reduced.shape[1] == hidden_states_lowres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  print(hidden_states_lowres.shape)\n",
        "  hidden_states_lowres = bert_reduce_add_integrate_lowres(\n",
        "      inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "      hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "      attention_mask = extended_attention_mask_l2_reduced,\n",
        "      head_mask=None,\n",
        "      query_hidden_states = hidden_states_midres_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        "  )\n",
        "  print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFdByXbYAz2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJAHT_SyxQwK"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from transformers.modeling_utiles import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQPJPPkpmibK"
      },
      "source": [
        "### Base-Layer nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbBLQZJJlu6n"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 2, # number of transformer stacks\n",
        "    scale_ratio2 = 0.5, # reduce sequence-length by X, from high-res to mid-res\n",
        "    scale_ratio3 = 0.25, # reduce sequence-length by Y, from high-res to low-res\n",
        "    multipler_intermediate2 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    multipler_intermediate3 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05, # dropout when performing downscaling from one-sequence length to next\n",
        "    use_cheap_integrator_for_stacks = [],\n",
        "    do_mlm=False,# whether to output MLM token predictions\n",
        "    do_cls=False,# whether to output a pooled sentence-vector for sequence classification\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config,'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks',num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multipler_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multipler_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", use_cheap_integrator_for_stacks)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        # cheap (non-transformer) method to integrate high- and mid-res hidden states\n",
        "        bert_integrative_layer_1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        # full Transformer layer as mid-to-highres upscaling\n",
        "        BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1//2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    bert_integrative_layer_1 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size,\n",
        "        hidden_size_query=config.query_size1,\n",
        "        intermediate_size=config.intermediate_size_l1\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_l1\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"attention\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled3to2        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_highres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_highres\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "class BertClassificationHead(nn.Module):\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "def tokenize_anathem(text, device=device):\n",
        "    #padding_length = int(math.ceil(max_length / 4)) *\n",
        "    tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "    input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    # change token padding to be multiple of 4\n",
        "    #ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "    #if input_shape[-1]!=ideal_length:\n",
        "    #  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "    #  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "    tokens['token_type_ids'] = token_type_ids\n",
        "    for k,v in tokens.items():\n",
        "        tokens[k] = v.to(device)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdRq7bM3pQhp",
        "outputId": "452ade89-f3b4-4404-ab8f-8442de7689bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#config = make_config('distilroberta-base')\n",
        "#config = make_config('t5-small') # can't use t5 because it uses relative\n",
        "config = make_config('google/bert_uncased_L-12_H-512_A-8') #\n",
        "\n",
        "if False:\n",
        "  (tokenizer,basemod,layer_embedding,layer_basetransformer,maxpool,maxpool_attn,bert_reducer_l2,\n",
        "   bert_reducer_l3,bert_encoder_lowres,upscaler_x2,upscaler_x4,bert_integrative_layer_2,bert_integrative_layer_1) = initialize(config)\n",
        "\n",
        "# make the basemod and tokenizer\n",
        "basemod = AutoModel.from_pretrained(config.model_string)\n",
        "basemod.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgEOUtHYoB-I"
      },
      "outputs": [],
      "source": [
        "# the Anathem encoder includes the embeddings and first transformer block\n",
        "anathem_encoder1 = AnathemBaseModule(config, basemod, tokenizer)\n",
        "anathem_encoder2 = AnathemMidModule(config, basemod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87RTY9a059mQ"
      },
      "outputs": [],
      "source": [
        "cls_head = BertClassificationHead(config, n_classes = 3, activation = 'none',device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-1aZOdgB_g8"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"* Welcome home to this gorgeously upgraded, beautifully maintained, three-bedroom home with double attached garage. Drive up to this quiet cul-de-sac and let the experience begin. On the main floor, you’ll notice the abundance of natural light. There is a separate office with view over the front of the property. The layout was customized, with a great open living space. The kitchen is a chef’s dream, with a breakfast bar, granite countertops, stainless steel appliance package, a pantry, and a view out to the sunny west facing yard.\",\n",
        "    \"There’s room for formal dining and the family room has a gas fireplace to relax by on the cooler nights. Out back, there’s a stunner of a deck, perfect for BBQ season! Upstairs, you’ll find a massive bonus room with tons of windows. There are two, secondary bedrooms and the master suite is amazing\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbt_zlrlCVEU"
      },
      "outputs": [],
      "source": [
        "tokens = tokenize_anathem(text,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XpXyV6YW4DI",
        "outputId": "6e4777a3-d95c-48ce-d799-2b761e72213c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#stack 1\n",
        "out1 = anathem_encoder1(\n",
        "      input_ids = tokens['input_ids'],\n",
        "      attention_mask = tokens['attention_mask'],\n",
        "      token_type_ids = tokens['token_type_ids']\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A87nQ24Ccoh",
        "outputId": "bbf75272-c1db-4da1-9543-acfe3832812b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.8376, -0.3891, -0.6668],\n",
              "        [-0.8747, -0.3621, -0.7735]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stack2\n",
        "out2 = anathem_encoder2(\n",
        "      hidden_states_highres = hidden_states[0],\n",
        "      hidden_states_midres = hidden_states[1],\n",
        "      hidden_states_lowres = hidden_states[2],\n",
        "      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out2\n",
        "\n",
        "cls_head(hidden_states[0], tokens['attention_mask'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQ9ABhkU8pE",
        "outputId": "76b0b2cb-196f-44c5-9079-4b9992a9835d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out1[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBi1G7ay63nr"
      },
      "outputs": [],
      "source": [
        "####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2L-jYJ6u4qd"
      },
      "outputs": [],
      "source": [
        "## Next steps, do something simple like sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLHCo5vZ-brJ"
      },
      "outputs": [],
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from scipy.special import softmax\n",
        "#datasets_list = list_datasets()\n",
        "#[k for k in datasets_list if 'phrasebank' in k]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "04db53bae1ea4e81a1acbad7401cd331",
            "81afc2262c8545dab41aacde91066b7d",
            "b96a361475c947e5a0f9e5f0f867ced7",
            "f697e928e02f405d99c43c4b1fd890c9",
            "6da885f236a24cf5a09add7c9927db76",
            "638f36ef35ec4ec88ba057c63093eca2",
            "4b35ff0e35ca4e6088f2f1f687ff924c",
            "e1c9ec9890384cb4b17139a7335e371e",
            "adef362bc525401c8b657d33dfec55ce",
            "f5912ed9e9c944e5ae35be20f0634165",
            "c7d86dc22b0747dba72d6aa5fd899df0"
          ]
        },
        "id": "rvjAv19p1Un6",
        "outputId": "a84e2ae7-d09e-49f8-b454-00f8c494fd17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset financial_phrasebank (/root/.cache/huggingface/datasets/financial_phrasebank/sentences_75agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04db53bae1ea4e81a1acbad7401cd331",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#[k for k in datasets_list if 'phrasebank' in k]\n",
        "\n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_75agree')\n",
        "\n",
        "# split\n",
        "idx_train, idx_val = train_test_split(np.arange(len(dataset['train']['sentence'])), test_size=0.1)\n",
        "dataset_train = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]}  for idx in idx_train]\n",
        "dataset_val = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]} for idx in idx_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_fRokuwB1h9",
        "outputId": "cbbc64cc-0bad-42bd-987c-aec7460b3960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3107\n",
            "346\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset_train)); print(len(dataset_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B86BY_m_x12"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"torch dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.data = dataset\n",
        "        self.n = len(self.data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        unit = self.data[idx]\n",
        "        return unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh3NKKrZ_xuX"
      },
      "outputs": [],
      "source": [
        "ds_train = MyDataset(dataset_train)\n",
        "ds_val = MyDataset(dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn4rR8QqEiS3"
      },
      "outputs": [],
      "source": [
        "batch_size_train = 12\n",
        "batch_size_val = 36\n",
        "lr = 0.00005\n",
        "eval_iter = 20\n",
        "n_epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9JPB6miBpQ9"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(ds_train, batch_size=batch_size_train, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=batch_size_val, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbhvjxbeKHh9"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(list(anathem_encoder1.parameters()) + list(anathem_encoder2.parameters()) + list(cls_head.parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "fPmQOT5OEnEY",
        "outputId": "cd172411-6a85-4bce-f076-9d03d8dc276f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:19: f1:0.402 (0.000); prec:0.352 (0.000); rec:0.469 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:39: f1:0.326 (0.000); prec:0.400 (0.000); rec:0.372 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:59: f1:0.459 (0.158); prec:0.531 (0.405); rec:0.485 (0.095)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:79: f1:0.506 (0.305); prec:0.583 (0.450); rec:0.494 (0.231)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:99: f1:0.499 (0.190); prec:0.555 (0.383); rec:0.551 (0.116)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:119: f1:0.552 (0.280); prec:0.663 (0.568); rec:0.534 (0.179)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:139: f1:0.661 (0.469); prec:0.708 (0.600); rec:0.636 (0.385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-d95d13a5603a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "optimizer.zero_grad()\n",
        "anathem_encoder1.train()\n",
        "anathem_encoder2.train()\n",
        "cls_head.train()\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "\n",
        "      # tokenize the batch\n",
        "      tokens = tokenize_anathem(batch['text'],device)\n",
        "      target = batch['label'].to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      out1 = anathem_encoder1(\n",
        "        input_ids = tokens['input_ids'],\n",
        "        attention_mask = tokens['attention_mask'],\n",
        "        token_type_ids = tokens['token_type_ids']\n",
        "      )\n",
        "      (hidden_states, extended_attention_masks) = out1\n",
        "\n",
        "      features,_ = anathem_encoder2(\n",
        "          hidden_states_highres = hidden_states[0],\n",
        "          hidden_states_midres = hidden_states[1],\n",
        "          hidden_states_lowres = hidden_states[2],\n",
        "          extended_attention_mask_highres = extended_attention_masks[0],\n",
        "          extended_attention_mask_midres = extended_attention_masks[1],\n",
        "          extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "      )\n",
        "\n",
        "      # prediction\n",
        "      preds = cls_head(features[0], tokens['attention_mask'])\n",
        "\n",
        "      # loss\n",
        "      loss = nn.functional.cross_entropy(preds, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # do evaluation\n",
        "      if ((iteration+1) % eval_iter)==0:\n",
        "          anathem_encoder1.eval()\n",
        "          anathem_encoder2.eval()\n",
        "          cls_head.eval()\n",
        "          # tokenize the eval\n",
        "          eval_logits = []\n",
        "          eval_targets = []\n",
        "          for i, batch_eval in enumerate(tqdm(dl_val, disable=True)):\n",
        "              with torch.no_grad():\n",
        "                  # tokenize the batch\n",
        "                  tokens_eval = tokenize_anathem(batch_eval['text'], device)\n",
        "                  labels_eval = batch_eval['label'].to(device)\n",
        "                  out_eval1 = anathem_encoder1(\n",
        "                      input_ids = tokens_eval['input_ids'],\n",
        "                      attention_mask = tokens_eval['attention_mask'],\n",
        "                      token_type_ids = tokens_eval['token_type_ids']\n",
        "                  )\n",
        "                  (hidden_states, extended_attention_masks) = out_eval1\n",
        "                  features,_ = anathem_encoder2(\n",
        "                      hidden_states_highres = hidden_states[0],\n",
        "                      hidden_states_midres = hidden_states[1],\n",
        "                      hidden_states_lowres = hidden_states[2],\n",
        "                      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "                  )\n",
        "                  # prediction\n",
        "                  batch_logits = cls_head(features[0], tokens_eval['attention_mask'])\n",
        "                  eval_logits+=batch_logits.detach().tolist()\n",
        "                  eval_targets+=labels_eval.detach().tolist()\n",
        "\n",
        "          eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)\n",
        "          print('E:%d; i:%d: f1:%0.3f (%0.3f); prec:%0.3f (%0.3f); rec:%0.3f (%0.3f)' % (epoch, iteration, eval_f1.mean(), eval_f1.min(), eval_prec.mean(), eval_prec.min(), eval_recall.mean(), eval_recall.min()))\n",
        "          cls_head.train()\n",
        "          anathem_encoder1.train()\n",
        "          anathem_encoder2.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVZ7tZ7JYSO",
        "outputId": "60a71e09-6d52-49f5-f42d-bf6cb36c9d2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZugKHbocDR0"
      },
      "source": [
        "## Test performance speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chS7dYV4cA2a",
        "outputId": "97dccd81-d967-42a4-de00-278241cc1dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for anathem: 33283328\n"
          ]
        }
      ],
      "source": [
        "# how many parameters in the model in total\n",
        "from math import prod\n",
        "nparam = 0\n",
        "for encoder in [anathem_encoder1, anathem_encoder2]:\n",
        "    for na,l in encoder.named_parameters():\n",
        "        nparam+=prod(l.data.shape)\n",
        "print('Number of parameters for anathem: %d' % nparam)\n",
        "# 33676544"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOKuhoSQgN28",
        "outputId": "118fbf58-b22a-4e63-ee9a-b5382eba30f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# compare this to distilbert\n",
        "#other_mod = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "other_mod = AutoModel.from_pretrained('google/bert_uncased_L-12_H-512_A-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNPeFA5gg-3u",
        "outputId": "c58db76c-2e88-4cf8-d1e1-ddc3ee70b194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for other-mod: 53982720\n"
          ]
        }
      ],
      "source": [
        "nparam = 0\n",
        "for na,l in other_mod.named_parameters():\n",
        "    nparam+=prod(l.data.shape)\n",
        "\n",
        "print('Number of parameters for other-mod: %d' % nparam)\n",
        "\n",
        "# number of parameters for anathem-trans: 33676544 (google/bert_uncased_L-12_H-512_A-8)\n",
        "# number of parametres for anathem-trans: 78973824 (includng 2 more mid-res encoders)\n",
        "# number of parameters for anathem-trans: 73062528 (with a 768 dimension)\n",
        "# Number of parameters for distilroberta: 82118400 (with a 768 dimension)\n",
        "# Number of parameters  all-MiniLM-L6-v2: 22713216\n",
        "# Number of parameters google/bert_uncased_L-12_H-512_A-8: 53982720 (512 dim, 12L)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En8rgr4mSNBt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIeQesGRSOKl"
      },
      "source": [
        "## Test Performance Speed at inference (CPU)\n",
        "- distilroberta-base: 10 batches: 23.517s , CPU\n",
        "- oogle/bert_uncased_L-12_H-512_A-8: 10 batches: 12.44s, CPU\n",
        "- anathem (distilroberta-768): 10 batches, 23.23s,\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 10 batches, ~7.5s, CPU\n",
        "\n",
        "## Test Performance Speed at inference (GPU)\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 30 batches, 0.79s, GPU\n",
        "- google/bert_uncased_L-12_H-512_A-8: 30 batches: 0.8 GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwXj277YTa71"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiKeaFEQKLUg",
        "outputId": "db5c7019-151b-4bc7-de75-6bacfd6d2e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8027215003967285\n"
          ]
        }
      ],
      "source": [
        "time1 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time2 = time.time()\n",
        "        print(time2-time1)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        (hidden_states, extended_attention_masks) = anathem_encoder1(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )\n",
        "        features,_ = anathem_encoder2(\n",
        "            hidden_states_highres = hidden_states[0],\n",
        "            hidden_states_midres = hidden_states[1],\n",
        "            hidden_states_lowres = hidden_states[2],\n",
        "            extended_attention_mask_highres = extended_attention_masks[0],\n",
        "            extended_attention_mask_midres = extended_attention_masks[1],\n",
        "            extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaHOImksIE4s",
        "outputId": "e25c00cc-a643-46ff-ed4f-a54be0b86c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7066085338592529\n"
          ]
        }
      ],
      "source": [
        "time3 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time4 = time.time()\n",
        "        print(time4-time3)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        out = basemod(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpDJu4TrGJme",
        "outputId": "3223ab06-d6db-4c25-da03-b33c72689884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.86464646, 0.52173913])"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kO-XYGLFCuk"
      },
      "outputs": [],
      "source": [
        "eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcAhKojQOKOt"
      },
      "source": [
        "## Variant: Possibly Faster Integrative Layer\n",
        "\n",
        "The above version uses a BertIntegrativeLayer that uses the high-res hidden-states as the key/values, and the upscaled-low res as the query\n",
        "\n",
        "This variant flips it: the high-res is the query (thereby upscaling via attention) and the low-res are the value and keys\n",
        "\n",
        "#### Varient #2 has slightly fewer parameters: 33283328 vs 336"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVu2yPrYDJrr",
        "outputId": "5a5aa9e0-a25a-41eb-a762-64ea010ce58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=912c71a09879d3cf51b9382dd9ef132640c98d05d4fc67b1a10e50e32f92892d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, rank_bm25, langdetect, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 langdetect-1.0.9 multiprocess-0.70.15 rank_bm25-0.2.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1 xxhash-3.3.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25 langdetect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxVyqa3vNlYc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForMaskedLM\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "import math\n",
        "from langdetect import detect\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, Optional, Sequence, Tuple, Union\n",
        "from transformers.utils import PaddingStrategy\n",
        "\n",
        "EncodedInput = List[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RILlmtI3NxD8"
      },
      "outputs": [],
      "source": [
        "class CustomTokenizer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    ):\n",
        "        # initialize the tokenizer from the base model\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        # how many cls tokens to prepend to the fullsize data\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not ((k[0]=='_') or (k in ['tokenize','encode','build_inputs_with_special_tokens','batch_encode_plus','encode_plus','pad'])):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "        self.downscale_multiple = downscale_multiple\n",
        "        # downscale attention\n",
        "        self.maxpool_attn = nn.MaxPool1d(\n",
        "            (self.downscale_multiple), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True\n",
        "        )\n",
        "\n",
        "        # ensure excess_token_ids are included for .pad operations\n",
        "        if 'excess_cls_ids' not in self.base_tokenizer.model_input_names:\n",
        "            self.base_tokenizer.model_input_names += ['excess_cls_ids']\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._batch_prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        # downscale the attention, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='excess_cls_ids'\n",
        "        )\n",
        "        return tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_tokenizer)\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [self.cls_token_id]*(n_cls_prepend-1)+tokens['input_ids'] + [self.pad_token_id]*self._num_pad_tokens(tokens['input_ids'])\n",
        "        tokens['excess_cls_ids'] = [0]*(n_cls_prepend)+tokens['attention_mask'][1:] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        tokens['attention_mask'] = [1]*(n_cls_prepend-1)+tokens['attention_mask'] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                tokens['token_type_ids'][0]\n",
        "            ]*(n_cls_prepend-1) + tokens['token_type_ids'] + [tokens['token_type_ids'][-1]]*self._num_pad_tokens(tokens['token_type_ids'])\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def _batch_prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['excess_cls_ids'] = [\n",
        "            [0]*(n_cls_prepend)+attnmask[1:] +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                # we use the token_type_ids\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def encode_plus(self, text, add_special_tokens=True, return_tensors=None, *args, **kwargs):\n",
        "        tokens = self.base_tokenizer.encode_plus(text, add_special_tokens=add_special_tokens, return_tensors=return_tensors, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "        return tokens\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "    def downscale_attention(self, tokens, downscale_multiple=None, name = 'attention_mask'):\n",
        "        \"\"\"\n",
        "        Reduces the sequence-dimenion by self.downscale_multiple using nn.maxpool\n",
        "        Adds the downscale attention to the tokens dictionary\n",
        "        \"\"\"\n",
        "        if downscale_multiple is None:\n",
        "            downscale_multiple = [self.downscale_multiple, self.downscale_multiple]\n",
        "\n",
        "        # fullsize attention\n",
        "        attn = tokens[name]\n",
        "        if not isinstance(attn, torch.Tensor):\n",
        "            attn = torch.Tensor(attn)\n",
        "\n",
        "        for i, mult in enumerate(downscale_multiple):\n",
        "            name_of_downsized_attn = '%s_l%d' % (name, i+2)\n",
        "            with torch.no_grad():\n",
        "                attn = self.maxpool_attn(attn.float())\n",
        "            tokens[name_of_downsized_attn] = attn\n",
        "        return tokens\n",
        "\n",
        "    def pad(\n",
        "        self,\n",
        "        encoded_inputs,\n",
        "        pad_to_multiple_of=4,\n",
        "        return_tensors=None,\n",
        "        padding: Union[bool, str, PaddingStrategy] = True,\n",
        "        max_length: Optional[int] = None,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Pad a list of tokenized-inputs to the same batch-length, with special processing of Anathem-specific inputs\"\"\"\n",
        "\n",
        "        # which are conventional inputs and which are anathem specific\n",
        "        conventional_input_nm = [k for k in encoded_inputs[0].keys() if k in ['input_ids', 'token_type_ids','attention_mask']]\n",
        "        unconventional_input_nm = [k for k in encoded_inputs[0].keys() if k not in conventional_input_nm]\n",
        "\n",
        "        # pad the vanilla inputs\n",
        "        conventional_encoded_inputs = self.base_tokenizer.pad([\n",
        "                {k:v for k,v in encoded_input.items() if k in conventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "            ], pad_to_multiple_of=pad_to_multiple_of, return_tensors=return_tensors, padding=padding, max_length=max_length, *args, **kwargs\n",
        "        )\n",
        "\n",
        "        # deal with the remaining inputs\n",
        "        padding_strategy, _, max_length, _ = self.base_tokenizer._get_padding_truncation_strategies(\n",
        "            padding=padding, max_length=max_length, verbose=False\n",
        "        )\n",
        "\n",
        "        #required_input = encoded_inputs[][self.model_input_names[0]]\n",
        "        # this is stupid, I need to pad each input in batch individually\n",
        "        special_anathem_inputs = [\n",
        "                {k:v for k,v in encoded_input.items() if k in unconventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "        ]\n",
        "        special_anathem_encoded_inputs = self.pad_special_anathem_inputs(\n",
        "            special_anathem_inputs=special_anathem_inputs,\n",
        "            encoded_inputs=conventional_encoded_inputs,\n",
        "            max_length=max_length,\n",
        "            padding_strategy=padding_strategy,#: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "            pad_to_multiple_of=pad_to_multiple_of,\n",
        "            return_tensors=return_tensors\n",
        "        )\n",
        "        # let's see if I can just insert into the conventional_encode_inputs\n",
        "        conventional_encoded_inputs.update(special_anathem_encoded_inputs) # apparently I can just append..\n",
        "\n",
        "        # downscale the attention and add to inputs\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='excess_cls_ids'\n",
        "        )\n",
        "        return conventional_encoded_inputs\n",
        "\n",
        "    def pad_special_anathem_inputs(\n",
        "        self,\n",
        "        special_anathem_inputs,\n",
        "        encoded_inputs,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None,\n",
        "        return_tensors=None,\n",
        "    ):\n",
        "        required_input = encoded_inputs[self.model_input_names[0]]\n",
        "        batch_size,max_length = required_input.shape\n",
        "        #print(batch_size,max_length)\n",
        "        assert batch_size == len(special_anathem_inputs)\n",
        "        assert isinstance(special_anathem_inputs, list)\n",
        "        padding_strategy = PaddingStrategy.MAX_LENGTH\n",
        "        special_anathem_batch_outputs = {}\n",
        "        for i in range(batch_size):\n",
        "            inputs = special_anathem_inputs[i] #{k: v[i] for k, v in special_anathem_inputs.items()}\n",
        "            assert isinstance(inputs, dict)\n",
        "            outputs = self._pad_special_anathem_input(\n",
        "                inputs,\n",
        "                max_length=max_length,\n",
        "                padding_strategy=padding_strategy,\n",
        "                pad_to_multiple_of=pad_to_multiple_of\n",
        "            )\n",
        "            for key, value in outputs.items():\n",
        "                if key not in special_anathem_batch_outputs:\n",
        "                    special_anathem_batch_outputs[key] = []\n",
        "                special_anathem_batch_outputs[key].append(value)\n",
        "\n",
        "        return BatchEncoding(special_anathem_batch_outputs, tensor_type=return_tensors) # returning because of failure\n",
        "\n",
        "    def _pad_special_anathem_input(\n",
        "        self,\n",
        "        special_anathem_input,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Pad encoded Anathem-specific inputs (on left/right and up to predefined length or max length in the batch)\n",
        "        \"\"\"\n",
        "        assert isinstance(special_anathem_input, dict)\n",
        "        len_required_input = len(special_anathem_input[list(special_anathem_input.keys())[0]])\n",
        "        if max_length is not None and pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
        "            max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
        "\n",
        "        needs_to_be_padded = padding_strategy != PaddingStrategy.DO_NOT_PAD and len_required_input != max_length\n",
        "\n",
        "        # Initialize attention mask if not present\n",
        "        if needs_to_be_padded:\n",
        "            special_anathem_outputs = dict.fromkeys(special_anathem_input.keys())\n",
        "            difference = max_length - len_required_input\n",
        "            if self.padding_side == \"right\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = special_anathem_input[k] + [0] * difference\n",
        "            elif self.padding_side == \"left\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = [0] * difference + special_anathem_input[k]\n",
        "            else:\n",
        "                raise ValueError(\"Invalid padding strategy:\" + str(self.padding_side))\n",
        "\n",
        "            return special_anathem_outputs\n",
        "        return special_anathem_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e2f772d1181b417e8f3bc2feee4f6e16",
            "825fb9aa19594a61b2a779837eb230b4",
            "b076eddbd7a74d5495615776c26a6f3e",
            "75d76bf886514ba5ac9fedee0fcfba8d",
            "e9685ee9b4aa47fcb5a3a79261ca87c7",
            "686aaeb98c1a4e688af5030963b8525e",
            "0a024ed7f3514fd6a544804a8bee0d78",
            "f230ba518eed434fb107f97c66293470",
            "1a7dd0c3112945959e9908425fcaa8b8",
            "80fd0e5e6b8f47c6a4c9557f127ef73b",
            "b963a45c28d1437f86109f283a370f38",
            "bdc7642ca3e748069974df4a510470ce",
            "1034a93ce59f439bb128b6c096eefdf2",
            "4a16335de26a43c09d578cbbe20e98d1",
            "573b3112cbee4ba581c18884df0a269e",
            "4fe04dcab6654d0594a56109e7eb6805",
            "c225230ea12f4f90bd461485f300580e",
            "4d3b7432f11a4a4b9eb444743d158c0d",
            "1d567e39c5ac4b9f8d9908111b04100f",
            "f619ea2b062a4eacb80ade328d56c2aa",
            "bc799bb2e34741fabc79181ea30ee78f",
            "a78c45e4929847f0a635988d1ef9d78f"
          ]
        },
        "id": "8TRaTA1dDv10",
        "outputId": "1b1d9054-f164-49ea-eb1e-300eb4223758"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f772d1181b417e8f3bc2feee4f6e16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc7642ca3e748069974df4a510470ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = CustomTokenizer(\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qTUF85MsPkS",
        "outputId": "ef24d6fc-34fa-4865-cbe4-800035ff05e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.base_tokenizer.model_input_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6pmDZa6D22L"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrb_tyIFXoz",
        "outputId": "388102cd-666c-41fd-c565-bdf683e416bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids 40\n",
            "input_ids [101, 101, 101, 101, 1037, 3115, 103, 11075, 2003, 1037, 23701, 6299, 11075, 2008, 2163, 2008, 2028, 2283, 2180, 1005, 1056, 2907, 1996, 2060, 20090, 2005, 12394, 1010, 6409, 1010, 2030, 5366, 3378, 2007, 3314, 1012, 102, 0, 0, 0]\n",
            "token_type_ids 40\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 40\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "excess_cls_ids 40\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "input_ids 48\n",
            "input_ids [101, 101, 101, 101, 2009, 2788, 3774, 1997, 2048, 3787, 1024, 1037, 9495, 2724, 2030, 25652, 1998, 1037, 103, 14987, 1012, 1996, 9495, 2724, 2030, 25652, 2003, 1996, 103, 1997, 1996, 3820, 1010, 23337, 1010, 2030, 27988, 1997, 1996, 27427, 6633, 3490, 14116, 2283, 2030, 2049, 18460, 102]\n",
            "token_type_ids 48\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 48\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "excess_cls_ids 48\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "---\n",
            "CONVENTIONAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "SPECIAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "input_ids 2\n",
            "48\n",
            "48\n",
            "token_type_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask 2\n",
            "48\n",
            "48\n",
            "excess_cls_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask_l2 2\n",
            "24\n",
            "24\n",
            "attention_mask_l3 2\n",
            "12\n",
            "12\n",
            "excess_cls_ids_l2 2\n",
            "24\n",
            "24\n",
            "excess_cls_ids_l3 2\n",
            "12\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "# FOOFU\n",
        "# in the vanilla DataCollatorForLanguageModelling, if the data is pretokenized (unpadded)\n",
        "#    then collator will simply \"pad\", the input_ids and the attention_mask (but not the generated excess_cls_ids, nor the attention_mask_l2 or l3)\n",
        "#    ... but, I created these _l2,_l3 assuming that everything was already padded properly\n",
        "# so, adding excess_token_ids to _model_names_inputs (or whatev, doesn't automatically cause the behaviour I wanted)\n",
        "# the error is because the _pad specifically only handles special_token_ids and token_type_ids in a very specific way\n",
        "#... there is no generic list_of_names to enforce padding of generic inputs.\n",
        "\n",
        "# options:\n",
        "# --- make an updated \"pad\" function for the tokenizer, that will likewise apply padding\n",
        "tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "\n",
        "for tok in tokens:\n",
        "    for k,v in tok.items():\n",
        "        print(k,len(v))\n",
        "        print(k,v)\n",
        "print('---')\n",
        "\n",
        "pad_out = tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt')\n",
        "print('CONVENTIONAL')\n",
        "print(pad_out)\n",
        "\n",
        "#for k,v in tokenizer.base_tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt').items():\n",
        "print('SPECIAL')\n",
        "print(pad_out)\n",
        "for k,v in pad_out.items():\n",
        "    print(k, len(v))\n",
        "    for j in v:\n",
        "        print(len(j))\n",
        "\n",
        "\n",
        "# still need to do: reduce attention_mask\n",
        "# return as tensor\n",
        "# merge and make a BatchEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxawLdRdHStR",
        "outputId": "e76fe1b0-3584-48a0-db64-806542ac0c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pad_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3WljX9NzSW"
      },
      "outputs": [],
      "source": [
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n",
        "try:\n",
        "    from transformers.modeling_utils import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbXNphafOX2i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size= self.hidden_size, # high dim output\n",
        "            hidden_size_query = self.hidden_size_query, # high dim query\n",
        "            hidden_size_keyvalue = self.hidden_size_keyvalues, # low-dim keyvalues\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        keyvalue_hidden_states: torch.Tensor=None, # low-res hidden-states (1/2 seq-dim) used for key-value pairs\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to query\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = keyvalue_hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = torch.cat((hidden_states, query_to_concat_hidden_states),axis=2),\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "        assert cross_hidden_states.shape[1]==hidden_states.shape[1], f\"{cross_hidden_states.shape[1]},{cross_hidden_states.shape[2]} vs {hidden_states.shape[1]},{hidden_states[2]}\"\n",
        "        assert cross_hidden_states.shape[2]==hidden_states.shape[2]\n",
        "\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.output_attn(cross_hidden_states)\n",
        "        cross_hidden_states = self.dropout_attn(cross_hidden_states)\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        intermediate_states = self.intermediate(intermediate_states)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        out_states = self.output_intm(intermediate_states)\n",
        "        out_states = self.dropout_intm(out_states)\n",
        "        out_states = self.lnorm_intm(out_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOl85thAOiu3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class CheapMLPIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Cheap (non-transformer) Integrator layer that merges a (low-res) layers with higher-res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues=None, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        if hidden_size_keyvalues is None:\n",
        "            hidden_size_keyvalues = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(2*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # expand hidden-size to a multiple\n",
        "        self.dense_expander = nn.Linear(\n",
        "            self.hidden_size_query,\n",
        "            self.intermediate_size\n",
        "        ) # deflate back to same size as hidden-state\n",
        "        self.dense_deflator = nn.Linear(\n",
        "            self.intermediate_size,\n",
        "            self.hidden_size\n",
        "        )\n",
        "\n",
        "        # intermediate activation function\n",
        "        self.intermediate_act_fn = nn.RReLU(0.0625, 0.125)\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.lnorm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask = None, # ignored\n",
        "        head_mask = None, # ignored\n",
        "        keyvalue_hidden_states =None, # ignored\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to hidden_states\n",
        "        query_attention_mask = None, # ignored\n",
        "        past_key_value = None, # ignored\n",
        "        output_attentions = False, # ignored\n",
        "    ) -> torch.Tensor:\n",
        "\n",
        "        # concat (lowres) to hidden-states\n",
        "        inputs = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        # expand x2 dimension\n",
        "        intermediate_states = self.dense_expander(inputs)\n",
        "        # activation (leaky relue)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        # like BertOutput\n",
        "        out_states = self.dense_deflator(intermediate_states)\n",
        "        # dropout\n",
        "        out_states = self.dropout(out_states)\n",
        "        # combine with hidden-state inputs\n",
        "        out_states = self.lnorm(out_states + hidden_states)\n",
        "\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo-LWT_jOFNa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    sequence_classification_intermediate_dim = None, # default is the same as the basemodel hidden-dim\n",
        "    sequence_classification_out_dim = None, # default is x2 same as the basemodel hidden-dim\n",
        "    do_mlm =False,\n",
        "    do_cls = False\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config, 'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks', num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multiplier_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multiplier_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", do_cheap_integrator)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # hidden dimension\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_intermediate_dim\",\n",
        "        sequence_classification_intermediate_dim  if sequence_classification_intermediate_dim is not None else [\n",
        "            int(base_config.hidden_size*s)\n",
        "            for s in [1, scale_ratio2, scale_ratio3]\n",
        "        ]\n",
        "    )\n",
        "    # final dimension outputed for sequence classification\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_out_dim\",\n",
        "        sequence_classification_out_dim  if sequence_classification_out_dim is not None else base_config.hidden_size*2\n",
        "    )\n",
        "\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None, stack_id=1):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: from low-res to mide-res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    if not do_cheap_integrator:\n",
        "        # from mid-res to high-res\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "\n",
        "def initialize_finaltransformerlayers(config, basemod=None, tokenizer=None, names_encoder_module = 'encoder', stack_id=3):\n",
        "    \"\"\"Initializes the final BertLayer before output, but copying the final BertLayer from `Basemod`\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    assert basemod is not None, \"`initialize_finaltransformerlayers` requires the basemod to instantiate the final transformer block\"\n",
        "\n",
        "    # get the Encoder stacks\n",
        "    assert names_encoder_module in basemod._modules.keys(), 'expected %s in basemod._modules' % names_encoder_module\n",
        "    basemod_encoder_stack = get_to_bertlayer(basemod, target_layer_name = names_encoder_module)\n",
        "\n",
        "    # get the name of the final transformer block (-1) in encoder\n",
        "    names_of_final_transformer_block = list(basemod_encoder_stack._modules['layer']._modules.keys())[-1]\n",
        "\n",
        "    # get the final transformer block (NN weights pretrained)\n",
        "    bert_finaltransformer_block = basemod_encoder_stack._modules['layer']._modules[\n",
        "        names_of_final_transformer_block\n",
        "    ]\n",
        "\n",
        "    return copy.deepcopy(bert_finaltransformer_block)\n",
        "\n",
        "def get_to_bertlayer(basemod, target_layer_name = 'encoder', model_string = None):\n",
        "    \"\"\"Clumsily locates a particular layer within a pretrained bert model\"\"\"\n",
        "    if  target_layer_name in basemod._modules.keys():\n",
        "        return basemod._modules[target_layer_name]\n",
        "    elif target_layer_name in basemod._modules['bert']._modules.keys():\n",
        "        return basemod._modules['bert']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L79IXfrOKEs"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None,\n",
        "            stack_id=0\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer, stack_id=0)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        self.stack_id = 0\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l3,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        #hidden_states_upscaled = torch.cat((\n",
        "        #    hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        #),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l2,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1,\n",
        "            query_attention_mask = extended_attention_mask_l2\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "                (attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"extended_attention_masks\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "            \"attention_masks\":(attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "            stack_id = 1\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer, stack_id)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_lowres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2\n",
        "        )\n",
        "        #hidden_states_midres = self.bert_integrative_layer_2(\n",
        "        #    hidden_states = hidden_states_l2,\n",
        "        #    attention_mask = extended_attention_mask_midres,\n",
        "        #    head_mask = None,\n",
        "        #    query_hidden_states = hidden_states_upscaled3to2)\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        #hidden_states_upscaled = torch.cat((hidden_states_upscaled2to1, hidden_states_upscaled3to1),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_midres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1\n",
        "        )\n",
        "\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemEncoder(nn.Module):\n",
        "    \"\"\"Anathem cores stacks of layers, from embeddings to final transformer block\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # initialize embedings and first stack\n",
        "        self.anathem_base_stack = AnathemBaseModule(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            past_key_values_length,\n",
        "            device,\n",
        "        )\n",
        "\n",
        "        # initialize all subsequence stacks\n",
        "        self.anathem_mid_stack = nn.ModuleList([\n",
        "            AnathemMidModule(\n",
        "                config,\n",
        "                basemod,\n",
        "                tokenizer,\n",
        "                past_key_values_length,\n",
        "                device,\n",
        "                stack_id = i\n",
        "            ) for i in range(1, self.config.num_transformer_stacks)\n",
        "        ])\n",
        "\n",
        "        # initialize the final transformer modules\n",
        "        self.final_transformer_block = initialize_finaltransformerlayers(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            stack_id=self.config.num_transformer_stacks+1\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = False,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        output_hidden_states: Optional[bool] = False,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # embed and run through first stack of transformers\n",
        "        hidden_states, extended_attention_masks, attention_masks = self.anathem_base_stack(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2,\n",
        "            attention_mask_l3=attention_mask_l3,\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "\n",
        "        # middle stack of transformers\n",
        "        for i, anathem_stack in enumerate(self.anathem_mid_stack):\n",
        "\n",
        "            # run through each stack (1-2)\n",
        "            hidden_states, extended_attention_masks = anathem_stack(\n",
        "                hidden_states_highres = hidden_states[0],\n",
        "                hidden_states_midres = hidden_states[1],\n",
        "                hidden_states_lowres = hidden_states[2],\n",
        "                extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "            )\n",
        "\n",
        "        # hidden states (high,med,low resolution)\n",
        "        hidden_states_highres, hidden_states_midres, hidden_states_lowres = hidden_states\n",
        "\n",
        "        # run through final transformer block (pretrained)\n",
        "        out_final = self.final_transformer_block(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_masks[0],\n",
        "            head_mask=None,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        #print(type(out_final))\n",
        "        #print(len(out_final))\n",
        "        hidden_states_highres = out_final[0]\n",
        "        if not output_attentions:\n",
        "            return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks\n",
        "\n",
        "        attention_final = out_final[1]\n",
        "        return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks, attention_final\n",
        "\n",
        "\n",
        "class BertGenericClassificationHead(nn.Module):\n",
        "    \"\"\"Instantiates a basic classification head that takes the CLS token and mean of the final layer for classification\"\"\"\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "class AnathemMultiSiloPooler(nn.Module):\n",
        "    \"\"\"\n",
        "    Pools the token-embeddings along the sequence dimenions for a final sentence-vector.\n",
        "    The pooling occuras across all three 'silos'\n",
        "    The pooling consists of the CLS token as well as mean pooling, concatenated token\n",
        "    Use the pooling outputs prior to any sequenceClassification\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        dim_out = None,\n",
        "        mean_activation = nn.Tanhshrink,\n",
        "        out_activation = None,\n",
        "        dims_in = None,\n",
        "        p_dropout=None,\n",
        "        device=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # dimensions of the hiddens states being processed as inputs\n",
        "        if dims_in is None:\n",
        "            try:\n",
        "                dims_in = config.sequence_classification_intermediate_dim\n",
        "            except:\n",
        "                dims_in = [dim_out, dim_out//2, dim_out//4]\n",
        "        self.dims_in = dims_in\n",
        "        self.dim_in = sum(dims_in)\n",
        "        self.hidden_size = config.hidden_size\n",
        "        if dim_out is None:\n",
        "            try:\n",
        "                dim_out = config.sequence_classification_out_dim\n",
        "            except:\n",
        "                dim_out = config.hidden_size*2\n",
        "        self.dim_out = dim_out\n",
        "        self.mean_activation = mean_activation\n",
        "\n",
        "        #self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if out_activation == 'none' or out_activation is None:\n",
        "            self.activation = lambda x: x\n",
        "        elif out_activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif out_activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif out_activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "        # linear layer operating on the concatenated CLS tokens from all silos\n",
        "        self.cls_pooler = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            nn.Linear(self.dim_in, int(self.hidden_size)),\n",
        "        )\n",
        "\n",
        "        # pre-mean-pooling (one for each silo)\n",
        "        #self.pre_poolers = [nn.Sequential(\n",
        "        #    nn.Dropout(p_dropout),\n",
        "        #    nn.Linear(dim,dim)\n",
        "        #    ) for dim in self.dims_in\n",
        "        # ]\n",
        "        self.pre_poolers = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            self.mean_activation\n",
        "        )\n",
        "\n",
        "        # sequential layer to concatenate the mean tokens from multiple tokens\n",
        "        self.mean_pooler = nn.Linear(self.dim_in, self.hidden_size)\n",
        "\n",
        "    def forward(self, hidden_states, attention_masks, excess_cls_ids=None) -> torch.Tensor:\n",
        "        \"\"\"Combines CLS token and mean-pooling for the sentence-vectorization\"\"\"\n",
        "\n",
        "        # CLS/first-tokens from all silos, all concatenated together\n",
        "        first_token_tensors = self._get_cls_tokens_all_silos(hidden_states)\n",
        "\n",
        "        # mean pooling\n",
        "        mean_pooled_tensors = self._mean_pool_all_silos(hidden_states, attention_masks, excess_cls_ids)\n",
        "\n",
        "        # concatenate CLS and mean\n",
        "        pooled_output = torch.concat((first_token_tensors, mean_pooled_tensors), axis=1)\n",
        "\n",
        "        return self.activation(pooled_output)\n",
        "\n",
        "    def _get_cls_token(self, hidden_state):\n",
        "        \"\"\"Grabs the CLS token from a hidden-states\"\"\"\n",
        "        return hidden_state[:, 0]\n",
        "\n",
        "    def _get_cls_tokens_all_silos(self, hidden_states):\n",
        "        \"\"\"Grabs the CLS token from all hidden_states\"\"\"\n",
        "        first_tokens = [\n",
        "            self._get_cls_token(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "        # concat all first tokens\n",
        "        all_first_tokens_cat = torch.cat(first_tokens,axis=1)\n",
        "        # run the concatenated first-tokens through Dense\n",
        "        all_first_tokens_out = self.cls_pooler(all_first_tokens_cat)\n",
        "        return all_first_tokens_out\n",
        "\n",
        "    def _mean_pool(self, hidden_state, attention_mask=None, excess_cls_id=None):\n",
        "        \"\"\"Pool along a sequence dimension (for just one silo)\"\"\"\n",
        "        if excess_cls_id is None:\n",
        "            excess_cls_id = attention_mask\n",
        "        input_mask_expanded = excess_cls_id.unsqueeze(-1).expand(hidden_state.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        return sum_embeddings / sum_mask\n",
        "\n",
        "    def _mean_pool_all_silos(self, hidden_states, attention_masks=None, excess_cls_ids=None):\n",
        "        \"\"\"Pool along a sequence dimension (for all silos)\"\"\"\n",
        "        if excess_cls_ids is None:\n",
        "            excess_cls_ids = attention_masks\n",
        "\n",
        "        # pre-pool: dense-layer before pooling\n",
        "        hidden_states = [\n",
        "            self.pre_poolers(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "\n",
        "        # mean pool each silo\n",
        "        mean_pooled_states = [\n",
        "            self._mean_pool(\n",
        "                hidden_state=hidden_state, excess_cls_id=excess_cls_id\n",
        "            ) for hidden_state, excess_cls_id\n",
        "            in zip(hidden_states, excess_cls_ids)\n",
        "        ]\n",
        "\n",
        "        # concat all mean-pooled states\n",
        "        all_mean_pooled_states = torch.cat(mean_pooled_states,axis=1)\n",
        "        # run the concatenated meanpooled states through Dense\n",
        "        all_mean_pooled_states = self.mean_pooler(all_mean_pooled_states)\n",
        "        return all_mean_pooled_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J18VNXqTYNY2"
      },
      "outputs": [],
      "source": [
        "class AnathemTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=None,\n",
        "        device=None,\n",
        "        do_mlm = None,\n",
        "        do_cls = None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # default config\n",
        "        if config is None:\n",
        "            config = make_config()\n",
        "        self.config = config\n",
        "        self.do_mlm = config.do_mlm if do_mlm is None else do_mlm\n",
        "        self.do_cls = config.do_cls if do_cls is None else do_cls\n",
        "\n",
        "        # device\n",
        "        if device is None:\n",
        "            if torch.cuda.is_available():\n",
        "                device = torch.device('cuda')\n",
        "            else:\n",
        "                device = torch.device('cpu')\n",
        "        self.device= device\n",
        "\n",
        "        # get the basemodel (and its masked LM head\n",
        "        self.model_string = self.config.model_string\n",
        "        basemodelLM_pretrained = AutoModelForMaskedLM.from_pretrained(self.model_string)\n",
        "\n",
        "        # get the Pretrained BertEncoder\n",
        "        basemod_pretrained = get_to_bertlayer(\n",
        "            basemodelLM_pretrained,\n",
        "            target_layer_name = 'encoder'\n",
        "        )\n",
        "\n",
        "        # make the tokenizer (based on pretrained)\n",
        "        self.tokenizer = CustomTokenizer(\n",
        "            model_string=self.config.model_string,\n",
        "            n_cls_prepend = int(1/config.scale_ratio3),\n",
        "            n_pad_to_multiple_of= int(1/config.scale_ratio3)\n",
        "        )\n",
        "\n",
        "        # make the Embedding and first layers (pretrained)\n",
        "        self.encoder = AnathemEncoder(\n",
        "            self.config,\n",
        "            basemod=basemod_pretrained,\n",
        "            tokenizer=self.tokenizer ,\n",
        "            past_key_values_length = None,\n",
        "            device=self.device,\n",
        "        )\n",
        "\n",
        "        # get the Pretrained maskedLM head\n",
        "        if self.do_mlm:\n",
        "            # perform maskedLM\n",
        "            self.mlm = get_to_bertlayer(\n",
        "                basemodelLM_pretrained,\n",
        "                target_layer_name = 'cls'\n",
        "            )\n",
        "        else:\n",
        "            self.mlm = lambda x : x\n",
        "\n",
        "        # make the sequence-classification head\n",
        "        if self.do_cls:\n",
        "            self.pooler = AnathemMultiSiloPooler(\n",
        "                config=self.config,\n",
        "                mean_activation = nn.Tanhshrink(),\n",
        "                dims_in = self.config.sequence_classification_intermediate_dim,\n",
        "                p_dropout=self.config.hidden_dropout_prob,\n",
        "                device=self.device\n",
        "            )\n",
        "\n",
        "    def _get_name(self):\n",
        "        return 'ANATHEM_MODEL_FOR_MLM'\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l2: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l3: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # run through base-layer (embeddings, transformer-block, 1 anathem stack)\n",
        "        outputs_encoder = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2, # optional downsized attention mask for sequence-dim 1/2\n",
        "            attention_mask_l3=attention_mask_l3, # optional downsized attention mask for sequence-dim 1/4\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=False\n",
        "        )\n",
        "        if output_attentions:\n",
        "            hidden_states, extended_attention_masks, attention = outputs_encoder\n",
        "        else:\n",
        "            hidden_states, extended_attention_masks = outputs_encoder\n",
        "            attention = None\n",
        "\n",
        "        out_mlm = {'logits':None}\n",
        "        out_pooled_vector = None\n",
        "        hidden_states_highres, hidden_states_midres, hiddenstates_lowres = hidden_states\n",
        "\n",
        "        # MLM outputs\n",
        "        if self.do_mlm:\n",
        "            out_mlm = self.mlm(hidden_states_highres)\n",
        "\n",
        "        # sequence pooling (for classification)\n",
        "        if self.do_cls:\n",
        "            out_pooled_vector = self.pooler(\n",
        "                hidden_states=hidden_states,\n",
        "                attention_masks=(attention_mask, attention_mask_l2, attention_mask_l3),\n",
        "                excess_cls_ids=(excess_cls_ids, excess_cls_ids_l2, excess_cls_ids_l3)\n",
        "            )\n",
        "        #\n",
        "        if return_dict:\n",
        "            return {\n",
        "                'hidden_states':(hidden_states_highres, hidden_states_midres, hiddenstates_lowres),\n",
        "                'pooled':out_pooled_vector,\n",
        "                'logits':out_mlm['logits'],\n",
        "                'attention':attention,\n",
        "                'extended_attention_masks':extended_attention_masks\n",
        "            }\n",
        "        return hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fb064cacf0e243299a2d092facae8c79",
            "be7af49d0afe4ecdaa800be969d5a3e7",
            "560c716068a645d596cc2fe9b886c0ad",
            "08c60bb508854cc9b6772ab78502b6fb",
            "e84136de295d4d39b44c908ff2458ba9",
            "2166426a7a224f1da2065f3221463693",
            "77d712d32c0f491cb9a58df33b012b0c",
            "235afab600844a9f8ef8f45cdba142e0",
            "c7537c19825a49cd8f3343c153fe56ef",
            "497aad7b9ab34f158382033f65d9a8c9",
            "814c0fc7e64c49bfa85d5087d1e07cb4"
          ]
        },
        "id": "jYu06BPCY1Oz",
        "outputId": "a8d0df70-d7a6-47ac-ab3a-e6377dd18a37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb064cacf0e243299a2d092facae8c79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelstring_teacher_mlm = 'bert-base-uncased'\n",
        "model_string = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "\n",
        "config = make_config(\n",
        "    modelstring = model_string,\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    do_mlm=True,\n",
        "    do_cls=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496,
          "referenced_widgets": [
            "19e70f5c3ae04d4b8b4a86c1233418be",
            "c7fcfc2727db445695b908ffd3370feb",
            "546b278b05e643a4905055d1d7ffeea5",
            "289aa49d154a496d9804cf30545bc5fc",
            "f54be5e820704ad2b31b6b7a6b946181",
            "8a0851189dae4fbdb953f6afe6f3ba29",
            "01f4a70e089f4fe5abb0d9246aeee403",
            "195b549a3cd745ffbe55e24f5865b1da",
            "fe156388571b4c63b5fc5f5ca857e522",
            "36c0e136fa3f400bab5deec7a0aff11f",
            "bcee86d4105743f5a69c595029994bc8",
            "9c8b871e03af41ada7990e7b76084f84",
            "33ae5a6ee9244aeea02e10990e8dd3da",
            "470a84311bbf40c6ae6322d6edc353ae",
            "8974203b2bde4395b3144ffe61596643",
            "d4ea11ee38044f7cb7ffe1a5b018bda7",
            "5f1b9961c6b14a1a92f3cb2c82883a17",
            "dfd3f1f64d81471083416a3e4ca6aa60",
            "9568bdb74f3e450f91b3558cf5ad5da1",
            "b7b946e1ad95455b818512986f83f7cd",
            "5fdca1f2b388437fac7624c0eca1ec26",
            "1c00f260ca44415c9c2cc342c9cab470",
            "476c5672e7784cda8255af2049de1ecd",
            "73e2bfea29de4c47b0c60590deff9771",
            "4326c46139fd4b6882d864400e35a9bc",
            "a53d537c8c0e48d1a77fbc22e5c41402",
            "4eba976ecf5145e0a60cc8a838bff5c9",
            "2750de9a4c5740b080f5a8145de41111",
            "ecf9c5705a7b491c82d4e8b5cbd8c439",
            "e76cddc6d7d04d3fb01c11225ec1b6a2",
            "9ad1276e945e4915a079e97e06048ee9",
            "02191a5509094a0abcf8862d3a8ee4cd",
            "5c69e45579f54fc6b2415ebbad4da477",
            "8dbb1fccc920458cbffc7029953e5363",
            "29e9e92bc30c4b2f89416481b4fb1455",
            "1c5678cdeb204d21b94526ccdab34d32",
            "dea6b34486294d388d68aa9ef3aaa281",
            "e34566724c6e4598860e77d6b710faf8",
            "b34433ff3b52491fb5829b9f1522e162",
            "5250f6a6e5c34894adb20a9120388ba0",
            "0381ff6309df4052bb0ce823e7ff741b",
            "bd79d8ce5e28404c988f4965873a2f2c",
            "b70156e5cb144e75b97697a2439d9a5d",
            "96e7d97dc8f44c7d873060a89f82ce0e",
            "aa099b9c51d6447a9a22fb13b103cb41",
            "03a6cc127c8c4f03bab0b31bb3a1721b",
            "08fbdead6ab540d4a1d2d8f06879e417",
            "5f0512fb3607471f817b5c215d94e4d8",
            "0457dfcb462c4173bbfb7890bb043c97",
            "d6ccd976679e45fcbf6d6b5d06360ea6",
            "f6c454dc6dcb4528b7b05b83c72640fc",
            "029adddbce024f50bc5d7a06d304632d",
            "d2a8de725a934927b52792351e0d5099",
            "dcd68849bd0a44238fbb9bec129b0511",
            "3312caf3fc76420ead7f4945675df52a",
            "169e8fa7a73d4797945e98ccba4cd10c",
            "b072faf11c504e39939d1ad4534f9112",
            "f3707c74969e4f6c84d6a36b59d6fa9e",
            "32184fc9b099416a8d49ef3c3f8c3a2e",
            "2b95b44611524401ac7826dab5a21aa8",
            "3fb4b68eda9f481abbc7b2456644e16b",
            "3c54d6fd6a004ed98c1cb595a0bb84a0",
            "7f511160291e4a4a82f8694772449ea8",
            "91eebca40ce344039704522c4570353c",
            "2137d76adc0b4235bcf4e52ab94ae445",
            "fcb506371e6e4cd2947988d6c7050809",
            "a5967030d5aa4581b66d319588b92db4",
            "6baecbf668bc4a6f93be03e5f671b76a",
            "a33ab96c585c411ab148d76865b848f2",
            "5589d685cbc94ea0a045dcba0e69a7e5",
            "01ac22caf29c4b2baf0ebc428f3398b3",
            "1d322e088a6a4904a0b99740d8d4e45c",
            "20402646761d4cf3975763fc130d6ff5",
            "5183ef3eec0d4bdfbcc5544b0fec573b",
            "3751db7e581847efa6c224dd50c9b7bb",
            "600bc8f5877547aca898f8c85902040e",
            "b65ef6da8ad34e2285813544d00bf3e5",
            "4ef3bcbd56164ddaac3068fb93a66630",
            "0cbd831de3c64f4aa269776dc73c5e28",
            "d947bfe9101646c9a7222ada482d4455",
            "8e9137be11744d329bceecd548d91025",
            "326c1c104f254d1189c78c6abd318451",
            "a4848184b58645b2a572c6e1a1231f05",
            "92d450929c8e45539c2726eaf96d5ddb",
            "d9a90b08aaec44d9962e8c090b8d0baa",
            "70225a6a843d4ccf87d1b43d4cf1895b",
            "8c45ce351a9b45dda4359b706ea36aba",
            "9e2644d3c3bb40aa9eba632e756112a3",
            "a6770d150cfa459780d5adb12fc7c7b8",
            "78608a4a3a8f4c119d9a0128153a39eb",
            "91de7341a97a4415b5656ee33fe6395f",
            "82f1dc2ca5ef4e45818a2b9107732d58",
            "5e1a387877054dacbb6bf1fa32b08d7a",
            "48729429682c4b37a624ba2eb55d1966",
            "6eeb3579c2b644a6b8501cc246083c97",
            "8f1bf2df4214449483a37dc84d9f3c43",
            "9afa2b87f4a94a58b7c639a0a7f63813",
            "8ae32d0dd19e40e8a0fc4b04b325abd6",
            "20ae65dc26cb4ab98a9637dfa2bd5a62",
            "641fd37171904fb590b7877d8403aeea",
            "e8f710e2dcfc40398ce16a4ac265cc26",
            "377a7fa0ebce4c8a96a55c6e1c08403f",
            "5ed5174d9d6c4680bb7cc1e803184102",
            "2c148a8aa9fe4f30a69392f10a350eac",
            "177dee7aa0754c7db2b595f83a4eb105",
            "2fe3c4d6e4774be691e7c0551fd334ff",
            "6ff3a2b6be1f4220b0e3c055fc587c7e",
            "af816340aae74a81a6eaf63a1933f5bf",
            "91bcf74809894d39b5199ca23691f00f",
            "85a35c16364f4c6880dbbecf061faf44"
          ]
        },
        "id": "Y7HRRYhrfm18",
        "outputId": "0fc7cf35-f252-47f1-a9a0-3b2ef5615da2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e70f5c3ae04d4b8b4a86c1233418be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c8b871e03af41ada7990e7b76084f84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "476c5672e7784cda8255af2049de1ecd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dbb1fccc920458cbffc7029953e5363",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa099b9c51d6447a9a22fb13b103cb41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "169e8fa7a73d4797945e98ccba4cd10c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5967030d5aa4581b66d319588b92db4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ef3bcbd56164ddaac3068fb93a66630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6770d150cfa459780d5adb12fc7c7b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "641fd37171904fb590b7877d8403aeea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "anamod = AnathemTransformer(\n",
        "        config=config,\n",
        "        device=None,\n",
        "        do_mlm = True,\n",
        "        do_cls = True\n",
        "    )\n",
        "\n",
        "teacher_mlm = AutoModelForMaskedLM.from_pretrained(modelstring_teacher_mlm)\n",
        "\n",
        "\n",
        "from torch import Tensor\n",
        "class TeacherEmbedder:\n",
        "\n",
        "    def __init__(self, pretrained_name = 'intfloat/e5-large-v2'):\n",
        "        self.pretrained_name = pretrained_name\n",
        "        self.teacher_tokenizer = AutoTokenizer.from_pretrained(pretrained_name)\n",
        "        self.teacher_embedder = AutoModel.from_pretrained(pretrained_name)\n",
        "\n",
        "    @staticmethod\n",
        "    def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "    def forward(self, input_text, prepend = 'passage: '):\n",
        "        input_text = [prepend + s for s in input_text]\n",
        "        with torch.no_grad():\n",
        "            batch_dict = self.teacher_tokenizer(input_text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "            outputs = self.teacher_embedder(**batch_dict)\n",
        "            embeddings = self.average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "        return embeddings\n",
        "\n",
        "    def __call__(self, input_text, prepend = 'passage: '):\n",
        "        return self.forward(input_text)\n",
        "\n",
        "\n",
        "teacher_emb = TeacherEmbedder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_BdVwTUsWj1",
        "outputId": "2e956c25-393b-4fc3-996e-5b18796b9e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertOnlyMLMHead(\n",
            "  (predictions): BertLMPredictionHead(\n",
            "    (transform): BertPredictionHeadTransform(\n",
            "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (transform_act_fn): GELUActivation()\n",
            "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(anamod.mlm) # MLM head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PaoAjDffxVd",
        "outputId": "868f0300-5add-4258-da89-da358ddf8b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids', 'attention_mask_l2', 'attention_mask_l3', 'excess_cls_ids_l2', 'excess_cls_ids_l3'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 512])\n",
            "torch.Size([2, 24, 256])\n",
            "torch.Size([2, 12, 128])\n",
            "torch.Size([2, 1024])\n",
            "torch.Size([2, 48, 30522])\n",
            "torch.Size([2, 48, 30522])\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'a', 'standard', 'liability', 'clause', 'is', 'a', 'wai', '##ver', 'clause', 'that', 'states', 'that', 'one', 'party', 'won', \"'\", 't', 'hold', 'the', 'other', 'liable', 'for', 'damages', ',', 'losses', ',', 'or', 'costs', 'associated', 'with', 'issues', '.', 's', '.', '.', 'it', '.', 'the', 'it', 'it', 'it', 'parties', 'one', 'party']\n",
            "Anamod\n",
            "['-', 'the', '-', '-', 'a', '-', '-', '-', '.', 'a', '-', '-', '.', '.', 'is', '.', 'the', '.', '-', \"'\", 's', '.', 'the', 'other', ',', 'for', 'me', ',', 'my', ',', 'or', 'the', '-', 'with', 'the', '.', 'the', 'he', 'he', 'he', '-', '-', ',', ',', ',', 'the', '-', ',']\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'it', 'usually', 'consists', 'of', 'two', 'elements', ':', 'a', 'trigger', 'event', 'or', 'circumstance', 'and', 'a', 'trigger', 'obligation', '.', 'the', 'trigger', 'event', 'or', 'circumstance', 'is', 'the', 'violation', 'of', 'the', 'agreement', ',', 'misconduct', ',', 'or', 'negligence', 'of', 'the', 'ind', '##em', '##ni', '##fying', 'party', 'or', 'its', '.', 's']\n",
            "Anamod\n",
            "['-', 'the', 'the', '-', 'it', 'or', 'the', 'of', 'two', 'of', ':', 'a', 'the', ',', 'or', ',', 'and', 'a', '-', 'of', '.', 'the', 'trigger', '-', 'or', '-', 'is', 'the', 'part', 'of', 'the', 'or', ',', 'the', ',', 'or', ',', 'of', 'the', 'ind', '##em', ',', ',', ',', 'or', 'the', '-', 'the']\n",
            "torch.Size([4, 1024])\n"
          ]
        }
      ],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "inputs = anamod.tokenizer(text, add_special_tokens=True, return_tensors='pt', padding='longest')\n",
        "\n",
        "print(inputs.keys())\n",
        "inputs\n",
        "\n",
        "outputs = anamod.forward(\n",
        "    input_ids = inputs['input_ids'],\n",
        "    attention_mask = inputs['attention_mask'],\n",
        "    attention_mask_l2 = inputs['attention_mask_l2'],\n",
        "    attention_mask_l3 = inputs['attention_mask_l3'],\n",
        "    excess_cls_ids = inputs['excess_cls_ids'],\n",
        "    excess_cls_ids_l2 = inputs['excess_cls_ids_l2'],\n",
        "    excess_cls_ids_l3 = inputs['excess_cls_ids_l3']\n",
        ")\n",
        "# hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "\n",
        "outputs_teacher_mlm = teacher_mlm(input_ids = inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "\n",
        "print(outputs[0][0].shape) # full hidden state sequence\n",
        "print(outputs[0][1].shape) # mid hidden state sequence\n",
        "print(outputs[0][2].shape) # small hidden state sequence\n",
        "print(outputs[1].shape) # sentencevector\n",
        "print(outputs[2].shape) # mlm outputs\n",
        "\n",
        "#\n",
        "print(outputs_teacher_mlm['logits'].shape) # Teacher shape mlm\n",
        "\n",
        "predicted_token_ids1 = outputs_teacher_mlm[0][0].argmax(dim=-1)\n",
        "predicted_token_ids2 = outputs[2][0].argmax(dim=-1)\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][0].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][0].argmax(dim=-1)))\n",
        "\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][1].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][1].argmax(dim=-1)))\n",
        "\n",
        "# try to embed text with the teacher_emb\n",
        "text2 = input_texts = [\n",
        "    'query: how much protein should a female eat',\n",
        "    'query: summit define',\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"\n",
        "]\n",
        "sentence_embeddings = teacher_emb(text2)\n",
        "print(sentence_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzb5l9wymf4D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "1a3234bae89d4c1eb7e84da16675cde8",
            "7c50e41b12ab40ae88db5a68806a5287",
            "9a675022c08043438f0288c2dc3d1692",
            "42ed4267878a46a9a1a1de7f63006ab4",
            "a587d42c581c4f75984a189ebe1b1831",
            "1aea1f6de91a43a4b491c82ffc1522be",
            "3c45e6794f974b4199098bcd87765e63",
            "ff58b4945b004e9996568c228986d287",
            "1290569b6a4d490fbfc8ca3915983263",
            "ba76516f42224f79a9dfe8a36385bb22",
            "c6b2dc48588b482f80e9a2473dc5b452",
            "e7bd0a23537441b6a41373c7db399423",
            "7bdb5cce9c364437970f01220e5f0aa3",
            "5df7aa079833485bbde65e4658b496e0",
            "e9149263e2264fe6b5e5cb50f67d55c2",
            "e3712984d7774865be2c1e97faf82d57",
            "3e72971bf9804c3688c24e0a3eca0da7",
            "d36c80ffd8824fdb8e1e344f41fa3669",
            "283065bbec654b89a6be726e3fe790fd",
            "ebf0c7ac01e441d68a38cac5fed89d00",
            "ab8bf4aa34c5452d8c6d01df44402eea",
            "c1ad349038c94c1f9ec7b1d0d7245699",
            "fc40e712ccca489e8cb2eaadbc47aa54",
            "d87e9ee37dfe44bcad7b97ccfef0f5ff",
            "afd68f4512e045c2bfaa46eb36d4ab5a",
            "db1f664494c94faf8998df1f25718b9f",
            "63a2424581894ab48ad61b9f38cc882e",
            "44ce4959b2bc410a8b455eb2adb7ffc9",
            "422ac21cdb1d45a8a0814ef00c9769ff",
            "f387685057a6405f86292bd9ce5df000",
            "808dad49922a431d9c43faf48478a069",
            "5c96dd4ef67f4900af004f322706921f",
            "c519b80ce005494caf41456ec90111bf",
            "694f0df64a4b433aa22afef48d968090",
            "75d264b002cc4c3889089fe28f6cfa80",
            "f6a686a076954e0c9c5d11429a14d582",
            "9f512b3c83bf4fcaa1640cf5cdbea8c8",
            "282f350bdadd41fa82b37f527ffe8a63",
            "052465580f854b15be0d29e9dc59125b",
            "619bcc47eac24a098ac5908bddc4297d",
            "0a320f7b8bba47ddb97d2aff966e162f",
            "0e215f7f87fc48bfbb3e74c9c97b23a8",
            "5ab64a9556124cf892f33cc9973240ea",
            "656cb0e3b85c4a57936749caa02f664d",
            "f7ca459667fe48c2a54d0ca13ccfe114",
            "91738a91e20344f1b848ccc39bd0b686",
            "ae85f3dd9b864de7897e02a2313c8093",
            "e97d23572a21475fa4b5b9fa4454d4cc",
            "32f65d2703c048929de10720219fdf53",
            "f9d88bd9fdda49bcbf01366f8fe6fab2",
            "ca5cfab63b2d47869f69b772f9801d69",
            "ea00ba0feb164981bdb521803fd29049",
            "16501e0f5de84fc7bbbdcc9b37f61d85",
            "68db1531b9574e72a2ff0d52995a7347",
            "eeafa1a037dd42a88774f76ea6275360",
            "e891d996e42f425cb2b31d563dfc77ef",
            "216e1650231e471fa0d88e3d73bf6da0",
            "d1dafb9eb15541489d740cbf202fac2f",
            "e362a74248d24aa28ab7dd3500c9d303",
            "1eb78591c14840daaf6741730f2280f8",
            "a2bbd67afcb9463cb0f78d7a24c5f126",
            "ad9c165248ef4e0b9c357316b95f66af",
            "adc06005b98c44f0a6308cbd4f6a3527",
            "eace7bc2187b4dd0af47dbee9327903a",
            "a9f66a8eed1443d099d0fadab83d02e9",
            "292c0b150eb84f06a012e2084b035350",
            "755e3809aa3043f99d3664955a3a2c03",
            "44d07abd85374cca92698119139b140e",
            "00001f9f055045f9ae35f94f76be8fe4",
            "1e7d06e9df9b4a88a003bbba433c1cae",
            "a87f8ff9f575436da0dcf9a31642f7b7",
            "1deae35c0489408fa7e374cd93cca642",
            "260f38a6c52d464999f74443c04cdc03",
            "c16dd57325504698b35f155d1bd040b5",
            "7950d803ab5b4c4ab10dc9e0902e34b1",
            "d151de5a1862426f9d3ab2aaae73f4d9",
            "3963ddae09b14417abf20a566ce82a03",
            "03a8f530cfb0469998f56dcca5f00803",
            "cafc757655d74a2697f4ba566b3623ee",
            "46cd1079cad04e7ea04959e14225b7fb",
            "c508e67d54c24888b82b66108681da19",
            "b08eba43d39846869bdd9050836be1cb",
            "d1837578698f426d8c65a40770a3488c",
            "fdf37a5ac48c477d99318631238a5756",
            "ef504e4ab1384063bff714e1649e0aa3",
            "7b387dec327543f79f957f81fb651cc7",
            "d71e718353ac40788febf07676b3cb25",
            "addf3619a835489f8d9f3ce4498daf36",
            "3315267c32f24d29804c12af760956aa",
            "31fef27ae4d44fa691185c3fa750756a",
            "11db36da26a94bae9ad00e99a10d8c5a",
            "f4bb56cde5b042e8821ee26d25da4ea2",
            "312b0a411cf7451d845fae7b77dff7d6",
            "fa205a1da88e418a881efb0963042e9d",
            "30f6111712e2491198ac03400ef0ce7d",
            "c5323c16a9ca4decbe25c651a14517de",
            "eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "ffe8145192c34433b3140f05b5b2528f",
            "3988d9e57bc841b49a5079130f071dfc",
            "d9bcbb8cd61d4fa5b9e0b95304f8969c",
            "8ea68f6b18c342938de8be19d3896038",
            "0b0c4175d283414ab014c95269b4421b",
            "00c7829ca16746089c8896865f374b1f",
            "f9f77be1c3044483bbd3714a5a45e2ad",
            "b42f3b105ff645dcb58805289594baad",
            "d4214693adb54e44b31fd40e549802b8",
            "b17a0dd6bd24481e8e597415bfc02c87",
            "2c43b4c9b58842acaf321862c3a1625d",
            "99ef066e53974658a59443c917b2c615",
            "98bd45b05dda4319adf853b5104f0a0a",
            "0003c5e497294b5abf83ff5edbf90261",
            "28542ed3d1b443c9a7ba7074825ee208",
            "7c01fc1aabb0486f9f1f0674b46b5481",
            "6b349f8f7890488eaa05b156ec971bf6",
            "1602c7712db64b829a6ed1fa73367a1e",
            "d72812af3cd8475f8a76a8ff3ec236e9",
            "40731cc8e1a245868c9bf6d0972c0467",
            "6f102144e4fd4840b77808f1e6ff7697",
            "82084929de714135a363f5693f4a0aac",
            "f3537b58aca04f398663d6a8f6bd7cf8",
            "0ea16b4f2c6d428191dd7d31d21ad659"
          ]
        },
        "id": "b2ueft2IwxIr",
        "outputId": "4d0bdc1a-4261-4233-cfc0-d686ea8b1e84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a3234bae89d4c1eb7e84da16675cde8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7bd0a23537441b6a41373c7db399423",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc40e712ccca489e8cb2eaadbc47aa54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset glue/mrpc to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "694f0df64a4b433aa22afef48d968090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7ca459667fe48c2a54d0ca13ccfe114",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e891d996e42f425cb2b31d563dfc77ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "755e3809aa3043f99d3664955a3a2c03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03a8f530cfb0469998f56dcca5f00803",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3315267c32f24d29804c12af760956aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9bcbb8cd61d4fa5b9e0b95304f8969c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0003c5e497294b5abf83ff5edbf90261",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHq4Udecy1S6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSdXchNStSMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "pQXS1wenz68U",
        "outputId": "09fec374-2e3b-47d5-d4eb-02ab69561b78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f52e91588ea352bb.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-055028f389e5>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hit %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m: hit 19"
          ]
        }
      ],
      "source": [
        "\n",
        "## Test a batched inference routine: including loss calculations\n",
        "## steps:\n",
        "## 1) tokenize inputs internal to a torch dataset (encode_plus?)\n",
        "## 2) loop through dataloader, with a MLM collator also set?\n",
        "## 3) do inference using teacher\n",
        "## 5) do inference using anathem\n",
        "## 6) loss\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# load dummy dataset\n",
        "dataset_glue = load_dataset('glue', 'mrpc', split='test') # small set\n",
        "\n",
        "# tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "# tokenize\n",
        "dataset_glue = dataset_glue.map(lambda e: tokenizer.encode_plus(e['sentence1'], add_special_tokens=True))\n",
        "print(dataset_glue.features)\n",
        "dataset_glue = dataset_glue.remove_columns(column_names = ['sentence1','sentence2','idx','label'])\n",
        "print(dataset_glue.features)\n",
        "_ = \"\"\"\n",
        "{'sentence1': Value(dtype='string', id=None),\n",
        " 'sentence2': Value(dtype='string', id=None),\n",
        " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
        " 'idx': Value(dtype='int32', id=None),\n",
        " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
        " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
        " \"\"\"\n",
        "\n",
        "# MLM collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")\n",
        "\n",
        "# MLM distillation loss function (kl-divergence between teacher and student outputs)\n",
        "loss_fn_mlm_distil = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "loss_fn_mlm_labels = nn.CrossEntropyLoss(ignore_index=-100) # non-masked tokens have -100\n",
        "weights_mlm_distil = 0.5\n",
        "weights_mlm_labels = (1-weights_mlm_distil)\n",
        "\n",
        "# dataloader with MLM collator\n",
        "dl_mlm = DataLoader(dataset_glue, collate_fn=data_collator, batch_size=4)\n",
        "\n",
        "# optimizer\n",
        "optimizer = AdamW(anamod.parameters(), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "\n",
        "for step_i, batch in enumerate(dl_mlm):\n",
        "\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    # label loss\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "    optimizer.zero_grad()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    #\n",
        "    optimizer.step()\n",
        "\n",
        "    if ((step_i+1) % 20) ==0:\n",
        "        raise NotImplementedError('hit %d' % step_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyCvyxgiqAdm"
      },
      "source": [
        "## MultiTask Training: adapted from s-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "dab6a9ff832540bfae51a3f0dcfedfba",
            "c5adcad970e4455cbf797f14e2e5303e",
            "928bc9d9e240469298d2a267fe3b9e65",
            "24e977d511bd4f03bc8d730cd4c86027",
            "4b4dae6b5bd5474491e1c86a6e462ebf",
            "21f6c046574b4badbf5dac2bd4989d67",
            "e844aa942c604f17b61375f59aad56f3",
            "595530337aab40f6b5cc24d69b3ebaf9",
            "85aa23b715f248248204a2bdf3e5f7ec",
            "3f2b4543fdb94a1d9153de7f18d108be",
            "da3eb201a16240aaa91baf19b49d4209",
            "f53073dd81bf427188a9cfde75c18bff",
            "2b5f6a6687b34036bd5a87c8b61dc2c3",
            "b0546b4b929f4fe3927af49ab119d99a",
            "37e0abc511f04624986368ef45b50131",
            "d365ebcd816a44da80bc74870dd008bd",
            "d265db9a419d4edfbdb91e4bd8f78846",
            "aae2a30b7f474dbcbf55aa677b9518f9",
            "df31cc0682014cdb881817de1c02288f",
            "01fa51a473a6472da89d47bf1116e575",
            "33088ffab85f4898bc39a1167e70388c",
            "1672001c1d7e449f9cc0ce76fcf50fc8",
            "fc2d3eb4b1304b97bf336245736983ec",
            "4d798a40b2a24c4f8ce823023d75ea6a",
            "429379eb4c4f452d94a52521911811a8",
            "49a90c227b9342ddbb670c9fe85591cc",
            "843d11a2271246f49dbabe80fc4762d4",
            "f10d3cde2d7b4121971d8e19e3362b30",
            "4818654025b94f38a631b2bcdf36014c",
            "f68c38cc7bf84db2ab1540ca985599e2",
            "d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "8a1ecdd97d194a9ab63a15980d1e2e31",
            "5dd1df4079d44b1aad849b4a0a5e3b55",
            "2958b232a65d47d7950e040ddd583898",
            "82db512ae4ce4b1fbde3aed3d893e032",
            "8b3982acce834b95a6f318dfb78add1c",
            "3df2e72406454de7ade25cfe0fca7295",
            "979449deb4254629b80f0089584c851a",
            "cd748fe04232441abb30f153e54f9890",
            "8eda2864b2774815bd6d860c1fdf2625",
            "09a93d25cd25426e9c60222b29321889",
            "0db15040be1242378220fa56a21aba28",
            "7834f7deaa3b43669cd0de893fa62448",
            "cfa5b162648c4abca773a478c3e3beb9",
            "2a7388d890b2460c86be4cd32187f319",
            "38b91d162c304c6eaad444f0abffa931",
            "0f331a136adf425f87a1a35682256cd9",
            "1f65726d2e20471e99928e5dc96726c7",
            "dae9d080adfc4bfbba896820bbf57c3b",
            "9ef72b344a964832bd2b19140d230f7b",
            "b719af868833401c86d45d2ae059c868",
            "46f2289d8f6c460892864f1ef5ad8e08",
            "f81a1dd1a8b547b39297478219b41c81",
            "454aeb5a95b94bb580698d8d2f62f43f",
            "a417b74f6fdb4dedbd6bf3408d0dea69",
            "42c13d8f7c694c6599c0a2e10ca0765f",
            "0322aeeda2bd42c1b8ce348bd56424eb",
            "c0908ccc452b42e681765c37a139e878",
            "251219f28bd54de9a608686672dddf0d",
            "e982215023c24a3caf881dd3986cca86",
            "5398b51140574840979cfe9ae2640c96",
            "d6012c2d60024501a1bd8c529bf055e6",
            "d74fd39704b44cea8f012402e7449a80",
            "f5e5dd22e0b24a30a485b54dbdacf1cf",
            "7e61f641028148e988678a2ecbe24a21",
            "df8de4914b3f4c51b4e048f053a0e009",
            "868c8d0c5a4a4535a00dd833ad0dbb6f",
            "7c1ea655a2844e0e81c89529f95acb4c",
            "f4a51d5c122645a5a58acfbadb0cf752",
            "5bd4908665db4c8baac9d52a40a1c28e",
            "000f6133e191461c893cffdc6783a5f9",
            "b5fca62c132b4b9c9af64955480ac905",
            "7081369f016f46ec9ad16edcedd027b0",
            "8631f393c12e4ebaa57838a4f1c1efb0",
            "bc7e0e6c4b154e55875c6fddc0aac6f0",
            "46ff0481a7a94abb9cea91aaacd1ea29",
            "05fd99843ed746d1baf705e6c31881f6"
          ]
        },
        "id": "1C-THFy0tPik",
        "outputId": "5118abac-4cb3-47f3-d368-683d051edb47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab6a9ff832540bfae51a3f0dcfedfba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f53073dd81bf427188a9cfde75c18bff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.88k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc2d3eb4b1304b97bf336245736983ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset multi_nli/default to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2958b232a65d47d7950e040ddd583898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a7388d890b2460c86be4cd32187f319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42c13d8f7c694c6599c0a2e10ca0765f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "868c8d0c5a4a4535a00dd833ad0dbb6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset multi_nli downloaded and prepared to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "### Normal label-based losses (MLI\n",
        "# -- https://huggingface.co/datasets/multi_nli\n",
        "dataset_nli3 = load_dataset('multi_nli', split='train') # 383k examples\n",
        "\n",
        "# I think I should keep the text untokenize for the multi-task, maybe use the default collator from sbert\n",
        "dataset_nli3 = dataset_nli3.remove_columns(\n",
        "    column_names = ['promptID', 'pairID', 'premise_binary_parse', 'premise_parse','hypothesis_binary_parse', 'hypothesis_parse', 'genre']\n",
        ")\n",
        "\n",
        "dl_mli3 = DataLoader(dataset_nli3, batch_size=4, shuffle=True)\n",
        "\n",
        "\n",
        "# make a classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZRIJYI8eBBC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClassifierMNLI3(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size = 512,\n",
        "        do_subtract = True,\n",
        "        dropout = 0.1,\n",
        "        n_labels = 3\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.do_subtract = do_subtract\n",
        "        self.dropout_p = dropout\n",
        "        self.n_labels = n_labels\n",
        "        self.size_of_concatenated_inputs = self.hidden_size*2*2 + self.do_subtract*self.hidden_size*2\n",
        "\n",
        "        # final output\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Dropout(self.dropout_p),\n",
        "            nn.Linear(self.size_of_concatenated_inputs, self.n_labels)\n",
        "        )\n",
        "    def forward(self, input1, input2):\n",
        "        features_concat = torch.concat((\n",
        "            input1,\n",
        "            input2,\n",
        "            torch.sub(input1,input2)\n",
        "        ),axis=1)\n",
        "        return self.layer(features_concat)\n",
        "\n",
        "\n",
        "# Make classifier for MNLI labelled data\n",
        "classifier_mnli3 = ClassifierMNLI3(\n",
        "    hidden_size = anamod.config.hidden_size,\n",
        "    n_labels=3\n",
        ")\n",
        "classifier_mnli3.train()\n",
        "anamod.train()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(anamod.encoder.parameters()) +  list(anamod.pooler.parameters()) + list(classifier_mnli3.parameters()),\n",
        "    lr=0.0001\n",
        ")\n",
        "\n",
        "# make loss function (3 labels)\n",
        "loss_fn_nmli3 = nn.CrossEntropyLoss()\n",
        "weights_mnli_distil = 0.5\n",
        "weights_mnli_labels = (1-weights_mnli_distil)\n",
        "\n",
        "loss_fn_mnli3_distil = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "rBSnisaFT-3O",
        "outputId": "7fa6b430-8619-400b-cf57-20a3c5e76fd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6361832022666931\n",
            "0.5656223297119141\n",
            "0.3880550265312195\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1cec90a56f65>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# NEXT do distillation loss with teacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfeature_teacher_nmli1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mfeature_teacher_nmli2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hypothesis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# MNLI distillation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, batch_mnli in enumerate(dl_mli3):\n",
        "    optimizer.zero_grad()\n",
        "    # get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # mnli predictions n labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # mnli binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label']) * weights_nmli_labels\n",
        "    #loss_cls_nmli3.backward()\n",
        "\n",
        "    # NEXT do distillation loss with teacher\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%3 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "had3LEY4a5rT",
        "outputId": "6e2912df-f412-446d-f31a-f3a8710cbe98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3287630081176758\n",
            "1.1084638833999634\n",
            "1.1774473190307617\n",
            "1.0645709037780762\n",
            "1.091556429862976\n",
            "1.1649658679962158\n",
            "1.319928765296936\n",
            "1.1654601097106934\n",
            "0.9826673865318298\n",
            "1.1563453674316406\n",
            "1.0446501970291138\n",
            "1.1165382862091064\n",
            "1.1049705743789673\n",
            "0.9217707514762878\n",
            "1.14559006690979\n",
            "1.1429061889648438\n",
            "0.9149771928787231\n",
            "1.207316279411316\n",
            "1.1845396757125854\n",
            "1.2629420757293701\n",
            "0.9769338369369507\n",
            "1.0895546674728394\n",
            "1.0898280143737793\n",
            "1.1648684740066528\n",
            "0.9611557126045227\n",
            "1.044935703277588\n",
            "1.144046425819397\n",
            "1.099448561668396\n",
            "1.0884103775024414\n",
            "1.142393946647644\n",
            "1.0853071212768555\n",
            "1.1239224672317505\n",
            "1.0658488273620605\n",
            "1.1993112564086914\n",
            "0.9642707109451294\n",
            "1.182077407836914\n",
            "1.3221166133880615\n",
            "1.1279082298278809\n",
            "1.0723700523376465\n",
            "1.1399314403533936\n",
            "1.0013256072998047\n",
            "1.1049387454986572\n",
            "1.0147031545639038\n",
            "1.2314361333847046\n",
            "1.0651648044586182\n",
            "1.1327135562896729\n",
            "0.9887092709541321\n",
            "1.0250582695007324\n",
            "1.1199613809585571\n",
            "1.094027042388916\n",
            "1.091330885887146\n",
            "1.098750114440918\n",
            "1.1193275451660156\n",
            "1.1657143831253052\n",
            "1.0800719261169434\n",
            "1.152091383934021\n",
            "1.1550073623657227\n",
            "1.0005279779434204\n",
            "1.063902497291565\n",
            "1.0364967584609985\n",
            "1.0193161964416504\n",
            "1.1669244766235352\n",
            "1.055404543876648\n",
            "1.2059553861618042\n",
            "1.1156867742538452\n",
            "1.1356735229492188\n",
            "1.1261953115463257\n",
            "1.0520744323730469\n",
            "1.0741896629333496\n",
            "1.0739905834197998\n",
            "1.1333951950073242\n",
            "1.0113921165466309\n",
            "1.1244165897369385\n",
            "1.1339558362960815\n",
            "1.125321626663208\n",
            "1.0819061994552612\n",
            "1.1043788194656372\n",
            "1.108479380607605\n",
            "1.148271083831787\n",
            "1.0951212644577026\n",
            "1.1449416875839233\n",
            "1.0795189142227173\n",
            "1.1403652429580688\n",
            "1.086578130722046\n",
            "1.0184922218322754\n",
            "1.1535804271697998\n",
            "1.0355476140975952\n",
            "1.120854377746582\n"
          ]
        }
      ],
      "source": [
        "# Combine the teacher training with classification\n",
        "optimizer = AdamW(list(anamod.parameters()) + list(classifier_mnli3.parameters()), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "for i,(batch_mlm, batch_mnli) in enumerate(zip(dl_mlm, dl_mli3)):\n",
        "    optimizer.zero_grad()\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # mlm teacher outputs\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "        # to do this, I'd need to have the original text, and NOT pre-tokenized text\n",
        "        #teacher_emb(input_text=batch['premise'], prepend = 'passage: ')\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    #loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    #loss_mlm_distil.backward()\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "\n",
        "    # loss on paragraph embedding\n",
        "\n",
        "    # BACKPROP MLM label loss and distilloss\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "\n",
        "    # NLI task: get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label'])\n",
        "    #loss_cls_nmli3.backward()\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%4 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "NWWBkB_gqEkE",
        "outputId": "6a69aabe-43c8-42bc-dd5f-f15a8840b73d"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8c7bf2d1f796>\"\u001b[0;36m, line \u001b[0;32m319\u001b[0m\n\u001b[0;31m    self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "class TrainerMultiTask:\n",
        "    \"\"\"Adapted from the uklab/sentence-transformers .fit() function\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            do_reload = True,\n",
        "            epochs_total_lifetime = 5,\n",
        "            scheduler: str = 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            output_path: str = None,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = False,\n",
        "            checkpoint_path: str = 'checkpoint.pt',\n",
        "            checkpoint_path_optimizer: str = 'checkpoint_optimizer.pt',\n",
        "            checkpoint_path_scheduler: str = 'checkpoint_scheduler.pt',\n",
        "            checkpoint_path_trainer_state: str = 'checkpoint_trainer_state.json',\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 0,\n",
        "            do_minimize_global_objective: Int = 1\n",
        "        ):\n",
        "            self.epochs_global = -1 # track the total number of epochs\n",
        "            self.epochs_total_lifetime = epochs_total_lifetime # total number of epochs over lifetime\n",
        "            self.global_step = 0 # track the toatl number of steps\n",
        "            self.do_minimize = do_minimize_global_objective\n",
        "            self.best_score = 9999999 if self.do_minimize else -9999999\n",
        "            self.output_path = output_path\n",
        "            self.checkpoint_path = checkpoint_path\n",
        "            self.checkpoint_path_optimizer = checkpoint_path_optimizer\n",
        "            self.checkpoint_path_scheduler = checkpoint_path_scheduler\n",
        "            self.checkpoint_path_trainer_state = checkpoint_path_trainer_state\n",
        "            self.scheduler_state_dict = None\n",
        "            self.optimizer_state_dict = None\n",
        "            self.trainer_state = None\n",
        "            self.loss_models_states = None\n",
        "            if do_reload:\n",
        "                print('attempting to reload cached model, optimizer, scheduler, and saved trainer sate')\n",
        "                model_state, loss_models_states = self.load_saved_model(self.checkpoint_path)\n",
        "                self.model_state = model_state\n",
        "                self.loss_models_states = loss_models_states\n",
        "                self.scheduler_state_dicts = self.load_saved_scheduler(self.checkpoint_path_scheduler)\n",
        "                self.optimizer_state_dicts = self.load_saved_optimizer(self.checkpoint_path_optimizer)\n",
        "                self.trainer_state = self.load_saved_trainer_state(self.checkpoint_path_trainer_state)\n",
        "\n",
        "    def fit(self,\n",
        "            train_objectives: Iterable[Tuple[DataLoader, nn.Module]],\n",
        "            model=None,\n",
        "            weights_train_objectives:List = None,\n",
        "            teachers: List = None,\n",
        "            evaluator: SentenceEvaluator = None,\n",
        "            epochs: int = 1,\n",
        "            epochs_total_lifetime = None,\n",
        "            steps_per_epoch = None,\n",
        "            scheduler: str = None, # 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = True,\n",
        "            checkpoint_path = None,\n",
        "            checkpoint_path_optimizer= None,\n",
        "            checkpoint_path_scheduler= None,\n",
        "            checkpoint_path_trainer_config= None,\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 2\n",
        "            ):\n",
        "        \"\"\"\n",
        "        Train the model with the given training objective\n",
        "        Each training objective is sampled in turn for one batch.\n",
        "        We sample only as many batches from each objective as there are in the smallest one\n",
        "        to make sure of equal training with each dataset.\n",
        "\n",
        "        :param train_objectives: Tuples of (DataLoader, LossFunction). Pass more than one for multi-task learning\n",
        "        :param evaluator: An evaluator (sentence_transformers.evaluation) evaluates the model performance during training on held-out dev data. It is used to determine the best model that is saved to disc.\n",
        "        :param epochs: Number of epochs for training\n",
        "        :param steps_per_epoch: Number of training steps per epoch. If set to None (default), one epoch is equal the DataLoader size from train_objectives.\n",
        "        :param scheduler: Learning rate scheduler. Available schedulers: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        :param warmup_steps: Behavior depends on the scheduler. For WarmupLinear (default), the learning rate is increased from o up to the maximal learning rate. After these many training steps, the learning rate is decreased linearly back to zero.\n",
        "        :param optimizer_class: Optimizer\n",
        "        :param optimizer_params: Optimizer parameters\n",
        "        :param weight_decay: Weight decay for model parameters\n",
        "        :param evaluation_steps: If > 0, evaluate the model using evaluator after each number of training steps\n",
        "        :param output_path: Storage path for the model and evaluation files\n",
        "        :param save_best_model: If true, the best model (according to evaluator) is stored at output_path\n",
        "        :param max_grad_norm: Used for gradient normalization.\n",
        "        :param use_amp: Use Automatic Mixed Precision (AMP). Only for Pytorch >= 1.6.0\n",
        "        :param callback: Callback function that is invoked after each evaluation.\n",
        "                It must accept the following three parameters in this order:\n",
        "                `score`, `epoch`, `steps`\n",
        "        :param show_progress_bar: If True, output a tqdm progress bar\n",
        "        :param checkpoint_path: Folder to save checkpoints during training\n",
        "        :param checkpoint_save_steps: Will save a checkpoint after so many steps\n",
        "        :param checkpoint_save_total_limit: Total number of checkpoints to store\n",
        "        \"\"\"\n",
        "        if self.model_state is not None:\n",
        "            print('reloading saved model state into model')\n",
        "            model.load_state_dict(self.model_state)\n",
        "            self.model = model\n",
        "\n",
        "        # paths (optional update)\n",
        "        self.checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        self.checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        self.checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        self.checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "        self._target_device = model.device\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.weight_decay = weight_decay\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.optimizer_params = optimizer_params\n",
        "        self.evaluation_steps = evaluation_steps\n",
        "\n",
        "        if use_amp:\n",
        "            from torch.cuda.amp import autocast\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        #self.to(self._target_device)\n",
        "\n",
        "        dataloaders = [dataloader for dataloader, _ in train_objectives]\n",
        "\n",
        "        # Use smart batching\n",
        "        if len(collators)==0 or collators is None:\n",
        "            print('using default batch collators')\n",
        "        for dli, dataloader in enumerate(dataloaders):\n",
        "            if dataloader.collate_fn is None:\n",
        "                print('using default batch collators for dataloader %d' % dli)\n",
        "                dataloader.collate_fn = self.smart_batching_collate\n",
        "\n",
        "        loss_models = [loss for _, loss in train_objectives]\n",
        "        for midx, loss_model in enumerate(loss_models):\n",
        "            if self.loss_models_states is not None:\n",
        "                # reload each loss_model.classifier's saved states\n",
        "                if hassattr(loss_model, 'classifier'):\n",
        "                    loss_model.classifier.load_state_dict(self.loss_models_states[midx])\n",
        "            loss_model.to(self._target_device)\n",
        "\n",
        "        if steps_per_epoch is None or steps_per_epoch == 0:\n",
        "            steps_per_epoch = min([len(dataloader) for dataloader in dataloaders])\n",
        "\n",
        "        if epochs_total_lifetime is None:\n",
        "            epochs_total_lifetime = self.epochs_total_lifetime\n",
        "        num_train_steps = int(steps_per_epoch * epochs_total_lifetime)\n",
        "\n",
        "        # Prepare optimizers\n",
        "        #optimizers = []\n",
        "        #schedulers = []\n",
        "        #for model_idx, loss_model in enumerate(loss_models):\n",
        "        #    param_optimizer = list(loss_model.named_parameters())#\n",
        "        #    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        #    optimizer_grouped_parameters = [\n",
        "        #        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "        #        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        #    ]\n",
        "        #    optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        #    scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        #    if self.optimizer_state_dicts is not None:\n",
        "        #        # reload optimizer states\n",
        "        #        optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "        #    if self.scheduler_state_dicts is not None:\n",
        "        #        # relead scheduler states\n",
        "        #        scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "        #    optimizers.append(optimizer)\n",
        "        #    schedulers.append(scheduler_obj)\n",
        "\n",
        "        # from: https://stackoverflow.com/questions/46377599/when-to-use-individual-optimizers-in-pytorch\n",
        "        optimizer_parameters = set()\n",
        "        for model_idx, loss_model in enumerate(loss_models):\n",
        "            optimizer_parameters |= loss_model.named_parameters()\n",
        "\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in optimizer_parameters if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in optimizer_parameters if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        if self.optimizer_state_dicts is not None:\n",
        "            # reload optimizer states\n",
        "            #optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "            optimizer.load_state_dict(self.optimizer_state_dicts)\n",
        "        if self.scheduler_state_dicts is not None:\n",
        "            # relead scheduler states\n",
        "            #scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "            scheduler_obj.load_state_dict(self.scheduler_state_dicts)\n",
        "\n",
        "        global_step = self.global_step\n",
        "        data_iterators = [iter(dataloader) for dataloader in dataloaders]\n",
        "\n",
        "        num_train_objectives = len(train_objectives)\n",
        "\n",
        "        for epoch in trange(epochs, desc=\"Epoch\", disable=not show_progress_bar):\n",
        "            self.epochs_global += epoch\n",
        "            training_steps = 0\n",
        "\n",
        "            for loss_model in loss_models:\n",
        "                loss_model.zero_grad()\n",
        "                loss_model.train()\n",
        "\n",
        "            for _ in trange(steps_per_epoch, desc=\"Iteration\", smoothing=0.05, disable=not show_progress_bar):\n",
        "\n",
        "                # loop through multiple tasks\n",
        "                for train_idx in range(num_train_objectives):\n",
        "                    loss_model = loss_models[train_idx]\n",
        "                    loss_weight = weights_train_objectives[train_idx]\n",
        "                    teacher = teachers[train_idx]\n",
        "                    optimizer = optimizers[train_idx]\n",
        "                    scheduler = schedulers[train_idx]\n",
        "                    data_iterator = data_iterators[train_idx]\n",
        "\n",
        "                    try:\n",
        "                        data = next(data_iterator)\n",
        "                    except StopIteration:\n",
        "                        data_iterator = iter(dataloaders[train_idx])\n",
        "                        data_iterators[train_idx] = data_iterator\n",
        "                        data = next(data_iterator)\n",
        "\n",
        "                    features, labels = data\n",
        "                    features = list(map(lambda batch: batch_to_device(batch, self._target_device), features))\n",
        "                    if labels is not None:\n",
        "                        labels = labels.to(self._target_device)\n",
        "\n",
        "                    loss_value = loss_model(features, labels, teacher=teacher)\n",
        "                    loss_value *= loss_weight\n",
        "                    loss_value.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad_norm)\n",
        "                optimizers.step()\n",
        "                optimizers.zero_grad()\n",
        "                schedulers.step()\n",
        "\n",
        "                # TODO: integrate amp: https://discuss.pytorch.org/t/ddp-amp-gradient-accumulation-calling-optimizer-step-leads-to-nan-loss/162624\n",
        "                training_steps += 1\n",
        "                global_step += 1\n",
        "                self.global_step = global_step\n",
        "\n",
        "                if evaluation_steps > 0 and training_steps % evaluation_steps == 0:\n",
        "                    self._eval_during_training(evaluator, output_path, save_best_model, epoch, training_steps, callback)\n",
        "\n",
        "                    for loss_model in loss_models:\n",
        "                        loss_model.zero_grad()\n",
        "                        loss_model.train()\n",
        "\n",
        "                if self.checkpoint_path is not None and checkpoint_save_steps is not None and checkpoint_save_steps > 0 and global_step % checkpoint_save_steps == 0:\n",
        "                    self._save_checkpoint(\n",
        "                        model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "                    )\n",
        "\n",
        "            self._eval_during_training(evaluator, output_path, save_best_model, epoch, -1, callback)\n",
        "\n",
        "        #if evaluator is None and output_path is not None:   #No evaluator, but output path: save final model version\n",
        "        #    self.save(output_path)\n",
        "\n",
        "        if checkpoint_path is not None:\n",
        "            self._save_checkpoint(\n",
        "                model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "            )\n",
        "\n",
        "    def evaluate(self, evaluator: SentenceEvaluator, output_path: str = None):\n",
        "        \"\"\"\n",
        "        Evaluate the model\n",
        "\n",
        "        :param evaluator:\n",
        "            the evaluator\n",
        "        :param output_path:\n",
        "            the evaluator can write the results to this path\n",
        "        \"\"\"\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "        return evaluator(self, output_path)\n",
        "\n",
        "    def _eval_during_training(self, evaluator, output_path, save_best_model, epoch, steps, callback):\n",
        "        \"\"\"Runs evaluation during the training\"\"\"\n",
        "        eval_path = output_path\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "            eval_path = os.path.join(output_path, \"eval\")\n",
        "            os.makedirs(eval_path, exist_ok=True)\n",
        "\n",
        "        if evaluator is not None:\n",
        "            score = evaluator(self, output_path=eval_path, epoch=epoch, steps=steps)\n",
        "            if callback is not None:\n",
        "                callback(score, epoch, steps)\n",
        "            if score > self.best_score:\n",
        "                self.best_score = score\n",
        "                if save_best_model:\n",
        "                    self.save(output_path)\n",
        "\n",
        "    def _save_checkpoint(\n",
        "        self,\n",
        "        model,\n",
        "        optimizers,\n",
        "        schedulers,\n",
        "        loss_models,\n",
        "        checkpoint_save_total_limit,\n",
        "        step,\n",
        "        checkpoint_path = None,\n",
        "        checkpoint_path_optimizer = None,\n",
        "        checkpoint_path_scheduler = None,\n",
        "        checkpoint_path_trainer_state =None\n",
        "    ):\n",
        "        # Store new checkpoint\n",
        "        checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "\n",
        "        # model states\n",
        "        self.model_state = model.state_dict()\n",
        "        self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'model_state_dict':self.model_state,\n",
        "            'loss_models_state_dicts':self.loss_models_states,\n",
        "        }, \"%s-%08g\" % (checkpoint_path, step))\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer_state_dicts = optimizers.state_dict() #[opt.state_dict() for opt in optimizers],\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'optimizer_state_dicts':self.optimizer_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_optimizer, step))\n",
        "\n",
        "        # scheduler\n",
        "        self.scheduler_state_dicts = schedulers.state_dict() #[scheduler.state_dict() for scheduler in schedulers]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'scheduler_state_dicts':self.scheduler_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_scheduler, step))\n",
        "\n",
        "        # trainer info\n",
        "        with open(checkpoint_path_trainer_state, 'w') as jcon:\n",
        "            trainer_objs_to_save = {\n",
        "                'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "                'max_grad_norm':self.max_grad_norm,\n",
        "                'weight_decay':self.weight_decay,\n",
        "                'warmup_steps':self.warmup_steps,\n",
        "                'optimizer_params':self.optimizer_params,\n",
        "                'evaluation_steps':self.evaluation_steps,\n",
        "                'checkpoint_path_optimizer': \"%s-%08g\" % (checkpoint_path_optimizer, step),\n",
        "                'checkpoint_path_scheduler': \"%s-%08g\" % (checkpoint_path_scheduler, step),\n",
        "            }\n",
        "            json.dump(trainer_objs_to_save, jcon)\n",
        "\n",
        "        # Delete old checkpoints\n",
        "        if checkpoint_save_total_limit is not None and checkpoint_save_total_limit > 0:\n",
        "            old_checkpoints = []\n",
        "            dir_to_checkpoints = \"/\".join(checkpoint_path.split('/')[:-1])\n",
        "            for f in os.listdir(dir_to_checkpoints):\n",
        "                if bool(re.search('(\\-[0-9]+$',f)) & (checkpoint_path in f):\n",
        "                    # get step of saved checkpoint\n",
        "                    old_pt_step = int(re.search('(?<=\\-)[0-9]+$',f).group())\n",
        "                    old_checkpoints.append({\n",
        "                        'step': old_pt_step, 'path': os.path.join(dir_to_checkpoints, f)\n",
        "                    })\n",
        "\n",
        "            if len(old_checkpoints) > checkpoint_save_total_limit:\n",
        "                old_checkpoints = sorted(old_checkpoints, key=lambda x: x['step'])\n",
        "                oldest_step = old_checkpoints[0]['step']\n",
        "                for old_checkpoint in old_checkpoints:\n",
        "                    if old_checkpoint['step']==oldest_step:\n",
        "                        print('deleting old checkpoint: %s' % old_checkpoint['path'])\n",
        "                        shutil.rmtree(old_checkpoint['path'])\n",
        "\n",
        "    def _grab_loss_states(loss_model):\n",
        "        \"\"\"Gets the loss_model.state_dict() for a model embedded in a loss function\"\"\"\n",
        "        return loss_model.classifier.state_dict()\n",
        "\n",
        "    def load_saved_model(checkpoint_path=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path = self.checkpoint_path if checkpoint_path is None else checkpoint_path\n",
        "        saved_dict = torch.load(checkpoint_path)\n",
        "        return saved_dict['model_state_dict'], saved_dict['loss_models_state_dicts']\n",
        "\n",
        "    def load_saved_scheduler(checkpoint_path_scheduler=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_scheduler = self.checkpoint_path_scheduler if checkpoint_path_scheduler is None else checkpoint_path_scheduler\n",
        "        saved_dict = torch.load(checkpoint_path_scheduler)\n",
        "        return saved_dict['scheduler_state_dicts']\n",
        "\n",
        "    def load_saved_optimizer(checkpoint_path_optimizer=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_optimizer = self.checkpoint_path_optimizer if checkpoint_path_optimizer is None else checkpoint_path_optimizer\n",
        "        saved_dict = torch.load(checkpoint_path_optimizer)\n",
        "        return saved_dict['optimizer_state_dicts']\n",
        "\n",
        "    def load_saved_trainer_state(checkpoint_path_trainer_state):\n",
        "        checkpoint_path_trainer_state = self.checkpoint_path_trainer_state if checkpoint_path_trainer_state is None else checkpoint_path_trainer_state\n",
        "        with open(checkpoint_path_trainer_state, 'r') as jcon:\n",
        "            trainer_state = json.load(jcon)\n",
        "        self.epochs_global = trainer_state['epochs_global']\n",
        "        self.global_step = trainer_state['global_step']\n",
        "        self.step = trainer_state['step']\n",
        "        self.max_grad_norm = trainer_state['max_grad_norm']\n",
        "        self.weight_decay = trainer_state['weight_decay']\n",
        "        self.warmup_steps = trainer_state['warmup_steps']\n",
        "        self.optimizer_params = trainer_state['optimizer_params']\n",
        "        self.evaluation_steps = trainer_state['evaluation_steps']\n",
        "\n",
        "    def _load_auto_model(self, model_name_or_path):\n",
        "        \"\"\"\n",
        "        Creates a simple Transformer + Mean Pooling model and returns the modules\n",
        "        \"\"\"\n",
        "        logger.warning(\"No sentence-transformers model found with name {}. Creating a new one with MEAN pooling.\".format(model_name_or_path))\n",
        "        transformer_model = Transformer(model_name_or_path)\n",
        "        pooling_model = Pooling(transformer_model.get_word_embedding_dimension(), 'mean')\n",
        "        return [transformer_model, pooling_model]\n",
        "\n",
        "    def _load_sbert_model(self, model_path):\n",
        "        \"\"\"\n",
        "        Loads a full sentence-transformers model\n",
        "        \"\"\"\n",
        "        # Check if the config_sentence_transformers.json file exists (exists since v2 of the framework)\n",
        "        config_sentence_transformers_json_path = os.path.join(model_path, 'config_sentence_transformers.json')\n",
        "        if os.path.exists(config_sentence_transformers_json_path):\n",
        "            with open(config_sentence_transformers_json_path) as fIn:\n",
        "                self._model_config = json.load(fIn)\n",
        "\n",
        "            if '__version__' in self._model_config and 'sentence_transformers' in self._model_config['__version__'] and self._model_config['__version__']['sentence_transformers'] > __version__:\n",
        "                logger.warning(\"You try to use a model that was created with version {}, however, your version is {}. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\\n\\n\\n\".format(self._model_config['__version__']['sentence_transformers'], __version__))\n",
        "\n",
        "        # Check if a readme exists\n",
        "        model_card_path = os.path.join(model_path, 'README.md')\n",
        "        if os.path.exists(model_card_path):\n",
        "            try:\n",
        "                with open(model_card_path, encoding='utf8') as fIn:\n",
        "                    self._model_card_text = fIn.read()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Load the modules of sentence transformer\n",
        "        modules_json_path = os.path.join(model_path, 'modules.json')\n",
        "        with open(modules_json_path) as fIn:\n",
        "            modules_config = json.load(fIn)\n",
        "\n",
        "        modules = OrderedDict()\n",
        "        for module_config in modules_config:\n",
        "            module_class = import_from_string(module_config['type'])\n",
        "            module = module_class.load(os.path.join(model_path, module_config['path']))\n",
        "            modules[module_config['name']] = module\n",
        "\n",
        "        return modules\n",
        "\n",
        "    @staticmethod\n",
        "    def load(input_path):\n",
        "        return SentenceTransformer(input_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_scheduler(optimizer, scheduler: str, warmup_steps: int, t_total: int):\n",
        "        \"\"\"\n",
        "        Returns the correct learning rate scheduler. Available scheduler: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        \"\"\"\n",
        "        scheduler = scheduler.lower()\n",
        "        if scheduler == 'constantlr':\n",
        "            return transformers.get_constant_schedule(optimizer)\n",
        "        elif scheduler == 'warmupconstant':\n",
        "            return transformers.get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
        "        elif scheduler == 'warmuplinear':\n",
        "            return transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosine':\n",
        "            return transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosinewithhardrestarts':\n",
        "            return transformers.get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown scheduler {}\".format(scheduler))\n",
        "\n",
        "    @property\n",
        "    def device(self) -> device:\n",
        "        \"\"\"\n",
        "        Get torch.device from module, assuming that the whole module has one device.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return next(self.parameters()).device\n",
        "        except StopIteration:\n",
        "            # For nn.DataParallel compatibility in PyTorch 1.5\n",
        "\n",
        "            def find_tensor_attributes(module: nn.Module) -> List[Tuple[str, Tensor]]:\n",
        "                tuples = [(k, v) for k, v in module.__dict__.items() if torch.is_tensor(v)]\n",
        "                return tuples\n",
        "\n",
        "            gen = self._named_members(get_members_fn=find_tensor_attributes)\n",
        "            first_tuple = next(gen)\n",
        "            return first_tuple[1].device\n",
        "\n",
        "    @property\n",
        "    def tokenizer(self):\n",
        "        \"\"\"\n",
        "        Property to get the tokenizer that is used by this model\n",
        "        \"\"\"\n",
        "        return self.model.tokenizer\n",
        "\n",
        "    #@tokenizer.setter\n",
        "    #def tokenizer(self, value):\n",
        "    #    self._first_module().tokenizer = value\n",
        "\n",
        "    @property\n",
        "    def max_seq_length(self):\n",
        "        \"\"\"\n",
        "        Property to get the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        return self.model._first_module().max_seq_length\n",
        "\n",
        "    @max_seq_length.setter\n",
        "    def max_seq_length(self, value):\n",
        "        \"\"\"\n",
        "        Property to set the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        self.model._first_module().max_seq_length = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2hwROspo0uI"
      },
      "source": [
        "### Load a Standard Dataset for MLM task\n",
        "\n",
        "Also need to grab datasets here: https://arxiv.org/pdf/1908.08962.pdf\n",
        "\n",
        "```\n",
        "    The Pile dataset looks good: https://pile.eleuther.ai/\n",
        "    https://arxiv.org/abs/2101.00027\n",
        "    PubMed Central, ArXiv, GitHub, the FreeLaw Project, Stack Exchange, the US\n",
        "    Patent and Trademark Office, PubMed, Ubuntu IRC, HackerNews, YouTube, PhilPapers, and NIH ExPorter.\n",
        "    We also introduce OpenWebText2 and\n",
        "    BookCorpus2, which are extensions of the original\n",
        "    OpenWebText (Gokaslan and Cohen, 2019) and\n",
        "    BookCorpus (Zhu et al., 2015; Kobayashi, 2018)\n",
        "    datasets, respectively.\n",
        "    In addition, we incorporate several existing highquality datasets: Books3 (Presser, 2020), Project Gutenberg (PG-19) (Rae et al., 2019), OpenSubtitles (Tiedemann, 2016), English Wikipedia, DM Mathematics (Saxton et al., 2019), EuroParl\n",
        "    (Koehn, 2005), and\n",
        "\n",
        "    ABout the law:\n",
        "    and other metadata, we focused specifically on\n",
        "    court opinions due to an abundance of full-text\n",
        "    entries. This data is entirely within the public domain.\n",
        "\n",
        "```\n",
        "\n",
        "Scientific Papers: You can use the scientific_papers dataset, which includes a large collection of scientific papers from various domains. It covers research articles from fields such as computer science, physics, biology, and more.\n",
        "\n",
        "Patents: The patent_citations dataset contains patent text data along with citation information, making it suitable for training language models with a focus on technical and scientific domains.\n",
        "\n",
        "ArXiv: The arxiv dataset includes research papers from the arXiv repository, covering a wide range of scientific disciplines. It can be used to enhance the exposure of your model to academic literature.\n",
        "\n",
        "PubMed: The pubmed dataset consists of abstracts from biomedical research articles indexed in PubMed. It is a valuable resource if you want to incorporate biomedical and life sciences content into your MLM pretraining.\n",
        "\n",
        "joelito/Multi_Legal_Pile - use subset `en_all` to access EU-courts, and other datasets\n",
        "\n",
        "\n",
        "Looks like streaming data is available:\n",
        "https://huggingface.co/learn/nlp-course/chapter5/4?fw=pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-boy1-ZoqWI",
        "outputId": "36b03ab8-16c2-4d02-e034-a6d96f9262ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynndescent\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (1.10.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (0.56.4)\n",
            "Requirement already satisfied: llvmlite>=0.30 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (0.39.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->pynndescent) (67.7.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->pynndescent) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Building wheels for collected packages: langdetect, pynndescent\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=a1083920b91aa38521e7313c8b1532e5b7f90b577995a75a7e375862f74e2d2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=0f7d71c3f4048a46c298778e841131942e4d7eee2ab52a81cf9dc8c0605ab667\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built langdetect pynndescent\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, rank_bm25, langdetect, dill, multiprocess, huggingface-hub, transformers, pynndescent, datasets\n",
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 langdetect-1.0.9 multiprocess-0.70.15 pynndescent-0.5.10 rank_bm25-0.2.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1 xxhash-3.3.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "### Load a standard dataset\n",
        "%pip install transformers datasets zstandard rank_bm25 langdetect pynndescent\n",
        "# need the zstandard to use the streaming data function from huggingface datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0KGmDMqKlxC4"
      },
      "outputs": [],
      "source": [
        "import lzma\n",
        "from datasets import load_dataset\n",
        "from itertools import islice\n",
        "from datasets import interleave_datasets # for interweaving streaming datasets\n",
        "#from transformers import BertTokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from langdetect import detect\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoEELjudRvL_"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pI0G9zyjuH-6"
      },
      "outputs": [],
      "source": [
        "def check_is_code(text):\n",
        "    \"\"\"Estimates a ratio of special char (that may indicate math/code notation); less than 10% is code for normal text\"\"\"\n",
        "    nchar = min(5000,len(text))\n",
        "    nchar_after_removespecialchar = len(re.sub(r\"[\\<\\>\\_\\@\\^\\=\\+\\*\\$\\{\\[\\]\\}\\(\\)\\/\\\\\\.]\",'',text[:5000]))\n",
        "    ratio_specialchar = 1-nchar_after_removespecialchar/nchar\n",
        "    return ratio_specialchar\n",
        "\n",
        "def check_language(text, special_char_threshold=0.10):\n",
        "    \"\"\"Verifies that a string is: i) English, and ii) not overly mathematical/code\"\"\"\n",
        "    ratio_specialchar = check_is_code(text)\n",
        "    if ratio_specialchar>=special_char_threshold:\n",
        "        return False, ratio_specialchar\n",
        "    try:\n",
        "        is_eng = detect(text[:200]+\" hello\")=='en'\n",
        "        return is_eng, -1\n",
        "    except:\n",
        "        return False, -1\n",
        "\n",
        "if False:\n",
        "    bad_language = []\n",
        "    good_language = []\n",
        "    foo = load_dataset(\"EleutherAI/the_pile_deduplicated\", split='train',streaming=True).shuffle(buffer_size=20000).take(20000)\n",
        "    for e in foo:\n",
        "        is_good, ratiospecialchar = check_language(e['text'])\n",
        "        if not is_good:\n",
        "            bad_language.append((e['text'], ratiospecialchar))\n",
        "        else:\n",
        "            if ratiospecialchar>0.025:\n",
        "                good_language.append((e['text'], ratiospecialchar))\n",
        "\n",
        "    print(len(bad_language)); print(len(good_language))\n",
        "    bad_language = [p for p in bad_language if p[-1]>0]\n",
        "    bad_language = sorted(zip([score for _,score in bad_language],[w for w,_ in bad_language]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "30h2nnzWnDpz"
      },
      "outputs": [],
      "source": [
        "\n",
        "CHAR_PER_WORD = 6.36\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "config = {\n",
        "    'max_seq_length':512,\n",
        "    'min_seq_length':48,\n",
        "    'max_chunk_size':6,\n",
        "    'min_sentence_len':20,\n",
        "    'seed':42\n",
        "}\n",
        "\n",
        "\n",
        "class ExampleProcessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=config,\n",
        "        char_per_word = CHAR_PER_WORD,\n",
        "        nlp =nlp,\n",
        "    ):\n",
        "        self.nlp = nlp\n",
        "        self.char_per_word = char_per_word\n",
        "        self.max_seq_length = config.get('max_seq_length', 512) # maximum word-length for chunks for mlm objective (else split)\n",
        "        self.min_seq_length = config.get('min_seq_length', 128) # min sequence length for chunks (else discard\n",
        "        self.max_chunk_size = config.get('max_chunk_size', 5) # maximum number of chunks of text to take (each ~512 in length)\n",
        "        self.min_sentence_len = config.get('min_sentence_len', 20) # for next-sentence, min sentence size to merge together\n",
        "        self.seed = config.get('seed', 42)\n",
        "        self.max_chunk_length = self.max_chunk_size * self.max_seq_length\n",
        "        self.max_chunk_length_char = int(self.max_chunk_length*self.char_per_word)\n",
        "        self.min_seq_length_char = int(self.min_seq_length*self.char_per_word)\n",
        "        self.min_sentence_length_char = int(self.min_sentence_len*self.char_per_word)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_into_chunks(text, chunk_char_size, overlapping_size = 50):\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        end = chunk_char_size + overlapping_size\n",
        "        while start < len(text):\n",
        "            chunk = text[start:end]\n",
        "            period_index = chunk.find(\". \")\n",
        "            if period_index != -1:\n",
        "                chunk = chunk[period_index + 1:]\n",
        "            else:\n",
        "                first_space_index = chunk.find(\" \")\n",
        "                if first_space_index != -1:\n",
        "                    chunk = chunk[first_space_index + 1:]\n",
        "            # Check if the chunk has been split and contains more than one word\n",
        "            #if start > 0 and \" \" in chunk:\n",
        "            if end < len(text) and \" \" in chunk and chunk[-1]!=\" \":\n",
        "                last_space_index = chunk.rfind(\" \")\n",
        "                chunk = chunk[:last_space_index]\n",
        "            chunks.append(chunk)\n",
        "            start += chunk_char_size\n",
        "            end += chunk_char_size\n",
        "        return chunks\n",
        "\n",
        "    def split_chunk_into_sentences(self, chunk, discard_first_sentence=True, discard_last_sentence=True ):\n",
        "        doc = self.nlp(chunk)\n",
        "        MAX_CHAR_LEN = int(self.max_seq_length*self.char_per_word)\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        if discard_first_sentence:\n",
        "            sentences = sentences[1:]\n",
        "        if discard_last_sentence:\n",
        "            sentences = sentences[:-1]\n",
        "\n",
        "        super_list_concatenated = [] # accumulates concatenated sentences\n",
        "        super_list_raw_sentences = [] # accumulates raw sentences (for next-sentence prediction)\n",
        "        buffer = []\n",
        "        buffer_len = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_len = len(sentence)\n",
        "\n",
        "            if buffer_len + sentence_len > MAX_CHAR_LEN:\n",
        "                super_list_concatenated.append(\" \".join(buffer))\n",
        "                super_list_raw_sentences.extend(buffer)\n",
        "                buffer = []\n",
        "                buffer_len = 0\n",
        "\n",
        "            buffer.append(sentence)\n",
        "            buffer_len += sentence_len\n",
        "\n",
        "        if buffer:  # If there are any remaining sentences in the buffer\n",
        "            super_list_concatenated.append(\" \".join(buffer))\n",
        "            super_list_raw_sentences.extend(buffer)\n",
        "\n",
        "        return super_list_concatenated, super_list_raw_sentences\n",
        "\n",
        "    def _sample_chunk_span(self, text, max_chunk_length_char):\n",
        "        chunks = self.split_into_chunks(text, max_chunk_length_char)\n",
        "        # randomly sample from the chunks\n",
        "        #FOOBAR SAMPLE FROM CHUNKS\n",
        "        return random.choice(chunks)\n",
        "\n",
        "    def is_too_small_quickcheck(self, text, textlen=None):\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.min_seq_length_char*0.9\n",
        "\n",
        "    def is_too_small(self, nwords):\n",
        "        return nwords < self.min_seq_length\n",
        "\n",
        "    def is_larger_than_max_chunk_quickcheck(self, text, textlen):\n",
        "        \"\"\"if it is larger than a chunksize, then we need to sample chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen > self.max_chunk_length_char\n",
        "\n",
        "    def is_short_than_a_chunk(self, text, textlen):\n",
        "        \"\"\"if it is shorter than a chunk, then we'll take all text, in chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.max_chunk_length_char\n",
        "\n",
        "    def is_smaller_than_two_paragraphs(self, text):\n",
        "        charlen = len(text)\n",
        "        if charlen < (1.5*self.max_seq_length*self.char_per_word):\n",
        "            return True, re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        if charlen > (2.5*self.max_seq_length*self.char_per_word):\n",
        "            return False, None\n",
        "        # inbetween cases, split and calculate the number of words\n",
        "        textsplit = re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        nwords = len(textsplit)\n",
        "        if nwords < 1.2*self.max_seq_length:\n",
        "            return True, textsplit\n",
        "        return False, textsplit\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_sentences(list_of_sentences, min_sentence_char_length):\n",
        "        \"\"\"Merges small sentences in a sequence of sentence, until the strings are greater than `min_sentence_char_length`\"\"\"\n",
        "        processed_sentences = []\n",
        "        buffer = \"\"\n",
        "\n",
        "        for sentence in list_of_sentences:\n",
        "            if len(sentence) < min_sentence_char_length:\n",
        "                buffer = buffer + \" \" + sentence\n",
        "                if (len(buffer)>=min_sentence_char_length):\n",
        "                    processed_sentences.append(buffer.strip())\n",
        "                    buffer = \"\"\n",
        "            else:\n",
        "                if (len(buffer)<min_sentence_char_length):\n",
        "                    to_add = buffer + \" \" + sentence\n",
        "                    processed_sentences.append(to_add.strip())\n",
        "                    buffer = \"\"\n",
        "                else:\n",
        "                    processed_sentences.extend([buffer.strip(), sentence.strip()])\n",
        "\n",
        "        if buffer:  # If there are any remaining sentences in the buffer\n",
        "            processed_sentences.append(buffer)\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def process(self, text):\n",
        "        \"\"\"Chunks and samples large portions of text\"\"\"\n",
        "\n",
        "        charlen = len(text.strip())\n",
        "\n",
        "        # DISCARD if it is too small for copus\n",
        "        if self.is_too_small_quickcheck(text, charlen):\n",
        "\n",
        "            return {'text':[], 'do_accept':False, 'sentences':[]}\n",
        "\n",
        "        # sample span of chunks: if it larger than our max chunk size\n",
        "        if self.is_larger_than_max_chunk_quickcheck(text, charlen):\n",
        "            text_span_chunks = self._sample_chunk_span(text, self.max_chunk_length_char)\n",
        "        else:\n",
        "            text_span_chunks = text\n",
        "\n",
        "        # check if it smaller, than 1.5 seqlen, then we just accept it all as one unit to truncate later in tokenizer\n",
        "        is_smaller_than_2_paras, textsplit = self.is_smaller_than_two_paragraphs(text_span_chunks)\n",
        "\n",
        "        if is_smaller_than_2_paras:\n",
        "\n",
        "            # check if less than minsize\n",
        "            if self.is_too_small(len(textsplit)):\n",
        "                # if too small, return nothing\n",
        "                return {'text':[], 'do_accept':False, 'sentences':[]}\n",
        "\n",
        "            # return text to be truncated\n",
        "            return {'text':[text_span_chunks], 'do_accept':True, 'sentences':[]}\n",
        "\n",
        "        # leftover cases: text that needs to be chunked into ~512 / max_seq_len\n",
        "        text_to_return, sentences_to_return = self.split_chunk_into_sentences(text_span_chunks)\n",
        "\n",
        "        # return text strings as list of chunks, flag\n",
        "        return {\n",
        "            'text':text_to_return,\n",
        "            'do_accept':True,\n",
        "            'sentences':self.preprocess_sentences(sentences_to_return, self.min_sentence_length_char),\n",
        "        }\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.process(text)\n",
        "if False:\n",
        "    example_processor = ExampleProcessor(config=data_streaming_config, char_per_word = CHAR_PER_WORD, nlp =nlp)\n",
        "    text = \"\"\"As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy's capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor.Red-faced, the Army Air Corps commanders sought to minimize the attack's results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell's carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game's umpires sided with the Army. Their report made no mention of Yarnell's attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy's victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**\"\"\"\n",
        "    text += text\n",
        "    text += text\n",
        "    text += text\n",
        "    text += text\n",
        "    foo = example_processor(text = text)\n",
        "    foo,is_good, foo_sentences = foo.values()\n",
        "    print(is_good)\n",
        "    print('mlm_sentences')\n",
        "    print(foo)\n",
        "\n",
        "    print('next sentences:') # this seems to be working okay\n",
        "    print(foo_sentences)\n",
        "    print(len(foo_sentences))\n",
        "\n",
        "\n",
        "    # works: test the process_sentences\n",
        "    print(example_processor.preprocess_sentences([\"This is fine.\",\"foo\",'sh',\"This is fine and long.\",\"This is also find and long.\",'No', \"This is long and good.\"], 10))\n",
        "\n",
        "    # works, this returns split sentences\n",
        "    example_processor.split_chunk_into_sentences(\n",
        "        chunk=\"This is the first sentence. This is the 2nd sentence and another. I'm the third sentence. Hello, this is me. 5th sentence here. And finally its me.\",\n",
        "        discard_first_sentence=True, discard_last_sentence=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJXQz58BQIub"
      },
      "outputs": [],
      "source": [
        "### Random (Smark) Negative Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Wy5s-lmwQL75",
        "outputId": "a0be9875-dda6-4088-867f-f852f060bd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warning: `corpus` is empty. Generating default corpus from RedPajama\n",
            "reloading negative corpus negative_corpus_cache.pkl for NegativeExampleGenerator\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b79e3d130c96>\u001b[0m in \u001b[0;36m<cell line: 187>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# Build the Negative Corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m negative_example_generator= NegativeExampleGenerator(\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mn_reps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mn_takes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-b79e3d130c96>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_reps, n_takes, tfidf_nfeatures, nchar_max_paragraph, nword_max, nchar_max_word, max_sent_total, corpus, save_cache)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# fetch the corpus from streaming data (or reload from cache if available)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'warning: `corpus` is empty. Generating default corpus from RedPajama'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_default_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-b79e3d130c96>\u001b[0m in \u001b[0;36mfetch_default_corpus\u001b[0;34m(self, cache_file)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnword_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnchar_max_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sent_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fetching streaming corpus for negatives (RedPajama)(%s reps)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_reps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import pynndescent\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class NegativeExampleGenerator:\n",
        "    \"\"\"Builds a queryable corpus of negative examples using ANN and approximate TFIDF vectors\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_reps = 1,\n",
        "            n_takes = 5000,\n",
        "            #dataset_name = 'cerebras/SlimPajama-627B',\n",
        "            tfidf_nfeatures = 3000,\n",
        "            nchar_max_paragraph=3000,\n",
        "            nword_max=100,\n",
        "            nchar_max_word=4,\n",
        "            max_sent_total = 5,\n",
        "            corpus = None,\n",
        "            save_cache = '/tmp/negative_corpus_cache.pkl'\n",
        "    ):\n",
        "        self.stopwords = [\n",
        "            'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself',\n",
        "            'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its',\n",
        "            'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
        "            'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
        "            'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',\n",
        "            'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',\n",
        "            'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up',\n",
        "            'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
        "            'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n",
        "            'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will',\n",
        "            'just', 'don', 'should', 'now'\n",
        "        ]\n",
        "        self.n_reps = n_reps\n",
        "        self.n_takes = n_takes\n",
        "        self.tfidf_nfeatures = tfidf_nfeatures\n",
        "        self.nchar_max_paragraph = nchar_max_paragraph\n",
        "        self.nword_max = nword_max\n",
        "        self.nchar_max_word = nchar_max_word\n",
        "        self.max_sent_total = max_sent_total\n",
        "        self.save_cache = save_cache\n",
        "        if corpus is None:\n",
        "            # fetch the corpus from streaming data (or reload from cache if available)\n",
        "            print('warning: `corpus` is empty. Generating default corpus from RedPajama')\n",
        "            self.corpus_static = self.fetch_default_corpus(self.save_cache)\n",
        "        else:\n",
        "            assert isinstance(corpus,list)\n",
        "            assert len(corpus)>0\n",
        "            print('using predefined corpus of length: %s' % len(corpus))\n",
        "            self.corpus_static = corpus\n",
        "\n",
        "        # build an ann index\n",
        "        self.build_ann_index(self.corpus_static)\n",
        "\n",
        "    def fetch_default_corpus(self, cache_file):\n",
        "        \"\"\"fetches streaming corpus and converts to a static list of data\"\"\"\n",
        "        corpus_static = []\n",
        "        if os.path.isfile(cache_file):\n",
        "            print('reloading negative corpus %s for NegativeExampleGenerator' % cache_file)\n",
        "            with open(cache_file, 'rb') as pcon:\n",
        "                corpus_static = pickle.load(pcon)\n",
        "                self.n_reps = pickle.load(pcon)\n",
        "                self.n_takes = pickle.load(pcon)\n",
        "                self.tfidf_nfeatures = pickle.load(pcon)\n",
        "                self.nchar_max_paragraph = pickle.load(pcon)\n",
        "                self.nword_max = pickle.load(pcon)\n",
        "                self.nchar_max_word = pickle.load(pcon)\n",
        "                self.max_sent_total = pickle.load(pcon)\n",
        "        else:\n",
        "            print('fetching streaming corpus for negatives (RedPajama)(%s reps)' % self.n_reps)\n",
        "            # first do random draws from the corpora\n",
        "            redpajama_set_name_support = [\"RedPajamaCommonCrawl\", \"RedPajamaC4\", \"RedPajamaStackExchange\", \"RedPajamaWikipedia\",\"RedPajamaBook\", \"RedPajamaArxiv\"]\n",
        "            for i_rep in range(self.n_reps):\n",
        "                # load the streaming datasets (RedPajama)\n",
        "                corpus_streaming = datasets.load_dataset(\n",
        "                    'cerebras/SlimPajama-627B',\n",
        "                    split=\"train\",\n",
        "                    streaming=True\n",
        "                ).shuffle(\n",
        "                    buffer_size = self.n_takes\n",
        "                ).filter(\n",
        "                    lambda x : x['meta']['redpajama_set_name'] in redpajama_set_name_support\n",
        "                ).take(\n",
        "                    self.n_takes\n",
        "                ).remove_columns('meta')\n",
        "                # convert streaming data to static and check language\n",
        "                this_corpus_static = [\n",
        "                    e['text'] for e in corpus_streaming #if langdetect(e['text'][:200]+' hello')=='en'\n",
        "                    if check_language(e['text'])[0]\n",
        "                ]\n",
        "                # take only a few sentences per text\n",
        "                this_corpus_static = [\n",
        "                    self.limit_text_to_k_sentences(s, k=self.max_sent_total) for s in this_corpus_static\n",
        "                ]\n",
        "                # filtering again non-english\n",
        "                this_corpus_static = [\n",
        "                    s for s in this_corpus_static\n",
        "                    if check_language(s)[0]\n",
        "                ]\n",
        "                # add\n",
        "                corpus_static += this_corpus_static\n",
        "                if (i_rep % 5)==0:\n",
        "                    print('size of negative corpus: %d' % len(corpus_static))\n",
        "\n",
        "            print('finished collecting streaming examples for negative corpus. Saving to %s' % self.save_cache)\n",
        "            # save the cache\n",
        "            with open(self.save_cache, 'wb') as pcon:\n",
        "                pickle.dump(corpus_static, pcon)\n",
        "                pickle.dump(self.n_reps, pcon)\n",
        "                pickle.dump(self.n_takes, pcon)\n",
        "                pickle.dump(self.tfidf_nfeatures, pcon)\n",
        "                pickle.dump(self.nchar_max_paragraph, pcon)\n",
        "                pickle.dump(self.nword_max, pcon)\n",
        "                pickle.dump(self.nchar_max_word, pcon)\n",
        "                picke.dump(self.max_sent_total, pcon)\n",
        "\n",
        "        return corpus_static\n",
        "\n",
        "    def build_ann_index(self, corpus):\n",
        "        \"\"\"vectorizes a corpus and builds an ann index\"\"\"\n",
        "        # stem words in preparation for tfidf vectorizer\n",
        "        corpus_processed = [\n",
        "            self.preprocess_text_to_index(s) for s in corpus\n",
        "        ]\n",
        "        # convert the corpus into tfidfvectors\n",
        "        self.tfidfvectorizer = TfidfVectorizer(max_features=self.tfidf_nfeatures)\n",
        "        self.tfidfvectorizer.fit(corpus_processed)\n",
        "        self.corpus_vectors = self.tfidfvectorizer.transform(corpus_processed)\n",
        "\n",
        "        # build the ann index\n",
        "        self.ann_index = pynndescent.NNDescent(self.corpus_vectors)\n",
        "        print('finished building the ANN index')\n",
        "\n",
        "    @staticmethod\n",
        "    def limit_text_to_k_sentences(text, k=5):\n",
        "        \"\"\"splits text into sentences, then limits the paragraph to just `k` sentences\"\"\"\n",
        "        if len(text)<400:\n",
        "            return text\n",
        "        text = text[:10000]\n",
        "        sentences = [s for s in re.split(r\"(?<=\\w\\w\\.)\\s+\",text) if len(s)>1]\n",
        "        n_sent = len(sentences)\n",
        "        if n_sent<=k:\n",
        "            return text\n",
        "        # if larger than limit, pick a (pseudo)random set of sentences\n",
        "        random_sent_start_max_offset = n_sent-k\n",
        "        random_sent_start_offset = ord(sentences[-1][:10][-1]) % random_sent_start_max_offset\n",
        "        random_sent_end_offset = random_sent_start_offset + k\n",
        "        return \" \".join(sentences[random_sent_start_offset:random_sent_end_offset])\n",
        "\n",
        "    def preprocess_text_to_index(self, text):\n",
        "        \"\"\"converts text into small k-character word stems before passing to TFIDF\"\"\"\n",
        "        ptext = text[:self.nchar_max_paragraph].lower()\n",
        "        ptext = ' '.join([\n",
        "            w[:self.nchar_max_word] for w in ptext.split(' ')[:self.nword_max]\n",
        "            if (w not in self.stopwords)\n",
        "        ])\n",
        "        ptext = re.sub(\"\\W+\",' ',ptext).strip()\n",
        "        return ptext\n",
        "\n",
        "    def process_query(self,text):\n",
        "        \"\"\"Vectorizes query text for retrieval\"\"\"\n",
        "        query_processed = self.preprocess_text_to_index(text)\n",
        "        return self.tfidfvectorizer.transform([query_processed]), query_processed\n",
        "\n",
        "    def find_negative(self, query_text, k=1, skip=1):\n",
        "        \"\"\"Finds similar text to the query text, skipping the first `skip` and returning `k` top matches\"\"\"\n",
        "        query_vector, query_processed = self.process_query(query_text)\n",
        "        ann_idx,scores = self.ann_index.query(query_vector, k = k+skip)\n",
        "        retrieved_text = [\n",
        "            self.corpus_static[i] for i in ann_idx[0][skip:]\n",
        "        ]\n",
        "        retrieved_text = [\n",
        "            s for s in retrieved_text\n",
        "            if (\n",
        "                s.lower().replace(\" \",\"\")[:100]!=query_text.lower().replace(\" \",\"\")[:100]\n",
        "            )\n",
        "        ]\n",
        "        if len(retrieved_text)>0:\n",
        "            return retrieved_text, scores\n",
        "        # check that the texts are different\n",
        "        skip+=1\n",
        "        return self.find_negative(query_text, k=k, skip=skip)\n",
        "\n",
        "# Build the Negative Corpus\n",
        "negative_example_generator= NegativeExampleGenerator(\n",
        "    n_reps = 1, #\n",
        "    n_takes = 40000,\n",
        "    tfidf_nfeatures = 4000,\n",
        "    nchar_max_paragraph=3000,\n",
        "    nword_max=100,\n",
        "    nchar_max_word=4,\n",
        "    save_cache = 'negative_corpus_cache.pkl'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISTzJb5XQ8Ud",
        "outputId": "a0dc6566-e3a9-4ed4-90d4-565327d5bde2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "كما أنّ ضرب الأسواق المدنية المزدحمة، الذي أسفر عن مقتل ما يقرب من مائة من مواطنيها، من قبل الحكومة أمر غير مقبول في أي ظرف من الظروف،\" قال السيّد دي مستورا. هجمات أمس تأتي في أعقاب القصف العشوائي على دمشق الاسبوع الماضي من قبل جماعات المعارضة المسلحة وقطع إمدادات المياه، وجميعها تدابير تؤثر على المدنيين وهو أمر غير مقبول. هذه الهجمات الاخيرة هي مثال آخر على وحشية الصراع الدائر. \"يجب السماح بوصول المساعدات الإنسانية دون قيد أو شرط ويجب أن يُتوقّف القتل.\n"
          ]
        }
      ],
      "source": [
        "# test query\n",
        "neg_retrievals,_ = negative_example_generator.find_negative(\n",
        "    \"MIT is an elite education institution based in Boston Massatusetts and is one of the first institutions of higher learning in the USA, dating back to the founding fathers. Recently, it has become embroiled in a series of scandels to do with free speech and allegations of scientific misconduct\",\n",
        "    k=1, skip=1\n",
        ")\n",
        "for _ in neg_retrievals: print(_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSP-Hmb8vUm_"
      },
      "source": [
        "#### A Sample of 1000 will have...\n",
        "... approximately 1523 samples of 512-long examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "UmhZQWnl1EUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86eb771-951a-4f99-d28b-c6acb7513bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'anchor': 'a b', 'next': 'c', 'opposite': 'f'}, {'anchor': 'b c', 'next': 'd', 'opposite': 'a'}, {'anchor': 'c d', 'next': 'e', 'opposite': 'b'}, {'anchor': 'd e', 'next': 'f', 'opposite': 'c'}]\n"
          ]
        }
      ],
      "source": [
        "# FUNCTIONS TO MAKE THE TRAINING AND VAL SETs\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "## convert the streaming dataset in a static dataset\n",
        "def convert_streaming_dataset_to_static_corpus(\n",
        "    streaming_dataset,\n",
        "    skip=0,\n",
        "    take=1000\n",
        "):\n",
        "    \"\"\"Takes a streaming_dataset and converts it into a list of examples\"\"\"\n",
        "    if skip !=0:\n",
        "        dataset_to_make_static = streaming_dataset.skip(skip).take(take)\n",
        "    else:\n",
        "        dataset_to_make_static = streaming_dataset.take(take)\n",
        "\n",
        "    examples_static_mlm = [] # data for MLM objective\n",
        "    examples_static_nextsentence = [] # data for next sentence task\n",
        "    for i, example in enumerate(dataset_to_make_static):\n",
        "        # chunk text into ~512 text-strings, and sentences\n",
        "        examples_processed = example_processor(text = example['text'])\n",
        "        # chunk, accept/reject, sentences\n",
        "        example_parsed, do_accept, parsed_sentences = examples_processed.values()\n",
        "        if is_do_acceptgood:\n",
        "            # mlm gets the chunks of text-strings\n",
        "            examples_static_mlm.extend(example_parsed)\n",
        "            if len(parsed_sentences)>5:\n",
        "                # sentences for next sentence prediction: make triplet of s1,s2,opposite, where opposites get label=1\n",
        "                examples_static_nextsentence.extend(\n",
        "                    convert_sequence_into_nextsentence_pairs(parsed_sentences)\n",
        "                )\n",
        "                #FOOFU - STOPPED HERE TO FIGURE OUT WHY MY NEXT-SENTENCE STUFF IS SO LONG\n",
        "        if (i+1)%100==0:\n",
        "            print(\"...streaming size: \" % len(examples_static_mlm))\n",
        "\n",
        "    return examples_static_mlm, examples_static_nextsentence\n",
        "\n",
        "def convert_sequence_into_nextsentence_pairs(list_of_sentences):\n",
        "    \"\"\"Converts a list of sentences into a list of dicts, with next-sentence pairs\"\"\"\n",
        "    n = len(list_of_sentences)\n",
        "\n",
        "    def opposite(i,n):\n",
        "        return (i + round(n/2+1)) % n\n",
        "\n",
        "    list_of_nextsentence_pairs = []\n",
        "    # loop through sequence, make triplet of anchor1+anchor2, next and an opposite\n",
        "    for o1a, o1b, o2 in zip(range(0,n-2), range(1,n-1), range(2,n)):\n",
        "        s_anchor = list_of_sentences[o1a] + \" \" + list_of_sentences[o1b]\n",
        "        s_next = list_of_sentences[o2]\n",
        "        s_opposite = list_of_sentences[opposite(o1b,n)]\n",
        "        list_of_nextsentence_pairs.append(\n",
        "            {\n",
        "                \"anchor\":s_anchor,\n",
        "                \"next\":s_next,\n",
        "                \"opposite\":s_opposite\n",
        "            }\n",
        "        )\n",
        "    return list_of_nextsentence_pairs\n",
        "\n",
        "print(convert_sequence_into_nextsentence_pairs(['a','b','c','d','e','f']))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dall = load_dataset('pile-of-law/pile-of-law',\"irs_legal_advice_memos\",split='train')\n",
        "#print(dall[0]['text'])\n",
        "check_language(dall[40]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpjVKYuJrmIs",
        "outputId": "1649fe8c-40aa-48b9-8dea-82a18c695649"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, 0.10219999999999996)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_WZnBT2rriK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "oz7n3lp6oH49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b198ab88-a35d-41e7-99cd-98c2a39602ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADD 'joelito/legal-mc4','en' TO THE LIST OF MLM DATASETS\n",
            "ADD \"izumi-lab/open-text-books\" to have more textbook context and reduce the amount of openbooks\n",
            "[18.21, 18.11, 30, 5.0, 0, 0, 0.75, 1.0, 2.0, 0, 9.0, 1.5, 0.1, 0.5, 2.0, 4.2, 1.0, 2.5, 1.0, 0.75, 0.75, 3.3]\n",
            "0.179  EleutherAI/the_pile_deduplicated ||| EleutherAI/the_pile_deduplicated\n",
            "\n",
            "0.178  tiiuae/falcon-refinedweb ||| tiiuae/falcon-refinedweb\n",
            "\n",
            "0.295  Cohere/wikipedia-22-12 ||| Cohere/wikipedia-22-12\n",
            "\n",
            "0.049  Multi-Domain-Expert-Layers/the_pile_books3_packed_128k ||| Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\n",
            "\n",
            "0.000  macrocosm/arxiv_abstracts ||| macrocosm/arxiv_abstracts\n",
            "\n",
            "0.000  ccdv/pubmed-summarization ||| ccdv/pubmed-summarization\n",
            "\n",
            "0.007  big_patent ||| big_patent\n",
            "\n",
            "0.010  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/euro_parl\n",
            "\n",
            "0.020  kerinin/hackernews-stories ||| kerinin/hackernews-stories\n",
            "\n",
            "0.000  https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst ||| https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\n",
            "\n",
            "0.089  https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip ||| https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\n",
            "\n",
            "0.015  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/r_legaladvice\n",
            "\n",
            "0.001  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/exam_outlines\n",
            "\n",
            "0.005  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/cc_casebooks\n",
            "\n",
            "0.020  eloukas/edgar-corpus ||| eloukas/edgar-corpus\n",
            "\n",
            "0.041  Rahmaa/ElsevieR_ClEaN ||| Rahmaa/ElsevieR_ClEaN\n",
            "\n",
            "0.010  ashraq/financial-news-articles ||| ashraq/financial-news-articles\n",
            "\n",
            "0.025  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/courtlistener_opinions\n",
            "\n",
            "0.010  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/sec_administrative_proceedings\n",
            "\n",
            "0.007  pile-of-law/pile-of-law ||| pile-of-law/pile-of-law/irs_legal_advice_memos\n",
            "\n",
            "0.007  launch/gov_report ||| launch/gov_report\n",
            "\n",
            "0.032  izumi-lab/open-text-books ||| izumi-lab/open-text-books\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#print('NEED TO VERIFY IF PILE DEDUP CAN BE STREAMED: YES')\n",
        "print(\"ADD 'joelito/legal-mc4','en' TO THE LIST OF MLM DATASETS\") # it is just a version of C4 that focuses on legal language\n",
        "print('ADD \"izumi-lab/open-text-books\" to have more textbook context and reduce the amount of openbooks')\n",
        "\n",
        "#def make_url_for_random_pile():\n",
        "#    random_pile_urls = \"RANDOM:\"\n",
        "#    for i in range(30):\n",
        "#        if i>0: random_pile_urls+=\";\"\n",
        "#        random_pile_urls+= \"https://the-eye.eu/public/AI/pile/train/%02g.jsonl.zst\" % i\n",
        "#    return random_pile_urls\n",
        "\n",
        "def clean_stream_refinedweb(x):\n",
        "    x['text'] = x['content']\n",
        "    return x\n",
        "\n",
        "def clean_stream_arxiv(x):\n",
        "    x['text'] = x['abstract']\n",
        "    return x\n",
        "\n",
        "def clean_stream_pubmedsum(x):\n",
        "    x['text'] = x['article']\n",
        "    return x\n",
        "\n",
        "def remove_first_http_url(text):\n",
        "    \"\"\"Removes http strings from hackersnews\"\"\"\n",
        "    pattern = r'http[s]*://[^ ]+'\n",
        "    return re.sub(pattern, '', text, 1)\n",
        "\n",
        "#def parse_hacker_news(text):\n",
        "#    \"\"\"removes hackernews' thread separators ----- ===== ~~~ and removes urls\"\"\"\n",
        "#    return remove_first_http_url(\" \".join([\" \".join(j.split('\\n')[1:]) for j in text.replace(\"------\\n\",\"~~~\\n\").replace(\"======\\n\",\"~~~\\n\").split(\"~~~\\n\")]))\n",
        "#def clean_hackernews(x):\n",
        "#    x['text'] = parse_hacker_news(x['text'])\n",
        "#    return x\n",
        "\n",
        "def clean_ledgarmlm(x):\n",
        "    x['text'] = x['provision']\n",
        "    return x\n",
        "\n",
        "def clean_casetextbook(example):\n",
        "    # discards the first 8 percent\n",
        "    discard = int(0.08*len(example['text']))\n",
        "    example['text'] = example['text'][discard:].replace('\\n',\" \")\n",
        "    return example\n",
        "\n",
        "def clean_edgarcorpus(example):\n",
        "    example['text'] = example['section_1'] + \"\\n\" + example['section_2'] + \"\\n\" + example['section_3'] + \"\\n\" + example['section_7']\n",
        "    return example\n",
        "\n",
        "def clean_elseiver_mlm(example):\n",
        "    example['text'] = example['Clean_Title'] + \" - \" + example['Clean_Summary'] + \"\\n\" + example['Clean_Text']\n",
        "    return example\n",
        "\n",
        "def clean_financial_news_mlm(example):\n",
        "    example['text'] = example['title'] + \"\\n\" + example['text']\n",
        "    return example\n",
        "\n",
        "def filter_pileall_mlm(x):\n",
        "    return x['meta']['pile_set_name'] in ['NIH ExPorter','OpenWebText2','PubMed Abstracts','StackExchange','Wikipedia (en)','ArXiv']\n",
        "\n",
        "def filter_europarl_mlm(x):\n",
        "    return len(x['text'])>60*7 # at least a small paragraphs\n",
        "\n",
        "def clean_irs_advice_mlm(x):\n",
        "    text = x['text']\n",
        "    text = re.sub(r'^[\\d,.%$+\\-\\s\\=]+\\n?$',\"\",text,flags=re.MULTILINE | re.DOTALL)\n",
        "    text = re.sub(r'\\-{10,}',\"\",text)\n",
        "    text = re.sub(r'^(.*)?[Pp]age\\s\\d+\\n?$',\"\",text,flags=re.MULTILINE)\n",
        "    x['text'] = text.replace(\"\\n\",\" \").strip()\n",
        "    return x\n",
        "\n",
        "def clean_secproceedings_mlm(x):\n",
        "    text = x['text']\n",
        "    if 'I.\\n' in text:\n",
        "        text = \"\".join(re.split(r\"^I.\\n\", text, flags=re.MULTILINE)[1:])\n",
        "    else:\n",
        "        text = '\\n'.join(text.split('\\n')[10:])\n",
        "\n",
        "    text = re.sub(r'^(\\()*\\d+[\\.\\)]?\\n?$', '', text,flags=re.MULTILINE)\n",
        "\n",
        "    x['text'] = text\n",
        "    return x\n",
        "\n",
        "def filter_notcodelike(x):\n",
        "    \"\"\"checks if text has a lot of non-alphanumeric characters that indicates it is probably computer code / math notation\"\"\"\n",
        "    ratio_specialchar = check_is_code(x['text'])\n",
        "    return ratio_specialchar<0.1\n",
        "\n",
        "def clean_hackernews(x):\n",
        "    x['text']= x['Title'] + ' ' + remove_first_http_url(x['Text'])\n",
        "    return x\n",
        "\n",
        "def filter_hackernews(x):\n",
        "    return (len(x['Text']) > 60) and (check_is_code(x['Text'])<0.1)\n",
        "\n",
        "def clean_bigpatent(x):\n",
        "    x['text'] = x['abstract'] + \" \" + x['description']\n",
        "    return x\n",
        "\n",
        "def clean_govreport(x):\n",
        "    x['text'] = x['document']\n",
        "    return x\n",
        "\n",
        "mlm_streaming_cleaning_functions = {\n",
        "    #'EleutherAI/pile/all':(lambda x: x, filter_pileall_mlm, ['meta']), # GONE\n",
        "    'EleutherAI/the_pile_deduplicated':(lambda x: x, filter_notcodelike, []),\n",
        "    # monology/pile-uncopyrighted -> this seems like the original pile that I was using, with book3 removed\n",
        "    \"tiiuae/falcon-refinedweb\":(clean_stream_refinedweb, None, ['url', 'timestamp', 'dump', 'segment', 'image_urls','content']),\n",
        "    \"Cohere/wikipedia-22-12\":(lambda x : x, None, ['id', 'title', 'url', 'wiki_id', 'views', 'paragraph_id', 'langs']),\n",
        "    \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\":(lambda x: x, None, ['meta']),\n",
        "    \"macrocosm/arxiv_abstracts\":(clean_stream_arxiv, None, ['embeddings', 'doi','abstract']),\n",
        "    \"ccdv/pubmed-summarization\":(clean_stream_pubmedsum, None, ['abstract','article']),\n",
        "    #\"conceptofmind/pile_uspto_backgrounds\":(lambda x : x ,None, ['meta']),\n",
        "    'big_patent':(clean_bigpatent, None, ['description', 'abstract']),\n",
        "    \"pile-of-law/pile-of-law/euro_parl\":(lambda x : x, filter_europarl_mlm, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    #\"philArchive\": fails, but available as subset in eloukas/edgar-corpus as domain=='PhilPapers'\n",
        "    #\"conceptofmind/pile_hacker_news\":(clean_hackernews, None,['meta']),\n",
        "    'kerinin/hackernews-stories':(clean_hackernews, filter_hackernews, ['Title','Text','labels']),\n",
        "    \"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\":(lambda x:x, None,['meta']),\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\":(clean_ledgarmlm,None,['provision','source']),\n",
        "    \"pile-of-law/pile-of-law/r_legaladvice\":(lambda x : x, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/exam_outlines\":(lambda x : x, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/cc_casebooks\":(clean_casetextbook, None, ['created_timestamp', 'downloaded_timestamp', 'url']), # clean_casetextbook\n",
        "    \"eloukas/edgar-corpus\":(\n",
        "        clean_edgarcorpus, None, [\n",
        "            'filename', 'cik', 'year', 'section_1A', 'section_1B', 'section_4', 'section_1', 'section_2', 'section_3', 'section_7',\n",
        "            'section_5', 'section_6', 'section_8', 'section_9', 'section_10', 'section_7A', 'section_9A', 'section_9B',\n",
        "            'section_11', 'section_12', 'section_13', 'section_14', 'section_15'\n",
        "        ]),\n",
        "    \"Rahmaa/ElsevieR_ClEaN\":(clean_elseiver_mlm, None, ['Unnamed: 0', 'Clean_Title', 'Clean_Text', 'Clean_Summary']),\n",
        "    'ashraq/financial-news-articles':(clean_financial_news_mlm, None, ['title','url']),\n",
        "    'pile-of-law/pile-of-law/courtlistener_opinions':(lambda x : x, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/sec_administrative_proceedings\":(clean_secproceedings_mlm, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    \"pile-of-law/pile-of-law/irs_legal_advice_memos\":(clean_irs_advice_mlm, None, ['created_timestamp', 'downloaded_timestamp', 'url']),\n",
        "    'launch/gov_report':(clean_govreport, None, ['id','document','summary']),\n",
        "    'izumi-lab/open-text-books':(lambda x: x, None, [])\n",
        "}\n",
        "\n",
        "# entries: url, subset, probability, size, option(name of postprocess subsetting), shuffle?\n",
        "mlm_files = [\n",
        "    #('EleutherAI/pile','all', 18.21, 700000, \"mlm\", (30, 1000000)), # 10.01 + 5.13 + 3.07 has 30 files (each with? millions of examples)\n",
        "    ('EleutherAI/the_pile_deduplicated', None, 18.21, 134000000, 'mlm', (1650, 81405), 0.1), # 1650 files each with ~?\n",
        "    # monology/pile-uncopyrighted -> this seems like the original pile that I was using, with book3 removed\n",
        "    (\"tiiuae/falcon-refinedweb\", None, 18.11, 968000000, \"mlm\", (5534, 174000), 0.1), # CC; has 5534 files as parquet (each with ~174919)\n",
        "    (\"Cohere/wikipedia-22-12\", 'en', 30, 8590000, \"mlm\",(351, 100000), 0.16), # wikipedia has 351 files (each with 100000 examples)\n",
        "    # should I reduce the books component? because it is in the pile anyway\n",
        "    (\"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\", None, 5.0, 34500, \"mlm\", (15, 9900), 0.15), # has 15 files (each with with ~9978/9983)\n",
        "    (\"macrocosm/arxiv_abstracts\", None, 0, 2250000, \"mlm\", False, 0.12), # set to zero because in PILE (has 23 parquet files)\n",
        "    (\"ccdv/pubmed-summarization\", None, 0, 120000, \"mlm\", False, 0.12), # 3.75 set to zero because elsiever and pubmed in Pile below\n",
        "    #(\"conceptofmind/pile_uspto_backgrounds\", None, 0, 11000000, \"mlm\",(139, 80000)), # 3% has 139 Files (each with 80024) IS DEAD NOW\n",
        "    ('big_patent', 'all', 0.75, 15400, 'mlm', False, 0.15), # use as an alternative to /NIH_ExPORTER_awarded_grant_text.jsonl.zst\n",
        "    (\"pile-of-law/pile-of-law\",'euro_parl', 1.0, 7254, \"mlm\", False, 0.1),\n",
        "    #(\"conceptofmind/pile_hacker_news\", None, 0, 1570000, \"mlm\", (20, 78500)), # 2% has 20 files (each wit ~78599 or 78598) IS DEAD NOW\n",
        "    ('kerinin/hackernews-stories', None, 2.0, 31300, 'mlm', (8, 52220), 0.1), # hackernews stories alternative\n",
        "    (\"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\", None, 0, 985651, \"mlm\", False, 0.15), # still works, but may fail eventually\n",
        "    (\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", None, 9.0, 1200000, \"mlm\", False, 0.2),\n",
        "    (\"pile-of-law/pile-of-law\",'r_legaladvice', 1.5, 109740, \"mlm\", False, 0.15),\n",
        "    (\"pile-of-law/pile-of-law\",'exam_outlines', 0.1, 12, \"mlm\",False, 0.2), # useless (but interesting)\n",
        "    (\"pile-of-law/pile-of-law\",'cc_casebooks',0.5, 59 ,\"mlm\",False, 0.2),\n",
        "    (\"eloukas/edgar-corpus\", \"full\", 2.0, 47000, \"mlm\",(28, 4000), 0.15), # has 28 files each with 1k-5k (variable amount of data: 1styear 1060 vs 5508 in 2018\n",
        "    (\"Rahmaa/ElsevieR_ClEaN\", None, 4.2, 31600, \"mlm\", False, 0.15),\n",
        "    ('ashraq/financial-news-articles', None, 1.0, 306000, \"mlm\", (2, 153100), 0.1), # has 2 files (each with 153121)\n",
        "    ('pile-of-law/pile-of-law','courtlistener_opinions',  2.5, 1000000 , \"mlm\", (16, 229000), 0.1), # has 16 files (each with 229678 to 526543)\n",
        "    ('pile-of-law/pile-of-law',\"sec_administrative_proceedings\", 1.0, 10805, \"mlm\", False, 0.1), # 118.4 MiB\n",
        "    ('pile-of-law/pile-of-law',\"irs_legal_advice_memos\", 0.75, 442, \"mlm\", False,0.18), # 35.8 MiB\n",
        "    ('launch/gov_report', 'plain_text',0.75, 17500, 'mlm', False, 0.1),\n",
        "    ('izumi-lab/open-text-books',None,  3.3, 150000, 'mlm', False, 0.15)\n",
        "] # need to estimate the size of the def ['NIH ExPorter','OpenWebText2','PubMed Abstracts','StackExchange','Wikipedia (en)'] subset\n",
        "\n",
        "\n",
        "# entries: url, subset, probability, size, option(name of postprocess subsetting), shuffle?\n",
        "# looks like the Pile is finally gone\n",
        "# monology/pile says it will be available in december\n",
        "# the_pile_openwebtext2 -> substitute? (no)\n",
        "# could just use: EleutherAI/the_pile_deduplicated and then filter for english and exclude too much special characters\n",
        "\n",
        "print([k[2] for k in mlm_files])\n",
        "total_prob = sum([k[2] for k in mlm_files])\n",
        "for url, f in zip(mlm_files,mlm_streaming_cleaning_functions.keys()):\n",
        "    print(\"%0.3f\" % (url[2]/total_prob) + \"  \"+ url[0] + \" ||| \" + f + '\\n')\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':mlm_files,\n",
        "    'val_size':2000,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':6000,\n",
        "    'max_chunk_start':1000000,\n",
        "    \"seed\":42,\n",
        "}\n",
        "\n",
        "def chunk_docs_into_chunks_and_sentences(\n",
        "    list_of_strings,\n",
        "    nlp=None,\n",
        "    config_chunking=None,\n",
        "    seed = 42,\n",
        "    fieldname='text',\n",
        "    min_number_of_sentence_for_nextsentence_prediction = 10\n",
        "):\n",
        "    \"\"\"Splits long docs into chunks that do next exceet max_seq_len, as well as sentences for next-sentence-prediction \"\"\"\n",
        "    if nlp is None:\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "        nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "    if config_chunking is None:\n",
        "        config_chunking = {\n",
        "            'max_seq_length':512,\n",
        "            'min_seq_length':48,\n",
        "            'max_chunk_size':6,\n",
        "            'min_sentence_len':20,\n",
        "            'seed':seed\n",
        "        }\n",
        "    else:\n",
        "        config_chunking.update({'seed':seed})\n",
        "\n",
        "    # initialize the example processor\n",
        "    example_processor = ExampleProcessor(\n",
        "        config=config_chunking, char_per_word = CHAR_PER_WORD, nlp =nlp\n",
        "    )\n",
        "\n",
        "    examples_static_chunks = [] # data for MLM objective\n",
        "    examples_static_nextsentence = [] # data for next sentence task\n",
        "    for i, example in enumerate(list_of_strings):\n",
        "        # chunk text into ~512 text-strings, and sentences\n",
        "        if isinstance(example,str):\n",
        "            examples_processed = example_processor(text = example)\n",
        "        elif isinstance(example,dict):\n",
        "            examples_processed = example_processor(text = example[fieldname])\n",
        "        # chunk, accept/reject, sentences\n",
        "        example_parsed, do_accept, parsed_sentences = examples_processed.values()\n",
        "        if do_accept:\n",
        "            # mlm gets the text-strings chunked to size 512\n",
        "            examples_static_chunks.extend(example_parsed)\n",
        "            if len(parsed_sentences)> min_number_of_sentence_for_nextsentence_prediction: #4:\n",
        "                # sentences for next sentence prediction: make triplet of s1,s2,opposite, where opposites get label=1\n",
        "                examples_static_nextsentence.extend(\n",
        "                    convert_sequence_into_nextsentence_pairs(parsed_sentences)\n",
        "                )\n",
        "\n",
        "    return examples_static_chunks, examples_static_nextsentence\n",
        "\n",
        "def nwords_quick(text):\n",
        "    return len([w for w in text.split(\" \") if len(w)>0])\n",
        "\n",
        "def initialize_and_get_mlm_streaming_datasets(\n",
        "    data_streaming_config,\n",
        "    streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_mlm.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_mlm_%03g.pkl',\n",
        "    do_check_english = True\n",
        "):\n",
        "    \"\"\"Converts stream of unlabelled text data into static datasets for: MLM task and next-sentence-prediction task\"\"\"\n",
        "    # list of files to stream\n",
        "    files = data_streaming_config['files']\n",
        "    # number of examples to take from stream for validation set\n",
        "    val_size = data_streaming_config['val_size']\n",
        "    # number of examples to take from stream for training set\n",
        "    train_chunk_size = data_streaming_config['train_chunk_size']\n",
        "    min_seq_len = data_streaming_config['min_seq_length']\n",
        "    # normalization constant for normalizing the weights into probabilities\n",
        "    probability_normalization_const = sum([x[2] for x in files])\n",
        "\n",
        "    # where to initialize start-stream for training data\n",
        "    if start_proportion is None:\n",
        "        start_proportion = np.random.RandomState(seed+epoch).uniform()*0.95\n",
        "\n",
        "    # reload cached files\n",
        "    path_to_train_cache = None if not '%03g' in path_to_train_cache_epoch else path_to_train_cache_epoch % epoch\n",
        "    do_make_valset = not os.path.isfile(path_to_val_cache)\n",
        "    do_make_trainset = not os.path.isfile(path_to_train_cache)\n",
        "    if not do_make_valset:\n",
        "        print('RELOADING VAL-MLM SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            datalist_val_mlm_static = pickle.load(pcon)\n",
        "            datalist_val_sentences_static = pickle.load(pcon)\n",
        "            epoch = pickle.load(pcon)\n",
        "            log_source_val = pickle.load(pcon)\n",
        "        print('VAL-MLM SET SIZE: %d' % len(datalist_val_mlm_static))\n",
        "    else:\n",
        "        datalist_val_mlm_static, datalist_val_sentences_static, log_source_val = [],[],{}\n",
        "    if not do_make_trainset:\n",
        "        print('RELOADING VAL-QA SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_train_cache,'rb') as pcon:\n",
        "            datalist_train_mlm_static = pickle.load(pcon)\n",
        "            datalist_train_sentences_static = pickle.load(pcon)\n",
        "            epoch = pickle.load(pcon)\n",
        "            log_source_train = pickle.load(pcon)\n",
        "        print('TRAIN-MLM EPOCH-%d SET SIZE: %d' % (epoch, len(datalist_train_mlm_static)))\n",
        "    else:\n",
        "        datalist_train_mlm_static, datalist_train_sentences_static,log_source_train = [],[],{}\n",
        "\n",
        "    if (do_make_trainset or do_make_valset):\n",
        "\n",
        "        # initialize the nlp-sentencizer for chunking\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "        nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "        # loop through datasets\n",
        "        for (mlm_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle, threshold_specialchar), dataset_key in zip(\n",
        "            files, streaming_cleaning_functions.keys()\n",
        "        ):\n",
        "            if prob ==0:\n",
        "                continue\n",
        "            prob /= probability_normalization_const\n",
        "\n",
        "            # get cleaning & filter functions for streaming data functionality\n",
        "            clean_func, filter_func, removefeature_names = streaming_cleaning_functions[dataset_key]\n",
        "\n",
        "            # set arguments for the load_dataset (huggingface repos)\n",
        "            load_dataset_args = {\n",
        "                'path':mlm_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "            }\n",
        "            # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "            if mlm_nm.endswith('.jsonl') or mlm_nm.endswith('.jsonl.zip') or mlm_nm.endswith('.jsonl.zst'):\n",
        "                load_dataset_args.update({'path':'json','data_files':mlm_nm})\n",
        "\n",
        "            # special proecssing of datasets with multiple partitions\n",
        "            if bool(partition_shuffle): # or str(epoch)=='val':\n",
        "\n",
        "                n_files, n_per_file = partition_shuffle\n",
        "                dataset_size = n_per_file\n",
        "                print('trying %s initialization (shuffling through %d files)' % (mlm_nm, n_files))\n",
        "\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func)\n",
        "\n",
        "                # validation set\n",
        "                if do_make_valset:\n",
        "                    # take from stream\n",
        "                    n_valset_take = max(int(prob*val_size), 1)\n",
        "                    print('take %d from %s validation'% (n_valset_take, mlm_nm))\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert stream to a static set (and check english language)\n",
        "                    dset_static_val_thisset =[\n",
        "                        e['text'] for e in dset_stream_val\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "                # training set\n",
        "                if do_make_trainset:\n",
        "                    # randomly skip a bunch from this set\n",
        "                    skip_to_start = int(start_proportion*n_per_file)\n",
        "                    take_from_this_set = max(int(round(train_chunk_size*prob)),1)\n",
        "                    print('take %d from %s training'% (take_from_this_set, mlm_nm))\n",
        "                    # shuffle: take a random data partition (from the dataset's list of files)\n",
        "                    dset_stream_train = dset_stream.shuffle(\n",
        "                        seed = seed+epoch, buffer_size = skip_to_start+take_from_this_set,\n",
        "                    )\n",
        "                    dset_stream_train = dset_stream_train.skip(\n",
        "                        skip_to_start # random skip through dataset to new start position\n",
        "                    ).take(\n",
        "                        take_from_this_set # take this amount for the training ste\n",
        "                    ).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert training to static dataset\n",
        "                    dset_static_train_thisset =[\n",
        "                        e['text'] for e in dset_stream_train\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "            else:\n",
        "                # regular streaming\n",
        "                print('trying %s initialization' % mlm_nm)\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "                # take from stream\n",
        "                n_valset_take = max(int(prob*val_size), 1) # size of valset\n",
        "                print('take %d from %s validation'% (n_valset_take, mlm_nm))\n",
        "                skip_to_start = int(start_proportion*(dataset_size-n_valset_take)) # random point to skip to\n",
        "                n_train_take = max(int(round(train_chunk_size*prob)),1) # size of train set\n",
        "                print('take %d from %s train'% (n_train_take, mlm_nm))\n",
        "                if do_make_valset:\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take)\n",
        "                    # checking for: existence of any words and ii) size of sequence meets minimum criteria\n",
        "                    dset_static_val_thisset = [\n",
        "                        e['text'] for e in dset_stream_val\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "                if do_make_trainset:\n",
        "                    dset_stream_train = dset_stream.skip(n_valset_take+skip_to_start).take(n_train_take)\n",
        "                    # checking for: existence of any words and ii) size of sequence meets minimum criteria\n",
        "                    dset_static_train_thisset = [\n",
        "                        e['text'] for e in dset_stream_train\n",
        "                        if bool(re.search(r\"\\w+\",e['text'][:200])) and (nwords_quick(e['text'][:10000])>min_seq_len)\n",
        "                    ]\n",
        "            print('Done getting streams/reloading from %s' % mlm_nm)\n",
        "            # check language, chunk sentences\n",
        "            if do_make_valset:\n",
        "                # discard non-english\n",
        "                dset_static_val_thisset =[\n",
        "                    e for e in dset_static_val_thisset\n",
        "                    if check_language(e, threshold_specialchar)[0]\n",
        "                ]\n",
        "                print('done val language check')\n",
        "                # chunk the docs (512-tokens and next-sentence prediction sentences)\n",
        "                dset_val_chunked_for_mlm, dset_val_nextsentence = chunk_docs_into_chunks_and_sentences(\n",
        "                    list_of_strings=dset_static_val_thisset,\n",
        "                    config_chunking=copy.deepcopy(data_streaming_config),\n",
        "                    seed=seed+epoch,\n",
        "                    nlp=nlp\n",
        "                )\n",
        "                print('done val longtext chunking')\n",
        "                # add to val set\n",
        "                datalist_val_mlm_static.extend(dset_val_chunked_for_mlm)\n",
        "                datalist_val_sentences_static.extend(dset_val_nextsentence)\n",
        "                # log the sources of text\n",
        "                log_source_val[dataset_key] = len(dset_val_chunked_for_mlm)\n",
        "\n",
        "            # check language, chunk sentences\n",
        "            if do_make_trainset:\n",
        "                # discard non-english\n",
        "                dset_static_train_thisset =[\n",
        "                    e for e in dset_static_train_thisset\n",
        "                    if check_language(e, threshold_specialchar)[0]\n",
        "                ]\n",
        "                print('done train language check')\n",
        "                # chunk the docs (512-tokens and next-sentence prediction sentences)\n",
        "                dset_train_chunked_for_mlm, dset_train_nextsentence = chunk_docs_into_chunks_and_sentences(\n",
        "                    list_of_strings=dset_static_train_thisset,\n",
        "                    config_chunking=copy.deepcopy(data_streaming_config),\n",
        "                    seed=seed+epoch,\n",
        "                    nlp=nlp\n",
        "                )\n",
        "                print('done trains longtext chunking')\n",
        "\n",
        "                # ensure that none of the examples in the traning set are in the validation set\n",
        "                if do_make_valset:\n",
        "                    dset_train_chunked_for_mlm = [\n",
        "                        s for s in dset_train_chunked_for_mlm\n",
        "                        if s not in dset_val_chunked_for_mlm\n",
        "                    ]\n",
        "                    dset_train_nextsentence = [\n",
        "                        tlt for tlt in dset_train_nextsentence\n",
        "                        if (\n",
        "                            tlt['anchor'] not in [\n",
        "                                vtlt['anchor'] for vtlt in dset_val_nextsentence\n",
        "                            ]\n",
        "                        )\n",
        "                    ]\n",
        "\n",
        "                # add to training set\n",
        "                datalist_train_mlm_static.extend(dset_train_chunked_for_mlm)\n",
        "                datalist_train_sentences_static.extend(dset_train_nextsentence)\n",
        "                # log the sources of text\n",
        "                log_source_train[dataset_key] = len(dset_train_chunked_for_mlm)\n",
        "\n",
        "        print('Done collecting streaming data')\n",
        "\n",
        "    if do_make_valset:\n",
        "        print('saving streamed validation data: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_val_mlm_static, pcon)\n",
        "            pickle.dump(datalist_val_sentences_static, pcon)\n",
        "            pickle.dump(epoch,pcon)\n",
        "            pickle.dump(log_source_val, pcon)\n",
        "    if do_make_trainset:\n",
        "        print('saving streamed training for epoch %d: %s' % (epoch, path_to_train_cache))\n",
        "        with open(path_to_train_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_train_mlm_static, pcon)\n",
        "            pickle.dump(datalist_train_sentences_static, pcon)\n",
        "            pickle.dump(epoch,pcon)\n",
        "            pickle.dump(log_source_train,pcon)\n",
        "    return {\n",
        "        'train':{\n",
        "            'mlm':datalist_train_mlm_static,\n",
        "            'nextsentence':datalist_train_sentences_static\n",
        "        },\n",
        "        'val':{\n",
        "            'mlm':datalist_val_mlm_static,\n",
        "            'nextsentence':datalist_val_sentences_static\n",
        "        },\n",
        "        'epoch':epoch,\n",
        "        'index_stream':start_proportion,\n",
        "        'log_source':{'train':log_source_train, 'val':log_source_val}\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569,
          "referenced_widgets": [
            "e0d054a9b7e542a2b3baacae63505902",
            "9c8ab19e291e49abb168771f34f815cf",
            "28b6b9dd2e764332b9f70f44ea76dd88",
            "03bf9c4f6d2e4522b45662b08b132119",
            "8463c6ee6a6a4495a99ec524e6b45b0b",
            "3d610e9d8f1c40aba63271f63e816f52",
            "44b63624787b4dc7b92f77a1b1401523",
            "4ebfe65a2ed34ba192ea315c5adedc8c",
            "0ebfe1d120694a0b8017349380832d46",
            "21d6717e21f34e78aff2ba659915049e",
            "a9a643803d32406391d24a7d34a76314",
            "0c9c1811fae340ceb7492141e6c851ff",
            "77c0ad37b8ef4924a88e3841f440582c",
            "8d97cd879ba847c49bd2efee97cbb580",
            "cc41c738e24b4f69839b4d56dff7e6c8",
            "14a6bb9a906d480cbea0aced476bc387",
            "425a7763611e48dbba54d8d727332a42",
            "3020e229affc4700aa868dd4a2b5e571",
            "8c488eb7f9c44e1f8af1954b13de5836",
            "3b6fb92ae8674429aacb5e3ea6c71bc6",
            "199e3a188ac34c81afec0f8a00814586",
            "d727d6119b3548d5893b2575f32423b8"
          ]
        },
        "id": "euHxSzBA2cFG",
        "outputId": "0137635a-0786-4a78-f701-365a30b954af"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trying EleutherAI/the_pile_deduplicated initialization (shuffling through 1650 files)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0d054a9b7e542a2b3baacae63505902",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/1650 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration EleutherAI--the_pile_deduplicated-7876b99d9513d623\n",
            "INFO:datasets.builder:Using custom data configuration EleutherAI--the_pile_deduplicated-7876b99d9513d623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 35 from EleutherAI/the_pile_deduplicated validation\n",
            "take 179 from EleutherAI/the_pile_deduplicated training\n",
            "Done getting streams/reloading from EleutherAI/the_pile_deduplicated\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying tiiuae/falcon-refinedweb initialization (shuffling through 5534 files)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c9c1811fae340ceb7492141e6c851ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/5534 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-33459d9d641983a0\n",
            "INFO:datasets.builder:Using custom data configuration default-33459d9d641983a0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 35 from tiiuae/falcon-refinedweb validation\n",
            "take 178 from tiiuae/falcon-refinedweb training\n",
            "Done getting streams/reloading from tiiuae/falcon-refinedweb\n",
            "done val language check\n",
            "done val longtext chunking\n",
            "done train language check\n",
            "done trains longtext chunking\n",
            "trying Cohere/wikipedia-22-12 initialization (shuffling through 351 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/Cohere--wikipedia-22-12/6dd523fbe67151cac99b22f6c6fc8b33db6292f9682e49305b3fad58edc34802\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/Cohere--wikipedia-22-12/6dd523fbe67151cac99b22f6c6fc8b33db6292f9682e49305b3fad58edc34802\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 59 from Cohere/wikipedia-22-12 validation\n",
            "take 295 from Cohere/wikipedia-22-12 training\n"
          ]
        }
      ],
      "source": [
        "data_streaming_config_mlm = {\n",
        "    'files':mlm_files,\n",
        "    'val_size':200, #2000,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':1000, #6000,\n",
        "    'max_chunk_start':1000000,\n",
        "    \"seed\":42,\n",
        "}\n",
        "\n",
        "#!rm cache_*\n",
        "dataset_static_mlm = initialize_and_get_mlm_streaming_datasets(\n",
        "    data_streaming_config=data_streaming_config_mlm,\n",
        "    streaming_cleaning_functions=mlm_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=2,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_mlms.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_mlm_%03g.pkl',\n",
        "    do_check_english = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "sums = {}\n",
        "for setnm,setcnt in dataset_static_mlm['log_source'].items():\n",
        "    #if setnm=='train':\n",
        "    #    continue\n",
        "    for dnm,dcnt in setcnt.items():\n",
        "        if dnm not in sums: sums[dnm]=0\n",
        "        sums[dnm]+=dcnt\n",
        "print(json.dumps({k:round(v/sum([a for a in sums.values()]),4) for k,v in sums.items()},indent=3))\n",
        "\n",
        "#dataset_static_mlm['log_source']\n",
        "\n",
        "print('TRAIN')\n",
        "print(json.dumps(dataset_static_mlm['log_source']['train'],indent=3))\n",
        "print('VAL')\n",
        "print(json.dumps(dataset_static_mlm['log_source']['val'],indent=3))\n",
        "\n",
        "# epoch 0\n",
        "epoch_0 = {\n",
        "   \"EleutherAI/the_pile_deduplicated\": 0.1376,\n",
        "   \"tiiuae/falcon-refinedweb\": 0.113,\n",
        "   \"Cohere/wikipedia-22-12\": 0.0472,\n",
        "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 0.3048,\n",
        "   \"big_patent\": 0.0192,\n",
        "   \"pile-of-law/pile-of-law/euro_parl\": 0.0223,\n",
        "   \"kerinin/hackernews-stories\": 0.0192,\n",
        "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 0.0239,\n",
        "   \"pile-of-law/pile-of-law/r_legaladvice\": 0.0062,\n",
        "   \"pile-of-law/pile-of-law/exam_outlines\": 0.0032,\n",
        "   \"pile-of-law/pile-of-law/cc_casebooks\": 0.0156,\n",
        "   \"eloukas/edgar-corpus\": 0.0767,\n",
        "   \"Rahmaa/ElsevieR_ClEaN\": 0.1162,\n",
        "   \"ashraq/financial-news-articles\": 0.0071,\n",
        "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 0.0436,\n",
        "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 0.0136,\n",
        "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 0.0139,\n",
        "   \"launch/gov_report\": 0.0168\n",
        "}\n",
        "\n",
        "epoch_1 = {\n",
        "   \"EleutherAI/the_pile_deduplicated\": 0.1584,\n",
        "   \"tiiuae/falcon-refinedweb\": 0.1311,\n",
        "   \"Cohere/wikipedia-22-12\": 0.1173,\n",
        "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 0.1759,\n",
        "   \"big_patent\": 0.0213,\n",
        "   \"pile-of-law/pile-of-law/euro_parl\": 0.0259,\n",
        "   \"kerinin/hackernews-stories\": 0.0206,\n",
        "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 0.03,\n",
        "   \"pile-of-law/pile-of-law/r_legaladvice\": 0.0069,\n",
        "   \"pile-of-law/pile-of-law/exam_outlines\": 0.0041,\n",
        "   \"pile-of-law/pile-of-law/cc_casebooks\": 0.0187,\n",
        "   \"eloukas/edgar-corpus\": 0.0547,\n",
        "   \"Rahmaa/ElsevieR_ClEaN\": 0.1182,\n",
        "   \"ashraq/financial-news-articles\": 0.0063,\n",
        "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 0.0337,\n",
        "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 0.0168,\n",
        "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 0.0202,\n",
        "   \"launch/gov_report\": 0.0221,\n",
        "   \"izumi-lab/open-text-books\": 0.0178\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr9pqs6AmG3D",
        "outputId": "f07f10f2-a5b0-4cfd-d4b9-6c7727a5120d"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "   \"EleutherAI/the_pile_deduplicated\": 0.1584,\n",
            "   \"tiiuae/falcon-refinedweb\": 0.1311,\n",
            "   \"Cohere/wikipedia-22-12\": 0.1173,\n",
            "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 0.1759,\n",
            "   \"big_patent\": 0.0213,\n",
            "   \"pile-of-law/pile-of-law/euro_parl\": 0.0259,\n",
            "   \"kerinin/hackernews-stories\": 0.0206,\n",
            "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 0.03,\n",
            "   \"pile-of-law/pile-of-law/r_legaladvice\": 0.0069,\n",
            "   \"pile-of-law/pile-of-law/exam_outlines\": 0.0041,\n",
            "   \"pile-of-law/pile-of-law/cc_casebooks\": 0.0187,\n",
            "   \"eloukas/edgar-corpus\": 0.0547,\n",
            "   \"Rahmaa/ElsevieR_ClEaN\": 0.1182,\n",
            "   \"ashraq/financial-news-articles\": 0.0063,\n",
            "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 0.0337,\n",
            "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 0.0168,\n",
            "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 0.0202,\n",
            "   \"launch/gov_report\": 0.0221,\n",
            "   \"izumi-lab/open-text-books\": 0.0178\n",
            "}\n",
            "TRAIN\n",
            "{\n",
            "   \"EleutherAI/the_pile_deduplicated\": 813,\n",
            "   \"tiiuae/falcon-refinedweb\": 645,\n",
            "   \"Cohere/wikipedia-22-12\": 545,\n",
            "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 910,\n",
            "   \"big_patent\": 108,\n",
            "   \"pile-of-law/pile-of-law/euro_parl\": 127,\n",
            "   \"kerinin/hackernews-stories\": 113,\n",
            "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 148,\n",
            "   \"pile-of-law/pile-of-law/r_legaladvice\": 32,\n",
            "   \"pile-of-law/pile-of-law/exam_outlines\": 21,\n",
            "   \"pile-of-law/pile-of-law/cc_casebooks\": 100,\n",
            "   \"eloukas/edgar-corpus\": 285,\n",
            "   \"Rahmaa/ElsevieR_ClEaN\": 591,\n",
            "   \"ashraq/financial-news-articles\": 32,\n",
            "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 199,\n",
            "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 90,\n",
            "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 98,\n",
            "   \"launch/gov_report\": 117,\n",
            "   \"izumi-lab/open-text-books\": 82\n",
            "}\n",
            "VAL\n",
            "{\n",
            "   \"EleutherAI/the_pile_deduplicated\": 263,\n",
            "   \"tiiuae/falcon-refinedweb\": 246,\n",
            "   \"Cohere/wikipedia-22-12\": 252,\n",
            "   \"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\": 285,\n",
            "   \"big_patent\": 37,\n",
            "   \"pile-of-law/pile-of-law/euro_parl\": 49,\n",
            "   \"kerinin/hackernews-stories\": 27,\n",
            "   \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\": 56,\n",
            "   \"pile-of-law/pile-of-law/r_legaladvice\": 15,\n",
            "   \"pile-of-law/pile-of-law/exam_outlines\": 7,\n",
            "   \"pile-of-law/pile-of-law/cc_casebooks\": 27,\n",
            "   \"eloukas/edgar-corpus\": 87,\n",
            "   \"Rahmaa/ElsevieR_ClEaN\": 212,\n",
            "   \"ashraq/financial-news-articles\": 11,\n",
            "   \"pile-of-law/pile-of-law/courtlistener_opinions\": 30,\n",
            "   \"pile-of-law/pile-of-law/sec_administrative_proceedings\": 24,\n",
            "   \"pile-of-law/pile-of-law/irs_legal_advice_memos\": 39,\n",
            "   \"launch/gov_report\": 33,\n",
            "   \"izumi-lab/open-text-books\": 39\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nKlnrcC3G9n",
        "outputId": "42fe1ed0-1319-481f-bd4c-a51a58d11c39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'anchor': 'He passes upon all the motions, he supervises all the discovery and pre-trial proceedings and he decides when the cases are to be tried.',\n",
              " 'next': '4\\nNor do we find any miscarriage of justice in this case or the slightest hint or scintilla of evidence that the proceedings were expedited \"at the expense of justice.\"',\n",
              " 'opposite': 'I was unaware that a history of alcoholism disentitled an injured person to recovery.\\n\\n\\n 23\\n5. The majority refers to Mr. Lamb in language better reserved, I think, for common criminals as a \"chronic falsifier of the evidence.\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ],
      "source": [
        "#!rm *.pkl\n",
        "np.random.choice(dataset_static_mlm['train']['nextsentence'])\n",
        "#dataset_static_mlm['train']['mlm'][110]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCG8JHCz3Xzp"
      },
      "source": [
        "\n",
        "### Q&A Triplets!\n",
        "\n",
        "Here I make a triplet dataset of query, positive answer, and negatives (if available)\n",
        "\n",
        "B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- DONE LLukas22/lfqa_preprocessed - question and answers 226k (from REDDIT)\n",
        "- DONE gbharti/finance-alpaca (like FIQA - finance Q&A) on 14k?\n",
        "- DONE embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- GONE the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- DONE donfu/oa-stackexchange - 6.3 million (AND GROWING -- must monitor)\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- DONE sciq - science questions - see question and support\n",
        "- DONE wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers\n",
        "- DONE JoBeer/eclassTrainST - can easily convert into question-answer pairs\n",
        "- DONE - dictinonary -\n",
        "- DONE POLICY QA - alzoubi36/policy_qa (has contracts and questions about contract)\n",
        "=ra)\n",
        "- TODO sc2qa/sc2q_commoncrawl - qa on common crawl with 45k\n",
        "- TODO: yahoo_answers_topics (filter for 6=business; 3=education; 9=govt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q96FHzngk0FH",
        "outputId": "42e76e56-8ade-4ede-d465-650cb56ada00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to: gov_report_qs/paragraph\n",
            "INFO:datasets.builder:No config specified, defaulting to: gov_report_qs/paragraph\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report_qs/bb5dd166005269e4124933219e1def95272a1197dde526383d05c88cc83548d2\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report_qs/bb5dd166005269e4124933219e1def95272a1197dde526383d05c88cc83548d2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doc_id': 'CRS_R43130', 'summary_paragraph_index': 3, 'document_sections': {'title': ['Politics and Governance Under President Zuma', 'Governance Challenges', 'Youth Population: Political Potential and Character'], 'paragraphs': [\"The ANC has held a large majority in the National Assembly (parliament) since the first universal suffrage elections in 1994, and currently holds a majority just shy of the two-thirds required to amend the constitution. The parliament elects the country's president and, as a result, the ANC has controlled the executive branch since 1994. The ANC customarily nominates its party president to serve as national president, with some exceptions (see textbox below). The assembly elected the incumbent ANC president, Jacob Zuma, to his first term as national president in 2009.\\nDespite rising criticism of Zuma and internal party challenges to his candidacy, Zuma mounted a carefully crafted, successful campaign to ensure his reelection as head of the ANC at a late 2012 ANC party congress. He easily thwarted a belated and reportedly ill-coordinated rival bid by his deputy, Kgalema Motlanthe. Zuma's election as head of the ANC means that he is almost certain to win a second term as South Africa's president.\", \"While the challenges identified and solutions offered by the NDP are the product of sober public policy analyses and planning, they also reflect a politically realistic self-assessment by the government; its findings dovetail with the views of many government and ANC critics. This is particularly true of unemployment, lack of educational and healthcare access, poor public service delivery, crime, and corruption, which are notable sources of widespread public anger. A wave of often violent mass labor strikes in 2012 was accompanied by a sharp rise in protests over inadequate township service delivery in 2012. At least 226 such protests occurred during the first eight months of 2012 and, as with labor protests, many were violent. Such protests have been common for many years but have steadily risen. Ineffective police responses or other actual or perceived failures by the criminal justice system have also often been the focus on local protests in recent years. In some instances, protests turn into acts of vigilante justice (e.g., lynchings and extra-judicial mob beatings or killings of suspected criminals).\\nCorruption by economic elites, including some senior ANC members, of policies aimed at reversing the economic inequalities of the apartheid era has also stirred resentment. The same is true of the ANC's reportedly often politicized management of public goods and services, which frequently appears to financially benefit its local or national leaders, their kin, or associates. Such practices and the local political violence that they may generate are a reflection of the dearth of economic opportunities for blacks. For blacks with limited education and job prospects, local government posts gained through party ties may be one of the few ways out of poverty. Such actions often breed antipathy, however. According to one writer:\\nLocal protests, in which [the ANC's] own members are participants, are increasingly hard to manage. While in the past, protestors symbolically burned public property, targets are now the homes, cars and persons of ANC councilors. ANC branch and regional politics has become dirty and violent, with some members carrying firearms to meetings and attacks and shootings of local leaders are not infrequent.\", 'Another long-term challenge for the ANC government stems from South Africa\\'s large youth population, especially those born after 1994. Dubbed the \"born free\" generation, they comprise about 38% of the population and have always lived in a democracy. Of this age cohort, nearly 2 million (almost 10% of the potential electorate) will be eligible to vote for the first time in the 2014 elections. The group will make up nearly 23% of eligible voters in the 2019 elections (when the entire generation will make up 48% of the population). Adults under 35 years of age suffer especially high unemployment rates, estimated at over 50%. The \"born-free\" group shares frustrations with older generations over corruption, lack of services, and poverty, but many are reportedly not party-affiliated and lack older generations\\' continuing allegiance and gratitude to the ANC for its role in ending apartheid. Generational rifts have recently been on display within the ANC Youth League (ANCYL) in relation to the ANC\\'s expulsion of the fiery, populist former ANCYL leader, Julius Malema. Youth also participate in more service protests than do older generations, but reportedly vote less often than their elders, which may attenuate their potential electoral influence. To cater to youth demands, political parties have vied to introduce state youth wage and jobs schemes (often in the face of union opposition), expanded skills training programs, and youth-friendly procurement and hiring preferences.'], 'depth': [1, 2, 3]}, 'question_summary_pairs': {'question': ['What did the ANC party do in late 2012?', 'What challenges does the ANC government face?', 'Why are youths dissatisfied with the ANC?', 'How is the government trying to address these challenges?'], 'summary': ['In late 2012, the governing African National Congress (ANC) party, despite some reported internal divisions, reelected as its president Jacob Zuma, ahead of the May 2014 national elections.', 'The ANC government faces the substantial challenges noted above, along with others, including labor unrest, rising dissatisfaction within key labor constituencies, and dissatisfaction among youths.', \"Youth populations face particularly high jobless rates and may lack older generations' continuing allegiance and gratitude to the ANC for helping to end apartheid.\", 'To address these diverse challenges, all of which are electoral issues, the government is investing billions of dollars to upgrade infrastructure and improve public service delivery, but is likely to face continuing challenges in meeting popular expectations.'], 'parent_pair_index': [-1, -1, 1, 1]}, 'query': 'what did the ANC party do in late 2012, what challenges does the ANC government face, and why are youths dissatisfied with the ANC?', 'positives': [\"In late 2012, the governing African National Congress (ANC) party, despite some reported internal divisions, reelected as its president Jacob Zuma, ahead of the May 2014 national elections. The ANC government faces the substantial challenges noted above, along with others, including labor unrest, rising dissatisfaction within key labor constituencies, and dissatisfaction among youths. Youth populations face particularly high jobless rates and may lack older generations' continuing allegiance and gratitude to the ANC for helping to end apartheid. To address these diverse challenges, all of which are electoral issues, the government is investing billions of dollars to upgrade infrastructure and improve public service delivery, but is likely to face continuing challenges in meeting popular expectations.\"], 'negatives': []}\n",
            "dict_keys(['doc_id', 'summary_paragraph_index', 'document_sections', 'question_summary_pairs', 'query', 'positives', 'negatives'])\n"
          ]
        }
      ],
      "source": [
        "#JoBeer/eclassTrainST\n",
        "#foo =  load_dataset('gart-labor/eclassTrainST',split='train',streaming=True).map(clean_eclassTrainST).remove_columns(['text', 'entailment', 'contradiction', 'label'])\n",
        "#foo =  load_dataset('gbharti/finance-alpaca',split='train',streaming=True)  # good, financial questions\n",
        "#foo =  load_dataset('gart-labor/eclassTrainST',split='train',streaming=True) # NAD; just for paraphrased questions, not for QA\n",
        "# foo =  load_dataset('parquet',data_files = 'https://huggingface.co/datasets/gart-labor/eclassTrainST/resolve/main/data/eval-00001-of-00001-d8aa08935841e6a9.parquet',split='train',streaming=False) # NAD; just for paraphrased questions, not for QA\n",
        "#foo =  load_dataset('wiki_qa',split='train',streaming=True) # excellent; with negatives and positives\n",
        "#foo =  load_dataset('THUDM/webglm-qa',split='train',streaming=True) # excellent; with negatives and positives\n",
        "#foo = load_dataset(\"sciq\",split='train',streaming=False) #\n",
        "#foo = load_dataset(\"LLukas22/lfqa_preprocessed\", split='train',streaming=True)\n",
        "\n",
        "def clean_govreportqa(x):\n",
        "    q_raw = x['question_summary_pairs']['question']\n",
        "    a_raw = x['question_summary_pairs']['summary']\n",
        "    if len(q_raw)==1:\n",
        "        q_concat = q_raw[0]\n",
        "        a_concat = a_raw[0]\n",
        "    elif len(q_raw)<=3 and len(q_raw)>1:\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    else:\n",
        "        q_raw = q_raw[:2] + [random.choice(q_raw[2:])]\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    x['query']=q_concat\n",
        "    x['positives']=[a_concat]\n",
        "    x['negatives']=[]\n",
        "    return x\n",
        "\n",
        "foo = load_dataset(\"launch/gov_report_qs\", split='train',streaming=True).map(clean_govreportqa) # ['id', 'title', 'context', 'question', 'answers'] # context is the answer\n",
        "\n",
        "examples = []\n",
        "#add definitions\n",
        "if True:\n",
        "    # embedding-data/WikiAnswers\n",
        "    for j,e in enumerate(foo):\n",
        "        #print(e)\n",
        "        clean_govreportqa(e)\n",
        "        if j > 3000:\n",
        "          break\n",
        "        examples.append(e)\n",
        "    print(e)\n",
        "    print(e.keys())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples[50]['query']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5sXoZL-2rUZW",
        "outputId": "d93d28ff-9888-413d-b6f3-305b98625e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what accounts for the growth in individuals on SSDI, what do these demographic changes consist of, and what is non-demographic growth?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHB8cc5SmXFL"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data as torch_data\n",
        "from rank_bm25 import BM25Okapi\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABJazLSA3WTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688e6b8c-c011-4654-f078-e1f061a9406a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TODO:\n",
            "Blacks law: try streaming this CSV file (or just get it):\n",
            "https://github.com/LexPredict/lexpredict-legal-dictionary/blob/master/sources/blacks_second_edition/blacks_second_edition_terms.csv\n",
            "And probably filter for length, add a context\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\"\"TODO:\n",
        "Blacks law: try streaming this CSV file (or just get it):\n",
        "https://github.com/LexPredict/lexpredict-legal-dictionary/blob/master/sources/blacks_second_edition/blacks_second_edition_terms.csv\n",
        "And probably filter for length, add a context\n",
        "\"\"\")\n",
        "\n",
        "def clean_govreportqa(x):\n",
        "    q_raw = x['question_summary_pairs']['question']\n",
        "    a_raw = x['question_summary_pairs']['summary']\n",
        "    if len(q_raw)==1:\n",
        "        q_concat = q_raw[0]\n",
        "        a_concat = a_raw[0]\n",
        "    elif len(q_raw)<=3 and len(q_raw)>1:\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    else:\n",
        "        q_raw = q_raw[:2] + [random.choice(q_raw[2:])]\n",
        "        q_proc = [q[0].lower() + q[1:].strip('?') for q in q_raw]\n",
        "        q_concat = ', '.join(q_proc[:-1]) + ', and ' + q_proc[-1] + '?'\n",
        "        a_concat = ' '.join(a_raw)\n",
        "    x['query']=q_concat\n",
        "    x['positives']=[a_concat]\n",
        "    x['negatives']=[]\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "POLICYQA_PREPEND = [\n",
        "    \"Regarding the online Terms of Service and Data Protection policies: %s\",\n",
        "    \"Considering your data security, %s\",\n",
        "    \"With respect to user privacy guidelines, %s\",\n",
        "    \"As outlined in the data protection commitments, %s\",\n",
        "    \"Pertaining to the terms of service, %s\",\n",
        "    \"Addressing information usage, %s\",\n",
        "    \"Pertaining to data confidentiality, %s\",\n",
        "    \"In connection to your privacy assurance, %s\",\n",
        "    \"Touching upon online data policies, %s\",\n",
        "    \"In alignment with your user data safeguards, %s\",\n",
        "    \"Taking a closer look at data security, %s\",\n",
        "    \"In light of your user-information protocols, %s\",\n",
        "    \"Within the context of user data sharing, %s\",\n",
        "    \"In consideration for user data ownership, %s\",\n",
        "    \"In consideration of data securty and user-data protection, %s\",\n",
        "    \"In regards to your online services, %s\",\n",
        "    \"Regarding your data handling procedures and policies, %s\",\n",
        "    \"In the context of user information disclosure and privacy, %s\",\n",
        "    \"As per the information security policies, %s\",\n",
        "    \"In the context of the Terms of Service: %s\",\n",
        "    \"%s (in the context of your online Terms of Service)\"\n",
        "]\n",
        "\n",
        "STACKEXCHANGE_NONQUANT_DOMAINS = [\n",
        "    \"stackexchange-\"+k for k in [\n",
        "        \"academia\",\n",
        "        \"aviation\",\n",
        "        \"bicycles\",\n",
        "        \"biology\",\n",
        "        \"buddhism\",\n",
        "        \"chemistry\",\n",
        "        \"chess\",\n",
        "        \"christianity\",\n",
        "        \"coffee\",\n",
        "        \"cogsci\",\n",
        "        \"cooking\",\n",
        "        \"crafts\",\n",
        "        \"cseducators\",\n",
        "        \"diy\",\n",
        "        \"drones\",\n",
        "        \"earthscience\",\n",
        "        \"ebooks\",\n",
        "        \"electronics\",\n",
        "        \"english\",\n",
        "        \"expatriates\",\n",
        "        \"fitness\",\n",
        "        \"freelancing\",\n",
        "        \"gardening\",\n",
        "        \"gaming\",\n",
        "        \"genealogy\",\n",
        "        \"ham\",\n",
        "        \"hardwarerecs\",\n",
        "        \"health\",\n",
        "        \"hinduism\",\n",
        "        \"history\",\n",
        "        \"homebrew\",\n",
        "        \"hsm\",\n",
        "        \"interpersonal\",\n",
        "        \"iot\",\n",
        "        \"islam\",\n",
        "        \"judaism\",\n",
        "        \"law\",\n",
        "        \"lifehacks\",\n",
        "        \"linguistics\",\n",
        "        \"literature\",\n",
        "        \"martialarts\",\n",
        "        \"materials\",\n",
        "        \"mechanics\",\n",
        "        \"moderators\",\n",
        "        \"money\",\n",
        "        \"music\",\n",
        "        \"mythology\",\n",
        "        \"outdoors\",\n",
        "        \"parenting\",\n",
        "        \"patents\",\n",
        "        \"pets\",\n",
        "        \"philosophy\",\n",
        "        \"pm\",\n",
        "        \"politics\",\n",
        "        \"security\",\n",
        "        \"skeptics\",\n",
        "        \"softwarerecs\",\n",
        "        \"sustainability\",\n",
        "        \"travel\",\n",
        "        \"vegetarianism\",\n",
        "        \"woodworking\",\n",
        "        \"workplace\",\n",
        "        \"worldbuilding\",\n",
        "        \"writers\"\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "list_of_dictionary_paraphrases = [\n",
        "    \"Define the term: %s\",\n",
        "    \"What is the definition of the following word or expression: %s\",\n",
        "    \"Define the following term: %s\",\n",
        "    \"what does the following term mean: %s\",\n",
        "    \"What is the definition of the following word: %s\",\n",
        "    'Provide the definition for the term \"%s\".',\n",
        "    'Explain the meaning of the word \"%s\".',\n",
        "    'Elucidate the definition of \"%s\".',\n",
        "    'Clarify the term \"%s\".',\n",
        "    'What does the word \"%s\" signify?',\n",
        "    'Provide a definition for \"%s\".',\n",
        "    'How is the term \"%s\" defined?',\n",
        "    'What exactly is meant by \"%s\"?',\n",
        "    'Share the definition of \"%s\".',\n",
        "    'Offer a definition for word or expression \"%s\".',\n",
        "    'Explain what \"%s\" refers to.',\n",
        "    'Define the term \"%s\", please.',\n",
        "    'What\\'s the definition of \"%s\"?',\n",
        "    'Please elucidate \"%s\".',\n",
        "    'How is \"%s\" defined?',\n",
        "    'Explain the concept behind \"%s\".',\n",
        "    'What is meant by the word \"%s\"?',\n",
        "    'Can you give the definition of \"%s\"?',\n",
        "    'Could you provide the meaning of \"%s\"?',\n",
        "    'Please offer the definition of \"%s\".'\n",
        "]\n",
        "\n",
        "\n",
        "def filter_dictionary(x):\n",
        "    \"\"\"get definitions of only medium sized words with large definitions\"\"\"\n",
        "    if x['word'] is None:\n",
        "        return False\n",
        "    return len(x['definition'])>100 and len(x['word'].replace(\" \",''))>=4\n",
        "\n",
        "def clean_dictionary(x):\n",
        "    \"\"\"converts a dictionary term into a question, sampling randomly from 20 template questions\"\"\"\n",
        "    idx_random_question_template = ord(x['definition'].replace(' ','')[-6]) % len(list_of_dictionary_paraphrases)\n",
        "    question_template =list_of_dictionary_paraphrases[idx_random_question_template]\n",
        "    x['query'] = question_template % x['word']\n",
        "    x['positives'] = [x['definition']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_webglmqa(x):\n",
        "    x['query']=x['question']\n",
        "    x['positives'] = [x['answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_PAQ_pairs(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_finance_alpaca(x):\n",
        "    x['query'] = x['instruction']\n",
        "    x['positives'] = [x['output']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_wiki_qa(x):\n",
        "    x['query'] = x['question']\n",
        "    is_pos = x['label']\n",
        "    answer = x['answer']\n",
        "    pos = [answer] if is_pos else []\n",
        "    neg = [answer] if (not is_pos) else []\n",
        "    x['positives'] = pos\n",
        "    x['negatives'] = neg\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_oa_stackexchange(x):\n",
        "    x['query'] = x['INSTRUCTION']\n",
        "    x['positives'] = [x['RESPONSE']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_sciqa(x):\n",
        "    x['query'] = x['question']\n",
        "    x['positives'] = [x['support']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_lfqa(x):\n",
        "    x['query'] = x['question']\n",
        "    x['positives'] = [x['answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def filter_os_stackexchange(x):\n",
        "    return x['SOURCE'] in STACKEXCHANGE_NONQUANT_DOMAINS\n",
        "\n",
        "def get_name_and_description_eclassTrainST(text):\n",
        "    description, name = text.split(\"; Name:\")\n",
        "    return description.replace(\"Description: \",\"\").strip(), name.strip()\n",
        "\n",
        "def clean_eclassTrainST(x):\n",
        "    \"\"\"This set isn't really about entailment/contradiction; it is really a dictionary\"\"\"\n",
        "    description, name = get_name_and_description_eclassTrainST(x['text'])\n",
        "    pos, _ = get_name_and_description_eclassTrainST(x['entailment'])\n",
        "    extra, _ = get_name_and_description_eclassTrainST(x['contradiction'])\n",
        "    x['query'] = 'What is a \"%s\"?' % name\n",
        "    x['positives'] = [pos]\n",
        "    x['negatives'] = []\n",
        "    # add the entailment as positive, contradiction as negatives\n",
        "    if x['label'] == 'entailment':\n",
        "        x['positives'].append(extra)\n",
        "    else:\n",
        "        x['negatives'] = [extra]\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "# do to: alzoubi36/policy_qa - policy questions\n",
        "def clean_policyqa(x):\n",
        "    \"\"\"Adds more context to the questions about data security in the alzoubi36/policy_qa qa set \"\"\"\n",
        "    idx_random_question_template = ord(x['context'].replace(' ','')[-5]) % len(POLICYQA_PREPEND)\n",
        "    question_template =POLICYQA_PREPEND[idx_random_question_template]\n",
        "    q = x['question']\n",
        "    q = q[0].lower() + q[1:]\n",
        "    x['query'] = question_template % q # ['id', 'title', 'context', 'question', 'answers']\n",
        "    x['positives'] = [x['context']]\n",
        "    # fetch a negative from the negative corpus\n",
        "    negatives_random, _ = negative_example_generator.find_negative(x['context'], k = 1, skip=10)\n",
        "    x['negatives'] = negatives_random\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_sc2qa(x):\n",
        "    x['query'] = x['question']\n",
        "    x['positives'] = [x['article']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_yahooanswers(x):\n",
        "    x['query'] = (x['question_title'] + \" \" + x['question_content']).strip() # 'question_title', 'question_content'\n",
        "    x['positives'] = [x['best_answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def filter_yahooanswers(x):\n",
        "    \"\"\"Yahoo news filtering (filter for 6=business; 3=education; 9=govt)\"\"\"\n",
        "    return x['topic'] in [3,6,9] and len(x['question_title'])>10 and len(x['best_answer'])>10\n",
        "\n",
        "#dict_keys(['question_id', 'question', 'document_title', 'answer', 'label'])\n",
        "qa_streaming_cleaning_functions = {\n",
        "    'embedding-data/PAQ_pairs':(clean_stream_PAQ_pairs, None, ['query','positives','negatives'],['set']),\n",
        "    'gbharti/finance-alpaca':(clean_stream_finance_alpaca,None, ['query','positives','negatives'],['input', 'output', 'text', 'instruction']),\n",
        "    'wiki_qa':(clean_stream_wiki_qa, None, ['query','positives','negatives'],['question_id', 'question', 'document_title', 'answer', 'label']),\n",
        "    'donfu/oa-stackexchange':(clean_stream_oa_stackexchange, filter_os_stackexchange, ['query','positives','negatives'], ['INSTRUCTION', 'RESPONSE', 'SOURCE', 'METADATA']),\n",
        "    'gart-labor/eclassTrainST':(clean_eclassTrainST, None, ['query','positives','negatives'], ['text', 'entailment', 'contradiction', 'label']),\n",
        "    'THUDM/webglm-qa':( clean_webglmqa, None, ['query','positives','negatives'], ['question','answer','references']),\n",
        "    'sciqa': (clean_stream_sciqa, None, ['query','positives','negatives'], ['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support']),\n",
        "    'LLukas22/lfqa_preprocessed':(clean_lfqa, None, ['query','positives','negatives'], ['question','answer','context']), #REDDIT QUESTION ANSWERS (ASK historians, ask me like I'M FIVE)\n",
        "    'npvinHnivqn/EnglishDictionary':(clean_dictionary, filter_dictionary, ['query','positives','negatives'], ['word','definition']), # dictionaries\n",
        "    'alzoubi36/policy_qa':(clean_policyqa, None, ['query','positives','negatives'],  ['id', 'title', 'context', 'question', 'answers'] ), # PRIVACYGLUE\n",
        "    'sc2qa/sc2q_commoncrawl':(clean_sc2qa, None, ['query','positives','negatives'], ['question','article','url']),\n",
        "    'yahoo_answers_topics':(clean_yahooanswers, filter_yahooanswers, ['query','positives','negatives'], ['id', 'topic', 'question_title', 'question_content', 'best_answer']),\n",
        "    'launch/gov_report_qs':(clean_govreportqa, None, ['query','positives','negatives'],['doc_id', 'summary_paragraph_index', 'document_sections', 'question_summary_pairs'])\n",
        "}\n",
        "\n",
        "DEFAULT_PROB_QA = 0.1\n",
        "qa_files = [\n",
        "    ('embedding-data/PAQ_pairs',None, DEFAULT_PROB_QA, 7.29*10**6, 'qa_triplet', False), # wikipedia pop culture pairs # get from 'set', 7.29*10**6\n",
        "    ('gbharti/finance-alpaca',None, DEFAULT_PROB_QA, 6.89*10**5, 'qa_triplet', False), # Stanford's Alpaca (https://github.com/tatsu-lab/stanford_alpaca) and FiQA (https://sites.google.com/view/fiqa/) with another 1.3k pairs custom generated using GPT3.5\n",
        "    ('wiki_qa',None, DEFAULT_PROB_QA, 20.4*10**3, 'qa_triplet', False), # Wiki Question Answering corpus from Microsoft. with multiple negatives that are similar!\n",
        "    ('donfu/oa-stackexchange',None, DEFAULT_PROB_QA, 6330000, 'qa_triplet', (14, int(6330000//14))), # stack-exchange question-answer pairs, across lots of domains; notice the original is 6.6 million, but there is a filter\n",
        "    ('gart-labor/eclassTrainST', None, 0.02, 450912, 'qa_triplet', False), # questions about trade / business stuff\n",
        "    ('THUDM/webglm-qa', None, DEFAULT_PROB_QA, 43600, 'qa_triplet', False),\n",
        "    ('sciq',None, DEFAULT_PROB_QA, 11679, 'qa_triplet', False), # science questions from Allenai, with a question and support\n",
        "    ('LLukas22/lfqa_preprocessed', None, DEFAULT_PROB_QA, 226000,'qa_triplet',False),# REDDIT QUESTION ANSWERS (ASK historians, ask me like I'M FIVE)\n",
        "    ('npvinHnivqn/EnglishDictionary',None, DEFAULT_PROB_QA/4, 30864, 'qa_triplet',False), # 0.05 original size: 11200, post-file 30865\n",
        "    ('alzoubi36/policy_qa', None, DEFAULT_PROB_QA/4, 17100,  'qa_triplet',False),\n",
        "    ('sc2qa/sc2q_commoncrawl',None, DEFAULT_PROB_QA, 44500, 'qa_triplet', False),\n",
        "    ('yahoo_answers_topics', None, DEFAULT_PROB_QA, 401357,'qa_triplet', False),\n",
        "    ('launch/gov_report_qs','paragraph', DEFAULT_PROB_QA/5, 4878, 'qa_triplet', False),\n",
        "]\n",
        "\n",
        "qadata_streaming_config = {\n",
        "    'files':qa_files,\n",
        "    'max_seq_length':512,\n",
        "    'prepend_q': 'query: ',\n",
        "    'prepend_a': 'passage: ',\n",
        "    'val_size':1000,\n",
        "    'train_chunk_size':5000,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "def initialize_qa_streaming_datasets(data_streaming_config, streaming_cleaning_functions):\n",
        "    files = data_streaming_config['files']\n",
        "    qa_streaming_datsets, qa_probabilities, qa_datasizes = [],[],[]\n",
        "    for (qa_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle) in files:\n",
        "\n",
        "        if prob ==0:\n",
        "            continue\n",
        "        # get cleaning & filter functions for streaming data / map & filters\n",
        "        clean_func, filter_func, feature_names, removefeature_names = streaming_cleaning_functions[qa_nm]\n",
        "\n",
        "        # arguments for the load_dataset (huggingface repos)\n",
        "        load_dataset_args = {\n",
        "            'path':qa_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "        }\n",
        "        # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "        if qa_nm.endswith('.jsonl') or qa_nm.endswith('.jsonl.zip') or qa_nm.endswith('.jsonl.zst'):\n",
        "            load_dataset_args.update({'path':'json','data_files':qa_nm})\n",
        "\n",
        "        print('trying %s' % qa_nm)\n",
        "        if filter_func is None:\n",
        "            dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "        else:\n",
        "            dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "\n",
        "        qa_streaming_datsets.append(dset_stream)\n",
        "        qa_probabilities.append(prob);\n",
        "        qa_datasizes.append(dataset_size)\n",
        "\n",
        "    print('done initializing the QA streaming datasets')\n",
        "    return qa_streaming_datsets, qa_probabilities, qa_datasizes\n",
        "\n",
        "def streaming_skip(skip, list_of_streaming_datasets, probabilities, datasizes, seed=42, convert_to_static = False):\n",
        "    \"\"\"Function loops through a list of streaming datasets, skips a first K values based on the probabilities, and returns them\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for dset, p, size in list_of_streaming_datasets, normalized_p, datasizes:\n",
        "        skip_in_this_set = max(0,int(p)*skip)\n",
        "        out.append(dset.skip(skip_in_this_set))\n",
        "    return out\n",
        "\n",
        "def streaming_take(skip, start_proportion, chunksize, list_of_streaming_datasets, probabilities, datasizes,  convert_to_static = False):\n",
        "    \"\"\"Takes some examples based on a starting point within the dataset, as a proportion of its total size\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for j, (dset, p, size) in enumerate(zip(list_of_streaming_datasets, normalized_p, datasizes)):\n",
        "        #print(type(dset))\n",
        "        #print(type(p))\n",
        "        #print(type(size))\n",
        "        # skip for valset\n",
        "        skip_in_this_set = int(round(p*skip))\n",
        "        # afterwards, where to start?\n",
        "        skip_to_start = int(start_proportion*(size-skip_in_this_set))\n",
        "        take_from_this_set = int(round(chunksize*p))\n",
        "        if skip_to_start>0:\n",
        "            dset_skipped = dset.skip(skip_in_this_set+skip_to_start).take(take_from_this_set)\n",
        "        else:\n",
        "            dset_skipped = dset.take(take_from_this_set)\n",
        "\n",
        "        if not convert_to_static:\n",
        "            # option to return the streaming dataset\n",
        "            out.append(dset_skipped)\n",
        "        else:\n",
        "            # option just to convert the streaming dataset to static outputs\n",
        "            for example in dset_skipped:\n",
        "                example['source_id'] = j\n",
        "                out.append(example)\n",
        "        print('done %d' % j)\n",
        "    return out\n",
        "\n",
        "def train_test_splits_from_stream_qa(\n",
        "    streaming_dataset,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    path_to_val_cache = 'val_qa_cache.pkl',\n",
        "    probabilities = None,\n",
        "    datasizes = None,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"\n",
        "    val_size = 2000, number of streaming-iter to skip, reserved for the val-sze\n",
        "    epoch = 0, epoch will change the seed when sampling the chunk idx for making the training set\n",
        "    chunk_size = 5000, # number of streaming-iter to select the training data chunk\n",
        "    max_chunk_start = 2000000, # randomly sample within this interval for streaming chunks\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path_to_val_cache):\n",
        "        print('RELOADING VAL-QA SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            val_corpus_list = pickle.load(pcon)\n",
        "        print('VAL-QA SET SIZE: %d' % len(val_corpus_list))\n",
        "    else:\n",
        "        # stream validation set\n",
        "        print('STREAMING VAL-QA DATA: %d' % val_size)\n",
        "        val_corpus_list = streaming_take(\n",
        "            skip=0,\n",
        "            start_proportion=0,\n",
        "            chunksize=val_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "        print('REALIZED VAL-QA DATA: %d' % len(val_corpus_list))\n",
        "        # save the validation corpus\n",
        "        print('SAVING VAL-QA SET: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(val_corpus_list, pcon)\n",
        "\n",
        "    # take a random interger to start the streaming of training data\n",
        "    # starts at a random position\n",
        "    train_start_proportion = np.random.RandomState(seed + epoch).random()*0.99\n",
        "    print(train_start_proportion)\n",
        "\n",
        "    # stream training data\n",
        "    print('STREAMING TRAIN QA-DATA: %d STARTING AT: %0.3f' % (chunk_size,train_start_proportion))\n",
        "    train_corpus_list = streaming_take(\n",
        "            skip=val_size,\n",
        "            start_proportion=train_start_proportion,\n",
        "            chunksize=chunk_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "\n",
        "    print('REALISED TRAIN QA-DATA SIZE: %d' % len(train_corpus_list))\n",
        "    return {\n",
        "        'train':train_corpus_list,\n",
        "        'val':val_corpus_list,\n",
        "        'epoch':0,\n",
        "        'index_stream':train_start_proportion\n",
        "    }\n",
        "\n",
        "def initialize_and_get_triplet_streaming_datasets(\n",
        "    data_streaming_config,\n",
        "    streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_qa.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_qa_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'QA' #\n",
        "):\n",
        "    \"\"\"Converts stream of unlabelled text data into static datasets for: for Triplet data tasks (QA-task/IR-task)\"\"\"\n",
        "    # list of files to stream\n",
        "    print('Initializing the streaming-QA to static-dataset procedure...')\n",
        "    files = data_streaming_config['files']\n",
        "    # number of examples to take from stream for validation set\n",
        "    val_size = data_streaming_config['val_size']\n",
        "    # number of examples to take from stream for training set\n",
        "    train_chunk_size = data_streaming_config['train_chunk_size']\n",
        "    min_seq_len = data_streaming_config.get('min_seq_length', 48)\n",
        "    # normalization constant for normalizing the weights into probabilities\n",
        "    probability_normalization_const = sum([x[2] for x in files])\n",
        "\n",
        "    # where to initialize start-stream for training data\n",
        "    if start_proportion is None:\n",
        "        start_proportion = np.random.RandomState(seed+epoch).uniform()*0.95\n",
        "\n",
        "    # reload cached files\n",
        "    path_to_train_cache = None if not '%03g' in path_to_train_cache_epoch else path_to_train_cache_epoch % epoch\n",
        "    do_make_valset = not os.path.isfile(path_to_val_cache)\n",
        "    do_make_trainset = not os.path.isfile(path_to_train_cache)\n",
        "    if not do_make_valset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            datalist_val_triplet_static = pickle.load(pcon)\n",
        "        print(f'VAL-{name} SET SIZE: %d' % len(datalist_val_triplet_static))\n",
        "    else:\n",
        "        datalist_val_triplet_static = []\n",
        "    if not do_make_trainset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_train_cache,'rb') as pcon:\n",
        "            datalist_train_triplet_static = pickle.load(pcon)\n",
        "        print(f'TRAIN-{name} EPOCH-%d SET SIZE: %d' % (epoch, len(datalist_train_triplet_static)))\n",
        "    else:\n",
        "        datalist_train_triplet_static = []\n",
        "\n",
        "    if (do_make_trainset or do_make_valset):\n",
        "\n",
        "        # loop through datasets\n",
        "        for (data_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle), dataset_key in zip(\n",
        "            files, streaming_cleaning_functions.keys()\n",
        "        ):\n",
        "            if prob ==0:\n",
        "                continue\n",
        "            prob /= probability_normalization_const\n",
        "\n",
        "            # get cleaning & filter functions for streaming data functionality\n",
        "            clean_func, filter_func, feature_names, removefeature_names = streaming_cleaning_functions[dataset_key]\n",
        "\n",
        "            # set arguments for the load_dataset (huggingface repos)\n",
        "            load_dataset_args = {\n",
        "                'path':data_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "            }\n",
        "            # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "            if data_nm.endswith('.jsonl') or data_nm.endswith('.jsonl.zip') or data_nm.endswith('.jsonl.zst'):\n",
        "                load_dataset_args.update({'path':'json','data_files':data_nm})\n",
        "\n",
        "            # special proecssing of datasets with multiple partitions\n",
        "            if bool(partition_shuffle): # or str(epoch)=='val':\n",
        "\n",
        "                n_files, n_per_file = partition_shuffle\n",
        "                dataset_size = n_per_file\n",
        "                print('trying %s initialization (shuffling through %d files)' % (data_nm, n_files))\n",
        "\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func)\n",
        "\n",
        "                # validation set\n",
        "                if do_make_valset:\n",
        "                    # take from stream\n",
        "                    n_valset_take = max(int(prob*val_size), 1)\n",
        "                    print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert stream to a static set and do check\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "                # training set\n",
        "                if do_make_trainset:\n",
        "                    # randomly skip a bunch from this set\n",
        "                    skip_to_start = int(start_proportion*n_per_file)\n",
        "                    take_from_this_set = max(int(round(train_chunk_size*prob)),1)\n",
        "                    print('take %d from %s training'% (take_from_this_set, data_nm))\n",
        "                    # shuffle: take a random data partition (from the dataset's list of files)\n",
        "                    dset_stream_train = dset_stream_val.shuffle(\n",
        "                        seed = seed+epoch, buffer_size = skip_to_start+take_from_this_set,\n",
        "                    )\n",
        "                    dset_stream_train = dset_stream_train.skip(\n",
        "                        skip_to_start # random skip through dataset to new start position\n",
        "                    ).take(\n",
        "                        take_from_this_set # take this amount for the training ste\n",
        "                    ).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert training to static dataset\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "            else:\n",
        "                # regular streaming\n",
        "                print('trying %s initialization' % data_nm)\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "                # take from stream\n",
        "                n_valset_take = max(int(prob*val_size), 1) # size of valset\n",
        "                print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                skip_to_start = int(start_proportion*(dataset_size-n_valset_take)) # random point to skip to\n",
        "                n_train_take = max(int(round(train_chunk_size*prob)),1) # size of train set\n",
        "                print('take %d from %s train'% (n_train_take, data_nm))\n",
        "                if do_make_valset:\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take)\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "                if do_make_trainset:\n",
        "                    dset_stream_train = dset_stream.skip(n_valset_take+skip_to_start).take(n_train_take)\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['query'][:200]))\n",
        "                    ]\n",
        "            print('Done getting streams/reloading from %s' % data_nm)\n",
        "            # check language, chunk sentences\n",
        "            if do_make_valset:\n",
        "                # discard non-english\n",
        "                dset_static_val_thisset =[\n",
        "                    e for e in dset_static_val_thisset if check_language(e['query'])[0] #detect(e['query'][:200]+\" hello\")=='en'\n",
        "                ]\n",
        "                print('done val language check')\n",
        "                # add to val set\n",
        "                datalist_val_triplet_static.extend(dset_static_val_thisset)\n",
        "\n",
        "            # check language, chunk sentences\n",
        "            if do_make_trainset:\n",
        "                # discard non-english\n",
        "                dset_static_train_thisset =[\n",
        "                    e for e in dset_static_train_thisset if check_language(e['query'])[0] #detect(e['query'][:200] +\" hello\")=='en'\n",
        "                ]\n",
        "                print('done train language check')\n",
        "\n",
        "                # ensure that none of the examples in the traning set are in the validation set\n",
        "                if do_make_valset:\n",
        "                    val_queries = set([q['query'] for q in dset_static_val_thisset])\n",
        "                    dset_static_train_thisset = [\n",
        "                        s for s in dset_static_train_thisset if s['query'] not in val_queries\n",
        "                    ]\n",
        "\n",
        "                # add to training set\n",
        "                datalist_train_triplet_static.extend(dset_static_train_thisset)\n",
        "\n",
        "        print(f'Done collecting {name} streaming data')\n",
        "\n",
        "    if do_make_valset:\n",
        "        print('saving streamed %s validation data: %s' % (name, path_to_val_cache))\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_val_triplet_static, pcon)\n",
        "\n",
        "    if do_make_trainset:\n",
        "        print('saving streamed %s training for epoch %d: %s' % (name, epoch, path_to_train_cache))\n",
        "        with open(path_to_train_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_train_triplet_static, pcon)\n",
        "\n",
        "    return {\n",
        "        'train':datalist_train_triplet_static,\n",
        "        'val':datalist_val_triplet_static,\n",
        "        'epoch':epoch,\n",
        "        'index_stream':start_proportion\n",
        "    }\n",
        "\n",
        "\n",
        "class DatasetTriplets(torch_data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        list_of_data=None,\n",
        "        n_negatives= 3,\n",
        "        topk_negatives_discard = 15, # get top kth most-similar results, discard first k, to use as negative\n",
        "        focal_text_name ='query',\n",
        "        positives_text_name ='positives',\n",
        "        negativess_text_name ='negatives',\n",
        "        seed = 32,\n",
        "        negative_corpus_method = 'bm25', # how to sample (pseudo)negatives internally\n",
        "        label_processor_class = None # (optional) function to process negatives\n",
        "    ):\n",
        "        self.n_negatives = n_negatives\n",
        "        self.topk_negatives_discard = topk_negatives_discard\n",
        "        self.data = {}\n",
        "        self.focal_text_name =focal_text_name\n",
        "        self.positives_text_name = positives_text_name\n",
        "        self.negativess_text_name = negativess_text_name\n",
        "        self.seed = 42\n",
        "        self.random = np.random.RandomState(self.seed)\n",
        "        self.label_processor_class = label_processor_class\n",
        "        self.negative_corpus_method = negative_corpus_method\n",
        "        assert negative_corpus_method in ['bm25','ann-tfidf']\n",
        "\n",
        "        if list_of_data is not None and len(list_of_data)>0:\n",
        "\n",
        "            # loop through the data and add each triplets: export a panda df as final data\n",
        "            self.df = self.process(list_of_data)\n",
        "\n",
        "    def process(self, list_of_data):\n",
        "        \"\"\"Makes (query,pos,neg)-triplets, converts samples to dataframe for pytorch iteration\"\"\"\n",
        "\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(\n",
        "            list_of_data = list_of_data\n",
        "        )\n",
        "\n",
        "        # add positives to self.data\n",
        "        self._find_positives_and_add_to_data()\n",
        "\n",
        "        # add negatives to self.data\n",
        "        self._find_negatives_and_add_to_data()\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        df = self.sample_data_and_make_static_dataframe(self.data)\n",
        "        return df\n",
        "\n",
        "    def _loop_through_list_of_data_and_add_to_selfdata(\n",
        "        self,\n",
        "        list_of_data\n",
        "    ):\n",
        "        \"\"\"loops through and adds the positive/focal texts and negatives\"\"\"\n",
        "        for raw_example in list_of_data:\n",
        "            # add each element to the data\n",
        "            self._add_triplet_to_data(\n",
        "                focal_texts=raw_example[self.focal_text_name],\n",
        "                positve_texts=raw_example[self.positives_text_name],\n",
        "                negative_texts=raw_example[self.negativess_text_name],\n",
        "            )\n",
        "        self.focal_texts_as_keys = list(self.data.keys())\n",
        "\n",
        "    def _add_triplet_to_data(\n",
        "        self,\n",
        "        focal_texts,\n",
        "        positve_texts,\n",
        "        negative_texts\n",
        "    ):\n",
        "        \"\"\"add focal text to the data\"\"\"\n",
        "        do_add_focals = False\n",
        "        if isinstance(focal_texts,list):\n",
        "            focal_text = sort(focal_texts)[0]\n",
        "            do_add_focals = True\n",
        "        elif isinstance(focal_texts, str):\n",
        "            focal_text = focal_texts\n",
        "        if focal_text not in self.data.keys():\n",
        "            self.data[focal_text] = {'positives':[], 'negatives':[]}\n",
        "        self.data[focal_text]['positives'] += [p for p in positve_texts if p not in self.data[focal_text]['positives']]\n",
        "        #if negative_texts is None:\n",
        "        #    print(focal_texts)\n",
        "        #    print(positve_texts)\n",
        "        #    print(negative_texts)\n",
        "        self.data[focal_text]['negatives'] += negative_texts if (negative_texts is not None) else []\n",
        "        if do_add_focals:\n",
        "            self.data[focal_text]['positives'] += focal_texts[1:]\n",
        "\n",
        "    def _build_corpus_of_potential_negatives(self):\n",
        "        # grab positives as default negatives\n",
        "        potential_corpus = [\n",
        "            self.data[k]['positives'][:1] for k in self.focal_texts_as_keys\n",
        "        ]\n",
        "        # insert NEGATIVE if empty for an entry\n",
        "        potential_corpus = [\n",
        "            'NEGATIVE' if (not bool(s)) else s[0] for s in potential_corpus\n",
        "        ]\n",
        "\n",
        "        # negatives by BM25\n",
        "        if self.negative_corpus_method == 'bm25':\n",
        "\n",
        "            # tokenize for BM25\n",
        "            print('building negatives via BM25')\n",
        "            tokenized_corpus = [s.lower().split(\" \") for s in potential_corpus]\n",
        "            # compile BM25 corpus\n",
        "            bm25 = BM25Okapi(tokenized_corpus)\n",
        "            return {'retriever':bm25, 'corpus':potential_corpus}\n",
        "\n",
        "        elif self.negative_corpus_method == 'ann-tfidf':\n",
        "            print('building negatives via ANN-TFIDF')\n",
        "            potential_corpus = [\n",
        "                s for s in potential_corpus\n",
        "                if len(s)>40 and len(s.split(\" \"))>10\n",
        "            ]\n",
        "            negative_example_generator= NegativeExampleGenerator(\n",
        "                n_reps = 1, #\n",
        "                tfidf_nfeatures = 4000,\n",
        "                nchar_max_paragraph=3000,\n",
        "                nword_max=100,\n",
        "                nchar_max_word=4,\n",
        "                save_cache = 'negative_sampler_%d-%s.pkl' % (len(potential_corpus), potential_corpus[0][0]),\n",
        "                corpus = potential_corpus\n",
        "            )\n",
        "            return {'retriever':negative_example_generator, 'corpus':potential_corpus}\n",
        "\n",
        "    def _find_negative(\n",
        "        self,\n",
        "        focal_text_as_query,\n",
        "        positive_examples=None,\n",
        "        use_focal_text = True,\n",
        "        use_positives=True,\n",
        "        neg_retriever=None,\n",
        "        corpus = None\n",
        "    ):\n",
        "        \"\"\"Given a query, uses BM25 to find similar but wrong answers, to serve as triplet negatives; for a single query\"\"\"\n",
        "        bmquery = (focal_text_as_query if use_focal_text else \"\") + \" \" + (\"\" if (not use_positives) else positive_examples[0])\n",
        "        bmquery = bmquery.strip()\n",
        "        if self.negative_corpus_method == 'bm25':\n",
        "            # make the query tokens\n",
        "            bmquery_tokenized = bmquery.lower().split(\" \")\n",
        "            # search by BM25\n",
        "            top_results = neg_retriever.get_top_n(\n",
        "                bmquery_tokenized, corpus, n=self.topk_negatives_discard + self.n_negatives\n",
        "            )\n",
        "        elif self.negative_corpus_method == 'ann-tfidf':\n",
        "            # query the ANN index\n",
        "            top_results,_ = neg_retriever.find_negative(\n",
        "                bmquery, k=self.n_negatives+2, skip=self.topk_negatives_discard\n",
        "            )\n",
        "\n",
        "        top_results = [\n",
        "            s for s in top_results\n",
        "            if (\n",
        "                s not in positive_examples+[focal_text_as_query]\n",
        "            )\n",
        "        ]\n",
        "        # remove any text that is equivalent to the query / focal texts\n",
        "        potential_negatives = top_results[-1*self.n_negatives:]\n",
        "        return potential_negatives\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"For data that has a label, this can be used to artifically find and create synthetic positives\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "        \"\"\"Uses BM25 to find similar but wrong answers, to serve as triplet negatives; loop over data\"\"\"\n",
        "\n",
        "        # build bm25 corpus or tfidf-ANN index\n",
        "        neg_corpus = self._build_corpus_of_potential_negatives()\n",
        "\n",
        "        # loop through data, find examples which don't have negatives\n",
        "        for k,d in self.data.items():\n",
        "            if not bool(d['negatives']):\n",
        "                negatives = self._find_negative(\n",
        "                    focal_text_as_query=k,\n",
        "                    positive_examples=d['positives'],\n",
        "                    use_focal_text = True,\n",
        "                    use_positives=bool(d['positives']),\n",
        "                    neg_retriever=neg_corpus['retriever'],\n",
        "                    corpus = neg_corpus['corpus']\n",
        "                )\n",
        "                d['negatives']+= negatives\n",
        "        print('done finding negatives')\n",
        "\n",
        "    def sample_data_and_make_static_dataframe(self, seed = 42):\n",
        "        focals =[]\n",
        "        pos =[]\n",
        "        neg = []\n",
        "        for query,d in self.data.items():\n",
        "            for j in range(min(self.n_negatives, len(d['negatives']))):\n",
        "                if len(d['positives'])==0:\n",
        "                    continue\n",
        "                elif len(d['positives'])==1:\n",
        "                    pos+=d['positives']\n",
        "                elif len(d['positives'])>1:\n",
        "                    pos.append(self.random.choice(d['positives']))\n",
        "                neg.append(d['negatives'][j])\n",
        "                focals.append(query)\n",
        "        df = pd.DataFrame({'query':focals, 'pos':pos, 'neg':neg})\n",
        "        return df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        #key = self.focal_texts_as_keys[idx]\n",
        "        #return {**{'query':key}, **self.data[key]}\n",
        "        return self.df.iloc[idx].to_dict()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NF5JtWPn-7T",
        "outputId": "94dc16aa-8268-44ba-da13-b3d01ca0e773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing the streaming-QA to static-dataset procedure...\n",
            "trying gbharti/finance-alpaca initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-febc8405eef501a1\n",
            "INFO:datasets.builder:Using custom data configuration default-febc8405eef501a1\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from gbharti/finance-alpaca validation\n",
            "take 562 from gbharti/finance-alpaca train\n",
            "Done getting streams/reloading from gbharti/finance-alpaca\n",
            "done val language check\n",
            "done train language check\n",
            "trying wiki_qa initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wiki_qa/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wiki_qa/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from wiki_qa validation\n",
            "take 562 from wiki_qa train\n",
            "Done getting streams/reloading from wiki_qa\n",
            "done val language check\n",
            "done train language check\n",
            "trying donfu/oa-stackexchange initialization (shuffling through 14 files)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-6796263ff0bd3544\n",
            "INFO:datasets.builder:Using custom data configuration default-6796263ff0bd3544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from donfu/oa-stackexchange validation\n",
            "take 562 from donfu/oa-stackexchange training\n",
            "Done getting streams/reloading from donfu/oa-stackexchange\n",
            "done val language check\n",
            "done train language check\n",
            "trying gart-labor/eclassTrainST initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-9c5fea7054e72cfc\n",
            "INFO:datasets.builder:Using custom data configuration default-9c5fea7054e72cfc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 44 from gart-labor/eclassTrainST validation\n",
            "take 112 from gart-labor/eclassTrainST train\n",
            "Done getting streams/reloading from gart-labor/eclassTrainST\n",
            "done val language check\n",
            "done train language check\n",
            "trying THUDM/webglm-qa initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-93f18c47932a3e57\n",
            "INFO:datasets.builder:Using custom data configuration default-93f18c47932a3e57\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from THUDM/webglm-qa validation\n",
            "take 562 from THUDM/webglm-qa train\n",
            "Done getting streams/reloading from THUDM/webglm-qa\n",
            "done val language check\n",
            "done train language check\n",
            "trying sciq initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/sciq/50e5c6e3795b55463819d399ec417bfd4c3c621105e00295ddb5f3633d708493\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/sciq/50e5c6e3795b55463819d399ec417bfd4c3c621105e00295ddb5f3633d708493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from sciq validation\n",
            "take 562 from sciq train\n",
            "Done getting streams/reloading from sciq\n",
            "done val language check\n",
            "done train language check\n",
            "trying LLukas22/lfqa_preprocessed initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-07a2efd4d318fb4c\n",
            "INFO:datasets.builder:Using custom data configuration default-07a2efd4d318fb4c\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from LLukas22/lfqa_preprocessed validation\n",
            "take 562 from LLukas22/lfqa_preprocessed train\n",
            "Done getting streams/reloading from LLukas22/lfqa_preprocessed\n",
            "done val language check\n",
            "done train language check\n",
            "trying npvinHnivqn/EnglishDictionary initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-6168461407772fdd\n",
            "INFO:datasets.builder:Using custom data configuration default-6168461407772fdd\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 56 from npvinHnivqn/EnglishDictionary validation\n",
            "take 140 from npvinHnivqn/EnglishDictionary train\n",
            "Done getting streams/reloading from npvinHnivqn/EnglishDictionary\n",
            "done val language check\n",
            "done train language check\n",
            "trying alzoubi36/policy_qa initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default-c298bf6ae73d42c5\n",
            "INFO:datasets.builder:Using custom data configuration default-c298bf6ae73d42c5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 56 from alzoubi36/policy_qa validation\n",
            "take 140 from alzoubi36/policy_qa train\n",
            "Done getting streams/reloading from alzoubi36/policy_qa\n",
            "done val language check\n",
            "done train language check\n",
            "trying sc2qa/sc2q_commoncrawl initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to the single config: sc2q_commoncrawl/plain_text\n",
            "INFO:datasets.builder:No config specified, defaulting to the single config: sc2q_commoncrawl/plain_text\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/sc2qa--sc2q_commoncrawl/88638cbfc5b44b10a840338ae62c73da303b5f4cb83a96afd6002c7f1d2cb256\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/sc2qa--sc2q_commoncrawl/88638cbfc5b44b10a840338ae62c73da303b5f4cb83a96afd6002c7f1d2cb256\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from sc2qa/sc2q_commoncrawl validation\n",
            "take 562 from sc2qa/sc2q_commoncrawl train\n",
            "Done getting streams/reloading from sc2qa/sc2q_commoncrawl\n",
            "done val language check\n",
            "done train language check\n",
            "trying yahoo_answers_topics initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No config specified, defaulting to the single config: yahoo_answers_topics/yahoo_answers_topics\n",
            "INFO:datasets.builder:No config specified, defaulting to the single config: yahoo_answers_topics/yahoo_answers_topics\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/yahoo_answers_topics/0edb353eefe79d9245d7bd7cac5ae6af19530439da520d6dde1c206ee38f4439\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/yahoo_answers_topics/0edb353eefe79d9245d7bd7cac5ae6af19530439da520d6dde1c206ee38f4439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 224 from yahoo_answers_topics validation\n",
            "take 562 from yahoo_answers_topics train\n",
            "Done getting streams/reloading from yahoo_answers_topics\n",
            "done val language check\n",
            "done train language check\n",
            "trying launch/gov_report_qs initialization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report_qs/bb5dd166005269e4124933219e1def95272a1197dde526383d05c88cc83548d2\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/launch--gov_report_qs/bb5dd166005269e4124933219e1def95272a1197dde526383d05c88cc83548d2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take 44 from launch/gov_report_qs validation\n",
            "take 112 from launch/gov_report_qs train\n",
            "Done getting streams/reloading from launch/gov_report_qs\n",
            "done val language check\n",
            "done train language check\n",
            "Done collecting QA streaming data\n",
            "saving streamed QA validation data: cache_val_qa.pkl\n",
            "saving streamed QA training for epoch 0: cache_train_qa_000.pkl\n"
          ]
        }
      ],
      "source": [
        "qadata_streaming_config = {\n",
        "    'files':qa_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':2000,\n",
        "    'train_chunk_size':5000,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "# !rm cache_*\n",
        "qa_statics_datsets = initialize_and_get_triplet_streaming_datasets(\n",
        "    data_streaming_config = qadata_streaming_config,\n",
        "    streaming_cleaning_functions = qa_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_qa.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_qa_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'QA' #\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVO8t6irLjYO",
        "outputId": "0f4ec08c-a069-4435-9694-275dbb4f04d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['train', 'val', 'epoch', 'index_stream'])\n",
            "-------\n",
            "Q:when did the cold war start\n",
            "A:The conflict was expressed through military coalitions, strategic conventional force deployments, extensive aid to client states , espionage, massive propaganda campaigns, conventional and nuclear arms races , appeals to neutral nations, rivalry at sports events (in particular the Olympics ), and technological competitions such as the Space Race .\n",
            "-------\n",
            "Q:who created facebook\n",
            "A:Facebook is an online social networking service , whose name stems from the colloquial name for the book given to students at the start of the academic year by some university administrations in the United States to help students get to know each other.\n",
            "-------\n",
            "Q:what type of batteries are 357 (LR44)\n",
            "A:157, 303, 357\n",
            "-------\n",
            "Q:where did the persian war take place\n",
            "A:Some historical sources suggest the end of hostilities was marked by a peace treaty between Athens and Persia, the so-called Peace of Callias .\n",
            "-------\n",
            "Q:what are the houses of hogwarts\n",
            "A:Hogwarts school was voted as the 36th best Scottish educational establishment in a 2008 online ranking, outranking Edinburgh's Loretto School .\n",
            "-------\n",
            "Q:when barack obama was born\n",
            "A:He then defeated Republican nominee John McCain in the general election , and was inaugurated as president on January 20, 2009.\n",
            "-------\n",
            "Q:What is a \"acoustic pressure level\"?\n",
            "A:Ten times the logarithm to the base 10 of the ratio of the square of the sound pressure, p, to the square of a reference value, p0, expressed in decibels\n",
            "-------\n",
            "Q:Why does hot water come out white/cloudy from the tap but when I boil cold water it is transparent?\n",
            "A:Hot water from the tap can be cloudy because the heated water molecules expand and trap other gases, such as tiny air bubbles, due to pressure[1][2]. This can happen in a similar way to how a bottle of soda holds onto carbonation[2]. When the hot water is drawn, the sudden reduction in pressure allows the gas to separate itself and float to the top[5], and then escape into the air[1][5]. When cold water is boiled, the pressure does not decrease so quickly as when hot water is drawn from the tap, which is why it does not appear cloudy or white.\n",
            "-------\n",
            "Q:How do cell towers know the direction to send data for phone calls and texts?\n",
            "A:Cell towers are able to send data in the right direction by having each tower have a precise location with latitude and longitude coordinates, and each tower is comprised of three sectors pointing in different directions, forming a triangle that covers 360 degrees[1]. When a cellular phone attaches to a particular cellular tower, the records indicate which sector the cell phone pinged, so the provider can determine the general direction from that cell tower[1][4]. In order to more closely pinpoint the location, the cell phone needs to be connected to two different sectors on two distinct cell towers[1][2][3]. The cellular phone transmits via land-based towers and will attach to the closest tower to provide service[1][4]. The phone will continue to attempt to connect to the closest appropriate cell phone tower, but the only time your movements and location are not being tracked is when your phone is completely off[2][5].\n",
            "-------\n",
            "Q:When, where, and why did today's \"gender roles\" come into existence\n",
            "A:Gender roles came into existence in 1950s America in response to cultural, technological, economic, and demographic forces. During this decade, it was expected that men would marry and work to support a family, while women were expected to marry, have children, and devote themselves to maintaining a home and being the primary caretaker of the children[5]. This created a strict dichotomy between male and female roles, which is no longer the expected life pattern today[1].\n",
            "-------\n",
            "Q:Why are plants green when the sun puts out a lot of green light and the only reason we see plants as green is they reflect the green light.\n",
            "A:Plants are green because they absorb red and blue light most efficiently, and the green light is reflected[1][2][3]. This is because the small amount of light they reflect is that color, and it seems to be the most efficient way for them to use the sun's energy[5]. Plants prefer to absorb red light and reflect green light because the green light holds the most energy and is too powerful for plants to use without harm[2][3][5].\n",
            "-------\n",
            "Q:Ternary logic and ternary computers\n",
            "A:Ternary logic is a type of logic that uses three possible values instead of the more common two values used in binary logic[1][2]. Ternary computers are computers that use this type of logic for their calculations. Examples of the use of ternary logic in popular culture include Tasen and Komato aliens in the computer game Iji[5] and the Conjoiners in Alastair Reynolds' Revelation Space series[4]. With the advent of mass-produced binary components for computers, ternary computers have diminished in significance[5]. However, Donald Knuth argues that they will be brought back into development in the future to take advantage of ternary logic's elegance and efficiency, such as by combining an optical computer with the ternary logic system.[5]\n",
            "-------\n",
            "Q:Why do we always ask animals and babies what they're doing, even though we know they can't respond?\n",
            "A:People often ask animals and babies questions, even though they know they won't be able to respond, because they tend to see something human in them and their cuteness and responsiveness enforce that tendency[1]. With animals, people often think of them as little members of the family, so it's natural to talk to them[5]. Additionally, some people may not want animals to be conscious because it makes it easier for them to do things to animals that would be hard to do if they knew they were unhappy and suffering[3]. On the other hand, it is hard to deny that animals have a conscious mental experience of play, sleep, fear, or love, as evidenced by the way they respond to the world around them[4].\n",
            "-------\n",
            "Q:Gases can undergo diffusion, or the opposite, which is what?\n",
            "A:Define diffusion and effusion and how they relate to other properties of gases.\n",
            "-------\n",
            "Q:What does fluorine attract better than any other element?\n",
            "A:Valence electrons of both atoms are always involved when those two atoms come together to form a chemical bond. Chemical bonds are the basis for how elements combine with one another to form compounds. When these chemical bonds form, atoms of some elements have a greater ability to attract the valence electrons involved in the bond than other elements. Electronegativity is a measure of the ability of an atom to attract shared electrons when the atom is part of a compound. Electronegativity differs from electron affinity because electron affinity is a measure of the actual energy released when an atom gains an electron. In contrast, electronegativity is a relative scale, so it is not measured in units of energy. All elements are compared to one another, and the most electronegative element, fluorine, is assigned an electronegativity value of 3.98. Fluorine attracts shared electrons better than any other element. Figure below shows the electronegativity values of most elements.\n",
            "-------\n",
            "Q:The field of organic chemistry studies the structure and reactivity of compounds containing what element?\n",
            "A:Since then, the distinction between organic and inorganic compounds and reactions has blurred. Currently, the field of organic chemistry studies the structure and reactivity of nearly all carbon-containing compounds. Over twenty million organic compounds are known, ranging from very simple molecules to complex proteins.\n",
            "-------\n",
            "Q:What type of reproduction is exemplified by starfish and yeasts?\n",
            "A:Starfish: Flickr:amanderson2; Yeast: Zappy's. Starfish and yeasts are examples of organisms that reproduce asexually . Starfish: CC BY 2.0; Yeast: CC BY-NC 3.0.\n",
            "-------\n",
            "Q:Water moving up the plane and evaporating from the leaves is a process known as what?\n",
            "A:Water also moves through the living organisms in an ecosystem. Plants soak up large amounts of water through their roots. The water then moves up the plant and evaporates from the leaves in a process called transpiration . The process of transpiration, like evaporation, returns water back into the atmosphere.\n",
            "-------\n",
            "Q:What was life like for a French prisoner during the 19th century?\n",
            "A:Miranda Spieler just released a book called [_Empire and Underworld: Captivity in French Guiana_](_URL_0_).  The title is a bit misleading, as the majority of the book is about convicts in France in the early 19th century and the penal system.  I'd check it out for further info.\n",
            "-------\n",
            "Q:why does a middle octane gas exist? i understand using low octane for price and high octane for quality, but why use middle?\n",
            "A:The thing about different grades of gas, is you should only use the one your car requires.  Believe it or not, 87 will perform better than 93 in a car that's tuned for 87.    With that being said, some cars require mid-grade.  The ignition timing was increased, but not to the point where the owner would have to get the most expensive gas.  You'll find this in some domestic luxury vehicles.\n",
            "-------\n",
            "Q:Was there a point in European history where it became 'superstitious' to believe in fairy-like beings\n",
            "A:Religious orthodoxy is effectively impossible in a premodern state. The religious experiences of people in medieval Europe, and indeed elsewhere, as you have stated, were very personal, and the exact form of Christianity practiced could change from village to village. Many places were still awash with local tradition predating their Christianizations, much to the ire of the *bureaucratic* clergy. One example of such a role is the Hungarian *taltos*. They were essentially the leftovers of shamans from the days of pagan Hungary, but of course conformed to the \"skin\" of Christianity, as it were. One *Taltos*, an Erzsebet Balazsi was accused of being a witch, to which she defended herself, saying that, \"the *Taltos* cures, finds buried treasure, and fights for Hungary in heaven*. They drew the attention of the Hungarian priest Arnold Ipolyi, who wrote of them as being a very famous Hungarian folk tradition. Another such example of an isolated tribe maintaining their \"pagan\" trappings were the *Sarakatsani* of Greece. Patrick Leigh Fermor, who was perhaps the most hellenized Barbarian in history, wrote as recently as the 1930s that they were Orthodox, but did not know of the Holy Spirit, combining the son and father into a deity called *Ays*, and that they paid great reverence to nature spirits and to the spirits of animals. So your answer for when people put aside the fairies was at least more recently than 1930.\n",
            "-------\n",
            "Q:why is it when you're outside and feeling sleepy you would do anything to have a nap but once you get home the desire to sleep is completely gone?\n",
            "A:The brain actually needs to cool down a couple of degrees in order to go to sleep. When you’re outside, it is likely colder than when inside your home. This can make you sleepy.   Blue light from screens also causes people to say up and be less sleepy. \n",
            "-------\n",
            "Q:how exactly does a new development cause a rise in property values, taxes, and rents in the surrounding neighbourhood?\n",
            "A:Not Canadian, but this should be fairly universal:   > For example, if a fancy condo gets built in/near a lower-income area. How does it work (in terms of the actual economics/the market)?  Imagine a line of 11 communities. From left to right, the homes get progressively worse... lower quality, less enjoyable to live in, etc. So some nice, beautiful mansions/condos on the left, and some dilapidated crack houses all the way on the right.   You live in the very middle community. It's not as good as the left. Not as bad as the right. Where would you prefer to go outside and play?   You'd probably prefer to go to the left a bit. It's nicer there. Better kept. Nice things are generally taken care of, which means its more safe, less crime, more enjoyable.  Given the option, you would happily move to any community to your left vs. to your right. In fact, most people would. Rarely, if ever, would someone choose to live in a crime invested area when they could live in some safe luxurious neighborhood. So if it cost the same amount to live in any of the 11 neighborhoods... why would anyone pay to live to the right when the same money gets them to the left?  And this is where the economics come into play.   Going back to your example, before that fancy condo was built, it was just near a low-income area that was likely less desirable to live in/near than other areas. But now... now there is a fancy condo. Sure, some people may not want to live in a fancy condo near a low-income area... and that may prevent the fancy condo from making as much money as a fancy condo near a nicer area... but a fancy condo is still nicer than a not-fancy-condo... which means, given the option of living in a fancy condo, many folks will opt-in if the price is right.  So that fancy condo has created an increase in value for the area of land it exists on. That increase of value generally means the property tax on that piece of property goes up... but that doesn't immediately have an affect on the surrounding area. For that, we have to look at the economic ripple affect.  Those people who have signed up to live in the fancy condo are likely paying more to live there than they would to live in the low income area surrounding it. Which means they probably have better jobs, more disposable income, etc. Having a high concentration of people like that draws in business. Maybe it starts with a dry cleaner... or a coffee shop to take advantage of everyone in the condo's morning commute.  Suddenly a fancy condo in a low income area has turned into a fancy condo and a coffee shop and a dry cleaner. Those are things some people value when they choose a place to live, so more people want to live in the fancy condo. Restaurants pop up. Maybe a park or two are built.  The area slowly becomes more desirable to live in, and as it does, the cost to live in the fancy condo rises as well. In fact, it may rise so much that it makes more sense to buy property in the lower-income area and convert it to something nice vs. buy a condo... sure it may not be as good as the condo, but it is still in a \"nice area.\" This concept drives up the market rate of the properties in the area, and the market rate / property values are generally tied to property taxes.  In other words, higher property value = higher property tax... and a single investment into a piece of property that creates value can, as a consequence, create value in the entire area surrounding that piece of property... and that value is how many areas decide on how much tax you must pay.  It goes the other way as well. If that condo turns into a radioactive waste site... suddenly the low-income area becomes a ghost town, since no one wants to live there, even if it is way below market rates.   >  Is there any room for policy controlling some aspect of this, for example property taxes?  Absolutely. Some states, like California, have instituted regulations which essentially lock your property tax to whatever the value of your property was at the time of purchase. The upside is that communities are more immune to fluctuations in developments surrounding them, which allows stability for family homes, etc. The downside is that it impacts the amount of taxes an area is able to collect, which impacts everything from infrastructure to school budgets.  But the alternative isn't free from fault. I remember an area in Idaho where they began to develop heavily on one side of a river. Idaho, not having any similar protections as California, created the environment I described above. So as one side of the river began to build out restaurants, and new homes, and movie theaters, small homes that had been owned by families for generations began to skyrocket in value due to market demand... as a result, many families had to sell due to inability to pay their property tax.  Ultimately, it comes down to \"which consequence do you prefer?\" vs. \"which is the best option?\"  \n",
            "-------\n",
            "Q:the clathrate gun hypothesis\n",
            "A:**Methane Clathrate**   The chemical compound Methane is a very powerful greenhouse gas, more so than CO2.   Methane Clathrate is basically ice that has a ton of methane locked inside of its crystal structure.   Methane Clathrate can only exists at low temperatures and high pressures. There is a lot of it along the ocean floor in polar regions.   **Clathrate Gun**  Global temperatures slowly increase over time due to other events.  As the temperature of the ocean increases, it gets too hot for Methane Clathrate to stay frozen.  Methane begins being released into the oceans and atmosphere.   This creates a feedback loop. It gets hotter, which releases more Methane. Then it gets hotter and releases even more.   This is theorized to be the reason why we see warm periods during the last few million years.  **Fear**  If we continue global warming, we will trigger the Clathrate Gun. This will create a feedback loop that we have next to no hope of stopping.\n",
            "-------\n",
            "Q:Define the term: gain\n",
            "A:a square or beveled notch cut out of a girder, binding joist, or other timber which supports a floor beam, so as to receive the end of the floor beam.-convenient; suitable; direct; near; handy; dexterous; easy; profitable; cheap; respectable.-that which is gained, obtained, or acquired, as increase, profit, advantage, or benefit; -- opposed to loss.-the obtaining or amassing of profit or valuable possessions; acquisition; accumulation.-to get, as profit or advantage; to obtain or acquire by effort or labor; as, to gain a good living.-to come off winner or victor in; to be successful in; to obtain by competition; as, to gain a battle; to gain a case at law; to gain a prize.-to draw into any interest or party; to win to one's side; to conciliate.-to reach; to attain to; to arrive at; as, to gain the top of a mountain; to gain a good harbor.-to get, incur, or receive, as loss, harm, or damage.-to have or receive advantage or profit; to acquire gain; to grow rich; to advance in interest, health, or happiness; to make progress; as, the sick man gains daily.\n",
            "-------\n",
            "Q:In light of your user-information protocols, does the website collect any information that I do not provide explicitly?\n",
            "A:Linking to other sites and Social media sites below. Advertising Bank of America advertises online (e.g., pages within our Sites and mobile apps through bank managed social media presences, and on other sites and mobile apps not affiliated with Bank of America) and offline (e.g. in banking centers, through call centers, and direct marketing). In order to understand how advertising performs, we may collect certain information on our Sites and other sites and mobile apps through our advertising service providers using cookies, IP addresses, and other technologies. The collected information may include the number of page visits, pages viewed on our Sites, search engine referrals, browsing activities over time and across other sites following your visit to one of our Sites or apps, and responses to advertisements and promotions on the Sites and on sites and apps where we advertise.\n",
            "-------\n",
            "Q:Does Ohio State deserve the No. 1 seed in the College Football Playoff rankings?\n",
            "A:COLUMBUS, Ohio - Ohio State football players will wake up on the day of the first College Football Playoff rankings as the co-favorite to eventually win the championship. Per betonline.ag, both the Buckeyes and Alabama are +275 to win it all as of late Monday night, slightly ahead of Clemson (+300). Over at Vegas Insider, the odds slightly favor the Crimson Tide (2/1) over OSU (5/2). You are probably not surprised to learn you can also bet on where teams will be ranked when the CFP committee releases its first rankings Tuesday night during the State Farms Champions Classic basketball doubleheader on ESPN. The announcement should come around 9 p.m., after Kansas plays Duke and before Michigan State plays Kentucky. Fittingly, the announcement leads into a Big Ten-SEC showdown, since thats what the No. 1 argument boils down to as well. Every Tuesday morning this season we have speculated on what the rankings would be if they were announced that early. This week we take one final blind swing before we see what the committee actually thinks. Once again, the criteria, as stated on the CFP website:  Conference championships won  Not yet applicable. However, we can safely assume the committee will only consider undefeated teams for those top four spots on Tuesday. Head-to-head results  This will not be a major criteria among the known contenders until LSU and Alabama play on Saturday. Then, two weeks later, Penn State and Ohio State play. After those results, Georgia and Oregon can potentially climb back into contention via their respective conference championship games. Results against common opponents  Also not yet a major factor, because whatever common opponents are shared by the undefeated teams, they are all ... you know ... undefeated against them. But for the sake of argument:  Ohio State/Penn State: Michigan State (OSU 38-7 home, PSU 28-7 away)  Alabama/Clemson: Texas A&M (Alabama 47-28 away, Clemson 24-10 home)  Alabama/LSU: none, yet  On the CFPs protocol\" page it says these common opponent results are to be considered without incenting margin of victory. Well see about that. Strength of schedule  I averaged together three sources (Sagarin, Sports-Reference and Team Rankings) to come to a consensus on the toughest schedules among the undefeated teams and any Power 5s with only one loss:  Team Sagarin SR TR Avg Ohio State 20 9 3 10.7 Oregon 24 45 9 26.0 Penn State 39 35 7 27.0 LSU 34 42 8 28.0 Utah 40 51 20 37.0 Georgia 50 59 18 42.3 Alabama 59 69 17 48.3 Oklahoma 49 67 36 50.7 Clemson 64 81 41 62.0 Baylor 65 86 58 69.7 Wake Forest 80 87 80 82.3 Minnesota 82 102 77 87.0  Thats good news for Ohio State and LSU, and potentially one-loss Oregon down the line, if it can make that ranking stand up. Evaluation of performance on the field  This one is trickier to predict as it is obviously the most subjective criteria. However, you can bet the members of the committee will take objective data into their decisions. With that in mind, I averaged the national rank of the 12 teams in the following six computer ranking sources:  ESPNs Football Power Index (FPI)  Football Outsiders Fremeau Efficiency Index (FEI) *Note: Not updated after last weekends games  Massey Index, a composite of 29 rankings  Sagarin Ratings  Bill Barnwells SP+  Sports References Simple Rating System (SRS)  Team ESPN  FPI FEI* Massey Sagarin SP+ SRS Avg. Ohio State 1 1 1 1 1 1 1.0 Alabama 2 2 5 2 2 2 2.5 LSU 4 4 2 4 3 3 3.3 Clemson 3 3 4 3 5 5 3.8 Penn State 5 9 3 5 7 4 5.5 Oklahoma 7 8 10 6 4 8 7.2 Georgia 6 7 8 11 6 11 8.2 Utah 13 6 9 12 9 6 9.2 Oregon 8 15 6 7 14 10 10.0 Baylor 21 12 15 17 15 20 16.7 Minnesota 20 11 14 25 10 22 17.0 Wake Forest 41 39 26 40 46 34 37.7  This tells us non-human calculations are in agreement on a) a clear No. 1, b) a clear No. 2 and c) a clear No. 3-4. Penn State is not far outside of that sphere. Margin of victory  This is not a stated criteria of the committee. However, when my colleague Doug Lesmerises attended the mock selection committee last month, relative scoring differential was an important metric. I dont have access to that number, but here are those teams national rank in simple scoring margin:  Team Avg. margin Ohio State 40.4 Alabama 33.4 Clemson 31.0 LSU 23.3 Penn State 22.7 Oklahoma 22.0 Oregon 21.2 Minnesota 20.0 Georgia 19.9 Utah 19.6 Baylor 14.6 Wake Forest 9.3  Compare those scoring margins to the strength of schedule rankings and the Buckeyes case is further enhanced. Choosing the No. 1 seed tonight essentially comes down to two teams: Ohio State vs. LSU. LSU boasts wins over two currently ranked teams: No. 10 Florida and No. 12 Auburn. Another big win, at Texas, has lost some luster as the Longhorns toppled out of the top 25 altogether. Ohio State boasts wins over No. 16 Wisconsin and No. 17 Cincinnati. It also beat an Indiana team that sits right behind Texas in the others receiving votes pool. When you consider the strength of schedule ratings that heavily favor OSU, the LSU marquee victories dont carry quite as much weight. With all of the above in mind, here is my prediction of the committees first rankings tonight:  1. Ohio State (8-0)  2. LSU (8-0)  3. Alabama (8-0)  4. Clemson (9-0)  Ive made my own snide the committee wont leave out the undefeated defending champion comments, but I agree Clemson deserves that spot over Penn State right now. The hate on the Tigers went a smidge too far after the North Carolina game. They won the following four games 208-45. Next four: 5. Penn State (8-0), 6. Oregon (8-1), 7. Georgia (7-1), 8. Oklahoma (7-1). Something else that Lesmerises wrote about following his mock CFP experience stuck with me. The committee deals with a lot of conflicting information coming from all angles. If the committee looks at those computer rankings  and if the relative scoring differentials favor Ohio State as much as I think they will  they may actually see the Buckeyes as an easy choice for No. 1. Will the LSU-Alabama winner take over at No. Sounds like a topic for next Tuesday morning. Get Buckeyes Insider texts in your phone from Doug Lesmerises: Cut through the clutter of social media and communicate directly with the award-winning OSU football reporter, just like you would with your friends. Sign up for insight on the Buckeyes in your phone for $3.99 per month.\n",
            "-------\n",
            "Q:Were Hedge Funds Right About Souring On Southern National Bancorp of Virginia, Inc. (SONA)?\n",
            "A:We check hedge fund and billionaire investor sentiment before delving into hours of research. Hedge funds spend millions of dollars on Ivy League graduates, expert networks, and get tips from investment bankers and industry insiders. Sure they sometimes fail miserably, but their consensus stock picks historically outperformed the market after adjusting for known risk factors. Southern National Bancorp of Virginia, Inc. (NASDAQ:SONA) investors should be aware of a decrease in hedge fund sentiment in recent months. SONA was in 7 hedge funds' portfolios at the end of the second quarter of 2019. There were 8 hedge funds in our database with SONA positions at the end of the previous quarter. Our calculations also showed that SONA isn't among the 30 most popular stocks among hedge funds (see the video below). Video: Click the image to watch our video about the top 5 most popular hedge fund stocks. 5 Most Popular Stocks Among Hedge Funds More  At the moment there are many signals stock traders use to assess publicly traded companies. Two of the most underrated signals are hedge fund and insider trading activity. We have shown that, historically, those who follow the top picks of the elite money managers can outclass their index-focused peers by a solid margin (see the details here). Matthew Lindenbaum Basswood Capital More  Unlike other investors who track every movement of the 25 largest hedge funds, our long-short investment strategy relies on hedge fund buy/sell signals given by the 100 best performing hedge funds. Let's take a look at the key hedge fund action encompassing Southern National Bancorp of Virginia, Inc. (NASDAQ:SONA). At the end of the second quarter, a total of 7 of the hedge funds tracked by Insider Monkey held long positions in this stock, a change of -13% from the previous quarter. The graph below displays the number of hedge funds with bullish position in SONA over the last 16 quarters. So, let's examine which hedge funds were among the top holders of the stock and which hedge funds were making big moves. No of Hedge Funds with SONA Positions More  Among these funds, Renaissance Technologies held the most valuable stake in Southern National Bancorp of Virginia, Inc. (NASDAQ:SONA), which was worth $8.8 million at the end of the second quarter. On the second spot was Royce & Associates which amassed $6.7 million worth of shares. Moreover, Basswood Capital, Cove Street Capital, and D E Shaw were also bullish on Southern National Bancorp of Virginia, Inc. (NASDAQ:SONA), allocating a large percentage of their portfolios to this stock. Seeing as Southern National Bancorp of Virginia, Inc. (NASDAQ:SONA) has witnessed bearish sentiment from the entirety of the hedge funds we track, it's easy to see that there was a specific group of funds that slashed their full holdings by the end of the second quarter. Intriguingly, Ken Griffin's Citadel Investment Group dropped the largest position of the 750 funds monitored by Insider Monkey, comprising an estimated $0.3 million in stock, and Paul Marshall and Ian Wace's Marshall Wace LLP was right behind this move, as the fund sold off about $0.3 million worth. These bearish behaviors are interesting, as total hedge fund interest was cut by 1 funds by the end of the second quarter.\n",
            "-------\n",
            "Q:Why are India's Twitter users moving to Mastodon?\n",
            "A:Image copyright Mastodon Image caption A number of India's twitter influencers are joining the little known Mastodon  A number of Indian Twitter users, including \"influencers\" are leaving the social media network for a little known alternative called Mastodon. The move comes amid criticism of what some are calling Twitter's \"highly inconsistent\" stand on hate speech. It has been sparked by Twitter suspending a leading Supreme Court lawyer's account twice - first over an image and then a poem he retweeted. Supporters of Sanjay Hegde say Twitter tolerates rhetoric against minorities. Twitter has denied these charges. It put out a statement saying it does not moderate its content based on \"ideological or political\" viewpoints. But regular Twitter users as well as technology experts say that the platform has a blemished history when it comes to moderating content in India. \"Until the Indian government started going after WhatsApp, it was clear the company hadn't done enough to address misinformation on its platform. Similarly, Twitter hasn't done enough to address hate speech - there is a huge bias in the way it works,\" the editor of internet watchdog Medianama, Nikhil Pahwa told the BBC's Krutika Pathi. A recent report from the Committee to Protect Journalists (CPJ) found that Twitter removed nearly one million tweets and blocked about 100 accounts in India as part of their \"country withheld\" policy. The report said most of the blocked content was critical of the government's recent move to strip Indian-administered Kashmir of its semi autonomous status, and were made after requests by the government itself. \"With twitter, the problem is mounting - there is a growing sense that the platform is closing down or suppressing voices that are critical of the government, so there is a lot of concern over that,\" said Nilanjana Roy, an author who recently signed up for a Mastodon account. Mastodon is an open source network, where users can post, comment, follow other users and publish images and videos like on a conventional platform. But what is most significant is that it is decentralised and open-source - this means that there is no single entity running the network. Instead, users create and run their own servers. This means the social network then is made up of many servers - each of which has its own rules. This also allows users to choose servers that they think conform with the policies they agree with. Mastodon was first released in October 2016 by Eugen Rochko, a software developer, and began to expand in 2017. The network claims to have over 2.2 million users, a mere fraction of the 321 million monthly active users of Twitter.\n",
            "-------\n",
            "Q:Can Oregon Ducks prevent Arizona State loss from beating them twice, refocus for Civil War?\n",
            "A:EUGENE  The Oregon players to speak after the loss at Arizona State said little; once they left Sun Devil Stadium for the trip home the Ducks said even less. Reality was setting in and being digested by players, coaches and staffers that their College Football Playoff dreams had come to an end. You could hear a pin drop, linebacker Troy Dye said. You could hear the rain drops hit the windows (on the plane). It was very quiet but it needed to be like that because of the way it ended. Thats just how it is.  Teams traveling home off a loss are usually somber and the Ducks were no exception. Were continuing to elevate our own expectations for ourselves,\" Oregon coach Mario Cristobal said. \"So after a game like that youre going to be upset; youre not going to be happy. Youre going to be down  and it should be that way. We talked as a team and thats as quiet as a plane ride as Ive ever been on and not by a little. And you know what, it should be that way. If it wasnt that way Id be really disappointed and Id say that you know what we got the wrong guys.  The same group has to respond this week to avoid any lingering disappointment from carrying into the Civil War Saturday afternoon (1 p.m., Pac-12 Network). Oregon failed to do so a year ago after its loss at Washington State and had its worst loss of the season at Arizona. The Ducks have not had such an issue following their two losses since then, but neither the loss at Utah last season or falling to Auburn to start this season had the same magnitude of implications as last weekend. In terms of understanding that you can never allow yourself to get beat twice by the same team, its popping right back into what you need to to prepare for the next one,\" Cristobal said. \"Our leadership council and coaches, the team as a whole, when we meet we recognize, assess, understand good things, bad things, things that must improve to go on and get better and we did that and immediately right back, shaking it off and going on to the next one. Understanding that were playing a really good football team, a really good football team thats got a lot to play for and we feel were a really good football team that has a lot to play for. Some of it takes care of itself and the rest of it, the culture is taking over.  The Civil War will have no impact on Oregons postseason destination. The Ducks will play for a trip to the Rose Bowl and the Pac-12 Championship next week regardless, and that was they primary goal this season. Personally, the playoff was never the goal, nose tackle Jordon Scott said. From the beginning of the season our goal was always to win the Pac-12 and thats still in front of us. Thats all weve been focusing on and everybody getting to Take the Pac back in their head.  Dye said he saw the early signs of a team moving on from last weeks loss and focusing on the task at hand this week. Between the rivalry, Oregon State (5-6, 4-4 Pac-12) also coming off a brutal road loss and in need of a win to reach a bowl game, and it being the last home game for Oregons seniors, Cristobal was confident his team would respond. This is everything you would want in a college football game, especially for your last one of the regular season, he said. I think and feel very confident well be dialed and focused in.\n",
            "-------\n",
            "Q:How can anyone be offended by the celebration of Christmas?\n",
            "A:Efforts to find her have once again been unsuccessful, but heres hoping, wherever she is, this somehow reaches her because shes become a fond remembrance here every year about this time when the Christmas season  or holiday season, as secularists clamor for it to be called  kicks into high gear on the heels of Thanksgiving. Her name was Irina; she was a Jewish immigrant from Lithuania when she arrived in America in December 1989. She was 44 and totally agog. It was like stepping into a fairy tale, she recalled. There were ornaments, lights, trees everywhere we looked. It was so festive and such a joy to see everyone free to celebrate what was important to them.  Those were the days when a corporate giant like John Hancock had no qualms about distributing thousands of Christmas carol booklets to Boston schoolkids. No one found that inappropriate; no one saw it as proselytizing. It was simply getting into the spirit of the season. But by 2005 the cultural war on Christmas was raging: Postal clerks were forbidden to wish anyone a Merry Christmas! and while Santa, Frosty and Rudolph could still be seen, angels, shepherds and a baby wrapped in swaddling clothes had been declared personas non grata in the public square. Thats what prompted Irina to call, more out of heartbreak than anger. Where she came from, Vilnius, the capital city on the shores of the Baltic Sea, she explained, religious freedom was virtually nonexistent. I am afraid, she said. For people like us who have already been down this road, it scares us to see what is happening because we do not want to go down that road again. We see America turning into the kind of society we came from where everyone was worried about offending someone else and where it was dangerous to draw attention to your beliefs.  She would find kindred spirits among Russian-speaking congregants in the synagogue she attended in Brighton; together they started a group called Chaveirim, meaning friends. This conspiracy against Christmas frightens me, she said. We are living the lives we all dreamed of before we came to America. Weve met Mormons and plan to visit the Christian Science Church; I want to take (group members) to a Catholic service, too. Please. If you had to categorize her, Irina was a visionary. I am not worried about a country where there are too many religions, she said. What I am worried about is America becoming a country where there is no religion at all.\n",
            "-------\n",
            "Q:What Happened To All The Women In NASCAR?\n",
            "A:KANSAS CITY, KS - MAY 10: Natalie Decker, driver of the #54 N29 Technologies LLC Toyota, stands on ... [+] pit road during qualifying for the NASCAR Gander Outdoors Truck Series Digital Ally 250 at Kansas Speedway on May 10, 2019 in Kansas City, Kansas. (Photo by Sean Gardner/Getty Images) Getty Images  Not that women stock-car drivers try to be the next Danica Patrick  they want to be themselves!  but theyd love a chance to race at NASCARs premier level, as Patrick did for five full seasons. It might be a couple of years until we see another top female driver, though. This marked the first year since 2000 that a female has not raced in either of the two top levels of NASCAR. Three women drove in the trucks series  two levels down from the Cup big leagues  with only Angela Ruch recording just one top-10 finish in 48 total races among them. Patricks one-off appearance in the 2018 Daytona 500 marked the last time that a female drove in a Cup race. Although women have been in NASCAR races since the very first top-level race in 1949, Shawna Robinson is the only other female to drive in a Cup race since 2001. Diversity is critically important to NASCAR; Patrick appealed to female fans in a way that men just could not. Of eight women who drove at least one race in a NASCAR national series race, though, Hailie Deegan was the only winner in 2019, taking two K&N Series West races. (More about Deegan here, here and here.) Deegan, the 18-year-old from Temecula, Calif., has lately received the most attention of any female stock-car driver, but she is not the only woman aiming for the top. Natalie Decker, a 22-year-old from Eagle River, Wis., is probably the closest woman to a Cup ride at the moment. Decker jumped to a near-full-time ride in the trucks series in 2019, finishing 19th in the series standings but failing to post a top-10 finish in 19 races. Jennifer Jo Cobb finished 21st in the trucks series standings, with similar finishes to Decker, but Cobb is 46, riding out her career. In 28 races in the ARCA Series and K&N Series East and West  sort of like Single-A long-season and short-season baseball is to the major leagues  Deegan had nine top-five finishes and 18 top-10 finishes, far best of females. She could get a promotion to the ARCA level in 2020. MADISON, IL - AUGUST 24: NASCAR K&N Pro Series Toyota Camry driver Brittney Zamora (99) prepares to ... [+] climb into her car for the start of practice for the NASCAR K&N Pro Series East & West Monaco 125 presented by West Coast Stock Car Hall of Fame on August 24, 2019, at World Wide Technology Raceway in Madison, Illinois. (Photo by Michael Allio/Icon Sportswire via Getty Images) Icon Sportswire via Getty Images  But Deegan was not the only woman who had a good 2019. Another young female who stood out in the K&N Series East and West was Brittney Zamora, a 20-year-old from Kennewick, Wash., who finished fifth, two spots behind Deegan, in the K&N Series West. Zamora, like Deegan, drove a Toyota for Bill McAnally, a long-time owner who has nurtured the careers of other young drivers, male and female. In her first full year, Zamora had six top-five and 11 top-10 finishes in 20 races total. She also won two pole positions. Another female driver worth following is Bridget Burgess, a 17-year-old who was born in Australia and now lives in Tooele, Utah. Her background, like Deegans, is in off-road racing, but she drove in two K&N Series West races last year. Decker, Deegan and Zamora dont appear ready to race in the Xfinity Series, a level down from Cup. Any would say they want to work for their shot and earn a big shot. Patrick had Indy-car experience, but she drove 58 second-tier NASCAR races before joining Cup full-time. NASCAR is in no hurry to move them up, either, even though there would appear to be a little more urgency on the diversity front. Daniel Suarez, a Mexican who was the only non-American regular in the Cup series, lost his ride with Stewart-Haas Racing this month. Cole Custer, a 21-year-old hotshot from California, will replace Suarez, who had only a one-year contract with an option. Ive heard Tony Stewart and Gene Haas loved Suarezs talent, personality and marketability, but the Cup seat was always going to Custer when he was ready. Another prized Cup seat will open at Hendrick Motorsports after Jimmie Johnson, the seven-time champion, retires from racing after the 2020 season. Speculation is underway about who will get the job. No women were included in this list of possibilities. There dont seem to be any female drivers right now with enough seasoning to fill such a high-profile vacancy. But one move sets off a chain reaction. So something could come open for a female driver to move up in 2021. Whoever gets a promotion will have earned it.\n",
            "-------\n",
            "Q:New Orleans girl wants to know? Why can't these stupid politicians get real and stop jerkin' everybody around?  I know that is what they do best here in good ole' Louisiana, but come on!!! Can we get a little help that is actually worth something to the poor people who are still living out of town? And do ya think they could pick up the nasty flooded out cars?\n",
            "A:First, let me say that if you lived on the other side of the canal, you are NOT from New Orleans, you are in fact a Metairian from Jefferson Parish.\\n\\nSecond, the politics are so bad b/c of the political framework that has developed primarily since Huey P. Long which supports patronage and a welfare state.  These two components have been in place and supported by the electorate for so long, no one knows how to think differently.  This is obvious by the #2 vote winner in last week's mayoral election.\\n\\nTrue change cannot come overnight and will be very painful for those who most gain from the existing system.  This includes the politicians, their buddies in the businesses which are required to keep government going, the poor who depend on the state to help them by giving out money and equivalents, the list goes on . . .\\n\\nYou can fix it by doing two things: First, move into Orleans Parish.  If Orleans Parish does not succeed, your precious sheltered life in Metairie will quickly follow.  Second, get involved on city politics. You don't have to run for office,  but be informed and participate where you can.\\n\\nThe greater New Orleans area will recover but everyone has to make some sacrifice and also participate in the rebuilding of the arguably greatest city in the country.\\n\\nFollow Up: Point well taken!  I believe that the interconnectedness of the area still has its centerpoint in the economic health of Orleans Parish.  More power to you if you support Orleans with your actions, as you mentioned.  But,  your vote only counts if you live in the parish.  If you want to fix the politics, you must live in the parish so you can vote there.  Thanks for being someone who is committed to the rebuilding of the city, even if you won't live in it.\n",
            "-------\n",
            "Q:CAN anyone help me with my homework it deals with forernsic evidence? i need 2 use a famous case that involved forensic evidence whether to free the suspect or bust em.\n",
            "A:Use the most famous Oj\\num that famous case with tha pregnant lady her husband was Scott Petterson\\nMicheal Jackson\\nthe God father \\ncome on think!\n",
            "-------\n",
            "Q:Should immigrants to Quebec learn the French language? My friend has relatives who are immigrating to Quebec.  His relatives say they have no obligation to learn the French language and have no plans to learn the language.\\n\\nShould immigrants (to any country or region) learn the local language and customs?\n",
            "A:You have no obligation to learn English of French I assume but wouldn't it make sense to make an effort? \\n\\nCanada has two official languages. It is not a bilingual country where population evenly speaks both languages. French is spoken in Quebec. Large pockets of english speakers exist in Montreal. Immigrants who only speak english usually live in those areas but why don't they go live elsewhere in CAnada if they are not interested in Quebec's culture?\\n\\nQuebec has a very different culture than the rest of Canada. It's French-speaking populion grew up with different cultural refences than English-Canadian or Americans. (Even though it truly offends English Canadians to be compared to Americans). Making an effort to understand it really pays off. Wouldn't it be better not to be confined to small neighborhoods on montreal?\n",
            "-------\n",
            "Q:How can i raise my high school GPA? I currently have a 2.8, how can I get above a 3.0+?\n",
            "A:You spend your class time paying close attention, taking notes and doing the assignments to the best of your ability.  Then, you spend your AFTER school time studying.. even when you don't have homework.. you study the lesson ANYWAY..  You ask your teachers for extra credit work and then you do your VERY best on them.  You will not only raise your grades and your GPA, but you will impress the teachers which DOES make a difference, take my word for it.\n",
            "-------\n",
            "Q:when will bush burn in moltan lava in hell?\n",
            "A:he will burn in moltan lava soon as god sends his soul there\n",
            "-------\n",
            "Q:why do we have to wake up so early in the moring to go  to school?\n",
            "A:Your brain is the most important organ in your body, and also it's particularly helpful for school. When you concentrate your brain will use 20% of the glucose in your body. You therefore need to get out of bed early so that you can A) wake up your brain, and B) feed your body which will allow for the intake of glucose to your brain when you need it.....\n",
            "-------\n",
            "Q:what was the relevance of Medicare Part D in 2014, what errors contributed to the amount spent, and what does the RAC receive for their work?\n",
            "A:In 2014, the federal government spent $58 billion on Medicare Part D, the voluntary, outpatient prescription drug coverage program. An estimated $1.9 billion of this total was improper payments--including overpayments or underpayments that may be due to errors, such as the submission of duplicate claims for the same service. In January 2011, CMS began a RAC program in Part D that was intended in part to identify and recoup improper payments, as required under the Patient Protection and Affordable Care Act. The RAC is paid a contingency fee from amounts recovered.\n"
          ]
        }
      ],
      "source": [
        "print(qa_statics_datsets.keys())\n",
        "#qa_statics_datsets['train']\n",
        "\n",
        "for i,e in enumerate(qa_statics_datsets['train'][::100]):\n",
        "    if i>200:\n",
        "        break\n",
        "    print(\"-------\\nQ:%s\\nA:%s\" % (e['query'], e['positives'][0].replace(\"\\n\",\" \") if bool(e['positives']) else e['negatives'][0].replace(\"\\n\",\" \")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Vmko2SmxHe",
        "outputId": "76580bd4-9403-4620-eeb0-1b143548722e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 1662\n",
            "finished building the ANN index\n",
            "done finding negatives\n",
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 3041\n",
            "finished building the ANN index\n",
            "done finding negatives\n"
          ]
        }
      ],
      "source": [
        "# this takes a long time to query for negatives (maybe I should just use the other negaitve generator)\n",
        "\n",
        "NEGATIVE_CORPUS_METHOD_QA = 'ann-tfidf' #'bm25'\n",
        "qa_torchdataset_val = DatasetTriplets(\n",
        "    list_of_data = qa_statics_datsets['val'],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "    negative_corpus_method = NEGATIVE_CORPUS_METHOD_QA\n",
        ")\n",
        "\n",
        "#\n",
        "if True:\n",
        "    qa_torchdataset_train = DatasetTriplets(\n",
        "        list_of_data = qa_statics_datsets['train'],\n",
        "        n_negatives= 3,\n",
        "        focal_text_name ='query',\n",
        "        positives_text_name ='positives',\n",
        "        negativess_text_name ='negatives',\n",
        "        topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "        negative_corpus_method = NEGATIVE_CORPUS_METHOD_QA\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mje7yyhqniKU",
        "outputId": "e6e6a817-017c-4e7c-980f-c1fd1ad4cea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9151\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': \"How do they make 3D movies? Why do we have to wear glasses? What's their role?\",\n",
              " 'pos': '3D movies use a variety of technologies to create the illusion of depth and realism. Specialty glasses are used to create the 3D effect by allowing each eye to receive different images. The glasses use either shutters, color filters, or polarized lenses to receive the images so that your brain can put the 3D effect together. Without the glasses, the 3D movie will look blurred and may be too uncomfortable for some people to watch[2]. The glasses also enhance the depth perception of the images so that they seem more lifelike and as if they are leaping from the screen[3]. There are several different types of 3D technologies in use today, but they all work together to send each eye different perspectives of the same image[5].',\n",
              " 'neg': 'Looking directly at the sun can cause a condition called solar retinopathy, which is when solar radiation damages the eyes and can even lead to permanent blind spots or distortions in your vision[2][3]. The sun’s light is so intense that even a small sliver of exposed light is enough to cause irreversible damage[3]. The only safe way to look directly at the sun is through specifically designed solar filters, such as “eclipse glasses” or in solar eclipse viewers[4][5].'}"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(qa_torchdataset_train))\n",
        "qa_torchdataset_train[2700]\n",
        "\n",
        "# WORKS: done with the QA sets (need to expand amount of data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_ZSsSvhIBMY"
      },
      "source": [
        "### A) Retrieval Tasks\n",
        "In general, what loss would I use for the QA & retrieval tasks? Distillation is obvious, but what about\n",
        "- SQUAD - has QA pairs - squad_v2\n",
        "    - good for distillation\n",
        "- ORCA - has GPT-like prompting QA pairs: https://huggingface.co/datasets/Open-Orca/OpenOrca/viewer/Open-Orca--OpenOrca/train?row=29\n",
        "- DONE Simple-Wiki https://huggingface.co/datasets/embedding-data/simple-wiki - has paraphrases\n",
        "- DONE embedding-data/coco_captions_quintets - multiple captions as paraphrases\n",
        "- DONE embedding-data/simple-wiki - pairs of paraphrases from wikipedia\n",
        "- DONE embedding-data/SPECTER - triplets of {anchor, pos, neg}, small headline-like snippets in technical /statistical /science fields\n",
        "- https://huggingface.co/embedding-data - has a lot of retrieval tasks\n",
        "- LLukas22/scidocs - titles and abstracts\n",
        "- DONE allenai/scirepeval - cite_prediction - has query,pos, neg based on citations\n",
        "- DONE - LEDGAR - can possible do triplets on same label\n",
        "- Rahmaa/ElsevieR_ClEaN - possible relation between title and abstract\n",
        "- embedding-data/WikiAnswers - 25 question paraphrases (maybe no answers)\n",
        "- cnn_dailymail - summarization possiblility 287k (beware |||?)\n",
        "- multi_news - another summarization 45k (beware |||?)\n",
        "- DONE xsum - BBC extreme summarization 204k\n",
        "- DONE lighteval/legal_summarization - legal summization of bills (BillSum 18.8k)\n",
        "- SKIP launch/gov_report # this could be used for LONG document summaries/retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqTVMjmNIWpx"
      },
      "outputs": [],
      "source": [
        "#foo =  load_dataset(\"embedding-data/simple-wiki\",split='train',streaming=True)\n",
        "#foo =  load_dataset(\"embedding-data/coco_captions_quintets\",split='train',streaming=True).take(2000)\n",
        "#foo =  load_dataset(\"embedding-data/SPECTER\",split='train',streaming=True)\n",
        "#foo = load_dataset(**{'path': 'embedding-data/SPECTER', 'name':None, 'split':'train', 'streaming':True})\n",
        "#foo =  load_dataset(\"paws\",'labeled_final',split='train',streaming=True)\n",
        "#foo =  load_dataset(\"embedding-data/QQP_triplets\",None,split='train',streaming=True)\n",
        "#foo =  load_dataset(\"\",None,split='train',streaming=True)\n",
        "#foo =  load_dataset(\"\",None,split='train',streaming=True)\n",
        "#foo = load_dataset(\"allenai/scirepeval\", 'cite_prediction',None, split='train',streaming=True)\n",
        "# foo = load_dataset(**{'path': 'allenai/scirepeval', 'name':'cite_prediction', 'split':'train', 'streaming':True})\n",
        "#foo = load_dataset('json', data_files=\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", split=\"train\", streaming=False)\n",
        "#foo = load_dataset(**{'path': 'json', 'name':None, 'data_files':'https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip', 'split':'train', 'streaming':True})\n",
        "foo =  load_dataset(\"lighteval/legal_summarization\",\"BillSum\",split='train',streaming=True)\n",
        "\n",
        "if True:\n",
        "    # embedding-data/WikiAnswers\n",
        "    for j,e in enumerate(foo):\n",
        "        print(e)\n",
        "        #print(len(e['set']))\n",
        "        if j > 100:\n",
        "            break\n",
        "    print(e.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFNfy-uRIDzD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def clean_legalsum(x):\n",
        "    MAX_CHAR_LEN_BILLSUM = int(6.7*600)\n",
        "    text = x['article'][:MAX_CHAR_LEN_BILLSUM]\n",
        "    if 'SEC. 2.' in text:\n",
        "        text = \".\".join(text.split('SEC. 2.')[1].split('.')[1:])\n",
        "    else:\n",
        "        if 'SHORT TITLE' in text:\n",
        "             text = text.split('SHORT TITLE')[1]\n",
        "    x['query'] = x['summary']\n",
        "    x['positives'] = [text.strip()]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_xsum(x):\n",
        "    x['query'] = x['summary']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = [x['document']]\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_eurlex(x):\n",
        "    x['query'] = x['text']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = []\n",
        "    x['type'] = 'sts_by_textlabel'\n",
        "    x['label'] = x['eurovoc_concepts']\n",
        "    return x\n",
        "\n",
        "def clean_allenai_citeprediction(x):\n",
        "    x['query'] = x['query']['abstract']\n",
        "    pos = x['pos']['abstract']\n",
        "    x['positives'] = [pos] if pos is not None else []\n",
        "    neg = x['neg']['abstract']\n",
        "    x['negatives'] = [neg] if neg is not None else []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_simple_wiki(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_coco_captions_quintets(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = x['set'][1:]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_specter(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = [x['set'][2]]\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_paws(x):\n",
        "    x['query'] = x['sentence1']\n",
        "    x['positives'] = [x['sentence2']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_qqp(x):\n",
        "    x['query'] = x['set']['query']\n",
        "    x['positives'] = x['set']['pos']\n",
        "    x['negatives'] = x['set']['neg']\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_ledgarlabelled(x):\n",
        "    x['query'] = x['provision']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = []\n",
        "    x['type'] = 'sts_by_textlabel'\n",
        "    return x\n",
        "\n",
        "#dict_keys(['question_id', 'question', 'document_title', 'answer', 'label'])\n",
        "sts_streaming_cleaning_functions = {\n",
        "    'xsum':(clean_xsum, None, ['query','positives','negatives'],['summary','id','document']),\n",
        "    'embedding-data/simple-wiki':(clean_simple_wiki, None, ['query','positives','negatives'],['set']),\n",
        "    'embedding-data/coco_captions_quintets':(clean_coco_captions_quintets,None, ['query','positives','negatives'],['set']),\n",
        "    'embedding-data/SPECTER':(clean_specter,None, ['query','positives','negatives'],['set']),\n",
        "    'paws':(clean_paws,None, ['query','positives','negatives'],['id', 'sentence1', 'sentence2', 'label']),\n",
        "    'embedding-data/QQP_triplets':(clean_qqp,None, ['query','positives','negatives'],['set']),\n",
        "    \"allenai/scirepeval\":(clean_allenai_citeprediction, None,  ['query','positives','negatives'], ['pos','neg']),\n",
        "    \"lighteval/legal_summarization\":(clean_legalsum, None, ['query','positives','negatives'], ['article', 'summary']),\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\":(\n",
        "        clean_ledgarlabelled, None, ['query','label'], ['provision','source']\n",
        "    ),\n",
        "    \"eurlex\":(clean_eurlex, None,  ['query','positives','negatives'], ['celex_id', 'title', 'text', 'eurovoc_concepts']),\n",
        "    #'':(,None, ['query','positives','negatives'],['']),\n",
        "    #'':(,None, ['query','positives','negatives'],['']),\n",
        " }\n",
        "\n",
        "DEFAULT_PROB = 1.0\n",
        "sts_files = [\n",
        "    # dataset name, subset, take_probability, dataset size\n",
        "    ('xsum', None, DEFAULT_PROB, 204000, 'sts_by_triplet', False),\n",
        "    ('embedding-data/simple-wiki',None, DEFAULT_PROB, 102000, 'sts_by_triplet', False), # wikipedia paraphrases\n",
        "    ('embedding-data/coco_captions_quintets',None, DEFAULT_PROB,82800, 'sts_by_triplet', False), # caption paraphrases\n",
        "    ('embedding-data/SPECTER',None, DEFAULT_PROB,684000, 'sts_by_triplet', False), # ?\n",
        "    ('paws','labeled_final',DEFAULT_PROB, 49400, 'sts_by_triplet', False), # paws paraphrases\n",
        "    ('embedding-data/QQP_triplets',None,DEFAULT_PROB, 102000, 'sts_by_triplet', False), # quora?\n",
        "    (\"allenai/scirepeval\", 'cite_prediction_new', DEFAULT_PROB, 1300000, 'sts_by_triplet', False), # ?\n",
        "    (\"lighteval/legal_summarization\",\"BillSum\", DEFAULT_PROB, 18900, 'sts_by_triplet', False),\n",
        "    ('https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip', None, DEFAULT_PROB, 1000000, 'sts_by_label', False),\n",
        "    ('eurlex', None, DEFAULT_PROB, 45000, 'sts_by_label', False)\n",
        "]\n",
        "\n",
        "stsdata_streaming_config = {\n",
        "    'files':sts_files,\n",
        "    'max_seq_length':512,\n",
        "    'prepend_q': 'passage: ',\n",
        "    'prepend_a': 'passage: ',\n",
        "    'val_size':100,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1d79ada03ea7445b94a2e90d42da3c50",
            "489bca43eaa34024ae076d61836b481b",
            "91f909ed91a74906ac58b474dfb17b23",
            "1e92221379c449be9f18e1bc813787c1",
            "0dd164739739485abf56d1c16e5fd00d",
            "3cdf813044f446c0b2cf4ec8c5f51b41",
            "c7208573f8204d9b9f0956753eda0ad0",
            "bd79c278334743d6a7f0c3c512924a74",
            "cb05ae1df75e414b82a94b188118cfe9",
            "b5fc72b3f24643c892c8c5426deb48c5",
            "df893a2f587e456288a0fd0b30438669",
            "ddb2d1c4288447748b7f2379ec2d49dd",
            "24f281ec4d904b27a5f45a7820fff9a9",
            "f08a92940f3444298e26db95fe957e78",
            "7bafeac027304b49b44f913fdbfdd54d",
            "71ea3c60b4104f41b1fc714a4aaa4ae8",
            "e24e2408e27249d4841b1633f386f012",
            "41f3134a1ab842df849f97fa73f51254",
            "6bab212ec66b4136b3c2c695ba309c07",
            "e9912207e85a49819be3aa3f5f9a9397",
            "119f25badf4e4cb8a9bacc4ba77dc51e",
            "f6fdd2a41cb1482a9b2b869776dd1dbe",
            "4a3d7c6179fb4158bb1a5f452b29c308",
            "fc03f25dc1d642a79e21e2ff2be3dd35",
            "c05be6815b304522ab70ebeb2dd1a3b9",
            "da9e8a5d31f64f98baabcdd61a092cb1",
            "aa46d7c838df43508b1187d034341421",
            "51b2478fccc64ed99f54ef99d1ddffd5",
            "a68b302b53b341d9918ebb3e3ef3048b",
            "9343a32f5b0b4f0fb271430b6343831f",
            "1c9d94d1b8b74549b9f473c5220b32b0",
            "729e25ed88bd4d4d89338d0d8e54d4dc",
            "d5bb855c24c944e1b76c9e9414020778",
            "941fd9d0a162417cb7cbc799339bc9be",
            "27942f0823b6469db6f785463d429e27",
            "6aa762333f4e459092b6f2949203b7e7",
            "3a95095e2d0845d793654199eba19cd5",
            "c9fc0fbae8854d609c9a923c475f43ba",
            "849e4b64e3c14349acee2f55f9600249",
            "b7c9909bd1574248801e53bdf8827cb6",
            "98804ca8de5c4af7ba392f82e2decc75",
            "6676d80a5adc45e4806ae8e369fcfe23",
            "32b99a92413745a3976c31c5cdae8fad",
            "a76e83b34560423e82cbe55717f7082c",
            "bb472469d98c4849acbc2dd2cfe21495",
            "f62eff66629340149fb997d61bbda086",
            "41ce600f2e84451cb91a75e4c1eb5cac",
            "b1c27f532e474f45af9a247df33df4d5",
            "fc6fde1c20494c289551b7356f1e341c",
            "e3108925761e44a5b772723a970eeb09",
            "f05a48bb63db4f7aba5ccaba188b75fe",
            "1c43d1c2070b4ccc89e8714ead9ee0dd",
            "5b29d0db23b9481db48a6c56e93a41cf",
            "43a0d30d3abf4da694265f61dc05d9c7",
            "9a7f1c78669845af9b39f2904b061b4d",
            "650346b4f83a419297fa6fb6cc5156b8",
            "0a9e9f87e453478db26276ec5b4d9913",
            "a611dd18d0284289b4b1dddf574f4e3e",
            "6beef838fd8a4d119c6b704746b4322a",
            "8abf5e3e9645453991ff2ebf5b714763",
            "47ca81ae665a4437a4e4d3ece5591823",
            "08ed0c209fc14c8db78149696ec91e58",
            "824bdc0faabd449096459e491d7a7d45",
            "6de1573bc51f495fa27bf5cfecd85295",
            "936348ad30684927b387b7e02efd4361",
            "5f2f6e6fb7624adbbe1229344230335d",
            "eab2c2bd6f424206b26c9c2e5bec6cfe",
            "e45fad24ed164a8ebd0856fa32df68cb",
            "eb8445f4f2474f128a9a34ee815a09ad",
            "5e0b9eeeed064894be9807fc5464073a",
            "ef63ffca2aaf4e6c9953cf5af742addf",
            "b70d5fa86a5b410cbfdff89da51ef6f8",
            "52a159d9e9854013bf1a5cf711d50093",
            "356f65307a5b4ffb845b0a51dd82a10a",
            "09ceb11ff6e34ecf995aab26e8f9c05d",
            "51c65da12a5a401b9263fbe8050b5bc5",
            "c2beabf523574127b916e27b1be2a248",
            "a3c32097486242fabc161b3d3511a7f4",
            "a5f83f5df68d4ade896e03e3326c1f17",
            "d207a39f2e344b668c345f522b60cca5",
            "258524f690c449b793139e8b03d1fc9d",
            "8dba751b9b1544369fcc9f4bca44c449",
            "0044237cbef746f9afbe688592bd0e84",
            "8366f2cb708944b38ccd18c2407c2fd1",
            "3525c2478cdb44dd9b80f4b5f4af2659",
            "56c0600f62514fea9a456a457720311b",
            "d4acc49dcd844d7892ab2a432e79d56a",
            "6f48447043914f1ea91cfd94e442a4e7",
            "d684c0d984204682b0797ffe01c55cae",
            "b34f87e950dc4fbbafc0e13414c81ecf",
            "4451aba03f3a4d378cfeb04ceee5481f",
            "2b9d70f4869c456b994ef7166e42d253",
            "1ed23c72816b4505bb41e26c734a471b",
            "3b7d6c3a741249d48ebcda417eec08aa",
            "d817d7511de84e92b77cd980658aa629",
            "35d01e3e13ed4a3f8ecfaecde0352a21",
            "0bc388b26cf64aecb160ab0f86482c93",
            "e7f79d2154784e4dac011fb680cf5e60",
            "99e3d22fc1584f63861fd9524949ee68",
            "ea178923525e40c28517d6d88d97745e",
            "25e3340ed1fa4ff28744b87cd44ff756",
            "c15a5c91a236400aa4873a4fe74d78be",
            "7291eb717846498f83f7591b1733334b",
            "3d362a5dfe9b4554bff3647a29f1d93d",
            "064e092286b64c1db17f69fead063380",
            "72b96a7e939b48b7a98a85a1c901ce58",
            "c90d99092731428f86c1125913e520f0",
            "be0e2757b3c34fb68b46cc21e471a077",
            "b4589d7a584b4690b47cd06b82c18053",
            "78d7a9d704834b13b7c2a7562da62d4d",
            "975d06eb7c6d48d7afc6f662b4239c2c",
            "8c8b7e081e834ccf98a4ce2730e00f24",
            "8ed7a47170dc42739ff049440372b2d3",
            "ba056ae684d5497c8639be605c2b152e",
            "6319e3d301f040008853a8112bec28e3",
            "f471e7ebb7c245179c58992fc78b3e55",
            "e31dc156f8034495a5737385ef032e77",
            "4c0d4a0a16664758987fcc67422c2c89",
            "38bcb0d78ed94011936def4c3615504b",
            "361d5a3bb70e49a3bb27d843cf6b0afc",
            "18db0004a5de4fe7a7b0ccc2a2e8fed3",
            "fd75292380894c7db8ec027b6667c9b1",
            "372c8e31995545df9d59d0d39733e49a",
            "abca76b7bf414761b58614bafd4acf18",
            "a35999c21eed4068a9d768e200c148ed",
            "145fcb4a45264b089edb8c7503470d72",
            "891bfb21ffed4024bc38f8a62fdd62fb",
            "361e6535b4194815b783b5a572c0c725",
            "c3e8acf24d3a43ba916dfcf016cc97cd",
            "fd7af48fb7dc4ba5bdc583c19786cacf",
            "5d880747de69431a896ecb1104284873",
            "cb8c595679a6465abb9c836d570766bf",
            "3a2911388c6845018ba8454fdf44e2b9",
            "a17af08f33c6440081c2fe9cd6e27a38",
            "42ef3d3c96c94aca9833834c52ea126b",
            "48598cc0fb5045f888e265a561711726",
            "30cda55d35044431bffc7ce4ad88bcdc",
            "18b959f151f64f34949c2820e9684be8",
            "994c9803c31e49ec810796863532f52f",
            "f5dfeae5f20a425cab5a19aa8ae340ea",
            "91a8e2de38594a55828cb3e19f4b9d32",
            "cce2d3a52ab449a9b8539a663f88dc23",
            "cdf772bf44f8400caf20d7df43bad6c0",
            "f62de3a243d54c358d31fef138b73997",
            "3fd737f15fe74553a4cd7d29ecd813f2",
            "cc95388f183f414991678bdf20e380fc",
            "1295ac5c11614966bff2570a26fe515c",
            "a8dcf6c462d14fba93e6b8335d0939e5",
            "c92ca0a6d3b9472f98613666cdeb0d73",
            "480c0caed8a94250a9264b59620bbb29",
            "402d63f4215a480aba1156661261a877",
            "b166384a68ae4e3ebd9e3fe19b719885",
            "ad891b6016e143b1841351478cfc15a0",
            "fe935a9cce43441f94e231c54e34779b",
            "b925756579154db5994a21d6768a00b9",
            "359118bc2d25450cb5c69de24f84d533",
            "778438eb8eba453fb926277641f26b35",
            "5c0b31457c634b7fb06a00cb78362e09",
            "4e5fc1ebc9b0447abc615de359a5e2fa",
            "80aa0f5a62774db5ad80778f93dfd5b3",
            "2abdae7b3f57423cbb15cac196752b9a",
            "60e06687a91843119fe512da01b90bfd",
            "1283ef2790484d7da9f8e2e51d91f9c6",
            "49bb63cd356546bcacfe6dc514b0ace6",
            "7b13c1d51dec405ca19e803a26b8726b",
            "0ac4b892acc24d2f9d3416110d36ad03",
            "37afab3d5b54448ebfbef920d1b81aa0",
            "a4eea440e6544b5fa1cb92745c17d138",
            "ddeff3c577cc4817806eb81c79a2f3f2",
            "e954280499de40579d62a674e1c2acc4",
            "faa23b88cb754258a876d7d6132c2903",
            "0e871253040141da803ba07be6447d93",
            "e9200fc6a2064330ae6ddbbf1b157fd4",
            "1c061d153d6043beb838304e363dde5a",
            "44673cba464f4e5799fc317192a5d987",
            "a606a8d169a64b138069d0469261b7ab"
          ]
        },
        "id": "LamNdWbR0P8e",
        "outputId": "996dd00a-746c-4348-fb2a-cd7144d949e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing the streaming-QA to static-dataset procedure...\n",
            "trying xsum initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d79ada03ea7445b94a2e90d42da3c50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.76k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddb2d1c4288447748b7f2379ec2d49dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from xsum validation\n",
            "take 50 from xsum train\n",
            "Done getting streams/reloading from xsum\n",
            "done val language check\n",
            "done train language check\n",
            "trying embedding-data/simple-wiki initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a3d7c6179fb4158bb1a5f452b29c308",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.16k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from embedding-data/simple-wiki validation\n",
            "take 50 from embedding-data/simple-wiki train\n",
            "Done getting streams/reloading from embedding-data/simple-wiki\n",
            "done val language check\n",
            "done train language check\n",
            "trying embedding-data/coco_captions_quintets initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "941fd9d0a162417cb7cbc799339bc9be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from embedding-data/coco_captions_quintets validation\n",
            "take 50 from embedding-data/coco_captions_quintets train\n",
            "Done getting streams/reloading from embedding-data/coco_captions_quintets\n",
            "done val language check\n",
            "done train language check\n",
            "trying embedding-data/SPECTER initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb472469d98c4849acbc2dd2cfe21495",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.28k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from embedding-data/SPECTER validation\n",
            "take 50 from embedding-data/SPECTER train\n",
            "Done getting streams/reloading from embedding-data/SPECTER\n",
            "done val language check\n",
            "done train language check\n",
            "trying paws initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "650346b4f83a419297fa6fb6cc5156b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.43k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eab2c2bd6f424206b26c9c2e5bec6cfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/7.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3c32097486242fabc161b3d3511a7f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/9.34k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from paws validation\n",
            "take 50 from paws train\n",
            "Done getting streams/reloading from paws\n",
            "done val language check\n",
            "done train language check\n",
            "trying embedding-data/QQP_triplets initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d684c0d984204682b0797ffe01c55cae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from embedding-data/QQP_triplets validation\n",
            "take 50 from embedding-data/QQP_triplets train\n",
            "Done getting streams/reloading from embedding-data/QQP_triplets\n",
            "done val language check\n",
            "done train language check\n",
            "trying allenai/scirepeval initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea178923525e40c28517d6d88d97745e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/9.01k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "975d06eb7c6d48d7afc6f662b4239c2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/12.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd75292380894c7db8ec027b6667c9b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/28.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets_modules.datasets.allenai--scirepeval.893c7671ad824a7f358400e8cee217464689c5e0a1029cacc69a6943d840717c.scirepeval:https://ai2-s2-research-public.s3.us-west-2.amazonaws.com/scirepeval/train/cite_prediction_new/train.jsonl\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from allenai/scirepeval validation\n",
            "take 50 from allenai/scirepeval train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets_modules.datasets.allenai--scirepeval.893c7671ad824a7f358400e8cee217464689c5e0a1029cacc69a6943d840717c.scirepeval:https://ai2-s2-research-public.s3.us-west-2.amazonaws.com/scirepeval/train/cite_prediction_new/train.jsonl\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done getting streams/reloading from allenai/scirepeval\n",
            "done val language check\n",
            "done train language check\n",
            "trying lighteval/legal_summarization initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a2911388c6845018ba8454fdf44e2b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from lighteval/legal_summarization validation\n",
            "take 50 from lighteval/legal_summarization train\n",
            "Done getting streams/reloading from lighteval/legal_summarization\n",
            "done val language check\n",
            "done train language check\n",
            "trying https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip initialization\n",
            "take 20 from https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip validation\n",
            "take 50 from https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip train\n",
            "Done getting streams/reloading from https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\n",
            "done val language check\n",
            "done train language check\n",
            "trying eurlex initialization\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f62de3a243d54c358d31fef138b73997",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.11k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b925756579154db5994a21d6768a00b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ac4b892acc24d2f9d3416110d36ad03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/10.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 20 from eurlex validation\n",
            "take 50 from eurlex train\n",
            "Done getting streams/reloading from eurlex\n",
            "done val language check\n",
            "done train language check\n",
            "Done collecting STS streaming data\n",
            "saving streamed STS validation data: cache_val_sts.pkl\n",
            "saving streamed STS training for epoch 0: cache_train_sts_000.pkl\n"
          ]
        }
      ],
      "source": [
        "stsdata_streaming_config = {\n",
        "    'files':sts_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':200,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "sts_statics_datsets = initialize_and_get_triplet_streaming_datasets(\n",
        "    data_streaming_config = stsdata_streaming_config,\n",
        "    streaming_cleaning_functions = sts_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_sts.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_sts_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'STS' #\n",
        ")\n",
        "\n",
        "\n",
        "if False:\n",
        "    print('old functions')\n",
        "    # initialize streaming data for sts tasks\n",
        "    sts_streaming_datsets, sts_probabilities, sts_datasizes = initialize_qa_streaming_datasets(\n",
        "        stsdata_streaming_config,\n",
        "        sts_streaming_cleaning_functions\n",
        "    )\n",
        "\n",
        "    # split and make-static (train and val sets, non-streaming)\n",
        "    sts_statics_datsets = train_test_splits_from_stream_qa(\n",
        "        streaming_dataset=sts_streaming_datsets,\n",
        "        val_size = 100,#2000,\n",
        "        epoch = 0,\n",
        "        chunk_size = 2000,#6000,\n",
        "        path_to_val_cache = 'val_sts_cache.pkl',\n",
        "        probabilities = sts_probabilities,\n",
        "        datasizes = sts_datasizes,\n",
        "        seed=stsdata_streaming_config['seed']\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcFQO9CMc533",
        "outputId": "cb660aa8-97ac-41d9-c847-42dbc38158bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': \"A man who tried to cut the throat of his estranged wife's aunt has been jailed for 22 years.\", 'negatives': [], 'positives': ['Farai Kambarani, 26, was convicted of the attempted murder of social worker Ruth Nayamazana, who he wrongly blamed for not letting him see his child.\\nLuton Crown Court heard his victim, who he also punched in the head 10 to 20 times, still lives in fear.\\nKambarani was given a 22-year jail sentence with a three-year extension on licence.\\nThe court heard Kambarani, from Wolverhampton, shunted a car into the back of Ruth Nayamazana\\'s vehicle in Saxon Gate car park in Milton Keynes on 22 August last year.\\nWhen she got out, he repeatedly punched her in the head.\\nIn the witness box, the 34-year-old said he pulled out a small knife and used it against the side of her throat.\\nShe said: \"I was screaming. I thought he was going to cut my throat. The blood started gushing out.\"\\nKambarani, a former carer for elderly people, was also convicted criminal damage and stalking his former partner.\\nThe court heard Kambarani fled to the UK from Zimbabwe in November 2014 after being arrested and tortured. He began a relationship with another woman in Wolverhampton.\\nLater his wife and child moved to the UK. In June last year, he became angry when she moved in with her uncle and his wife in Milton Keynes.\\nSebastian Gardiner, defending, said: \"Fortunately, her life was not endangered. She spent three days in hospital and made a full recovery.\"\\nHe accepted the attack had caused serious psychological difficulties for the victim.\\nJudge Philip Bartle said: \"You became fixated with Ruth and saw her as an obstacle to you seeing your daughter. There was no justification for that.\"'], 'type': 'sts_triplet'}\n",
            "{'query': 'Somerset director of cricket Matt Maynard has hailed the arrival of former Australian opener Chris Rogers as a marquee signing for next season.', 'negatives': [], 'positives': ['Rogers, 38, will play in next season\\'s County Championship and Maynard is delighted with the signing.\\n\"He has agreed to come in and bat at three for the summer and that\\'s a real top signing for us, a marquee player,\" Maynard told BBC Radio Somerset.\\n\"He is a great acquisition, I\\'m really looking forward to working with him.\"\\nMaynard says the Sydney-born left-hander will be a huge asset to the side and will help support the opening duo of Marcus Trescothick and 21-year-old Tom Abell.\\n\"I think it was quite evident that apart from Marcus and Tom at the top of the order, we needed a bit more stability at three.\\n\"He\\'s got a world of experience, he is still very athletic, he is a very fit lad, he has got that Aussie determination, that steely quality and we saw during the summer he is a high-class player on tough wickets.\"\\nRogers announced his retirement from Test cricket prior to this summer\\'s Ashes series and Maynard hopes his experience can help the younger members of Somerset\\'s squad.\\n\"We can\\'t stifle our young talent and ask Tom Abell to bat out of position. He has established himself as an opener, he still has a long way to go but has the potential to go all the way and bat for England for a number of years.\\n\"Obviously Marcus is still at the top of his game. Chris has batted at three a number of times in his career and is happy there. Also it will give him time to bed in, he is a quality performer and we\\'re hoping for an excellent season from him.\"'], 'type': 'sts_triplet'}\n",
            "{'query': \"World number one and defending champion Rory McIlroy will miss next week's Open after injuring his left ankle.\", 'negatives': [], 'positives': ['The Northern Irishman, 26, revealed on Monday he had ruptured an ankle ligament playing football with friends.\\nConfirming he would not compete at St Andrews, he posted on Instagram: \"I\\'m taking a long-term view of this injury.\\n\"Although rehab is progressing well, I want to come back to tournament play when I feel 100% healthy and 100% competitive.\"\\nThe 2015 Open begins on 16 July, and tournament organisers said they were \"naturally very disappointed\" at McIlroy\\'s withdrawal.\\nThey added: \"Rory will play in many more Opens and our primary concern is for his complete recovery.\"\\nMcIlroy, who has won four majors, could also miss the chance to defend his US PGA Championship title in mid-August.\\nMcIlroy ruptured his left ankle ligament on Saturday during a \"soccer kickabout with friends\".\\nOn Monday he wrote on Instagram: \"Total rupture of left ATFL (ankle ligament) and associated joint capsule damage. Continuing to assess extent of injury and treatment plan day by day. Rehab already started..... Working hard to get back as soon as I can.\"\\nAt the time, McIlroy had not ruled himself out of the Open and an announcement on his condition had not been expected until the weekend.\\nMcIlroy finished fourth at the Masters in April, and joint ninth at last month\\'s US Open. Both tournaments were won by American Jordan Spieth.\\nThe Northern Irishman missed the cut at the Honda Classic in March, but won the World Golf Championships Match Play and the Wells Fargo Championship in May.\\nMcIlroy\\'s Ryder Cup team-mate Graeme McDowell: \"I wasn\\'t expecting him to play in the Open, so I\\'m not surprised he\\'s pulled out. But it\\'s a massive blow for the tournament, he\\'s the world\\'s number one player.\\n\"No-one would love to stop Jordan Spieth in his tracks next week more than Rory. With the fun rivalry going on and everything, he\\'s going to be gutted. I saw the golf course last Saturday and I believed that Rory was rightly a favourite. I thought he\\'d get it done round there.\"\\nFormer US Open champion Justin Rose: \"I would have been surprised if he was there given the initial diagnosis but it\\'s a big shame for him and the tournament.\"\\nFlorida-based Scot Russell Knox who was first reserve and replaces McIlroy in the field at St Andrews: \"Nobody wants to get in because someone got injured but I am happy I am in the field and can\\'t wait to give it a blast.\"\\nSpieth said McIlroy had done nothing wrong by playing football with friends ahead of the Open: \"It\\'s unlucky, it\\'s unfortunate and I\\'m sure he\\'s taking it harder on himself than anybody else.\\n\"But I don\\'t think he did anything wrong. It just was an unfortunate situation and hopefully he rebounds quickly and gets back right to where he was.\"'], 'type': 'sts_triplet'}\n",
            "{'query': 'Congress in Uruguay has voted overwhelmingly to legalise gay marriage, becoming the second country in Latin America to do so, after Argentina.', 'negatives': [], 'positives': ['The bill was approved by more than two-thirds of the lower chamber, despite opposition from the Catholic Church.\\nThe proposal has already been backed by the upper house. It is expected to be signed into law within two weeks.\\nPresident Jose Mujica has been championing the bill.\\nDespite opposition from the Roman Catholic Church in Uruguay, 71 out of 92 deputies have voted in favour of the measure.\\nBy Vladimir HernandezBBC Mundo\\nA wave of reform seems to be sweeping through Uruguay.\\nIts Congress has started to debate the possible legalisation of cannabis, it passed a law to give women the right to opt for an abortion, and now it has  allowed gay couples to marry.\\nUruguay has become the second country in the Latin America, after Argentina, to legalise same-sex marriages.\\nThis has attracted criticism from some sectors, such as the Roman Catholic Church, which say that the law weakens the institution of marriage.\\nAccording to Ignacio Zuasnabar, director of the Uruguayan pollster Equipos: \"There has been more acceptance of gay marriage in recent years as public opinion seems in favour of giving more rights to same-sex couples.\\n\"Things are different with other divisive subjects, like the possible legalisation of cannabis and the recent law that approved abortions, which have more polarised views or simply a majority of people that disapprove of them,\" he told the BBC.\\n\"Freedom, freedom,\" shouted activists who were attending the session in the Congress building in Montevideo as the result was announced.\\n\"Same-sex couples have always existed,\" said Mr Mujica, a former left-wing guerrilla, in a television interview with Russia Today earlier this year.\\nThe Marriage Equality Law was approved by the Senate last week by 23 votes to 8.\\nIt allows same-sex couples to choose the order of the surnames of the children they adopt.\\nAnd it also increases the age of consent for sexual relations to 16, from the current 12 for women and 14 for men.\\nIn recent years, Uruguay has moved to allow same-sex civil unions, adoption by gay couples, and to allow gay members of the armed forces.\\nUruguay\\'s neighbour Argentina legalised gay marriage in 2010. Same-sex marriages have been legal in Mexico City since 2009.\\nIn May, Brazil\\'s Supreme Court  voted overwhelmingly in favour of allowing same-sex couples the same legal rights as married heterosexuals.'], 'type': 'sts_triplet'}\n",
            "{'query': 'Four key Commons committees are asking the education secretary to make Personal, Social, Health and Economic (PSHE) education compulsory in schools.', 'negatives': [], 'positives': ['The education, health, home affairs and business committee chairmen want PSHE, which covers sex education, made statutory in primaries and secondaries.\\nIn a letter to Nicky Morgan, they express concern at her failure to respond to various committees\\' calls.\\nThe government is working on a way to achieve high-quality PSHE for all.\\nIt published guidelines on sex and relationship education (SRE) in 2015.\\nWhile PSHE education is not part of the statutory national curriculum, which means there is no national programme of study for the subject, the Department for Education say schools should teach it to pupils.\\nSchools are also required to have a policy on sex and relationship education which is made available to parents, and for inspection, which must set out how this is provided, monitored and evaluated..\\nIt must also include information about parents\\' right to withdraw their children from sex education classes.\\nThe chairmen\\'s letter said: \"We write to express our disappointment with your response so far to the issue of the statutory status for PSHE and sex and relationships education in schools.\\n\"PSHE is a crucial part of preparing young people for life. It can provide them with the knowledge and confidence to make decisions which affect their health, well-being and relationships, now and in the future.\\n\"It can develop the skills and attributes needed to secure employment and can help protect young people from abuse in many forms.\"\\nIn February 2015, the education committee called for the DfE to \"develop a work plan for introducing age-appropriate PSHE and SRE as statutory subjects in primary and secondary schools, setting out its strategy for improving the supply of teachers able to deliver this subject and a timetable for achieving this\".\\nIn January 2015, the Joint Committee on Human Rights said it would be better if schools were \"required broadly to teach the same curriculum in PSHE\" and that this should include issues in relation to violence against women and girls.\\nSix months earlier, the Home Affairs Committee called for PSHE, covering education about female genital mutilation in high prevalence areas, to be made compulsory.\\nAnd both the Children\\'s Commissioner for England and the Chief Medical Officer made their own calls to make the subject statutory.\\nA Department for Education spokesman said it wanted all young people to leave school equipped with a curriculum for life that prepares them to succeed in modern Britain and the teaching of PSHE was central to that plan.\\n\"We are working with head teachers and other experts to understand how best to achieve high-quality PSHE for every pupil,\" he said.\\nThe spokesman added that PSHE was not yet good enough in many schools, adding the department had committed to looking further at this issue and examining all the options to ensure the subject was taught to a high standard in all schools.\\nIt intended to make significant progress on this issue this Parliament, he said.'], 'type': 'sts_triplet'}\n",
            "{'query': \"A mother has launched a legal battle for access to her dead daughter's frozen eggs, so she can carry her own grandchild.\", 'negatives': [], 'positives': ['The unnamed woman and her husband are challenging an independent regulator\\'s refusal to let them export the eggs from London to a US fertility clinic.\\nThe couple\\'s daughter died from bowel cancer in her late 20s.\\nThey claim she wanted her eggs to be fertilised by a sperm donor and implanted into her mother\\'s womb.\\nThe daughter, who was the couple\\'s only child, decided to freeze her eggs in a clinic at IVF Hammersmith in west London in 2008, following her cancer diagnosis.\\nShe hoped she would one day carry her own child, but she lost her battle with the disease.\\nA clinic in New York has indicated that it is willing to provide her 59-year-old mother with the fertility treatment she desires, at a cost of up to Â£60,000 ($92,000).\\nBut the Human Fertilisation and Embryology Authority (HFEA) has refused to issue a \"special direction\" to allow the eggs to be taken out of storage and sent to the US.\\nIts statutory approvals committee (SAC) made the ruling in 2014, saying there was insufficient evidence to show that the daughter wanted her mother to carry her child.\\nAlthough the woman completed a form giving consent for the eggs to be stored after her death, she did not fill out a separate document indicating how she wanted them to be used.\\nMinutes from a committee meeting revealed the \"strongest and only evidence\" of her wishes was a reported conversation with her mother while she was in hospital in 2010.\\nFertility expert Dr Mohammed Taranissi, who runs the ARGC clinic in London, said: \"I have never heard of a surrogacy case involving a mother and her dead daughter\\'s eggs.\\n\"It\\'s fair to say that this may be a world first.\"\\nThe application for judicial review is listed anonymously as \"M v the HFEA\" and it is understood the family does not want to be identified.'], 'type': 'sts_triplet'}\n",
            "{'query': 'Huddersfield defender Michael Hefele has signed a deal to keep him at the club until the end of next season.', 'negatives': [], 'positives': ['The 26-year-old joined the Terriers from Dynamo Dresden in July 2016 and made 40 appearances in 2016-17.\\nBoss David Wagner said: \"I think everyone can see how big an influence he is in the dressing room and how good of a character he is for the team.\"\\nThe Terriers start their inaugural Premier League campaign at Crystal Palace on Saturday.'], 'type': 'sts_triplet'}\n",
            "{'query': 'The UK government has defended security services against criticism they missed signs which might have helped prevent the murder of a soldier in London.', 'negatives': [], 'positives': ['The security services face a Commons inquiry after it was confirmed the two men arrested over the murder of Drummer Lee Rigby were known to MI5.\\nBut Communities Secretary Eric Pickles said it was impossible to control everyone all the time.\\nMichael Adebolajo and Michael Adebowale were named as suspects.\\nMr Pickles told the BBC: \"Peers and MPs will do a thorough investigation in terms of what the security forces knew but I\\'ve seen experts on security explaining how difficult it is in a free society to be able to control everyone.\"\\nDrummer Rigby, 25, was murdered on a street in Woolwich, south-east London on Wednesday afternoon.\\nShortly after the killing, a man, thought to be 28-year-old Mr Adebolajo, was filmed by a passer-by, saying he had carried out the attack because British soldiers killed Muslims every day.\\nArmed police arrived on the scene 13 minutes after the first 999 call and shot the two suspected attackers, who had made no attempt to flee.\\nMore than 30 people attended a prayer service in Drummer Rigby\\'s hometown of Middleton, Greater Manchester on Friday morning. Residents on the Langley estate where he grew up are being urged to fly union jacks by community activists.\\nDrummer Rigby had served in Afghanistan, Germany and Cyprus.\\nThe former head of counter terrorism at MI6, Richard Barrett, told the BBC how hard it could be to detect attacks of the type seen in Woolwich - despite the suspects having been known to MI5 for eight years.\\n\"I assume that these people are probably coming out of a small group without, necessarily, any overseas connections or any other broader connections in the United Kingdom which could come to the attention of the security services more than they did,\" he said.\\n\"When does a person who expresses radical views, who joins a radical group, flip over to be a violent extremist?\\n\"To find the signals, the red flags as it were, I think is enormously hard.\"\\nFormer Metropolitan Police commissioner, Lord Blair, told BBC radio he hoped the committee investigating how the suspects were monitored \"would act fast\" to establish what might have gone wrong.\\n\"I think it\\'s important for the public to have somebody say within the limits of legality that either something was mistaken, either decisions were badly taken or they weren\\'t, because I think it\\'s important for the public to know security services and the police are operating properly,\" he said.\\nHis comments came as video footage, obtained by the Daily Mirror, emerged showing the moment police shot Mr Adebolajo, originally of Romford, east London, and Mr Adebowale, 22, of Greenwich, south-east London.\\nIt shows one of the men charge at police sitting in a patrol car. He drops a knife as he is shot and falls to the ground.\\nThe other man is shown aiming a gun at officers as he runs in a different direction. Police are heard firing eight shots in total at the two men.\\nBoth of the suspects remain under armed guard in separate London hospitals in stable conditions with non-life-threatening injuries.\\nAnd police are said to be standing guard outside Mr Adebowale\\'s home in Greenwich, according to BBC correspondent Tom Bateman.\\nDetectives are also interviewing a man and a woman at a south London police station after they were arrested on Thursday night on suspicion of conspiracy to murder.\\nThe BBC has uncovered its own footage of Mr Adebolajo taking part in an Islamist demonstration in April 2007 against the arrest of a man from Luton, holding a placard reading \"Crusade Against Muslims\".\\nHe is shown standing next to then-leader of the now banned al-Muhajiroun organisation, Anjem Choudary, who has said Mr Adebolajo went his own way in around 2010.\\nMr Choudary appeared on Newsnight on Thursday and said Mr Adebolajo had made comments that \"I think not many Muslims can disagree with\".\\nThe radical Islamist preacher said he was \"shocked\" by what had happened. He also said: \"One man killed in the street does not equate to the hundreds and thousands and millions, in fact, who\\'ve been slaughtered by the British and American foreign policy.\"\\nMeanwhile, thousands of members of the Ahmadiyya Muslim community are expected to gather in London to offer prayers for the dead soldier and his family and to \"express solidarity against extremism\".\\nNational president Rafiq Hayat said: \"We hope that the perpetrators of this crime, that is based on a twisted and warped ideology, are brought to justice.\"\\nOn Thursday, Drummer Rigby\\'s family paid tribute to \"a loving son, husband, father, brother, and uncle, and a friend to many\".\\nThey said in a statement that Drummer Rigby, who had a two-year-old son, \"would do anything for anybody - he always looked after his sisters and always protected them\".'], 'type': 'sts_triplet'}\n",
            "{'query': \"(Close): London's leading shares headed lower in Tuesday morning trading, with copper miner Antofagasta clearly the biggest loser.\", 'negatives': [], 'positives': [\"At close, the benchmark FTSE 100 index was down 34.60 points or 0.56% to 6139.97.\\nAnglo American was the biggest faller,  down at close by 11%, or 59.05p, at 487.45 pence.\\nAntofagasta fell 4.47% after posting a 58% drop in annual profit and cancelling its final dividend.\\nOther miners suffered too: BHP Billiton and Glencore declined by 6.54% and 4.77% respectively.\\nRoyal Bank of Scotland was one of the biggest risers on the 100-share index, adding 1.47% after an upgrade from analysts at Goldman Sachs.\\nSupermarket chain Sainsbury's fared less well, shedding 1%, despite issuing a trading statement showing its first sales rise in two years.\\nOn the currency markets, the pound was down 1.07% against the dollar at $1.4150 and 1.05% lower against the euro at â‚¬1.2749.\\nTraders said sterling had been dragged lower by an opinion poll in the Telegraph newspaper indicating a narrow majority for supporters of an exit from the EU ahead of the 23 June referendum.\"], 'type': 'sts_triplet'}\n",
            "{'query': \"Inflation in the eurozone returned to zero in October from September's -0.1%.\", 'negatives': [], 'positives': ['Price growth in food, alcohol and tobacco increased slightly, while energy prices were still considerably lower than last year, according to Eurostat estimates.\\nThe statistics agency also estimated the unemployment rate in the 19 countries that use the euro was 10.8% in September, down from August\\'s 10.9%.\\nThe rate for the 28 EU members was 9.3%, down from 9.4% the month before.\\nThe eurozone rate is the lowest since January 2012 while the rate for the whole EU is the lowest since September 2009.\\nGreece had the highest rate at 21.6% (Greece is expected to be higher but has yet to report September figures), while Germany had the lowest at 4.5%.\\nThe inflation figures are an early, flash estimate from Eurostat and so are not broken down by member state.\\nIt does give broad indications of which groups of products have gone up or down.\\nFood, alcohol and tobacco prices were estimated to be rising 1.5% in October, compared with 1.4% in September.\\nEnergy prices were falling an annual 8.7%, compared with 8.9% a month earlier.\\nAnd the price of services were up 1.3% compared with 1.2% the month before.\\nMario Draghi, president of the European Central Bank, suggested this month that he might be prepared to extend the bank\\'s programme of quantitative easing given the low levels of eurozone inflation.\\n\"Although today\\'s inflation and unemployment data for the eurozone revealed small improvements, they are still very weak by past standards, suggesting that the ECB cannot afford to delay increasing its policy support much longer,\" said Jessica Hinds, European economist at Capital Economics.'], 'type': 'sts_triplet'}\n",
            "{'query': 'A drone the size of a football was flown within 20m (66ft) of a passenger jet as it approached Heathrow Airport, an investigation has found.', 'negatives': [], 'positives': ['The Airbus A320 was above Biggin Hill, south-east London, when it narrowly avoided a collision with the unmanned craft, UK Airprox Board (UKAB) said.\\nCrew members saw the drone but would not have had sufficient time to take action.\\nPolice have not been able to locate the drone operator, UKAB said.\\nThe plane was flying at 11,000ft when the drone was spotted passing the right wing \"very quickly\" by the first officer on 4 August.\\nUK rules on flying drones, called the dronecode, were drawn up by the Civil Aviation Authority (CAA). It states drones should:\\nThe officer alerted the captain by shouting \"look\", the report said, but they did not have time to take evasive action.\\nThey informed Air Traffic Control and were interviewed by Met Police officers about the near-miss once they landed.\\nUKAB\\'s board found the drone had \"flown into conflict with the A320\".\\nThe report concluded the drone had endangered the lives of those on the plane as a collision \"had only been narrowly avoided\".\\nAn Airbus A320 can typically carry up to 180 passengers.\\nA spokesperson for the CAA said it was \"totally unacceptable to fly drones close to aircraft and airports\" and \"anyone flouting the rules can face severe penalties including up to five years in prison.\"\\nFigures have shown there were more reported near misses between drones and aircraft over the UK in the first six months of 2016 than during the whole of the previous year.\\nSion Roberts, the head of drone training academy RUSTA, said the operator would have been flying \"BVLOS (Beyond visual line of sight)\" which was against regulations.\\n\"These vehicles are easily bought from shops or online and often the people buying them don\\'t know the rules and regulation or indeed the dangers involved\", he said.\\nHe added it was \"vital distributors and sellers make their customers aware of the rules\" or \"one incident could put this growing industry back years.\"'], 'type': 'sts_triplet'}\n",
            "{'query': 'One in five of all children born in a single year in England was referred to social services before they reached age five, research suggests.', 'negatives': [], 'positives': ['A study of children born in 2009-10 suggests up to 150,000 pre-school children were reported over fears of abuse or neglect, most unnecessarily.\\nOnly 25% of referrals were formally investigated while 10% led to protection plans, the study said.\\nThe University of Central Lancashire report said staff were wasting time.\\nThe researchers said while public and professional vigilance was welcome, the number of alerts received by social services meant staff were wasting their time on innocent families, and making it harder to find the children who are at risk.\\nIt follows a series of high profile cases where serious child abuse was missed by social workers.\\nThe researchers used data from Freedom of Information Act requests to 150 councils, with 114 responding.\\nThey found half a million children were born in those areas and 115,735 were referred to social services by last year.\\nWhen that was extrapolated across England, it suggested more than 150,000 children born that year had been brought to the attention of child protection teams by the age of five.\\nThe report said its findings show the full extent of children\\'s involvement in children\\'s social care before the age of five.\\nSocial workers are under intense pressure to make sure they do not miss any child at risk, and end up checking up more of the warnings they receive than is necessary, the research suggests.\\nIt said: \"Whilst some children needed to be protected, there is little evidence to support this scale of statutory involvement or the growing focus on early, and increasingly investigative, interventions alongside increases in removal of children from families into long-term care, special guardianship and adoption.\"\\nLead researcher Professor Andy Bilson said other data showed how much time referrals took up.\\nHe told BBC Radio 4\\'s Today Programme that the majority of these concerns probably were not ones that were founded.\\nOne example of a referral that did not make it beyond an initial assessment included a call from a neighbour who said a father was yelling at his children and might be taking drugs.\\n\"Many of these lead to nothing,\" he said.\\n\"We have this mantra that says it\\'s everybody\\'s job to safeguard children but what we are doing doesn\\'t actually safeguard children.\\n\"Creating these huge numbers of referrals of concern is like creating a huge, extra big haystack in which we are trying to find the needle of the children who are really at risk.\"\\nHe added: \"If you are a parent and someone has logged a complaint about you, it doesn\\'t matter if you aren\\'t formally investigated, you will still feel that you are under threat.\"\\nA Department for Education spokesperson said: \"Ensuring children are safe and well looked after is our top priority - where there are concerns about a child\\'s safety or welfare, it is only right that the appropriate people are informed and where needed, action is taken.\\n\"We have introduced a new Social Care Bill that will continue to reform the care system so that we increase the quality of our social workers and ensure children receive the highest quality care and support.\\n\"We are also enabling councils to look at innovative ways in caring for vulnerable children, backed by Â£100m of government funding.\"'], 'type': 'sts_triplet'}\n",
            "{'query': 'A man convicted of killing Washington intern Chandra Levy has had all charges in his retrial dropped.', 'negatives': [], 'positives': ['The US Attorney\\'s Office said it had dismissed the case against Ingmar Guandique, an El Salvadorean immigrant.\\nMs Levy, 24, had just finished an internship with the US Bureau of Prisons when she disappeared in 2001.\\nHer body was found in a park more than a year later, in a case that generated national headlines and claimed one politician\\'s career.\\nDemocratic politician Gary Condit, to whom Ms Levy was romantically linked, was a suspect in the murder and ended up leaving Congress.\\nAccording to the statement from the attorney\\'s office, the case against Guandique was no longer one that prosecutors could prove beyond a reasonable doubt, due to \"recent unforeseen developments\".\\n\"The government now believes it is in the interests of justice for the court to dismiss the case without prejudice,\" prosecutors wrote.\\nLevy\\'s remains were found in Washington\\'s Rock Creek Park in 2002 and prosecutors had argued at Guandique\\'s trial that he preyed on female joggers.\\nHe was found guilty of her murder in 2010 but granted a new trial last year after Guandique\\'s lawyers successfully argued that a key witness had lied on the stand.\\nThe dismissal of all charges against him means he will now be released to immigration authorities.\\nHe is likely to be deported.'], 'type': 'sts_triplet'}\n",
            "{'query': 'A Texas man who said he wanted to be put to death for killing a couple in 2003 has been executed, after telling his lawyer to drop appeals.', 'negatives': [], 'positives': ['Barney Fuller, 58, pleaded guilty to capital murder for killing his neighbours during a shooting rampage.\\nFuller avoided eye contact in the death chamber with witnesses, including two children of the slain couple.\\nHe blurted out a comment to officials administering the lethal injection and took longer than expected to die.\\nIn a hearing earlier this year, he said he had no challenges to his death sentence and was \"ready to move on\".\\nAsked on Wednesday evening if he had any final statement, Fuller responded: \"I don\\'t have anything to say. You can proceed on, Warden Jones.\"\\nIs the death penalty dying out in the US?\\nFuller took a deep breath as officials injected a lethal dose of pentobarbital into each arm.\\n\"Hey, you fixin\\' to put me to sleep,\" he said.\\nAfter a couple of breaths, Fuller began snoring and all movement stopped within 30 seconds.\\nHe was pronounced dead 38 minutes later, at 19:01 local time, taking longer than expected to die.\\nTexas Department of Criminal Justice spokesman Jason Clark explained the extended time by saying: \"Each person is unique in how his body shuts down.\"\\nFuller\\'s lethal injection was Texas\\' seventh execution this year. The Lone Star state carries out the most executions in the US.\\nHis death marks the longest gap between executions in Texas since 2008, when the US Supreme Court considered whether lethal injection was unconstitutional.\\nHe was arrested and charged 13 years ago for the murder of Nathan Copeland, 43, and his wife, Annette, 39, at their home in Lovelady, about 100 miles north of Houston.\\nHe fired 60 shots into their home before breaking in and opening fire on the couple and their children, injuring their 14-year-old son.\\nThe couple\\'s 10-year-old daughter was able to escape when Fuller could not turn on the light in her bedroom.\\nFuller and the Copelands had a longstanding dispute that culminated when Fuller was summoned to court in 2003 on a charge that he threatened the family.\\nTwo days later, he killed the couple.\\nLast year, Fuller wrote to his attorney saying that he wanted proceed with the execution.\\nDoes a death sentence always mean death?\\n\"But I also really do not care and do not want to go on living in this hellhole,\" he wrote. \"Do not do anything for me which will prolong my appeals and time here on Texas death row.\"\\nAt hearing in the spring, a federal judge ruled Fuller competent to waive his right to appeal.\\n\"What\\'s the point of sentencing someone to death, you know, if you\\'re not going to carry on through with what you ordered,\" he said at the hearing.\\nFuller\\'s execution is the 16th this year in the US.'], 'type': 'sts_triplet'}\n",
            "{'query': 'Scotland\\'s First Minister Nicola Sturgeon said she remained \"frustrated\" with the UK\\'s approach to Brexit.', 'negatives': [], 'positives': ['27 March 2017 Last updated at 18:14 BST\\nShe was speaking after meeting Prime Minister Theresa May in Glasgow for talks ahead of the triggering of Article 50 on Wednesday.\\nMs Sturgeon told BBC Scotland\\'s political editor Brian Taylor: \"I continued to be frustrated by a process that does not appear to be listening, not just to Scotland, but to any of the devolved administrations and I made that point to her [Theresa May].\"'], 'type': 'sts_triplet'}\n",
            "{'query': \"French Socialist Prime Minister Manuel Valls has announced he is standing in next year's presidential election.\", 'negatives': [], 'positives': ['Mr Valls said he wanted to \"give everything for France\". He was speaking days after President Francois Hollande announced he would not be running.\\nMr Valls will face other contenders in the Socialist primary next month.\\nIf successful, he will be set to face Francois Fillon and Marine Le Pen in the first round of the presidential election in April.\\nCurrent polling suggest that Ms Le Pen, leader of the far-right Front National, could come in the top two in the first round, but would be likely to lose to the centre-right Mr Fillon in the second.\\nWho is Manuel Valls?\\nBut Mr Valls, who will resign from his government role on Tuesday, is not guaranteed to win the primary, which will involve at least seven other Socialist candidates.\\nHe is seen as a divisive figure on the left, after forcing labour reforms through parliament and endorsing controversial bans last summer on the Islamic \"burkini\" swimsuit.\\nAnalysts say Mr Valls may be damaged by his close association with Mr Hollande, France\\'s least popular leader in recent history.\\nHowever, he used Monday\\'s speech to call on the left to rally behind him - and against the threat of the far right.\\n\"My candidacy is that of conciliation,\" Mr Valls promised.\\nIf he does become the Socialist candidate, he will be facing a new threat in the form of former Economy Minister Emmanuel Macron, who is standing as a centrist candidate for his newly created party, En Marche.'], 'type': 'sts_triplet'}\n",
            "{'query': 'Republic of Ireland defender Marc Wilson is expected to be out of action for around three months after sustaining a knee injury on Saturday.', 'negatives': [], 'positives': ['Wilson was injured during Stoke City\\'s FA Cup match against Crystal Palace and it could make the 28-year-old a doubt for the Euro 2016 finals in France.\\n\"Marc looks like he has got a bad injury,\" said Stoke boss Mark Hughes.\\n\"The physio thinks he\\'s got medial ligament damage so he is going to be out for a period of maybe 10-12 weeks.\"\\nStoke expect to have a clearer idea on the extent of the injury on Monday.\\nHughes added: \"Marc is down at the moment, which you would expect.\\n\"He is looking forward to the European Championship which is what he wants to be involved in at the end of the season.\\n\"I am not sure if this injury will make him a doubt for that, we hope not.\"'], 'type': 'sts_triplet'}\n",
            "{'query': \"Scotland's publicans have stepped up their war of words with one of the world's big brewers over its plans to take over a large chain of British pubs.\", 'negatives': [], 'positives': ['Heineken is being strongly criticised by the Scottish Licensed Trade Association (SLTA) for its plans to buy Punch Taverns.\\nThe sale would increase Heineken\\'s ownership of pubs from 2% of the Scottish total to 6%. Although it would increase its market share of beer sales, the Netherlands-based brewer points to a much larger share for Tennent\\'s owner C&C.\\nThe SLTA\\'s chief executive, Paul Waterson, claimed Heineken has \"little regard for local relationships\", alleging that its investments had been in \"up-market, city centre\" bars, and that it was not committed to supporting smaller, community-based pubs.\\nHe also claimed Heineken, with brands including Amstel, Sol and Strongbow cider, would stifle drinkers\\' options on which brands of beers and other drinks were available.\\nHeineken already has 1,100 British pubs, including some it bought when it took over part of Scottish & Newcastle in 2008.\\nLast month, it won a brief bidding battle for the 3,300 pubs in the Punch Tavern chain in a joint £400m bid with real estate specialist Patron Capital private equity. They intend to divide up the portfolio.\\nThe Scottish publicans\\' association said tied pubs - those owned and leased by brewing firms - suffered from skewed investment and financial restrictions.\\n\"Our greatest concern are the barriers that Heineken will put in place when it comes to other brewers,\" said Mr Waterson. \"This will have a disastrous effect on consumer choice.\\n\"Quoted as saying, \\'no-one expects to buy Costa when in Starbucks\\', they will impose 85% of their own products in Punch pubs, at least, leaving little room for others,\" the SLTA boss claimed.\\n\"That\\'s hardly working with licensees to ensure they have the right drinks offer to suit the specific needs of each pub. The framework is clear, and it\\'s restrictive, anti-competitive and will disadvantage our own home-grown producers.\"\\nThe comments follow an exchange between the brewing giant and the SLTA, following the announcement late last year of the Punch Taverns deal.\\nAfter the landlords expressed their initial \"grave concerns,\" a response was published by the managing director of Heineken Star Pubs and Bars, Lawson Mountstevens.\\nHe wrote: \"Heineken has a long track record of working with entrepreneurial licensees who know that success comes from providing a consistently excellent experience for customers. In 2016, we committed a further £2 million of investment for our Scottish pubs, adding to the £5m we have spent over the last three years.\\n\"The scale and scope of our refurbishments have helped to ensure that licensees can significantly improve their food offer, with new kitchens and flexible areas within pubs to cater for a wider range of events.\\n\"With our pubs better equipped to meet changing consumer needs, they are also generating multiple income streams for our licensees.\"\\nThe boss of the pub division continued his response: \"Rather than \\'de-stabilise our fragile industry\\', we hope to bring our passion, expertise and successful operating model to more Scottish pubs.\\n\"When it comes to consumer choice, Heineken\\'s market share in Scotland\\'s pubs is less than half that of the largest producer, C&C Group. We have consistently said that we start with what is right for each pub, and we will work with licensees to ensure they have the right drinks offer to suit the specific needs of each pub.\"'], 'type': 'sts_triplet'}\n",
            "{'query': 'For reasons I find somewhat difficult to explain, I have never been a huge fan of the movie, \"The Wizard of Oz\".', 'negatives': [], 'positives': ['I mean, it\\'s not as though I entirely revile fantasy narratives.  When younger, I roamed happily through Gormenghast and Middle Earth.\\nAnd yet the tale of Dorothy tends to leave me cold or puzzled or both.  Not so, it seems, Nick Clegg - he who would be kingmaker-in-chief for the next Westminster Parliament.\\nClearly delving into Oz imagery, Mr Clegg said that he would provide the Tories with a heart and Labour with a brain.  Which, of course, only leaves courage.  Who, one wonders, will supply that to our tribunes?\\nPolls continue to suggest that the Liberal Democrats will be decidedly fortunate to hold what they have, especially in terms of Scottish seats.\\nGiven that, it is understandable that Mr Clegg\\'s pitch was one of political realism.  He knows he is not going to be Prime Minister.  That honour would fall to David Cameron or to Ed Miliband.\\nMr Clegg\\'s role would be to act as guiding shepherd, shunning what he characterised as the borrowing excesses of Labour on the one hand and the zeal for spending cuts of the Tories on the other.\\nA more apposite metaphor for Mr Clegg\\'s approach might be to see him as Cerberus, the ferocious janny of Hades, energetically supervising ingress.  (You think Cerberus is tough:  you should have seen the janitor at my primary school in Dundee……)\\nCertainly, he will need a multi-headed approach to achieve the various defensive objectives he has set himself.\\nBeyond steering Labour and the Tories, he says the Lib Dems will prevent Alex Salmond from wielding any influence on UK governance and will keep Nigel Farage remote from Downing Street.\\nWhy Alex Salmond, rather than Nicola Sturgeon?  Because, Mr Clegg explained, he is the potential MP, not her.\\nOther possible reasons?  Mr Salmond is challenging the Lib Dems in one of their Scottish seats.  And Ms Sturgeon seemingly won chums in England with her debate performance, leaving her an unlikely hate figure.\\nIn essence, then, he is offering a coalition or a confidence and supply deal with either the Tories or Labour - pre-empting the need for them to rely upon the SNP or UKIP.\\nIt is, by definition, a limited ambition - driven by recent history and those polls.\\nAnd the offer?  The LibDems have deliberately narrowed their core pitch.  Increase the personal tax allowance to £12,500 - trying to garner credit for a further amplification of a policy they drove in the coalition with the Tories.\\nSpend more on education and the NHS in England, with comparable increases in Scotland.\\nComparable importance attached to mental and physical health.  Protect the environment with new green laws.  Balance the structural deficit in the current budget - current, note - by 2017/18.\\nAnd West Lothian?  The Lib Dems back the planned new powers for Holyrood.  Like the Tories, they favour an English only stage to Commons consideration of matters which solely affect England.\\nHowever, the Lib Dems say the entire UK constitution needs consideration by a convention.\\nUKIP, who also launched their manifesto today, would probably regard such consultation as unwarranted dithering.  They favour English Votes on English Laws, full stop.\\nThey are equally blunt on the European Union.  It is a bad thing: there should be an early referendum with the objective of taking Britain out.\\nOn immigration, they favour curbs.  And they are, similarly, less than enthusiastic about the Barnett Formula which varies annually the amount of public spending devoted to Scotland, by comparison with comparable English spending departments.\\nUKIP would dump it, seeking thus to relieve Scotland of billions of pounds.  Other parties, they say, are too worried about upsetting the Scots.  UKIP are, seemingly, sanguine about Caledonian ire.\\nTheir manifesto, of course, contains much more.  Low taxation.  More money for the NHS in England.  A boost for defence spending.\\nTheir leader Nigel Farage previously said that his party\\'s manifesto for 2010 was \"drivel\".\\nTo be clear, Mr Farage was not responsible for that.\\nLaunching the new version, he said UKIP had changed immeasurably from the party of five years back.  This election will presumably reflect how much voters appreciate that.'], 'type': 'sts_triplet'}\n",
            "{'query': \"Attackers have set alight the office of one of the few human rights groups active in Chechnya after it criticised the Russian republic's president.\", 'negatives': [], 'positives': ['They attacked the Joint Mobile Group (JMG) office in the Chechen capital, Grozny, on Saturday evening.\\nNobody was hurt but there are concerns over the safety of two activists.\\nThe JMG had criticised Ramzan Kadyrov after he called for collective punishment of the families of rebels behind a recent attack in Grozny.\\nIslamist rebels launched an assault on the city on 4 December, killing 14 police officers. Nine militants also died.\\nIn the wake of that attack Kadyrov called for relatives of the militants to be punished. Not long afterwards masked men burnt down homes in the village of Yandi.\\nJMG founder Igor Kalyapin formally complained in Moscow last week about Mr Kadyrov, after which the Kremlin-backed leader publicly accused the NGO official of \"backing criminals\".\\nA demonstration was held on Saturday in Grozny against the human rights group, after which armed men tried unsuccessfully to enter its office before setting it on fire.\\nThe extent of the damage to JMG\\'s office is unclear.\\nVideo published by Russian independent newspaper Novaya Gazeta shows a fire engine outside a four-storey building, which does not look seriously damaged.\\nThe two activists, Dmitry Dimitriyev and Sergei Babinets, reportedly called police to their flat on Sunday to make a complaint about the arson attack in the office next door.\\nInstead, the police searched the two men and confiscated their laptops, cameras and phones, Mr Kalyapin wrote on Facebook (in Russian).\\nTheir phones were later returned but when Mr Dimitriyev tried to leave the building he was physically prevented from doing so, the JMG founder added.\\nA Chechen police source denied harassing the JMG staff, accusing them of spreading misinformation.\\nHe told Russia\\'s Interfax news agency the fire was accidental.\\nJMG is part of Russia\\'s Committee Against Torture, a non-governmental organisation which has been active for 14 years and largely relies on foreign grants for its investigations.'], 'type': 'sts_triplet'}\n",
            "{'query': 'Two months ago, Canadian Liberal leader Justin Trudeau won in a dramatic election that unseated Conservative Stephen Harper after nearly a decade as prime minister.', 'negatives': [], 'positives': ['The son of former Canadian Prime Minister Pierre Trudeau promised \"sunny ways\" for Canadians during his victory speech.\\nHe has had a busy first 10 weeks in office:\\nWe spoke to three Canadian pundits about how Mr Trudeau and his Liberal government is doing so far.\\n\"So far, so good. But also, so far, he hasn\\'t really been tested. A year from now, we can make a proper assessment.\"\\nShe recently participated in a town hall discussion with Mr Trudeau.\\n\"He said it was very important for him to be outside the bubble of Ottawa,\" said Ms Giese. \"He said it\\'s not good for a leader to be stuck talking to other politicians.\"\\nHe\\'s established very quickly out of the gate that his government is going to look very different\\nMs Giese said this attitude is starkly different from the \"tightly-controlled\" image of Mr Harper.\\nHe knows a lot about symbolism and image and knows how to take advantage of social media and understanding pop culture, perhaps taking a cue from US President Barack Obama, she said.\\nSymbolism is one thing, but substance is another. Has Mr Trudeau kept his campaign promises?\\n\"I think he\\'s done a couple of things of real substance, and a couple of things about the style and tone of government going forward,\" she said. \"He\\'s established very quickly out of the gate that his government will look very different.\"\\nMr Trudeau is certainly ambitious, and so critics are wondering if he can deliver.\\nThere are concerns about the economy, the Canadian dollar is in bad shape, oil prices are low and Canada is seeing a lot of household debt, said Ms Giese.\\nHis decision to withdraw fighter jets from Syria some time this year has drawn some scorn, too, especially after the Paris terrorist attacks carried out by the so-called Islamic State which killed scores of people.\\nThe scaling back of the Liberal government\\'s promise to bring 25,000 refugees to Canada by the end of 2015 disappointed some as well.\\n\"It was a hard goal to achieve when he suggested it… and in a strange awful kind of way, the attacks allowed [Mr Trudeau] to scale back a very ambitious plan without taking a lot of heat,\" she said.\\n\"Justin Trudeau is going to be on a long political honeymoon,\" he said.\\nMr Trudeau has done more interviews in the last two months than other politicians had done in years, he said.\\nHe has made his entire cabinet available publicly available and made their mandate letters, which detail policy objectives, open to read to the public.\\n\"His agenda is probably the most ambitious we\\'ve seen in generations,\" said Mr Solomon. \"He\\'s stored up an enormous amount of political capital to get this agenda done… it\\'s going to be more complicated than saying good words.\"\\nThe first evidence of that has been the scaling back of the refugee intake, but Mr Trudeau\\'s greeting of refugees at the airport in Toronto was \"not insignificant\", he said.\\nWe haven\\'t heard him say no yet. It\\'s too early to be cynical, but it\\'s not too early to be sceptical\\n\"That was a very powerful image, and the Trudeau government understands how powerfully resonant this kind of image is. That\\'s soft power,\" he said. \"The problem is, when you look under the hood, it\\'s a little less effective.\"\\nLiberals have been \"all over the map\" on promises to end combat missions in Iraq and Syria, he said.\\nThe Trudeau government has also promptly accepted all 94 recommendations from the Truth and Reconciliation Commission, formed in response to \"cultural genocide\" committed by the Canadian government in which aboriginal children were taken from their homes and sent to government-run Christian schools.\\n\"There are fundamental, complex legal issues in the recommendations,\" he said. \"How he will do it, I don\\'t know.\"\\nMr Solomon predicts revenue will prove to be the most pressing challenge for Mr Trudeau.\\n\"When his finance minister puts out the first budget, we will know the difference between rhetoric and reality… We haven\\'t heard him say no yet. It\\'s too early to be cynical, but it\\'s not too early to be sceptical.\"\\nMr Solomon hosts Everything is Political on SiriusXM satellite radio.\\nThe Institute for Research on Public Policy in Canada recently conducted a survey of 1,000 Canadians, finding that Canadians are largely feeling positive about their government and country since Mr Trudeau took office.\\n\"The economy is weak, the price of oil has collapsed and the loonie is doing a swan dive, but Canadians are remarkably happy with the performance of the federal government,\" a release from the organisation says.\\nSixty percent of those surveyed last month rated the Liberal government\\'s performance so far good or very good, a record for the nine years the survey has been conducted. The closest Mr Harper\\'s government ever came in the same survey was 40% in 2011.\\nThe country is \"moving in the right direction\", 63% said, and a little more than half surveyed said federal provincial relations have improved under Mr Trudeau.\\n\"For him, it\\'s almost like the campaigning has not stopped, but now he is campaigning as prime minister,\" said Mr Nanos.\\nFor him, it\\'s almost like the campaigning has not stopped, but now he is campaigning as prime minister\\nThe prime minister\\'s biggest challenge will be sticking to his promise of running the government on a $10b (£4b) deficit, he said.\\nBecause his administration has been so transparent, Canadians are accepting him running the government on a deficit, but if the deficit goes beyond that number, it \"could be a political risk\".\\n\"I would expect that his political honeymoon will probably continue until the federal budget is tabled in the spring,\" said Mr Nanos.\\nDespite a decrease in the number of Syrian refugees arriving in the country from what was promised, Mr Trudeau is \"looking even better\" to Canadians because of the unwelcoming rhetoric of US politicians on the topic, such as Donald Trump.\\n\"He has the ability to grab people\\'s attention, and he\\'s using that to engage Canadians in politics on the environment and social justice and so forth,\" said Mr Nanos.\\n\"What\\'s interesting is how he\\'s using his star power to advance his political agenda for the country. He\\'s not like a politician that we\\'ve seen before.\"\\nInterviews conducted by Ashley Gold'], 'type': 'sts_triplet'}\n"
          ]
        }
      ],
      "source": [
        "for i,e in enumerate(sts_statics_datsets['train']):\n",
        "  if i>20:\n",
        "    break\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p9YPJwhkt3h",
        "outputId": "c0ce8e39-ad09-488e-b1f4-6c657295cd50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from multiprocessing import Pool\n",
        "# Download stopwords and lemmatization resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "#lemmatizer = WordNetLemmatizer()\n",
        "#stemmer = PorterStemmer()\n",
        "#stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LLn5zFf0i2E"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LabelProcesser:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pos_thres = 0.97,\n",
        "        neg_thres = 0.9,\n",
        "        min_similarity_matrix_pos =0.34,\n",
        "        max_similarity_matrix_pos = 0.30,\n",
        "        examples=None, seed=42, textname='text',labelname='label'\n",
        "    ):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this\n",
        "        #self.lemmatizer = WordNetLemmatizer()\n",
        "        #self.stemmer = PorterStemmer()\n",
        "        #self.stop_words = set(stopwords.words('english'))\n",
        "        #self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def jaccard_similarity(tokens1, tokens2):\n",
        "        set1 = set(tokens1)\n",
        "        set2 = set(tokens2)\n",
        "        intersection = set1.intersection(set2)\n",
        "        union = set1.union(set2)\n",
        "        similarity_score = len(intersection) / len(union)\n",
        "        return similarity_score\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _compute_similarity_for_processor_func(self, pair):\n",
        "        \"\"\"to be used internally with Pool map similarity functions\"\"\"\n",
        "        idx, j, tokens1, tokens2 = pair\n",
        "        return idx, j, self.jaccard_similarity(tokens1, tokens2)\n",
        "\n",
        "    def compute_similarity_matrix(self, corpus):\n",
        "        \"\"\"Csompute similarity using calculate_similarity\"\"\"\n",
        "        corpus_size = len(corpus)\n",
        "\n",
        "        # Create an empty similarity matrix\n",
        "        similarity_matrix = np.zeros((corpus_size, corpus_size))\n",
        "\n",
        "        # Generate all pairwise combinations of indices and texts\n",
        "        pairs = [(i, j, corpus[i], corpus[j]) for i in range(corpus_size) for j in range(i + 1, corpus_size)]\n",
        "\n",
        "        # Use parallel processing to compute similarities efficiently\n",
        "        with Pool() as pool:\n",
        "            results = pool.map(self._compute_similarity_for_processor_func, pairs)\n",
        "\n",
        "        # Fill in the similarity matrix\n",
        "        for i,j, similarity in results:\n",
        "            #i, j = divmod(idx, corpus_size)\n",
        "            similarity_matrix[i, j] = similarity\n",
        "            similarity_matrix[j, i] = similarity\n",
        "\n",
        "        # threshold the similarity matrx -- no, because that will creat positives in the negatives\n",
        "        return similarity_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def is_in(tuple1, tuple2):\n",
        "        \"\"\"is a in b or b in a\"\"\"\n",
        "        s1=set(tuple1); s2 = set(tuple2)\n",
        "        if not bool(s1.difference(s2)):\n",
        "            return True\n",
        "        return not bool(s2.difference(s1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _quick_text_hash(text):\n",
        "        return re.sub(\"\\W+\",\"\",text.lower())\n",
        "\n",
        "    def find_positive(\n",
        "        self,\n",
        "        query_text, # text of anchor/query (used to ensure not too similar, like an exact match)\n",
        "        query_labelstem, # processed label (often a multi-label)\n",
        "        corpus_keys, # corpus keys of other labels to find matches\n",
        "        max_candidates=15\n",
        "    ):\n",
        "        \"\"\"find positive match, based on best overlap of multi-label\"\"\"\n",
        "        # first, check if there are other text with same label\n",
        "        query_label_hash = self._quick_text_hash(query_text)\n",
        "\n",
        "        # get all text with same label\n",
        "        best_candidates_text = [\n",
        "            s for s in self.label_corpus[query_labelstem] if self._quick_text_hash(s)!=query_label_hash\n",
        "        ]\n",
        "        if len(best_candidates_text)==0:\n",
        "            # no similar text: need to find text with overlapping labelss\n",
        "            kidx = corpus_keys.index(query_labelstem)\n",
        "            # get similarities with other keys\n",
        "            k_similarities = self.SimMat[kidx]\n",
        "            if k_similarities.max()==0:\n",
        "                #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                return []\n",
        "            else:\n",
        "                idx_bests = np.argsort(-1*k_similarities)[:max_candidates]\n",
        "                # get most similar labels\n",
        "                label_candidates = [\n",
        "                    corpus_keys[j] for j in idx_bests if k_similarities[j]>= self.min_similarity_matrix\n",
        "                ]\n",
        "                # assert that the labels are AT LEAST inside of each other -- otherwise, no match\n",
        "                label_candidates = [\n",
        "                    lab for lab in label_candidates if self.is_in(lab, query_labelstem)\n",
        "                ]\n",
        "                if len(label_candidates)==0:\n",
        "                    #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                    return []\n",
        "\n",
        "                # get the text of the top candidate text\n",
        "                best_candidates_text = [subs for s in [\n",
        "                    self.label_corpus[lab] for lab in label_candidates\n",
        "                ] for subs in s][:100]\n",
        "\n",
        "                # ensure candidate texts are not the same\n",
        "                best_candidates_text = [\n",
        "                  s for s in self.label_corpus[query_labelstem] if self._quick_text_hash(s)!=query_label_hash\n",
        "                ]\n",
        "                if len(best_candidates_text)==0:\n",
        "                    #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                    return []\n",
        "\n",
        "        # grab first candidate text htat is NOT a high jaccard similarity\n",
        "        best_candidates_text = best_candidates_text[::-1]\n",
        "        top_match = None\n",
        "        query_text_tokenized = [w for w in query_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "        while top_match is None and len(best_candidates_text)>0:\n",
        "            candidate_text = best_candidates_text.pop()\n",
        "            # check that they aren't too similar in text\n",
        "            candidate_text_tokenized = [w for w in candidate_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "            candidate_sim_score = self.jaccard_similarity(query_text_tokenized, candidate_text_tokenized)\n",
        "            if candidate_sim_score < self.pos_thres:\n",
        "                top_match = candidate_text\n",
        "                return [top_match]\n",
        "        #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "        #print('Its candidate pool was:')\n",
        "        #print(best_candidates_text[:4])\n",
        "        return []\n",
        "\n",
        "    def find_positives(self, examples):\n",
        "        if True:\n",
        "            # find positives\n",
        "            for idx, example in enumerate(examples):\n",
        "                pos = self.find_positive(\n",
        "                    query_text=example[self.textname],\n",
        "                    query_labelstem=self.label2stem[tuple(example[self.labelname])],\n",
        "                    corpus_keys = list(self.label_corpus.keys()),\n",
        "                )\n",
        "                example.update({'positives':pos})\n",
        "                examples[idx] = example\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def find_negative(self, query_text, query_labelstem, corpus_keys, max_candidates=15, n_negatives=1):\n",
        "        # first, check if there are other text with same label\n",
        "        query_label_hash = self._quick_text_hash(query_text)\n",
        "        # get similarities with other keys\n",
        "        kidx = corpus_keys.index(query_labelstem)\n",
        "        k_similarities = self.SimMat[kidx]\n",
        "        if k_similarities.max()==0:\n",
        "            best_candidate_label = query_labelstem\n",
        "            while best_candidate_label == query_labelstem:\n",
        "                best_candidate_label = self.random.choice(corpus_keys)\n",
        "        else:\n",
        "            idx_bests = np.argsort(-1*k_similarities)[:max_candidates]\n",
        "            # get most similar labels\n",
        "            label_candidates = [\n",
        "                corpus_keys[j] for j in idx_bests if (k_similarities[j]!=0 and k_similarities[j] <= self.max_similarity_matrix)\n",
        "            ]\n",
        "            # assert that the labels have some disjoint labels\n",
        "            label_candidates = [\n",
        "                lab for lab in label_candidates if not self.is_in(lab, query_labelstem)\n",
        "            ] # disjoint entirely\n",
        "            # sample randomly from candidate labels\n",
        "            if len(label_candidates)>0:\n",
        "                best_candidate_label_idx = self.random.choice(np.arange(len(label_candidates)))\n",
        "                best_candidate_label = label_candidates[best_candidate_label_idx]\n",
        "            # sample randomly from entire corpus\n",
        "            elif len(label_candidates)==0:\n",
        "                # pick random\n",
        "                best_candidate_label = query_labelstem\n",
        "                while best_candidate_label == query_labelstem:\n",
        "                    best_candidate_label_idx = self.random.choice(np.arange(len(corpus_keys)))\n",
        "                    best_candidate_label = corpus_keys[best_candidate_label_idx]\n",
        "\n",
        "        # grab best text\n",
        "        best_candidates_text = self.label_corpus[best_candidate_label]\n",
        "        if len(best_candidates_text)==0:\n",
        "            return []\n",
        "\n",
        "        # ensure texts and query are not the same\n",
        "        best_candidates_text = [\n",
        "            s for s in best_candidates_text if self._quick_text_hash(s)!=query_label_hash\n",
        "        ]\n",
        "        if len(best_candidates_text)==0:\n",
        "            return []\n",
        "\n",
        "        # ensure texts are not very similar\n",
        "        top_matches = []\n",
        "        query_text_tokenized = [w for w in query_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "        while len(top_matches) < n_negatives and len(best_candidates_text)>0:\n",
        "            candidate_text = best_candidates_text.pop()\n",
        "            # check that they aren't too similar in text\n",
        "            candidate_text_tokenized = [w for w in candidate_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "            candidate_sim_score = self.jaccard_similarity(query_text_tokenized, candidate_text_tokenized)\n",
        "            if candidate_sim_score < self.neg_thres:\n",
        "                top_matches.append(candidate_text)\n",
        "                if len(top_matches)==n_negatives:\n",
        "                    return top_matches\n",
        "        # no matches\n",
        "        return []\n",
        "\n",
        "    def find_negatives(self, examples, n_negatives=1):\n",
        "        if True:\n",
        "            # find negatives\n",
        "            for idx, example in enumerate(examples):\n",
        "                neg = self.find_negative(\n",
        "                    query_text=example[self.textname],\n",
        "                    query_labelstem=self.label2stem[tuple(example[self.labelname])],\n",
        "                    corpus_keys = list(self.label_corpus.keys()),\n",
        "                    n_negatives=1\n",
        "                )\n",
        "                example.update({'negatives':neg})\n",
        "                examples[idx] = example\n",
        "\n",
        "        return examples\n",
        "\n",
        "\n",
        "class LabelProcesserLedgar(LabelProcesser):\n",
        "    \"\"\"Preprocesses labels of LEDGAR for semantic similarity, as well as functionality for finding positive and negative pairs\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pos_thres = 0.97,\n",
        "        neg_thres = 0.9,\n",
        "        min_similarity_matrix_pos =0.33,\n",
        "        max_similarity_matrix_neg=0.3,\n",
        "        examples=None,\n",
        "        seed=42,\n",
        "        textname='text',\n",
        "        labelname='label'\n",
        "    ):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this, else 0\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "        #print(self.preprocess_label(\"The Borrowers’ obligation\"))\n",
        "        #print(self.preprocess_label(\"The Borrower's obligations\"))\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        if isinstance(text,str):\n",
        "            tokens = word_tokenize(text.lower())\n",
        "            # Remove stop words\n",
        "            filtered_tokens = [token for token in tokens if token not in self.stop_words]\n",
        "            # Perform lemmatization and stemming\n",
        "            processed_tokens = [self.lemmatizer.lemmatize(self.stemmer.stem(token)) for token in filtered_tokens]\n",
        "            processed_tokens = [w for w in processed_tokens if w not in [\"'\", \"’\", \"’s\", \"'s\", \"(\",\")\", \",\", \".\"]]\n",
        "            # Return the lemmatized and stop word-free tokens as a string\n",
        "            return sorted(processed_tokens)\n",
        "\n",
        "        elif isinstance(text,list):\n",
        "            if len(text)==1:\n",
        "                return self.preprocess_label(text[0])\n",
        "            all_labels = [self.preprocess_label(l) for l in text]\n",
        "            return sorted([subl for l in all_labels for subl in l])\n",
        "        else:\n",
        "            raise NotImplementedError(text)\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        label_corpus = {}\n",
        "        label2lem = {}\n",
        "        for example in list_of_dict_with_labels_and_text:\n",
        "            label = example[self.labelname]\n",
        "            s = example[self.textname]\n",
        "            if tuple(label) not in label2lem:\n",
        "                labelstemmed = tuple(self.preprocess_label(label))\n",
        "                label2lem[tuple(label)] = labelstemmed\n",
        "            else:\n",
        "                labelstemmed = label2lem[tuple(label)]\n",
        "            if labelstemmed not in label_corpus.keys():\n",
        "                label_corpus[labelstemmed] = []\n",
        "            if s not in label_corpus[labelstemmed]:\n",
        "                label_corpus[labelstemmed].append(s)\n",
        "\n",
        "        # next, calculate the similarities between all pairs of keys\n",
        "        return label_corpus, label2lem\n",
        "\n",
        "\n",
        "class DatasetTripletsSimilarityByCoLabel(DatasetTriplets):\n",
        "\n",
        "    def process(self, list_of_data):\n",
        "        \"\"\"Makes (query,pos,neg)-triplets, converts samples to dataframe for pytorch iteration\"\"\"\n",
        "\n",
        "        # initialize the LabelProcessor\n",
        "        label_processor = self.label_processor_class(\n",
        "            examples = list_of_data,\n",
        "            textname = self.focal_text_name\n",
        "        )\n",
        "\n",
        "        # find positives\n",
        "        list_of_data = label_processor.find_positives(list_of_data)\n",
        "\n",
        "        # only do ones with positives (otherwise no point)\n",
        "        #list_of_data = [example for example in list_of_data if len(example['positives'])>0]\n",
        "        #print(len(list_of_data))\n",
        "\n",
        "        # find negatives\n",
        "        list_of_data = label_processor.find_negatives(list_of_data, n_negatives=self.n_negatives)\n",
        "        print(len(list_of_data))\n",
        "\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(list_of_data = list_of_data)\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        df = self.sample_data_and_make_static_dataframe(self.data)\n",
        "        return df #pd.DataFrame({})\n",
        "\n",
        "    def _build_corpus_of_potential_negatives(self):\n",
        "        pass\n",
        "\n",
        "    def _find_negative(self):\n",
        "        pass\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"For data that has a label, this can be used to artifically find and create synthetic positives\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "       pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rw5n61iayhm",
        "outputId": "4d83ea72-e846-47d3-efd1-dea5cafc9305"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': \"A man who tried to cut the throat of his estranged wife's aunt has been jailed for 22 years.\",\n",
              " 'negatives': [],\n",
              " 'positives': ['Farai Kambarani, 26, was convicted of the attempted murder of social worker Ruth Nayamazana, who he wrongly blamed for not letting him see his child.\\nLuton Crown Court heard his victim, who he also punched in the head 10 to 20 times, still lives in fear.\\nKambarani was given a 22-year jail sentence with a three-year extension on licence.\\nThe court heard Kambarani, from Wolverhampton, shunted a car into the back of Ruth Nayamazana\\'s vehicle in Saxon Gate car park in Milton Keynes on 22 August last year.\\nWhen she got out, he repeatedly punched her in the head.\\nIn the witness box, the 34-year-old said he pulled out a small knife and used it against the side of her throat.\\nShe said: \"I was screaming. I thought he was going to cut my throat. The blood started gushing out.\"\\nKambarani, a former carer for elderly people, was also convicted criminal damage and stalking his former partner.\\nThe court heard Kambarani fled to the UK from Zimbabwe in November 2014 after being arrested and tortured. He began a relationship with another woman in Wolverhampton.\\nLater his wife and child moved to the UK. In June last year, he became angry when she moved in with her uncle and his wife in Milton Keynes.\\nSebastian Gardiner, defending, said: \"Fortunately, her life was not endangered. She spent three days in hospital and made a full recovery.\"\\nHe accepted the attack had caused serious psychological difficulties for the victim.\\nJudge Philip Bartle said: \"You became fixated with Ruth and saw her as an obstacle to you seeing your daughter. There was no justification for that.\"'],\n",
              " 'type': 'sts_triplet'}"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sts_statics_datsets['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhnPR4rraJV5"
      },
      "outputs": [],
      "source": [
        "class LabelProcesserEurlex(LabelProcesser):\n",
        "    \"\"\"Preprocesses labels of EURLEX for semantic similarity, as well as functionality for finding positive and negative pairs\"\"\"\n",
        "\n",
        "    def __init__(self, pos_thres = 0.97, neg_thres = 0.9, min_similarity_matrix_pos =0.33, max_similarity_matrix_neg =0.30,  examples=None, seed=42, textname='text',labelname='label'):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this, else 0\n",
        "        self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "        #print(self.preprocess_label(\"The Borrowers’ obligation\"))\n",
        "        #print(self.preprocess_label(\"The Borrower's obligations\"))\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        # eurlex labels are already \"tokenized\" into integers of concepts\n",
        "        if isinstance(text,str):\n",
        "            return text\n",
        "        elif isinstance(text,list):\n",
        "            if len(text)==1:\n",
        "                return text\n",
        "            return sorted(list(set(text)))\n",
        "        else:\n",
        "            raise NotImplementedError(text)\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        label_corpus = {}\n",
        "        label2lem = {}\n",
        "        for example in list_of_dict_with_labels_and_text:\n",
        "            label = example[self.labelname]\n",
        "            s = example[self.textname]\n",
        "            if tuple(label) not in label2lem:\n",
        "                labelstemmed = tuple(self.preprocess_label(label))\n",
        "                label2lem[tuple(label)] = labelstemmed\n",
        "            else:\n",
        "                labelstemmed = label2lem[tuple(label)]\n",
        "            if labelstemmed not in label_corpus.keys():\n",
        "                label_corpus[labelstemmed] = []\n",
        "            if s not in label_corpus[labelstemmed]:\n",
        "                label_corpus[labelstemmed].append(s)\n",
        "\n",
        "        # next, calculate the similarities between all pairs of keys\n",
        "        return label_corpus, label2lem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuLbI2CLakZh"
      },
      "outputs": [],
      "source": [
        "sts_statics_datsets['train'][0]\n",
        "\n",
        "label_processer_eurlex = LabelProcesserEurlex(\n",
        "    pos_thres = 0.97,\n",
        "    neg_thres = 0.9,\n",
        "    min_similarity_matrix_pos =0.33,\n",
        "    examples=sts_statics_datsets['train'],\n",
        "    seed=42,\n",
        "    textname='query',\n",
        "    labelname='label'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owGqWwzDW0q5"
      },
      "outputs": [],
      "source": [
        "sts_statics_datsets['train'] = label_processer_eurlex.find_positives(sts_statics_datsets['train'])\n",
        "\n",
        "sts_statics_datsets['train'] = label_processer_eurlex.find_negatives(sts_statics_datsets['train'], n_negatives=3)\n",
        "#print(len(list_of_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWrPGhgneRiN"
      },
      "outputs": [],
      "source": [
        "foo = [e for e in sts_statics_datsets['train'] if bool(e['positives'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q9NBIBYey4K",
        "outputId": "ab5276cf-5abf-40d3-86ce-d376f93a2932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-52-01dc088b8e40>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        }
      ],
      "source": [
        "sts_torchdataset_train_eurlex = DatasetTripletsSimilarityByCoLabel(\n",
        "    list_of_data=[\n",
        "        example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    seed = 42,\n",
        "    label_processor_class = LabelProcesserEurlex\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNoFf6aTUiuQ",
        "outputId": "e20ab990-2e8d-45a9-f0d3-5cd2caad3901"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-58-c010377498b5>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "sts_torchdataset_train_ledgar = DatasetTripletsSimilarityByCoLabel(\n",
        "    list_of_data=[\n",
        "        example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    seed = 42,\n",
        "    label_processor_class = LabelProcesserLedgar\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z6vZNuhaWyf",
        "outputId": "1a21d46f-e22d-40b0-87bf-5f2454f4bc32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Seller has not received any written notice of any pending or threatened condemnation of any portion of the Properties.',\n",
              " 'pos': 'If the whole or any substantial (more than 25%) part of the Premises shall be condemned by eminent domain for any public or quasi-public purpose, this Lease shall terminate on the date of the vesting of title, and Tenant shall have no claim against Landlord for the value of any unexpired portion of the term of the Lease, nor shall Tenant be entitled to any part of the condemnation award. If less than a substantial part of the Premises is condemned, this Lease shall not terminate, but Rent shall abate in proportion to the portion of the Premises condemned.',\n",
              " 'neg': \"Tenant has inspected the Premises prior to entering this Lease and hereby accepts the Premises in its “As Is” condition. Landlord shall keep the foundation, outer walls, roof and buried conduits of the Premises in good repair except the Landlord shall not be called on to make any such repairs occasioned by the negligence of the Tenant, its agents, invitees or employees. Tenant shall at Tenant’s sole cost and expense take good care of and maintain in a good condition the Premises and the fixtures, equipment and furnishings therein, and make all repairs necessary to keep them clean, in good working order and condition. It is Tenant's sole responsibility to maintain, repair and replace, whether interior or exterior, all glass and doors in or on the Premises. The heating and air conditioning system shall be under the control of Tenant and Tenant agrees that all operation and upkeep will be at Tenant's expense. Landlord shall be under no obligation, however, to bring any action or proceeding against its insurer or warrantor should the insurer or warrantor deny that such repair or replacement falls within the insurance or warranty coverage, in which event Tenant shall pay the costs of the repair or replacement. Should the repair or replacement be made by Landlord’s warrantor or insurer, Tenant shall pay upon demand to Landlord any deductible or other cost Landlord incurs for such repair or replacement. During the term of this Lease and any extension thereof, Tenant shall enter into and maintain a service agreement with a licensed air-conditioning contractor, providing routine maintenance to the air conditioning equipment. A copy of this maintenance agreement shall be provided to Landlord within thirty (30) days after the commencement of the term of this Lease. Provided Tenant maintains the service agreement with a licensed air conditioning contractor, Landlord shall be responsible for the major repair or replacement of the HVAC system provided such replacement was not caused by Tenant’s negligence. Landlord shall have the right, but not the obligation, to make repairs necessitated by the fault or negligence of Tenant, or that of Tenant's agents, employees, contractors, consultants or invitees, and Tenant shall immediately reimburse Landlord for all expenses and costs for such repairs upon demand of Landlord. Tenant shall not make any alterations, additions or improvements to the Premises without the prior written consent of the Landlord.\"}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sts_torchdataset_train_eurlex[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15D5Lf1Xp7tF"
      },
      "outputs": [],
      "source": [
        "for example in sts_statics_datsets['train']:\n",
        "    if example['type']=='sts_by_textlabel':\n",
        "        assert 'label' in example.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA27NcTqDNvL",
        "outputId": "efedfd24-fb0a-4959-ece3-c8c98b8d9f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['borrow', 'oblig']\n",
            "['borrow', 'oblig']\n",
            "0.4376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-1451465b933c>:204: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "labelprocessor = LabelProcesserLedgar(examples = [\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "foopos = labelprocessor.find_positives([\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "print(sum([bool(d['positives']) for d in foopos])/len(foopos))\n",
        "\n",
        "fooneg = labelprocessor.find_negatives([\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "print(sum([bool(d['negatives']) for d in fooneg])/len(fooneg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAP4wenTovCw",
        "outputId": "c1806b00-0a4c-4e09-d993-5c993aa59cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 111\n",
            "finished building the ANN index\n",
            "done finding negatives\n",
            "STS DatasetTriplet\n",
            "building negatives via ANN-TFIDF\n",
            "using predefined corpus of length: 286\n",
            "finished building the ANN index\n",
            "done finding negatives\n"
          ]
        }
      ],
      "source": [
        "NEGATIVE_CORPUS_METHOD_STS ='ann-tfidf'\n",
        "# convert to torch dataset (val)\n",
        "sts_torchdataset_val = DatasetTriplets(\n",
        "    list_of_data = [\n",
        "       x for x in sts_statics_datsets['val'] if x.get('type','na') == 'sts_triplet'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "    negative_corpus_method = NEGATIVE_CORPUS_METHOD_STS\n",
        "\n",
        ")\n",
        "# convert to torch dataset (train)\n",
        "print('STS DatasetTriplet')\n",
        "sts_torchdataset_train = DatasetTriplets(\n",
        "    list_of_data = [\n",
        "       x for x in sts_statics_datsets['train'] if x.get('type','na')== 'sts_triplet'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    topk_negatives_discard=15, # to get similar but different negatives, use BM25 and discard these topk\n",
        "    negative_corpus_method = NEGATIVE_CORPUS_METHOD_STS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISaK7WFF8rTM",
        "outputId": "2abebcdc-00bb-4d38-d88b-f3f7d7386465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'Elaine Sullivan Act - Amends title XVIII (Medicare) of the Social Security Act to require emergency departments to contact family members, a specified healthcare agent, or a surrogate decisionmaker of an incapacitated patient within 24 hours of arrival at the emergency department. Authorizes the Secretary of Health and Human Services to make grants to qualified not-for-profit organizations for the purpose of assisting them to establish and operate voluntary next of kin registries.',\n",
              " 'pos': \"(a) In General.--Section 1866(a)(1) of the Social Security Act (42 U.S.C. 1395cc(a)(1)) is amended-- (1) in subparagraph (U), by striking ``and'' at the end; (2) in subparagraph (V), by striking the period at the end and inserting ``, and''; and (3) by inserting after subparagraph (V) the following new subparagraph: ``(W) in the case of a hospital (as defined in section 1861(e)) with an emergency department, to adopt and enforce a policy to ensure compliance with the requirements of subsection (k) (relating to requirements to make reasonable efforts to contact certain individuals in the case of a patient who is unconscious or physically unable to communicate with staff of the hospital).''. (b) Requirement to Contact Family Members or Other Individuals With Authority to Make Health Care Decisions.--Section 1866 of such Act (42 U.S.C. 1395cc) is amended by adding at the end the following new subsection: ``(k)(1)(A) In the case of a hospital (as defined in section 1861(e)) with an emergency department, if any individual arrives at the emergency department requiring medical treatment and is unconscious or otherwise unable to communicate with a health care professional of the department, the hospital shall take reasonable measures (described in paragraph (3)) to identify and contact a person the hospital reasonably believes has the authority to make health care decisions on behalf of the individual. ``(B) A person referred to in subparagraph (A) is any of the following: ``(i) An immediate family member. ``(ii) A person authorized to make health care decisions for the individual under a durable power of attorney for health care, recognized under State law (whether by statute or as recognized by the courts of the State). ``(2)(A) The hospital shall take the reasonable measures as soon as practicable, but, subject to subparagraph (B), in no case later than the end of the 24-hour period that begins at the point in time that a health care professional of the emergency department of the hospital determines that the individual is unconscious or otherwise unable to communicate. ``(B)(i) The 24-hour period under subparagraph (A) shall not apply during any period in which the hospital implements a disaster and mass casualty program or a fire and internal disaster program, or during a declared state of emergency (as defined in clause (ii)) or other local mass casualty situation. ``(ii) For purposes of clause (i), the term `declared state of emergency' means an officially designated state of emergency that has been declared by the Federal Government or a State or local government official having authority to declare that the State, county, municipality, or locality is in a state of emergency. ``(3) Reasonable measures referred to in paragraph (1) include the following: ``(A) Contacting the emergency contact, family member, surrogate decisionmaker, or other health care agent identified from personal effects of the individual. ``(B) Examining medical records in the hospital's possession, including a review of any verbal or written report made by emergency medical technicians or the police with respect to the individual. ``(C) Insofar as actions under subparagraphs (A) and (B) are unsuccessful, contacting the hospital's social service department or the appropriate local law enforcement agency. ``(4) The provisions of this subsection do not preempt any State or local law requirement, except to the extent that the requirement directly conflicts with a requirement of this subsection.''. (c) Effective Date.--The amendments made by this section shall apply to hospitals as of the date that is one year after the date of the enactment of this Act. SEC. 3. GRANT PROGRAM FOR THE ESTABLISHMENT\",\n",
              " 'neg': \"(a) Grants Authorized.--The Secretary of Homeland Security may make a grant of financial assistance to any State or local government or Indian tribe in order to reimburse the State or local government or tribe for costs incurred by the State or local government or tribe as a result of a call or order to active duty of one or more Reserves who are first responder personnel of the State or local government or tribe if the call or order to duty is issued under the authority of a provision of law referred to in section 101(a)(13)(B) of title 10, United States Code. (b) First Responder Personnel.--For purposes of this section, the term ``first responder personnel''-- (1) means police, fire, rescue, emergency medical service, and emergency hazardous material disposal personnel; and (2) includes such other personnel as the Secretary may specify in regulations prescribed under this section. (c) Covered Costs.--(1) The costs that may be reimbursed by a grant under subsection (a) to a State or local government or Indian tribe in connection with a call or order of first responder personnel of the State or local government or tribe to active duty are any costs incurred by the State or local government or tribe as follows: (A) Costs (including salary and benefits) of hiring first responder personnel to replace the first responder personnel called or ordered to active duty. (B) Costs of overtime pay for other first responder personnel of the State or local government or tribe. (C) Any other costs that the Secretary specifies in regulations prescribed under this section. (2) Costs of a State or local government or tribe may be reimbursed by a grant under subsection (a) only if the State or local government or tribe would not have incurred such costs but for the absence of first responder personnel pursuant to a call or order to active duty described in that subsection. (3) In seeking reimbursement for costs under subsection (a), a State or local government or tribe shall deduct from the costs for which reimbursement is sought the amounts, if any, saved by the State or local government or tribe by reason of the absence of first responder personnel for active duty pursuant to a call or order to active duty described in that subsection. (d) Period Covered by Grant.--(1) Except as provided in paragraph (2), a grant under subsection (a) shall reimburse a State or local government or Indian tribe for costs incurred by the State or local government or tribe during the year preceding the year of the application for the grant under subsection (f). (2) If the active duty of a particular Reserve during a year is insufficient to meet the duty requirement in subsection (e) for such year, but when combined with active duty in the succeeding year is sufficient to meet the duty requirement for such succeeding year, a grant under subsection (a) for such succeeding year shall also reimburse the State or local government or tribe for costs incurred in connection with the active duty of the Reserve during such year. (e) Minimum Period of Duty for Reimbursement.--(1) Costs may be reimbursed by a grant under subsection (a) with respect to a particular Reserve only if the Reserve serves six or more consecutive months on active duty pursuant to a call or order to active duty issued under the authority of a provision of law referred to in subsection (a) at any time during the two calendar years preceding the application for the grant under subsection (f). (2) If a particular Reserve meets the duty requirement in paragraph (1) for a grant under subsection (a) for a year, costs reimbursable by the grant shall include any costs in connection with the active duty of the Reserve described in that paragraph during such\"}"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sts_torchdataset_train[-4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYbqWcsOtc5Q"
      },
      "source": [
        "### Pair Classifications Datasets\n",
        "- one datasets are naturally pair-based (NLI, cannot-datasets); some like the multi-label dataets can be made into a \"same class / different class\" binary dataset (ag_news, ; others like sentiment\n",
        "\n",
        "\n",
        "###### Datasets\n",
        "- DONE snli (550k, 1 file) - naturally pair classification  \n",
        "    - 3 labels: 0,1,2\n",
        "- DONE multi_nli - (393k, 1 file)\n",
        "- NO ag_news classification - (a couple of labels -- only 4)\n",
        "- DONE heegyu/news-category-dataset - (maybe multiple categories)\n",
        "- dbpedia_14 (560k, 1 file)- news classification or topic ? (~14 labels corresponding to art or building types)\n",
        "    - 14 classes\n",
        "- ccdv/patent-classification - 25k (abstract) (maybe skip)\n",
        "- fkdosilovic/docee-event-classification (21.9k, 1 file) - 59 labels (news-event like elections, diasters)\n",
        "- NO scholarly360/contracts-classification-instruction-llm-experiments - 6.05k (clauses) -- no, I think these are just the auto-labels from LEDGAR\n",
        "- NO 'rcds/swiss_judgment_prediction','mt_en', (59703 examples) (NO, it is autotranslated)\n",
        "- DONE **'tum-nlp/cannot-dataset'** - like entailment, but contains paraphrases & negations\n",
        "- NO sentiment analysis -- ?\n",
        "- NO samchain/BIS_Speeches_97_23 - next sentence prediction\n",
        "- next sentence prediction from MLM\n",
        "\n",
        "MASKING: a mask vector will be used to focus the loss only on the appropriate dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6fDrV6r75Ib",
        "outputId": "366869c5-2c7e-4471-978a-e9973bdd4bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'example_id': 0, 'citing_prompt': \"Drapeau’s cohorts, the cohort would be a “victim” of making the bomb. Further, firebombs are inherently dangerous. There is no peaceful purpose for making a bomb. Felony offenses that involve explosives qualify as “violent crimes” for purposes of enhancing the sentences of career offenders. See 18 U.S.C. § 924(e)(2)(B)(ii) (defining a “violent felony” as: “any crime punishable by imprisonment for a term exceeding one year ... that ... involves use of explosives”). Courts have found possession of a'bomb to be a crime of violence based on the lack of a nonviolent purpose for a bomb and the fact that, by its very nature, there is a substantial risk that the bomb would be used against the person or property of another. See United States v. Newman, 125 F.3d 863 (10th Cir.1997) (unpublished) (<HOLDING>); United States v. Dodge, 846 F.Supp. 181,\", 'holding_0': 'holding that possession of a pipe bomb is a crime of violence for purposes of 18 usc  3142f1', 'holding_1': 'holding that bank robbery by force and violence or intimidation under 18 usc  2113a is a crime of violence', 'holding_2': 'holding that sexual assault of a child qualified as crime of violence under 18 usc  16', 'holding_3': 'holding for the purposes of 18 usc  924e that being a felon in possession of a firearm is not a violent felony as defined in 18 usc  924e2b', 'holding_4': 'holding that a court must only look to the statutory definition not the underlying circumstances of the crime to determine whether a given offense is by its nature a crime of violence for purposes of 18 usc  16', 'label': '0'}\n"
          ]
        }
      ],
      "source": [
        "foo = load_dataset('casehold/casehold','all',split='train', streaming=True)\n",
        "print(next(iter(foo)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnt-qYtg8m9v",
        "outputId": "09cf6f3d-f767-477d-a23f-79591e463675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['example_id', 'citing_prompt', 'holding_0', 'holding_1', 'holding_2', 'holding_3', 'holding_4', 'label'])\n"
          ]
        }
      ],
      "source": [
        "labels = set()\n",
        "for i,e in enumerate(foo):\n",
        "    labels |= {e['label']}\n",
        "    if i > 2:\n",
        "        break\n",
        "\n",
        "print(e.keys())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmaObS_dP0HK"
      },
      "outputs": [],
      "source": [
        "DEFAULT_COLUMNS = ['pair1','pair2','label','type','cls_id','n_labels']\n",
        "\n",
        "DBPEDIA_L2 = {\n",
        "    'Tower': 0, 'NaturalPlace': 1, 'Presenter': 2, 'RacingDriver': 3, 'FloweringPlant': 4, 'SportFacility': 5, 'Venue': 6, 'Database': 7,\n",
        "    'EducationalInstitution': 8, 'Olympics': 9, 'Race': 10, 'VolleyballPlayer': 11, 'Infrastructure': 12, 'MusicalWork': 13, 'Genre': 14, 'ComicsCharacter': 15,\n",
        "    'Song': 16, 'MusicalArtist': 17, 'Settlement': 18, 'Tournament': 19, 'Engine': 20, 'Politician': 21, 'Coach': 22, 'SocietalEvent': 23, 'Person': 24,\n",
        "    'LegalCase': 25, 'AmusementParkAttraction': 26, 'GridironFootballPlayer': 27, 'Cleric': 28, 'FootballLeagueSeason': 29, 'MotorcycleRider': 30, 'SportsTeam': 31,\n",
        "    'SportsEvent': 32, 'Satellite': 33, 'Eukaryote': 34, 'RaceTrack': 35, 'Boxer': 36, 'Wrestler': 37, 'Scientist': 38, 'Building': 39, 'Actor': 40, 'Plant': 41,\n",
        "    'Cartoon': 42, 'NaturalEvent': 43, 'SportsLeague': 44, 'RouteOfTransportation': 45, 'OrganisationMember': 46, 'FictionalCharacter': 47, 'Horse': 48,\n",
        "    'ClericalAdministrativeRegion': 49, 'PeriodicalLiterature': 50, 'WrittenWork': 51, 'Writer': 52, 'CelestialBody': 53, 'WinterSportPlayer': 54,\n",
        "    'SportsTeamSeason': 55, 'Company': 56, 'Animal': 57, 'Broadcaster': 58, 'BritishRoyalty': 59, 'Organisation': 60, 'Athlete': 61, 'Group': 62, 'Stream': 63,\n",
        "    'Artist': 64, 'Station': 65, 'SportsManager': 66, 'BodyOfWater': 67, 'Software': 68, 'Comic': 69, 'other': 70\n",
        "}\n",
        "\n",
        "DBPEDIA_L3 = {\n",
        "    'TelevisionStation': 0, 'NetballPlayer': 1, 'FigureSkater': 2, 'BadmintonPlayer': 3, 'School': 4, 'River': 5, 'WomensTennisAssociationTournament': 6,\n",
        "    'ShoppingMall': 7, 'GreenAlga': 8, 'Winery': 9, 'Religious': 10, 'SumoWrestler': 11, 'Planet': 12, 'Swimmer': 13, 'Curler': 14, 'Astronaut': 15,\n",
        "    'MemberOfParliament': 16, 'MythologicalFigure': 17, 'CanadianFootballTeam': 18, 'OlympicEvent': 19, 'Senator': 20, 'Album': 21, 'PublicTransitSystem': 22,\n",
        "    'Photographer': 23, 'Library': 24, 'Village': 25, 'Play': 26, 'Legislature': 27, 'AdultActor': 28, 'Lake': 29, 'Earthquake': 30,\n",
        "    'SupremeCourtOfTheUnitedStatesCase': 31, 'Airline': 32, 'Road': 33, 'SoccerPlayer': 34, 'BaseballSeason': 35, 'CultivatedVariety': 36, 'Judge': 37,\n",
        "    'PlayboyPlaymate': 38, 'GolfPlayer': 39, 'RadioHost': 40, 'WrestlingEvent': 41, 'Theatre': 42, 'Saint': 43, 'CollegeCoach': 44, 'VideoGame': 45,\n",
        "    'NCAATeamSeason': 46, 'Museum': 47, 'GolfCourse': 48, 'ComicsCreator': 49, 'Cycad': 50, 'Bird': 51, 'Stadium': 52, 'Magazine': 53, 'Manga': 54,\n",
        "    'Newspaper': 55, 'BaseballPlayer': 56, 'Reptile': 57, 'Diocese': 58, 'ChessPlayer': 59, 'SoccerLeague': 60, 'Grape': 61, 'Architect': 62, 'Monarch': 63,\n",
        "    'Cave': 64, 'Skater': 65, 'HorseRace': 66, 'RadioStation': 67, 'MilitaryPerson': 68, 'EurovisionSongContestEntry': 69, 'Fish': 70,\n",
        "    'NationalFootballLeagueSeason': 71, 'PoliticalParty': 72, 'Single': 73, 'Skier': 74, 'MixedMartialArtsEvent': 75, 'Philosopher': 76,\n",
        "    'Hospital': 77, 'BasketballTeam': 78, 'Mountain': 79, 'RailwayStation': 80, 'Comedian': 81, 'Galaxy': 82, 'AmericanFootballPlayer': 83,\n",
        "    'Cardinal': 84, 'Mollusca': 85, 'Journalist': 86, 'OfficeHolder': 87, 'Glacier': 88, 'Rower': 89, 'Baronet': 90, 'RollerCoaster': 91,\n",
        "    'BaseballLeague': 92, 'ArtificialSatellite': 93, 'Dam': 94, 'MilitaryUnit': 95, 'Engineer': 96, 'Restaurant': 97, 'HockeyTeam': 98,\n",
        "    'GaelicGamesPlayer': 99, 'Hotel': 100, 'Publisher': 101, 'Fungus': 102, 'AutomobileEngine': 103, 'Moss': 104, 'FormulaOneRacer': 105,\n",
        "    'Cricketer': 106, 'IceHockeyPlayer': 107, 'Mayor': 108, 'MartialArtist': 109, 'RaceHorse': 110, 'Canoeist': 111, 'BeachVolleyballPlayer': 112,\n",
        "    'RecordLabel': 113, 'Musical': 114, 'BusinessPerson': 115, 'ArtistDiscography': 116, 'SoccerClubSeason': 117, 'Ambassador': 118, 'Gymnast': 119,\n",
        "    'RailwayLine': 120, 'Town': 121, 'CyclingTeam': 122, 'LacrossePlayer': 123, 'HollywoodCartoon': 124, 'MilitaryConflict': 125, 'RugbyClub': 126,\n",
        "    'Racecourse': 127, 'Pope': 128, 'RoadTunnel': 129, 'Economist': 130, 'University': 131, 'President': 132, 'Bodybuilder': 133, 'DartsPlayer': 134,\n",
        "    'Canal': 135, 'CricketGround': 136, 'Crustacean': 137, 'SpeedwayRider': 138, 'Cyclist': 139, 'MusicGenre': 140, 'Volcano': 141, 'Medician': 142,\n",
        "    'Castle': 143, 'Anime': 144, 'BasketballPlayer': 145, 'Model': 146, 'SoccerManager': 147, 'Chef': 148, 'SportsTeamMember': 149, 'Convention': 150,\n",
        "    'Airport': 151, 'HandballTeam': 152, 'FootballMatch': 153, 'ClassicalMusicComposition': 154, 'Conifer': 155, 'RugbyLeague': 156, 'Fern': 157,\n",
        "    'HistoricBuilding': 158, 'ChristianBishop': 159, 'BusCompany': 160, 'VoiceActor': 161, 'SoccerTournament': 162, 'GolfTournament': 163, 'HorseRider': 164,\n",
        "    'SolarEclipse': 165, 'Prison': 166, 'CyclingRace': 167, 'AustralianRulesFootballPlayer': 168, 'BasketballLeague': 169, 'Bridge': 170, 'Noble': 171,\n",
        "    'Arachnid': 172, 'ComicStrip': 173, 'AnimangaCharacter': 174, 'Bank': 175, 'Amphibian': 176, 'Poet': 177, 'LawFirm': 178, 'NascarDriver': 179,\n",
        "    'Congressman': 180, 'FashionDesigner': 181, 'BiologicalDatabase': 182, 'CricketTeam': 183, 'HandballPlayer': 184, 'MountainPass': 185, 'Band': 186,\n",
        "    'Brewery': 187, 'AcademicJournal': 188, 'Insect': 189, 'Jockey': 190, 'ClassicalMusicArtist': 191, 'Governor': 192, 'PokerPlayer': 193, 'Poem': 194,\n",
        "    'TennisPlayer': 195, 'Historian': 196, 'ScreenWriter': 197, 'MusicFestival': 198, 'TennisTournament': 199, 'TradeUnion': 200, 'BeautyQueen': 201,\n",
        "    'AustralianFootballTeam': 202, 'AmateurBoxer': 203, 'SquashPlayer': 204, 'Painter': 205, 'RugbyPlayer': 206, 'MountainRange': 207, 'Lighthouse': 208,\n",
        "    'TableTennisPlayer': 209, 'SoapCharacter': 210, 'IceHockeyLeague': 211, 'HorseTrainer': 212, 'Election': 213, 'GrandPrix': 214, 'PrimeMinister': 215,\n",
        "    'Entomologist': 216, 'BroadcastNetwork': 217, 'FilmFestival': 218, 'other': 219\n",
        "    }\n",
        "\n",
        "DOCEEEVENTS = {\n",
        "    'Famous Person - Death': 0, 'Strike': 1, 'Awards ceremony': 2, 'Road Crash': 3, 'Famous Person - Commit Crime - Accuse': 4, 'New wonders in nature': 5,\n",
        "    'Droughts': 6, 'Mudslides': 7, 'Shipwreck': 8, 'Government Policy Changes': 9, 'Famous Person - Commit Crime - Sentence': 10, 'Tsunamis': 11,\n",
        "    'Insect Disaster': 12, 'Government Job change - Election': 13, 'Famous Person - Sick': 14, 'Train collisions': 15, 'Financial Crisis': 16, 'Earthquakes': 17,\n",
        "    'Protest_Online Condemnation': 18, 'Tear Up Agreement': 19, 'Famine': 20, 'Organization Established': 21, 'Gas explosion': 22, 'Military Exercise': 23,\n",
        "    'Sign Agreement': 24, 'Armed Conflict': 25, 'Famous Person - Commit Crime - Arrest': 26, 'Withdraw from an Organization': 27,\n",
        "    'Famous Person - Give a speech': 28, 'Organization Closed': 30, 'Famous Person - Commit Crime - Release': 31, 'Fire': 32, 'Financial Aid': 33,\n",
        "    'Bank Robbery': 34, 'Disease Outbreaks': 35, 'Riot': 36, 'Hurricanes_Tornado_Storm_Blizzard': 37, 'Air crash': 38,\n",
        "    'Government Job change - Appoint_Inauguration': 39, 'Famous Person - Recovered': 40, 'Break historical records': 41, 'Join in an Organization': 42,\n",
        "    'Famous Person - Marriage': 43, 'Diplomatic Talks _ Diplomatic_Negotiation_ Summit Meeting': 44, 'Organization Fine': 45, 'Floods': 46,\n",
        "    'Sports Competition': 47, 'Volcano Eruption': 48, 'New achievements in aerospace': 49, 'Regime Change': 50, 'Government Job change - Resignation_Dismissal': 51,\n",
        "    'Mine Collapses': 52, 'Famous Person - Divorce': 53, 'Mass Poisoning': 54, 'New archeological discoveries': 55, 'Famous Person - Commit Crime - Investigate': 56,\n",
        "    'Diplomatic Visit': 57, 'Organization Merge': 58, 'Environment Pollution': 59, 'other': 60,\n",
        "}\n",
        "\n",
        "# categories for news categories\n",
        "NEWSCATEGORIES = {\n",
        "    'WORLDPOST': 0, 'PARENTS': 1, 'COMEDY': 2,'MONEY': 3, 'WOMEN': 4,'GOOD NEWS': 5,'WEIRD NEWS': 6,'TECH': 8,'ARTS & CULTURE': 9,\n",
        "    'WEDDINGS': 10,'EDUCATION': 11,'CRIME': 13,'FIFTY': 14,'STYLE': 15,'SPORTS': 16,'TASTE': 17,'COLLEGE': 18,'THE WORLDPOST': 19,'WORLD NEWS': 20,\n",
        "    'GREEN': 21,'CULTURE & ARTS': 22,'POLITICS': 23, 'WELLNESS': 24,'HOME & LIVING': 25,'MEDIA': 26,'SCIENCE': 27,'HEALTHY LIVING': 28,\n",
        "    'U.S. NEWS': 29,'ARTS': 30,'FOOD & DRINK': 31,'ENTERTAINMENT': 32,'ENVIRONMENT': 33,'IMPACT': 34,'RELIGION': 35,\n",
        "    'PARENTING': 36,'STYLE & BEAUTY': 37,'BUSINESS': 38,'TRAVEL': 39,'OTHER':40\n",
        "}\n",
        "\n",
        "def clean_snli(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'snli'\n",
        "    x['n_labels'] = 3\n",
        "    return x\n",
        "\n",
        "def clean_contractnli(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'contractnli'\n",
        "    x['n_labels'] = 3\n",
        "    return x\n",
        "\n",
        "def clean_mnli(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    #x['label'] = []\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'mnli'\n",
        "    x['n_labels'] = 3\n",
        "    return x\n",
        "\n",
        "def clean_cannotdatast(x):\n",
        "    x['pair1'] = x['premise']\n",
        "    x['pair2'] = x['hypothesis']\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'cannotdataset'\n",
        "    x['n_labels'] = 2\n",
        "    return x\n",
        "\n",
        "def clean_newscategory(x):\n",
        "    x['pair1'] = x['headline'] + \". \" + x['short_description']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = NEWSCATEGORIES.get(x['category'],NEWSCATEGORIES['OTHER'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'newscategory'\n",
        "    x['n_labels'] = 40\n",
        "    return x\n",
        "\n",
        "def clean_doceeevents(x):\n",
        "    x['pair1'] = x['text']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = DOCEEEVENTS.get(x['event_type'],DOCEEEVENTS['other'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'doceeevents'\n",
        "    x['n_labels'] = 61\n",
        "    return x\n",
        "\n",
        "def clean_dbpedia_l2(x):\n",
        "    x['pair1'] = x['text']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = DBPEDIA_L2.get(x['l2'],DBPEDIA_L2['other'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'dbpedia_l2'\n",
        "    x['n_labels'] = 71 # 219\n",
        "    return x\n",
        "\n",
        "def clean_dbpedia_l3(x):\n",
        "    x['pair1'] = x['text']\n",
        "    x['pair2'] = None\n",
        "    x['label'] = DBPEDIA_L3.get(x['l3'],DBPEDIA_L3['other'])\n",
        "    x['type'] = 'classification'\n",
        "    x['cls_id'] = 'dbpedia_l3'\n",
        "    x['n_labels'] = 220\n",
        "    return x\n",
        "\n",
        "def clean_casehold_positives(x):\n",
        "    x['pair1'] = x['citing_prompt'].split('(<HOLDING>)')[0]\n",
        "    correct_holding_id = int(x['label'])\n",
        "    correct_holding_text = x['holding_%d' % correct_holding_id]\n",
        "    x['pair2'] = correct_holding_text\n",
        "    x['label'] = 1\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'casehold'\n",
        "    x['n_labels'] = 2\n",
        "    return x\n",
        "\n",
        "def clean_casehold_negatives(x):\n",
        "    x['pair1'] = x['citing_prompt'].split('(<HOLDING>)')[0]\n",
        "    correct_holding_id = int(x['label'])\n",
        "    incorrect_holding_id = (correct_holding_id+1) % 4\n",
        "    incorrect_holding_text = x['holding_%d' % incorrect_holding_id]\n",
        "    x['pair2'] = incorrect_holding_text\n",
        "    x['label'] = 0\n",
        "    x['type'] = 'pair_classification'\n",
        "    x['cls_id'] = 'casehold'\n",
        "    x['n_labels'] = 2\n",
        "    return x\n",
        "\n",
        "def filter_snli(x):\n",
        "    return x['label']!=-1\n",
        "\n",
        "def filter_newscategory(x):\n",
        "    return x['category'] not in ['LATINO VOICES',\"QUEER VOICES\", \"BLACK VOICES\"]\n",
        "\n",
        "cls_streaming_cleaning_functions = {\n",
        "    'snli':(clean_snli, filter_snli, DEFAULT_COLUMNS,['hypothesis','premise']),\n",
        "    'multi_nli':(clean_mnli, None, DEFAULT_COLUMNS, ['promptID', 'pairID', 'premise', 'premise_binary_parse', 'premise_parse', 'hypothesis', 'hypothesis_bi\n",
        "    'tum-nlp/cannot-dataset':(clean_cannotdatast, None, DEFAULT_COLUMNS,['hypothesis','premise']),\n",
        "    'kiddothe2b/contract-nli':(clean_contractnli, None, DEFAULT_COLUMNS, ['premise','hypothesis']),\n",
        "    'kiddothe2b/contract-nli':(clean_contractnli, None, DEFAULT_COLUMNS, ['premise','hypothesis']),\n",
        "    'heegyu/news-category-dataset':(clean_newscategory, filter_newscategory, DEFAULT_COLUMNS, ['category', 'headline', 'authors', 'link', 'short_description', 'date']),\n",
        "    'fkdosilovic/docee-event-classification':(clean_doceeevents, None, DEFAULT_COLUMNS, ['title', 'text', 'event_type', 'date', 'metadata']),\n",
        "    'DeveloperOats/DBPedia_Classes_level2':(clean_dbpedia_l2, None, DEFAULT_COLUMNS, ['text','l1','l2','l3']),\n",
        "    'DeveloperOats/DBPedia_Classes_level3':(clean_dbpedia_l3, None, DEFAULT_COLUMNS, ['text','l1','l2','l3']),\n",
        "    'casehold/casehold_positives':(clean_casehold_positives, None, DEFAULT_COLUMNS, ['example_id', 'citing_prompt', 'holding_0', 'holding_1', 'holding_2', 'holding_3', 'holding_4']),\n",
        "    'casehold/casehold_negatives':(clean_casehold_negatives, None, DEFAULT_COLUMNS, ['example_id', 'citing_prompt', 'holding_0', 'holding_1', 'holding_2', 'holding_3', 'holding_4']),\n",
        "}\n",
        "\n",
        "DEFAULT_PROB = 1.0\n",
        "cls_files = [\n",
        "    # dataset name, subset, take_probability, dataset size\n",
        "    ('snli', None, DEFAULT_PROB/2, 550000, 'pair_classification', False),\n",
        "    ('multi_nli', None, DEFAULT_PROB, 393000, 'pair_classification', False),\n",
        "    ('tum-nlp/cannot-dataset', None, DEFAULT_PROB, 77400, 'pair_classification', False),\n",
        "    ('kiddothe2b/contract-nli','contractnli_a', DEFAULT_PROB//5, 71900, 'pair_classification', False),\n",
        "    ('kiddothe2b/contract-nli','contractnli_b', DEFAULT_PROB//5, 71900, 'pair_classification', False),\n",
        "    ('heegyu/news-category-dataset', None, DEFAULT_PROB/2, 210000, 'classification', False),\n",
        "    ('fkdosilovic/docee-event-classification', None, DEFAULT_PROB/2, 21900, 'classification', False),\n",
        "    ('DeveloperOats/DBPedia_Classes', None, DEFAULT_PROB/2, 241000, 'classification', False),\n",
        "    ('DeveloperOats/DBPedia_Classes', None, DEFAULT_PROB/2, 241000,'classification', False),\n",
        "    ('casehold/casehold', 'all', DEFAULT_PROB/2, 53100, 'pair_classification', False),\n",
        "    ('casehold/casehold', 'all', DEFAULT_PROB/2, 53100, 'pair_classification', False)\n",
        "]\n",
        "\n",
        "clsdata_streaming_config = {\n",
        "    'files':cls_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':100,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVZo2_49P0Em"
      },
      "outputs": [],
      "source": [
        "def initialize_and_get_classification_streaming_datasets(\n",
        "    data_streaming_config,\n",
        "    streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_cls.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_cls_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'CLS' #\n",
        "):\n",
        "    \"\"\"Converts stream of unlabelled text data into static datasets for: pair-classification tasks\"\"\"\n",
        "    # list of files to stream\n",
        "    files = data_streaming_config['files']\n",
        "    # number of examples to take from stream for validation set\n",
        "    val_size = data_streaming_config['val_size']\n",
        "    # number of examples to take from stream for training set\n",
        "    train_chunk_size = data_streaming_config['train_chunk_size']\n",
        "    min_seq_len = data_streaming_config.get('min_seq_length', 48)\n",
        "    # normalization constant for normalizing the weights into probabilities\n",
        "    probability_normalization_const = sum([x[2] for x in files])\n",
        "\n",
        "    # where to initialize start-stream for training data\n",
        "    if start_proportion is None:\n",
        "        start_proportion = np.random.RandomState(seed+epoch).uniform()*0.95\n",
        "\n",
        "    # reload cached files\n",
        "    path_to_train_cache = None if not '%03g' in path_to_train_cache_epoch else path_to_train_cache_epoch % epoch\n",
        "    do_make_valset = not os.path.isfile(path_to_val_cache)\n",
        "    do_make_trainset = not os.path.isfile(path_to_train_cache)\n",
        "    if not do_make_valset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            datalist_val_triplet_static = pickle.load(pcon)\n",
        "        print(f'VAL-{name} SET SIZE: %d' % len(datalist_val_triplet_static))\n",
        "    else:\n",
        "        datalist_val_triplet_static = []\n",
        "    if not do_make_trainset:\n",
        "        print(f'RELOADING VAL-{name} SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_train_cache,'rb') as pcon:\n",
        "            datalist_train_triplet_static = pickle.load(pcon)\n",
        "        print(f'TRAIN-{name} EPOCH-%d SET SIZE: %d' % (epoch, len(datalist_train_triplet_static)))\n",
        "    else:\n",
        "        datalist_train_triplet_static = []\n",
        "\n",
        "    if (do_make_trainset or do_make_valset):\n",
        "\n",
        "        # loop through datasets\n",
        "        for (data_nm, set_nm, prob, dataset_size, special_handling, partition_shuffle), dataset_key in zip(\n",
        "            files, streaming_cleaning_functions.keys()\n",
        "        ):\n",
        "            if prob ==0:\n",
        "                continue\n",
        "            prob /= probability_normalization_const\n",
        "\n",
        "            # get cleaning & filter functions for streaming data functionality\n",
        "            clean_func, filter_func, feature_names, removefeature_names = streaming_cleaning_functions[dataset_key]\n",
        "\n",
        "            # set arguments for the load_dataset (huggingface repos)\n",
        "            load_dataset_args = {\n",
        "                'path':data_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "            }\n",
        "            # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "            if data_nm.endswith('.jsonl') or data_nm.endswith('.jsonl.zip') or data_nm.endswith('.jsonl.zst'):\n",
        "                load_dataset_args.update({'path':'json','data_files':data_nm})\n",
        "\n",
        "            # special proecssing of datasets with multiple partitions\n",
        "            if bool(partition_shuffle): # or str(epoch)=='val':\n",
        "\n",
        "                n_files, n_per_file = partition_shuffle\n",
        "                dataset_size = n_per_file\n",
        "                print('trying %s initialization (shuffling through %d files)' % (data_nm, n_files))\n",
        "\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func)\n",
        "\n",
        "                # validation set\n",
        "                if do_make_valset:\n",
        "                    # take from stream\n",
        "                    n_valset_take = max(int(prob*val_size), 1)\n",
        "                    print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert stream to a static set and do check\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "                # training set\n",
        "                if do_make_trainset:\n",
        "                    # randomly skip a bunch from this set\n",
        "                    skip_to_start = int(start_proportion*n_per_file)\n",
        "                    take_from_this_set = max(int(round(train_chunk_size*prob)),1)\n",
        "                    print('take %d from %s training'% (take_from_this_set, data_nm))\n",
        "                    # shuffle: take a random data partition (from the dataset's list of files)\n",
        "                    dset_stream_train = dset_stream_val.shuffle(\n",
        "                        seed = seed+epoch, buffer_size = skip_to_start+take_from_this_set,\n",
        "                    )\n",
        "                    dset_stream_train = dset_stream_train.skip(\n",
        "                        skip_to_start # random skip through dataset to new start position\n",
        "                    ).take(\n",
        "                        take_from_this_set # take this amount for the training ste\n",
        "                    ).map(clean_func).remove_columns(removefeature_names)\n",
        "                    # convert training to static dataset\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "            else:\n",
        "                # regular streaming\n",
        "                print('trying %s initialization' % data_nm)\n",
        "                # whether there is a filter\n",
        "                if filter_func is None:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "                else:\n",
        "                    dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "                # take from stream\n",
        "                n_valset_take = max(int(prob*val_size), 1) # size of valset\n",
        "                print('take %d from %s validation'% (n_valset_take, data_nm))\n",
        "                skip_to_start = int(start_proportion*(dataset_size-n_valset_take)) # random point to skip to\n",
        "                n_train_take = max(int(round(train_chunk_size*prob)),1) # size of train set\n",
        "                print('take %d from %s train'% (n_train_take, data_nm))\n",
        "                if do_make_valset:\n",
        "                    dset_stream_val = dset_stream.take(n_valset_take)\n",
        "                    dset_static_val_thisset = [\n",
        "                        e for e in dset_stream_val if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "                if do_make_trainset:\n",
        "                    dset_stream_train = dset_stream.skip(n_valset_take+skip_to_start).take(n_train_take)\n",
        "                    dset_static_train_thisset = [\n",
        "                        e for e in dset_stream_train if bool(re.search(r\"\\w+\",e['pair1'][:200]))\n",
        "                    ]\n",
        "            print('Done getting streams/reloading from %s' % data_nm)\n",
        "            # check language\n",
        "            if do_make_valset:\n",
        "                # discard non-english\n",
        "                dset_static_val_thisset =[\n",
        "                    e for e in dset_static_val_thisset if check_language(e['pair1'])[0] #detect(e['pair1'][:200]+\" hello\")=='en'\n",
        "                ]\n",
        "                print('done val language check')\n",
        "                # add to val set\n",
        "                datalist_val_triplet_static.extend(dset_static_val_thisset)\n",
        "\n",
        "            # check language\n",
        "            if do_make_trainset:\n",
        "                # discard non-english\n",
        "                dset_static_train_thisset =[\n",
        "                    e for e in dset_static_train_thisset if check_language(e['pair1'])[0]\n",
        "                ]\n",
        "                print('done train language check')\n",
        "\n",
        "                # ensure that none of the examples in the traning set are in the validation set\n",
        "                def hashtest(text1,text2):\n",
        "                    texthash = text1.lower()\n",
        "                    texthash+= \"\" if text2 is None else text2[:1000].lower()\n",
        "                    return texthash\n",
        "\n",
        "                if do_make_valset:\n",
        "                    val_queries = set([hashtest(q['pair1'],q['pair2']) for q in dset_static_val_thisset])\n",
        "                    dset_static_train_thisset = [\n",
        "                        s for s in dset_static_train_thisset if hashtest(s['pair1'],s['pair2']) not in val_queries\n",
        "                    ]\n",
        "\n",
        "                # add to training set\n",
        "                datalist_train_triplet_static.extend(dset_static_train_thisset)\n",
        "\n",
        "        print(f'Done collecting {name} streaming data')\n",
        "\n",
        "    if do_make_valset:\n",
        "        print('saving streamed %s validation data: %s' % (name, path_to_val_cache))\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_val_triplet_static, pcon)\n",
        "\n",
        "    if do_make_trainset:\n",
        "        print('saving streamed %s training for epoch %d: %s' % (name, epoch, path_to_train_cache))\n",
        "        with open(path_to_train_cache,'wb') as pcon:\n",
        "            pickle.dump(datalist_train_triplet_static, pcon)\n",
        "\n",
        "    return {\n",
        "        'train':datalist_train_triplet_static,\n",
        "        'val':datalist_val_triplet_static,\n",
        "        'epoch':epoch,\n",
        "        'index_stream':start_proportion\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ad7eb1adf3b24d51b6d9db581ff11f18",
            "d3c8e6e942294ddf913c84f52160737b",
            "d149c9c014b54125be2f9ccb3f271504",
            "5cc04f68fbda455aaf16e78c98ad9f9e",
            "67b7ad21a48a4a339697122fd6e0c10e",
            "318eb12f8c014bf090024d2d0e82e127",
            "712c22b5be60449bb23b7555a5c22038",
            "c0a77f0c068c451298dc5c4904a51cc6",
            "aeab7fe8570a418e8b0d6fa5ee4116cc",
            "fed7ec45ec594d90bc2d11c56f8330ba",
            "41f2b3c081344be783534fb60fdd5c00",
            "45627e42f92a446eb93348029234446b",
            "7f6aa7c5f8f24392b23ebb21f9d8502a",
            "b97f76334b48437dbb7d7365cb93d2ec",
            "b9136a5d0eae4f9297b6b3490f36c0d3",
            "6639002ed37d40ff8083323541d97f3e",
            "37fc3be40adf4411ba11d7e448e6f753",
            "8a59fc9ba9e0478ca02ac0d067f2e781",
            "864c3f3a16f648edada464a8397f7b6f",
            "1d4ad789412a4b6895e89a53fb62b6d8",
            "e8fbf86680854fd48a93c7f3def67d98",
            "13e2a857eb49428aba8c96b962767d52",
            "1d552e4cb4c842ff8d848b3a212d84c9",
            "882c790b42fe48dfaf7b18bd8f45c5b9",
            "36bb22cb0b9449218327463a4a644c7e",
            "92e674416f8646eaa6bcea05d083ed6c",
            "b8d45f71d3da45968b6c845cf4744f70",
            "54ab0ccab0954ee087b5a0e7c46f049d",
            "35c4327146b44171a0cfbc53d7fd9c6a",
            "a244c1afad7940caa2aacee1c7099d04",
            "5597290e83314b2fb70149128b837acb",
            "40710930eadf4cdea0ae4f21c9a457f6",
            "c6c6f34f55c14980ad301ff3cbd6efd5",
            "ef41b64939ce43f5bf0a7e2a2c34e5b6",
            "97343c8cd0be4a388806d2a08eee4f83",
            "0bfcee1a11c64820be92f82b36ae1f3b",
            "77222effa92b47c4b9b5aca2e1fc7971",
            "85a8afac57e741c8ba4e5fca23d29c82",
            "d93bf1eb51a742088ad7a78783af1550",
            "96e17bcfb86841e78640add9858f2e73",
            "bc087a4d9d3b4ee29f31dd677a44ad20",
            "6138f28660bd4610a19dbf919c399105",
            "6d42028ff9f54dcb9effdd01af728e82",
            "2191d1a5b41d4d2c80a80ee3487f2b84",
            "8ebeabb6e81f466bb2e5c587f475d58c",
            "5c3bd5b4fc2d480185bf8afe73720af5",
            "5aa71718a83446e58408f5baada02739",
            "19d3a395a2104e5eabc47c1f0ee7425b",
            "3669f6c8d83e469da8ac6a0662b5b3b6",
            "b03b7f723b8748bfa4bfd987f80b472e",
            "cd4b814a828847d7882704c3032d3fd6",
            "d1f164ebe9824ae4986a5fb9913b5d79",
            "413cb02e70c94df0ae721c178216499c",
            "8ef69e815a9746de9cf72f70c7c55bd6",
            "d9238e5174354b99abc293fffd924410",
            "54027a2d3bf240388116336d153cb6d8",
            "5674b6d3832d4a51aad763db048fa0b2",
            "86978ff9ee2b43d1875aec95965bafa1",
            "7b4b08fa4aca4532839925f9a4a5182d",
            "fee5b87f231c40e49a6b5408520948e1",
            "e713295328e84a95abfc13fd5e0fbf79",
            "39a0cc13934b4794b0103244457caf58",
            "67a7154376b34eb2b6625f7eea7cb8e1",
            "96683385bb0048edab833d70bc9b94f7",
            "f7ef96f903a348829426015c210a75c6",
            "f3f6078f2844467fa8b6e2dfa45eeefa",
            "b4c84bb6090644d3a7840c67f308dccb",
            "cecadb4b6d364dc9bcd443a913fac313",
            "9d5a89bd9cc94d019cc2dfbaa9ddf5f3",
            "585e63900ddb4fc098d8fdf6ab979b01",
            "a92aa894397749729cba070a8ca45a58",
            "fb32c9a099f242f49454f7f4fa9379a4",
            "978f79f285df4b19ba87c30abe443649",
            "094c77436878498099a7df8dddaade6b",
            "80ee1a5161b544b380fe6b2bf431ce00",
            "de7a2b9ab0ae42a38b4188f5a837ffe0",
            "c19adb67cf904bdc89b23db9c463ad70",
            "93d4f2893b8c47f388f2fd118fa8a0e0",
            "20919ce79bb54810bae8420eac2e9d6a",
            "84276e7b4ec141c3a7f5497bdc24a084",
            "14bbc1a8479744c688060e76179bb910",
            "e4d8a9054cbd4f36a0cbfd42d14a34d2",
            "6318eda7d3bc4b778ed92e779a0a4664",
            "02e13a92f0934b95951876571fff46bc",
            "3175f3e1e82549eca3f0210fd797d73b",
            "71be80ab68ba4da2a3a7066ef36e8d1c",
            "feec1cb456ec4924a79fc88b601d3ec1",
            "9ebd09f91c5b4a1cbd4ec9d4baf00d96",
            "d8c1e448fcc84881898158a453e1b003",
            "0cd233c207bb4c86ac5d002fff7f1d89",
            "da5372cb9eff4fc79e53215de91ba50d",
            "787eddad8809411fa14915244c03c24d",
            "47ed21294f9e42d9817708809f620d5f",
            "d56da3a1733e4c7990cc8a7dcded2474",
            "45173e6c935b4381a5d1f11663fa834a",
            "25a2bf19539642259412fbb1b4d9f69f",
            "cea7f31b2095405591f6f983f29a59ef",
            "58c7f5f99a99451d9e715066b8d4698a",
            "a9febc2bee944b66beb98c7ca39a2f67",
            "8ab8d0701eb54f4d8d43ebdb4f9d582c",
            "933287a3795541209985a9585a4b9b00",
            "c8f8b1493e1b4b2bb1a8f99719c21c81",
            "a1e33db2760f40aebfb725dc8261ac6d",
            "5f0dc4f1fe9e4b7d8bbf3c12a61cca3a",
            "dc49243de7304f988297672941344df1",
            "cd5fef47a92845508ff3d61db7da9867",
            "7d37d5db223e4588a13a65429c6b644c",
            "e627e0a7f374421b9b84f440789e99c0",
            "c8990d6ddea74c9db353c3a8702ff7ca",
            "2c0a41159b1241039386b5bf99d864c7",
            "5e959b2e1fc7460899db727adb156c2e",
            "6a7f36e7433d4f32876ea4ac13ee203a",
            "28d0bbe4650343fb8d4a12109bc78b20",
            "cbeae0b822a5446f9687157d33c457fd",
            "e93bede3188e4bf1bdd1de7ecb919483",
            "93fdce4ab8d049cb8982686dfea11829",
            "61177aa1734d4e4d9b78538bdc8c0266",
            "8e6c56c2991d433fa81332d7c48b183a",
            "137b6408b0fa4dd9bbc495a48c63272e",
            "4ad6947770a94c819fe4b90b67d8dedc",
            "f014adc3358445d4adc91797f81544a7"
          ]
        },
        "id": "qyCUlurNP0CY",
        "outputId": "8db3c999-bb56-4d11-a4e5-c12ca61aa386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOOFU: WIP converting this function from the MLM for classification tasks\n",
            "trying snli initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/snli/resolve/main/snli.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/86329aac5c7e9e8c647e8222ae58a56d78d8e732bf3247a8625b62774ab9c718.f39cdc981a04e8e99f36c751f118ff3775bcdb0b023e326afd18f3119c74c69d.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/snli/resolve/main/snli.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/86329aac5c7e9e8c647e8222ae58a56d78d8e732bf3247a8625b62774ab9c718.f39cdc981a04e8e99f36c751f118ff3775bcdb0b023e326afd18f3119c74c69d.py.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad7eb1adf3b24d51b6d9db581ff11f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/3.82k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/snli/resolve/main/snli.py in cache at /root/.cache/huggingface/datasets/downloads/86329aac5c7e9e8c647e8222ae58a56d78d8e732bf3247a8625b62774ab9c718.f39cdc981a04e8e99f36c751f118ff3775bcdb0b023e326afd18f3119c74c69d.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/snli/resolve/main/snli.py in cache at /root/.cache/huggingface/datasets/downloads/86329aac5c7e9e8c647e8222ae58a56d78d8e732bf3247a8625b62774ab9c718.f39cdc981a04e8e99f36c751f118ff3775bcdb0b023e326afd18f3119c74c69d.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/86329aac5c7e9e8c647e8222ae58a56d78d8e732bf3247a8625b62774ab9c718.f39cdc981a04e8e99f36c751f118ff3775bcdb0b023e326afd18f3119c74c69d.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/86329aac5c7e9e8c647e8222ae58a56d78d8e732bf3247a8625b62774ab9c718.f39cdc981a04e8e99f36c751f118ff3775bcdb0b023e326afd18f3119c74c69d.py\n",
            "https://huggingface.co/datasets/snli/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/e157ba42cfdf23e41f77696d41884676df3fa77322fc5f619ccdda1e0ab8131a.a88980f957e314e808c665b847185984f5f66ec662929d35db5414f3c0f33d08.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/snli/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/e157ba42cfdf23e41f77696d41884676df3fa77322fc5f619ccdda1e0ab8131a.a88980f957e314e808c665b847185984f5f66ec662929d35db5414f3c0f33d08.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45627e42f92a446eb93348029234446b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/snli/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/e157ba42cfdf23e41f77696d41884676df3fa77322fc5f619ccdda1e0ab8131a.a88980f957e314e808c665b847185984f5f66ec662929d35db5414f3c0f33d08\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/snli/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/e157ba42cfdf23e41f77696d41884676df3fa77322fc5f619ccdda1e0ab8131a.a88980f957e314e808c665b847185984f5f66ec662929d35db5414f3c0f33d08\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/e157ba42cfdf23e41f77696d41884676df3fa77322fc5f619ccdda1e0ab8131a.a88980f957e314e808c665b847185984f5f66ec662929d35db5414f3c0f33d08\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/e157ba42cfdf23e41f77696d41884676df3fa77322fc5f619ccdda1e0ab8131a.a88980f957e314e808c665b847185984f5f66ec662929d35db5414f3c0f33d08\n",
            "https://huggingface.co/datasets/snli/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/5e10e23a1db8375c6fccebefdb2195f7925cfca3dd0344ed624d90de8ea587ff.edea728f2967c81b245ed3ff79c4897795dd1a8d91736f976f36f5c53dafb815.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/snli/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/5e10e23a1db8375c6fccebefdb2195f7925cfca3dd0344ed624d90de8ea587ff.edea728f2967c81b245ed3ff79c4897795dd1a8d91736f976f36f5c53dafb815.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d552e4cb4c842ff8d848b3a212d84c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/snli/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/5e10e23a1db8375c6fccebefdb2195f7925cfca3dd0344ed624d90de8ea587ff.edea728f2967c81b245ed3ff79c4897795dd1a8d91736f976f36f5c53dafb815\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/snli/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/5e10e23a1db8375c6fccebefdb2195f7925cfca3dd0344ed624d90de8ea587ff.edea728f2967c81b245ed3ff79c4897795dd1a8d91736f976f36f5c53dafb815\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/5e10e23a1db8375c6fccebefdb2195f7925cfca3dd0344ed624d90de8ea587ff.edea728f2967c81b245ed3ff79c4897795dd1a8d91736f976f36f5c53dafb815\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/5e10e23a1db8375c6fccebefdb2195f7925cfca3dd0344ed624d90de8ea587ff.edea728f2967c81b245ed3ff79c4897795dd1a8d91736f976f36f5c53dafb815\n",
            "No config specified, defaulting to the single config: snli/plain_text\n",
            "INFO:datasets.builder:No config specified, defaulting to the single config: snli/plain_text\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/snli/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/snli/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 45 from snli validation\n",
            "take 182 from snli train\n",
            "Done getting streams/reloading from snli\n",
            "done val language check\n",
            "done train language check\n",
            "trying multi_nli initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/multi_nli/resolve/main/multi_nli.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/e4060d56cfc5e7bc6bb77aa91b0ef422172ed72bea2670214eb4536c31396fe8.0656fd8e33127605464f7e93b7c95ed73e6dd7d1606db8e96cccbaa85c220a34.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/multi_nli/resolve/main/multi_nli.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/e4060d56cfc5e7bc6bb77aa91b0ef422172ed72bea2670214eb4536c31396fe8.0656fd8e33127605464f7e93b7c95ed73e6dd7d1606db8e96cccbaa85c220a34.py.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef41b64939ce43f5bf0a7e2a2c34e5b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/multi_nli/resolve/main/multi_nli.py in cache at /root/.cache/huggingface/datasets/downloads/e4060d56cfc5e7bc6bb77aa91b0ef422172ed72bea2670214eb4536c31396fe8.0656fd8e33127605464f7e93b7c95ed73e6dd7d1606db8e96cccbaa85c220a34.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/multi_nli/resolve/main/multi_nli.py in cache at /root/.cache/huggingface/datasets/downloads/e4060d56cfc5e7bc6bb77aa91b0ef422172ed72bea2670214eb4536c31396fe8.0656fd8e33127605464f7e93b7c95ed73e6dd7d1606db8e96cccbaa85c220a34.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/e4060d56cfc5e7bc6bb77aa91b0ef422172ed72bea2670214eb4536c31396fe8.0656fd8e33127605464f7e93b7c95ed73e6dd7d1606db8e96cccbaa85c220a34.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/e4060d56cfc5e7bc6bb77aa91b0ef422172ed72bea2670214eb4536c31396fe8.0656fd8e33127605464f7e93b7c95ed73e6dd7d1606db8e96cccbaa85c220a34.py\n",
            "https://huggingface.co/datasets/multi_nli/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/6f711c5a9730f623e07151c7edac50ba41682b5ec6600747a34fdcf1a6a148f8.ecf4f1bed49e8bba8f4a0df940d2c152c2c969a14b08b2d9a742cb031512ae2c.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/multi_nli/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/6f711c5a9730f623e07151c7edac50ba41682b5ec6600747a34fdcf1a6a148f8.ecf4f1bed49e8bba8f4a0df940d2c152c2c969a14b08b2d9a742cb031512ae2c.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ebeabb6e81f466bb2e5c587f475d58c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.88k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/multi_nli/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/6f711c5a9730f623e07151c7edac50ba41682b5ec6600747a34fdcf1a6a148f8.ecf4f1bed49e8bba8f4a0df940d2c152c2c969a14b08b2d9a742cb031512ae2c\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/multi_nli/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/6f711c5a9730f623e07151c7edac50ba41682b5ec6600747a34fdcf1a6a148f8.ecf4f1bed49e8bba8f4a0df940d2c152c2c969a14b08b2d9a742cb031512ae2c\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/6f711c5a9730f623e07151c7edac50ba41682b5ec6600747a34fdcf1a6a148f8.ecf4f1bed49e8bba8f4a0df940d2c152c2c969a14b08b2d9a742cb031512ae2c\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/6f711c5a9730f623e07151c7edac50ba41682b5ec6600747a34fdcf1a6a148f8.ecf4f1bed49e8bba8f4a0df940d2c152c2c969a14b08b2d9a742cb031512ae2c\n",
            "https://huggingface.co/datasets/multi_nli/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2805917a1bce309cd8d8bb953584da44bee148e9fb818ab189cbf85501ffb510.180cc34931bb6484265f249bb1d278376ca84adc3c921211e0a5b52a7a67d782.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/multi_nli/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2805917a1bce309cd8d8bb953584da44bee148e9fb818ab189cbf85501ffb510.180cc34931bb6484265f249bb1d278376ca84adc3c921211e0a5b52a7a67d782.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54027a2d3bf240388116336d153cb6d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/multi_nli/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/2805917a1bce309cd8d8bb953584da44bee148e9fb818ab189cbf85501ffb510.180cc34931bb6484265f249bb1d278376ca84adc3c921211e0a5b52a7a67d782\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/multi_nli/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/2805917a1bce309cd8d8bb953584da44bee148e9fb818ab189cbf85501ffb510.180cc34931bb6484265f249bb1d278376ca84adc3c921211e0a5b52a7a67d782\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/2805917a1bce309cd8d8bb953584da44bee148e9fb818ab189cbf85501ffb510.180cc34931bb6484265f249bb1d278376ca84adc3c921211e0a5b52a7a67d782\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/2805917a1bce309cd8d8bb953584da44bee148e9fb818ab189cbf85501ffb510.180cc34931bb6484265f249bb1d278376ca84adc3c921211e0a5b52a7a67d782\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/multi_nli/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/multi_nli/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 90 from multi_nli validation\n",
            "take 364 from multi_nli train\n",
            "Done getting streams/reloading from multi_nli\n",
            "done val language check\n",
            "done train language check\n",
            "trying tum-nlp/cannot-dataset initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/tum-nlp/cannot-dataset/resolve/bb311cd81a019620d8a07179edc325d0d6eff3d0/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/1753e0c317119e8c1a526a7b94c6013ef49c3b02b30ee1772bbdff0b9ec535ee.ac785a6ee2f2ca4316300d6735799ecb267bfd9a397b935056703fcc84a698af.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/tum-nlp/cannot-dataset/resolve/bb311cd81a019620d8a07179edc325d0d6eff3d0/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/1753e0c317119e8c1a526a7b94c6013ef49c3b02b30ee1772bbdff0b9ec535ee.ac785a6ee2f2ca4316300d6735799ecb267bfd9a397b935056703fcc84a698af.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4c84bb6090644d3a7840c67f308dccb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.51k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/tum-nlp/cannot-dataset/resolve/bb311cd81a019620d8a07179edc325d0d6eff3d0/README.md in cache at /root/.cache/huggingface/datasets/downloads/1753e0c317119e8c1a526a7b94c6013ef49c3b02b30ee1772bbdff0b9ec535ee.ac785a6ee2f2ca4316300d6735799ecb267bfd9a397b935056703fcc84a698af\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/tum-nlp/cannot-dataset/resolve/bb311cd81a019620d8a07179edc325d0d6eff3d0/README.md in cache at /root/.cache/huggingface/datasets/downloads/1753e0c317119e8c1a526a7b94c6013ef49c3b02b30ee1772bbdff0b9ec535ee.ac785a6ee2f2ca4316300d6735799ecb267bfd9a397b935056703fcc84a698af\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/1753e0c317119e8c1a526a7b94c6013ef49c3b02b30ee1772bbdff0b9ec535ee.ac785a6ee2f2ca4316300d6735799ecb267bfd9a397b935056703fcc84a698af\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/1753e0c317119e8c1a526a7b94c6013ef49c3b02b30ee1772bbdff0b9ec535ee.ac785a6ee2f2ca4316300d6735799ecb267bfd9a397b935056703fcc84a698af\n",
            "Using custom data configuration default-d7d1b17ffb51affc\n",
            "INFO:datasets.builder:Using custom data configuration default-d7d1b17ffb51affc\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 90 from tum-nlp/cannot-dataset validation\n",
            "take 364 from tum-nlp/cannot-dataset train\n",
            "Done getting streams/reloading from tum-nlp/cannot-dataset\n",
            "done val language check\n",
            "done train language check\n",
            "trying heegyu/news-category-dataset initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/heegyu/news-category-dataset/resolve/304a05a55bc6abc0446d8fae0d0771716b6a271a/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7b348ded798c70e2b853af42585429d5382d9811e56eda3a395f504a8649f9cb.45120473e625c080737e518969025d9a18cbc67c0349d1d4485dde6920714f17.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/heegyu/news-category-dataset/resolve/304a05a55bc6abc0446d8fae0d0771716b6a271a/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7b348ded798c70e2b853af42585429d5382d9811e56eda3a395f504a8649f9cb.45120473e625c080737e518969025d9a18cbc67c0349d1d4485dde6920714f17.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93d4f2893b8c47f388f2fd118fa8a0e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/101 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/heegyu/news-category-dataset/resolve/304a05a55bc6abc0446d8fae0d0771716b6a271a/README.md in cache at /root/.cache/huggingface/datasets/downloads/7b348ded798c70e2b853af42585429d5382d9811e56eda3a395f504a8649f9cb.45120473e625c080737e518969025d9a18cbc67c0349d1d4485dde6920714f17\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/heegyu/news-category-dataset/resolve/304a05a55bc6abc0446d8fae0d0771716b6a271a/README.md in cache at /root/.cache/huggingface/datasets/downloads/7b348ded798c70e2b853af42585429d5382d9811e56eda3a395f504a8649f9cb.45120473e625c080737e518969025d9a18cbc67c0349d1d4485dde6920714f17\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/7b348ded798c70e2b853af42585429d5382d9811e56eda3a395f504a8649f9cb.45120473e625c080737e518969025d9a18cbc67c0349d1d4485dde6920714f17\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/7b348ded798c70e2b853af42585429d5382d9811e56eda3a395f504a8649f9cb.45120473e625c080737e518969025d9a18cbc67c0349d1d4485dde6920714f17\n",
            "Using custom data configuration default-b97a6085eeea7052\n",
            "INFO:datasets.builder:Using custom data configuration default-b97a6085eeea7052\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 45 from heegyu/news-category-dataset validation\n",
            "take 182 from heegyu/news-category-dataset train\n",
            "Done getting streams/reloading from heegyu/news-category-dataset\n",
            "done val language check\n",
            "done train language check\n",
            "trying fkdosilovic/docee-event-classification initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/fkdosilovic/docee-event-classification/resolve/548191053344a231c016a74927e87fae9fef786d/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/49d31aa66efbac6d5392e968e5cd0f5f181670fb0cc4c629e5565f32096445bd.65a2b89e109a3d234b3728360707fd282295f0fdda7688ae4ae3eb2a4348c556.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/fkdosilovic/docee-event-classification/resolve/548191053344a231c016a74927e87fae9fef786d/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/49d31aa66efbac6d5392e968e5cd0f5f181670fb0cc4c629e5565f32096445bd.65a2b89e109a3d234b3728360707fd282295f0fdda7688ae4ae3eb2a4348c556.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8c1e448fcc84881898158a453e1b003",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/fkdosilovic/docee-event-classification/resolve/548191053344a231c016a74927e87fae9fef786d/README.md in cache at /root/.cache/huggingface/datasets/downloads/49d31aa66efbac6d5392e968e5cd0f5f181670fb0cc4c629e5565f32096445bd.65a2b89e109a3d234b3728360707fd282295f0fdda7688ae4ae3eb2a4348c556\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/fkdosilovic/docee-event-classification/resolve/548191053344a231c016a74927e87fae9fef786d/README.md in cache at /root/.cache/huggingface/datasets/downloads/49d31aa66efbac6d5392e968e5cd0f5f181670fb0cc4c629e5565f32096445bd.65a2b89e109a3d234b3728360707fd282295f0fdda7688ae4ae3eb2a4348c556\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/49d31aa66efbac6d5392e968e5cd0f5f181670fb0cc4c629e5565f32096445bd.65a2b89e109a3d234b3728360707fd282295f0fdda7688ae4ae3eb2a4348c556\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/49d31aa66efbac6d5392e968e5cd0f5f181670fb0cc4c629e5565f32096445bd.65a2b89e109a3d234b3728360707fd282295f0fdda7688ae4ae3eb2a4348c556\n",
            "Using custom data configuration default-6c165a7220961fec\n",
            "INFO:datasets.builder:Using custom data configuration default-6c165a7220961fec\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 45 from fkdosilovic/docee-event-classification validation\n",
            "take 182 from fkdosilovic/docee-event-classification train\n",
            "Done getting streams/reloading from fkdosilovic/docee-event-classification\n",
            "done val language check\n",
            "done train language check\n",
            "trying DeveloperOats/DBPedia_Classes initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes/resolve/4d0aa96069f24063697e4df63b95be78d3f7fb7d/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7611d402e4d9a7b91d21c8ccb80928a9222bd98be3459d3e6ef4912c16630bab.c8502bb00ba1225bb8d96e77de386e235233885110c0320eab09e5f07f8dd2bd.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes/resolve/4d0aa96069f24063697e4df63b95be78d3f7fb7d/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/7611d402e4d9a7b91d21c8ccb80928a9222bd98be3459d3e6ef4912c16630bab.c8502bb00ba1225bb8d96e77de386e235233885110c0320eab09e5f07f8dd2bd.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ab8d0701eb54f4d8d43ebdb4f9d582c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes/resolve/4d0aa96069f24063697e4df63b95be78d3f7fb7d/README.md in cache at /root/.cache/huggingface/datasets/downloads/7611d402e4d9a7b91d21c8ccb80928a9222bd98be3459d3e6ef4912c16630bab.c8502bb00ba1225bb8d96e77de386e235233885110c0320eab09e5f07f8dd2bd\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/DeveloperOats/DBPedia_Classes/resolve/4d0aa96069f24063697e4df63b95be78d3f7fb7d/README.md in cache at /root/.cache/huggingface/datasets/downloads/7611d402e4d9a7b91d21c8ccb80928a9222bd98be3459d3e6ef4912c16630bab.c8502bb00ba1225bb8d96e77de386e235233885110c0320eab09e5f07f8dd2bd\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/7611d402e4d9a7b91d21c8ccb80928a9222bd98be3459d3e6ef4912c16630bab.c8502bb00ba1225bb8d96e77de386e235233885110c0320eab09e5f07f8dd2bd\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/7611d402e4d9a7b91d21c8ccb80928a9222bd98be3459d3e6ef4912c16630bab.c8502bb00ba1225bb8d96e77de386e235233885110c0320eab09e5f07f8dd2bd\n",
            "Using custom data configuration default-b8c8b2ecb255bab7\n",
            "INFO:datasets.builder:Using custom data configuration default-b8c8b2ecb255bab7\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 45 from DeveloperOats/DBPedia_Classes validation\n",
            "take 182 from DeveloperOats/DBPedia_Classes train\n",
            "Done getting streams/reloading from DeveloperOats/DBPedia_Classes\n",
            "done val language check\n",
            "done train language check\n",
            "trying DeveloperOats/DBPedia_Classes initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-b8c8b2ecb255bab7\n",
            "INFO:datasets.builder:Using custom data configuration default-b8c8b2ecb255bab7\n",
            "Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 45 from DeveloperOats/DBPedia_Classes validation\n",
            "take 182 from DeveloperOats/DBPedia_Classes train\n",
            "Done getting streams/reloading from DeveloperOats/DBPedia_Classes\n",
            "done val language check\n",
            "done train language check\n",
            "trying casehold/casehold initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/datasets/casehold/casehold/resolve/main/casehold.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/c1f8f42083675b9c5c9effa081e8dc6d0beacd92e300ae82adc7814c365c491e.8ef4d3cdd8817871dcf0bbf785ae714db56e377984f9c2adfec4fb7982a03091.py.incomplete\n",
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/casehold/casehold/resolve/main/casehold.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/c1f8f42083675b9c5c9effa081e8dc6d0beacd92e300ae82adc7814c365c491e.8ef4d3cdd8817871dcf0bbf785ae714db56e377984f9c2adfec4fb7982a03091.py.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e959b2e1fc7460899db727adb156c2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/datasets/casehold/casehold/resolve/main/casehold.py in cache at /root/.cache/huggingface/datasets/downloads/c1f8f42083675b9c5c9effa081e8dc6d0beacd92e300ae82adc7814c365c491e.8ef4d3cdd8817871dcf0bbf785ae714db56e377984f9c2adfec4fb7982a03091.py\n",
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/casehold/casehold/resolve/main/casehold.py in cache at /root/.cache/huggingface/datasets/downloads/c1f8f42083675b9c5c9effa081e8dc6d0beacd92e300ae82adc7814c365c491e.8ef4d3cdd8817871dcf0bbf785ae714db56e377984f9c2adfec4fb7982a03091.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/c1f8f42083675b9c5c9effa081e8dc6d0beacd92e300ae82adc7814c365c491e.8ef4d3cdd8817871dcf0bbf785ae714db56e377984f9c2adfec4fb7982a03091.py\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/c1f8f42083675b9c5c9effa081e8dc6d0beacd92e300ae82adc7814c365c491e.8ef4d3cdd8817871dcf0bbf785ae714db56e377984f9c2adfec4fb7982a03091.py\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/casehold--casehold/56b9c04b77aae7ed78ede73bbabef236b72e73e2bbda22f66dfcdb8465985b0b\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/casehold--casehold/56b9c04b77aae7ed78ede73bbabef236b72e73e2bbda22f66dfcdb8465985b0b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 45 from casehold/casehold validation\n",
            "take 182 from casehold/casehold train\n",
            "Done getting streams/reloading from casehold/casehold\n",
            "done val language check\n",
            "done train language check\n",
            "trying casehold/casehold initialization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/casehold--casehold/56b9c04b77aae7ed78ede73bbabef236b72e73e2bbda22f66dfcdb8465985b0b\n",
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/casehold--casehold/56b9c04b77aae7ed78ede73bbabef236b72e73e2bbda22f66dfcdb8465985b0b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "take 45 from casehold/casehold validation\n",
            "take 182 from casehold/casehold train\n",
            "Done getting streams/reloading from casehold/casehold\n",
            "done val language check\n",
            "done train language check\n",
            "Done collecting CLS streaming data\n",
            "saving streamed CLS validation data: cache_val_cls.pkl\n",
            "saving streamed CLS training for epoch 0: cache_train_cls_000.pkl\n"
          ]
        }
      ],
      "source": [
        "clsdata_streaming_config = {\n",
        "    'files':cls_files,\n",
        "    'max_seq_length':512,\n",
        "    'val_size':500,\n",
        "    'train_chunk_size':2000,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "cls_statics_datsets = initialize_and_get_classification_streaming_datasets(\n",
        "    data_streaming_config=clsdata_streaming_config,\n",
        "    streaming_cleaning_functions=cls_streaming_cleaning_functions,\n",
        "    start_proportion = None,\n",
        "    epoch=0,\n",
        "    seed=42,\n",
        "    path_to_val_cache = 'cache_val_cls.pkl',\n",
        "    path_to_train_cache_epoch = 'cache_train_cls_%03g.pkl',\n",
        "    do_check_english = True,\n",
        "    name = 'CLS' #\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioHTHynKZ4Zq"
      },
      "outputs": [],
      "source": [
        "!rm *.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4-gXxVquzJZ"
      },
      "outputs": [],
      "source": [
        "# TODO - make dataloaders for pair_classification, classification, and next-sentence-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F92fGv0NTmT6"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as torch_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3tDKE1QPz9q"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DatasetPairClassification(torch_data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        list_of_data=None,\n",
        "        text1_name ='pair1',\n",
        "        text2_name ='pair2',\n",
        "        label_name = 'label',\n",
        "        datasetname_name = 'cls_id',\n",
        "        classificationtype_name = 'type',\n",
        "        nlabels_name = 'n_labels',\n",
        "        seed = 42\n",
        "    ):\n",
        "        self.data = {} # internal data preprocessed\n",
        "        self.datasets = [] # list of names of datasets in Dataset class\n",
        "        self.label2int = {} #maps {label:int} dictionary\n",
        "        self.label2dataset = {} #maps {label:mask}\n",
        "        self.label2mask = {}\n",
        "        self.dataset_classification_types = {} # dataset types (pair-classification, classificaiton)\n",
        "        self.text1_name = text1_name\n",
        "        self.text2_name = text2_name\n",
        "        self.label_name = label_name#'label',\n",
        "        self.datasetname_name = datasetname_name #'cls_id',\n",
        "        self.classificationtype_name = classificationtype_name#'type',\n",
        "        self.nlabels_name = nlabels_name #'n_labels'\n",
        "        self.seed = seed\n",
        "\n",
        "        # random state\n",
        "        self.np_random = np.random.RandomState(seed)\n",
        "\n",
        "        if list_of_data is not None and len(list_of_data)>0:\n",
        "\n",
        "            # loop through the data and add each triplets: export a panda df as final data\n",
        "            self.df = self.process(list_of_data, False)\n",
        "\n",
        "    def process(self, list_of_data, inplace=True):\n",
        "        \"\"\"convert the raw examples to dataset\"\"\"\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(\n",
        "            list_of_data = list_of_data\n",
        "        )\n",
        "\n",
        "        # add positives to self.data\n",
        "        self._find_positives_and_add_to_data()\n",
        "\n",
        "        # add negatives to self.data\n",
        "        self._find_negatives_and_add_to_data()\n",
        "\n",
        "        # make mask for loss function\n",
        "        self._convert_labelint_to_vectors()\n",
        "\n",
        "        # make mask for loss function\n",
        "        self._make_mask()\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        data_flatten = self.flatten_data(self.data)\n",
        "        if not inplace:\n",
        "            return data_flatten\n",
        "        self.df = data_flatten\n",
        "\n",
        "    def _loop_through_list_of_data_and_add_to_selfdata(\n",
        "            self,\n",
        "            list_of_data\n",
        "        ):\n",
        "        \"\"\"loops through and adds the text pair and label\"\"\"\n",
        "        for raw_example in list_of_data:\n",
        "\n",
        "            # add each element to the data\n",
        "            self._add_unit_to_data(\n",
        "                text1 = raw_example[self.text1_name],\n",
        "                text2= raw_example[self.text2_name],\n",
        "                label= raw_example[self.label_name],\n",
        "                n_labels= raw_example[self.nlabels_name],\n",
        "                dataset_name= raw_example[self.datasetname_name],\n",
        "                method = raw_example[self.classificationtype_name]\n",
        "            )\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"Finds data with the same label, and adds them as positives\"\"\"\n",
        "        which_clsdatasets_lack_positives = [\n",
        "            datasetname for datasetname, datasettype\n",
        "            in self.dataset_classification_types.items()\n",
        "            if datasettype == 'classification'\n",
        "        ]\n",
        "        for datasetname in which_clsdatasets_lack_positives:\n",
        "\n",
        "            # all unique labels in subdataset\n",
        "            ulabels_in_clsdataset = sorted(list(set([\n",
        "                (d['class'],d['label']) for d in self.data[datasetname]\n",
        "                if d['label'] == self.label2int['%s_%d' % (datasetname, 1)]\n",
        "            ])))\n",
        "\n",
        "            # loop through label classes\n",
        "            for labelclass,label in ulabels_in_clsdataset:\n",
        "\n",
        "                # other samples with the same class (and positive)\n",
        "                # `class` is the original dataset class, label = {different, same}\n",
        "                idx_this_class = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] == labelclass and d['label']==label\n",
        "                ]\n",
        "\n",
        "                idx_this_class_need_positives = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] == labelclass and d['label']==label\n",
        "                    and d['text2'] is None\n",
        "                ]\n",
        "\n",
        "                # subsample within by permutation\n",
        "                idx_sample_within = self.np_random.permutation(idx_this_class)\n",
        "\n",
        "                # get text of permuted-indicies, assign as positive for each sample\n",
        "                for i,j in zip(idx_this_class_need_positives, idx_sample_within[:len(idx_this_class_need_positives)]):\n",
        "\n",
        "                    self.data[datasetname][i]['text2'] = self.data[datasetname][j]['text1']\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "        \"\"\"Finds data with the same label, and adds them as positives\"\"\"\n",
        "        which_clsdatasets_lack_negatives = [\n",
        "            datasetname for datasetname, datasettype\n",
        "            in self.dataset_classification_types.items()\n",
        "            if datasettype == 'classification'\n",
        "        ]\n",
        "        for datasetname in which_clsdatasets_lack_negatives:\n",
        "\n",
        "            # all unique labels in subdataset\n",
        "            ulabels_in_clsdataset = sorted(list(set([\n",
        "                (d['class'],d['label']) for d in self.data[datasetname]\n",
        "                if d['label'] == self.label2int['%s_%d' % (datasetname, 0)]\n",
        "            ])))\n",
        "\n",
        "            # loop through label classes\n",
        "            for labelclass,label in ulabels_in_clsdataset:\n",
        "\n",
        "                # other samples with the same class (and positive)\n",
        "                # `class` is the original dataset class, label = {different, same}\n",
        "                idx_this_class = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] == labelclass and d['label']==label\n",
        "                ]\n",
        "                # indices of all other data\n",
        "                idx_this_other_class = [\n",
        "                    i for i,d\n",
        "                    in enumerate(self.data[datasetname])\n",
        "                    if d['class'] != labelclass\n",
        "                ]\n",
        "\n",
        "                # subsample within by permutation\n",
        "                idx_sample_otherlabels= self.np_random.choice(idx_this_other_class, size =len(idx_this_class))\n",
        "\n",
        "                # get text of permuted-indicies, assign as positive for each sample\n",
        "                for i,j in zip(idx_this_class, idx_sample_otherlabels):\n",
        "\n",
        "                    self.data[datasetname][i]['text2'] = self.data[datasetname][j]['text1']\n",
        "\n",
        "    def _convert_labelint_to_vectors(self):\n",
        "        \"\"\"Loops through data and converts each labelinteger into a vector for multi-label loss\"\"\"\n",
        "        for datasetname, dataset in self.data.items():\n",
        "            for example in dataset:\n",
        "                example.update({\n",
        "                    'labelvector':self._convert_labelint_to_vector([example['label']])\n",
        "                })\n",
        "\n",
        "    def _convert_labelint_to_vector(self, labelints):\n",
        "        \"\"\"Loops through data and converts each labelinteger into a vector for multi-label loss\"\"\"\n",
        "        v = np.zeros(len(self.label2int))\n",
        "        for labelint in labelints:\n",
        "            v[labelint]=1\n",
        "        return v\n",
        "\n",
        "    def _make_mask(self):\n",
        "        \"\"\"for each sample, the loss should only pertain to labels within the same dataset, not other datasets -- by masking\"\"\"\n",
        "        if (\n",
        "            len(self.label2mask)!=self.label2dataset\n",
        "        ) or bool(\n",
        "            set(list(self.label2mask.keys())).symmetric_differnce(set(list(self.label2dataset.keys())))\n",
        "        ):\n",
        "            # make the self.label2mask\n",
        "            for label,dataset in self.label2dataset.items():\n",
        "                #\n",
        "                self.label2mask[self.label2int[label]] = self._convert_labelint_to_vector([\n",
        "                    self.label2int[l] for l,dset in self.label2dataset.items() if dset==dataset\n",
        "                ])\n",
        "\n",
        "        # loop through data and insert mask into each sample\n",
        "        for datasetname, dataset in self.data.items():\n",
        "            for example in dataset:\n",
        "                example.update({\n",
        "                    'mask':self.label2mask[example['label']]\n",
        "                })\n",
        "\n",
        "    def _add_labels_to_label2int(self, dataset_labels_as_globalname, dataset_name):\n",
        "        for globallabel in dataset_labels_as_globalname:\n",
        "            if globallabel not in self.label2int.keys():\n",
        "                next_label_int = len(self.label2int)\n",
        "                self.label2int[globallabel] = next_label_int\n",
        "                self.label2dataset[globallabel] = dataset_name\n",
        "\n",
        "    def _add_unit_to_data(\n",
        "        self,\n",
        "        text1,\n",
        "        text2,\n",
        "        label,\n",
        "        n_labels,\n",
        "        dataset_name,\n",
        "        method\n",
        "    ):\n",
        "        \"\"\"Adds one unit of processed data to the internal self.data\"\"\"\n",
        "        if method == 'pair_classification':\n",
        "\n",
        "            # pair classification: two texts with a label of the relationship between pair\n",
        "            self._add_text_pair_to_data(\n",
        "                text1,\n",
        "                text2,\n",
        "                label,\n",
        "                n_labels,\n",
        "                dataset_name\n",
        "            )\n",
        "\n",
        "        elif method == 'classification':\n",
        "\n",
        "            # classification: single texts, with negatives needing to be deduced later\n",
        "            self._add_textclass_to_data(\n",
        "                text1,\n",
        "                label,\n",
        "                dataset_name\n",
        "            )\n",
        "\n",
        "    def _add_text_pair_to_data(\n",
        "        self,\n",
        "        text1,\n",
        "        text2,\n",
        "        label,\n",
        "        n_labels,\n",
        "        dataset_name\n",
        "    ):\n",
        "        \"\"\"add a text pair to the self data: specifically for pair_classification\"\"\"\n",
        "        if dataset_name not in self.data.keys():\n",
        "            print('encountered new dataset for pair-classification: %s' % dataset_name)\n",
        "            self.data[dataset_name] = []\n",
        "            self.datasets += [dataset_name]\n",
        "            self.dataset_classification_types[dataset_name] = 'pair_classification'\n",
        "\n",
        "            # common naming for all labels across all datasets\n",
        "            dataset_labels_as_globalname = [\n",
        "                \"%s_%d\" % (dataset_name, l) for l in range(n_labels)\n",
        "            ]\n",
        "\n",
        "            self._add_labels_to_label2int(dataset_labels_as_globalname, dataset_name)\n",
        "\n",
        "        if text2 is not None:\n",
        "\n",
        "            self.data[dataset_name].append({\n",
        "                'text1':text1,\n",
        "                'text2':text2,\n",
        "                'label':self.label2int[\"%s_%d\" % (dataset_name, label)],\n",
        "                'mask':None\n",
        "            })\n",
        "\n",
        "    def _add_textclass_to_data(\n",
        "        self,\n",
        "        text,\n",
        "        classlabel,\n",
        "        dataset_name\n",
        "    ):\n",
        "        \"\"\"add a text to the self data: specifically for classification\"\"\"\n",
        "        if dataset_name not in self.data.keys():\n",
        "            print('encountered new dataset for classification: %s' % dataset_name)\n",
        "            self.data[dataset_name] = []\n",
        "            # register dataset to list of datasets\n",
        "            self.datasets += [dataset_name]\n",
        "            # map datset classification types\n",
        "            self.dataset_classification_types[dataset_name] = 'classification'\n",
        "\n",
        "            # common naming for all labels across all datasets\n",
        "            dataset_labels_as_globalname = [\n",
        "                \"%s_%d\" % (dataset_name, l) for l in [0,1]\n",
        "            ]\n",
        "\n",
        "            self._add_labels_to_label2int(dataset_labels_as_globalname, dataset_name)\n",
        "\n",
        "        # positives and negatives must be added seperately (same label, different label)\n",
        "        for label in [0,1]:\n",
        "\n",
        "            self.data[dataset_name].append({\n",
        "                'text1':text,\n",
        "                'text2':None,\n",
        "                'mask':None,\n",
        "                'label':self.label2int[\"%s_%d\" % (dataset_name, label)],\n",
        "                'class':classlabel\n",
        "            })\n",
        "\n",
        "    def flatten_data(self, data):\n",
        "        \"\"\"Converts data to a giant list\"\"\"\n",
        "        data_all_flat = []\n",
        "        for datasetname, subdataset in self.data.items():\n",
        "            data_all_flat += subdataset\n",
        "        return data_all_flat\n",
        "\n",
        "    def integrate_another_dataset(\n",
        "        self,\n",
        "        list_of_newdata,\n",
        "        function_to_reformatdata,\n",
        "        dataset_name\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Adds new data to the existing self.df\n",
        "        Arguments:\n",
        "        :param list_of_newdata: list of data to integrate/add\n",
        "        :function_to_reformatdata: function that converts the data in list_of_newdata[idx]\n",
        "        \"\"\"\n",
        "        # check that the unit of data has the required fields\n",
        "        newtestdata = function_to_reformatdata(list_of_newdata[0])\n",
        "        assert isinstance(newtestdata, list), 'function_to_reformatdata must output a list of reformated data'\n",
        "        assert not bool(set(['text1','text2','class']).difference(set(newtestdata[0].keys()))), 'new data must have `text1`, `text2`,`class`'\n",
        "        classlabels = set()\n",
        "        newdata_converted_all = []\n",
        "\n",
        "        # loop through and convert all data to acceptable format for internal datasets\n",
        "        for newdata in list_of_newdata:\n",
        "            newdata_converted = function_to_reformatdata(newdata)\n",
        "            for unit in newdata_converted:\n",
        "                classlabels |= set([unit['class']])\n",
        "            newdata_converted_all += newdata_converted\n",
        "\n",
        "        # loop through and ingest all converted data into the self.data internal dataset\n",
        "        for unit in newdata_converted_all:\n",
        "            self._add_text_pair_to_data(\n",
        "                text1=unit['text1'],\n",
        "                text2=unit['text2'],\n",
        "                label=unit['class'],\n",
        "                n_labels=len(classlabels),\n",
        "                dataset_name=dataset_name\n",
        "            )\n",
        "        # remake the mask for ALL data, given the new label sets\n",
        "        self._convert_labelint_to_vectors()\n",
        "        # make mask for loss function\n",
        "        self._make_mask()\n",
        "        # harden the dataset to pandas dataframe\n",
        "        data_flatten = self.flatten_data(self.data)\n",
        "        self.df = data_flatten\n",
        "        print('done integrating new dataset %s' % dataset_name)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.df[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7itnwQwZYPh",
        "outputId": "92650ad4-746d-43bc-f5d9-2eae62d9c12e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encountered new dataset for pair-classification: snli\n",
            "encountered new dataset for pair-classification: mnli\n",
            "encountered new dataset for pair-classification: cannotdataset\n",
            "encountered new dataset for classification: newscategory\n",
            "encountered new dataset for classification: doceeevents\n",
            "encountered new dataset for classification: dbpedia_l2\n",
            "encountered new dataset for classification: dbpedia_l3\n",
            "encountered new dataset for pair-classification: casehold\n",
            "Size of pair-classification dataset 2714\n"
          ]
        }
      ],
      "source": [
        "# initialize the (empty) CLS-dataset\n",
        "dataset_paircls = DatasetPairClassification(\n",
        "    list_of_data=None,\n",
        "    text1_name ='pair1',\n",
        "    text2_name ='pair2',\n",
        "    label_name = 'label',\n",
        "    datasetname_name = 'cls_id',\n",
        "    classificationtype_name = 'type',\n",
        "    nlabels_name = 'n_labels',\n",
        "    seed = 42\n",
        ")\n",
        "\n",
        "# add the data to empty datas\n",
        "dataset_paircls.process(cls_statics_datsets['train'], inplace=True)\n",
        "\n",
        "print('Size of pair-classification dataset %d' % len(dataset_paircls))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3iyAQPEc8JR",
        "outputId": "1618cb9b-3d7f-4b3e-c498-8763a3f3eee5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text1': 'of child\\'s best interests). 13 . Sylvia asserts that she would have pursued a different trial strategy had she known that OCS intended to assert mental illness as a basis for termination, but she gives no specifics. In fact, Sylvia\\'s mental illness was a significant issue at trial, and her need for well-directed treatment of it is the focus of her \"active efforts\" argument on this appeal, as addressed later in this opinion. 14 . See, eg., Sherman B. v. State, Dep\\'t of Health & Soc. Servs., Office of Children\\'s Servs., 290 P.3d 421, 431 (Alaska 2012) (\"Because we affirm the superior court\\'s finding of abandonment, we do not reach the State\\'s alternative argument for termination based on neglect.\"). 15 . See Alderman v. Iditarod Props., Inc., 32 P.3d 373, 395-96 (Alaska 2001) ',\n",
              " 'text2': 'holding district court abused discretion in denying leave to amend complaint to add claim when party opposing motion made no showing of prejudice from delay',\n",
              " 'label': 16,\n",
              " 'mask': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        1.]),\n",
              " 'labelvector': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0.])}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_paircls[-100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsnUJOGkPz33",
        "outputId": "560bd200-a95c-4a40-f5cd-0e7ea4266d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done integrating new dataset nextsentence\n",
            "Size of pair-classification dataset 7986\n",
            "types of datasets in classification task:\n",
            "{'snli': 'pair_classification', 'mnli': 'pair_classification', 'cannotdataset': 'pair_classification', 'newscategory': 'classification', 'doceeevents': 'classification', 'dbpedia_l2': 'classification', 'dbpedia_l3': 'classification', 'casehold': 'pair_classification', 'nextsentence': 'pair_classification'}\n"
          ]
        }
      ],
      "source": [
        "## integrate the nextsentence data\n",
        "def function_to_reformatnextsentence(x):\n",
        "    \"\"\"reformats a triplet into one positive pair and one negative pair\"\"\"\n",
        "    return [\n",
        "        {\"text1\":x['anchor'], \"text2\":x['next'], \"class\":1},\n",
        "        {\"text1\":x['anchor'], \"text2\":x['opposite'], \"class\":0},\n",
        "    ]\n",
        "\n",
        "# integrate the next sentence data\n",
        "dataset_paircls.integrate_another_dataset(\n",
        "    list_of_newdata = dataset_static_mlm['train']['nextsentence'],\n",
        "    function_to_reformatdata = function_to_reformatnextsentence,\n",
        "    dataset_name = 'nextsentence'\n",
        ")\n",
        "\n",
        "print('Size of pair-classification dataset %d' % len(dataset_paircls))\n",
        "\n",
        "print('types of datasets in classification task:')\n",
        "print(dataset_paircls.dataset_classification_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o7-J10UglUG",
        "outputId": "040f7b21-25c1-4522-9d33-94464ffc98c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text1': \"Breathe Easy, Jar Jar Binks Won't Be In 'Star Wars: The Force Awakens'. Crisis averted.\",\n",
              " 'text2': 'Omarion Wasn\\'t Happy About Grammy Nomination Snub. \"As an artist you look forward to being acknowledged by the game.\"',\n",
              " 'mask': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.]),\n",
              " 'label': 9,\n",
              " 'class': 32,\n",
              " 'labelvector': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.])}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_paircls[1006]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81QaRC0Pg34D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PCG8JHCz3Xzp"
      ],
      "authorship_tag": "ABX9TyN+BRS/wM2DW/4vHY9WjYMc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00001f9f055045f9ae35f94f76be8fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16dd57325504698b35f155d1bd040b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7950d803ab5b4c4ab10dc9e0902e34b1",
            "value": 1
          }
        },
        "0003c5e497294b5abf83ff5edbf90261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28542ed3d1b443c9a7ba7074825ee208",
              "IPY_MODEL_7c01fc1aabb0486f9f1f0674b46b5481",
              "IPY_MODEL_6b349f8f7890488eaa05b156ec971bf6"
            ],
            "layout": "IPY_MODEL_1602c7712db64b829a6ed1fa73367a1e"
          }
        },
        "000f6133e191461c893cffdc6783a5f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0044237cbef746f9afbe688592bd0e84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00c7829ca16746089c8896865f374b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ef066e53974658a59443c917b2c615",
            "placeholder": "​",
            "style": "IPY_MODEL_98bd45b05dda4319adf853b5104f0a0a",
            "value": " 1725/1725 [00:00&lt;00:00, 3472.08 examples/s]"
          }
        },
        "01ac22caf29c4b2baf0ebc428f3398b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f4a70e089f4fe5abb0d9246aeee403": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01fa51a473a6472da89d47bf1116e575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02191a5509094a0abcf8862d3a8ee4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029adddbce024f50bc5d7a06d304632d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02e13a92f0934b95951876571fff46bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0322aeeda2bd42c1b8ce348bd56424eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5398b51140574840979cfe9ae2640c96",
            "placeholder": "​",
            "style": "IPY_MODEL_d6012c2d60024501a1bd8c529bf055e6",
            "value": "Generating validation_matched split:  99%"
          }
        },
        "0381ff6309df4052bb0ce823e7ff741b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a6cc127c8c4f03bab0b31bb3a1721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ccd976679e45fcbf6d6b5d06360ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_f6c454dc6dcb4528b7b05b83c72640fc",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "03a8f530cfb0469998f56dcca5f00803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cafc757655d74a2697f4ba566b3623ee",
              "IPY_MODEL_46cd1079cad04e7ea04959e14225b7fb",
              "IPY_MODEL_c508e67d54c24888b82b66108681da19"
            ],
            "layout": "IPY_MODEL_b08eba43d39846869bdd9050836be1cb"
          }
        },
        "0457dfcb462c4173bbfb7890bb043c97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04db53bae1ea4e81a1acbad7401cd331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81afc2262c8545dab41aacde91066b7d",
              "IPY_MODEL_b96a361475c947e5a0f9e5f0f867ced7",
              "IPY_MODEL_f697e928e02f405d99c43c4b1fd890c9"
            ],
            "layout": "IPY_MODEL_6da885f236a24cf5a09add7c9927db76"
          }
        },
        "052465580f854b15be0d29e9dc59125b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05fd99843ed746d1baf705e6c31881f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "064e092286b64c1db17f69fead063380": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c60bb508854cc9b6772ab78502b6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497aad7b9ab34f158382033f65d9a8c9",
            "placeholder": "​",
            "style": "IPY_MODEL_814c0fc7e64c49bfa85d5087d1e07cb4",
            "value": " 383/383 [00:00&lt;00:00, 8.70kB/s]"
          }
        },
        "08ed0c209fc14c8db78149696ec91e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08fbdead6ab540d4a1d2d8f06879e417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029adddbce024f50bc5d7a06d304632d",
            "max": 314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a8de725a934927b52792351e0d5099",
            "value": 314
          }
        },
        "094c77436878498099a7df8dddaade6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a93d25cd25426e9c60222b29321889": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ceb11ff6e34ecf995aab26e8f9c05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a024ed7f3514fd6a544804a8bee0d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a320f7b8bba47ddb97d2aff966e162f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9e9f87e453478db26276ec5b4d9913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47ca81ae665a4437a4e4d3ece5591823",
            "placeholder": "​",
            "style": "IPY_MODEL_08ed0c209fc14c8db78149696ec91e58",
            "value": "Downloading builder script: 100%"
          }
        },
        "0ac4b892acc24d2f9d3416110d36ad03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37afab3d5b54448ebfbef920d1b81aa0",
              "IPY_MODEL_a4eea440e6544b5fa1cb92745c17d138",
              "IPY_MODEL_ddeff3c577cc4817806eb81c79a2f3f2"
            ],
            "layout": "IPY_MODEL_e954280499de40579d62a674e1c2acc4"
          }
        },
        "0b0c4175d283414ab014c95269b4421b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17a0dd6bd24481e8e597415bfc02c87",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c43b4c9b58842acaf321862c3a1625d",
            "value": 1725
          }
        },
        "0bc388b26cf64aecb160ab0f86482c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bfcee1a11c64820be92f82b36ae1f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc087a4d9d3b4ee29f31dd677a44ad20",
            "max": 5145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6138f28660bd4610a19dbf919c399105",
            "value": 5145
          }
        },
        "0cbd831de3c64f4aa269776dc73c5e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4848184b58645b2a572c6e1a1231f05",
            "placeholder": "​",
            "style": "IPY_MODEL_92d450929c8e45539c2726eaf96d5ddb",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "0cd233c207bb4c86ac5d002fff7f1d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56da3a1733e4c7990cc8a7dcded2474",
            "placeholder": "​",
            "style": "IPY_MODEL_45173e6c935b4381a5d1f11663fa834a",
            "value": "Downloading readme: 100%"
          }
        },
        "0db15040be1242378220fa56a21aba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dd164739739485abf56d1c16e5fd00d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e215f7f87fc48bfbb3e74c9c97b23a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e871253040141da803ba07be6447d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ea16b4f2c6d428191dd7d31d21ad659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f331a136adf425f87a1a35682256cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f2289d8f6c460892864f1ef5ad8e08",
            "max": 392702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f81a1dd1a8b547b39297478219b41c81",
            "value": 392702
          }
        },
        "1034a93ce59f439bb128b6c096eefdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c225230ea12f4f90bd461485f300580e",
            "placeholder": "​",
            "style": "IPY_MODEL_4d3b7432f11a4a4b9eb444743d158c0d",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "119f25badf4e4cb8a9bacc4ba77dc51e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11db36da26a94bae9ad00e99a10d8c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5323c16a9ca4decbe25c651a14517de",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "value": 408
          }
        },
        "1283ef2790484d7da9f8e2e51d91f9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1290569b6a4d490fbfc8ca3915983263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1295ac5c11614966bff2570a26fe515c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad891b6016e143b1841351478cfc15a0",
            "placeholder": "​",
            "style": "IPY_MODEL_fe935a9cce43441f94e231c54e34779b",
            "value": " 5.11k/5.11k [00:00&lt;00:00, 176kB/s]"
          }
        },
        "137b6408b0fa4dd9bbc495a48c63272e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13e2a857eb49428aba8c96b962767d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "145fcb4a45264b089edb8c7503470d72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14bbc1a8479744c688060e76179bb910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feec1cb456ec4924a79fc88b601d3ec1",
            "placeholder": "​",
            "style": "IPY_MODEL_9ebd09f91c5b4a1cbd4ec9d4baf00d96",
            "value": " 101/101 [00:00&lt;00:00, 4.95kB/s]"
          }
        },
        "1602c7712db64b829a6ed1fa73367a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "16501e0f5de84fc7bbbdcc9b37f61d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1672001c1d7e449f9cc0ce76fcf50fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "169e8fa7a73d4797945e98ccba4cd10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b072faf11c504e39939d1ad4534f9112",
              "IPY_MODEL_f3707c74969e4f6c84d6a36b59d6fa9e",
              "IPY_MODEL_32184fc9b099416a8d49ef3c3f8c3a2e"
            ],
            "layout": "IPY_MODEL_2b95b44611524401ac7826dab5a21aa8"
          }
        },
        "177dee7aa0754c7db2b595f83a4eb105": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b959f151f64f34949c2820e9684be8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18db0004a5de4fe7a7b0ccc2a2e8fed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195b549a3cd745ffbe55e24f5865b1da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d3a395a2104e5eabc47c1f0ee7425b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef69e815a9746de9cf72f70c7c55bd6",
            "placeholder": "​",
            "style": "IPY_MODEL_d9238e5174354b99abc293fffd924410",
            "value": " 2.88k/2.88k [00:00&lt;00:00, 86.9kB/s]"
          }
        },
        "19e70f5c3ae04d4b8b4a86c1233418be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7fcfc2727db445695b908ffd3370feb",
              "IPY_MODEL_546b278b05e643a4905055d1d7ffeea5",
              "IPY_MODEL_289aa49d154a496d9804cf30545bc5fc"
            ],
            "layout": "IPY_MODEL_f54be5e820704ad2b31b6b7a6b946181"
          }
        },
        "1a3234bae89d4c1eb7e84da16675cde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c50e41b12ab40ae88db5a68806a5287",
              "IPY_MODEL_9a675022c08043438f0288c2dc3d1692",
              "IPY_MODEL_42ed4267878a46a9a1a1de7f63006ab4"
            ],
            "layout": "IPY_MODEL_a587d42c581c4f75984a189ebe1b1831"
          }
        },
        "1a7dd0c3112945959e9908425fcaa8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1aea1f6de91a43a4b491c82ffc1522be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c00f260ca44415c9c2cc342c9cab470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c061d153d6043beb838304e363dde5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c43d1c2070b4ccc89e8714ead9ee0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5678cdeb204d21b94526ccdab34d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0381ff6309df4052bb0ce823e7ff741b",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd79d8ce5e28404c988f4965873a2f2c",
            "value": 440449768
          }
        },
        "1c9d94d1b8b74549b9f473c5220b32b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d322e088a6a4904a0b99740d8d4e45c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4ad789412a4b6895e89a53fb62b6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d552e4cb4c842ff8d848b3a212d84c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_882c790b42fe48dfaf7b18bd8f45c5b9",
              "IPY_MODEL_36bb22cb0b9449218327463a4a644c7e",
              "IPY_MODEL_92e674416f8646eaa6bcea05d083ed6c"
            ],
            "layout": "IPY_MODEL_b8d45f71d3da45968b6c845cf4744f70"
          }
        },
        "1d567e39c5ac4b9f8d9908111b04100f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d79ada03ea7445b94a2e90d42da3c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_489bca43eaa34024ae076d61836b481b",
              "IPY_MODEL_91f909ed91a74906ac58b474dfb17b23",
              "IPY_MODEL_1e92221379c449be9f18e1bc813787c1"
            ],
            "layout": "IPY_MODEL_0dd164739739485abf56d1c16e5fd00d"
          }
        },
        "1deae35c0489408fa7e374cd93cca642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7d06e9df9b4a88a003bbba433c1cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d151de5a1862426f9d3ab2aaae73f4d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3963ddae09b14417abf20a566ce82a03",
            "value": " 441k/? [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "1e92221379c449be9f18e1bc813787c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fc72b3f24643c892c8c5426deb48c5",
            "placeholder": "​",
            "style": "IPY_MODEL_df893a2f587e456288a0fd0b30438669",
            "value": " 5.76k/5.76k [00:00&lt;00:00, 70.3kB/s]"
          }
        },
        "1eb78591c14840daaf6741730f2280f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed23c72816b4505bb41e26c734a471b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f65726d2e20471e99928e5dc96726c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454aeb5a95b94bb580698d8d2f62f43f",
            "placeholder": "​",
            "style": "IPY_MODEL_a417b74f6fdb4dedbd6bf3408d0dea69",
            "value": " 392000/392702 [01:52&lt;00:00, 7530.77 examples/s]"
          }
        },
        "20402646761d4cf3975763fc130d6ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20919ce79bb54810bae8420eac2e9d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6318eda7d3bc4b778ed92e779a0a4664",
            "placeholder": "​",
            "style": "IPY_MODEL_02e13a92f0934b95951876571fff46bc",
            "value": "Downloading readme: 100%"
          }
        },
        "20ae65dc26cb4ab98a9637dfa2bd5a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2137d76adc0b4235bcf4e52ab94ae445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2166426a7a224f1da2065f3221463693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216e1650231e471fa0d88e3d73bf6da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2bbd67afcb9463cb0f78d7a24c5f126",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9c165248ef4e0b9c357316b95f66af",
            "value": "Downloading data: "
          }
        },
        "2191d1a5b41d4d2c80a80ee3487f2b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f6c046574b4badbf5dac2bd4989d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235afab600844a9f8ef8f45cdba142e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e977d511bd4f03bc8d730cd4c86027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2b4543fdb94a1d9153de7f18d108be",
            "placeholder": "​",
            "style": "IPY_MODEL_da3eb201a16240aaa91baf19b49d4209",
            "value": " 5.14k/5.14k [00:00&lt;00:00, 173kB/s]"
          }
        },
        "24f281ec4d904b27a5f45a7820fff9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e24e2408e27249d4841b1633f386f012",
            "placeholder": "​",
            "style": "IPY_MODEL_41f3134a1ab842df849f97fa73f51254",
            "value": "Downloading readme: 100%"
          }
        },
        "251219f28bd54de9a608686672dddf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e61f641028148e988678a2ecbe24a21",
            "placeholder": "​",
            "style": "IPY_MODEL_df8de4914b3f4c51b4e048f053a0e009",
            "value": " 9703/9815 [00:01&lt;00:00, 7528.70 examples/s]"
          }
        },
        "258524f690c449b793139e8b03d1fc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4acc49dcd844d7892ab2a432e79d56a",
            "placeholder": "​",
            "style": "IPY_MODEL_6f48447043914f1ea91cfd94e442a4e7",
            "value": " 9.34k/9.34k [00:00&lt;00:00, 387kB/s]"
          }
        },
        "25a2bf19539642259412fbb1b4d9f69f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e3340ed1fa4ff28744b87cd44ff756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064e092286b64c1db17f69fead063380",
            "placeholder": "​",
            "style": "IPY_MODEL_72b96a7e939b48b7a98a85a1c901ce58",
            "value": "Downloading builder script: 100%"
          }
        },
        "260f38a6c52d464999f74443c04cdc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2750de9a4c5740b080f5a8145de41111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27942f0823b6469db6f785463d429e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849e4b64e3c14349acee2f55f9600249",
            "placeholder": "​",
            "style": "IPY_MODEL_b7c9909bd1574248801e53bdf8827cb6",
            "value": "Downloading readme: 100%"
          }
        },
        "282f350bdadd41fa82b37f527ffe8a63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283065bbec654b89a6be726e3fe790fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28542ed3d1b443c9a7ba7074825ee208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72812af3cd8475f8a76a8ff3ec236e9",
            "placeholder": "​",
            "style": "IPY_MODEL_40731cc8e1a245868c9bf6d0972c0467",
            "value": "Map: 100%"
          }
        },
        "289aa49d154a496d9804cf30545bc5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c0e136fa3f400bab5deec7a0aff11f",
            "placeholder": "​",
            "style": "IPY_MODEL_bcee86d4105743f5a69c595029994bc8",
            "value": " 116M/116M [00:03&lt;00:00, 35.9MB/s]"
          }
        },
        "28d0bbe4650343fb8d4a12109bc78b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6c56c2991d433fa81332d7c48b183a",
            "max": 8711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_137b6408b0fa4dd9bbc495a48c63272e",
            "value": 8711
          }
        },
        "292c0b150eb84f06a012e2084b035350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2958b232a65d47d7950e040ddd583898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82db512ae4ce4b1fbde3aed3d893e032",
              "IPY_MODEL_8b3982acce834b95a6f318dfb78add1c",
              "IPY_MODEL_3df2e72406454de7ade25cfe0fca7295"
            ],
            "layout": "IPY_MODEL_979449deb4254629b80f0089584c851a"
          }
        },
        "29e9e92bc30c4b2f89416481b4fb1455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34433ff3b52491fb5829b9f1522e162",
            "placeholder": "​",
            "style": "IPY_MODEL_5250f6a6e5c34894adb20a9120388ba0",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2a7388d890b2460c86be4cd32187f319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38b91d162c304c6eaad444f0abffa931",
              "IPY_MODEL_0f331a136adf425f87a1a35682256cd9",
              "IPY_MODEL_1f65726d2e20471e99928e5dc96726c7"
            ],
            "layout": "IPY_MODEL_dae9d080adfc4bfbba896820bbf57c3b"
          }
        },
        "2abdae7b3f57423cbb15cac196752b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b5f6a6687b34036bd5a87c8b61dc2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d265db9a419d4edfbdb91e4bd8f78846",
            "placeholder": "​",
            "style": "IPY_MODEL_aae2a30b7f474dbcbf55aa677b9518f9",
            "value": "Downloading metadata: 100%"
          }
        },
        "2b95b44611524401ac7826dab5a21aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9d70f4869c456b994ef7166e42d253": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7f79d2154784e4dac011fb680cf5e60",
            "placeholder": "​",
            "style": "IPY_MODEL_99e3d22fc1584f63861fd9524949ee68",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 328kB/s]"
          }
        },
        "2c0a41159b1241039386b5bf99d864c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c148a8aa9fe4f30a69392f10a350eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c43b4c9b58842acaf321862c3a1625d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fe3c4d6e4774be691e7c0551fd334ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30cda55d35044431bffc7ce4ad88bcdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f6111712e2491198ac03400ef0ce7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312b0a411cf7451d845fae7b77dff7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3175f3e1e82549eca3f0210fd797d73b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318eb12f8c014bf090024d2d0e82e127": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31fef27ae4d44fa691185c3fa750756a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa205a1da88e418a881efb0963042e9d",
            "placeholder": "​",
            "style": "IPY_MODEL_30f6111712e2491198ac03400ef0ce7d",
            "value": "Generating validation split:  73%"
          }
        },
        "32184fc9b099416a8d49ef3c3f8c3a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2137d76adc0b4235bcf4e52ab94ae445",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb506371e6e4cd2947988d6c7050809",
            "value": " 232k/232k [00:00&lt;00:00, 6.89MB/s]"
          }
        },
        "326c1c104f254d1189c78c6abd318451": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b99a92413745a3976c31c5cdae8fad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32f65d2703c048929de10720219fdf53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33088ffab85f4898bc39a1167e70388c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3312caf3fc76420ead7f4945675df52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3315267c32f24d29804c12af760956aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31fef27ae4d44fa691185c3fa750756a",
              "IPY_MODEL_11db36da26a94bae9ad00e99a10d8c5a",
              "IPY_MODEL_f4bb56cde5b042e8821ee26d25da4ea2"
            ],
            "layout": "IPY_MODEL_312b0a411cf7451d845fae7b77dff7d6"
          }
        },
        "33ae5a6ee9244aeea02e10990e8dd3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f1b9961c6b14a1a92f3cb2c82883a17",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd3f1f64d81471083416a3e4ca6aa60",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "3525c2478cdb44dd9b80f4b5f4af2659": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "356f65307a5b4ffb845b0a51dd82a10a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359118bc2d25450cb5c69de24f84d533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80aa0f5a62774db5ad80778f93dfd5b3",
            "placeholder": "​",
            "style": "IPY_MODEL_2abdae7b3f57423cbb15cac196752b9a",
            "value": "Downloading metadata: 100%"
          }
        },
        "35c4327146b44171a0cfbc53d7fd9c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35d01e3e13ed4a3f8ecfaecde0352a21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361d5a3bb70e49a3bb27d843cf6b0afc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361e6535b4194815b783b5a572c0c725": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3669f6c8d83e469da8ac6a0662b5b3b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36bb22cb0b9449218327463a4a644c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a244c1afad7940caa2aacee1c7099d04",
            "max": 14093,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5597290e83314b2fb70149128b837acb",
            "value": 14093
          }
        },
        "36c0e136fa3f400bab5deec7a0aff11f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "372c8e31995545df9d59d0d39733e49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891bfb21ffed4024bc38f8a62fdd62fb",
            "placeholder": "​",
            "style": "IPY_MODEL_361e6535b4194815b783b5a572c0c725",
            "value": "Downloading extra modules: 100%"
          }
        },
        "3751db7e581847efa6c224dd50c9b7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "377a7fa0ebce4c8a96a55c6e1c08403f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff3a2b6be1f4220b0e3c055fc587c7e",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af816340aae74a81a6eaf63a1933f5bf",
            "value": 1340616616
          }
        },
        "37afab3d5b54448ebfbef920d1b81aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa23b88cb754258a876d7d6132c2903",
            "placeholder": "​",
            "style": "IPY_MODEL_0e871253040141da803ba07be6447d93",
            "value": "Downloading readme: 100%"
          }
        },
        "37e0abc511f04624986368ef45b50131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33088ffab85f4898bc39a1167e70388c",
            "placeholder": "​",
            "style": "IPY_MODEL_1672001c1d7e449f9cc0ce76fcf50fc8",
            "value": " 2.88k/2.88k [00:00&lt;00:00, 139kB/s]"
          }
        },
        "37fc3be40adf4411ba11d7e448e6f753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b91d162c304c6eaad444f0abffa931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef72b344a964832bd2b19140d230f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_b719af868833401c86d45d2ae059c868",
            "value": "Generating train split: 100%"
          }
        },
        "38bcb0d78ed94011936def4c3615504b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3963ddae09b14417abf20a566ce82a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3988d9e57bc841b49a5079130f071dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39a0cc13934b4794b0103244457caf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a2911388c6845018ba8454fdf44e2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a17af08f33c6440081c2fe9cd6e27a38",
              "IPY_MODEL_42ef3d3c96c94aca9833834c52ea126b",
              "IPY_MODEL_48598cc0fb5045f888e265a561711726"
            ],
            "layout": "IPY_MODEL_30cda55d35044431bffc7ce4ad88bcdc"
          }
        },
        "3a95095e2d0845d793654199eba19cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b99a92413745a3976c31c5cdae8fad",
            "placeholder": "​",
            "style": "IPY_MODEL_a76e83b34560423e82cbe55717f7082c",
            "value": " 5.27k/5.27k [00:00&lt;00:00, 93.8kB/s]"
          }
        },
        "3b7d6c3a741249d48ebcda417eec08aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c45e6794f974b4199098bcd87765e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c54d6fd6a004ed98c1cb595a0bb84a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cdf813044f446c0b2cf4ec8c5f51b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d362a5dfe9b4554bff3647a29f1d93d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df2e72406454de7ade25cfe0fca7295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7834f7deaa3b43669cd0de893fa62448",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa5b162648c4abca773a478c3e3beb9",
            "value": " 227M/227M [00:07&lt;00:00, 30.8MB/s]"
          }
        },
        "3e72971bf9804c3688c24e0a3eca0da7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2b4543fdb94a1d9153de7f18d108be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb4b68eda9f481abbc7b2456644e16b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd737f15fe74553a4cd7d29ecd813f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92ca0a6d3b9472f98613666cdeb0d73",
            "placeholder": "​",
            "style": "IPY_MODEL_480c0caed8a94250a9264b59620bbb29",
            "value": "Downloading builder script: 100%"
          }
        },
        "402d63f4215a480aba1156661261a877": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40710930eadf4cdea0ae4f21c9a457f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40731cc8e1a245868c9bf6d0972c0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "413cb02e70c94df0ae721c178216499c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41ce600f2e84451cb91a75e4c1eb5cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c43d1c2070b4ccc89e8714ead9ee0dd",
            "max": 4283,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b29d0db23b9481db48a6c56e93a41cf",
            "value": 4283
          }
        },
        "41f2b3c081344be783534fb60fdd5c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41f3134a1ab842df849f97fa73f51254": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422ac21cdb1d45a8a0814ef00c9769ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "429379eb4c4f452d94a52521911811a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68c38cc7bf84db2ab1540ca985599e2",
            "max": 8671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "value": 8671
          }
        },
        "42c13d8f7c694c6599c0a2e10ca0765f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0322aeeda2bd42c1b8ce348bd56424eb",
              "IPY_MODEL_c0908ccc452b42e681765c37a139e878",
              "IPY_MODEL_251219f28bd54de9a608686672dddf0d"
            ],
            "layout": "IPY_MODEL_e982215023c24a3caf881dd3986cca86"
          }
        },
        "42ed4267878a46a9a1a1de7f63006ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba76516f42224f79a9dfe8a36385bb22",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b2dc48588b482f80e9a2473dc5b452",
            "value": " 28.8k/28.8k [00:00&lt;00:00, 619kB/s]"
          }
        },
        "42ef3d3c96c94aca9833834c52ea126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5dfeae5f20a425cab5a19aa8ae340ea",
            "max": 1893,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91a8e2de38594a55828cb3e19f4b9d32",
            "value": 1893
          }
        },
        "4326c46139fd4b6882d864400e35a9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e76cddc6d7d04d3fb01c11225ec1b6a2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ad1276e945e4915a079e97e06048ee9",
            "value": 570
          }
        },
        "43a0d30d3abf4da694265f61dc05d9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4451aba03f3a4d378cfeb04ceee5481f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35d01e3e13ed4a3f8ecfaecde0352a21",
            "max": 6266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bc388b26cf64aecb160ab0f86482c93",
            "value": 6266
          }
        },
        "44673cba464f4e5799fc317192a5d987": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ce4959b2bc410a8b455eb2adb7ffc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d07abd85374cca92698119139b140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1deae35c0489408fa7e374cd93cca642",
            "placeholder": "​",
            "style": "IPY_MODEL_260f38a6c52d464999f74443c04cdc03",
            "value": "Downloading data: "
          }
        },
        "45173e6c935b4381a5d1f11663fa834a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "454aeb5a95b94bb580698d8d2f62f43f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45627e42f92a446eb93348029234446b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f6aa7c5f8f24392b23ebb21f9d8502a",
              "IPY_MODEL_b97f76334b48437dbb7d7365cb93d2ec",
              "IPY_MODEL_b9136a5d0eae4f9297b6b3490f36c0d3"
            ],
            "layout": "IPY_MODEL_6639002ed37d40ff8083323541d97f3e"
          }
        },
        "46cd1079cad04e7ea04959e14225b7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef504e4ab1384063bff714e1649e0aa3",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b387dec327543f79f957f81fb651cc7",
            "value": 3668
          }
        },
        "46f2289d8f6c460892864f1ef5ad8e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ff0481a7a94abb9cea91aaacd1ea29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470a84311bbf40c6ae6322d6edc353ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9568bdb74f3e450f91b3558cf5ad5da1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7b946e1ad95455b818512986f83f7cd",
            "value": 231508
          }
        },
        "476c5672e7784cda8255af2049de1ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73e2bfea29de4c47b0c60590deff9771",
              "IPY_MODEL_4326c46139fd4b6882d864400e35a9bc",
              "IPY_MODEL_a53d537c8c0e48d1a77fbc22e5c41402"
            ],
            "layout": "IPY_MODEL_4eba976ecf5145e0a60cc8a838bff5c9"
          }
        },
        "47ca81ae665a4437a4e4d3ece5591823": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ed21294f9e42d9817708809f620d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480c0caed8a94250a9264b59620bbb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4818654025b94f38a631b2bcdf36014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48598cc0fb5045f888e265a561711726": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce2d3a52ab449a9b8539a663f88dc23",
            "placeholder": "​",
            "style": "IPY_MODEL_cdf772bf44f8400caf20d7df43bad6c0",
            "value": " 1.89k/1.89k [00:00&lt;00:00, 85.2kB/s]"
          }
        },
        "48729429682c4b37a624ba2eb55d1966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489bca43eaa34024ae076d61836b481b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cdf813044f446c0b2cf4ec8c5f51b41",
            "placeholder": "​",
            "style": "IPY_MODEL_c7208573f8204d9b9f0956753eda0ad0",
            "value": "Downloading builder script: 100%"
          }
        },
        "497aad7b9ab34f158382033f65d9a8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a90c227b9342ddbb670c9fe85591cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a1ecdd97d194a9ab63a15980d1e2e31",
            "placeholder": "​",
            "style": "IPY_MODEL_5dd1df4079d44b1aad849b4a0a5e3b55",
            "value": " 8.67k/8.67k [00:00&lt;00:00, 296kB/s]"
          }
        },
        "49bb63cd356546bcacfe6dc514b0ace6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a16335de26a43c09d578cbbe20e98d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d567e39c5ac4b9f8d9908111b04100f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f619ea2b062a4eacb80ade328d56c2aa",
            "value": 231508
          }
        },
        "4a3d7c6179fb4158bb1a5f452b29c308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc03f25dc1d642a79e21e2ff2be3dd35",
              "IPY_MODEL_c05be6815b304522ab70ebeb2dd1a3b9",
              "IPY_MODEL_da9e8a5d31f64f98baabcdd61a092cb1"
            ],
            "layout": "IPY_MODEL_aa46d7c838df43508b1187d034341421"
          }
        },
        "4ad6947770a94c819fe4b90b67d8dedc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b35ff0e35ca4e6088f2f1f687ff924c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4dae6b5bd5474491e1c86a6e462ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c0d4a0a16664758987fcc67422c2c89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3b7432f11a4a4b9eb444743d158c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d798a40b2a24c4f8ce823023d75ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10d3cde2d7b4121971d8e19e3362b30",
            "placeholder": "​",
            "style": "IPY_MODEL_4818654025b94f38a631b2bcdf36014c",
            "value": "Downloading readme: 100%"
          }
        },
        "4e5fc1ebc9b0447abc615de359a5e2fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eba976ecf5145e0a60cc8a838bff5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef3bcbd56164ddaac3068fb93a66630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cbd831de3c64f4aa269776dc73c5e28",
              "IPY_MODEL_d947bfe9101646c9a7222ada482d4455",
              "IPY_MODEL_8e9137be11744d329bceecd548d91025"
            ],
            "layout": "IPY_MODEL_326c1c104f254d1189c78c6abd318451"
          }
        },
        "4fe04dcab6654d0594a56109e7eb6805": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5183ef3eec0d4bdfbcc5544b0fec573b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b2478fccc64ed99f54ef99d1ddffd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c65da12a5a401b9263fbe8050b5bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5250f6a6e5c34894adb20a9120388ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a159d9e9854013bf1a5cf711d50093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5398b51140574840979cfe9ae2640c96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54027a2d3bf240388116336d153cb6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5674b6d3832d4a51aad763db048fa0b2",
              "IPY_MODEL_86978ff9ee2b43d1875aec95965bafa1",
              "IPY_MODEL_7b4b08fa4aca4532839925f9a4a5182d"
            ],
            "layout": "IPY_MODEL_fee5b87f231c40e49a6b5408520948e1"
          }
        },
        "546b278b05e643a4905055d1d7ffeea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195b549a3cd745ffbe55e24f5865b1da",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe156388571b4c63b5fc5f5ca857e522",
            "value": 116252865
          }
        },
        "54ab0ccab0954ee087b5a0e7c46f049d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5589d685cbc94ea0a045dcba0e69a7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600bc8f5877547aca898f8c85902040e",
            "placeholder": "​",
            "style": "IPY_MODEL_b65ef6da8ad34e2285813544d00bf3e5",
            "value": " 711k/711k [00:00&lt;00:00, 10.2MB/s]"
          }
        },
        "5597290e83314b2fb70149128b837acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "560c716068a645d596cc2fe9b886c0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235afab600844a9f8ef8f45cdba142e0",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7537c19825a49cd8f3343c153fe56ef",
            "value": 383
          }
        },
        "5674b6d3832d4a51aad763db048fa0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e713295328e84a95abfc13fd5e0fbf79",
            "placeholder": "​",
            "style": "IPY_MODEL_39a0cc13934b4794b0103244457caf58",
            "value": "Downloading readme: 100%"
          }
        },
        "56c0600f62514fea9a456a457720311b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "573b3112cbee4ba581c18884df0a269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc799bb2e34741fabc79181ea30ee78f",
            "placeholder": "​",
            "style": "IPY_MODEL_a78c45e4929847f0a635988d1ef9d78f",
            "value": " 232k/232k [00:00&lt;00:00, 2.46MB/s]"
          }
        },
        "585e63900ddb4fc098d8fdf6ab979b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7a2b9ab0ae42a38b4188f5a837ffe0",
            "placeholder": "​",
            "style": "IPY_MODEL_c19adb67cf904bdc89b23db9c463ad70",
            "value": " 6.51k/6.51k [00:00&lt;00:00, 250kB/s]"
          }
        },
        "58c7f5f99a99451d9e715066b8d4698a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595530337aab40f6b5cc24d69b3ebaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa71718a83446e58408f5baada02739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f164ebe9824ae4986a5fb9913b5d79",
            "max": 2877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_413cb02e70c94df0ae721c178216499c",
            "value": 2877
          }
        },
        "5ab64a9556124cf892f33cc9973240ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b29d0db23b9481db48a6c56e93a41cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bd4908665db4c8baac9d52a40a1c28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46ff0481a7a94abb9cea91aaacd1ea29",
            "placeholder": "​",
            "style": "IPY_MODEL_05fd99843ed746d1baf705e6c31881f6",
            "value": " 9832/9832 [00:01&lt;00:00, 7725.02 examples/s]"
          }
        },
        "5c0b31457c634b7fb06a00cb78362e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49bb63cd356546bcacfe6dc514b0ace6",
            "placeholder": "​",
            "style": "IPY_MODEL_7b13c1d51dec405ca19e803a26b8726b",
            "value": " 2.04k/2.04k [00:00&lt;00:00, 76.9kB/s]"
          }
        },
        "5c3bd5b4fc2d480185bf8afe73720af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b03b7f723b8748bfa4bfd987f80b472e",
            "placeholder": "​",
            "style": "IPY_MODEL_cd4b814a828847d7882704c3032d3fd6",
            "value": "Downloading metadata: 100%"
          }
        },
        "5c69e45579f54fc6b2415ebbad4da477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c96dd4ef67f4900af004f322706921f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc04f68fbda455aaf16e78c98ad9f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fed7ec45ec594d90bc2d11c56f8330ba",
            "placeholder": "​",
            "style": "IPY_MODEL_41f2b3c081344be783534fb60fdd5c00",
            "value": " 3.82k/3.82k [00:00&lt;00:00, 119kB/s]"
          }
        },
        "5d880747de69431a896ecb1104284873": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd1df4079d44b1aad849b4a0a5e3b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5df7aa079833485bbde65e4658b496e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283065bbec654b89a6be726e3fe790fd",
            "max": 28682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebf0c7ac01e441d68a38cac5fed89d00",
            "value": 28682
          }
        },
        "5e0b9eeeed064894be9807fc5464073a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c65da12a5a401b9263fbe8050b5bc5",
            "placeholder": "​",
            "style": "IPY_MODEL_c2beabf523574127b916e27b1be2a248",
            "value": " 7.52k/7.52k [00:00&lt;00:00, 232kB/s]"
          }
        },
        "5e1a387877054dacbb6bf1fa32b08d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e959b2e1fc7460899db727adb156c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a7f36e7433d4f32876ea4ac13ee203a",
              "IPY_MODEL_28d0bbe4650343fb8d4a12109bc78b20",
              "IPY_MODEL_cbeae0b822a5446f9687157d33c457fd"
            ],
            "layout": "IPY_MODEL_e93bede3188e4bf1bdd1de7ecb919483"
          }
        },
        "5ed5174d9d6c4680bb7cc1e803184102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91bcf74809894d39b5199ca23691f00f",
            "placeholder": "​",
            "style": "IPY_MODEL_85a35c16364f4c6880dbbecf061faf44",
            "value": " 1.34G/1.34G [00:17&lt;00:00, 83.7MB/s]"
          }
        },
        "5f0512fb3607471f817b5c215d94e4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd68849bd0a44238fbb9bec129b0511",
            "placeholder": "​",
            "style": "IPY_MODEL_3312caf3fc76420ead7f4945675df52a",
            "value": " 314/314 [00:00&lt;00:00, 4.38kB/s]"
          }
        },
        "5f0dc4f1fe9e4b7d8bbf3c12a61cca3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f1b9961c6b14a1a92f3cb2c82883a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2f6e6fb7624adbbe1229344230335d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fdca1f2b388437fac7624c0eca1ec26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600bc8f5877547aca898f8c85902040e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e06687a91843119fe512da01b90bfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61177aa1734d4e4d9b78538bdc8c0266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6138f28660bd4610a19dbf919c399105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "619bcc47eac24a098ac5908bddc4297d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6318eda7d3bc4b778ed92e779a0a4664": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6319e3d301f040008853a8112bec28e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638f36ef35ec4ec88ba057c63093eca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a2424581894ab48ad61b9f38cc882e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641fd37171904fb590b7877d8403aeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8f710e2dcfc40398ce16a4ac265cc26",
              "IPY_MODEL_377a7fa0ebce4c8a96a55c6e1c08403f",
              "IPY_MODEL_5ed5174d9d6c4680bb7cc1e803184102"
            ],
            "layout": "IPY_MODEL_2c148a8aa9fe4f30a69392f10a350eac"
          }
        },
        "650346b4f83a419297fa6fb6cc5156b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a9e9f87e453478db26276ec5b4d9913",
              "IPY_MODEL_a611dd18d0284289b4b1dddf574f4e3e",
              "IPY_MODEL_6beef838fd8a4d119c6b704746b4322a"
            ],
            "layout": "IPY_MODEL_8abf5e3e9645453991ff2ebf5b714763"
          }
        },
        "656cb0e3b85c4a57936749caa02f664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6639002ed37d40ff8083323541d97f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6676d80a5adc45e4806ae8e369fcfe23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67a7154376b34eb2b6625f7eea7cb8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b7ad21a48a4a339697122fd6e0c10e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686aaeb98c1a4e688af5030963b8525e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68db1531b9574e72a2ff0d52995a7347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694f0df64a4b433aa22afef48d968090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d264b002cc4c3889089fe28f6cfa80",
              "IPY_MODEL_f6a686a076954e0c9c5d11429a14d582",
              "IPY_MODEL_9f512b3c83bf4fcaa1640cf5cdbea8c8"
            ],
            "layout": "IPY_MODEL_282f350bdadd41fa82b37f527ffe8a63"
          }
        },
        "6a7f36e7433d4f32876ea4ac13ee203a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93fdce4ab8d049cb8982686dfea11829",
            "placeholder": "​",
            "style": "IPY_MODEL_61177aa1734d4e4d9b78538bdc8c0266",
            "value": "Downloading builder script: 100%"
          }
        },
        "6aa762333f4e459092b6f2949203b7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98804ca8de5c4af7ba392f82e2decc75",
            "max": 5266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6676d80a5adc45e4806ae8e369fcfe23",
            "value": 5266
          }
        },
        "6b349f8f7890488eaa05b156ec971bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3537b58aca04f398663d6a8f6bd7cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_0ea16b4f2c6d428191dd7d31d21ad659",
            "value": " 1725/1725 [00:03&lt;00:00, 758.62 examples/s]"
          }
        },
        "6bab212ec66b4136b3c2c695ba309c07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6baecbf668bc4a6f93be03e5f671b76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d322e088a6a4904a0b99740d8d4e45c",
            "placeholder": "​",
            "style": "IPY_MODEL_20402646761d4cf3975763fc130d6ff5",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "6beef838fd8a4d119c6b704746b4322a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_936348ad30684927b387b7e02efd4361",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2f6e6fb7624adbbe1229344230335d",
            "value": " 8.43k/8.43k [00:00&lt;00:00, 389kB/s]"
          }
        },
        "6d42028ff9f54dcb9effdd01af728e82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6da885f236a24cf5a09add7c9927db76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de1573bc51f495fa27bf5cfecd85295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eeb3579c2b644a6b8501cc246083c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f102144e4fd4840b77808f1e6ff7697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f48447043914f1ea91cfd94e442a4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ff3a2b6be1f4220b0e3c055fc587c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70225a6a843d4ccf87d1b43d4cf1895b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7081369f016f46ec9ad16edcedd027b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "712c22b5be60449bb23b7555a5c22038": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71be80ab68ba4da2a3a7066ef36e8d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71ea3c60b4104f41b1fc714a4aaa4ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7291eb717846498f83f7591b1733334b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4589d7a584b4690b47cd06b82c18053",
            "placeholder": "​",
            "style": "IPY_MODEL_78d7a9d704834b13b7c2a7562da62d4d",
            "value": " 9.01k/9.01k [00:00&lt;00:00, 508kB/s]"
          }
        },
        "729e25ed88bd4d4d89338d0d8e54d4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b96a7e939b48b7a98a85a1c901ce58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e2bfea29de4c47b0c60590deff9771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2750de9a4c5740b080f5a8145de41111",
            "placeholder": "​",
            "style": "IPY_MODEL_ecf9c5705a7b491c82d4e8b5cbd8c439",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "755e3809aa3043f99d3664955a3a2c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d07abd85374cca92698119139b140e",
              "IPY_MODEL_00001f9f055045f9ae35f94f76be8fe4",
              "IPY_MODEL_1e7d06e9df9b4a88a003bbba433c1cae"
            ],
            "layout": "IPY_MODEL_a87f8ff9f575436da0dcf9a31642f7b7"
          }
        },
        "75d264b002cc4c3889089fe28f6cfa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052465580f854b15be0d29e9dc59125b",
            "placeholder": "​",
            "style": "IPY_MODEL_619bcc47eac24a098ac5908bddc4297d",
            "value": "Downloading data files: 100%"
          }
        },
        "75d76bf886514ba5ac9fedee0fcfba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fd0e5e6b8f47c6a4c9557f127ef73b",
            "placeholder": "​",
            "style": "IPY_MODEL_b963a45c28d1437f86109f283a370f38",
            "value": " 384/384 [00:00&lt;00:00, 3.58kB/s]"
          }
        },
        "77222effa92b47c4b9b5aca2e1fc7971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d42028ff9f54dcb9effdd01af728e82",
            "placeholder": "​",
            "style": "IPY_MODEL_2191d1a5b41d4d2c80a80ee3487f2b84",
            "value": " 5.14k/5.14k [00:00&lt;00:00, 279kB/s]"
          }
        },
        "778438eb8eba453fb926277641f26b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e06687a91843119fe512da01b90bfd",
            "max": 2037,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1283ef2790484d7da9f8e2e51d91f9c6",
            "value": 2037
          }
        },
        "77d712d32c0f491cb9a58df33b012b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7834f7deaa3b43669cd0de893fa62448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78608a4a3a8f4c119d9a0128153a39eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48729429682c4b37a624ba2eb55d1966",
            "placeholder": "​",
            "style": "IPY_MODEL_6eeb3579c2b644a6b8501cc246083c97",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "787eddad8809411fa14915244c03c24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58c7f5f99a99451d9e715066b8d4698a",
            "placeholder": "​",
            "style": "IPY_MODEL_a9febc2bee944b66beb98c7ca39a2f67",
            "value": " 1.71k/1.71k [00:00&lt;00:00, 77.2kB/s]"
          }
        },
        "78d7a9d704834b13b7c2a7562da62d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7950d803ab5b4c4ab10dc9e0902e34b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b13c1d51dec405ca19e803a26b8726b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b387dec327543f79f957f81fb651cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b4b08fa4aca4532839925f9a4a5182d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7ef96f903a348829426015c210a75c6",
            "placeholder": "​",
            "style": "IPY_MODEL_f3f6078f2844467fa8b6e2dfa45eeefa",
            "value": " 8.67k/8.67k [00:00&lt;00:00, 260kB/s]"
          }
        },
        "7bafeac027304b49b44f913fdbfdd54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_119f25badf4e4cb8a9bacc4ba77dc51e",
            "placeholder": "​",
            "style": "IPY_MODEL_f6fdd2a41cb1482a9b2b869776dd1dbe",
            "value": " 6.24k/6.24k [00:00&lt;00:00, 70.8kB/s]"
          }
        },
        "7bdb5cce9c364437970f01220e5f0aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e72971bf9804c3688c24e0a3eca0da7",
            "placeholder": "​",
            "style": "IPY_MODEL_d36c80ffd8824fdb8e1e344f41fa3669",
            "value": "Downloading metadata: 100%"
          }
        },
        "7c01fc1aabb0486f9f1f0674b46b5481": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f102144e4fd4840b77808f1e6ff7697",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82084929de714135a363f5693f4a0aac",
            "value": 1725
          }
        },
        "7c1ea655a2844e0e81c89529f95acb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fca62c132b4b9c9af64955480ac905",
            "placeholder": "​",
            "style": "IPY_MODEL_7081369f016f46ec9ad16edcedd027b0",
            "value": "Generating validation_mismatched split: 100%"
          }
        },
        "7c50e41b12ab40ae88db5a68806a5287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aea1f6de91a43a4b491c82ffc1522be",
            "placeholder": "​",
            "style": "IPY_MODEL_3c45e6794f974b4199098bcd87765e63",
            "value": "Downloading builder script: 100%"
          }
        },
        "7d37d5db223e4588a13a65429c6b644c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e61f641028148e988678a2ecbe24a21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f511160291e4a4a82f8694772449ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6aa7c5f8f24392b23ebb21f9d8502a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37fc3be40adf4411ba11d7e448e6f753",
            "placeholder": "​",
            "style": "IPY_MODEL_8a59fc9ba9e0478ca02ac0d067f2e781",
            "value": "Downloading metadata: 100%"
          }
        },
        "808dad49922a431d9c43faf48478a069": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80aa0f5a62774db5ad80778f93dfd5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ee1a5161b544b380fe6b2bf431ce00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80fd0e5e6b8f47c6a4c9557f127ef73b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814c0fc7e64c49bfa85d5087d1e07cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81afc2262c8545dab41aacde91066b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638f36ef35ec4ec88ba057c63093eca2",
            "placeholder": "​",
            "style": "IPY_MODEL_4b35ff0e35ca4e6088f2f1f687ff924c",
            "value": "100%"
          }
        },
        "82084929de714135a363f5693f4a0aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "824bdc0faabd449096459e491d7a7d45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "825fb9aa19594a61b2a779837eb230b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686aaeb98c1a4e688af5030963b8525e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a024ed7f3514fd6a544804a8bee0d78",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "82db512ae4ce4b1fbde3aed3d893e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd748fe04232441abb30f153e54f9890",
            "placeholder": "​",
            "style": "IPY_MODEL_8eda2864b2774815bd6d860c1fdf2625",
            "value": "Downloading data: 100%"
          }
        },
        "82f1dc2ca5ef4e45818a2b9107732d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae32d0dd19e40e8a0fc4b04b325abd6",
            "placeholder": "​",
            "style": "IPY_MODEL_20ae65dc26cb4ab98a9637dfa2bd5a62",
            "value": " 616/616 [00:00&lt;00:00, 9.58kB/s]"
          }
        },
        "8366f2cb708944b38ccd18c2407c2fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84276e7b4ec141c3a7f5497bdc24a084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3175f3e1e82549eca3f0210fd797d73b",
            "max": 101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71be80ab68ba4da2a3a7066ef36e8d1c",
            "value": 101
          }
        },
        "843d11a2271246f49dbabe80fc4762d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849e4b64e3c14349acee2f55f9600249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a35c16364f4c6880dbbecf061faf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a8afac57e741c8ba4e5fca23d29c82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85aa23b715f248248204a2bdf3e5f7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8631f393c12e4ebaa57838a4f1c1efb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864c3f3a16f648edada464a8397f7b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868c8d0c5a4a4535a00dd833ad0dbb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1ea655a2844e0e81c89529f95acb4c",
              "IPY_MODEL_f4a51d5c122645a5a58acfbadb0cf752",
              "IPY_MODEL_5bd4908665db4c8baac9d52a40a1c28e"
            ],
            "layout": "IPY_MODEL_000f6133e191461c893cffdc6783a5f9"
          }
        },
        "86978ff9ee2b43d1875aec95965bafa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a7154376b34eb2b6625f7eea7cb8e1",
            "max": 8671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96683385bb0048edab833d70bc9b94f7",
            "value": 8671
          }
        },
        "882c790b42fe48dfaf7b18bd8f45c5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54ab0ccab0954ee087b5a0e7c46f049d",
            "placeholder": "​",
            "style": "IPY_MODEL_35c4327146b44171a0cfbc53d7fd9c6a",
            "value": "Downloading readme: 100%"
          }
        },
        "891bfb21ffed4024bc38f8a62fdd62fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8974203b2bde4395b3144ffe61596643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdca1f2b388437fac7624c0eca1ec26",
            "placeholder": "​",
            "style": "IPY_MODEL_1c00f260ca44415c9c2cc342c9cab470",
            "value": " 232k/232k [00:00&lt;00:00, 9.15MB/s]"
          }
        },
        "8a0851189dae4fbdb953f6afe6f3ba29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1ecdd97d194a9ab63a15980d1e2e31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a59fc9ba9e0478ca02ac0d067f2e781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ab8d0701eb54f4d8d43ebdb4f9d582c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_933287a3795541209985a9585a4b9b00",
              "IPY_MODEL_c8f8b1493e1b4b2bb1a8f99719c21c81",
              "IPY_MODEL_a1e33db2760f40aebfb725dc8261ac6d"
            ],
            "layout": "IPY_MODEL_5f0dc4f1fe9e4b7d8bbf3c12a61cca3a"
          }
        },
        "8abf5e3e9645453991ff2ebf5b714763": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae32d0dd19e40e8a0fc4b04b325abd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3982acce834b95a6f318dfb78add1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a93d25cd25426e9c60222b29321889",
            "max": 226850426,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0db15040be1242378220fa56a21aba28",
            "value": 226850426
          }
        },
        "8c45ce351a9b45dda4359b706ea36aba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c8b7e081e834ccf98a4ce2730e00f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f471e7ebb7c245179c58992fc78b3e55",
            "placeholder": "​",
            "style": "IPY_MODEL_e31dc156f8034495a5737385ef032e77",
            "value": "Downloading readme: 100%"
          }
        },
        "8dba751b9b1544369fcc9f4bca44c449": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbb1fccc920458cbffc7029953e5363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29e9e92bc30c4b2f89416481b4fb1455",
              "IPY_MODEL_1c5678cdeb204d21b94526ccdab34d32",
              "IPY_MODEL_dea6b34486294d388d68aa9ef3aaa281"
            ],
            "layout": "IPY_MODEL_e34566724c6e4598860e77d6b710faf8"
          }
        },
        "8e6c56c2991d433fa81332d7c48b183a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9137be11744d329bceecd548d91025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c45ce351a9b45dda4359b706ea36aba",
            "placeholder": "​",
            "style": "IPY_MODEL_9e2644d3c3bb40aa9eba632e756112a3",
            "value": " 125/125 [00:00&lt;00:00, 3.05kB/s]"
          }
        },
        "8ea68f6b18c342938de8be19d3896038": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42f3b105ff645dcb58805289594baad",
            "placeholder": "​",
            "style": "IPY_MODEL_d4214693adb54e44b31fd40e549802b8",
            "value": "Generating test split: 100%"
          }
        },
        "8ebeabb6e81f466bb2e5c587f475d58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c3bd5b4fc2d480185bf8afe73720af5",
              "IPY_MODEL_5aa71718a83446e58408f5baada02739",
              "IPY_MODEL_19d3a395a2104e5eabc47c1f0ee7425b"
            ],
            "layout": "IPY_MODEL_3669f6c8d83e469da8ac6a0662b5b3b6"
          }
        },
        "8ed7a47170dc42739ff049440372b2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c0d4a0a16664758987fcc67422c2c89",
            "max": 12411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38bcb0d78ed94011936def4c3615504b",
            "value": 12411
          }
        },
        "8eda2864b2774815bd6d860c1fdf2625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ef69e815a9746de9cf72f70c7c55bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1bf2df4214449483a37dc84d9f3c43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91738a91e20344f1b848ccc39bd0b686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d88bd9fdda49bcbf01366f8fe6fab2",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5cfab63b2d47869f69b772f9801d69",
            "value": "Downloading data: "
          }
        },
        "91a8e2de38594a55828cb3e19f4b9d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91bcf74809894d39b5199ca23691f00f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91de7341a97a4415b5656ee33fe6395f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1bf2df4214449483a37dc84d9f3c43",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9afa2b87f4a94a58b7c639a0a7f63813",
            "value": 616
          }
        },
        "91eebca40ce344039704522c4570353c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91f909ed91a74906ac58b474dfb17b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd79c278334743d6a7f0c3c512924a74",
            "max": 5758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb05ae1df75e414b82a94b188118cfe9",
            "value": 5758
          }
        },
        "928bc9d9e240469298d2a267fe3b9e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595530337aab40f6b5cc24d69b3ebaf9",
            "max": 5145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85aa23b715f248248204a2bdf3e5f7ec",
            "value": 5145
          }
        },
        "92d450929c8e45539c2726eaf96d5ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92e674416f8646eaa6bcea05d083ed6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40710930eadf4cdea0ae4f21c9a457f6",
            "placeholder": "​",
            "style": "IPY_MODEL_c6c6f34f55c14980ad301ff3cbd6efd5",
            "value": " 14.1k/14.1k [00:00&lt;00:00, 641kB/s]"
          }
        },
        "933287a3795541209985a9585a4b9b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc49243de7304f988297672941344df1",
            "placeholder": "​",
            "style": "IPY_MODEL_cd5fef47a92845508ff3d61db7da9867",
            "value": "Downloading readme: 100%"
          }
        },
        "9343a32f5b0b4f0fb271430b6343831f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936348ad30684927b387b7e02efd4361": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d4f2893b8c47f388f2fd118fa8a0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20919ce79bb54810bae8420eac2e9d6a",
              "IPY_MODEL_84276e7b4ec141c3a7f5497bdc24a084",
              "IPY_MODEL_14bbc1a8479744c688060e76179bb910"
            ],
            "layout": "IPY_MODEL_e4d8a9054cbd4f36a0cbfd42d14a34d2"
          }
        },
        "93fdce4ab8d049cb8982686dfea11829": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941fd9d0a162417cb7cbc799339bc9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27942f0823b6469db6f785463d429e27",
              "IPY_MODEL_6aa762333f4e459092b6f2949203b7e7",
              "IPY_MODEL_3a95095e2d0845d793654199eba19cd5"
            ],
            "layout": "IPY_MODEL_c9fc0fbae8854d609c9a923c475f43ba"
          }
        },
        "9568bdb74f3e450f91b3558cf5ad5da1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96683385bb0048edab833d70bc9b94f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96e17bcfb86841e78640add9858f2e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96e7d97dc8f44c7d873060a89f82ce0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97343c8cd0be4a388806d2a08eee4f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93bf1eb51a742088ad7a78783af1550",
            "placeholder": "​",
            "style": "IPY_MODEL_96e17bcfb86841e78640add9858f2e73",
            "value": "Downloading builder script: 100%"
          }
        },
        "975d06eb7c6d48d7afc6f662b4239c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c8b7e081e834ccf98a4ce2730e00f24",
              "IPY_MODEL_8ed7a47170dc42739ff049440372b2d3",
              "IPY_MODEL_ba056ae684d5497c8639be605c2b152e"
            ],
            "layout": "IPY_MODEL_6319e3d301f040008853a8112bec28e3"
          }
        },
        "978f79f285df4b19ba87c30abe443649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979449deb4254629b80f0089584c851a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98804ca8de5c4af7ba392f82e2decc75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bd45b05dda4319adf853b5104f0a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "994c9803c31e49ec810796863532f52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99e3d22fc1584f63861fd9524949ee68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99ef066e53974658a59443c917b2c615": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a675022c08043438f0288c2dc3d1692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff58b4945b004e9996568c228986d287",
            "max": 28751,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1290569b6a4d490fbfc8ca3915983263",
            "value": 28751
          }
        },
        "9a7f1c78669845af9b39f2904b061b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ad1276e945e4915a079e97e06048ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9afa2b87f4a94a58b7c639a0a7f63813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c8b871e03af41ada7990e7b76084f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ae5a6ee9244aeea02e10990e8dd3da",
              "IPY_MODEL_470a84311bbf40c6ae6322d6edc353ae",
              "IPY_MODEL_8974203b2bde4395b3144ffe61596643"
            ],
            "layout": "IPY_MODEL_d4ea11ee38044f7cb7ffe1a5b018bda7"
          }
        },
        "9d5a89bd9cc94d019cc2dfbaa9ddf5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_094c77436878498099a7df8dddaade6b",
            "max": 6515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80ee1a5161b544b380fe6b2bf431ce00",
            "value": 6515
          }
        },
        "9e2644d3c3bb40aa9eba632e756112a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ebd09f91c5b4a1cbd4ec9d4baf00d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ef72b344a964832bd2b19140d230f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f512b3c83bf4fcaa1640cf5cdbea8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab64a9556124cf892f33cc9973240ea",
            "placeholder": "​",
            "style": "IPY_MODEL_656cb0e3b85c4a57936749caa02f664d",
            "value": " 3/3 [00:01&lt;00:00,  2.26it/s]"
          }
        },
        "a17af08f33c6440081c2fe9cd6e27a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b959f151f64f34949c2820e9684be8",
            "placeholder": "​",
            "style": "IPY_MODEL_994c9803c31e49ec810796863532f52f",
            "value": "Downloading builder script: 100%"
          }
        },
        "a1e33db2760f40aebfb725dc8261ac6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8990d6ddea74c9db353c3a8702ff7ca",
            "placeholder": "​",
            "style": "IPY_MODEL_2c0a41159b1241039386b5bf99d864c7",
            "value": " 1.77k/1.77k [00:00&lt;00:00, 86.0kB/s]"
          }
        },
        "a244c1afad7940caa2aacee1c7099d04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2bbd67afcb9463cb0f78d7a24c5f126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33ab96c585c411ab148d76865b848f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5183ef3eec0d4bdfbcc5544b0fec573b",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3751db7e581847efa6c224dd50c9b7bb",
            "value": 711396
          }
        },
        "a35999c21eed4068a9d768e200c148ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d880747de69431a896ecb1104284873",
            "placeholder": "​",
            "style": "IPY_MODEL_cb8c595679a6465abb9c836d570766bf",
            "value": " 28.4k/28.4k [00:00&lt;00:00, 1.22MB/s]"
          }
        },
        "a3c32097486242fabc161b3d3511a7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5f83f5df68d4ade896e03e3326c1f17",
              "IPY_MODEL_d207a39f2e344b668c345f522b60cca5",
              "IPY_MODEL_258524f690c449b793139e8b03d1fc9d"
            ],
            "layout": "IPY_MODEL_8dba751b9b1544369fcc9f4bca44c449"
          }
        },
        "a417b74f6fdb4dedbd6bf3408d0dea69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4848184b58645b2a572c6e1a1231f05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4eea440e6544b5fa1cb92745c17d138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9200fc6a2064330ae6ddbbf1b157fd4",
            "max": 10877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c061d153d6043beb838304e363dde5a",
            "value": 10877
          }
        },
        "a53d537c8c0e48d1a77fbc22e5c41402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02191a5509094a0abcf8862d3a8ee4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_5c69e45579f54fc6b2415ebbad4da477",
            "value": " 570/570 [00:00&lt;00:00, 6.61kB/s]"
          }
        },
        "a587d42c581c4f75984a189ebe1b1831": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5967030d5aa4581b66d319588b92db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6baecbf668bc4a6f93be03e5f671b76a",
              "IPY_MODEL_a33ab96c585c411ab148d76865b848f2",
              "IPY_MODEL_5589d685cbc94ea0a045dcba0e69a7e5"
            ],
            "layout": "IPY_MODEL_01ac22caf29c4b2baf0ebc428f3398b3"
          }
        },
        "a5f83f5df68d4ade896e03e3326c1f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0044237cbef746f9afbe688592bd0e84",
            "placeholder": "​",
            "style": "IPY_MODEL_8366f2cb708944b38ccd18c2407c2fd1",
            "value": "Downloading readme: 100%"
          }
        },
        "a606a8d169a64b138069d0469261b7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a611dd18d0284289b4b1dddf574f4e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824bdc0faabd449096459e491d7a7d45",
            "max": 8425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6de1573bc51f495fa27bf5cfecd85295",
            "value": 8425
          }
        },
        "a6770d150cfa459780d5adb12fc7c7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78608a4a3a8f4c119d9a0128153a39eb",
              "IPY_MODEL_91de7341a97a4415b5656ee33fe6395f",
              "IPY_MODEL_82f1dc2ca5ef4e45818a2b9107732d58"
            ],
            "layout": "IPY_MODEL_5e1a387877054dacbb6bf1fa32b08d7a"
          }
        },
        "a68b302b53b341d9918ebb3e3ef3048b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a76e83b34560423e82cbe55717f7082c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78c45e4929847f0a635988d1ef9d78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a87f8ff9f575436da0dcf9a31642f7b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8dcf6c462d14fba93e6b8335d0939e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92aa894397749729cba070a8ca45a58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f66a8eed1443d099d0fadab83d02e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9febc2bee944b66beb98c7ca39a2f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa099b9c51d6447a9a22fb13b103cb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a6cc127c8c4f03bab0b31bb3a1721b",
              "IPY_MODEL_08fbdead6ab540d4a1d2d8f06879e417",
              "IPY_MODEL_5f0512fb3607471f817b5c215d94e4d8"
            ],
            "layout": "IPY_MODEL_0457dfcb462c4173bbfb7890bb043c97"
          }
        },
        "aa46d7c838df43508b1187d034341421": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae2a30b7f474dbcbf55aa677b9518f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8bf4aa34c5452d8c6d01df44402eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abca76b7bf414761b58614bafd4acf18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e8acf24d3a43ba916dfcf016cc97cd",
            "max": 28387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd7af48fb7dc4ba5bdc583c19786cacf",
            "value": 28387
          }
        },
        "ad7eb1adf3b24d51b6d9db581ff11f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3c8e6e942294ddf913c84f52160737b",
              "IPY_MODEL_d149c9c014b54125be2f9ccb3f271504",
              "IPY_MODEL_5cc04f68fbda455aaf16e78c98ad9f9e"
            ],
            "layout": "IPY_MODEL_67b7ad21a48a4a339697122fd6e0c10e"
          }
        },
        "ad891b6016e143b1841351478cfc15a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9c165248ef4e0b9c357316b95f66af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc06005b98c44f0a6308cbd4f6a3527": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "addf3619a835489f8d9f3ce4498daf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adef362bc525401c8b657d33dfec55ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae85f3dd9b864de7897e02a2313c8093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea00ba0feb164981bdb521803fd29049",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16501e0f5de84fc7bbbdcc9b37f61d85",
            "value": 1
          }
        },
        "aeab7fe8570a418e8b0d6fa5ee4116cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af816340aae74a81a6eaf63a1933f5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afd68f4512e045c2bfaa46eb36d4ab5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f387685057a6405f86292bd9ce5df000",
            "max": 27887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_808dad49922a431d9c43faf48478a069",
            "value": 27887
          }
        },
        "b03b7f723b8748bfa4bfd987f80b472e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0546b4b929f4fe3927af49ab119d99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df31cc0682014cdb881817de1c02288f",
            "max": 2877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01fa51a473a6472da89d47bf1116e575",
            "value": 2877
          }
        },
        "b072faf11c504e39939d1ad4534f9112": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb4b68eda9f481abbc7b2456644e16b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c54d6fd6a004ed98c1cb595a0bb84a0",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b076eddbd7a74d5495615776c26a6f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f230ba518eed434fb107f97c66293470",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a7dd0c3112945959e9908425fcaa8b8",
            "value": 384
          }
        },
        "b08eba43d39846869bdd9050836be1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b166384a68ae4e3ebd9e3fe19b719885": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b17a0dd6bd24481e8e597415bfc02c87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c27f532e474f45af9a247df33df4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a0d30d3abf4da694265f61dc05d9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_9a7f1c78669845af9b39f2904b061b4d",
            "value": " 4.28k/4.28k [00:00&lt;00:00, 112kB/s]"
          }
        },
        "b34433ff3b52491fb5829b9f1522e162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34f87e950dc4fbbafc0e13414c81ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7d6c3a741249d48ebcda417eec08aa",
            "placeholder": "​",
            "style": "IPY_MODEL_d817d7511de84e92b77cd980658aa629",
            "value": "Downloading readme: 100%"
          }
        },
        "b42f3b105ff645dcb58805289594baad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4589d7a584b4690b47cd06b82c18053": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4c84bb6090644d3a7840c67f308dccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cecadb4b6d364dc9bcd443a913fac313",
              "IPY_MODEL_9d5a89bd9cc94d019cc2dfbaa9ddf5f3",
              "IPY_MODEL_585e63900ddb4fc098d8fdf6ab979b01"
            ],
            "layout": "IPY_MODEL_a92aa894397749729cba070a8ca45a58"
          }
        },
        "b5fc72b3f24643c892c8c5426deb48c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fca62c132b4b9c9af64955480ac905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65ef6da8ad34e2285813544d00bf3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b70156e5cb144e75b97697a2439d9a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70d5fa86a5b410cbfdff89da51ef6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b719af868833401c86d45d2ae059c868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7b946e1ad95455b818512986f83f7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7c9909bd1574248801e53bdf8827cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8d45f71d3da45968b6c845cf4744f70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9136a5d0eae4f9297b6b3490f36c0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8fbf86680854fd48a93c7f3def67d98",
            "placeholder": "​",
            "style": "IPY_MODEL_13e2a857eb49428aba8c96b962767d52",
            "value": " 1.90k/1.90k [00:00&lt;00:00, 89.0kB/s]"
          }
        },
        "b925756579154db5994a21d6768a00b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_359118bc2d25450cb5c69de24f84d533",
              "IPY_MODEL_778438eb8eba453fb926277641f26b35",
              "IPY_MODEL_5c0b31457c634b7fb06a00cb78362e09"
            ],
            "layout": "IPY_MODEL_4e5fc1ebc9b0447abc615de359a5e2fa"
          }
        },
        "b963a45c28d1437f86109f283a370f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b96a361475c947e5a0f9e5f0f867ced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c9ec9890384cb4b17139a7335e371e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adef362bc525401c8b657d33dfec55ce",
            "value": 1
          }
        },
        "b97f76334b48437dbb7d7365cb93d2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_864c3f3a16f648edada464a8397f7b6f",
            "max": 1896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d4ad789412a4b6895e89a53fb62b6d8",
            "value": 1896
          }
        },
        "ba056ae684d5497c8639be605c2b152e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361d5a3bb70e49a3bb27d843cf6b0afc",
            "placeholder": "​",
            "style": "IPY_MODEL_18db0004a5de4fe7a7b0ccc2a2e8fed3",
            "value": " 12.4k/12.4k [00:00&lt;00:00, 468kB/s]"
          }
        },
        "ba76516f42224f79a9dfe8a36385bb22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb472469d98c4849acbc2dd2cfe21495": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f62eff66629340149fb997d61bbda086",
              "IPY_MODEL_41ce600f2e84451cb91a75e4c1eb5cac",
              "IPY_MODEL_b1c27f532e474f45af9a247df33df4d5"
            ],
            "layout": "IPY_MODEL_fc6fde1c20494c289551b7356f1e341c"
          }
        },
        "bc087a4d9d3b4ee29f31dd677a44ad20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc799bb2e34741fabc79181ea30ee78f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7e0e6c4b154e55875c6fddc0aac6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcee86d4105743f5a69c595029994bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd79c278334743d6a7f0c3c512924a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd79d8ce5e28404c988f4965873a2f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc7642ca3e748069974df4a510470ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1034a93ce59f439bb128b6c096eefdf2",
              "IPY_MODEL_4a16335de26a43c09d578cbbe20e98d1",
              "IPY_MODEL_573b3112cbee4ba581c18884df0a269e"
            ],
            "layout": "IPY_MODEL_4fe04dcab6654d0594a56109e7eb6805"
          }
        },
        "be0e2757b3c34fb68b46cc21e471a077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be7af49d0afe4ecdaa800be969d5a3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2166426a7a224f1da2065f3221463693",
            "placeholder": "​",
            "style": "IPY_MODEL_77d712d32c0f491cb9a58df33b012b0c",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c05be6815b304522ab70ebeb2dd1a3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9343a32f5b0b4f0fb271430b6343831f",
            "max": 4164,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c9d94d1b8b74549b9f473c5220b32b0",
            "value": 4164
          }
        },
        "c0908ccc452b42e681765c37a139e878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74fd39704b44cea8f012402e7449a80",
            "max": 9815,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5e5dd22e0b24a30a485b54dbdacf1cf",
            "value": 9815
          }
        },
        "c0a77f0c068c451298dc5c4904a51cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15a5c91a236400aa4873a4fe74d78be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90d99092731428f86c1125913e520f0",
            "max": 9006,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be0e2757b3c34fb68b46cc21e471a077",
            "value": 9006
          }
        },
        "c16dd57325504698b35f155d1bd040b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c19adb67cf904bdc89b23db9c463ad70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1ad349038c94c1f9ec7b1d0d7245699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c225230ea12f4f90bd461485f300580e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2beabf523574127b916e27b1be2a248": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e8acf24d3a43ba916dfcf016cc97cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c508e67d54c24888b82b66108681da19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71e718353ac40788febf07676b3cb25",
            "placeholder": "​",
            "style": "IPY_MODEL_addf3619a835489f8d9f3ce4498daf36",
            "value": " 3668/3668 [00:01&lt;00:00, 2844.62 examples/s]"
          }
        },
        "c519b80ce005494caf41456ec90111bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5323c16a9ca4decbe25c651a14517de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5adcad970e4455cbf797f14e2e5303e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f6c046574b4badbf5dac2bd4989d67",
            "placeholder": "​",
            "style": "IPY_MODEL_e844aa942c604f17b61375f59aad56f3",
            "value": "Downloading builder script: 100%"
          }
        },
        "c6b2dc48588b482f80e9a2473dc5b452": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6c6f34f55c14980ad301ff3cbd6efd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7208573f8204d9b9f0956753eda0ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7537c19825a49cd8f3343c153fe56ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d86dc22b0747dba72d6aa5fd899df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7fcfc2727db445695b908ffd3370feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0851189dae4fbdb953f6afe6f3ba29",
            "placeholder": "​",
            "style": "IPY_MODEL_01f4a70e089f4fe5abb0d9246aeee403",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "c8990d6ddea74c9db353c3a8702ff7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f8b1493e1b4b2bb1a8f99719c21c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d37d5db223e4588a13a65429c6b644c",
            "max": 1766,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e627e0a7f374421b9b84f440789e99c0",
            "value": 1766
          }
        },
        "c90d99092731428f86c1125913e520f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92ca0a6d3b9472f98613666cdeb0d73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9fc0fbae8854d609c9a923c475f43ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca5cfab63b2d47869f69b772f9801d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafc757655d74a2697f4ba566b3623ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1837578698f426d8c65a40770a3488c",
            "placeholder": "​",
            "style": "IPY_MODEL_fdf37a5ac48c477d99318631238a5756",
            "value": "Generating train split: 100%"
          }
        },
        "cb05ae1df75e414b82a94b188118cfe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb8c595679a6465abb9c836d570766bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbeae0b822a5446f9687157d33c457fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ad6947770a94c819fe4b90b67d8dedc",
            "placeholder": "​",
            "style": "IPY_MODEL_f014adc3358445d4adc91797f81544a7",
            "value": " 8.71k/8.71k [00:00&lt;00:00, 300kB/s]"
          }
        },
        "cc95388f183f414991678bdf20e380fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402d63f4215a480aba1156661261a877",
            "max": 5110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b166384a68ae4e3ebd9e3fe19b719885",
            "value": 5110
          }
        },
        "cce2d3a52ab449a9b8539a663f88dc23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4b814a828847d7882704c3032d3fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd5fef47a92845508ff3d61db7da9867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd748fe04232441abb30f153e54f9890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf772bf44f8400caf20d7df43bad6c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cea7f31b2095405591f6f983f29a59ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cecadb4b6d364dc9bcd443a913fac313": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb32c9a099f242f49454f7f4fa9379a4",
            "placeholder": "​",
            "style": "IPY_MODEL_978f79f285df4b19ba87c30abe443649",
            "value": "Downloading readme: 100%"
          }
        },
        "cfa5b162648c4abca773a478c3e3beb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d149c9c014b54125be2f9ccb3f271504": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0a77f0c068c451298dc5c4904a51cc6",
            "max": 3821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aeab7fe8570a418e8b0d6fa5ee4116cc",
            "value": 3821
          }
        },
        "d151de5a1862426f9d3ab2aaae73f4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1837578698f426d8c65a40770a3488c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1dafb9eb15541489d740cbf202fac2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc06005b98c44f0a6308cbd4f6a3527",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eace7bc2187b4dd0af47dbee9327903a",
            "value": 1
          }
        },
        "d1f164ebe9824ae4986a5fb9913b5d79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d207a39f2e344b668c345f522b60cca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3525c2478cdb44dd9b80f4b5f4af2659",
            "max": 9339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56c0600f62514fea9a456a457720311b",
            "value": 9339
          }
        },
        "d265db9a419d4edfbdb91e4bd8f78846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a8de725a934927b52792351e0d5099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d365ebcd816a44da80bc74870dd008bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36c80ffd8824fdb8e1e344f41fa3669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3c8e6e942294ddf913c84f52160737b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318eb12f8c014bf090024d2d0e82e127",
            "placeholder": "​",
            "style": "IPY_MODEL_712c22b5be60449bb23b7555a5c22038",
            "value": "Downloading builder script: 100%"
          }
        },
        "d4214693adb54e44b31fd40e549802b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4acc49dcd844d7892ab2a432e79d56a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4ccb21f87954a31ab7ab0fd7e11a8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4ea11ee38044f7cb7ffe1a5b018bda7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56da3a1733e4c7990cc8a7dcded2474": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5bb855c24c944e1b76c9e9414020778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6012c2d60024501a1bd8c529bf055e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d684c0d984204682b0797ffe01c55cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b34f87e950dc4fbbafc0e13414c81ecf",
              "IPY_MODEL_4451aba03f3a4d378cfeb04ceee5481f",
              "IPY_MODEL_2b9d70f4869c456b994ef7166e42d253"
            ],
            "layout": "IPY_MODEL_1ed23c72816b4505bb41e26c734a471b"
          }
        },
        "d6ccd976679e45fcbf6d6b5d06360ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71e718353ac40788febf07676b3cb25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72812af3cd8475f8a76a8ff3ec236e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74fd39704b44cea8f012402e7449a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d817d7511de84e92b77cd980658aa629": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87e9ee37dfe44bcad7b97ccfef0f5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ce4959b2bc410a8b455eb2adb7ffc9",
            "placeholder": "​",
            "style": "IPY_MODEL_422ac21cdb1d45a8a0814ef00c9769ff",
            "value": "Downloading readme: 100%"
          }
        },
        "d8c1e448fcc84881898158a453e1b003": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cd233c207bb4c86ac5d002fff7f1d89",
              "IPY_MODEL_da5372cb9eff4fc79e53215de91ba50d",
              "IPY_MODEL_787eddad8809411fa14915244c03c24d"
            ],
            "layout": "IPY_MODEL_47ed21294f9e42d9817708809f620d5f"
          }
        },
        "d9238e5174354b99abc293fffd924410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93bf1eb51a742088ad7a78783af1550": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d947bfe9101646c9a7222ada482d4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a90b08aaec44d9962e8c090b8d0baa",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70225a6a843d4ccf87d1b43d4cf1895b",
            "value": 125
          }
        },
        "d9a90b08aaec44d9962e8c090b8d0baa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9bcbb8cd61d4fa5b9e0b95304f8969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea68f6b18c342938de8be19d3896038",
              "IPY_MODEL_0b0c4175d283414ab014c95269b4421b",
              "IPY_MODEL_00c7829ca16746089c8896865f374b1f"
            ],
            "layout": "IPY_MODEL_f9f77be1c3044483bbd3714a5a45e2ad"
          }
        },
        "da3eb201a16240aaa91baf19b49d4209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da5372cb9eff4fc79e53215de91ba50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a2bf19539642259412fbb1b4d9f69f",
            "max": 1705,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cea7f31b2095405591f6f983f29a59ef",
            "value": 1705
          }
        },
        "da9e8a5d31f64f98baabcdd61a092cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729e25ed88bd4d4d89338d0d8e54d4dc",
            "placeholder": "​",
            "style": "IPY_MODEL_d5bb855c24c944e1b76c9e9414020778",
            "value": " 4.16k/4.16k [00:00&lt;00:00, 118kB/s]"
          }
        },
        "dab6a9ff832540bfae51a3f0dcfedfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5adcad970e4455cbf797f14e2e5303e",
              "IPY_MODEL_928bc9d9e240469298d2a267fe3b9e65",
              "IPY_MODEL_24e977d511bd4f03bc8d730cd4c86027"
            ],
            "layout": "IPY_MODEL_4b4dae6b5bd5474491e1c86a6e462ebf"
          }
        },
        "dae9d080adfc4bfbba896820bbf57c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "db1f664494c94faf8998df1f25718b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c96dd4ef67f4900af004f322706921f",
            "placeholder": "​",
            "style": "IPY_MODEL_c519b80ce005494caf41456ec90111bf",
            "value": " 27.9k/27.9k [00:00&lt;00:00, 587kB/s]"
          }
        },
        "dc49243de7304f988297672941344df1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd68849bd0a44238fbb9bec129b0511": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb2d1c4288447748b7f2379ec2d49dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24f281ec4d904b27a5f45a7820fff9a9",
              "IPY_MODEL_f08a92940f3444298e26db95fe957e78",
              "IPY_MODEL_7bafeac027304b49b44f913fdbfdd54d"
            ],
            "layout": "IPY_MODEL_71ea3c60b4104f41b1fc714a4aaa4ae8"
          }
        },
        "ddeff3c577cc4817806eb81c79a2f3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44673cba464f4e5799fc317192a5d987",
            "placeholder": "​",
            "style": "IPY_MODEL_a606a8d169a64b138069d0469261b7ab",
            "value": " 10.9k/10.9k [00:00&lt;00:00, 354kB/s]"
          }
        },
        "de7a2b9ab0ae42a38b4188f5a837ffe0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea6b34486294d388d68aa9ef3aaa281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70156e5cb144e75b97697a2439d9a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_96e7d97dc8f44c7d873060a89f82ce0e",
            "value": " 440M/440M [00:05&lt;00:00, 85.0MB/s]"
          }
        },
        "df31cc0682014cdb881817de1c02288f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df893a2f587e456288a0fd0b30438669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df8de4914b3f4c51b4e048f053a0e009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfd3f1f64d81471083416a3e4ca6aa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c9ec9890384cb4b17139a7335e371e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e24e2408e27249d4841b1633f386f012": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f772d1181b417e8f3bc2feee4f6e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825fb9aa19594a61b2a779837eb230b4",
              "IPY_MODEL_b076eddbd7a74d5495615776c26a6f3e",
              "IPY_MODEL_75d76bf886514ba5ac9fedee0fcfba8d"
            ],
            "layout": "IPY_MODEL_e9685ee9b4aa47fcb5a3a79261ca87c7"
          }
        },
        "e3108925761e44a5b772723a970eeb09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31dc156f8034495a5737385ef032e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e34566724c6e4598860e77d6b710faf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e362a74248d24aa28ab7dd3500c9d303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f66a8eed1443d099d0fadab83d02e9",
            "placeholder": "​",
            "style": "IPY_MODEL_292c0b150eb84f06a012e2084b035350",
            "value": " 1.05M/? [00:00&lt;00:00, 3.55MB/s]"
          }
        },
        "e3712984d7774865be2c1e97faf82d57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45fad24ed164a8ebd0856fa32df68cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70d5fa86a5b410cbfdff89da51ef6f8",
            "placeholder": "​",
            "style": "IPY_MODEL_52a159d9e9854013bf1a5cf711d50093",
            "value": "Downloading metadata: 100%"
          }
        },
        "e4d8a9054cbd4f36a0cbfd42d14a34d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e627e0a7f374421b9b84f440789e99c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e713295328e84a95abfc13fd5e0fbf79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76cddc6d7d04d3fb01c11225ec1b6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bd0a23537441b6a41373c7db399423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bdb5cce9c364437970f01220e5f0aa3",
              "IPY_MODEL_5df7aa079833485bbde65e4658b496e0",
              "IPY_MODEL_e9149263e2264fe6b5e5cb50f67d55c2"
            ],
            "layout": "IPY_MODEL_e3712984d7774865be2c1e97faf82d57"
          }
        },
        "e7f79d2154784e4dac011fb680cf5e60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84136de295d4d39b44c908ff2458ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e844aa942c604f17b61375f59aad56f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e891d996e42f425cb2b31d563dfc77ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216e1650231e471fa0d88e3d73bf6da0",
              "IPY_MODEL_d1dafb9eb15541489d740cbf202fac2f",
              "IPY_MODEL_e362a74248d24aa28ab7dd3500c9d303"
            ],
            "layout": "IPY_MODEL_1eb78591c14840daaf6741730f2280f8"
          }
        },
        "e8f710e2dcfc40398ce16a4ac265cc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177dee7aa0754c7db2b595f83a4eb105",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe3c4d6e4774be691e7c0551fd334ff",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "e8fbf86680854fd48a93c7f3def67d98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9149263e2264fe6b5e5cb50f67d55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8bf4aa34c5452d8c6d01df44402eea",
            "placeholder": "​",
            "style": "IPY_MODEL_c1ad349038c94c1f9ec7b1d0d7245699",
            "value": " 28.7k/28.7k [00:00&lt;00:00, 559kB/s]"
          }
        },
        "e9200fc6a2064330ae6ddbbf1b157fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93bede3188e4bf1bdd1de7ecb919483": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e954280499de40579d62a674e1c2acc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9685ee9b4aa47fcb5a3a79261ca87c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97d23572a21475fa4b5b9fa4454d4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68db1531b9574e72a2ff0d52995a7347",
            "placeholder": "​",
            "style": "IPY_MODEL_eeafa1a037dd42a88774f76ea6275360",
            "value": " 6.22k/? [00:00&lt;00:00, 91.2kB/s]"
          }
        },
        "e982215023c24a3caf881dd3986cca86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e9912207e85a49819be3aa3f5f9a9397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea00ba0feb164981bdb521803fd29049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ea178923525e40c28517d6d88d97745e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25e3340ed1fa4ff28744b87cd44ff756",
              "IPY_MODEL_c15a5c91a236400aa4873a4fe74d78be",
              "IPY_MODEL_7291eb717846498f83f7591b1733334b"
            ],
            "layout": "IPY_MODEL_3d362a5dfe9b4554bff3647a29f1d93d"
          }
        },
        "eab2c2bd6f424206b26c9c2e5bec6cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e45fad24ed164a8ebd0856fa32df68cb",
              "IPY_MODEL_eb8445f4f2474f128a9a34ee815a09ad",
              "IPY_MODEL_5e0b9eeeed064894be9807fc5464073a"
            ],
            "layout": "IPY_MODEL_ef63ffca2aaf4e6c9953cf5af742addf"
          }
        },
        "eace7bc2187b4dd0af47dbee9327903a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb0aa78ac5ed4e8189871f2dcb7b68d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb8445f4f2474f128a9a34ee815a09ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_356f65307a5b4ffb845b0a51dd82a10a",
            "max": 7520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09ceb11ff6e34ecf995aab26e8f9c05d",
            "value": 7520
          }
        },
        "ebf0c7ac01e441d68a38cac5fed89d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecf9c5705a7b491c82d4e8b5cbd8c439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeafa1a037dd42a88774f76ea6275360": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef41b64939ce43f5bf0a7e2a2c34e5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97343c8cd0be4a388806d2a08eee4f83",
              "IPY_MODEL_0bfcee1a11c64820be92f82b36ae1f3b",
              "IPY_MODEL_77222effa92b47c4b9b5aca2e1fc7971"
            ],
            "layout": "IPY_MODEL_85a8afac57e741c8ba4e5fca23d29c82"
          }
        },
        "ef504e4ab1384063bff714e1649e0aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef63ffca2aaf4e6c9953cf5af742addf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f014adc3358445d4adc91797f81544a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f05a48bb63db4f7aba5ccaba188b75fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f08a92940f3444298e26db95fe957e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bab212ec66b4136b3c2c695ba309c07",
            "max": 6243,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9912207e85a49819be3aa3f5f9a9397",
            "value": 6243
          }
        },
        "f10d3cde2d7b4121971d8e19e3362b30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f230ba518eed434fb107f97c66293470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3537b58aca04f398663d6a8f6bd7cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3707c74969e4f6c84d6a36b59d6fa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f511160291e4a4a82f8694772449ea8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91eebca40ce344039704522c4570353c",
            "value": 231508
          }
        },
        "f387685057a6405f86292bd9ce5df000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f6078f2844467fa8b6e2dfa45eeefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f471e7ebb7c245179c58992fc78b3e55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a51d5c122645a5a58acfbadb0cf752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8631f393c12e4ebaa57838a4f1c1efb0",
            "max": 9832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7e0e6c4b154e55875c6fddc0aac6f0",
            "value": 9832
          }
        },
        "f4bb56cde5b042e8821ee26d25da4ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe8145192c34433b3140f05b5b2528f",
            "placeholder": "​",
            "style": "IPY_MODEL_3988d9e57bc841b49a5079130f071dfc",
            "value": " 296/408 [00:00&lt;00:00, 1064.07 examples/s]"
          }
        },
        "f53073dd81bf427188a9cfde75c18bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b5f6a6687b34036bd5a87c8b61dc2c3",
              "IPY_MODEL_b0546b4b929f4fe3927af49ab119d99a",
              "IPY_MODEL_37e0abc511f04624986368ef45b50131"
            ],
            "layout": "IPY_MODEL_d365ebcd816a44da80bc74870dd008bd"
          }
        },
        "f54be5e820704ad2b31b6b7a6b946181": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5912ed9e9c944e5ae35be20f0634165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5dfeae5f20a425cab5a19aa8ae340ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e5dd22e0b24a30a485b54dbdacf1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f619ea2b062a4eacb80ade328d56c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f62de3a243d54c358d31fef138b73997": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fd737f15fe74553a4cd7d29ecd813f2",
              "IPY_MODEL_cc95388f183f414991678bdf20e380fc",
              "IPY_MODEL_1295ac5c11614966bff2570a26fe515c"
            ],
            "layout": "IPY_MODEL_a8dcf6c462d14fba93e6b8335d0939e5"
          }
        },
        "f62eff66629340149fb997d61bbda086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3108925761e44a5b772723a970eeb09",
            "placeholder": "​",
            "style": "IPY_MODEL_f05a48bb63db4f7aba5ccaba188b75fe",
            "value": "Downloading readme: 100%"
          }
        },
        "f68c38cc7bf84db2ab1540ca985599e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f697e928e02f405d99c43c4b1fd890c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5912ed9e9c944e5ae35be20f0634165",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d86dc22b0747dba72d6aa5fd899df0",
            "value": " 1/1 [00:00&lt;00:00, 33.60it/s]"
          }
        },
        "f6a686a076954e0c9c5d11429a14d582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a320f7b8bba47ddb97d2aff966e162f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e215f7f87fc48bfbb3e74c9c97b23a8",
            "value": 3
          }
        },
        "f6c454dc6dcb4528b7b05b83c72640fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6fdd2a41cb1482a9b2b869776dd1dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7ca459667fe48c2a54d0ca13ccfe114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91738a91e20344f1b848ccc39bd0b686",
              "IPY_MODEL_ae85f3dd9b864de7897e02a2313c8093",
              "IPY_MODEL_e97d23572a21475fa4b5b9fa4454d4cc"
            ],
            "layout": "IPY_MODEL_32f65d2703c048929de10720219fdf53"
          }
        },
        "f7ef96f903a348829426015c210a75c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81a1dd1a8b547b39297478219b41c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9d88bd9fdda49bcbf01366f8fe6fab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f77be1c3044483bbd3714a5a45e2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fa205a1da88e418a881efb0963042e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa23b88cb754258a876d7d6132c2903": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb064cacf0e243299a2d092facae8c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7af49d0afe4ecdaa800be969d5a3e7",
              "IPY_MODEL_560c716068a645d596cc2fe9b886c0ad",
              "IPY_MODEL_08c60bb508854cc9b6772ab78502b6fb"
            ],
            "layout": "IPY_MODEL_e84136de295d4d39b44c908ff2458ba9"
          }
        },
        "fb32c9a099f242f49454f7f4fa9379a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc03f25dc1d642a79e21e2ff2be3dd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51b2478fccc64ed99f54ef99d1ddffd5",
            "placeholder": "​",
            "style": "IPY_MODEL_a68b302b53b341d9918ebb3e3ef3048b",
            "value": "Downloading readme: 100%"
          }
        },
        "fc2d3eb4b1304b97bf336245736983ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d798a40b2a24c4f8ce823023d75ea6a",
              "IPY_MODEL_429379eb4c4f452d94a52521911811a8",
              "IPY_MODEL_49a90c227b9342ddbb670c9fe85591cc"
            ],
            "layout": "IPY_MODEL_843d11a2271246f49dbabe80fc4762d4"
          }
        },
        "fc40e712ccca489e8cb2eaadbc47aa54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87e9ee37dfe44bcad7b97ccfef0f5ff",
              "IPY_MODEL_afd68f4512e045c2bfaa46eb36d4ab5a",
              "IPY_MODEL_db1f664494c94faf8998df1f25718b9f"
            ],
            "layout": "IPY_MODEL_63a2424581894ab48ad61b9f38cc882e"
          }
        },
        "fc6fde1c20494c289551b7356f1e341c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb506371e6e4cd2947988d6c7050809": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd75292380894c7db8ec027b6667c9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_372c8e31995545df9d59d0d39733e49a",
              "IPY_MODEL_abca76b7bf414761b58614bafd4acf18",
              "IPY_MODEL_a35999c21eed4068a9d768e200c148ed"
            ],
            "layout": "IPY_MODEL_145fcb4a45264b089edb8c7503470d72"
          }
        },
        "fd7af48fb7dc4ba5bdc583c19786cacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdf37a5ac48c477d99318631238a5756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe156388571b4c63b5fc5f5ca857e522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe935a9cce43441f94e231c54e34779b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fed7ec45ec594d90bc2d11c56f8330ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee5b87f231c40e49a6b5408520948e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feec1cb456ec4924a79fc88b601d3ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff58b4945b004e9996568c228986d287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe8145192c34433b3140f05b5b2528f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d054a9b7e542a2b3baacae63505902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c8ab19e291e49abb168771f34f815cf",
              "IPY_MODEL_28b6b9dd2e764332b9f70f44ea76dd88",
              "IPY_MODEL_03bf9c4f6d2e4522b45662b08b132119"
            ],
            "layout": "IPY_MODEL_8463c6ee6a6a4495a99ec524e6b45b0b"
          }
        },
        "9c8ab19e291e49abb168771f34f815cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d610e9d8f1c40aba63271f63e816f52",
            "placeholder": "​",
            "style": "IPY_MODEL_44b63624787b4dc7b92f77a1b1401523",
            "value": "Resolving data files: 100%"
          }
        },
        "28b6b9dd2e764332b9f70f44ea76dd88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ebfe65a2ed34ba192ea315c5adedc8c",
            "max": 1650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ebfe1d120694a0b8017349380832d46",
            "value": 1650
          }
        },
        "03bf9c4f6d2e4522b45662b08b132119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d6717e21f34e78aff2ba659915049e",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a643803d32406391d24a7d34a76314",
            "value": " 1650/1650 [00:00&lt;00:00, 3025.35it/s]"
          }
        },
        "8463c6ee6a6a4495a99ec524e6b45b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d610e9d8f1c40aba63271f63e816f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b63624787b4dc7b92f77a1b1401523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ebfe65a2ed34ba192ea315c5adedc8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ebfe1d120694a0b8017349380832d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21d6717e21f34e78aff2ba659915049e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a643803d32406391d24a7d34a76314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c9c1811fae340ceb7492141e6c851ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77c0ad37b8ef4924a88e3841f440582c",
              "IPY_MODEL_8d97cd879ba847c49bd2efee97cbb580",
              "IPY_MODEL_cc41c738e24b4f69839b4d56dff7e6c8"
            ],
            "layout": "IPY_MODEL_14a6bb9a906d480cbea0aced476bc387"
          }
        },
        "77c0ad37b8ef4924a88e3841f440582c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425a7763611e48dbba54d8d727332a42",
            "placeholder": "​",
            "style": "IPY_MODEL_3020e229affc4700aa868dd4a2b5e571",
            "value": "Resolving data files: 100%"
          }
        },
        "8d97cd879ba847c49bd2efee97cbb580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c488eb7f9c44e1f8af1954b13de5836",
            "max": 5534,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b6fb92ae8674429aacb5e3ea6c71bc6",
            "value": 5534
          }
        },
        "cc41c738e24b4f69839b4d56dff7e6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_199e3a188ac34c81afec0f8a00814586",
            "placeholder": "​",
            "style": "IPY_MODEL_d727d6119b3548d5893b2575f32423b8",
            "value": " 5534/5534 [00:01&lt;00:00, 2505.76it/s]"
          }
        },
        "14a6bb9a906d480cbea0aced476bc387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425a7763611e48dbba54d8d727332a42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3020e229affc4700aa868dd4a2b5e571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c488eb7f9c44e1f8af1954b13de5836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b6fb92ae8674429aacb5e3ea6c71bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "199e3a188ac34c81afec0f8a00814586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d727d6119b3548d5893b2575f32423b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}