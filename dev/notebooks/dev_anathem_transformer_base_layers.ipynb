{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faraway1nspace/AnathemTransformer/blob/main/dev/notebooks/dev_anathem_transformer_base_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gcFatBIhzdu"
      },
      "source": [
        "## Development Notebook: build and test base layers for Anathem Transformer (aka Silo'd Transformer)\n",
        "\n",
        "### Notes\n",
        "- the google-minature models have the same vocab size and heads as bert-large-ucased\n",
        "- the minature-google papers discusses the classification and distallation tasks & corpus's including:\n",
        "    - *NLI* (Natural language inference involves classifying pairs of sentences (a premise and a hypothesis) as entailment, contradiction, or neutral. This task is representative of the scenario in which proxy data is non-trivial to gather (Gururangan et al., 2018). We chose MNLI (Williams et al., 2018) as our target dataset. Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "    - *sentiment analysis* -\n",
        "- the MTEB leader best model is e5-large (24 layers) which uses the CLS token. It is also \"instruction fine-tuned\", requiring query and passage prefixes.\n",
        "- distillation example: https://github.com/philschmid/knowledge-distillation-transformers-pytorch-sagemaker/blob/master/knowledge-distillation.ipynb\n",
        "    - they set temperature to 2: which results in a flatter probability distribution. I could make this dynamic -> start 0.5 progress to 1\n",
        "    - they set alpha to 0.5, which balances label-loss vs distil-loss\n",
        "\n",
        "#### Loss MLM - hf example:\n",
        "- https://github.com/huggingface/transformers/blob/601ac5b1dc1438f00d09696588f2deb0f045ae3b/src/transformers/modeling_bert.py#L1001-L1004\n",
        "    - notice that when initializing CrossEntropyLoss, the ignore index is -100, so, when I make the masked-token objective, I can compute the loss by masking out all -100?\n",
        "\n",
        "\n",
        "#### DataCollator for Masked MLM - hf example\n",
        "- https://github.com/huggingface/transformers/blob/ee88ae59940fd4b2c8fc119373143d7a1175c651/src/transformers/data/data_collator.py#L607\n",
        "\n",
        "\n",
        "# Dataset specifics\n",
        "\n",
        "### From the Google mini-architectures:\n",
        "- with labels: Williams 2018 (NLI-task): citation: https://aclanthology.org/N18-1101/; available at https://huggingface.co/datasets/multi_nli  \n",
        "    - how should I process these? [sep] or sentence pairs? or both?\n",
        "    - I could do sentence-pairs for teaching & labels, I guess (why not)\n",
        "    - I could also include concatenated text, stricly with labels (what would be the point of this though? Better sub-sectioning the input data, not so much a sentence-vector thing\n",
        "- with no-labels, used for teaching: Since strictly in-domain data is difficult to obtain, we supplement DT with two other sentence-pair datasets: SNLI (Bowman et al., 2015) and QQP (Chen et al., 2018).\n",
        "\n",
        "### 1) MLM Tasks\n",
        "- Pile (multi-domain, books, wiki, law, and more) - curate and remove twitter  \n",
        "    - see urls at: https://github.com/EleutherAI/the-pile/blob/master/the_pile/datasets.py\n",
        "    - https://the-eye.eu/public/AI/pile_preliminary_components/\n",
        "- Supplements to pile:  \n",
        "    - https://huggingface.co/datasets/him1411/EDGAR10-Q - numeric filings\n",
        "    - eloukas/edgar-corpus - annual reports (but it is in weird sections)\n",
        "    - LEDGAR .jsonl https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A - this can be streamed too\n",
        "    - Pile of Law - https://huggingface.co/datasets/pile-of-law/pile-of-law - but cannot be streamed\n",
        "- JanosAudran/financial-reports-sec - SEC financial reports in small sentences\n",
        "- RefinedWeb - a competitor to Pile, curated common-crawl - https://arxiv.org/abs/2306.01116\n",
        "- CNN_dailymail? ag_news?\n",
        "\n",
        "### A) Retrieval Tasks\n",
        "In general, what loss would I use for the QA & retrieval tasks? Distillation is obvious, but what about\n",
        "- SQUAD - has QA pairs - squad_v2\n",
        "    - good for distillation\n",
        "- ORCA - has GPT-like prompting QA pairs: https://huggingface.co/datasets/Open-Orca/OpenOrca/viewer/Open-Orca--OpenOrca/train?row=29\n",
        "- Simple-Wiki https://huggingface.co/datasets/embedding-data/simple-wiki - has paraphrases\n",
        "- embedding-data/coco_captions_quintets - multiple captions as paraphrases\n",
        "- embedding-data/simple-wiki - pairs of paraphrases from wikipedia\n",
        "- embedding-data/SPECTER - triplets of {anchor, pos, neg}, small headline-like snippets in technical /statistical /science fields\n",
        "- https://huggingface.co/embedding-data - has a lot of retrieval tasks\n",
        "- LLukas22/scidocs - titles and abstracts\n",
        "- LEDGAR - can possible do triplets on same label\n",
        "- Rahmaa/ElsevieR_ClEaN - possible relation between title and abstract\n",
        "- embedding-data/WikiAnswers - 25 question paraphrases (maybe no answers)\n",
        "\n",
        "### B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- LLukas22/lfqa_preprocessed - question and answers 226k\n",
        "- gbharti/finance-alpaca (like FIQA - finance Q&A)\n",
        "- embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- sciq - science questions - see question and support\n",
        "- wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers\n",
        "- EnglishDictionary - auto convert \"What is the definition of X'?\n",
        "\n",
        "## C) NER tasks\n",
        "- tner/ontonotes5 - has > 12 entities and 59.9k\n",
        "- tner/multinerd - 23 entiteis and 157k test set - see also tner/wikineural which has a 98.8k training set?\n",
        "-\n",
        "\n",
        "\n",
        "# Teacher Models\n",
        "\n",
        "## Embeddings\n",
        "Mteb leaderboard\n",
        "\n",
        "- instructor-xl / large - this does best, but it prepends instructions that are domain specific (like science this, or wikipedia that.... it could be possible to do that with the Pile dataset, possible) https://huggingface.co/hkunlp/instructor-xl\n",
        "- https://huggingface.co/intfloat/e5-large-v2 - winner otherwise\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6mZMauZ9KW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XS2jBKoMmMn"
      },
      "source": [
        "#### Playing Around with novel architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQy_iTw-1g8O",
        "outputId": "99c1000a-93db-410c-f3fa-ae1711733ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, rank_bm25, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.14.0 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 rank_bm25-0.2.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0 xxhash-3.2.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "bCv855u5Mlgr",
        "outputId": "1d562d9e-05a3-405e-fffa-e6301d59a2e2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5f5cdcd6a5ec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataSet' from 'torch.utils.data' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, DataSet\n",
        "from typing import List, Optional\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "\n",
        "model_string = 'google/bert_uncased_L-12_H-512_A-8' # 'distilroberta-base\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "basemod = AutoModel.from_pretrained(model_string)\n",
        "basemod.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tNKrJaiXDvA"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "eNfU7szJWwfh",
        "outputId": "afd7de82-dcac-45b0-f9a1-4b874b1f529b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-761fa45d06d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomTokenizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google/bert_uncased_L-12_H-512_A-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cls_prepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "class CustomTokenizer:\n",
        "    def __init__(self, model_string='google/bert_uncased_L-12_H-512_A-8', n_cls_prepend = 4, n_pad_to_multiple_of=4):\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not (k[0]=='_' or k=='tokenize' or k=='encode' or k=='build_inputs_with_special_tokens' or k == 'batch_encode_plus'):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "\n",
        "        # run through base tokenizer\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens, return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        #batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "\n",
        "\n",
        "# Note, if I use the vanilla LineByLineTextDataset, it just calls tokenizer.__call__ turns on the `use_special_tokens`, and it pads to a multiple of optional\n",
        "# .. so somehow I need to ensure that, whatever base function it calls as part of the tokenizer pipeline, it will continue using MY new function\n",
        "# the tokenizer.__call__ DOES NOT use `encode` nor `tokenize` otherwise my modifications would manifest\n",
        "# looks like `prepare_for_model` (and maybe `batch_prepare_for_model`) is what adds special tokens?\n",
        "# looks like `prepare_for_model` just calls `build_inputs_with_special_tokens`, so maybe intervene there?\n",
        "#         if add_special_tokens:\n",
        "#            sequence = self.build_inputs_with_special_tokens(ids, pair_ids)\n",
        "#            token_type_ids = self.create_token_type_ids_from_sequences(ids, pair_ids)\n",
        "# editing `build_inputs_with_special_tokens` didn't work either\n",
        "\n",
        "# FOOFU:\n",
        "# see how .pad works: https://github.com/huggingface/transformers/blob/c5454eba9eac00a3e7d0a46a3d25aacd43187f1e/src/transformers/tokenization_utils_base.py#L2887\n",
        "# notice the `self.model_input_names[0]` list for a tokenizer -> I should update this for my unique inputs\n",
        "# ... and there is also a ._pad function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te7PvCnbvX-E"
      },
      "outputs": [],
      "source": [
        "tokenizer2 = CustomTokenizer()\n",
        "tokenizer2.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjHCfFlda8w"
      },
      "outputs": [],
      "source": [
        "#toks = tokenizer2.encode(text[0], add_special_tokens=True)\n",
        "#print(len(toks)) # works\n",
        "#print(toks[:10])\n",
        "\n",
        "tokens = tokenizer2(text, padding='longest', return_tensors=None) # doesn't work, obviously\n",
        "#print(tokens)\n",
        "print(len(tokens['input_ids'][0]))\n",
        "print(len(tokens['attention_mask'][0]))\n",
        "\n",
        "print(len(tokens['input_ids'][1]))\n",
        "print(len(tokens['attention_mask'][1]))\n",
        "\n",
        "tokens\n",
        "\n",
        "#tokenizer2.batch_encode_plus(text, add_special_tokens=True) # doesn't work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo5BhFq0kuJH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DToaqxfoM6bR"
      },
      "outputs": [],
      "source": [
        "dir(basemod)\n",
        "# base embedding layers\n",
        "layer_emb = copy.deepcopy(basemod._modules['embeddings'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha_xqtWlNIfI"
      },
      "outputs": [],
      "source": [
        "# base trasnformers (full)\n",
        "layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9OMlauFNTPZ"
      },
      "outputs": [],
      "source": [
        "# text\n",
        "text = [\n",
        "    \"A standard indemnity clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with legal issues1.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a payment obligation2. The trigger event or circumstance is the breach of the agreement, willful misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "import math\n",
        "\n",
        "#padding_length = int(math.ceil(max_length / 4)) * 4\n",
        "tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "input_shape = tokens['input_ids'].size()\n",
        "\n",
        "# change token padding to be multiple of 4\n",
        "#ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "#if input_shape[-1]!=ideal_length:\n",
        "#  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "#  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "tokens['token_type_ids'] = token_type_ids\n",
        "past_key_values_length =0\n",
        "\n",
        "# need to extend attention mask\n",
        "extended_attention_mask = basemod.get_extended_attention_mask(tokens['attention_mask'], input_shape)\n",
        "tokens['extended_attention_mask'] = extended_attention_mask\n",
        "print(tokens.keys())\n",
        "print(tokens['input_ids'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4DF2F2y3WVs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIisgmAC3SgY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_PXX-SRjd7Mv",
        "outputId": "9be41735-2875-4ac5-ee8e-d0be3fbf3a2b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c65df7c427ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m silo_dimensions = {0:basemod.config.hidden_size,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbasemod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   }\n\u001b[1;32m      5\u001b[0m \u001b[0mreintegration_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msilo_dimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'basemod' is not defined"
          ]
        }
      ],
      "source": [
        "silo_dimensions = {0:basemod.config.hidden_size,\n",
        "                  1:basemod.config.hidden_size//2,\n",
        "                  2:basemod.config.hidden_size//4,\n",
        "                  }\n",
        "reintegration_dim = silo_dimensions[1] + silo_dimensions[2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XuMY6iaRNpOc",
        "outputId": "a9e272e9-2e80-4b29-dc62-536f42bd1334"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-40b0ed09dca5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_output = layer_emb(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'position_ids'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_emb' is not defined"
          ]
        }
      ],
      "source": [
        "embedding_output = layer_emb(\n",
        "            input_ids=tokens['input_ids'],\n",
        "            position_ids=tokens.get('position_ids',None),\n",
        "            token_type_ids=tokens['token_type_ids'],\n",
        "            inputs_embeds=None,\n",
        "            past_key_values_length=past_key_values_length\n",
        ")\n",
        "print(embedding_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3kgUzTJsO_1i",
        "outputId": "5d16b103-4d99-40de-8c0c-039faefd0e64"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-40a2b2d12b51>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# basemodel transformer outputs: *full bert model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m out_l1 = layer_basetransformer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extended_attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#tokens['attention_mask'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_basetransformer' is not defined"
          ]
        }
      ],
      "source": [
        "# basemodel transformer outputs: *full bert model\n",
        "out_l1 = layer_basetransformer(\n",
        "    hidden_states = embedding_output,\n",
        "    attention_mask = tokens['extended_attention_mask'],#tokens['attention_mask'],\n",
        "    head_mask=None,\n",
        "    encoder_hidden_states=None,\n",
        "    encoder_attention_mask=None,\n",
        "    #past_key_values=0,\n",
        "    #use_cache=None,\n",
        "    output_attentions=True,\n",
        "    #output_hidden_states=True,\n",
        "    #return_dict=True\n",
        ")\n",
        "\n",
        "hidden_states_l1 = out_l1[0]\n",
        "self_attention_l1 = out_l1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvj_XlNsTYXt"
      },
      "outputs": [],
      "source": [
        "# Next Layer:\n",
        "# Query -> max pool and reduce  hidden dimension // 2\n",
        "# Key -> reduce hidden_dim // 2\n",
        "# value -> reduce hidden_dim //2\n",
        "#maxpool_l2 = nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "maxpool_l2 = nn.Sequential(\n",
        "    nn.Dropout(0.05),\n",
        "    nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True),\n",
        ")\n",
        "\n",
        "maxpool_l2_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ5xAaELVuwk",
        "outputId": "b5dbf2f4-277d-4b55-97ac-0453fed2908d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n",
            "torch.Size([2, 24, 768])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 48])\n",
            "torch.Size([2, 1, 1, 48])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "# reduce dimension of hidden states\n",
        "hiddens_states_l1_reduced = maxpool_l2(hidden_states_l1)\n",
        "print(hidden_states_l1.shape)\n",
        "print(hiddens_states_l1_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l1_reduced = maxpool_l2_attn(tokens['attention_mask'].float())\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "print(input_shape)\n",
        "extended_attention_mask_l1_reduced = basemod.get_extended_attention_mask(attention_mask_l1_reduced, attention_mask_l1_reduced.shape)\n",
        "print(tokens['extended_attention_mask'].shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AcdIY3shHWN"
      },
      "outputs": [],
      "source": [
        "# Try to do Multi Headed attenion with differently sized query and value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYHtEQNFgh7U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "import copy\n",
        "\n",
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "bertlayer_l2_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")\n",
        "\n",
        "bertlayer_l3_reduction = BertSelfAttnDimensionReduction(\n",
        "    config=basemod.config,\n",
        "    hidden_size_input=basemod.config.hidden_size // 2,\n",
        "    position_embedding_type=basemod.config.position_embedding_type,\n",
        "    dim_reduction = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03mPp6aHgh9Y",
        "outputId": "e19aaf75-0247-498f-d967-2777f6f6df2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2 = bertlayer_l2_reduction(\n",
        "        hidden_states = hiddens_states_l1_reduced,\n",
        "        attention_mask = extended_attention_mask_l1_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l1,\n",
        "        encoder_attention_mask= tokens['extended_attention_mask'],\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "hidden_states_l2 = out_l2[0]\n",
        "print(hidden_states_l2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlN5aOsYgh_z",
        "outputId": "29b499c5-25ab-4dfb-de8e-ffc76c316e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12])\n",
            "torch.Size([2, 1, 1, 12])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Next dimension reduction:\n",
        "hiddens_states_l2_reduced = maxpool_l2(hidden_states_l2)\n",
        "print(hidden_states_l2.shape)\n",
        "print(hiddens_states_l2_reduced.shape)\n",
        "\n",
        "# reduce dimension of attention mask\n",
        "attention_mask_l2_reduced = maxpool_l2_attn(attention_mask_l1_reduced.float())\n",
        "print(attention_mask_l2_reduced.shape)\n",
        "\n",
        "# extend the dimension of the reduced attention_mask\n",
        "extended_attention_mask_l2_reduced = basemod.get_extended_attention_mask(attention_mask_l2_reduced, attention_mask_l2_reduced.shape)\n",
        "print(extended_attention_mask_l2_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  out_l3 = bertlayer_l3_reduction(\n",
        "        hidden_states = hiddens_states_l2_reduced, # input has been maxpooled\n",
        "        attention_mask = extended_attention_mask_l2_reduced,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states = hidden_states_l2,\n",
        "        encoder_attention_mask= extended_attention_mask_l1_reduced,\n",
        "        past_key_value=None,\n",
        "        output_attentions=False\n",
        "    )\n",
        "  hidden_states_l3 = out_l3[0]\n",
        "  print(hidden_states_l3.shape)\n",
        "\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q-GTg2fgiCB",
        "outputId": "c44f4175-70a0-4e38-e774-ee10df37de88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"_name_or_path\": \"distilroberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 192,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.29.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "\n",
        "config_lowres_encoder = copy.deepcopy(basemod.config)\n",
        "config_lowres_encoder.hidden_size = config_lowres_encoder.hidden_size//4\n",
        "config_lowres_encoder.num_hidden_layers = 3\n",
        "print(config_lowres_encoder)\n",
        "\n",
        "# The outputs of the bertlayer_l3_reduction can now run through a usual BertLayer for 3 times\n",
        "encoder_lowres = BertEncoder(config_lowres_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIN07S24_qp",
        "outputId": "bd44c178-932e-4c56-bfc8-56363ef9bff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "out_encoder_lowres = encoder_lowres(\n",
        "    hidden_states=hidden_states_l3,\n",
        "    attention_mask=extended_attention_mask_l2_reduced,\n",
        "    head_mask = None,\n",
        "    return_dict=True,\n",
        ")\n",
        "hidden_states_lowres = out_encoder_lowres[0]\n",
        "print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM75xap8L5cB"
      },
      "outputs": [],
      "source": [
        "## Upresolution Layer: up-resolution from dim-3 to dim-2 is as follows:\n",
        "# hs_l3 -> upsampled sequence-length as hs-l2\n",
        "# -> could have another attention-based mechanism that expands dimension of hs-l2\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "#hidden_states_upscaled_3to2_nearest = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='nearest').transpose(-2,-1)\n",
        "#hidden_states_upscaled_3to2_linear = nn.functional.interpolate(hidden_states_rowres.transpose(-2,-1), scale_factor=2, mode='linear').transpose(-2,-1)\n",
        "\n",
        "upscaler_x2 = InterpolateCombo(scale_factor=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lfpn9mEsPPCf"
      },
      "outputs": [],
      "source": [
        "hidden_states_upscaled3to2 = upscaler_x2(hidden_states_lowres)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GXB-9waPBv_"
      },
      "outputs": [],
      "source": [
        "## BertAttentiveIntegrator\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edzAlaOIPDa5"
      },
      "outputs": [],
      "source": [
        "bertlayer_l3_to_l2_crossattn = BertCrossAttention(\n",
        "        config=basemod.config,\n",
        "        hidden_size=silo_dimensions[1],\n",
        "        hidden_size_query=silo_dimensions[2],\n",
        "        position_embedding_type=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMmeXSBoipPv",
        "outputId": "ffce4e9c-101b-4d90-c31e-ea81ce0828be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 192])\n",
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24])\n",
            "torch.Size([2, 1, 1, 24])\n"
          ]
        }
      ],
      "source": [
        "print(hidden_states_upscaled3to2.shape)\n",
        "print(hidden_states_l2.shape)\n",
        "print(attention_mask_l1_reduced.shape)\n",
        "print(extended_attention_mask_l1_reduced.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVMll5RTQyVh",
        "outputId": "5ac82f6c-dd52-4295-9534-159d0dd26ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "out_l2_postencode = bertlayer_l3_to_l2_crossattn(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "hidden_states_l2_postencode = out_l2_postencode[0]\n",
        "print(hidden_states_l2_postencode.shape)\n",
        "assert hidden_states_l2_postencode.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5HD6Rc7POU",
        "outputId": "17ff76a1-827c-4945-9ae6-92535113b493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n",
            "3072\n",
            "4.0\n"
          ]
        }
      ],
      "source": [
        "print(basemod.config.hidden_size)\n",
        "print(basemod.config.intermediate_size)\n",
        "print(basemod.config.intermediate_size/basemod.config.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_ElURFHWk3B"
      },
      "outputs": [],
      "source": [
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_query,\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = query_hidden_states,\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeJysFTAgZm_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from low-res to mid-res\n",
        "bert_integrative_layer_midres = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[2],\n",
        "    intermediate_size=silo_dimensions[1]*4,\n",
        ")\n",
        "\n",
        "# from mid-res to high-res\n",
        "bert_integrative_layer_hires = BertIntegrativeLayer(\n",
        "    basemod.config,\n",
        "    hidden_size=silo_dimensions[0],\n",
        "    hidden_size_query=reintegration_dim,\n",
        "    intermediate_size=silo_dimensions[0]*4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcZ3MU-4hFN3",
        "outputId": "c521b9fe-1ccc-4e49-d8df-75f4801f795b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "hidden_states_midres = bert_integrative_layer_midres(\n",
        "    hidden_states = hidden_states_l2,\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled3to2,\n",
        "    query_attention_mask = attention_mask_l1_reduced\n",
        ")\n",
        "print(hidden_states_midres.shape)\n",
        "assert hidden_states_midres.shape == hidden_states_l2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iavtqpUohJAs",
        "outputId": "272bdcee-3341-41ea-bd80-87a1b6d0fe8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 576])\n"
          ]
        }
      ],
      "source": [
        "# upscale the l2 and l3 to the full dimension\n",
        "upscaler_x4 = InterpolateCombo(scale_factor=4)\n",
        "hidden_states_upscaled3to1 = upscaler_x4(hidden_states_lowres)\n",
        "hidden_states_upscaled2to1 = upscaler_x2(hidden_states_midres)\n",
        "\n",
        "hidden_states_upscaled = torch.cat(\n",
        "    (hidden_states_upscaled2to1, hidden_states_upscaled3to1),\n",
        "    axis=2)\n",
        "\n",
        "print(hidden_states_upscaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gDwXueYhJ1B",
        "outputId": "ed02eb22-18ea-4bce-91b2-bfc5ccf3ccd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 768])\n"
          ]
        }
      ],
      "source": [
        "# final layer to bring it up to full dimension\n",
        "hidden_states_hires = bert_integrative_layer_hires(\n",
        "    hidden_states = hidden_states_l1,\n",
        "    attention_mask = extended_attention_mask,\n",
        "    head_mask = None,\n",
        "    query_hidden_states = hidden_states_upscaled,\n",
        "    query_attention_mask = extended_attention_mask\n",
        ")\n",
        "print(hidden_states_hires.shape)\n",
        "assert hidden_states_hires.shape == hidden_states_l1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv4ZVcYORoL_",
        "outputId": "df6aca9a-68c3-4cc4-c579-7fa0e8518c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_states_hires.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJQJVvdMle3v",
        "outputId": "3e4830ce-7b1c-4d9b-c584-947339137ee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 24])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_mask_l1_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Z0KGMfm-Mn"
      },
      "source": [
        "### The Reduce and Integrate layer:\n",
        "- this is like a Transformer block, but:\n",
        "- does dimension reduction along sequence and embedding-dim\n",
        "- includes a skip connection from previous hidden-states of the same dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExGOdKwWm_46"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# this is the layer that just does cross-attention between a seq-reduced query and full-size value and key\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "\n",
        "BertReduceAddIntegrativeLayer\n",
        "inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkiZo9Npm_xi"
      },
      "outputs": [],
      "source": [
        "# initialize the mid-resolution BertReduceAndIntegrate layer\n",
        "bert_reduce_add_integrate_midres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[1], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[0],\n",
        "    hidden_size_query=silo_dimensions[0],\n",
        "    intermediate_size=silo_dimensions[1]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")\n",
        "\n",
        "bert_reduce_add_integrate_lowres = BertReduceAddIntegrativeLayer(\n",
        "    config,\n",
        "    hidden_size = silo_dimensions[2], # size of mid-res\n",
        "    hidden_size_input=silo_dimensions[1],\n",
        "    hidden_size_query=silo_dimensions[1],\n",
        "    intermediate_size=silo_dimensions[2]*3,\n",
        "    dim_reduction=2,\n",
        "    do_concat_hidden_and_query = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxtTomiPxQn8",
        "outputId": "0d221d7e-a51b-4a93-af5f-a7f23af07e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 24, 384])\n",
            "torch.Size([2, 24, 384])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_hires_reduced = maxpool_l2(hidden_states_hires)\n",
        "assert hidden_states_hires_reduced.shape[1] == hidden_states_midres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres.shape)\n",
        "hidden_states_midres = bert_reduce_add_integrate_midres(\n",
        "    inputs = hidden_states_hires, # from highres outputs previous layer (key, values)\n",
        "    hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "    attention_mask = extended_attention_mask_l1_reduced,\n",
        "    head_mask=None,\n",
        "    query_hidden_states = hidden_states_hires_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        ")\n",
        "print(hidden_states_midres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPGNtX3KxQuY",
        "outputId": "9a5d53a5-acf3-4255-b624-7aa38bf0ad9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 384])\n",
            "torch.Size([2, 12, 192])\n",
            "torch.Size([2, 12, 192])\n"
          ]
        }
      ],
      "source": [
        "# Reduce sequence-dim from l1->l2, and from high-res->mid-res\n",
        "hidden_states_midres_reduced = maxpool_l2(hidden_states_midres)\n",
        "assert hidden_states_midres_reduced.shape[1] == hidden_states_lowres.shape[1] # reduced-seq-dim should be same as mid-res hidden-states\n",
        "print(hidden_states_midres_reduced.shape)\n",
        "\n",
        "if True:\n",
        "  print(hidden_states_lowres.shape)\n",
        "  hidden_states_lowres = bert_reduce_add_integrate_lowres(\n",
        "      inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "      hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "      attention_mask = extended_attention_mask_l2_reduced,\n",
        "      head_mask=None,\n",
        "      query_hidden_states = hidden_states_midres_reduced # reduced version of high-res inputs (reduced along sequence dimenion)\n",
        "  )\n",
        "  print(hidden_states_lowres.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFdByXbYAz2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJAHT_SyxQwK"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from transformers.modeling_utiles import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQPJPPkpmibK"
      },
      "source": [
        "### Base-Layer nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbBLQZJJlu6n"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.activations import ACT2FN\n",
        "from typing import List, Optional, Tuple, Union\n",
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 2, # number of transformer stacks\n",
        "    scale_ratio2 = 0.5, # reduce sequence-length by X, from high-res to mid-res\n",
        "    scale_ratio3 = 0.25, # reduce sequence-length by Y, from high-res to low-res\n",
        "    multipler_intermediate2 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    multipler_intermediate3 = 4.0, # intermeidate size is a multiple of hidden size\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05, # dropout when performing downscaling from one-sequence length to next\n",
        "    use_cheap_integrator_for_stacks = [],\n",
        "    do_mlm=False,# whether to output MLM token predictions\n",
        "    do_cls=False,# whether to output a pooled sentence-vector for sequence classification\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config,'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks',num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multipler_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multipler_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", use_cheap_integrator_for_stacks)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        # cheap (non-transformer) method to integrate high- and mid-res hidden states\n",
        "        bert_integrative_layer_1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        # full Transformer layer as mid-to-highres upscaling\n",
        "        BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query=config.query_size1,\n",
        "            intermediate_size=config.intermediate_size_l1//2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrative_layer_2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_query=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    bert_integrative_layer_1 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size,\n",
        "        hidden_size_query=config.query_size1,\n",
        "        intermediate_size=config.intermediate_size_l1\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrative_layer_2,\n",
        "        bert_integrative_layer_1\n",
        "    )\n",
        "\n",
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_l1\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"attention\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrative_layer_2,\n",
        "            bert_integrative_layer_1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrative_layer_2 = bert_integrative_layer_2\n",
        "        self.bert_integrative_layer_1 = bert_integrative_layer_1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrative_layer_2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled3to2        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        hidden_states_upscaled = torch.cat((\n",
        "            hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        ),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrative_layer_1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_highres,\n",
        "            head_mask = None,\n",
        "            query_hidden_states = hidden_states_upscaled,\n",
        "            query_attention_mask = extended_attention_mask_highres\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "class BertClassificationHead(nn.Module):\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "def tokenize_anathem(text, device=device):\n",
        "    #padding_length = int(math.ceil(max_length / 4)) *\n",
        "    tokens = tokenizer(text,padding=True, return_tensors='pt', pad_to_multiple_of=4)\n",
        "    input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    # change token padding to be multiple of 4\n",
        "    #ideal_length = int(math.ceil(input_shape[-1] / 4)) * 4 # should be a multiple of 4\n",
        "    #if input_shape[-1]!=ideal_length:\n",
        "    #  tokens = tokenizer(text,padding='max_length', max_length = ideal_length, return_tensors='pt')\n",
        "    #  input_shape = tokens['input_ids'].size()\n",
        "\n",
        "    token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "    tokens['token_type_ids'] = token_type_ids\n",
        "    for k,v in tokens.items():\n",
        "        tokens[k] = v.to(device)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdRq7bM3pQhp",
        "outputId": "452ade89-f3b4-4404-ab8f-8442de7689bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#config = make_config('distilroberta-base')\n",
        "#config = make_config('t5-small') # can't use t5 because it uses relative\n",
        "config = make_config('google/bert_uncased_L-12_H-512_A-8') #\n",
        "\n",
        "if False:\n",
        "  (tokenizer,basemod,layer_embedding,layer_basetransformer,maxpool,maxpool_attn,bert_reducer_l2,\n",
        "   bert_reducer_l3,bert_encoder_lowres,upscaler_x2,upscaler_x4,bert_integrative_layer_2,bert_integrative_layer_1) = initialize(config)\n",
        "\n",
        "# make the basemod and tokenizer\n",
        "basemod = AutoModel.from_pretrained(config.model_string)\n",
        "basemod.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgEOUtHYoB-I"
      },
      "outputs": [],
      "source": [
        "# the Anathem encoder includes the embeddings and first transformer block\n",
        "anathem_encoder1 = AnathemBaseModule(config, basemod, tokenizer)\n",
        "anathem_encoder2 = AnathemMidModule(config, basemod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87RTY9a059mQ"
      },
      "outputs": [],
      "source": [
        "cls_head = BertClassificationHead(config, n_classes = 3, activation = 'none',device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-1aZOdgB_g8"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"* Welcome home to this gorgeously upgraded, beautifully maintained, three-bedroom home with double attached garage. Drive up to this quiet cul-de-sac and let the experience begin. On the main floor, you’ll notice the abundance of natural light. There is a separate office with view over the front of the property. The layout was customized, with a great open living space. The kitchen is a chef’s dream, with a breakfast bar, granite countertops, stainless steel appliance package, a pantry, and a view out to the sunny west facing yard.\",\n",
        "    \"There’s room for formal dining and the family room has a gas fireplace to relax by on the cooler nights. Out back, there’s a stunner of a deck, perfect for BBQ season! Upstairs, you’ll find a massive bonus room with tons of windows. There are two, secondary bedrooms and the master suite is amazing\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbt_zlrlCVEU"
      },
      "outputs": [],
      "source": [
        "tokens = tokenize_anathem(text,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XpXyV6YW4DI",
        "outputId": "6e4777a3-d95c-48ce-d799-2b761e72213c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#stack 1\n",
        "out1 = anathem_encoder1(\n",
        "      input_ids = tokens['input_ids'],\n",
        "      attention_mask = tokens['attention_mask'],\n",
        "      token_type_ids = tokens['token_type_ids']\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A87nQ24Ccoh",
        "outputId": "bbf75272-c1db-4da1-9543-acfe3832812b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.8376, -0.3891, -0.6668],\n",
              "        [-0.8747, -0.3621, -0.7735]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stack2\n",
        "out2 = anathem_encoder2(\n",
        "      hidden_states_highres = hidden_states[0],\n",
        "      hidden_states_midres = hidden_states[1],\n",
        "      hidden_states_lowres = hidden_states[2],\n",
        "      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        ")\n",
        "(hidden_states, extended_attention_masks) = out2\n",
        "\n",
        "cls_head(hidden_states[0], tokens['attention_mask'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQ9ABhkU8pE",
        "outputId": "76b0b2cb-196f-44c5-9079-4b9992a9835d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 48, 768])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out1[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBi1G7ay63nr"
      },
      "outputs": [],
      "source": [
        "####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2L-jYJ6u4qd"
      },
      "outputs": [],
      "source": [
        "## Next steps, do something simple like sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLHCo5vZ-brJ"
      },
      "outputs": [],
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from scipy.special import softmax\n",
        "#datasets_list = list_datasets()\n",
        "#[k for k in datasets_list if 'phrasebank' in k]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "04db53bae1ea4e81a1acbad7401cd331",
            "81afc2262c8545dab41aacde91066b7d",
            "b96a361475c947e5a0f9e5f0f867ced7",
            "f697e928e02f405d99c43c4b1fd890c9",
            "6da885f236a24cf5a09add7c9927db76",
            "638f36ef35ec4ec88ba057c63093eca2",
            "4b35ff0e35ca4e6088f2f1f687ff924c",
            "e1c9ec9890384cb4b17139a7335e371e",
            "adef362bc525401c8b657d33dfec55ce",
            "f5912ed9e9c944e5ae35be20f0634165",
            "c7d86dc22b0747dba72d6aa5fd899df0"
          ]
        },
        "id": "rvjAv19p1Un6",
        "outputId": "a84e2ae7-d09e-49f8-b454-00f8c494fd17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset financial_phrasebank (/root/.cache/huggingface/datasets/financial_phrasebank/sentences_75agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04db53bae1ea4e81a1acbad7401cd331",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#[k for k in datasets_list if 'phrasebank' in k]\n",
        "\n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_75agree')\n",
        "\n",
        "# split\n",
        "idx_train, idx_val = train_test_split(np.arange(len(dataset['train']['sentence'])), test_size=0.1)\n",
        "dataset_train = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]}  for idx in idx_train]\n",
        "dataset_val = [{'text':dataset['train']['sentence'][idx], 'label':dataset['train']['label'][idx]} for idx in idx_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_fRokuwB1h9",
        "outputId": "cbbc64cc-0bad-42bd-987c-aec7460b3960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3107\n",
            "346\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset_train)); print(len(dataset_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B86BY_m_x12"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    \"\"\"torch dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.data = dataset\n",
        "        self.n = len(self.data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        unit = self.data[idx]\n",
        "        return unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh3NKKrZ_xuX"
      },
      "outputs": [],
      "source": [
        "ds_train = MyDataset(dataset_train)\n",
        "ds_val = MyDataset(dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn4rR8QqEiS3"
      },
      "outputs": [],
      "source": [
        "batch_size_train = 12\n",
        "batch_size_val = 36\n",
        "lr = 0.00005\n",
        "eval_iter = 20\n",
        "n_epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9JPB6miBpQ9"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(ds_train, batch_size=batch_size_train, shuffle=True)\n",
        "dl_val = DataLoader(ds_val, batch_size=batch_size_val, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbhvjxbeKHh9"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(list(anathem_encoder1.parameters()) + list(anathem_encoder2.parameters()) + list(cls_head.parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "fPmQOT5OEnEY",
        "outputId": "cd172411-6a85-4bce-f076-9d03d8dc276f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:19: f1:0.402 (0.000); prec:0.352 (0.000); rec:0.469 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:39: f1:0.326 (0.000); prec:0.400 (0.000); rec:0.372 (0.000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:59: f1:0.459 (0.158); prec:0.531 (0.405); rec:0.485 (0.095)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:79: f1:0.506 (0.305); prec:0.583 (0.450); rec:0.494 (0.231)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:99: f1:0.499 (0.190); prec:0.555 (0.383); rec:0.551 (0.116)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:119: f1:0.552 (0.280); prec:0.663 (0.568); rec:0.534 (0.179)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:0; i:139: f1:0.661 (0.469); prec:0.708 (0.600); rec:0.636 (0.385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-d95d13a5603a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "optimizer.zero_grad()\n",
        "anathem_encoder1.train()\n",
        "anathem_encoder2.train()\n",
        "cls_head.train()\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "\n",
        "      # tokenize the batch\n",
        "      tokens = tokenize_anathem(batch['text'],device)\n",
        "      target = batch['label'].to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      out1 = anathem_encoder1(\n",
        "        input_ids = tokens['input_ids'],\n",
        "        attention_mask = tokens['attention_mask'],\n",
        "        token_type_ids = tokens['token_type_ids']\n",
        "      )\n",
        "      (hidden_states, extended_attention_masks) = out1\n",
        "\n",
        "      features,_ = anathem_encoder2(\n",
        "          hidden_states_highres = hidden_states[0],\n",
        "          hidden_states_midres = hidden_states[1],\n",
        "          hidden_states_lowres = hidden_states[2],\n",
        "          extended_attention_mask_highres = extended_attention_masks[0],\n",
        "          extended_attention_mask_midres = extended_attention_masks[1],\n",
        "          extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "      )\n",
        "\n",
        "      # prediction\n",
        "      preds = cls_head(features[0], tokens['attention_mask'])\n",
        "\n",
        "      # loss\n",
        "      loss = nn.functional.cross_entropy(preds, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # do evaluation\n",
        "      if ((iteration+1) % eval_iter)==0:\n",
        "          anathem_encoder1.eval()\n",
        "          anathem_encoder2.eval()\n",
        "          cls_head.eval()\n",
        "          # tokenize the eval\n",
        "          eval_logits = []\n",
        "          eval_targets = []\n",
        "          for i, batch_eval in enumerate(tqdm(dl_val, disable=True)):\n",
        "              with torch.no_grad():\n",
        "                  # tokenize the batch\n",
        "                  tokens_eval = tokenize_anathem(batch_eval['text'], device)\n",
        "                  labels_eval = batch_eval['label'].to(device)\n",
        "                  out_eval1 = anathem_encoder1(\n",
        "                      input_ids = tokens_eval['input_ids'],\n",
        "                      attention_mask = tokens_eval['attention_mask'],\n",
        "                      token_type_ids = tokens_eval['token_type_ids']\n",
        "                  )\n",
        "                  (hidden_states, extended_attention_masks) = out_eval1\n",
        "                  features,_ = anathem_encoder2(\n",
        "                      hidden_states_highres = hidden_states[0],\n",
        "                      hidden_states_midres = hidden_states[1],\n",
        "                      hidden_states_lowres = hidden_states[2],\n",
        "                      extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                      extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                      extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "                  )\n",
        "                  # prediction\n",
        "                  batch_logits = cls_head(features[0], tokens_eval['attention_mask'])\n",
        "                  eval_logits+=batch_logits.detach().tolist()\n",
        "                  eval_targets+=labels_eval.detach().tolist()\n",
        "\n",
        "          eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)\n",
        "          print('E:%d; i:%d: f1:%0.3f (%0.3f); prec:%0.3f (%0.3f); rec:%0.3f (%0.3f)' % (epoch, iteration, eval_f1.mean(), eval_f1.min(), eval_prec.mean(), eval_prec.min(), eval_recall.mean(), eval_recall.min()))\n",
        "          cls_head.train()\n",
        "          anathem_encoder1.train()\n",
        "          anathem_encoder2.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVZ7tZ7JYSO",
        "outputId": "60a71e09-6d52-49f5-f42d-bf6cb36c9d2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZugKHbocDR0"
      },
      "source": [
        "## Test performance speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chS7dYV4cA2a",
        "outputId": "97dccd81-d967-42a4-de00-278241cc1dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for anathem: 33283328\n"
          ]
        }
      ],
      "source": [
        "# how many parameters in the model in total\n",
        "from math import prod\n",
        "nparam = 0\n",
        "for encoder in [anathem_encoder1, anathem_encoder2]:\n",
        "    for na,l in encoder.named_parameters():\n",
        "        nparam+=prod(l.data.shape)\n",
        "print('Number of parameters for anathem: %d' % nparam)\n",
        "# 33676544"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOKuhoSQgN28",
        "outputId": "118fbf58-b22a-4e63-ee9a-b5382eba30f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# compare this to distilbert\n",
        "#other_mod = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "other_mod = AutoModel.from_pretrained('google/bert_uncased_L-12_H-512_A-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNPeFA5gg-3u",
        "outputId": "c58db76c-2e88-4cf8-d1e1-ddc3ee70b194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters for other-mod: 53982720\n"
          ]
        }
      ],
      "source": [
        "nparam = 0\n",
        "for na,l in other_mod.named_parameters():\n",
        "    nparam+=prod(l.data.shape)\n",
        "\n",
        "print('Number of parameters for other-mod: %d' % nparam)\n",
        "\n",
        "# number of parameters for anathem-trans: 33676544 (google/bert_uncased_L-12_H-512_A-8)\n",
        "# number of parametres for anathem-trans: 78973824 (includng 2 more mid-res encoders)\n",
        "# number of parameters for anathem-trans: 73062528 (with a 768 dimension)\n",
        "# Number of parameters for distilroberta: 82118400 (with a 768 dimension)\n",
        "# Number of parameters  all-MiniLM-L6-v2: 22713216\n",
        "# Number of parameters google/bert_uncased_L-12_H-512_A-8: 53982720 (512 dim, 12L)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En8rgr4mSNBt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIeQesGRSOKl"
      },
      "source": [
        "## Test Performance Speed at inference (CPU)\n",
        "- distilroberta-base: 10 batches: 23.517s , CPU\n",
        "- oogle/bert_uncased_L-12_H-512_A-8: 10 batches: 12.44s, CPU\n",
        "- anathem (distilroberta-768): 10 batches, 23.23s,\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 10 batches, ~7.5s, CPU\n",
        "\n",
        "## Test Performance Speed at inference (GPU)\n",
        "- anathem ((google/bert_uncased_L-12_H-512_A-8)): 30 batches, 0.79s, GPU\n",
        "- google/bert_uncased_L-12_H-512_A-8: 30 batches: 0.8 GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwXj277YTa71"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiKeaFEQKLUg",
        "outputId": "db5c7019-151b-4bc7-de75-6bacfd6d2e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8027215003967285\n"
          ]
        }
      ],
      "source": [
        "time1 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time2 = time.time()\n",
        "        print(time2-time1)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        (hidden_states, extended_attention_masks) = anathem_encoder1(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )\n",
        "        features,_ = anathem_encoder2(\n",
        "            hidden_states_highres = hidden_states[0],\n",
        "            hidden_states_midres = hidden_states[1],\n",
        "            hidden_states_lowres = hidden_states[2],\n",
        "            extended_attention_mask_highres = extended_attention_masks[0],\n",
        "            extended_attention_mask_midres = extended_attention_masks[1],\n",
        "            extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaHOImksIE4s",
        "outputId": "e25c00cc-a643-46ff-ed4f-a54be0b86c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7066085338592529\n"
          ]
        }
      ],
      "source": [
        "time3 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time4 = time.time()\n",
        "        print(time4-time3)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        out = basemod(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpDJu4TrGJme",
        "outputId": "3223ab06-d6db-4c25-da03-b33c72689884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.86464646, 0.52173913])"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kO-XYGLFCuk"
      },
      "outputs": [],
      "source": [
        "eval_prec,eval_recall,eval_f1,eval_support = precision_recall_fscore_support(eval_targets, np.array(eval_logits).argmax(axis=1),zero_division=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcAhKojQOKOt"
      },
      "source": [
        "## Variant: Possibly Faster Integrative Layer\n",
        "\n",
        "The above version uses a BertIntegrativeLayer that uses the high-res hidden-states as the key/values, and the upscaled-low res as the query\n",
        "\n",
        "This variant flips it: the high-res is the query (thereby upscaling via attention) and the low-res are the value and keys\n",
        "\n",
        "#### Varient #2 has slightly fewer parameters: 33283328 vs 336"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVu2yPrYDJrr",
        "outputId": "d790c978-c641-49d1-dc88-b3566f1e93df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 huggingface-hub-0.16.4 multiprocess-0.70.14 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2 xxhash-3.2.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch transformers datasets zstandard rank_bm25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxVyqa3vNlYc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForMaskedLM\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda import is_available\n",
        "if is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "from transformers.activations import ACT2FN\n",
        "import copy\n",
        "import math\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, Optional, Sequence, Tuple, Union\n",
        "from transformers.utils import PaddingStrategy\n",
        "\n",
        "EncodedInput = List[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RILlmtI3NxD8"
      },
      "outputs": [],
      "source": [
        "class CustomTokenizer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    ):\n",
        "        # initialize the tokenizer from the base model\n",
        "        self.base_tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
        "        # how many cls tokens to prepend to the fullsize data\n",
        "        self.n_cls_prepend = n_cls_prepend\n",
        "        self.n_pad_to_multiple_of = n_pad_to_multiple_of\n",
        "        for k in dir(self.base_tokenizer):\n",
        "            if not ((k[0]=='_') or (k in ['tokenize','encode','build_inputs_with_special_tokens','batch_encode_plus','encode_plus','pad'])):\n",
        "                setattr(self,k,getattr(self.base_tokenizer, k))\n",
        "        self.downscale_multiple = downscale_multiple\n",
        "        # downscale attention\n",
        "        self.maxpool_attn = nn.MaxPool1d(\n",
        "            (self.downscale_multiple), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True\n",
        "        )\n",
        "\n",
        "        # ensure excess_token_ids are included for .pad operations\n",
        "        if 'excess_cls_ids' not in self.base_tokenizer.model_input_names:\n",
        "            self.base_tokenizer.model_input_names += ['excess_cls_ids']\n",
        "\n",
        "    def __call__(self, text, pad_to_multiple_of=None, add_special_tokens = True, return_tensors=None, *args, **kwargs):\n",
        "        if pad_to_multiple_of is None:\n",
        "            pad_to_multiple_of = self.n_pad_to_multiple_of\n",
        "        tokens = self.base_tokenizer(\n",
        "            text,\n",
        "            pad_to_multiple_of=(pad_to_multiple_of if not add_special_tokens else False),\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            return_tensors=return_tensors if (not add_special_tokens) else None,\n",
        "            *args,\n",
        "            **kwargs\n",
        "        )\n",
        "        if add_special_tokens:\n",
        "            tokens = self._batch_prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "\n",
        "        # downscale the attention, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        tokens = self.downscale_attention(\n",
        "            tokens, downscale_multiple=[self.downscale_multiple, self.downscale_multiple],name='excess_cls_ids'\n",
        "        )\n",
        "        return tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_tokenizer)\n",
        "\n",
        "    def _num_pad_tokens(self, token_list):\n",
        "        \"\"\"Calculates how many PAD tokens to append to sequence to make a multiple of X\"\"\"\n",
        "        return (self.n_pad_to_multiple_of - ((len(token_list)+(self.n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "\n",
        "    def _prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [self.cls_token_id]*(n_cls_prepend-1)+tokens['input_ids'] + [self.pad_token_id]*self._num_pad_tokens(tokens['input_ids'])\n",
        "        tokens['excess_cls_ids'] = [0]*(n_cls_prepend)+tokens['attention_mask'][1:] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        tokens['attention_mask'] = [1]*(n_cls_prepend-1)+tokens['attention_mask'] +[0]*self._num_pad_tokens(tokens['attention_mask'])\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                tokens['token_type_ids'][0]\n",
        "            ]*(n_cls_prepend-1) + tokens['token_type_ids'] + [tokens['token_type_ids'][-1]]*self._num_pad_tokens(tokens['token_type_ids'])\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def _batch_prepend_extra_cls_tokens_because_of_maxpooling(self, tokens,return_tensors=None):\n",
        "        n_cls_prepend = self.n_cls_prepend\n",
        "        # prepend (n-1) CLS tokens to the front of the token_ids (because of maxpooling)\n",
        "        # also pad so that the total length is a multiple of n_cls_prepend\n",
        "        #num_pad_tokens = (self.n_pad_to_multiple_of - ((len_tokens+(n_cls_prepend-1)) % self.n_pad_to_multiple_of)) % self.n_pad_to_multiple_of\n",
        "        tokens['input_ids'] = [\n",
        "            [self.cls_token_id]*(n_cls_prepend-1)+input_id + [self.pad_token_id]*self._num_pad_tokens(input_id)\n",
        "            for input_id\n",
        "            in tokens['input_ids']\n",
        "        ]\n",
        "        tokens['excess_cls_ids'] = [\n",
        "            [0]*(n_cls_prepend)+attnmask[1:] +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        tokens['attention_mask'] = [\n",
        "            [1]*(n_cls_prepend-1)+attnmask +[0]*self._num_pad_tokens(attnmask)\n",
        "            for attnmask\n",
        "            in tokens['attention_mask']\n",
        "        ]\n",
        "        if 'token_type_ids' in tokens.keys():\n",
        "            tokens['token_type_ids'] = [\n",
        "                # we use the token_type_ids\n",
        "                [toktypeid[0]]*(n_cls_prepend-1)+toktypeid +[toktypeid[-1]]*self._num_pad_tokens(toktypeid)\n",
        "                for toktypeid\n",
        "                in tokens['token_type_ids']\n",
        "            ]\n",
        "        if return_tensors == 'pt':\n",
        "            for k,v in tokens.items():\n",
        "                tokens[k] = torch.LongTensor(v)\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, text, pad_to_multiple_of=4, add_special_tokens = True, *args, **kwargs):\n",
        "        encoded = self.base_tokenizer.encode(text, pad_to_multiple_of=False, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            encoded = [self.cls_token_id]*(pad_to_multiple_of-1) + encoded\n",
        "        if bool(pad_to_multiple_of):\n",
        "            num_pad_tokens = (pad_to_multiple_of - (len(encoded) % pad_to_multiple_of)) % pad_to_multiple_of\n",
        "            encoded += [self.pad_token_id] * num_pad_tokens\n",
        "        return encoded\n",
        "\n",
        "    def encode_plus(self, text, add_special_tokens=True, return_tensors=None, *args, **kwargs):\n",
        "        tokens = self.base_tokenizer.encode_plus(text, add_special_tokens=add_special_tokens, return_tensors=return_tensors, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            tokens = self._prepend_extra_cls_tokens_because_of_maxpooling(tokens, return_tensors)\n",
        "        return tokens\n",
        "\n",
        "    def tokenize(self, text, add_special_tokens=True, *args, **kwargs):\n",
        "        toks = self.base_tokenizer.tokenize(text, add_special_tokens=add_special_tokens, *args, **kwargs)\n",
        "        if add_special_tokens:\n",
        "            toks = [self.cls_token] * (self.n_cls_prepend-1) + toks\n",
        "        return toks\n",
        "\n",
        "    def build_inputs_with_special_tokens(\n",
        "        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n",
        "    ):\n",
        "        out = self.base_tokenizer.build_inputs_with_special_tokens(token_ids_0, token_ids_1)\n",
        "        return [self.cls_token_id]*3 + out\n",
        "\n",
        "    def batch_encode_plus(self, batch_text_or_text_pairs, *args, **kwargs):\n",
        "        batched_encoded = self.base_tokenizer.batch_encode_plus( batch_text_or_text_pairs, *args, **kwargs)\n",
        "        batched_encoded.update({'foo':'bar'})\n",
        "        return batched_encoded\n",
        "\n",
        "    def downscale_attention(self, tokens, downscale_multiple=None, name = 'attention_mask'):\n",
        "        \"\"\"\n",
        "        Reduces the sequence-dimenion by self.downscale_multiple using nn.maxpool\n",
        "        Adds the downscale attention to the tokens dictionary\n",
        "        \"\"\"\n",
        "        if downscale_multiple is None:\n",
        "            downscale_multiple = [self.downscale_multiple, self.downscale_multiple]\n",
        "\n",
        "        # fullsize attention\n",
        "        attn = tokens[name]\n",
        "        if not isinstance(attn, torch.Tensor):\n",
        "            attn = torch.Tensor(attn)\n",
        "\n",
        "        for i, mult in enumerate(downscale_multiple):\n",
        "            name_of_downsized_attn = '%s_l%d' % (name, i+2)\n",
        "            with torch.no_grad():\n",
        "                attn = self.maxpool_attn(attn.float())\n",
        "            tokens[name_of_downsized_attn] = attn\n",
        "        return tokens\n",
        "\n",
        "    def pad(\n",
        "        self,\n",
        "        encoded_inputs,\n",
        "        pad_to_multiple_of=4,\n",
        "        return_tensors=None,\n",
        "        padding: Union[bool, str, PaddingStrategy] = True,\n",
        "        max_length: Optional[int] = None,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"Pad a list of tokenized-inputs to the same batch-length, with special processing of Anathem-specific inputs\"\"\"\n",
        "\n",
        "        # which are conventional inputs and which are anathem specific\n",
        "        conventional_input_nm = [k for k in encoded_inputs[0].keys() if k in ['input_ids', 'token_type_ids','attention_mask']]\n",
        "        unconventional_input_nm = [k for k in encoded_inputs[0].keys() if k not in conventional_input_nm]\n",
        "\n",
        "        # pad the vanilla inputs\n",
        "        conventional_encoded_inputs = self.base_tokenizer.pad([\n",
        "                {k:v for k,v in encoded_input.items() if k in conventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "            ], pad_to_multiple_of=pad_to_multiple_of, return_tensors=return_tensors, padding=padding, max_length=max_length, *args, **kwargs\n",
        "        )\n",
        "\n",
        "        # deal with the remaining inputs\n",
        "        padding_strategy, _, max_length, _ = self.base_tokenizer._get_padding_truncation_strategies(\n",
        "            padding=padding, max_length=max_length, verbose=False\n",
        "        )\n",
        "\n",
        "        #required_input = encoded_inputs[][self.model_input_names[0]]\n",
        "        # this is stupid, I need to pad each input in batch individually\n",
        "        special_anathem_inputs = [\n",
        "                {k:v for k,v in encoded_input.items() if k in unconventional_input_nm}\n",
        "                for encoded_input in encoded_inputs\n",
        "        ]\n",
        "        special_anathem_encoded_inputs = self.pad_special_anathem_inputs(\n",
        "            special_anathem_inputs=special_anathem_inputs,\n",
        "            encoded_inputs=conventional_encoded_inputs,\n",
        "            max_length=max_length,\n",
        "            padding_strategy=padding_strategy,#: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "            pad_to_multiple_of=pad_to_multiple_of,\n",
        "            return_tensors=return_tensors\n",
        "        )\n",
        "        # let's see if I can just insert into the conventional_encode_inputs\n",
        "        conventional_encoded_inputs.update(special_anathem_encoded_inputs) # apparently I can just append..\n",
        "\n",
        "        # downscale the attention and add to inputs\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='attention_mask'\n",
        "        )\n",
        "        # dowscale the excess_cls_tokens, add to tokens\n",
        "        conventional_encoded_inputs = self.downscale_attention(\n",
        "            conventional_encoded_inputs,\n",
        "            downscale_multiple=[self.downscale_multiple, self.downscale_multiple],\n",
        "            name='excess_cls_ids'\n",
        "        )\n",
        "        return conventional_encoded_inputs\n",
        "\n",
        "    def pad_special_anathem_inputs(\n",
        "        self,\n",
        "        special_anathem_inputs,\n",
        "        encoded_inputs,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None,\n",
        "        return_tensors=None,\n",
        "    ):\n",
        "        required_input = encoded_inputs[self.model_input_names[0]]\n",
        "        batch_size,max_length = required_input.shape\n",
        "        #print(batch_size,max_length)\n",
        "        assert batch_size == len(special_anathem_inputs)\n",
        "        assert isinstance(special_anathem_inputs, list)\n",
        "        padding_strategy = PaddingStrategy.MAX_LENGTH\n",
        "        special_anathem_batch_outputs = {}\n",
        "        for i in range(batch_size):\n",
        "            inputs = special_anathem_inputs[i] #{k: v[i] for k, v in special_anathem_inputs.items()}\n",
        "            assert isinstance(inputs, dict)\n",
        "            outputs = self._pad_special_anathem_input(\n",
        "                inputs,\n",
        "                max_length=max_length,\n",
        "                padding_strategy=padding_strategy,\n",
        "                pad_to_multiple_of=pad_to_multiple_of\n",
        "            )\n",
        "            for key, value in outputs.items():\n",
        "                if key not in special_anathem_batch_outputs:\n",
        "                    special_anathem_batch_outputs[key] = []\n",
        "                special_anathem_batch_outputs[key].append(value)\n",
        "\n",
        "        return BatchEncoding(special_anathem_batch_outputs, tensor_type=return_tensors) # returning because of failure\n",
        "\n",
        "    def _pad_special_anathem_input(\n",
        "        self,\n",
        "        special_anathem_input,\n",
        "        max_length: Optional[int] = None,\n",
        "        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,\n",
        "        pad_to_multiple_of: Optional[int] = None\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Pad encoded Anathem-specific inputs (on left/right and up to predefined length or max length in the batch)\n",
        "        \"\"\"\n",
        "        assert isinstance(special_anathem_input, dict)\n",
        "        len_required_input = len(special_anathem_input[list(special_anathem_input.keys())[0]])\n",
        "        if max_length is not None and pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
        "            max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
        "\n",
        "        needs_to_be_padded = padding_strategy != PaddingStrategy.DO_NOT_PAD and len_required_input != max_length\n",
        "\n",
        "        # Initialize attention mask if not present\n",
        "        if needs_to_be_padded:\n",
        "            special_anathem_outputs = dict.fromkeys(special_anathem_input.keys())\n",
        "            difference = max_length - len_required_input\n",
        "            if self.padding_side == \"right\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = special_anathem_input[k] + [0] * difference\n",
        "            elif self.padding_side == \"left\":\n",
        "                for k in special_anathem_input.keys():\n",
        "                    special_anathem_outputs[k] = [0] * difference + special_anathem_input[k]\n",
        "            else:\n",
        "                raise ValueError(\"Invalid padding strategy:\" + str(self.padding_side))\n",
        "\n",
        "            return special_anathem_outputs\n",
        "        return special_anathem_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e2f772d1181b417e8f3bc2feee4f6e16",
            "825fb9aa19594a61b2a779837eb230b4",
            "b076eddbd7a74d5495615776c26a6f3e",
            "75d76bf886514ba5ac9fedee0fcfba8d",
            "e9685ee9b4aa47fcb5a3a79261ca87c7",
            "686aaeb98c1a4e688af5030963b8525e",
            "0a024ed7f3514fd6a544804a8bee0d78",
            "f230ba518eed434fb107f97c66293470",
            "1a7dd0c3112945959e9908425fcaa8b8",
            "80fd0e5e6b8f47c6a4c9557f127ef73b",
            "b963a45c28d1437f86109f283a370f38",
            "bdc7642ca3e748069974df4a510470ce",
            "1034a93ce59f439bb128b6c096eefdf2",
            "4a16335de26a43c09d578cbbe20e98d1",
            "573b3112cbee4ba581c18884df0a269e",
            "4fe04dcab6654d0594a56109e7eb6805",
            "c225230ea12f4f90bd461485f300580e",
            "4d3b7432f11a4a4b9eb444743d158c0d",
            "1d567e39c5ac4b9f8d9908111b04100f",
            "f619ea2b062a4eacb80ade328d56c2aa",
            "bc799bb2e34741fabc79181ea30ee78f",
            "a78c45e4929847f0a635988d1ef9d78f"
          ]
        },
        "id": "8TRaTA1dDv10",
        "outputId": "1b1d9054-f164-49ea-eb1e-300eb4223758"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f772d1181b417e8f3bc2feee4f6e16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc7642ca3e748069974df4a510470ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = CustomTokenizer(\n",
        "        model_string='google/bert_uncased_L-12_H-512_A-8',\n",
        "        n_cls_prepend = 4,\n",
        "        n_pad_to_multiple_of=4,\n",
        "        downscale_multiple=2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qTUF85MsPkS",
        "outputId": "ef24d6fc-34fa-4865-cbe4-800035ff05e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.base_tokenizer.model_input_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6pmDZa6D22L"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "tokens = tokenizer(text, return_tensors='pt', padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrb_tyIFXoz",
        "outputId": "388102cd-666c-41fd-c565-bdf683e416bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids 40\n",
            "input_ids [101, 101, 101, 101, 1037, 3115, 103, 11075, 2003, 1037, 23701, 6299, 11075, 2008, 2163, 2008, 2028, 2283, 2180, 1005, 1056, 2907, 1996, 2060, 20090, 2005, 12394, 1010, 6409, 1010, 2030, 5366, 3378, 2007, 3314, 1012, 102, 0, 0, 0]\n",
            "token_type_ids 40\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 40\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "excess_cls_ids 40\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "input_ids 48\n",
            "input_ids [101, 101, 101, 101, 2009, 2788, 3774, 1997, 2048, 3787, 1024, 1037, 9495, 2724, 2030, 25652, 1998, 1037, 103, 14987, 1012, 1996, 9495, 2724, 2030, 25652, 2003, 1996, 103, 1997, 1996, 3820, 1010, 23337, 1010, 2030, 27988, 1997, 1996, 27427, 6633, 3490, 14116, 2283, 2030, 2049, 18460, 102]\n",
            "token_type_ids 48\n",
            "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask 48\n",
            "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "excess_cls_ids 48\n",
            "excess_cls_ids [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "---\n",
            "CONVENTIONAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "SPECIAL\n",
            "{'input_ids': tensor([[  101,   101,   101,   101,  1037,  3115,   103, 11075,  2003,  1037,\n",
            "         23701,  6299, 11075,  2008,  2163,  2008,  2028,  2283,  2180,  1005,\n",
            "          1056,  2907,  1996,  2060, 20090,  2005, 12394,  1010,  6409,  1010,\n",
            "          2030,  5366,  3378,  2007,  3314,  1012,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   101,   101,   101,  2009,  2788,  3774,  1997,  2048,  3787,\n",
            "          1024,  1037,  9495,  2724,  2030, 25652,  1998,  1037,   103, 14987,\n",
            "          1012,  1996,  9495,  2724,  2030, 25652,  2003,  1996,   103,  1997,\n",
            "          1996,  3820,  1010, 23337,  1010,  2030, 27988,  1997,  1996, 27427,\n",
            "          6633,  3490, 14116,  2283,  2030,  2049, 18460,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'excess_cls_ids': tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask_l2': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'attention_mask_l3': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l2': tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1.]]), 'excess_cls_ids_l3': tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])}\n",
            "input_ids 2\n",
            "48\n",
            "48\n",
            "token_type_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask 2\n",
            "48\n",
            "48\n",
            "excess_cls_ids 2\n",
            "48\n",
            "48\n",
            "attention_mask_l2 2\n",
            "24\n",
            "24\n",
            "attention_mask_l3 2\n",
            "12\n",
            "12\n",
            "excess_cls_ids_l2 2\n",
            "24\n",
            "24\n",
            "excess_cls_ids_l3 2\n",
            "12\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "# FOOFU\n",
        "# in the vanilla DataCollatorForLanguageModelling, if the data is pretokenized (unpadded)\n",
        "#    then collator will simply \"pad\", the input_ids and the attention_mask (but not the generated excess_cls_ids, nor the attention_mask_l2 or l3)\n",
        "#    ... but, I created these _l2,_l3 assuming that everything was already padded properly\n",
        "# so, adding excess_token_ids to _model_names_inputs (or whatev, doesn't automatically cause the behaviour I wanted)\n",
        "# the error is because the _pad specifically only handles special_token_ids and token_type_ids in a very specific way\n",
        "#... there is no generic list_of_names to enforce padding of generic inputs.\n",
        "\n",
        "# options:\n",
        "# --- make an updated \"pad\" function for the tokenizer, that will likewise apply padding\n",
        "tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "\n",
        "for tok in tokens:\n",
        "    for k,v in tok.items():\n",
        "        print(k,len(v))\n",
        "        print(k,v)\n",
        "print('---')\n",
        "\n",
        "pad_out = tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt')\n",
        "print('CONVENTIONAL')\n",
        "print(pad_out)\n",
        "\n",
        "#for k,v in tokenizer.base_tokenizer.pad(tokens, pad_to_multiple_of=4, return_tensors='pt').items():\n",
        "print('SPECIAL')\n",
        "print(pad_out)\n",
        "for k,v in pad_out.items():\n",
        "    print(k, len(v))\n",
        "    for j in v:\n",
        "        print(len(j))\n",
        "\n",
        "\n",
        "# still need to do: reduce attention_mask\n",
        "# return as tensor\n",
        "# merge and make a BatchEncoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxawLdRdHStR",
        "outputId": "e76fe1b0-3584-48a0-db64-806542ac0c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pad_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3WljX9NzSW"
      },
      "outputs": [],
      "source": [
        "class BertSelfAttnDimensionReduction(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size_input=768,\n",
        "        hidden_size_query = None,\n",
        "        position_embedding_type=None,\n",
        "        dim_reduction = 2\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "        if (config.hidden_size // dim_reduction) % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "        self.dim_reduction = dim_reduction\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        self.hidden_size_reduced = hidden_size_input // dim_reduction\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size_reduced / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_input, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "\n",
        "        key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if encoder_attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            #print(attention_scores.shape)\n",
        "            #print(attention_scores.shape)\n",
        "            attention_scores = attention_scores + encoder_attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class InterpolateCombo(nn.Module):\n",
        "    \"\"\"there could also be an attentive way to do this\"\"\"\n",
        "    def __init__(self, scale_factor=2, dropout=0.05, alpha=0.667):\n",
        "        \"\"\"Arguments:\n",
        "        :param scaler_factor: float, multiple of up-scaling\n",
        "        :param dropout: float, dropout proportion\n",
        "        :param alpha: float, mixture weight between nearest-neighbor vs linear-interpolation\n",
        "        \"\"\"\n",
        "        super(InterpolateCombo, self).__init__()\n",
        "        self.interp = nn.functional.interpolate\n",
        "        self.scale_factor = scale_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.a = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_trans = x.transpose(-2,-1)\n",
        "        z = self.a*self.interp(x_trans, mode='nearest',scale_factor=self.scale_factor) + (1-self.a)*self.interp(x_trans, mode='linear',scale_factor=self.scale_factor)\n",
        "        z = self.dropout(z)\n",
        "        return z.transpose(-2,-1)\n",
        "\n",
        "\n",
        "class BertCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        hidden_size,\n",
        "        hidden_size_query,\n",
        "        hidden_size_keyvalue=None,\n",
        "        position_embedding_type=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_query = hidden_size_query\n",
        "        if hidden_size_keyvalue is None:\n",
        "            hidden_size_keyvalue = hidden_size\n",
        "        self.hidden_size_keyvalue = hidden_size_keyvalue\n",
        "        if self.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
        "            raise ValueError(\n",
        "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
        "                f\"heads ({config.num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(self.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(self.hidden_size_query, self.all_head_size)\n",
        "        self.key = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "        self.value = nn.Linear(self.hidden_size_keyvalue, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "        self.position_embedding_type = position_embedding_type or getattr(\n",
        "            config, \"position_embedding_type\", \"absolute\"\n",
        "        )\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            self.max_position_embeddings = config.max_position_embeddings\n",
        "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
        "\n",
        "        self.is_decoder = config.is_decoder\n",
        "\n",
        "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(query_hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
        "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class BertReduceAddIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Bert Layer that does dimenion reduction along embedding-dimenion and integrations a skip connection\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size,\n",
        "            hidden_size_input=None,\n",
        "            hidden_size_query=None,\n",
        "            intermediate_size=None,\n",
        "            dim_reduction=2,\n",
        "            do_concat_hidden_and_query = True\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.do_concat_hidden_and_query = do_concat_hidden_and_query\n",
        "        assert bool(do_concat_hidden_and_query), 'not implemented: concatenation of query and hidden-states must happen'\n",
        "        self.hidden_size = hidden_size\n",
        "        if dim_reduction is None:\n",
        "            dim_reduction = 2\n",
        "        self.dim_reduction = dim_reduction\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "        if hidden_size_input is None:\n",
        "            hidden_size_input = hidden_size\n",
        "        self.hidden_size_input = hidden_size_input\n",
        "        if hidden_size_query is None:\n",
        "            hidden_size_query = hidden_size_input\n",
        "        self.hidden_size_query = hidden_size_query + do_concat_hidden_and_query*hidden_size\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_input)\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertSelfAttnDimensionReduction(\n",
        "            config,\n",
        "            hidden_size_input=self.hidden_size_input,\n",
        "            hidden_size_query = self.hidden_size_query,\n",
        "            position_embedding_type=\"absolute\",\n",
        "            dim_reduction = self.dim_reduction\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor, # higher-resolution inputs for key and values (long sequence dimension)\n",
        "        hidden_states: torch.Tensor, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        query_hidden_states: torch.FloatTensor = None, # hidden-states for query (short squence-dim, low-res)\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        if self.do_concat_hidden_and_query:\n",
        "            query_hidden_states_plus = torch.cat((query_hidden_states, hidden_states),axis=2)\n",
        "        # cross attn between (low-res) query vector and (high-res) key-values\n",
        "        cross_attn_outputs = self.attention(\n",
        "            query_hidden_states_plus, # query (short seq-dim, high-res)\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = inputs, # for key/value (longer sequence dimension, high-res)\n",
        "            past_key_value=past_key_value,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.dropout_attn(self.output_attn(cross_hidden_states))\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.intermediate_act_fn(self.intermediate(\n",
        "            self.cat((hidden_states, query_hidden_states),axis=2)\n",
        "        ))\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        intermediate_states = self.dropout_intm(self.output_intm(intermediate_states))\n",
        "        out_states = self.lnorm_intm(intermediate_states + hidden_states)\n",
        "\n",
        "        #inputs = x_l1, x_l1_reduced, x_l2_prev\n",
        "        #- x2 = BertCrossAttention(k,v=x_l1, q= cat(x_l1_reduced, x_l2_prev) ) -notice three inputs\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2_prev)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l1_reduced))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n",
        "try:\n",
        "    from transformers.modeling_utils import get_extended_attention_mask\n",
        "except:\n",
        "    def get_extended_attention_mask(self, attention_mask: torch.Tensor, input_shape: Tuple[int], device: device) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (:obj:`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (:obj:`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "            device: (:obj:`torch.device`):\n",
        "                The device of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            :obj:`torch.Tensor` The extended attention mask, with a the same dtype as :obj:`attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        if attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                batch_size, seq_length = input_shape\n",
        "                seq_ids = torch.arange(seq_length, device=device)\n",
        "                causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
        "                # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
        "                # causal and attention masks must have same type with pytorch version < 1.3\n",
        "                causal_mask = causal_mask.to(attention_mask.dtype)\n",
        "\n",
        "                if causal_mask.shape[1] < attention_mask.shape[1]:\n",
        "                    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
        "                    causal_mask = torch.cat(\n",
        "                        [\n",
        "                            torch.ones(\n",
        "                                (batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype\n",
        "                            ),\n",
        "                            causal_mask,\n",
        "                        ],\n",
        "                        axis=-1,\n",
        "                    )\n",
        "\n",
        "                extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
        "                    input_shape, attention_mask.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        return extended_attention_mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbXNphafOX2i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BertIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Vanilla Bert Layer, but integrates other hiddens states from a parallel transformers stack typically low-re\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        self.hidden_size_concat = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(4*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # cross attention between (low-res) query and hidden layers below\n",
        "        self.attention = BertCrossAttention(\n",
        "            config,\n",
        "            hidden_size= self.hidden_size, # high dim output\n",
        "            hidden_size_query = self.hidden_size_query, # high dim query\n",
        "            hidden_size_keyvalue = self.hidden_size_keyvalues, # low-dim keyvalues\n",
        "            position_embedding_type=\"absolute\"\n",
        "        )\n",
        "        self.is_decoder = config.is_decoder\n",
        "        #self.intermediate = BertIntermediate(config)\n",
        "        #self.output = BertOutput(config)\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\n",
        "        # corresponds to BertAttention SelfOutput\n",
        "        self.output_attn = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lnorm_attn = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_attn = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # corresponds to BertIntermediate\n",
        "        self.intermediate = nn.Linear(self.hidden_size_concat, self.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.output_intm = nn.Linear(self.intermediate_size, self.hidden_size)\n",
        "        self.lnorm_intm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout_intm = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        keyvalue_hidden_states: torch.Tensor=None, # low-res hidden-states (1/2 seq-dim) used for key-value pairs\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to query\n",
        "        query_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        # cross attn between hiddens states and (low-res) query vector\n",
        "        cross_attn_outputs = self.attention(\n",
        "            hidden_states = keyvalue_hidden_states,\n",
        "            attention_mask = attention_mask,\n",
        "            head_mask = head_mask,\n",
        "            query_hidden_states = torch.cat((hidden_states, query_to_concat_hidden_states),axis=2),\n",
        "            query_attention_mask = query_attention_mask\n",
        "        )\n",
        "        cross_hidden_states = cross_attn_outputs[0]\n",
        "        assert cross_hidden_states.shape[1]==hidden_states.shape[1], f\"{cross_hidden_states.shape[1]},{cross_hidden_states.shape[2]} vs {hidden_states.shape[1]},{hidden_states[2]}\"\n",
        "        assert cross_hidden_states.shape[2]==hidden_states.shape[2]\n",
        "\n",
        "\n",
        "        # first Add+Norm skip connection (BertSelfOutput)\n",
        "        cross_hidden_states = self.output_attn(cross_hidden_states)\n",
        "        cross_hidden_states = self.dropout_attn(cross_hidden_states)\n",
        "        hidden_states = self.lnorm_attn(cross_hidden_states + hidden_states)\n",
        "\n",
        "        # intermediate expension\n",
        "        intermediate_states = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        intermediate_states = self.intermediate(intermediate_states)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        assert intermediate_states.shape[0]==hidden_states.shape[0]\n",
        "        assert intermediate_states.shape[1]==hidden_states.shape[1]\n",
        "\n",
        "        # BertOutput\n",
        "        out_states = self.output_intm(intermediate_states)\n",
        "        out_states = self.dropout_intm(out_states)\n",
        "        out_states = self.lnorm_intm(out_states + hidden_states)\n",
        "\n",
        "        #- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "        #- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "        #- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "        #- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOl85thAOiu3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# how does bert actually work?\n",
        "\"\"\"\n",
        "input = x\n",
        "\n",
        "BertLayer:\n",
        "- BertAttention\n",
        "--- x2 = BertSelfAttention(x)\n",
        "--- x3 = BertSelfOutput(x2,x) -> lnorm(drop(f(x2)) + x)\n",
        "- BertIntermediate (expension:  4*hidden_size)\n",
        "--- x4_ex = activation(f(x3)) # expansion (4*)\n",
        "- BertOutput\n",
        "--- x5 = lnorm(drop(f(x4_ex)) + x3 )\n",
        "\n",
        "\n",
        "inputs = x_l2, x_l3_up\n",
        "\n",
        "BertIntegrativeLayer:\n",
        "- x2 = BertCrossAttention(k,v=x_l2, q=x_l3_up)\n",
        "- x3 = lnorm(drop(f(x2)) + x_l2)\n",
        "- x4_ex = activation( f(cat(x3, x_l3_up))  )\n",
        "- x5 = lnorm(drop(f(x4_ex)) + x3)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class CheapMLPIntegrativeLayer(nn.Module):\n",
        "    \"\"\"Cheap (non-transformer) Integrator layer that merges a (low-res) layers with higher-res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            hidden_size, # dimensions of the (high-res) hiddens states; same dimension as output\n",
        "            hidden_size_keyvalues=None, # dimensions of (low-res) states used as key/values; 1/2 sequence-length and dim\n",
        "            hidden_size_query_to_concat=None, # dimensions of (low-res) to concat to hidden_states; 1/2 sequence-length and dim\n",
        "            intermediate_size=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        #self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        #self.seq_len_dim = 1\n",
        "        self.cat = torch.cat\n",
        "        self.hidden_size = hidden_size\n",
        "        if hidden_size_keyvalues is None:\n",
        "            hidden_size_keyvalues = hidden_size\n",
        "        self.hidden_size_keyvalues = hidden_size_keyvalues\n",
        "        if hidden_size_query_to_concat is None:\n",
        "            hidden_size_query_to_concat = hidden_size_keyvalues\n",
        "        self.hidden_size_query_to_concat = hidden_size_query_to_concat\n",
        "        self.hidden_size_query = int(hidden_size + hidden_size_query_to_concat)\n",
        "        if intermediate_size is None:\n",
        "            intermediate_size = int(2*hidden_size)\n",
        "        self.intermediate_size = intermediate_size\n",
        "\n",
        "        # expand hidden-size to a multiple\n",
        "        self.dense_expander = nn.Linear(\n",
        "            self.hidden_size_query,\n",
        "            self.intermediate_size\n",
        "        ) # deflate back to same size as hidden-state\n",
        "        self.dense_deflator = nn.Linear(\n",
        "            self.intermediate_size,\n",
        "            self.hidden_size\n",
        "        )\n",
        "\n",
        "        # intermediate activation function\n",
        "        self.intermediate_act_fn = nn.RReLU(0.0625, 0.125)\n",
        "\n",
        "        # corresponds to BertOutput\n",
        "        self.lnorm = nn.LayerNorm(self.hidden_size, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor, # high-res hidden states (same dimensions as output), used as query\n",
        "        attention_mask = None, # ignored\n",
        "        head_mask = None, # ignored\n",
        "        keyvalue_hidden_states =None, # ignored\n",
        "        query_to_concat_hidden_states: torch.Tensor=None, # to concatenate to hidden_states\n",
        "        query_attention_mask = None, # ignored\n",
        "        past_key_value = None, # ignored\n",
        "        output_attentions = False, # ignored\n",
        "    ) -> torch.Tensor:\n",
        "\n",
        "        # concat (lowres) to hidden-states\n",
        "        inputs = self.cat((hidden_states, query_to_concat_hidden_states),axis=2)\n",
        "        # expand x2 dimension\n",
        "        intermediate_states = self.dense_expander(inputs)\n",
        "        # activation (leaky relue)\n",
        "        intermediate_states = self.intermediate_act_fn(intermediate_states)\n",
        "        # like BertOutput\n",
        "        out_states = self.dense_deflator(intermediate_states)\n",
        "        # dropout\n",
        "        out_states = self.dropout(out_states)\n",
        "        # combine with hidden-state inputs\n",
        "        out_states = self.lnorm(out_states + hidden_states)\n",
        "\n",
        "        return out_states\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo-LWT_jOFNa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_config(\n",
        "    modelstring = \"distilroberta-base\",\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    sequence_classification_intermediate_dim = None, # default is the same as the basemodel hidden-dim\n",
        "    sequence_classification_out_dim = None, # default is x2 same as the basemodel hidden-dim\n",
        "    do_mlm =False,\n",
        "    do_cls = False\n",
        "):\n",
        "    #if True:\n",
        "    #modelstring = \"distilroberta-base\"\n",
        "    #scale_ratio2 = 0.5\n",
        "    #scale_ratio3 = 0.25\n",
        "    #scale_intermediate2 = 4\n",
        "    #scale_intermediate3 = 4\n",
        "    base_config = AutoConfig.from_pretrained(modelstring)\n",
        "    config_l2 = copy.deepcopy(base_config)\n",
        "    config_l3 = copy.deepcopy(base_config)\n",
        "    setattr(base_config, 'model_string', modelstring)\n",
        "    setattr(base_config,'num_transformer_stacks', num_transformer_stacks)\n",
        "    setattr(base_config,'num_layers_l2', num_layers_l2)\n",
        "    setattr(base_config,'num_layers_l3', num_layers_l3)\n",
        "    setattr(base_config,'scale_ratio2', scale_ratio2)\n",
        "    setattr(base_config,'scale_ratio3', scale_ratio3)\n",
        "    setattr(base_config,'scale_factor2', int(1/base_config.scale_ratio2))\n",
        "    setattr(base_config,'scale_factor3', int(1/base_config.scale_ratio3*base_config.scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l2\", int(base_config.hidden_size * scale_ratio2))\n",
        "    setattr(base_config,\"hidden_size_l3\", int(base_config.hidden_size * scale_ratio3))\n",
        "    setattr(base_config,\"intermediate_size_l1\", int(base_config.hidden_size_l2*multiplier_intermediate2))\n",
        "    setattr(base_config,\"intermediate_size_l2\", int(base_config.hidden_size_l3*multiplier_intermediate3))\n",
        "    setattr(base_config,\"query_size1\", base_config.hidden_size_l2 + base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"query_size2\", base_config.hidden_size_l3)\n",
        "    setattr(base_config,\"dropout_scaling\", dropout_scaling)\n",
        "    setattr(base_config,\"use_cheap_integrator_for_stacks\", do_cheap_integrator)\n",
        "    setattr(base_config, \"do_mlm\", do_mlm)\n",
        "    setattr(base_config, \"do_cls\", do_cls)\n",
        "\n",
        "    # hidden dimension\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_intermediate_dim\",\n",
        "        sequence_classification_intermediate_dim  if sequence_classification_intermediate_dim is not None else [\n",
        "            int(base_config.hidden_size*s)\n",
        "            for s in [1, scale_ratio2, scale_ratio3]\n",
        "        ]\n",
        "    )\n",
        "    # final dimension outputed for sequence classification\n",
        "    setattr(\n",
        "        base_config,\n",
        "        \"sequence_classification_out_dim\",\n",
        "        sequence_classification_out_dim  if sequence_classification_out_dim is not None else base_config.hidden_size*2\n",
        "    )\n",
        "\n",
        "\n",
        "    # make the configuration for the l2 mid-res encoder\n",
        "    config_l2.hidden_size = base_config.hidden_size_l2\n",
        "    config_l2.num_hidden_layers = num_layers_l2\n",
        "    setattr(base_config, 'config_l2', config_l2)\n",
        "\n",
        "    # make the configuration for the l3 encoder\n",
        "    config_l3.hidden_size = base_config.hidden_size_l3\n",
        "    config_l3.num_hidden_layers = num_layers_l3\n",
        "    setattr(base_config, 'config_l3', config_l3)\n",
        "    return base_config\n",
        "\n",
        "def initialize_baselayers(config, basemod = None, tokenizer=None, stack_id=0):\n",
        "    \"\"\"Initializes the embeddings and first stack of layers for the Anathem transformers\"\"\"\n",
        "    # initialize the basemodel\n",
        "    if basemod is None:\n",
        "        basemod = AutoModel.from_pretrained(config.model_string)\n",
        "    if tokenizer is None:\n",
        "        # download pretrained tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n",
        "\n",
        "    device = basemod.device\n",
        "    setattr(config, 'device', device)\n",
        "\n",
        "    # get basemodel's embeddings\n",
        "    layer_embedding = copy.deepcopy(basemod._modules['embeddings'])\n",
        "\n",
        "    # get basemodel's first transformer block\n",
        "    layer_basetransformer = copy.deepcopy(basemod._modules['encoder']._modules['layer']._modules['0'])\n",
        "\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize downsampling attention layers\n",
        "    bert_reducer_l2 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor2\n",
        "    )\n",
        "    # 1/4 hidden size\n",
        "    bert_reducer_l3 = BertSelfAttnDimensionReduction(\n",
        "        config=config,\n",
        "        hidden_size_input=config.hidden_size_l2,\n",
        "        position_embedding_type=config.position_embedding_type,\n",
        "        dim_reduction = config.scale_factor3\n",
        "    )\n",
        "\n",
        "    # initialize the mid-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: low res to mid res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    # from mid-res to high-res\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    # from mid-res to high-res\n",
        "    if not do_cheap_integrator:\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        tokenizer,\n",
        "        basemod,\n",
        "        layer_embedding,\n",
        "        layer_basetransformer,\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reducer_l2,\n",
        "        bert_reducer_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "def initialize_midlayers(config, basemod=None, tokenizer=None, stack_id=1):\n",
        "    \"\"\"Initializes all the intermediate layers for the Anathem transformers\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    maxpool = nn.Sequential(\n",
        "        nn.Dropout(config.dropout_scaling),\n",
        "        nn.MaxPool2d((2,1), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "    )\n",
        "    # pooling the attention has no dropout\n",
        "    maxpool_attn = nn.MaxPool1d((2), stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=True)\n",
        "\n",
        "    # initialize bert attentive downsampling and skipconnection (1/2 embedding dim)\n",
        "    bert_reduceintegrator_l2 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l2, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l1, # BertIntermediate dimension (expansion *4 the hiddensize)\n",
        "        dim_reduction=config.scale_factor2, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # 1/4 the size\n",
        "    bert_reduceintegrator_l3 = BertReduceAddIntegrativeLayer(\n",
        "        config,\n",
        "        config.hidden_size_l3, # size of mid-res\n",
        "        hidden_size_input=config.hidden_size_l2, # size full-resolution\n",
        "        hidden_size_query=config.hidden_size_l2, # size full-resolution\n",
        "        intermediate_size=config.intermediate_size_l2, # BertIntermediate dimension\n",
        "        dim_reduction=config.scale_factor3, # reduce embedding dimension by factor of 2\n",
        "        do_concat_hidden_and_query = True\n",
        "    )\n",
        "\n",
        "    # initialize the low-resolution BertEncoder\n",
        "    bert_encoder_midres = BertEncoder(config.config_l2)\n",
        "    bert_encoder_lowres = BertEncoder(config.config_l3)\n",
        "\n",
        "    # initailize the upscalers\n",
        "    upscaler_x2 = InterpolateCombo(scale_factor=config.scale_factor3, dropout=config.dropout_scaling)\n",
        "    upscaler_x4 = InterpolateCombo(scale_factor=int(1/config.scale_ratio3), dropout=config.dropout_scaling)\n",
        "\n",
        "    # initialize the BertIntegrative Layers: from low-res to mide-res\n",
        "    bert_integrater_l2 = BertIntegrativeLayer(\n",
        "        config,\n",
        "        hidden_size=config.hidden_size_l2,\n",
        "        hidden_size_keyvalues = config.hidden_size_l3,\n",
        "        hidden_size_query_to_concat=config.hidden_size_l3,\n",
        "        intermediate_size=config.intermediate_size_l2\n",
        "    )\n",
        "\n",
        "    do_cheap_integrator = (stack_id in config.use_cheap_integrator_for_stacks)\n",
        "    if not do_cheap_integrator:\n",
        "        # from mid-res to high-res\n",
        "        bert_integrater_l1 = BertIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_keyvalues = config.hidden_size_l2,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.intermediate_size_l1\n",
        "        )\n",
        "    else:\n",
        "        bert_integrater_l1 = CheapMLPIntegrativeLayer(\n",
        "            config,\n",
        "            hidden_size=config.hidden_size,\n",
        "            hidden_size_query_to_concat=config.hidden_size_l2,\n",
        "            intermediate_size=config.hidden_size*2\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        maxpool,\n",
        "        maxpool_attn,\n",
        "        bert_reduceintegrator_l2,\n",
        "        bert_reduceintegrator_l3,\n",
        "        bert_encoder_midres,\n",
        "        bert_encoder_lowres,\n",
        "        upscaler_x2,\n",
        "        upscaler_x4,\n",
        "        bert_integrater_l2,\n",
        "        bert_integrater_l1\n",
        "    )\n",
        "\n",
        "\n",
        "def initialize_finaltransformerlayers(config, basemod=None, tokenizer=None, names_encoder_module = 'encoder', stack_id=3):\n",
        "    \"\"\"Initializes the final BertLayer before output, but copying the final BertLayer from `Basemod`\"\"\"\n",
        "    # initialize the maxpooling downsamplers\n",
        "    assert basemod is not None, \"`initialize_finaltransformerlayers` requires the basemod to instantiate the final transformer block\"\n",
        "\n",
        "    # get the Encoder stacks\n",
        "    assert names_encoder_module in basemod._modules.keys(), 'expected %s in basemod._modules' % names_encoder_module\n",
        "    basemod_encoder_stack = get_to_bertlayer(basemod, target_layer_name = names_encoder_module)\n",
        "\n",
        "    # get the name of the final transformer block (-1) in encoder\n",
        "    names_of_final_transformer_block = list(basemod_encoder_stack._modules['layer']._modules.keys())[-1]\n",
        "\n",
        "    # get the final transformer block (NN weights pretrained)\n",
        "    bert_finaltransformer_block = basemod_encoder_stack._modules['layer']._modules[\n",
        "        names_of_final_transformer_block\n",
        "    ]\n",
        "\n",
        "    return copy.deepcopy(bert_finaltransformer_block)\n",
        "\n",
        "def get_to_bertlayer(basemod, target_layer_name = 'encoder', model_string = None):\n",
        "    \"\"\"Clumsily locates a particular layer within a pretrained bert model\"\"\"\n",
        "    if  target_layer_name in basemod._modules.keys():\n",
        "        return basemod._modules[target_layer_name]\n",
        "    elif target_layer_name in basemod._modules['bert']._modules.keys():\n",
        "        return basemod._modules['bert']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L79IXfrOKEs"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AnathemBaseModule(nn.Module):\n",
        "    \"\"\"First Sstack of layers with embeddings, that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device = None,\n",
        "            stack_id=0\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            tokenizer, basemod,\n",
        "            layer_embedding,\n",
        "            layer_basetransformer,\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducer_l2,\n",
        "            bert_reducer_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_baselayers(config, basemod, tokenizer, stack_id=0)\n",
        "\n",
        "        self.get_extended_attention_mask = basemod.get_extended_attention_mask\n",
        "        self.embedding = layer_embedding\n",
        "        self.layer_basetransformer = layer_basetransformer\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducer_l2 = bert_reducer_l2\n",
        "        self.bert_reducer_l3 = bert_reducer_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        self.stack_id = 0\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = input_ids\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        extended_attention_mask_l1 = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        # downsample the attention mask to l2 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l2 = self.maxpool_attn(attention_mask.float())\n",
        "        extended_attention_mask_l2 = self.get_extended_attention_mask(attention_mask_l2,attention_mask_l2.shape, self.device)\n",
        "        # downsample the attention mask to l3 dimension\n",
        "        if attention_mask_l2 is None:\n",
        "            attention_mask_l3 = self.maxpool_attn(attention_mask_l2.float())\n",
        "        extended_attention_mask_l3 = self.get_extended_attention_mask(attention_mask_l3,attention_mask_l3.shape, self.device)\n",
        "\n",
        "        # embed\n",
        "        embedding_output = self.embedding(\n",
        "            input_ids = input_ids,\n",
        "            position_ids = position_ids,\n",
        "            token_type_ids = token_type_ids,\n",
        "            #input_embeds=None,\n",
        "            past_key_values_length = past_key_values_length\n",
        "        )\n",
        "\n",
        "        # first transformer block (vanilla transformer)\n",
        "        out_l1 = self.layer_basetransformer(\n",
        "            hidden_states = embedding_output,\n",
        "            attention_mask = extended_attention_mask_l1,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        hidden_states_l1 = out_l1[0]\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_l1)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l2 = self.bert_reducer_l2(\n",
        "            hidden_states = hiddens_states_l1_reduced,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l1,\n",
        "            encoder_attention_mask= extended_attention_mask_l1,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l2 = out_l2[0]\n",
        "\n",
        "        # Vanilla transformers block at mid-resolution (1/2 seq-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (1/4 seq-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        out_l3 = self.bert_reducer_l3(\n",
        "            hidden_states = hiddens_states_l2_reduced,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states = hidden_states_l2,\n",
        "            encoder_attention_mask= extended_attention_mask_l2,\n",
        "            past_key_value=past_key_values,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states_l3 = out_l3[0]\n",
        "\n",
        "        #print(hidden_states_l3.shape)\n",
        "        #print(extended_attention_mask_l3.shape)\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l3 = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_l3)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_l2 = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_l3,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l3,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2,\n",
        "            query_attention_mask = attention_mask_l2\n",
        "        )\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_l3)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_l2)\n",
        "        #hidden_states_upscaled = torch.cat((\n",
        "        #    hidden_states_upscaled2to1, hidden_states_upscaled3to1\n",
        "        #),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_l1 = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_l1,\n",
        "            attention_mask = extended_attention_mask_l2,\n",
        "            head_mask = head_mask,\n",
        "            keyvalue_hidden_states = hidden_states_l2,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1,\n",
        "            query_attention_mask = extended_attention_mask_l2\n",
        "        )\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "                (extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "                (attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_l1, hidden_states_l2, hidden_states_l3),\n",
        "            \"extended_attention_masks\":(extended_attention_mask_l1, extended_attention_mask_l2, extended_attention_mask_l3),\n",
        "            \"attention_masks\":(attention_mask, attention_mask_l2, attention_mask_l3)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemMidModule(nn.Module):\n",
        "    \"\"\"Stack of layers that go full circle form high-res to low-res back to high res\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "            stack_id = 1\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # initalize the layers\n",
        "        (\n",
        "            maxpool,\n",
        "            maxpool_attn,\n",
        "            bert_reducerintegrator_l2,\n",
        "            bert_reducerintegrator_l3,\n",
        "            bert_encoder_midres,\n",
        "            bert_encoder_lowres,\n",
        "            upscaler_x2,\n",
        "            upscaler_x4,\n",
        "            bert_integrater_l2,\n",
        "            bert_integrater_l1\n",
        "        ) = initialize_midlayers(config, basemod, tokenizer, stack_id)\n",
        "\n",
        "        self.get_extended_attention_mask = get_extended_attention_mask\n",
        "        self.maxpool = maxpool\n",
        "        self.maxpool_attn = maxpool_attn\n",
        "        self.bert_reducerintegrator_l2 = bert_reducerintegrator_l2\n",
        "        self.bert_reducerintegrator_l3 = bert_reducerintegrator_l3\n",
        "        self.bert_encoder_midres = bert_encoder_midres\n",
        "        self.bert_encoder_lowres = bert_encoder_lowres\n",
        "        self.upscaler_x2 = upscaler_x2\n",
        "        self.upscaler_x4 = upscaler_x4\n",
        "        self.bert_integrater_l2 = bert_integrater_l2\n",
        "        self.bert_integrater_l1 = bert_integrater_l1\n",
        "        if device is None:\n",
        "            self.to(basemod.device)\n",
        "            #print(self.device)\n",
        "            self.device = basemod.device\n",
        "        else:\n",
        "            self.to(device)\n",
        "            self.device = device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states_highres: torch.Tensor,\n",
        "        hidden_states_midres: torch.Tensor,\n",
        "        hidden_states_lowres: torch.Tensor,\n",
        "        attention_mask: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_highres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_midres: Optional[List[torch.FloatTensor]] = None,\n",
        "        extended_attention_mask_lowres: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "        input_shape = hidden_states_highres.shape[:2]\n",
        "        past_key_values_length =0 if past_key_values is None else len(past_key_values)\n",
        "\n",
        "        # extend attention mask\n",
        "        if extended_attention_mask_highres is None:\n",
        "            extended_attention_mask_highres = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\n",
        "        if extended_attention_mask_midres is None:\n",
        "            attention_mask_midres = self.maxpool_attn(attention_mask.float())\n",
        "            extended_attention_mask_midres = self.get_extended_attention_mask(attention_mask_midres,attention_mask_midres.shape, self.device)\n",
        "        if extended_attention_mask_lowres is None:\n",
        "           attention_mask_lowres = self.maxpool_attn(attention_mask_midres.float())\n",
        "           extended_attention_mask_lowres = self.get_extended_attention_mask(attention_mask_lowres,attention_mask_lowres.shape, self.device)\n",
        "\n",
        "        # downsample to sequence 1 to length sequence 2\n",
        "        hiddens_states_l1_reduced = self.maxpool(hidden_states_highres)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l2 = self.bert_reducerintegrator_l2(\n",
        "            inputs = hidden_states_highres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_midres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l1_reduced\n",
        "        )\n",
        "\n",
        "        # Vanilla transformers at mid-resolution (1/2 sequence-length)\n",
        "        out_encoder = self.bert_encoder_midres(\n",
        "            hidden_states=hidden_states_l2,\n",
        "            attention_mask=extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_l2 = out_encoder[0]\n",
        "\n",
        "        # reduce sequence length (to 1/4 sequence-length)\n",
        "        hiddens_states_l2_reduced = self.maxpool(hidden_states_l2)\n",
        "\n",
        "        # reduce dimenion on sequence 2\n",
        "        hidden_states_l3 = self.bert_reducerintegrator_l3(\n",
        "            inputs = hidden_states_midres, # from highres outputs previous layer (key, values)\n",
        "            hidden_states = hidden_states_lowres, # previous hidden-states for skip connection (short squence-dim, low-res)\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask=None,\n",
        "            query_hidden_states = hiddens_states_l2_reduced\n",
        "        )\n",
        "\n",
        "        # BertEncoder at low-res\n",
        "        out_encoder = self.bert_encoder_lowres(\n",
        "            hidden_states=hidden_states_l3,\n",
        "            attention_mask=extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "        hidden_states_lowres = out_encoder[0]\n",
        "\n",
        "        # upscaling: l3 to l2\n",
        "        hidden_states_upscaled3to2 = self.upscaler_x2(hidden_states_lowres)\n",
        "\n",
        "        # integrate sequence-2 and upscaled sequence-3\n",
        "        hidden_states_midres = self.bert_integrater_l2(\n",
        "            hidden_states = hidden_states_l2,\n",
        "            attention_mask = extended_attention_mask_lowres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_lowres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled3to2\n",
        "        )\n",
        "        #hidden_states_midres = self.bert_integrative_layer_2(\n",
        "        #    hidden_states = hidden_states_l2,\n",
        "        #    attention_mask = extended_attention_mask_midres,\n",
        "        #    head_mask = None,\n",
        "        #    query_hidden_states = hidden_states_upscaled3to2)\n",
        "\n",
        "        # upscaling: l3/l2 to l1 sequence length\n",
        "        #hidden_states_upscaled3to1 = self.upscaler_x4(hidden_states_lowres)\n",
        "        hidden_states_upscaled2to1 = self.upscaler_x2(hidden_states_midres)\n",
        "        #hidden_states_upscaled = torch.cat((hidden_states_upscaled2to1, hidden_states_upscaled3to1),axis=2)\n",
        "\n",
        "        # integrate low-resolution information back to original dimension\n",
        "        hidden_states_highres = self.bert_integrater_l1(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_mask_midres,\n",
        "            head_mask = None,\n",
        "            keyvalue_hidden_states = hidden_states_midres,\n",
        "            query_to_concat_hidden_states = hidden_states_upscaled2to1\n",
        "        )\n",
        "\n",
        "        if not return_dict:\n",
        "            return (\n",
        "                (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "                (extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "            )\n",
        "        return {\n",
        "            \"hidden_states\": (hidden_states_highres, hidden_states_midres, hidden_states_lowres),\n",
        "            \"attention\":(extended_attention_mask_highres, extended_attention_mask_midres, extended_attention_mask_lowres)\n",
        "        }\n",
        "\n",
        "\n",
        "class AnathemEncoder(nn.Module):\n",
        "    \"\"\"Anathem cores stacks of layers, from embeddings to final transformer block\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            config,\n",
        "            basemod=None,\n",
        "            tokenizer=None,\n",
        "            past_key_values_length = None,\n",
        "            device=None,\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # initialize embedings and first stack\n",
        "        self.anathem_base_stack = AnathemBaseModule(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            past_key_values_length,\n",
        "            device,\n",
        "        )\n",
        "\n",
        "        # initialize all subsequence stacks\n",
        "        self.anathem_mid_stack = nn.ModuleList([\n",
        "            AnathemMidModule(\n",
        "                config,\n",
        "                basemod,\n",
        "                tokenizer,\n",
        "                past_key_values_length,\n",
        "                device,\n",
        "                stack_id = i\n",
        "            ) for i in range(1, self.config.num_transformer_stacks)\n",
        "        ])\n",
        "\n",
        "        # initialize the final transformer modules\n",
        "        self.final_transformer_block = initialize_finaltransformerlayers(\n",
        "            config,\n",
        "            basemod,\n",
        "            tokenizer,\n",
        "            stack_id=self.config.num_transformer_stacks+1\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = False,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        output_hidden_states: Optional[bool] = False,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # embed and run through first stack of transformers\n",
        "        hidden_states, extended_attention_masks, attention_masks = self.anathem_base_stack(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2,\n",
        "            attention_mask_l3=attention_mask_l3,\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=return_dict\n",
        "        )\n",
        "\n",
        "        # middle stack of transformers\n",
        "        for i, anathem_stack in enumerate(self.anathem_mid_stack):\n",
        "\n",
        "            # run through each stack (1-2)\n",
        "            hidden_states, extended_attention_masks = anathem_stack(\n",
        "                hidden_states_highres = hidden_states[0],\n",
        "                hidden_states_midres = hidden_states[1],\n",
        "                hidden_states_lowres = hidden_states[2],\n",
        "                extended_attention_mask_highres = extended_attention_masks[0],\n",
        "                extended_attention_mask_midres = extended_attention_masks[1],\n",
        "                extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "            )\n",
        "\n",
        "        # hidden states (high,med,low resolution)\n",
        "        hidden_states_highres, hidden_states_midres, hidden_states_lowres = hidden_states\n",
        "\n",
        "        # run through final transformer block (pretrained)\n",
        "        out_final = self.final_transformer_block(\n",
        "            hidden_states = hidden_states_highres,\n",
        "            attention_mask = extended_attention_masks[0],\n",
        "            head_mask=None,\n",
        "            encoder_hidden_states=None,\n",
        "            encoder_attention_mask=None,\n",
        "            output_attentions=output_attentions\n",
        "        )\n",
        "        #print(type(out_final))\n",
        "        #print(len(out_final))\n",
        "        hidden_states_highres = out_final[0]\n",
        "        if not output_attentions:\n",
        "            return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks\n",
        "\n",
        "        attention_final = out_final[1]\n",
        "        return (hidden_states_highres, hidden_states_midres, hidden_states_lowres), attention_masks, attention_final\n",
        "\n",
        "\n",
        "class BertGenericClassificationHead(nn.Module):\n",
        "    \"\"\"Instantiates a basic classification head that takes the CLS token and mean of the final layer for classification\"\"\"\n",
        "    def __init__(self, config, n_classes = 1, activation = 'sigmoid', device=None):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "        elif activation == 'none':\n",
        "            self.activation = lambda x: x\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask) -> torch.Tensor:\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        output_vectors=[]\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        output_vectors.append(first_token_tensor)\n",
        "        # mean pooling\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        output_vectors.append(sum_embeddings / sum_mask)\n",
        "        # concatenate\n",
        "        pooled_output = torch.concat(output_vectors, axis=1)\n",
        "        #print(pooled_output.shape)\n",
        "        logits = self.dense(pooled_output)\n",
        "        return self.activation(logits)\n",
        "\n",
        "\n",
        "class AnathemMultiSiloPooler(nn.Module):\n",
        "    \"\"\"\n",
        "    Pools the token-embeddings along the sequence dimenions for a final sentence-vector.\n",
        "    The pooling occuras across all three 'silos'\n",
        "    The pooling consists of the CLS token as well as mean pooling, concatenated token\n",
        "    Use the pooling outputs prior to any sequenceClassification\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        dim_out = None,\n",
        "        mean_activation = nn.Tanhshrink,\n",
        "        out_activation = None,\n",
        "        dims_in = None,\n",
        "        p_dropout=None,\n",
        "        device=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # dimensions of the hiddens states being processed as inputs\n",
        "        if dims_in is None:\n",
        "            try:\n",
        "                dims_in = config.sequence_classification_intermediate_dim\n",
        "            except:\n",
        "                dims_in = [dim_out, dim_out//2, dim_out//4]\n",
        "        self.dims_in = dims_in\n",
        "        self.dim_in = sum(dims_in)\n",
        "        self.hidden_size = config.hidden_size\n",
        "        if dim_out is None:\n",
        "            try:\n",
        "                dim_out = config.sequence_classification_out_dim\n",
        "            except:\n",
        "                dim_out = config.hidden_size*2\n",
        "        self.dim_out = dim_out\n",
        "        self.mean_activation = mean_activation\n",
        "\n",
        "        #self.dense = nn.Linear(config.hidden_size*2, n_classes)\n",
        "        if out_activation == 'none' or out_activation is None:\n",
        "            self.activation = lambda x: x\n",
        "        elif out_activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif out_activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif out_activation == 'sigmoid':\n",
        "            self.activation = torch.sigmoid\n",
        "\n",
        "        if device is not None:\n",
        "            self.to(device)\n",
        "\n",
        "        # linear layer operating on the concatenated CLS tokens from all silos\n",
        "        self.cls_pooler = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            nn.Linear(self.dim_in, int(self.hidden_size)),\n",
        "        )\n",
        "\n",
        "        # pre-mean-pooling (one for each silo)\n",
        "        #self.pre_poolers = [nn.Sequential(\n",
        "        #    nn.Dropout(p_dropout),\n",
        "        #    nn.Linear(dim,dim)\n",
        "        #    ) for dim in self.dims_in\n",
        "        # ]\n",
        "        self.pre_poolers = nn.Sequential(\n",
        "            nn.Dropout(p_dropout),\n",
        "            self.mean_activation\n",
        "        )\n",
        "\n",
        "        # sequential layer to concatenate the mean tokens from multiple tokens\n",
        "        self.mean_pooler = nn.Linear(self.dim_in, self.hidden_size)\n",
        "\n",
        "    def forward(self, hidden_states, attention_masks, excess_cls_ids=None) -> torch.Tensor:\n",
        "        \"\"\"Combines CLS token and mean-pooling for the sentence-vectorization\"\"\"\n",
        "\n",
        "        # CLS/first-tokens from all silos, all concatenated together\n",
        "        first_token_tensors = self._get_cls_tokens_all_silos(hidden_states)\n",
        "\n",
        "        # mean pooling\n",
        "        mean_pooled_tensors = self._mean_pool_all_silos(hidden_states, attention_masks, excess_cls_ids)\n",
        "\n",
        "        # concatenate CLS and mean\n",
        "        pooled_output = torch.concat((first_token_tensors, mean_pooled_tensors), axis=1)\n",
        "\n",
        "        return self.activation(pooled_output)\n",
        "\n",
        "    def _get_cls_token(self, hidden_state):\n",
        "        \"\"\"Grabs the CLS token from a hidden-states\"\"\"\n",
        "        return hidden_state[:, 0]\n",
        "\n",
        "    def _get_cls_tokens_all_silos(self, hidden_states):\n",
        "        \"\"\"Grabs the CLS token from all hidden_states\"\"\"\n",
        "        first_tokens = [\n",
        "            self._get_cls_token(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "        # concat all first tokens\n",
        "        all_first_tokens_cat = torch.cat(first_tokens,axis=1)\n",
        "        # run the concatenated first-tokens through Dense\n",
        "        all_first_tokens_out = self.cls_pooler(all_first_tokens_cat)\n",
        "        return all_first_tokens_out\n",
        "\n",
        "    def _mean_pool(self, hidden_state, attention_mask=None, excess_cls_id=None):\n",
        "        \"\"\"Pool along a sequence dimension (for just one silo)\"\"\"\n",
        "        if excess_cls_id is None:\n",
        "            excess_cls_id = attention_mask\n",
        "        input_mask_expanded = excess_cls_id.unsqueeze(-1).expand(hidden_state.size()).float()\n",
        "        sum_embeddings = torch.sum(hidden_state * input_mask_expanded, 1)\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        return sum_embeddings / sum_mask\n",
        "\n",
        "    def _mean_pool_all_silos(self, hidden_states, attention_masks=None, excess_cls_ids=None):\n",
        "        \"\"\"Pool along a sequence dimension (for all silos)\"\"\"\n",
        "        if excess_cls_ids is None:\n",
        "            excess_cls_ids = attention_masks\n",
        "\n",
        "        # pre-pool: dense-layer before pooling\n",
        "        hidden_states = [\n",
        "            self.pre_poolers(hidden_state) for hidden_state in hidden_states\n",
        "        ]\n",
        "\n",
        "        # mean pool each silo\n",
        "        mean_pooled_states = [\n",
        "            self._mean_pool(\n",
        "                hidden_state=hidden_state, excess_cls_id=excess_cls_id\n",
        "            ) for hidden_state, excess_cls_id\n",
        "            in zip(hidden_states, excess_cls_ids)\n",
        "        ]\n",
        "\n",
        "        # concat all mean-pooled states\n",
        "        all_mean_pooled_states = torch.cat(mean_pooled_states,axis=1)\n",
        "        # run the concatenated meanpooled states through Dense\n",
        "        all_mean_pooled_states = self.mean_pooler(all_mean_pooled_states)\n",
        "        return all_mean_pooled_states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J18VNXqTYNY2"
      },
      "outputs": [],
      "source": [
        "class AnathemTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=None,\n",
        "        device=None,\n",
        "        do_mlm = None,\n",
        "        do_cls = None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # default config\n",
        "        if config is None:\n",
        "            config = make_config()\n",
        "        self.config = config\n",
        "        self.do_mlm = config.do_mlm if do_mlm is None else do_mlm\n",
        "        self.do_cls = config.do_cls if do_cls is None else do_cls\n",
        "\n",
        "        # device\n",
        "        if device is None:\n",
        "            if torch.cuda.is_available():\n",
        "                device = torch.device('cuda')\n",
        "            else:\n",
        "                device = torch.device('cpu')\n",
        "        self.device= device\n",
        "\n",
        "        # get the basemodel (and its masked LM head\n",
        "        self.model_string = self.config.model_string\n",
        "        basemodelLM_pretrained = AutoModelForMaskedLM.from_pretrained(self.model_string)\n",
        "\n",
        "        # get the Pretrained BertEncoder\n",
        "        basemod_pretrained = get_to_bertlayer(\n",
        "            basemodelLM_pretrained,\n",
        "            target_layer_name = 'encoder'\n",
        "        )\n",
        "\n",
        "        # make the tokenizer (based on pretrained)\n",
        "        self.tokenizer = CustomTokenizer(\n",
        "            model_string=self.config.model_string,\n",
        "            n_cls_prepend = int(1/config.scale_ratio3),\n",
        "            n_pad_to_multiple_of= int(1/config.scale_ratio3)\n",
        "        )\n",
        "\n",
        "        # make the Embedding and first layers (pretrained)\n",
        "        self.encoder = AnathemEncoder(\n",
        "            self.config,\n",
        "            basemod=basemod_pretrained,\n",
        "            tokenizer=self.tokenizer ,\n",
        "            past_key_values_length = None,\n",
        "            device=self.device,\n",
        "        )\n",
        "\n",
        "        # get the Pretrained maskedLM head\n",
        "        if self.do_mlm:\n",
        "            # perform maskedLM\n",
        "            self.mlm = get_to_bertlayer(\n",
        "                basemodelLM_pretrained,\n",
        "                target_layer_name = 'cls'\n",
        "            )\n",
        "        else:\n",
        "            self.mlm = lambda x : x\n",
        "\n",
        "        # make the sequence-classification head\n",
        "        if self.do_cls:\n",
        "            self.pooler = AnathemMultiSiloPooler(\n",
        "                config=self.config,\n",
        "                mean_activation = nn.Tanhshrink(),\n",
        "                dims_in = self.config.sequence_classification_intermediate_dim,\n",
        "                p_dropout=self.config.hidden_dropout_prob,\n",
        "                device=self.device\n",
        "            )\n",
        "\n",
        "    def _get_name(self):\n",
        "        return 'ANATHEM_MODEL_FOR_MLM'\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l2: Optional[torch.Tensor] = None,\n",
        "        attention_mask_l3: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l2: Optional[torch.Tensor] = None,\n",
        "        excess_cls_ids_l3: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = False\n",
        "    ):\n",
        "\n",
        "        # run through base-layer (embeddings, transformer-block, 1 anathem stack)\n",
        "        outputs_encoder = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_mask_l2=attention_mask_l2, # optional downsized attention mask for sequence-dim 1/2\n",
        "            attention_mask_l3=attention_mask_l3, # optional downsized attention mask for sequence-dim 1/4\n",
        "            token_type_ids=token_type_ids, #: Optional[torch.Tensor] = None,\n",
        "            position_ids=position_ids,#: Optional[torch.Tensor] = None,\n",
        "            head_mask=head_mask,#: Optional[torch.Tensor] = None,\n",
        "            inputs_embeds=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_hidden_states=None,#: Optional[torch.Tensor] = None,\n",
        "            encoder_attention_mask=None,#: Optional[torch.Tensor] = None,\n",
        "            past_key_values=past_key_values,#: Optional[List[torch.FloatTensor]] = None,\n",
        "            use_cache=use_cache,#: Optional[bool] = None,\n",
        "            output_attentions=output_attentions,#: Optional[bool] = None,\n",
        "            output_hidden_states=output_hidden_states,#: Optional[bool] = None,\n",
        "            return_dict=False\n",
        "        )\n",
        "        if output_attentions:\n",
        "            hidden_states, extended_attention_masks, attention = outputs_encoder\n",
        "        else:\n",
        "            hidden_states, extended_attention_masks = outputs_encoder\n",
        "            attention = None\n",
        "\n",
        "        out_mlm = {'logits':None}\n",
        "        out_pooled_vector = None\n",
        "        hidden_states_highres, hidden_states_midres, hiddenstates_lowres = hidden_states\n",
        "\n",
        "        # MLM outputs\n",
        "        if self.do_mlm:\n",
        "            out_mlm = self.mlm(hidden_states_highres)\n",
        "\n",
        "        # sequence pooling (for classification)\n",
        "        if self.do_cls:\n",
        "            out_pooled_vector = self.pooler(\n",
        "                hidden_states=hidden_states,\n",
        "                attention_masks=(attention_mask, attention_mask_l2, attention_mask_l3),\n",
        "                excess_cls_ids=(excess_cls_ids, excess_cls_ids_l2, excess_cls_ids_l3)\n",
        "            )\n",
        "        #\n",
        "        if return_dict:\n",
        "            return {\n",
        "                'hidden_states':(hidden_states_highres, hidden_states_midres, hiddenstates_lowres),\n",
        "                'pooled':out_pooled_vector,\n",
        "                'logits':out_mlm['logits'],\n",
        "                'attention':attention,\n",
        "                'extended_attention_masks':extended_attention_masks\n",
        "            }\n",
        "        return hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fb064cacf0e243299a2d092facae8c79",
            "be7af49d0afe4ecdaa800be969d5a3e7",
            "560c716068a645d596cc2fe9b886c0ad",
            "08c60bb508854cc9b6772ab78502b6fb",
            "e84136de295d4d39b44c908ff2458ba9",
            "2166426a7a224f1da2065f3221463693",
            "77d712d32c0f491cb9a58df33b012b0c",
            "235afab600844a9f8ef8f45cdba142e0",
            "c7537c19825a49cd8f3343c153fe56ef",
            "497aad7b9ab34f158382033f65d9a8c9",
            "814c0fc7e64c49bfa85d5087d1e07cb4"
          ]
        },
        "id": "jYu06BPCY1Oz",
        "outputId": "a8d0df70-d7a6-47ac-ab3a-e6377dd18a37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb064cacf0e243299a2d092facae8c79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "modelstring_teacher_mlm = 'bert-base-uncased'\n",
        "model_string = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "\n",
        "config = make_config(\n",
        "    modelstring = model_string,\n",
        "    num_transformer_stacks = 3,\n",
        "    scale_ratio2 = 0.5,\n",
        "    scale_ratio3 = 0.25,\n",
        "    multiplier_intermediate2 = 4.0,\n",
        "    multiplier_intermediate3 = 4.0,\n",
        "    num_layers_l2 = 1, # mid-res encoder\n",
        "    num_layers_l3 = 3, # low-res encoder\n",
        "    dropout_scaling = 0.05,\n",
        "    do_cheap_integrator = [1],\n",
        "    do_mlm=True,\n",
        "    do_cls=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496,
          "referenced_widgets": [
            "19e70f5c3ae04d4b8b4a86c1233418be",
            "c7fcfc2727db445695b908ffd3370feb",
            "546b278b05e643a4905055d1d7ffeea5",
            "289aa49d154a496d9804cf30545bc5fc",
            "f54be5e820704ad2b31b6b7a6b946181",
            "8a0851189dae4fbdb953f6afe6f3ba29",
            "01f4a70e089f4fe5abb0d9246aeee403",
            "195b549a3cd745ffbe55e24f5865b1da",
            "fe156388571b4c63b5fc5f5ca857e522",
            "36c0e136fa3f400bab5deec7a0aff11f",
            "bcee86d4105743f5a69c595029994bc8",
            "9c8b871e03af41ada7990e7b76084f84",
            "33ae5a6ee9244aeea02e10990e8dd3da",
            "470a84311bbf40c6ae6322d6edc353ae",
            "8974203b2bde4395b3144ffe61596643",
            "d4ea11ee38044f7cb7ffe1a5b018bda7",
            "5f1b9961c6b14a1a92f3cb2c82883a17",
            "dfd3f1f64d81471083416a3e4ca6aa60",
            "9568bdb74f3e450f91b3558cf5ad5da1",
            "b7b946e1ad95455b818512986f83f7cd",
            "5fdca1f2b388437fac7624c0eca1ec26",
            "1c00f260ca44415c9c2cc342c9cab470",
            "476c5672e7784cda8255af2049de1ecd",
            "73e2bfea29de4c47b0c60590deff9771",
            "4326c46139fd4b6882d864400e35a9bc",
            "a53d537c8c0e48d1a77fbc22e5c41402",
            "4eba976ecf5145e0a60cc8a838bff5c9",
            "2750de9a4c5740b080f5a8145de41111",
            "ecf9c5705a7b491c82d4e8b5cbd8c439",
            "e76cddc6d7d04d3fb01c11225ec1b6a2",
            "9ad1276e945e4915a079e97e06048ee9",
            "02191a5509094a0abcf8862d3a8ee4cd",
            "5c69e45579f54fc6b2415ebbad4da477",
            "8dbb1fccc920458cbffc7029953e5363",
            "29e9e92bc30c4b2f89416481b4fb1455",
            "1c5678cdeb204d21b94526ccdab34d32",
            "dea6b34486294d388d68aa9ef3aaa281",
            "e34566724c6e4598860e77d6b710faf8",
            "b34433ff3b52491fb5829b9f1522e162",
            "5250f6a6e5c34894adb20a9120388ba0",
            "0381ff6309df4052bb0ce823e7ff741b",
            "bd79d8ce5e28404c988f4965873a2f2c",
            "b70156e5cb144e75b97697a2439d9a5d",
            "96e7d97dc8f44c7d873060a89f82ce0e",
            "aa099b9c51d6447a9a22fb13b103cb41",
            "03a6cc127c8c4f03bab0b31bb3a1721b",
            "08fbdead6ab540d4a1d2d8f06879e417",
            "5f0512fb3607471f817b5c215d94e4d8",
            "0457dfcb462c4173bbfb7890bb043c97",
            "d6ccd976679e45fcbf6d6b5d06360ea6",
            "f6c454dc6dcb4528b7b05b83c72640fc",
            "029adddbce024f50bc5d7a06d304632d",
            "d2a8de725a934927b52792351e0d5099",
            "dcd68849bd0a44238fbb9bec129b0511",
            "3312caf3fc76420ead7f4945675df52a",
            "169e8fa7a73d4797945e98ccba4cd10c",
            "b072faf11c504e39939d1ad4534f9112",
            "f3707c74969e4f6c84d6a36b59d6fa9e",
            "32184fc9b099416a8d49ef3c3f8c3a2e",
            "2b95b44611524401ac7826dab5a21aa8",
            "3fb4b68eda9f481abbc7b2456644e16b",
            "3c54d6fd6a004ed98c1cb595a0bb84a0",
            "7f511160291e4a4a82f8694772449ea8",
            "91eebca40ce344039704522c4570353c",
            "2137d76adc0b4235bcf4e52ab94ae445",
            "fcb506371e6e4cd2947988d6c7050809",
            "a5967030d5aa4581b66d319588b92db4",
            "6baecbf668bc4a6f93be03e5f671b76a",
            "a33ab96c585c411ab148d76865b848f2",
            "5589d685cbc94ea0a045dcba0e69a7e5",
            "01ac22caf29c4b2baf0ebc428f3398b3",
            "1d322e088a6a4904a0b99740d8d4e45c",
            "20402646761d4cf3975763fc130d6ff5",
            "5183ef3eec0d4bdfbcc5544b0fec573b",
            "3751db7e581847efa6c224dd50c9b7bb",
            "600bc8f5877547aca898f8c85902040e",
            "b65ef6da8ad34e2285813544d00bf3e5",
            "4ef3bcbd56164ddaac3068fb93a66630",
            "0cbd831de3c64f4aa269776dc73c5e28",
            "d947bfe9101646c9a7222ada482d4455",
            "8e9137be11744d329bceecd548d91025",
            "326c1c104f254d1189c78c6abd318451",
            "a4848184b58645b2a572c6e1a1231f05",
            "92d450929c8e45539c2726eaf96d5ddb",
            "d9a90b08aaec44d9962e8c090b8d0baa",
            "70225a6a843d4ccf87d1b43d4cf1895b",
            "8c45ce351a9b45dda4359b706ea36aba",
            "9e2644d3c3bb40aa9eba632e756112a3",
            "a6770d150cfa459780d5adb12fc7c7b8",
            "78608a4a3a8f4c119d9a0128153a39eb",
            "91de7341a97a4415b5656ee33fe6395f",
            "82f1dc2ca5ef4e45818a2b9107732d58",
            "5e1a387877054dacbb6bf1fa32b08d7a",
            "48729429682c4b37a624ba2eb55d1966",
            "6eeb3579c2b644a6b8501cc246083c97",
            "8f1bf2df4214449483a37dc84d9f3c43",
            "9afa2b87f4a94a58b7c639a0a7f63813",
            "8ae32d0dd19e40e8a0fc4b04b325abd6",
            "20ae65dc26cb4ab98a9637dfa2bd5a62",
            "641fd37171904fb590b7877d8403aeea",
            "e8f710e2dcfc40398ce16a4ac265cc26",
            "377a7fa0ebce4c8a96a55c6e1c08403f",
            "5ed5174d9d6c4680bb7cc1e803184102",
            "2c148a8aa9fe4f30a69392f10a350eac",
            "177dee7aa0754c7db2b595f83a4eb105",
            "2fe3c4d6e4774be691e7c0551fd334ff",
            "6ff3a2b6be1f4220b0e3c055fc587c7e",
            "af816340aae74a81a6eaf63a1933f5bf",
            "91bcf74809894d39b5199ca23691f00f",
            "85a35c16364f4c6880dbbecf061faf44"
          ]
        },
        "id": "Y7HRRYhrfm18",
        "outputId": "0fc7cf35-f252-47f1-a9a0-3b2ef5615da2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19e70f5c3ae04d4b8b4a86c1233418be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c8b871e03af41ada7990e7b76084f84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "476c5672e7784cda8255af2049de1ecd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dbb1fccc920458cbffc7029953e5363",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa099b9c51d6447a9a22fb13b103cb41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "169e8fa7a73d4797945e98ccba4cd10c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5967030d5aa4581b66d319588b92db4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ef3bcbd56164ddaac3068fb93a66630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6770d150cfa459780d5adb12fc7c7b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "641fd37171904fb590b7877d8403aeea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "anamod = AnathemTransformer(\n",
        "        config=config,\n",
        "        device=None,\n",
        "        do_mlm = True,\n",
        "        do_cls = True\n",
        "    )\n",
        "\n",
        "teacher_mlm = AutoModelForMaskedLM.from_pretrained(modelstring_teacher_mlm)\n",
        "\n",
        "\n",
        "from torch import Tensor\n",
        "class TeacherEmbedder:\n",
        "\n",
        "    def __init__(self, pretrained_name = 'intfloat/e5-large-v2'):\n",
        "        self.pretrained_name = pretrained_name\n",
        "        self.teacher_tokenizer = AutoTokenizer.from_pretrained(pretrained_name)\n",
        "        self.teacher_embedder = AutoModel.from_pretrained(pretrained_name)\n",
        "\n",
        "    @staticmethod\n",
        "    def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
        "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "    def forward(self, input_text, prepend = 'passage: '):\n",
        "        input_text = [prepend + s for s in input_text]\n",
        "        with torch.no_grad():\n",
        "            batch_dict = self.teacher_tokenizer(input_text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "            outputs = self.teacher_embedder(**batch_dict)\n",
        "            embeddings = self.average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "        return embeddings\n",
        "\n",
        "    def __call__(self, input_text, prepend = 'passage: '):\n",
        "        return self.forward(input_text)\n",
        "\n",
        "\n",
        "teacher_emb = TeacherEmbedder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_BdVwTUsWj1",
        "outputId": "2e956c25-393b-4fc3-996e-5b18796b9e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertOnlyMLMHead(\n",
            "  (predictions): BertLMPredictionHead(\n",
            "    (transform): BertPredictionHeadTransform(\n",
            "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (transform_act_fn): GELUActivation()\n",
            "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(anamod.mlm) # MLM head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PaoAjDffxVd",
        "outputId": "868f0300-5add-4258-da89-da358ddf8b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'excess_cls_ids', 'attention_mask_l2', 'attention_mask_l3', 'excess_cls_ids_l2', 'excess_cls_ids_l3'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 48, 512])\n",
            "torch.Size([2, 24, 256])\n",
            "torch.Size([2, 12, 128])\n",
            "torch.Size([2, 1024])\n",
            "torch.Size([2, 48, 30522])\n",
            "torch.Size([2, 48, 30522])\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'a', 'standard', 'liability', 'clause', 'is', 'a', 'wai', '##ver', 'clause', 'that', 'states', 'that', 'one', 'party', 'won', \"'\", 't', 'hold', 'the', 'other', 'liable', 'for', 'damages', ',', 'losses', ',', 'or', 'costs', 'associated', 'with', 'issues', '.', 's', '.', '.', 'it', '.', 'the', 'it', 'it', 'it', 'parties', 'one', 'party']\n",
            "Anamod\n",
            "['-', 'the', '-', '-', 'a', '-', '-', '-', '.', 'a', '-', '-', '.', '.', 'is', '.', 'the', '.', '-', \"'\", 's', '.', 'the', 'other', ',', 'for', 'me', ',', 'my', ',', 'or', 'the', '-', 'with', 'the', '.', 'the', 'he', 'he', 'he', '-', '-', ',', ',', ',', 'the', '-', ',']\n",
            "Bert Base\n",
            "['.', '.', '.', '.', 'it', 'usually', 'consists', 'of', 'two', 'elements', ':', 'a', 'trigger', 'event', 'or', 'circumstance', 'and', 'a', 'trigger', 'obligation', '.', 'the', 'trigger', 'event', 'or', 'circumstance', 'is', 'the', 'violation', 'of', 'the', 'agreement', ',', 'misconduct', ',', 'or', 'negligence', 'of', 'the', 'ind', '##em', '##ni', '##fying', 'party', 'or', 'its', '.', 's']\n",
            "Anamod\n",
            "['-', 'the', 'the', '-', 'it', 'or', 'the', 'of', 'two', 'of', ':', 'a', 'the', ',', 'or', ',', 'and', 'a', '-', 'of', '.', 'the', 'trigger', '-', 'or', '-', 'is', 'the', 'part', 'of', 'the', 'or', ',', 'the', ',', 'or', ',', 'of', 'the', 'ind', '##em', ',', ',', ',', 'or', 'the', '-', 'the']\n",
            "torch.Size([4, 1024])\n"
          ]
        }
      ],
      "source": [
        "text = [\n",
        "    \"A standard [MASK] clause is a waiver clause that states that one party won't hold the other liable for damages, losses, or costs associated with issues.\",\n",
        "    \"It usually consists of two elements: a trigger event or circumstance and a [MASK] obligation. The trigger event or circumstance is the [MASK] of the agreement, misconduct, or negligence of the indemnifying party or its affiliates\"\n",
        "]\n",
        "\n",
        "inputs = anamod.tokenizer(text, add_special_tokens=True, return_tensors='pt', padding='longest')\n",
        "\n",
        "print(inputs.keys())\n",
        "inputs\n",
        "\n",
        "outputs = anamod.forward(\n",
        "    input_ids = inputs['input_ids'],\n",
        "    attention_mask = inputs['attention_mask'],\n",
        "    attention_mask_l2 = inputs['attention_mask_l2'],\n",
        "    attention_mask_l3 = inputs['attention_mask_l3'],\n",
        "    excess_cls_ids = inputs['excess_cls_ids'],\n",
        "    excess_cls_ids_l2 = inputs['excess_cls_ids_l2'],\n",
        "    excess_cls_ids_l3 = inputs['excess_cls_ids_l3']\n",
        ")\n",
        "# hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "\n",
        "outputs_teacher_mlm = teacher_mlm(input_ids = inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "\n",
        "print(outputs[0][0].shape) # full hidden state sequence\n",
        "print(outputs[0][1].shape) # mid hidden state sequence\n",
        "print(outputs[0][2].shape) # small hidden state sequence\n",
        "print(outputs[1].shape) # sentencevector\n",
        "print(outputs[2].shape) # mlm outputs\n",
        "\n",
        "#\n",
        "print(outputs_teacher_mlm['logits'].shape) # Teacher shape mlm\n",
        "\n",
        "predicted_token_ids1 = outputs_teacher_mlm[0][0].argmax(dim=-1)\n",
        "predicted_token_ids2 = outputs[2][0].argmax(dim=-1)\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][0].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][0].argmax(dim=-1)))\n",
        "\n",
        "\n",
        "print('Bert Base')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs_teacher_mlm[0][1].argmax(dim=-1)))\n",
        "print('Anamod')\n",
        "print(anamod.tokenizer.convert_ids_to_tokens(outputs[2][1].argmax(dim=-1)))\n",
        "\n",
        "# try to embed text with the teacher_emb\n",
        "text2 = input_texts = [\n",
        "    'query: how much protein should a female eat',\n",
        "    'query: summit define',\n",
        "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
        "    \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"\n",
        "]\n",
        "sentence_embeddings = teacher_emb(text2)\n",
        "print(sentence_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzb5l9wymf4D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "1a3234bae89d4c1eb7e84da16675cde8",
            "7c50e41b12ab40ae88db5a68806a5287",
            "9a675022c08043438f0288c2dc3d1692",
            "42ed4267878a46a9a1a1de7f63006ab4",
            "a587d42c581c4f75984a189ebe1b1831",
            "1aea1f6de91a43a4b491c82ffc1522be",
            "3c45e6794f974b4199098bcd87765e63",
            "ff58b4945b004e9996568c228986d287",
            "1290569b6a4d490fbfc8ca3915983263",
            "ba76516f42224f79a9dfe8a36385bb22",
            "c6b2dc48588b482f80e9a2473dc5b452",
            "e7bd0a23537441b6a41373c7db399423",
            "7bdb5cce9c364437970f01220e5f0aa3",
            "5df7aa079833485bbde65e4658b496e0",
            "e9149263e2264fe6b5e5cb50f67d55c2",
            "e3712984d7774865be2c1e97faf82d57",
            "3e72971bf9804c3688c24e0a3eca0da7",
            "d36c80ffd8824fdb8e1e344f41fa3669",
            "283065bbec654b89a6be726e3fe790fd",
            "ebf0c7ac01e441d68a38cac5fed89d00",
            "ab8bf4aa34c5452d8c6d01df44402eea",
            "c1ad349038c94c1f9ec7b1d0d7245699",
            "fc40e712ccca489e8cb2eaadbc47aa54",
            "d87e9ee37dfe44bcad7b97ccfef0f5ff",
            "afd68f4512e045c2bfaa46eb36d4ab5a",
            "db1f664494c94faf8998df1f25718b9f",
            "63a2424581894ab48ad61b9f38cc882e",
            "44ce4959b2bc410a8b455eb2adb7ffc9",
            "422ac21cdb1d45a8a0814ef00c9769ff",
            "f387685057a6405f86292bd9ce5df000",
            "808dad49922a431d9c43faf48478a069",
            "5c96dd4ef67f4900af004f322706921f",
            "c519b80ce005494caf41456ec90111bf",
            "694f0df64a4b433aa22afef48d968090",
            "75d264b002cc4c3889089fe28f6cfa80",
            "f6a686a076954e0c9c5d11429a14d582",
            "9f512b3c83bf4fcaa1640cf5cdbea8c8",
            "282f350bdadd41fa82b37f527ffe8a63",
            "052465580f854b15be0d29e9dc59125b",
            "619bcc47eac24a098ac5908bddc4297d",
            "0a320f7b8bba47ddb97d2aff966e162f",
            "0e215f7f87fc48bfbb3e74c9c97b23a8",
            "5ab64a9556124cf892f33cc9973240ea",
            "656cb0e3b85c4a57936749caa02f664d",
            "f7ca459667fe48c2a54d0ca13ccfe114",
            "91738a91e20344f1b848ccc39bd0b686",
            "ae85f3dd9b864de7897e02a2313c8093",
            "e97d23572a21475fa4b5b9fa4454d4cc",
            "32f65d2703c048929de10720219fdf53",
            "f9d88bd9fdda49bcbf01366f8fe6fab2",
            "ca5cfab63b2d47869f69b772f9801d69",
            "ea00ba0feb164981bdb521803fd29049",
            "16501e0f5de84fc7bbbdcc9b37f61d85",
            "68db1531b9574e72a2ff0d52995a7347",
            "eeafa1a037dd42a88774f76ea6275360",
            "e891d996e42f425cb2b31d563dfc77ef",
            "216e1650231e471fa0d88e3d73bf6da0",
            "d1dafb9eb15541489d740cbf202fac2f",
            "e362a74248d24aa28ab7dd3500c9d303",
            "1eb78591c14840daaf6741730f2280f8",
            "a2bbd67afcb9463cb0f78d7a24c5f126",
            "ad9c165248ef4e0b9c357316b95f66af",
            "adc06005b98c44f0a6308cbd4f6a3527",
            "eace7bc2187b4dd0af47dbee9327903a",
            "a9f66a8eed1443d099d0fadab83d02e9",
            "292c0b150eb84f06a012e2084b035350",
            "755e3809aa3043f99d3664955a3a2c03",
            "44d07abd85374cca92698119139b140e",
            "00001f9f055045f9ae35f94f76be8fe4",
            "1e7d06e9df9b4a88a003bbba433c1cae",
            "a87f8ff9f575436da0dcf9a31642f7b7",
            "1deae35c0489408fa7e374cd93cca642",
            "260f38a6c52d464999f74443c04cdc03",
            "c16dd57325504698b35f155d1bd040b5",
            "7950d803ab5b4c4ab10dc9e0902e34b1",
            "d151de5a1862426f9d3ab2aaae73f4d9",
            "3963ddae09b14417abf20a566ce82a03",
            "03a8f530cfb0469998f56dcca5f00803",
            "cafc757655d74a2697f4ba566b3623ee",
            "46cd1079cad04e7ea04959e14225b7fb",
            "c508e67d54c24888b82b66108681da19",
            "b08eba43d39846869bdd9050836be1cb",
            "d1837578698f426d8c65a40770a3488c",
            "fdf37a5ac48c477d99318631238a5756",
            "ef504e4ab1384063bff714e1649e0aa3",
            "7b387dec327543f79f957f81fb651cc7",
            "d71e718353ac40788febf07676b3cb25",
            "addf3619a835489f8d9f3ce4498daf36",
            "3315267c32f24d29804c12af760956aa",
            "31fef27ae4d44fa691185c3fa750756a",
            "11db36da26a94bae9ad00e99a10d8c5a",
            "f4bb56cde5b042e8821ee26d25da4ea2",
            "312b0a411cf7451d845fae7b77dff7d6",
            "fa205a1da88e418a881efb0963042e9d",
            "30f6111712e2491198ac03400ef0ce7d",
            "c5323c16a9ca4decbe25c651a14517de",
            "eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "ffe8145192c34433b3140f05b5b2528f",
            "3988d9e57bc841b49a5079130f071dfc",
            "d9bcbb8cd61d4fa5b9e0b95304f8969c",
            "8ea68f6b18c342938de8be19d3896038",
            "0b0c4175d283414ab014c95269b4421b",
            "00c7829ca16746089c8896865f374b1f",
            "f9f77be1c3044483bbd3714a5a45e2ad",
            "b42f3b105ff645dcb58805289594baad",
            "d4214693adb54e44b31fd40e549802b8",
            "b17a0dd6bd24481e8e597415bfc02c87",
            "2c43b4c9b58842acaf321862c3a1625d",
            "99ef066e53974658a59443c917b2c615",
            "98bd45b05dda4319adf853b5104f0a0a",
            "0003c5e497294b5abf83ff5edbf90261",
            "28542ed3d1b443c9a7ba7074825ee208",
            "7c01fc1aabb0486f9f1f0674b46b5481",
            "6b349f8f7890488eaa05b156ec971bf6",
            "1602c7712db64b829a6ed1fa73367a1e",
            "d72812af3cd8475f8a76a8ff3ec236e9",
            "40731cc8e1a245868c9bf6d0972c0467",
            "6f102144e4fd4840b77808f1e6ff7697",
            "82084929de714135a363f5693f4a0aac",
            "f3537b58aca04f398663d6a8f6bd7cf8",
            "0ea16b4f2c6d428191dd7d31d21ad659"
          ]
        },
        "id": "b2ueft2IwxIr",
        "outputId": "4d0bdc1a-4261-4233-cfc0-d686ea8b1e84"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a3234bae89d4c1eb7e84da16675cde8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7bd0a23537441b6a41373c7db399423",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc40e712ccca489e8cb2eaadbc47aa54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset glue/mrpc to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "694f0df64a4b433aa22afef48d968090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7ca459667fe48c2a54d0ca13ccfe114",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e891d996e42f425cb2b31d563dfc77ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "755e3809aa3043f99d3664955a3a2c03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03a8f530cfb0469998f56dcca5f00803",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3315267c32f24d29804c12af760956aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9bcbb8cd61d4fa5b9e0b95304f8969c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0003c5e497294b5abf83ff5edbf90261",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHq4Udecy1S6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSdXchNStSMR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "pQXS1wenz68U",
        "outputId": "09fec374-2e3b-47d5-d4eb-02ab69561b78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f52e91588ea352bb.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
            "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-055028f389e5>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hit %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m: hit 19"
          ]
        }
      ],
      "source": [
        "\n",
        "## Test a batched inference routine: including loss calculations\n",
        "## steps:\n",
        "## 1) tokenize inputs internal to a torch dataset (encode_plus?)\n",
        "## 2) loop through dataloader, with a MLM collator also set?\n",
        "## 3) do inference using teacher\n",
        "## 5) do inference using anathem\n",
        "## 6) loss\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# load dummy dataset\n",
        "dataset_glue = load_dataset('glue', 'mrpc', split='test') # small set\n",
        "\n",
        "# tokens = [tokenizer.encode_plus(txt, add_special_tokens=True) for txt in text]\n",
        "# tokenize\n",
        "dataset_glue = dataset_glue.map(lambda e: tokenizer.encode_plus(e['sentence1'], add_special_tokens=True))\n",
        "print(dataset_glue.features)\n",
        "dataset_glue = dataset_glue.remove_columns(column_names = ['sentence1','sentence2','idx','label'])\n",
        "print(dataset_glue.features)\n",
        "_ = \"\"\"\n",
        "{'sentence1': Value(dtype='string', id=None),\n",
        " 'sentence2': Value(dtype='string', id=None),\n",
        " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
        " 'idx': Value(dtype='int32', id=None),\n",
        " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
        " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
        " 'excess_cls_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n",
        " \"\"\"\n",
        "\n",
        "# MLM collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")\n",
        "\n",
        "# MLM distillation loss function (kl-divergence between teacher and student outputs)\n",
        "loss_fn_mlm_distil = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "loss_fn_mlm_labels = nn.CrossEntropyLoss(ignore_index=-100) # non-masked tokens have -100\n",
        "weights_mlm_distil = 0.5\n",
        "weights_mlm_labels = (1-weights_mlm_distil)\n",
        "\n",
        "# dataloader with MLM collator\n",
        "dl_mlm = DataLoader(dataset_glue, collate_fn=data_collator, batch_size=4)\n",
        "\n",
        "# optimizer\n",
        "optimizer = AdamW(anamod.parameters(), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "\n",
        "for step_i, batch in enumerate(dl_mlm):\n",
        "\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    # label loss\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "    optimizer.zero_grad()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    #\n",
        "    optimizer.step()\n",
        "\n",
        "    if ((step_i+1) % 20) ==0:\n",
        "        raise NotImplementedError('hit %d' % step_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyCvyxgiqAdm"
      },
      "source": [
        "## MultiTask Training: adapted from s-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "dab6a9ff832540bfae51a3f0dcfedfba",
            "c5adcad970e4455cbf797f14e2e5303e",
            "928bc9d9e240469298d2a267fe3b9e65",
            "24e977d511bd4f03bc8d730cd4c86027",
            "4b4dae6b5bd5474491e1c86a6e462ebf",
            "21f6c046574b4badbf5dac2bd4989d67",
            "e844aa942c604f17b61375f59aad56f3",
            "595530337aab40f6b5cc24d69b3ebaf9",
            "85aa23b715f248248204a2bdf3e5f7ec",
            "3f2b4543fdb94a1d9153de7f18d108be",
            "da3eb201a16240aaa91baf19b49d4209",
            "f53073dd81bf427188a9cfde75c18bff",
            "2b5f6a6687b34036bd5a87c8b61dc2c3",
            "b0546b4b929f4fe3927af49ab119d99a",
            "37e0abc511f04624986368ef45b50131",
            "d365ebcd816a44da80bc74870dd008bd",
            "d265db9a419d4edfbdb91e4bd8f78846",
            "aae2a30b7f474dbcbf55aa677b9518f9",
            "df31cc0682014cdb881817de1c02288f",
            "01fa51a473a6472da89d47bf1116e575",
            "33088ffab85f4898bc39a1167e70388c",
            "1672001c1d7e449f9cc0ce76fcf50fc8",
            "fc2d3eb4b1304b97bf336245736983ec",
            "4d798a40b2a24c4f8ce823023d75ea6a",
            "429379eb4c4f452d94a52521911811a8",
            "49a90c227b9342ddbb670c9fe85591cc",
            "843d11a2271246f49dbabe80fc4762d4",
            "f10d3cde2d7b4121971d8e19e3362b30",
            "4818654025b94f38a631b2bcdf36014c",
            "f68c38cc7bf84db2ab1540ca985599e2",
            "d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "8a1ecdd97d194a9ab63a15980d1e2e31",
            "5dd1df4079d44b1aad849b4a0a5e3b55",
            "2958b232a65d47d7950e040ddd583898",
            "82db512ae4ce4b1fbde3aed3d893e032",
            "8b3982acce834b95a6f318dfb78add1c",
            "3df2e72406454de7ade25cfe0fca7295",
            "979449deb4254629b80f0089584c851a",
            "cd748fe04232441abb30f153e54f9890",
            "8eda2864b2774815bd6d860c1fdf2625",
            "09a93d25cd25426e9c60222b29321889",
            "0db15040be1242378220fa56a21aba28",
            "7834f7deaa3b43669cd0de893fa62448",
            "cfa5b162648c4abca773a478c3e3beb9",
            "2a7388d890b2460c86be4cd32187f319",
            "38b91d162c304c6eaad444f0abffa931",
            "0f331a136adf425f87a1a35682256cd9",
            "1f65726d2e20471e99928e5dc96726c7",
            "dae9d080adfc4bfbba896820bbf57c3b",
            "9ef72b344a964832bd2b19140d230f7b",
            "b719af868833401c86d45d2ae059c868",
            "46f2289d8f6c460892864f1ef5ad8e08",
            "f81a1dd1a8b547b39297478219b41c81",
            "454aeb5a95b94bb580698d8d2f62f43f",
            "a417b74f6fdb4dedbd6bf3408d0dea69",
            "42c13d8f7c694c6599c0a2e10ca0765f",
            "0322aeeda2bd42c1b8ce348bd56424eb",
            "c0908ccc452b42e681765c37a139e878",
            "251219f28bd54de9a608686672dddf0d",
            "e982215023c24a3caf881dd3986cca86",
            "5398b51140574840979cfe9ae2640c96",
            "d6012c2d60024501a1bd8c529bf055e6",
            "d74fd39704b44cea8f012402e7449a80",
            "f5e5dd22e0b24a30a485b54dbdacf1cf",
            "7e61f641028148e988678a2ecbe24a21",
            "df8de4914b3f4c51b4e048f053a0e009",
            "868c8d0c5a4a4535a00dd833ad0dbb6f",
            "7c1ea655a2844e0e81c89529f95acb4c",
            "f4a51d5c122645a5a58acfbadb0cf752",
            "5bd4908665db4c8baac9d52a40a1c28e",
            "000f6133e191461c893cffdc6783a5f9",
            "b5fca62c132b4b9c9af64955480ac905",
            "7081369f016f46ec9ad16edcedd027b0",
            "8631f393c12e4ebaa57838a4f1c1efb0",
            "bc7e0e6c4b154e55875c6fddc0aac6f0",
            "46ff0481a7a94abb9cea91aaacd1ea29",
            "05fd99843ed746d1baf705e6c31881f6"
          ]
        },
        "id": "1C-THFy0tPik",
        "outputId": "5118abac-4cb3-47f3-d368-683d051edb47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab6a9ff832540bfae51a3f0dcfedfba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.14k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f53073dd81bf427188a9cfde75c18bff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.88k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc2d3eb4b1304b97bf336245736983ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset multi_nli/default to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2958b232a65d47d7950e040ddd583898",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a7388d890b2460c86be4cd32187f319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42c13d8f7c694c6599c0a2e10ca0765f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "868c8d0c5a4a4535a00dd833ad0dbb6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset multi_nli downloaded and prepared to /root/.cache/huggingface/datasets/multi_nli/default/0.0.0/591f72eb6263d1ab527561777936b199b714cda156d35716881158a2bd144f39. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "### Normal label-based losses (MLI\n",
        "# -- https://huggingface.co/datasets/multi_nli\n",
        "dataset_nli3 = load_dataset('multi_nli', split='train') # 383k examples\n",
        "\n",
        "# I think I should keep the text untokenize for the multi-task, maybe use the default collator from sbert\n",
        "dataset_nli3 = dataset_nli3.remove_columns(\n",
        "    column_names = ['promptID', 'pairID', 'premise_binary_parse', 'premise_parse','hypothesis_binary_parse', 'hypothesis_parse', 'genre']\n",
        ")\n",
        "\n",
        "dl_mli3 = DataLoader(dataset_nli3, batch_size=4, shuffle=True)\n",
        "\n",
        "\n",
        "# make a classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZRIJYI8eBBC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ClassifierMNLI3(nn.Module):\n",
        "    \"\"\"Bert Attention Layer that uses a dimension-reduced version of the query, so to reduce the dimension of the outputs\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size = 512,\n",
        "        do_subtract = True,\n",
        "        dropout = 0.1,\n",
        "        n_labels = 3\n",
        "    ):\n",
        "        \"\"\"Special type of Bert Self attention that reduces the dimension of the inputs by half\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.do_subtract = do_subtract\n",
        "        self.dropout_p = dropout\n",
        "        self.n_labels = n_labels\n",
        "        self.size_of_concatenated_inputs = self.hidden_size*2*2 + self.do_subtract*self.hidden_size*2\n",
        "\n",
        "        # final output\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Dropout(self.dropout_p),\n",
        "            nn.Linear(self.size_of_concatenated_inputs, self.n_labels)\n",
        "        )\n",
        "    def forward(self, input1, input2):\n",
        "        features_concat = torch.concat((\n",
        "            input1,\n",
        "            input2,\n",
        "            torch.sub(input1,input2)\n",
        "        ),axis=1)\n",
        "        return self.layer(features_concat)\n",
        "\n",
        "\n",
        "# Make classifier for MNLI labelled data\n",
        "classifier_mnli3 = ClassifierMNLI3(\n",
        "    hidden_size = anamod.config.hidden_size,\n",
        "    n_labels=3\n",
        ")\n",
        "classifier_mnli3.train()\n",
        "anamod.train()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(anamod.encoder.parameters()) +  list(anamod.pooler.parameters()) + list(classifier_mnli3.parameters()),\n",
        "    lr=0.0001\n",
        ")\n",
        "\n",
        "# make loss function (3 labels)\n",
        "loss_fn_nmli3 = nn.CrossEntropyLoss()\n",
        "weights_mnli_distil = 0.5\n",
        "weights_mnli_labels = (1-weights_mnli_distil)\n",
        "\n",
        "loss_fn_mnli3_distil = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "rBSnisaFT-3O",
        "outputId": "7fa6b430-8619-400b-cf57-20a3c5e76fd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6361832022666931\n",
            "0.5656223297119141\n",
            "0.3880550265312195\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1cec90a56f65>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# NEXT do distillation loss with teacher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfeature_teacher_nmli1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mfeature_teacher_nmli2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteacher_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_mnli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hypothesis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# MNLI distillation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'passage: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-e1b75b587f27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_text, prepend)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, batch_mnli in enumerate(dl_mli3):\n",
        "    optimizer.zero_grad()\n",
        "    # get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # mnli predictions n labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # mnli binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label']) * weights_nmli_labels\n",
        "    #loss_cls_nmli3.backward()\n",
        "\n",
        "    # NEXT do distillation loss with teacher\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%3 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "had3LEY4a5rT",
        "outputId": "6e2912df-f412-446d-f31a-f3a8710cbe98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:884: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3287630081176758\n",
            "1.1084638833999634\n",
            "1.1774473190307617\n",
            "1.0645709037780762\n",
            "1.091556429862976\n",
            "1.1649658679962158\n",
            "1.319928765296936\n",
            "1.1654601097106934\n",
            "0.9826673865318298\n",
            "1.1563453674316406\n",
            "1.0446501970291138\n",
            "1.1165382862091064\n",
            "1.1049705743789673\n",
            "0.9217707514762878\n",
            "1.14559006690979\n",
            "1.1429061889648438\n",
            "0.9149771928787231\n",
            "1.207316279411316\n",
            "1.1845396757125854\n",
            "1.2629420757293701\n",
            "0.9769338369369507\n",
            "1.0895546674728394\n",
            "1.0898280143737793\n",
            "1.1648684740066528\n",
            "0.9611557126045227\n",
            "1.044935703277588\n",
            "1.144046425819397\n",
            "1.099448561668396\n",
            "1.0884103775024414\n",
            "1.142393946647644\n",
            "1.0853071212768555\n",
            "1.1239224672317505\n",
            "1.0658488273620605\n",
            "1.1993112564086914\n",
            "0.9642707109451294\n",
            "1.182077407836914\n",
            "1.3221166133880615\n",
            "1.1279082298278809\n",
            "1.0723700523376465\n",
            "1.1399314403533936\n",
            "1.0013256072998047\n",
            "1.1049387454986572\n",
            "1.0147031545639038\n",
            "1.2314361333847046\n",
            "1.0651648044586182\n",
            "1.1327135562896729\n",
            "0.9887092709541321\n",
            "1.0250582695007324\n",
            "1.1199613809585571\n",
            "1.094027042388916\n",
            "1.091330885887146\n",
            "1.098750114440918\n",
            "1.1193275451660156\n",
            "1.1657143831253052\n",
            "1.0800719261169434\n",
            "1.152091383934021\n",
            "1.1550073623657227\n",
            "1.0005279779434204\n",
            "1.063902497291565\n",
            "1.0364967584609985\n",
            "1.0193161964416504\n",
            "1.1669244766235352\n",
            "1.055404543876648\n",
            "1.2059553861618042\n",
            "1.1156867742538452\n",
            "1.1356735229492188\n",
            "1.1261953115463257\n",
            "1.0520744323730469\n",
            "1.0741896629333496\n",
            "1.0739905834197998\n",
            "1.1333951950073242\n",
            "1.0113921165466309\n",
            "1.1244165897369385\n",
            "1.1339558362960815\n",
            "1.125321626663208\n",
            "1.0819061994552612\n",
            "1.1043788194656372\n",
            "1.108479380607605\n",
            "1.148271083831787\n",
            "1.0951212644577026\n",
            "1.1449416875839233\n",
            "1.0795189142227173\n",
            "1.1403652429580688\n",
            "1.086578130722046\n",
            "1.0184922218322754\n",
            "1.1535804271697998\n",
            "1.0355476140975952\n",
            "1.120854377746582\n"
          ]
        }
      ],
      "source": [
        "# Combine the teacher training with classification\n",
        "optimizer = AdamW(list(anamod.parameters()) + list(classifier_mnli3.parameters()), lr = 0.00001)\n",
        "# (model.parameters(), lr=learning_rate)\n",
        "\n",
        "# MLM objective\n",
        "teacher_mlm.eval()\n",
        "distillation_temperature = 1.0\n",
        "for i,(batch_mlm, batch_mnli) in enumerate(zip(dl_mlm, dl_mli3)):\n",
        "    optimizer.zero_grad()\n",
        "    # do inference using anathem model\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    outputs = anamod.forward(\n",
        "        input_ids = batch['input_ids'],\n",
        "        attention_mask = batch['attention_mask'],\n",
        "        attention_mask_l2 = batch['attention_mask_l2'],\n",
        "        attention_mask_l3 = batch['attention_mask_l3'],\n",
        "        excess_cls_ids = batch['excess_cls_ids'],\n",
        "        excess_cls_ids_l2 = batch['excess_cls_ids_l2'],\n",
        "        excess_cls_ids_l3 = batch ['excess_cls_ids_l3']\n",
        "    )\n",
        "\n",
        "    # hidden_states, out_pooled_vector, out_mlm, attention, extended_attention_masks\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # mlm teacher outputs\n",
        "        outputs_teacher_mlm = teacher_mlm(\n",
        "            input_ids = batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "        # to do this, I'd need to have the original text, and NOT pre-tokenized text\n",
        "        #teacher_emb(input_text=batch['premise'], prepend = 'passage: ')\n",
        "\n",
        "    # FOOFU\n",
        "    assert outputs[2].size() == outputs_teacher_mlm.logits.size()\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    #loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_mlm_distil = loss_fn_mlm_distil(\n",
        "            F.log_softmax(outputs[2] / distillation_temperature, dim=-1),\n",
        "            F.softmax(outputs_teacher_mlm.logits / distillation_temperature, dim=-1)\n",
        "        ) * (distillation_temperature ** 2) * weights_mlm_distil\n",
        "    #loss_mlm_distil.backward()\n",
        "    loss_mlm_labels = loss_fn_mlm_labels(\n",
        "        outputs[2].view(-1, anamod.config.vocab_size),\n",
        "        batch['labels'].view(-1)\n",
        "    ) * weights_mlm_labels\n",
        "\n",
        "    # loss on paragraph embedding\n",
        "\n",
        "    # BACKPROP MLM label loss and distilloss\n",
        "    (loss_mlm_distil+loss_mlm_labels).backward()\n",
        "    # Return weighted student loss\n",
        "    #loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
        "    #return (loss, outputs_student) if return_outputs else loss\n",
        "\n",
        "    # NLI task: get tokens\n",
        "    tokens_mnli_1 = anamod.tokenizer(batch_mnli['premise'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "    tokens_mnli_2 = anamod.tokenizer(batch_mnli['hypothesis'],pad_to_multiple_of=4, add_special_tokens = True, return_tensors='pt', padding='longest')\n",
        "\n",
        "    # student embeddings\n",
        "    out_student_mnli1 = anamod.forward(\n",
        "            input_ids = tokens_mnli_1['input_ids'],\n",
        "            attention_mask = tokens_mnli_1['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_1['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_1['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_1['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_1['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_1 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    out_student_mnli2 = anamod.forward(\n",
        "            input_ids = tokens_mnli_2['input_ids'],\n",
        "            attention_mask = tokens_mnli_2['attention_mask'],\n",
        "            attention_mask_l2 = tokens_mnli_2['attention_mask_l2'],\n",
        "            attention_mask_l3 = tokens_mnli_2['attention_mask_l3'],\n",
        "            excess_cls_ids = tokens_mnli_2['excess_cls_ids'],\n",
        "            excess_cls_ids_l2 = tokens_mnli_2['excess_cls_ids_l2'],\n",
        "            excess_cls_ids_l3 = tokens_mnli_2 ['excess_cls_ids_l3']\n",
        "    )\n",
        "    # raw sentence-vectors from student\n",
        "    feature_student_mnli1, feature_student_mnli2 = out_student_mnli1[1], out_student_mnli2[1]\n",
        "    # labels\n",
        "    pred_mnli3 = classifier_mnli3(feature_student_mnli1, feature_student_mnli2)\n",
        "    # binary loss\n",
        "    loss_cls_nmli3 = loss_fn_nmli3(pred_mnli3, batch_mnli['label'])\n",
        "    #loss_cls_nmli3.backward()\n",
        "    feature_teacher_nmli1 = teacher_emb(input_text=batch_mnli['premise'], prepend = 'passage: ')\n",
        "    feature_teacher_nmli2 = teacher_emb(input_text=batch_mnli['hypothesis'], prepend = 'passage: ')\n",
        "    # MNLI distillation loss\n",
        "    loss_mnli_distil = (\n",
        "        loss_fn_mnli3_distil(feature_student_mnli1, feature_teacher_nmli1) + loss_fn_mnli3_distil(feature_student_mnli2, feature_teacher_nmli2)\n",
        "    )*weights_nmli_distil\n",
        "    # backprop\n",
        "    (loss_mnli_distil + loss_cls_nmli3).backward()\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%4 ==0:\n",
        "        print(loss_cls_nmli3.detach().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "NWWBkB_gqEkE",
        "outputId": "6a69aabe-43c8-42bc-dd5f-f15a8840b73d"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8c7bf2d1f796>\"\u001b[0;36m, line \u001b[0;32m319\u001b[0m\n\u001b[0;31m    self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "class TrainerMultiTask:\n",
        "    \"\"\"Adapted from the uklab/sentence-transformers .fit() function\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            do_reload = True,\n",
        "            epochs_total_lifetime = 5,\n",
        "            scheduler: str = 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            output_path: str = None,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = False,\n",
        "            checkpoint_path: str = 'checkpoint.pt',\n",
        "            checkpoint_path_optimizer: str = 'checkpoint_optimizer.pt',\n",
        "            checkpoint_path_scheduler: str = 'checkpoint_scheduler.pt',\n",
        "            checkpoint_path_trainer_state: str = 'checkpoint_trainer_state.json',\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 0,\n",
        "            do_minimize_global_objective: Int = 1\n",
        "        ):\n",
        "            self.epochs_global = -1 # track the total number of epochs\n",
        "            self.epochs_total_lifetime = epochs_total_lifetime # total number of epochs over lifetime\n",
        "            self.global_step = 0 # track the toatl number of steps\n",
        "            self.do_minimize = do_minimize_global_objective\n",
        "            self.best_score = 9999999 if self.do_minimize else -9999999\n",
        "            self.output_path = output_path\n",
        "            self.checkpoint_path = checkpoint_path\n",
        "            self.checkpoint_path_optimizer = checkpoint_path_optimizer\n",
        "            self.checkpoint_path_scheduler = checkpoint_path_scheduler\n",
        "            self.checkpoint_path_trainer_state = checkpoint_path_trainer_state\n",
        "            self.scheduler_state_dict = None\n",
        "            self.optimizer_state_dict = None\n",
        "            self.trainer_state = None\n",
        "            self.loss_models_states = None\n",
        "            if do_reload:\n",
        "                print('attempting to reload cached model, optimizer, scheduler, and saved trainer sate')\n",
        "                model_state, loss_models_states = self.load_saved_model(self.checkpoint_path)\n",
        "                self.model_state = model_state\n",
        "                self.loss_models_states = loss_models_states\n",
        "                self.scheduler_state_dicts = self.load_saved_scheduler(self.checkpoint_path_scheduler)\n",
        "                self.optimizer_state_dicts = self.load_saved_optimizer(self.checkpoint_path_optimizer)\n",
        "                self.trainer_state = self.load_saved_trainer_state(self.checkpoint_path_trainer_state)\n",
        "\n",
        "    def fit(self,\n",
        "            train_objectives: Iterable[Tuple[DataLoader, nn.Module]],\n",
        "            model=None,\n",
        "            weights_train_objectives:List = None,\n",
        "            teachers: List = None,\n",
        "            evaluator: SentenceEvaluator = None,\n",
        "            epochs: int = 1,\n",
        "            epochs_total_lifetime = None,\n",
        "            steps_per_epoch = None,\n",
        "            scheduler: str = None, # 'WarmupLinear',\n",
        "            warmup_steps: int = 10000,\n",
        "            optimizer_class: Type[Optimizer] = torch.optim.AdamW,\n",
        "            optimizer_params : Dict[str, object]= {'lr': 2e-5},\n",
        "            weight_decay: float = 0.01,\n",
        "            evaluation_steps: int = 0,\n",
        "            save_best_model: bool = True,\n",
        "            max_grad_norm: float = 2.0,\n",
        "            use_amp: bool = False,\n",
        "            callback: Callable[[float, int, int], None] = None,\n",
        "            show_progress_bar: bool = True,\n",
        "            checkpoint_path = None,\n",
        "            checkpoint_path_optimizer= None,\n",
        "            checkpoint_path_scheduler= None,\n",
        "            checkpoint_path_trainer_config= None,\n",
        "            checkpoint_save_steps: int = 500,\n",
        "            checkpoint_save_total_limit: int = 2\n",
        "            ):\n",
        "        \"\"\"\n",
        "        Train the model with the given training objective\n",
        "        Each training objective is sampled in turn for one batch.\n",
        "        We sample only as many batches from each objective as there are in the smallest one\n",
        "        to make sure of equal training with each dataset.\n",
        "\n",
        "        :param train_objectives: Tuples of (DataLoader, LossFunction). Pass more than one for multi-task learning\n",
        "        :param evaluator: An evaluator (sentence_transformers.evaluation) evaluates the model performance during training on held-out dev data. It is used to determine the best model that is saved to disc.\n",
        "        :param epochs: Number of epochs for training\n",
        "        :param steps_per_epoch: Number of training steps per epoch. If set to None (default), one epoch is equal the DataLoader size from train_objectives.\n",
        "        :param scheduler: Learning rate scheduler. Available schedulers: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        :param warmup_steps: Behavior depends on the scheduler. For WarmupLinear (default), the learning rate is increased from o up to the maximal learning rate. After these many training steps, the learning rate is decreased linearly back to zero.\n",
        "        :param optimizer_class: Optimizer\n",
        "        :param optimizer_params: Optimizer parameters\n",
        "        :param weight_decay: Weight decay for model parameters\n",
        "        :param evaluation_steps: If > 0, evaluate the model using evaluator after each number of training steps\n",
        "        :param output_path: Storage path for the model and evaluation files\n",
        "        :param save_best_model: If true, the best model (according to evaluator) is stored at output_path\n",
        "        :param max_grad_norm: Used for gradient normalization.\n",
        "        :param use_amp: Use Automatic Mixed Precision (AMP). Only for Pytorch >= 1.6.0\n",
        "        :param callback: Callback function that is invoked after each evaluation.\n",
        "                It must accept the following three parameters in this order:\n",
        "                `score`, `epoch`, `steps`\n",
        "        :param show_progress_bar: If True, output a tqdm progress bar\n",
        "        :param checkpoint_path: Folder to save checkpoints during training\n",
        "        :param checkpoint_save_steps: Will save a checkpoint after so many steps\n",
        "        :param checkpoint_save_total_limit: Total number of checkpoints to store\n",
        "        \"\"\"\n",
        "        if self.model_state is not None:\n",
        "            print('reloading saved model state into model')\n",
        "            model.load_state_dict(self.model_state)\n",
        "            self.model = model\n",
        "\n",
        "        # paths (optional update)\n",
        "        self.checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        self.checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        self.checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        self.checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "        self._target_device = model.device\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.weight_decay = weight_decay\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.optimizer_params = optimizer_params\n",
        "        self.evaluation_steps = evaluation_steps\n",
        "\n",
        "        if use_amp:\n",
        "            from torch.cuda.amp import autocast\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        #self.to(self._target_device)\n",
        "\n",
        "        dataloaders = [dataloader for dataloader, _ in train_objectives]\n",
        "\n",
        "        # Use smart batching\n",
        "        if len(collators)==0 or collators is None:\n",
        "            print('using default batch collators')\n",
        "        for dli, dataloader in enumerate(dataloaders):\n",
        "            if dataloader.collate_fn is None:\n",
        "                print('using default batch collators for dataloader %d' % dli)\n",
        "                dataloader.collate_fn = self.smart_batching_collate\n",
        "\n",
        "        loss_models = [loss for _, loss in train_objectives]\n",
        "        for midx, loss_model in enumerate(loss_models):\n",
        "            if self.loss_models_states is not None:\n",
        "                # reload each loss_model.classifier's saved states\n",
        "                if hassattr(loss_model, 'classifier'):\n",
        "                    loss_model.classifier.load_state_dict(self.loss_models_states[midx])\n",
        "            loss_model.to(self._target_device)\n",
        "\n",
        "        if steps_per_epoch is None or steps_per_epoch == 0:\n",
        "            steps_per_epoch = min([len(dataloader) for dataloader in dataloaders])\n",
        "\n",
        "        if epochs_total_lifetime is None:\n",
        "            epochs_total_lifetime = self.epochs_total_lifetime\n",
        "        num_train_steps = int(steps_per_epoch * epochs_total_lifetime)\n",
        "\n",
        "        # Prepare optimizers\n",
        "        #optimizers = []\n",
        "        #schedulers = []\n",
        "        #for model_idx, loss_model in enumerate(loss_models):\n",
        "        #    param_optimizer = list(loss_model.named_parameters())#\n",
        "        #    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        #    optimizer_grouped_parameters = [\n",
        "        #        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "        #        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        #    ]\n",
        "        #    optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        #    scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        #    if self.optimizer_state_dicts is not None:\n",
        "        #        # reload optimizer states\n",
        "        #        optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "        #    if self.scheduler_state_dicts is not None:\n",
        "        #        # relead scheduler states\n",
        "        #        scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "        #    optimizers.append(optimizer)\n",
        "        #    schedulers.append(scheduler_obj)\n",
        "\n",
        "        # from: https://stackoverflow.com/questions/46377599/when-to-use-individual-optimizers-in-pytorch\n",
        "        optimizer_parameters = set()\n",
        "        for model_idx, loss_model in enumerate(loss_models):\n",
        "            optimizer_parameters |= loss_model.named_parameters()\n",
        "\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in optimizer_parameters if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in optimizer_parameters if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = optimizer_class(optimizer_grouped_parameters, **optimizer_params)\n",
        "        scheduler_obj = self._get_scheduler(optimizer, scheduler=scheduler, warmup_steps=warmup_steps, t_total=num_train_steps)\n",
        "        if self.optimizer_state_dicts is not None:\n",
        "            # reload optimizer states\n",
        "            #optimizer.load_state_dict(self.optimizer_state_dicts[model_idx])\n",
        "            optimizer.load_state_dict(self.optimizer_state_dicts)\n",
        "        if self.scheduler_state_dicts is not None:\n",
        "            # relead scheduler states\n",
        "            #scheduler_obj.load_state_dict(self.scheduler_state_dicts[model_idx])\n",
        "            scheduler_obj.load_state_dict(self.scheduler_state_dicts)\n",
        "\n",
        "        global_step = self.global_step\n",
        "        data_iterators = [iter(dataloader) for dataloader in dataloaders]\n",
        "\n",
        "        num_train_objectives = len(train_objectives)\n",
        "\n",
        "        for epoch in trange(epochs, desc=\"Epoch\", disable=not show_progress_bar):\n",
        "            self.epochs_global += epoch\n",
        "            training_steps = 0\n",
        "\n",
        "            for loss_model in loss_models:\n",
        "                loss_model.zero_grad()\n",
        "                loss_model.train()\n",
        "\n",
        "            for _ in trange(steps_per_epoch, desc=\"Iteration\", smoothing=0.05, disable=not show_progress_bar):\n",
        "\n",
        "                # loop through multiple tasks\n",
        "                for train_idx in range(num_train_objectives):\n",
        "                    loss_model = loss_models[train_idx]\n",
        "                    loss_weight = weights_train_objectives[train_idx]\n",
        "                    teacher = teachers[train_idx]\n",
        "                    optimizer = optimizers[train_idx]\n",
        "                    scheduler = schedulers[train_idx]\n",
        "                    data_iterator = data_iterators[train_idx]\n",
        "\n",
        "                    try:\n",
        "                        data = next(data_iterator)\n",
        "                    except StopIteration:\n",
        "                        data_iterator = iter(dataloaders[train_idx])\n",
        "                        data_iterators[train_idx] = data_iterator\n",
        "                        data = next(data_iterator)\n",
        "\n",
        "                    features, labels = data\n",
        "                    features = list(map(lambda batch: batch_to_device(batch, self._target_device), features))\n",
        "                    if labels is not None:\n",
        "                        labels = labels.to(self._target_device)\n",
        "\n",
        "                    loss_value = loss_model(features, labels, teacher=teacher)\n",
        "                    loss_value *= loss_weight\n",
        "                    loss_value.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad_norm)\n",
        "                optimizers.step()\n",
        "                optimizers.zero_grad()\n",
        "                schedulers.step()\n",
        "\n",
        "                # TODO: integrate amp: https://discuss.pytorch.org/t/ddp-amp-gradient-accumulation-calling-optimizer-step-leads-to-nan-loss/162624\n",
        "                training_steps += 1\n",
        "                global_step += 1\n",
        "                self.global_step = global_step\n",
        "\n",
        "                if evaluation_steps > 0 and training_steps % evaluation_steps == 0:\n",
        "                    self._eval_during_training(evaluator, output_path, save_best_model, epoch, training_steps, callback)\n",
        "\n",
        "                    for loss_model in loss_models:\n",
        "                        loss_model.zero_grad()\n",
        "                        loss_model.train()\n",
        "\n",
        "                if self.checkpoint_path is not None and checkpoint_save_steps is not None and checkpoint_save_steps > 0 and global_step % checkpoint_save_steps == 0:\n",
        "                    self._save_checkpoint(\n",
        "                        model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "                    )\n",
        "\n",
        "            self._eval_during_training(evaluator, output_path, save_best_model, epoch, -1, callback)\n",
        "\n",
        "        #if evaluator is None and output_path is not None:   #No evaluator, but output path: save final model version\n",
        "        #    self.save(output_path)\n",
        "\n",
        "        if checkpoint_path is not None:\n",
        "            self._save_checkpoint(\n",
        "                model, optimizers, schedulers, loss_models, checkpoint_save_total_limit, global_step\n",
        "            )\n",
        "\n",
        "    def evaluate(self, evaluator: SentenceEvaluator, output_path: str = None):\n",
        "        \"\"\"\n",
        "        Evaluate the model\n",
        "\n",
        "        :param evaluator:\n",
        "            the evaluator\n",
        "        :param output_path:\n",
        "            the evaluator can write the results to this path\n",
        "        \"\"\"\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "        return evaluator(self, output_path)\n",
        "\n",
        "    def _eval_during_training(self, evaluator, output_path, save_best_model, epoch, steps, callback):\n",
        "        \"\"\"Runs evaluation during the training\"\"\"\n",
        "        eval_path = output_path\n",
        "        if output_path is not None:\n",
        "            os.makedirs(output_path, exist_ok=True)\n",
        "            eval_path = os.path.join(output_path, \"eval\")\n",
        "            os.makedirs(eval_path, exist_ok=True)\n",
        "\n",
        "        if evaluator is not None:\n",
        "            score = evaluator(self, output_path=eval_path, epoch=epoch, steps=steps)\n",
        "            if callback is not None:\n",
        "                callback(score, epoch, steps)\n",
        "            if score > self.best_score:\n",
        "                self.best_score = score\n",
        "                if save_best_model:\n",
        "                    self.save(output_path)\n",
        "\n",
        "    def _save_checkpoint(\n",
        "        self,\n",
        "        model,\n",
        "        optimizers,\n",
        "        schedulers,\n",
        "        loss_models,\n",
        "        checkpoint_save_total_limit,\n",
        "        step,\n",
        "        checkpoint_path = None,\n",
        "        checkpoint_path_optimizer = None,\n",
        "        checkpoint_path_scheduler = None,\n",
        "        checkpoint_path_trainer_state =None\n",
        "    ):\n",
        "        # Store new checkpoint\n",
        "        checkpoint_path = checkpoint_path if checkpoint_path is not None else self.checkpoint_path\n",
        "        checkpoint_path_optimizer = checkpoint_path_optimizer if checkpoint_path_optimizer is not None else self.checkpoint_path_optimizer\n",
        "        checkpoint_path_scheduler = checkpoint_path_scheduler if checkpoint_path_scheduler is not None else self.checkpoint_path_scheduler\n",
        "        checkpoint_path_trainer_state = checkpoint_path_trainer_state if checkpoint_path_trainer_state is not None else self.checkpoint_path_trainer_state\n",
        "\n",
        "        # model states\n",
        "        self.model_state = model.state_dict()\n",
        "        self.loss_models_states = [self._grab_loss_states(loss_model) for loss_models]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'model_state_dict':self.model_state,\n",
        "            'loss_models_state_dicts':self.loss_models_states,\n",
        "        }, \"%s-%08g\" % (checkpoint_path, step))\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer_state_dicts = optimizers.state_dict() #[opt.state_dict() for opt in optimizers],\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'optimizer_state_dicts':self.optimizer_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_optimizer, step))\n",
        "\n",
        "        # scheduler\n",
        "        self.scheduler_state_dicts = schedulers.state_dict() #[scheduler.state_dict() for scheduler in schedulers]\n",
        "        torch.save({\n",
        "            'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "            'scheduler_state_dicts':self.scheduler_state_dicts,\n",
        "        }, \"%s-%08g\" % (checkpoint_path_scheduler, step))\n",
        "\n",
        "        # trainer info\n",
        "        with open(checkpoint_path_trainer_state, 'w') as jcon:\n",
        "            trainer_objs_to_save = {\n",
        "                'epochs_global':self.epochs_global, 'global_step':self.global_step, 'step':step,\n",
        "                'max_grad_norm':self.max_grad_norm,\n",
        "                'weight_decay':self.weight_decay,\n",
        "                'warmup_steps':self.warmup_steps,\n",
        "                'optimizer_params':self.optimizer_params,\n",
        "                'evaluation_steps':self.evaluation_steps,\n",
        "                'checkpoint_path_optimizer': \"%s-%08g\" % (checkpoint_path_optimizer, step),\n",
        "                'checkpoint_path_scheduler': \"%s-%08g\" % (checkpoint_path_scheduler, step),\n",
        "            }\n",
        "            json.dump(trainer_objs_to_save, jcon)\n",
        "\n",
        "        # Delete old checkpoints\n",
        "        if checkpoint_save_total_limit is not None and checkpoint_save_total_limit > 0:\n",
        "            old_checkpoints = []\n",
        "            dir_to_checkpoints = \"/\".join(checkpoint_path.split('/')[:-1])\n",
        "            for f in os.listdir(dir_to_checkpoints):\n",
        "                if bool(re.search('(\\-[0-9]+$',f)) & (checkpoint_path in f):\n",
        "                    # get step of saved checkpoint\n",
        "                    old_pt_step = int(re.search('(?<=\\-)[0-9]+$',f).group())\n",
        "                    old_checkpoints.append({\n",
        "                        'step': old_pt_step, 'path': os.path.join(dir_to_checkpoints, f)\n",
        "                    })\n",
        "\n",
        "            if len(old_checkpoints) > checkpoint_save_total_limit:\n",
        "                old_checkpoints = sorted(old_checkpoints, key=lambda x: x['step'])\n",
        "                oldest_step = old_checkpoints[0]['step']\n",
        "                for old_checkpoint in old_checkpoints:\n",
        "                    if old_checkpoint['step']==oldest_step:\n",
        "                        print('deleting old checkpoint: %s' % old_checkpoint['path'])\n",
        "                        shutil.rmtree(old_checkpoint['path'])\n",
        "\n",
        "    def _grab_loss_states(loss_model):\n",
        "        \"\"\"Gets the loss_model.state_dict() for a model embedded in a loss function\"\"\"\n",
        "        return loss_model.classifier.state_dict()\n",
        "\n",
        "    def load_saved_model(checkpoint_path=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path = self.checkpoint_path if checkpoint_path is None else checkpoint_path\n",
        "        saved_dict = torch.load(checkpoint_path)\n",
        "        return saved_dict['model_state_dict'], saved_dict['loss_models_state_dicts']\n",
        "\n",
        "    def load_saved_scheduler(checkpoint_path_scheduler=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_scheduler = self.checkpoint_path_scheduler if checkpoint_path_scheduler is None else checkpoint_path_scheduler\n",
        "        saved_dict = torch.load(checkpoint_path_scheduler)\n",
        "        return saved_dict['scheduler_state_dicts']\n",
        "\n",
        "    def load_saved_optimizer(checkpoint_path_optimizer=None):\n",
        "        \"\"\"reload saved model\"\"\"\n",
        "        checkpoint_path_optimizer = self.checkpoint_path_optimizer if checkpoint_path_optimizer is None else checkpoint_path_optimizer\n",
        "        saved_dict = torch.load(checkpoint_path_optimizer)\n",
        "        return saved_dict['optimizer_state_dicts']\n",
        "\n",
        "    def load_saved_trainer_state(checkpoint_path_trainer_state):\n",
        "        checkpoint_path_trainer_state = self.checkpoint_path_trainer_state if checkpoint_path_trainer_state is None else checkpoint_path_trainer_state\n",
        "        with open(checkpoint_path_trainer_state, 'r') as jcon:\n",
        "            trainer_state = json.load(jcon)\n",
        "        self.epochs_global = trainer_state['epochs_global']\n",
        "        self.global_step = trainer_state['global_step']\n",
        "        self.step = trainer_state['step']\n",
        "        self.max_grad_norm = trainer_state['max_grad_norm']\n",
        "        self.weight_decay = trainer_state['weight_decay']\n",
        "        self.warmup_steps = trainer_state['warmup_steps']\n",
        "        self.optimizer_params = trainer_state['optimizer_params']\n",
        "        self.evaluation_steps = trainer_state['evaluation_steps']\n",
        "\n",
        "    def _load_auto_model(self, model_name_or_path):\n",
        "        \"\"\"\n",
        "        Creates a simple Transformer + Mean Pooling model and returns the modules\n",
        "        \"\"\"\n",
        "        logger.warning(\"No sentence-transformers model found with name {}. Creating a new one with MEAN pooling.\".format(model_name_or_path))\n",
        "        transformer_model = Transformer(model_name_or_path)\n",
        "        pooling_model = Pooling(transformer_model.get_word_embedding_dimension(), 'mean')\n",
        "        return [transformer_model, pooling_model]\n",
        "\n",
        "    def _load_sbert_model(self, model_path):\n",
        "        \"\"\"\n",
        "        Loads a full sentence-transformers model\n",
        "        \"\"\"\n",
        "        # Check if the config_sentence_transformers.json file exists (exists since v2 of the framework)\n",
        "        config_sentence_transformers_json_path = os.path.join(model_path, 'config_sentence_transformers.json')\n",
        "        if os.path.exists(config_sentence_transformers_json_path):\n",
        "            with open(config_sentence_transformers_json_path) as fIn:\n",
        "                self._model_config = json.load(fIn)\n",
        "\n",
        "            if '__version__' in self._model_config and 'sentence_transformers' in self._model_config['__version__'] and self._model_config['__version__']['sentence_transformers'] > __version__:\n",
        "                logger.warning(\"You try to use a model that was created with version {}, however, your version is {}. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\\n\\n\\n\".format(self._model_config['__version__']['sentence_transformers'], __version__))\n",
        "\n",
        "        # Check if a readme exists\n",
        "        model_card_path = os.path.join(model_path, 'README.md')\n",
        "        if os.path.exists(model_card_path):\n",
        "            try:\n",
        "                with open(model_card_path, encoding='utf8') as fIn:\n",
        "                    self._model_card_text = fIn.read()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Load the modules of sentence transformer\n",
        "        modules_json_path = os.path.join(model_path, 'modules.json')\n",
        "        with open(modules_json_path) as fIn:\n",
        "            modules_config = json.load(fIn)\n",
        "\n",
        "        modules = OrderedDict()\n",
        "        for module_config in modules_config:\n",
        "            module_class = import_from_string(module_config['type'])\n",
        "            module = module_class.load(os.path.join(model_path, module_config['path']))\n",
        "            modules[module_config['name']] = module\n",
        "\n",
        "        return modules\n",
        "\n",
        "    @staticmethod\n",
        "    def load(input_path):\n",
        "        return SentenceTransformer(input_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_scheduler(optimizer, scheduler: str, warmup_steps: int, t_total: int):\n",
        "        \"\"\"\n",
        "        Returns the correct learning rate scheduler. Available scheduler: constantlr, warmupconstant, warmuplinear, warmupcosine, warmupcosinewithhardrestarts\n",
        "        \"\"\"\n",
        "        scheduler = scheduler.lower()\n",
        "        if scheduler == 'constantlr':\n",
        "            return transformers.get_constant_schedule(optimizer)\n",
        "        elif scheduler == 'warmupconstant':\n",
        "            return transformers.get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
        "        elif scheduler == 'warmuplinear':\n",
        "            return transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosine':\n",
        "            return transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        elif scheduler == 'warmupcosinewithhardrestarts':\n",
        "            return transformers.get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown scheduler {}\".format(scheduler))\n",
        "\n",
        "    @property\n",
        "    def device(self) -> device:\n",
        "        \"\"\"\n",
        "        Get torch.device from module, assuming that the whole module has one device.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return next(self.parameters()).device\n",
        "        except StopIteration:\n",
        "            # For nn.DataParallel compatibility in PyTorch 1.5\n",
        "\n",
        "            def find_tensor_attributes(module: nn.Module) -> List[Tuple[str, Tensor]]:\n",
        "                tuples = [(k, v) for k, v in module.__dict__.items() if torch.is_tensor(v)]\n",
        "                return tuples\n",
        "\n",
        "            gen = self._named_members(get_members_fn=find_tensor_attributes)\n",
        "            first_tuple = next(gen)\n",
        "            return first_tuple[1].device\n",
        "\n",
        "    @property\n",
        "    def tokenizer(self):\n",
        "        \"\"\"\n",
        "        Property to get the tokenizer that is used by this model\n",
        "        \"\"\"\n",
        "        return self.model.tokenizer\n",
        "\n",
        "    #@tokenizer.setter\n",
        "    #def tokenizer(self, value):\n",
        "    #    self._first_module().tokenizer = value\n",
        "\n",
        "    @property\n",
        "    def max_seq_length(self):\n",
        "        \"\"\"\n",
        "        Property to get the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        return self.model._first_module().max_seq_length\n",
        "\n",
        "    @max_seq_length.setter\n",
        "    def max_seq_length(self, value):\n",
        "        \"\"\"\n",
        "        Property to set the maximal input sequence length for the model. Longer inputs will be truncated.\n",
        "        \"\"\"\n",
        "        self.model._first_module().max_seq_length = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2hwROspo0uI"
      },
      "source": [
        "### Load a Standard Dataset for MLM task\n",
        "\n",
        "Also need to grab datasets here: https://arxiv.org/pdf/1908.08962.pdf\n",
        "\n",
        "```\n",
        "    The Pile dataset looks good: https://pile.eleuther.ai/\n",
        "    https://arxiv.org/abs/2101.00027\n",
        "    PubMed Central, ArXiv, GitHub, the FreeLaw Project, Stack Exchange, the US\n",
        "    Patent and Trademark Office, PubMed, Ubuntu IRC, HackerNews, YouTube, PhilPapers, and NIH ExPorter.\n",
        "    We also introduce OpenWebText2 and\n",
        "    BookCorpus2, which are extensions of the original\n",
        "    OpenWebText (Gokaslan and Cohen, 2019) and\n",
        "    BookCorpus (Zhu et al., 2015; Kobayashi, 2018)\n",
        "    datasets, respectively.\n",
        "    In addition, we incorporate several existing highquality datasets: Books3 (Presser, 2020), Project Gutenberg (PG-19) (Rae et al., 2019), OpenSubtitles (Tiedemann, 2016), English Wikipedia, DM Mathematics (Saxton et al., 2019), EuroParl\n",
        "    (Koehn, 2005), and\n",
        "\n",
        "    ABout the law:\n",
        "    and other metadata, we focused specifically on\n",
        "    court opinions due to an abundance of full-text\n",
        "    entries. This data is entirely within the public domain.\n",
        "\n",
        "```\n",
        "\n",
        "Scientific Papers: You can use the scientific_papers dataset, which includes a large collection of scientific papers from various domains. It covers research articles from fields such as computer science, physics, biology, and more.\n",
        "\n",
        "Patents: The patent_citations dataset contains patent text data along with citation information, making it suitable for training language models with a focus on technical and scientific domains.\n",
        "\n",
        "ArXiv: The arxiv dataset includes research papers from the arXiv repository, covering a wide range of scientific disciplines. It can be used to enhance the exposure of your model to academic literature.\n",
        "\n",
        "PubMed: The pubmed dataset consists of abstracts from biomedical research articles indexed in PubMed. It is a valuable resource if you want to incorporate biomedical and life sciences content into your MLM pretraining.\n",
        "\n",
        "joelito/Multi_Legal_Pile - use subset `en_all` to access EU-courts, and other datasets\n",
        "\n",
        "\n",
        "Looks like streaming data is available:\n",
        "https://huggingface.co/learn/nlp-course/chapter5/4?fw=pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-boy1-ZoqWI",
        "outputId": "75d22bfc-67f0-4404-a102-c7aaceb33eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, safetensors, zstandard, xxhash, rank_bm25, dill, multiprocess, huggingface-hub, transformers, datasets\n",
            "Successfully installed datasets-2.14.0 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 rank_bm25-0.2.2 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0 xxhash-3.2.0 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "### Load a standard dataset\n",
        "%pip install transformers datasets zstandard rank_bm25\n",
        "# need the zstandard to use the streaming data function from huggingface datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KGmDMqKlxC4"
      },
      "outputs": [],
      "source": [
        "import lzma\n",
        "from datasets import load_dataset\n",
        "from itertools import islice\n",
        "from datasets import interleave_datasets # for interweaving streaming datasets\n",
        "#from transformers import BertTokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "7_vZTlRD7QML",
        "outputId": "235f7dfb-c226-4df4-a23b-c580414e9fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:17: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
            "<>:17: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
            "<ipython-input-3-59928d84ac75>:17: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
            "  (\"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\",None,12.07, 34500)# 34.5.k\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-59928d84ac75>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;34m'Cohere/wikipedia-22-12'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14.40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# see also: conceptofmind/pile_wikipedia_en\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m      \u001b[0;31m#(\"the_pile_books3\", None, 12.07), # alternative? bookcorpusopen (no); Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m      \u001b[0;34m(\u001b[0m\u001b[0;34m\"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# 34.5.k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;34m\"the_pile_openwebtext2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;34m\"macrocosm/arxiv_abstracts\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# just the abstracts k: abstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ],
      "source": [
        "#import zstandard maybe not necessary\n",
        "# Notes on Pile\n",
        "# the largest ones are tarred and cannoted be loaded (like openwebtext2), but some are already available on huggingface anyway\n",
        "\"\"\"dataset4 = load_dataset(\"the_pile_openwebtext2\",split='train',streaming=True)\"\"\" # load like THIS!!\n",
        "# consider using book2: RyokoExtra/books2-1.2-lite\n",
        "# 'the_pile_books3',\n",
        "# 'the_pile_stack_exchange'\n",
        "# 'the_pile_openwebtext2'\n",
        "# 'Cohere/wikipedia-22-12'\n",
        "# 'tiiuae/falcon-refinedweb' # see also google's C4\n",
        "# see more under conceptofmind/pile\n",
        "\n",
        "# base_url = \"https://the-eye.eu/public/AI/pile/\"\n",
        "data_files = [\n",
        "     (\"tiiuae/falcon-refinedweb\",None, 18.11),# CC\n",
        "     ('Cohere/wikipedia-22-12','en', 14.40), # see also: conceptofmind/pile_wikipedia_en\n",
        "     #(\"the_pile_books3\", None, 12.07), # alternative? bookcorpusopen (no); Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\n",
        "     (\"Multi-Domain-Expert-Layers/the_pile_books3_packed_128k\",None,12.07, 34500)# 34.5.k\n",
        "     (\"the_pile_openwebtext2\",None, 10.01),\n",
        "     (\"macrocosm/arxiv_abstracts\",None, 3.75), # just the abstracts k: abstract\n",
        "     (\"ccdv/pubmed-summarization\",None, 3.75),# PMC # I should reduce this, use wikipedia instead\n",
        "     ('https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst',None,  3.0), # freelaw THE EYE DELETED THE ORIGINAL DATA\n",
        "     ('the_pile_stack_exchange',None,  5.13),\n",
        "     (\"conceptofmind/pile_uspto_backgrounds\",None, 3.00),\n",
        "     (\"https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\",None,  3.07),\n",
        "     #\"pg19\", 0.1, # project gutenberg FAILS\n",
        "     #(\"https://the-eye.eu/public/AI/pile_v2/data/EuroParliamentProceedings_1996_2011.jsonl.zst\", None, 0.73), # NON ENGLISH\n",
        "     #('https://the-eye.eu/public/AI/pile_preliminary_components/EuroParliamentProceedings_1996_2011.jsonl.zst',None, 0.73), # NON ENGLISH\n",
        "     (\"pile-of-law/pile-of-law\",'euro_parl',1),\n",
        "     (\"conceptofmind/pile_hacker_news\", None,2),\n",
        "     #(\"https://the-eye.eu/public/AI/pile_preliminary_components/PhilArchive.jsonl.zst\", None, 0.38), #(( philosophy papers -- its taking too long?\n",
        "     ('https://the-eye.eu/public/AI/pile_v2/data/PhilArchive.jsonl.zst', None, 0.38), # does this work better?\n",
        "     (\"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\",None, 0.30),\n",
        "     (\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", None, 5.0),# ledgar worked\n",
        "     (\"pile-of-law/pile-of-law\",'r_legaladvice', 1.0),\n",
        "     (\"pile-of-law/pile-of-law\",'exam_outlines',0.5),\n",
        "     (\"pile-of-law/pile-of-law\",'cc_casebooks',0.5),\n",
        "     (\"eloukas/edgar-corpus\",None, 4.0),\n",
        "     #(\"orieg/elsevier-oa-cc-by\",None,3.75) fails (takes too long)\n",
        "     (\"Rahmaa/ElsevieR_ClEaN\",None,3.75),#\n",
        "     ('ashraq/financial-news-articles', None, 1.0),\n",
        "     ('pile-of-law/pile-of-law','courtlistener_opinions',  3.0), # freelaw THE EYE DELETED THE ORIGINAL DATA\n",
        "     ('suolyer/pile_nih-exporter',['validation','test'], 0.30/2),\n",
        "     ('EleutherAI/pile','all',10.01 + 5.13 + 3.07) # backup for openweb3 and stackexchange and  and pubmed abstracts\n",
        "    #\"https://huggingface.co/datasets/pile-of-law/pile-of-law/blob/main/data/train.edgar.jsonl.xz\"\n",
        "]\n",
        "\n",
        "print(len(data_files))\n",
        "\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files,\n",
        "    'val_size':2000,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':6000,\n",
        "    'max_chunk_start':1000000,\n",
        "    \"seed\":42,\n",
        "    \"do_cc\":True,\n",
        "    \"do_wikipedia\":True,\n",
        "    \"do_book3\":True, # delated from pile, no backup -- maybe book corpus and bookcorpus2?\n",
        "    \"do_openwebtext2\":False, # delated from pile, see pilebackup\n",
        "    \"do_arxiv\":True,\n",
        "    \"do_pmc-articles\":True,\n",
        "    \"do_freelawopinions\":False, # deleted from https://pile.eleuther.ai/\n",
        "    \"do_stackexchange\":False, # delated from pile, see pilebackup\n",
        "    \"do_upto\":True,\n",
        "    \"do_pubmed-abstracts\":False, # deleted from https://pile.eleuther.ai/ see pilebackup\n",
        "    \"do_EuroParliamentProceedings_1996_2011\":True,\n",
        "    \"do_hackernews\":True,\n",
        "    \"do_philpapers\":False, # this crashes my computer\n",
        "    \"do_NIH_ExPORTER_awarded_grant\":True, # deleted from pile.eleuther.ai, opps, looks like it is restored\n",
        "    \"do_ledgar\":True,\n",
        "    \"do_r_legaladvice\":True,\n",
        "    \"do_legalexams\":True,\n",
        "    \"do_casetexts\":True,\n",
        "    \"do_edgar\":True,\n",
        "    \"do_elseiver\":True,\n",
        "    'do_financialnews':True,\n",
        "    'do_pilelawopinions_sub':True,\n",
        "    'do_nih-backup':False,\n",
        "    'do_pilebackupfiltered':True, # backup pile, filtered : nope, it depend on pile.eleuther.ai\n",
        "}\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files,\n",
        "    'val_size':200,\n",
        "    'min_seq_length':48,\n",
        "    'max_seq_length':512,\n",
        "    'max_chunk_size':6,\n",
        "    'train_chunk_size':300,\n",
        "    'max_chunk_start':6000,\n",
        "    \"seed\":42,\n",
        "    \"do_cc\":True,\n",
        "    \"do_wikipedia\":True,\n",
        "    \"do_book3\":True, # delated from pile, but alternative seems to wors\n",
        "    \"do_openwebtext2\":False, # delated from pile, see pilebackup\n",
        "    \"do_arxiv\":False,\n",
        "    \"do_pmc-articles\":False,\n",
        "    \"do_freelawopinions\":False, # deleted from https://pile.eleuther.ai/\n",
        "    \"do_stackexchange\":False, # delated from pile, see pilebackup\n",
        "    \"do_upto\":False,\n",
        "    \"do_pubmed-abstracts\":False, # deleted from https://pile.eleuther.ai/ see pilebackup\n",
        "    \"do_EuroParliamentProceedings_1996_2011\":False,\n",
        "    \"do_hackernews\":False,\n",
        "    \"do_philpapers\":False, # this crashes my computer\n",
        "    \"do_NIH_ExPORTER_awarded_grant\":False, # deleted from pile.eleuther.ai, opps, looks like it is restored\n",
        "    \"do_ledgar\":False,\n",
        "    \"do_r_legaladvice\":False,\n",
        "    \"do_legalexams\":False,\n",
        "    \"do_casetexts\":False,\n",
        "    \"do_edgar\":True,\n",
        "    \"do_elseiver\":False,\n",
        "    'do_financialnews':False,\n",
        "    'do_pilelawopinions_sub':False,\n",
        "    'do_nih-backup':False,\n",
        "    'do_pilebackupfiltered':True, # backup pile, filtered : nope, it depend on pile.eleuther.ai\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZfwOl0Uh20l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "a60adef6-2a2f-4a5c-fa2c-3cb4fa37c531"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "EmptyDatasetError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDatasetError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bb6424108c06>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#foo = load_dataset('the_pile_books3',split='train',streaming=True) # fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#foo = load_dataset('bookcorpusopen',split='train',streaming=True) # fails: FileNotFoundError: https://the-eye.eu/public/AI/pile_preliminary_components/books1.tar.gz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hieule/vie-book-v2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m    \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   1786\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_auth_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1515\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1223\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't reach the Hugging Face Hub for dataset '{path}': {e1}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmptyDatasetError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m                     raise FileNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                     \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                     \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                 ).get_module()\n\u001b[0m\u001b[1;32m   1216\u001b[0m         except (\n\u001b[1;32m   1217\u001b[0m             \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns_in_dataset_repository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhfh_dataset_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m         )\n\u001b[1;32m    782\u001b[0m         data_files = DataFilesDict.from_hf_repo(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mget_data_patterns_in_dataset_repository\u001b[0;34m(dataset_info, base_path)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_data_files_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         raise EmptyDatasetError(\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;34mf\"The dataset repository at '{dataset_info.id}' doesn't contain any data files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         ) from None\n",
            "\u001b[0;31mEmptyDatasetError\u001b[0m: The dataset repository at 'hieule/vie-book-v2' doesn't contain any data files"
          ]
        }
      ],
      "source": [
        "# no longer works: the_pile_books3: maybe SaylorTwift/the_pile_books3_minus_gutenberg\n",
        "# the_pile_stack_exchange : is down, maybe use: donfu/oa-stackexchange (but it is badly sorted) or # teven/stackexchange (but it has other languages)\n",
        "# openwebtext2 : vietgpt/the_pile_openwebtext2\n",
        "# 'EleutherAI/pile','pubmed_central' dead\n",
        "# 'EleutherAI/pile','free_law' failes\n",
        "# 'EleutherAI/pile','nih_exporter', dead\n",
        "# 'EleutherAI/pile','hacker_news', dead\n",
        "#foo = load_dataset('json',data_files = \"https://the-eye.eu/public/AI/pile_neox/data/PhilPapersDataset_text_document.bin\",split='train') # fails\n",
        "\n",
        "# still works with all; # \"EleutherAI/pile\", split=\"\"\n",
        "#foo = load_dataset('json',data_files= \"https://the-eye.eu/public/AI/pile_v2/data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\", split=\"train\", streaming=True)\n",
        "#foo = load_dataset('text',data_files = \"https://the-eye.eu/public/AI/pile_neox/data/PhilPapersDataset_text_document.bin\",split='train', encoding='latin-1',streaming=True)\n",
        "#foo = load_dataset('the_pile_books3',split='train',streaming=True) # fails\n",
        "#foo = load_dataset('bookcorpusopen',split='train',streaming=True) # fails: FileNotFoundError: https://the-eye.eu/public/AI/pile_preliminary_components/books1.tar.gz\n",
        "foo =  load_dataset('hieule/vie-book-v2',split='train',streaming=True) # fails\n",
        "for e in foo:\n",
        "   break\n",
        "\n",
        "print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MULDJS_QVqid"
      },
      "outputs": [],
      "source": [
        "def make_streaming_datasets(data_streaming_config, streaming_datasets = None):\n",
        "    \"\"\"Makes the streaming dataset, like Pile but includes others\"\"\"\n",
        "\n",
        "    print('consider adding: ashraq/financial-news-articles, for finacial news')\n",
        "\n",
        "    def casetext_skip_first_k_char(example):\n",
        "        example['text'] = example['text'][120000:].replace('\\n',\" \")\n",
        "        return example\n",
        "\n",
        "    def edgar_consolidate_sections(example):\n",
        "        example['text'] = example['section_1'] + \"\\n\" + example['section_2'] + \"\\n\" + example['section_3'] + \"\\n\" + example['section_7']\n",
        "        return example\n",
        "\n",
        "    def clean_elseiver_mlm(example):\n",
        "        example['text'] = example['Clean_Title'] + \" - \" + example['Clean_Summary'] + \"\\n\" + example['Clean_Text']\n",
        "        return example\n",
        "\n",
        "    def clean_financial_news(example):\n",
        "        example['text'] = example['title'] + \"\\n\" + example['text']\n",
        "        return example\n",
        "\n",
        "    if streaming_datasets is None:\n",
        "        streaming_datasets = []\n",
        "\n",
        "    # new probabilities\n",
        "    probabilities = []\n",
        "\n",
        "    data_files = data_streaming_config['files']\n",
        "\n",
        "    if data_streaming_config['do_cc']:\n",
        "        # CommonCraw\n",
        "        j = 0\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['url', 'timestamp', 'dump', 'segment', 'image_urls']).rename_column('content','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_wikipedia']:\n",
        "        # wikipedia\n",
        "        j = 1\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[1][1], data_files[5][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['id', 'title', 'url', 'wiki_id', 'views', 'paragraph_id', 'langs'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_book3']:\n",
        "        # the_pile_books3: need to figure out how to skip a certain amount of tokens\n",
        "        j = 2\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[2][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['title'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_openwebtext2']:\n",
        "        # the_pile_openwebtext2:\n",
        "        j = 3\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[3][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['title','reddit_scores'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_arxiv']:\n",
        "        # arxiv_abstracts:\n",
        "        j = 4\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[4][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['embeddings', 'doi']).rename_column('abstract','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_pmc-articles']:\n",
        "        # PMC articles\n",
        "        j = 5\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[5][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['abstract']).rename_column('article','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_freelawopinions']:\n",
        "        # Freelaw opinions\n",
        "        j = 6\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_stackexchange']:\n",
        "        j = 7\n",
        "        # stackexchange\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(path=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['domain'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_upto']:\n",
        "        j = 8\n",
        "        # upto\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(path=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_pubmed-abstracts']:\n",
        "        j = 9\n",
        "        # pubmed abstracts\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_EuroParliamentProceedings_1996_2011']:\n",
        "        j = 10\n",
        "        #EuroParliamentProceedings_1996_2011\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_hackernews']:\n",
        "        j = 11\n",
        "        # hackernews discusions\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        print('Hacker news needs extra cleaning to remove ===== username and ----- username and ~~~ username')\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_philpapers']:\n",
        "        j = 12\n",
        "        # philosophy papers / philpapers\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_NIH_ExPORTER_awarded_grant']:\n",
        "        j = 13\n",
        "        # NIH_ExPORTER_awarded_grant_text\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_ledgar']:\n",
        "        j = 14\n",
        "        # LEDGAR_2016: (\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", None, 5.0),# ledgar worked\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset('json', data_files=data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['label', 'source']).rename_column('provision','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_r_legaladvice']:\n",
        "        j = 15\n",
        "        # r_legaladvice\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])#.rename_column('provision','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_legalexams']:\n",
        "        j = 16\n",
        "        # legal exams\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])#.rename_column('provision','text')\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_casetexts']:\n",
        "        j = 17\n",
        "        # case text books\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url']).map(casetext_skip_first_k_char)\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "\n",
        "    if data_streaming_config['do_edgar']:\n",
        "        j = 18\n",
        "        # edgar corpus\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].map(edgar_consolidate_sections).remove_columns([\n",
        "            'filename', 'cik', 'year', 'section_1A', 'section_1B', 'section_4', 'section_1', 'section_2', 'section_3', 'section_7',\n",
        "            'section_5', 'section_6', 'section_8', 'section_9', 'section_10', 'section_7A', 'section_9A', 'section_9B',\n",
        "            'section_11', 'section_12', 'section_13', 'section_14', 'section_15' #\n",
        "        ])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_elseiver']:\n",
        "        j = 19\n",
        "        # elseiver\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], None, split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].map(clean_elseiver_mlm).remove_columns(['Unnamed: 0', 'Clean_Title', 'Clean_Text', 'Clean_Summary'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_financialnews']:\n",
        "        j = 20\n",
        "        # financial_news\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], None, split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].map(clean_financial_news).remove_columns(['title','url'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    if data_streaming_config['do_pilelawopinions_sub']:\n",
        "        j = 21\n",
        "        # SUBSTITUTE: pile-of-law opinions\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split=\"train\", streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['created_timestamp', 'downloaded_timestamp', 'url'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    # do_nih-backup\n",
        "    if data_streaming_config['do_nih-backup']:\n",
        "        j = 22\n",
        "        # SUBSTITUTE: pile-of-law opinions\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=data_files[j][1][0], streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], split=data_files[j][1][1], streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    # backup using the pile's 'all' filtered {'ArXiv','FreeLaw', 'Github','NIH ExPorter','OpenWebText2','Pile-CC','PubMed Abstracts','PubMed Central','StackExchange',\n",
        "    #'USPTO Backgrounds', 'Wikipedia (en)'}\n",
        "    if data_streaming_config['do_pilebackupfiltered']:\n",
        "        j = 23\n",
        "        print(\"Trying '%s\" % data_files[j][0])\n",
        "        streaming_datasets.append(load_dataset(data_files[j][0], data_files[j][1], split='train',streaming=True))\n",
        "        streaming_datasets[-1] = streaming_datasets[-1].filter(\n",
        "            lambda x: x['meta']['pile_set_name'] in ['NIH ExPorter','OpenWebText2','PubMed Abstracts','StackExchange','Wikipedia (en)']\n",
        "        ).remove_columns(['meta'])\n",
        "        probabilities.append(data_files[j][-1])\n",
        "\n",
        "    assert len(streaming_datasets)==len(probabilities)\n",
        "    return streaming_datasets, probabilities\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fetch_and_combine_streaming_mlm_data(\n",
        "    data_streaming_config,\n",
        "    stopping_strategy ='all_exhausted',\n",
        "):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "\n",
        "    # make all the streaming datsets\n",
        "    datasets_to_stream, dataset_probabilities = make_streaming_datasets(\n",
        "        data_streaming_config, streaming_datasets = None\n",
        "    )\n",
        "    # normalize the probabilities\n",
        "    dataset_probabilities = [\n",
        "        p/sum(dataset_probabilities) for p in dataset_probabilities\n",
        "    ]\n",
        "\n",
        "    print('DONE initializing streaming datasets')\n",
        "    #return datasets_to_stream\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy = stopping_strategy,\n",
        "        probabilities = dataset_probabilities,\n",
        "        seed = data_streaming_config['seed']\n",
        "    )\n",
        "    return datasets_combined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGLBNn8i1_Ak"
      },
      "outputs": [],
      "source": [
        "# no longer works: the_pile_books3: maybe SaylorTwift/the_pile_books3_minus_gutenberg\n",
        "# the_pile_stack_exchange : is down, maybe use: donfu/oa-stackexchange (but it is badly sorted) or # teven/stackexchange (but it has other languages)\n",
        "# openwebtext2 : vietgpt/the_pile_openwebtext2\n",
        "if False:\n",
        "    foo = load_dataset('the_pile_stack_exchange',split='train',streaming=True)\n",
        "    for i,e in enumerate(foo):\n",
        "        if (i+1)%10:\n",
        "            print(e['text'])\n",
        "        if i>100:\n",
        "          lkjlkjlkj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30h2nnzWnDpz"
      },
      "outputs": [],
      "source": [
        "\n",
        "CHAR_PER_WORD = 6.36\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "config = {\n",
        "    'max_seq_length':512,\n",
        "    'min_seq_length':48,\n",
        "    'max_chunk_size':6,\n",
        "    'seed':42\n",
        "}\n",
        "\n",
        "class ExampleProcessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        config=config,\n",
        "        char_per_word = CHAR_PER_WORD,\n",
        "        nlp =nlp,\n",
        "    ):\n",
        "        self.nlp = nlp\n",
        "        self.char_per_word = char_per_word\n",
        "        self.max_seq_length = config.get('max_seq_length', 512)\n",
        "        self.min_seq_length = config.get('min_seq_length', 128)\n",
        "        self.max_chunk_size = config.get('max_chunk_size', 5)\n",
        "        self.seed = config.get('seed', 42)\n",
        "        self.max_chunk_length = self.max_chunk_size * self.max_seq_length\n",
        "        self.max_chunk_length_char = int(self.max_chunk_length*self.char_per_word)\n",
        "        self.min_seq_length_char = int(self.min_seq_length*self.char_per_word)\n",
        "\n",
        "    @staticmethod\n",
        "    def split_into_chunks(text, chunk_char_size, overlapping_size = 50):\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        end = chunk_char_size + overlapping_size\n",
        "        while start < len(text):\n",
        "            chunk = text[start:end]\n",
        "            period_index = chunk.find(\". \")\n",
        "            if period_index != -1:\n",
        "                chunk = chunk[period_index + 1:]\n",
        "            else:\n",
        "                first_space_index = chunk.find(\" \")\n",
        "                if first_space_index != -1:\n",
        "                    chunk = chunk[first_space_index + 1:]\n",
        "            # Check if the chunk has been split and contains more than one word\n",
        "            #if start > 0 and \" \" in chunk:\n",
        "            if end < len(text) and \" \" in chunk and chunk[-1]!=\" \":\n",
        "                last_space_index = chunk.rfind(\" \")\n",
        "                chunk = chunk[:last_space_index]\n",
        "            chunks.append(chunk)\n",
        "            start += chunk_char_size\n",
        "            end += chunk_char_size\n",
        "        return chunks\n",
        "\n",
        "    def split_chunk_into_sentences(self, chunk, discard_first_sentence=True, discard_last_sentence=True ):\n",
        "        doc = self.nlp(chunk)\n",
        "        MAX_CHAR_LEN = int(self.max_seq_length*self.char_per_word)\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        if discard_first_sentence:\n",
        "            sentences = sentences[1:]\n",
        "        if discard_last_sentence:\n",
        "            sentences = sentences[:-1]\n",
        "        super_list = []\n",
        "        buffer = []\n",
        "        buffer_len = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_len = len(sentence)\n",
        "\n",
        "            if buffer_len + sentence_len > MAX_CHAR_LEN:\n",
        "                super_list.append(\" \".join(buffer))\n",
        "                buffer = []\n",
        "                buffer_len = 0\n",
        "\n",
        "            buffer.append(sentence)\n",
        "            buffer_len += sentence_len\n",
        "\n",
        "        if buffer:  # If there are any remaining sentences in the buffer\n",
        "            super_list.append(\" \".join(buffer))\n",
        "\n",
        "        return super_list\n",
        "\n",
        "    def _sample_chunk_span(self, text, max_chunk_length_char):\n",
        "        chunks = self.split_into_chunks(text, max_chunk_length_char)\n",
        "        # randomly sample from the chunks\n",
        "        #FOOBAR SAMPLE FROM CHUNKS\n",
        "        return random.choice(chunks)\n",
        "\n",
        "    def is_too_small_quickcheck(self, text, textlen=None):\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.min_seq_length_char*0.9\n",
        "\n",
        "    def is_too_small(self, nwords):\n",
        "        return nwords < self.min_seq_length\n",
        "\n",
        "    def is_larger_than_max_chunk_quickcheck(self, text, textlen):\n",
        "        \"\"\"if it is larger than a chunksize, then we need to sample chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen > self.max_chunk_length_char\n",
        "\n",
        "    def is_short_than_a_chunk(self, text, textlen):\n",
        "        \"\"\"if it is shorter than a chunk, then we'll take all text, in chunks\"\"\"\n",
        "        if textlen is None: textlen = len(text.strip())\n",
        "        return textlen < self.max_chunk_length_char\n",
        "\n",
        "    def is_smaller_than_two_paragraphs(self, text):\n",
        "        charlen = len(text)\n",
        "        if charlen < (1.5*self.max_seq_length*self.char_per_word):\n",
        "            return True, re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        if charlen > (2.5*self.max_seq_length*self.char_per_word):\n",
        "            return False, None\n",
        "        # inbetween cases, split and calculate the number of words\n",
        "        textsplit = re.split(r\"[\\s\\n\\r]+\",text.strip())\n",
        "        nwords = len(textsplit)\n",
        "        if nwords < 1.2*self.max_seq_length:\n",
        "            return True, textsplit\n",
        "        return False, textsplit\n",
        "\n",
        "    def process(self, text):\n",
        "        # TODO: a quick chunk sampler\n",
        "        # a chunk splitter based on the sentencizer\n",
        "\n",
        "        charlen = len(text.strip())\n",
        "\n",
        "        # DISCARD if it is too small for copus\n",
        "        if self.is_too_small_quickcheck(text, charlen):\n",
        "\n",
        "            return [], False\n",
        "\n",
        "        # sample span of chunks: if it larger than our max chunk size\n",
        "        if self.is_larger_than_max_chunk_quickcheck(text, charlen):\n",
        "            text_span_chunks = self._sample_chunk_span(text, self.max_chunk_length_char)\n",
        "        else:\n",
        "            text_span_chunks = text\n",
        "\n",
        "        # check if it smaller, than 1.5 seqlen, then we just accept it all as one unit to truncate later in tokenizer\n",
        "        is_smaller_than_2_paras, textsplit = self.is_smaller_than_two_paragraphs(text_span_chunks)\n",
        "\n",
        "        if is_smaller_than_2_paras:\n",
        "\n",
        "            # check if less than minsize\n",
        "            if self.is_too_small(len(textsplit)):\n",
        "                # if too small, return nothing\n",
        "                return [],False\n",
        "\n",
        "            # return text to be truncated\n",
        "            return [text_span_chunks], True\n",
        "\n",
        "        # leftover cases: text that needs to be chunked into ~512 / max_seq_len\n",
        "        return (self.split_chunk_into_sentences(text_span_chunks), True)\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.process(text)\n",
        "\n",
        "example_processor = ExampleProcessor(config=data_streaming_config, char_per_word = CHAR_PER_WORD, nlp =nlp)\n",
        "text = \"\"\"As the aircraft approached Pearl Harbor, the weather cleared, as if on cue. This enabled the strike formations to use the battery of searchlights at Kahuku Point as a navigation aid to guide them toward their targets. Dawn was now breaking. As sunlight streamed over the horizon, the airborne strike force pressed home its attack over Pearl Harbor, achieving complete surprise. Dive-bombers and torpedo planes went to work on the ships lying at anchor along Battleship Row, where the U.S. Navy's capital ships were berthed. Fighter aircraft peeled off and strafed the airfield, hitting parked planes, fuel storage tanks, and hangars. Army Air Corps pilots rushed to take off after the attacking force, but by the time they were aloft, the attackers had completed their strikes and vanished. Failing to locate the attackers, the Army aircraft returned to base, whereupon a second wave of carrier strike aircraft hit them. A _New York Times_ reporter on the scene reported that the attacks were \"unopposed by the defense, which was caught virtually napping. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor. Surveying the results, the American defenders were filled with anger—and relief. The attack, executed on the morning of Sunday, _February 7, 1932_ , occurred at the outset of a U.S. Army-Navy war game called Grand Joint Exercise 4. Rear Admiral Harry Yarnell, commander of the newly commissioned American aircraft carriers _Saratoga_ and _Lexington_ , had launched the attacking planes. The \"bombs\" dropped were flour bags, which could be found splattered on the Navy's ships still sitting at anchor.Red-faced, the Army Air Corps commanders sought to minimize the attack's results. They argued that the damage incurred to Hickam Field was minimal, and asserted that they had found and attacked Yarnell's carriers. Finally, they protested the attack on legal grounds—it was improper to begin a war on Sunday! The war game's umpires sided with the Army. Their report made no mention of Yarnell's attack but concluded that \"it is doubtful if air attacks can be launched against Oahu in the face of strong defensive aviation without subjecting the attacking carriers to the danger of material damage and consequent great loss in the attacking] air force. Nearly ten years later carriers of the Imperial Japanese Navy, attacking Pearl Harbor on Sunday, December 7, 1941, proved that Admiral Yarnell, not the umpires or the Army, had gauged the future correctly. The admiral had been willing to confront uncomfortable possibilities, whereas others had not. Although America was shocked by the Japanese attack, many in the Navy were not. As Admiral Chester W. Nimitz, the architect of the Navy's victorious campaign against Japan, ruefully admitted, \"Nothing that happened in the Pacific was strange or unexpected. ## **THE DAWN OF BLITZKRIEG**\"\"\"\n",
        "text += text\n",
        "text += text\n",
        "text += text\n",
        "text += text\n",
        "foo,is_good = example_processor(text = text)\n",
        "print(is_good)\n",
        "print(foo)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSP-Hmb8vUm_"
      },
      "source": [
        "#### A Sample of 1000 will have...\n",
        "... approximately 1523 samples of 512-long examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_sequence_into_nextsentence_pairs(['a','b','c','d','e','f'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_nVLY58hvan",
        "outputId": "3778ad43-0cd3-46b4-d0ab-fc66ac7bd2ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'anchor': 'a', 'next': 'b', 'opposite': 'e'},\n",
              " {'anchor': 'b', 'next': 'c', 'opposite': 'f'},\n",
              " {'anchor': 'c', 'next': 'd', 'opposite': 'a'},\n",
              " {'anchor': 'd', 'next': 'e', 'opposite': 'b'},\n",
              " {'anchor': 'e', 'next': 'f', 'opposite': 'c'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmhZQWnl1EUQ"
      },
      "outputs": [],
      "source": [
        "# FUNCTIONS TO MAKE THE TRAINING AND VAL SETs\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "## convert the streaming dataset in a static dataset\n",
        "def convert_streaming_dataset_to_static_corpus(streaming_dataset, skip=0, take=1000):\n",
        "    \"\"\"Takes a streaming_dataset and converts it into a list of examples\"\"\"\n",
        "    if skip !=0:\n",
        "        dataset_to_make_static = streaming_dataset.skip(skip).take(take)\n",
        "    else:\n",
        "        dataset_to_make_static = streaming_dataset.take(take)\n",
        "\n",
        "    examples_static_mlm = [] # data for MLM objective\n",
        "    examples_static_nextsentence = [] # data for next sentence task\n",
        "    for i, example in enumerate(dataset_to_make_static):\n",
        "        example_parsed, is_good = example_processor(text = example['text'])\n",
        "        if is_good:\n",
        "            examples_static_mlm.extend(example_parsed)\n",
        "            if len(example_parsed)>4:\n",
        "                examples_static_nextsentence.extend(\n",
        "                    convert_sequence_into_nextsentence_pairs(example_parsed)\n",
        "                )\n",
        "        if (i+1)%100==0:\n",
        "            print(\"...streaming size: \" % len(examples_static_mlm))\n",
        "\n",
        "    return examples_static_mlm, examples_static_nextsentence\n",
        "\n",
        "print(convert_sequence_into_nextsentence_pairs(['a','b','c','d','e','f']))\n",
        "\n",
        "def convert_sequence_into_nextsentence_pairs(list_of_sentences):\n",
        "    \"\"\"Converts a list of sentences into a list of dicts, with next-sentence pairs\"\"\"\n",
        "    n = len(list_of_sentences)\n",
        "\n",
        "    def opposite(i,n):\n",
        "        return (i + round(n/2+1)) % n\n",
        "\n",
        "    list_of_nextsentence_pairs = []\n",
        "    # loop through sequence, make triplet of anchor, next and an opposite\n",
        "    for o1,o2 in zip(range(0,n-1), range(1,n)):\n",
        "        s_anchor = list_of_sentences[o1]\n",
        "        s_next = list_of_sentences[o2]\n",
        "        s_opposite = list_of_sentences[opposite(o1,n)]\n",
        "        list_of_nextsentence_pairs.append(\n",
        "            {\n",
        "                \"anchor\":s_anchor,\n",
        "                \"next\":s_next,\n",
        "                \"opposite\":s_opposite\n",
        "            }\n",
        "        )\n",
        "    return list_of_nextsentence_pairs\n",
        "\n",
        "\n",
        "def train_test_splits_from_stream(\n",
        "    streaming_dataset,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    max_chunk_start = 1000000,\n",
        "    path_to_val_cache = 'val_mlm_cache.pkl'\n",
        "):\n",
        "    \"\"\"\n",
        "    val_size = 2000, number of streaming-iter to skip, reserved for the val-sze\n",
        "    epoch = 0, epoch will change the seed when sampling the chunk idx for making the training set\n",
        "    chunk_size = 5000, # number of streaming-iter to select the training data chunk\n",
        "    max_chunk_start = 2000000, # randomly sample within this interval for streaming chunks\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path_to_val_cache):\n",
        "        print('RELOADING VAL SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            val_corpus_list = pickle.load(pcon)\n",
        "            val_corpus_nextsentence = pickle.load(pcon)\n",
        "        print('VAL SET SIZE: %d' % len(val_corpus_list))\n",
        "    else:\n",
        "        # stream validation set\n",
        "        print('STREAMING VAL DATA: %d' % val_size)\n",
        "        val_corpus_list, val_corpus_nextsentence = convert_streaming_dataset_to_static_corpus(\n",
        "            streaming_dataset, skip=0, take=val_size\n",
        "        )\n",
        "        # save the validation corpus\n",
        "        print('SAVING VAL SET: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(val_corpus_list, pcon)\n",
        "            pickle.dump(val_corpus_nextsentence, pcon)\n",
        "\n",
        "    # take a random interger to start the streaming of training data\n",
        "    skip_to_start_streaming_training_data = np.random.RandomState(\n",
        "        42 + epoch\n",
        "    ).randint(val_size, max_chunk_start)\n",
        "\n",
        "    # stream training data\n",
        "    print('STREAMING TRAIN DATA: %d STARTING AT: %d' % (chunk_size,skip_to_start_streaming_training_data))\n",
        "    train_corpus_mlm, train_corpus_nextsentence = convert_streaming_dataset_to_static_corpus(\n",
        "        streaming_dataset,\n",
        "        skip=skip_to_start_streaming_training_data,\n",
        "        take=chunk_size\n",
        "    )\n",
        "    print('TRAIN SET SIZE: %d' % len(train_corpus_mlm))\n",
        "    train_data_mlm = {\n",
        "        'train':train_corpus_mlm,\n",
        "        'val':val_corpus_list,\n",
        "        'epoch':0,\n",
        "        'index_stream':skip_to_start_streaming_training_data\n",
        "    }\n",
        "    train_data_nextsentence = {\n",
        "        'train'\n",
        "    }\n",
        "    # next sentence prediction\n",
        "    return train_data_mlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5TqK9885td5",
        "outputId": "16e64f2c-a3a9-4a95-9a21-736fb65b5de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "consider adding: ashraq/financial-news-articles, for finacial news\n",
            "Trying 'tiiuae/falcon-refinedweb\n",
            "Trying 'Cohere/wikipedia-22-12\n",
            "Trying 'eloukas/edgar-corpus\n",
            "Trying 'EleutherAI/pile\n",
            "DONE initializing streaming datasets\n",
            "STREAMING VAL DATA: 200\n",
            "132\n",
            "265\n",
            "SAVING VAL SET: val_mlm_cache.pkl\n",
            "STREAMING TRAIN DATA: 300 STARTING AT: 1060\n",
            "138\n",
            "284\n",
            "410\n",
            "TRAIN SET SIZE: 410\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# stream and combine the MLM datasets\n",
        "datasets_mlm_streaming_combined = fetch_and_combine_streaming_mlm_data(\n",
        "    data_streaming_config, #stopping_strategy ='all_exhausted'\n",
        ")\n",
        "\n",
        "\n",
        "# create the training set and validation set (save and reload later)\n",
        "datasets_static = train_test_splits_from_stream(\n",
        "    datasets_mlm_streaming_combined,\n",
        "    val_size = data_streaming_config['val_size'],#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size =  data_streaming_config['train_chunk_size'],#6000,\n",
        "    max_chunk_start = data_streaming_config['max_chunk_start'],#1000000,\n",
        "    path_to_val_cache = 'val_mlm_cache.pkl'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r51a5BrXzKZA"
      },
      "outputs": [],
      "source": [
        "for s in datasets_static['train']:\n",
        "    print(s.replace('\\n',' ')[:150] + \"\\n----\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Done making the MLM streaming dataset (although I still need a book corpus)"
      ],
      "metadata": {
        "id": "6IYVkevC3Vwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q&A Triplets!\n",
        "\n",
        "Here I make a triplet dataset of query, positive answer, and negatives (if available)\n",
        "\n",
        "B) QA Tasks\n",
        "- squad_2\n",
        "- WikiHow - used by S-BERT (questions and articles) - needs to be manually downloaded - https://github.com/mahnazkoupaee/WikiHow-Dataset/\n",
        "- trivia_qa - 680 question, ans, evidence triplets. But, the context strings are very long (like wikipedia) and the questions are almost pop culture\n",
        "- LLukas22/fiqa - financial QA, like conversations\n",
        "- embedding-data/WikiAnswers - question-duplicates as paraphrases\n",
        "- embedding-data/QQP_triplets - question-duplicates plus negatives (Quora)\n",
        "- LLukas22/lfqa_preprocessed - question and answers 226k\n",
        "- DONE gbharti/finance-alpaca (like FIQA - finance Q&A)\n",
        "- DONE embedding-data/PAQ_pairs - wikipedia question & answers\n",
        "- GONE the_pile_stack_exchange - single texts, but can be split into question, answer\n",
        "- donfu/oa-stackexchange - 6.3 million!\n",
        "- cais/mmlu - multiple choice, but some of the answers are longers (need to filter)\n",
        "- sciq - science questions - see question and support\n",
        "- DONE wiki_qa - wikipedia QA\n",
        "- qasc - high-school questions - can combine the \"facts\" into a support\n",
        "- pubmed_qa - science QA with answers\n",
        "- JoBeer/eclassTrainST - can easily convert into question-answer pairs"
      ],
      "metadata": {
        "id": "PCG8JHCz3Xzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#JoBeer/eclassTrainST\n",
        "#foo =  load_dataset('gart-labor/eclassTrainST',split='train',streaming=True).map(clean_eclassTrainST).remove_columns(['text', 'entailment', 'contradiction', 'label'])\n",
        "#foo =  load_dataset('gbharti/finance-alpaca',split='train',streaming=True)  # good, financial questions\n",
        "foo =  load_dataset('embedding-data/WikiAnswers',split='train',streaming=True) # NAD; just for paraphrased questions, not for QA\n",
        "#foo =  load_dataset('wiki_qa',split='train',streaming=True) # excellent; with negatives and positives\n",
        "#foo =  load_dataset('THUDM/webglm-qa',split='train',streaming=True) # excellent; with negatives and positives\n",
        "#foo = load_dataset(\"\",split='train',streaming=False) #\n",
        "if True:\n",
        "    # embedding-data/WikiAnswers\n",
        "    for j,e in enumerate(foo):\n",
        "        print(e)\n",
        "        if j > 10:\n",
        "          break\n",
        "    print(e)\n",
        "    print(e.keys())"
      ],
      "metadata": {
        "id": "q96FHzngk0FH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "e0ff34de926f4c0d8a4aba8c00356ba3",
            "dcd9c59700d24bc1a46c454e559960b5",
            "d11a9fd00ce741a6b89343c33b83026c",
            "e933054cc0904f48b4691db57bafc358",
            "a818dc39d66a40fab33efcba4aa497b8",
            "a63ec248c0cc40b1b546d3a434632621",
            "24a0eb797aa4418daebc63c29ab03395",
            "dbacecf8618c4ee185e5fd9afd2e1703",
            "b32b93922b6c48ec88cf40ee16b5ccab",
            "95dac27cd28b4f48b802605853109dcd",
            "15fe2a8ef27a4a09b16905b070a2d1bf"
          ]
        },
        "outputId": "9e41c21f-f871-4e7e-f055-a2ee616032ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0ff34de926f4c0d8a4aba8c00356ba3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'set': ['How many calories is in a handful of strawberries?', 'How many calories are in a strawberry popsickles?', 'How many calories in a handful of strawberrys?', 'How many calories in 3 small strawberries?', 'How many calories in some strawberries?', 'How many calories do strawberrys?', 'How many calories are in a handful of strawberries?', 'How many calories is a handful of strawberries?', 'How many calories on 10 strawberries?', 'How many calories are in one single strawberry?', 'How many kcals are in a strawberry?', 'How may strawberries in a handful?', 'How many calories in three strawberries?', 'How many calories are in 1cup of strawberrys?', 'How many calories in strawberriers?', 'How many calories is there in strawberries?', 'Calories in handful of strawberries?', 'Calories in a handful of strawberries?', 'How many calories are there in a handful of strawberries?', 'Is 350 Calories alot?', 'How many calories do strawberries have in it?', 'How much calories strawberry?', 'How many calories in handful of strawberries?', 'How many calories dose a strawberrys have?', 'How many calories is in six strawberries?', 'How many calories in a handful of strawberries?']}\n",
            "{'set': ['How do you change the water pump on a 1999 Taurus 3.0 24 valve?', 'How do you replace a water pump on a ford taurus 3.0 liter dohc?', 'How do you replace he water pump on 24 valve taurus?', 'How do you replace a water pump on a 1998 taurus duratec 24v v6?', 'How do you replace water pump taurus dohc?', 'Where is the water pump located on a 2002 mercury sable with a duratech dohc 24 valve engine?', 'Replace water pump in 1998 taurus 3.0 24v?', 'How do you replace a water pump on a 1998 ford taurus 3o duratec 24valve v6?', 'How do you replace the water pump on 01 ford taurus 3.0 dohc?', 'Where is the water pump located on a duratech dohc 24 valve engine?', 'How do you replace water pump on 01 ford taurs dohc?', 'Where is water pump located on dohc 2002 ford tarous?', '1999 ford taurus 3.0L DOHC engine water pump?', 'How much labor time do you get for installinga water pump on a 1999 ford taurus SE model 24 valve engine?', 'How do you replace a thermostat on a 97 ford Taurus duratec 24 valve?', 'How do you change a water pump on a Ford Taurus 24V DOHC?', 'How do you change a water pumpon a 2001 mercury sable 3.0 dohc?', 'Replace water pump 1998 ford taurus 24 valve?', 'Water pump 3.0 duratech?', 'How do you replace water pump on 01 ford taurus dohc?', 'Ford 3.0 dohc water pump replace?', 'How do you change a water pump on 3.0 duratec 24 valve v6?', 'How do you change water pump sable 3.0 dohc?', 'Where is the water pump on a 2004 mercury sable dohc?']}\n",
            "{'set': ['Why is britain important?', \"Non'significance of the battle of Britain?\", 'What was the signicance of the battle of britain?', 'How was th battle of britain important?', 'What made the battle of britain unique?', 'What was the singinifcance of the battle of Britain?', 'Why was important the battle of britain?', 'When and who was the battle of britain important?', 'Who are important people involved in the Battle of Britain?', 'What was the meanig of the battle of britain?', 'Why was the fall of britain important?', \"Why Germany felt it was important to restrict Britain's access?\", 'Are people still terrified of the battle of britain?', 'Why was the battle of britain so important in ww2?', 'Why was britain able to stand off in battle of britain?', 'Why was the battle of britain impotant?', 'Why was Battle of Britain importand for US?', 'What was each sides outlook on the battle of britain?', 'Why was britain sucsessfull in the battle of britain?', 'The reuslt of the battle of britain was?', 'Why was the battle of britain so important for the allies to win?', 'Why was the battle of Britain importana?', 'Why was the battle of britain and important victory for britain?', 'How important was britain in ww2?', 'Why was the battle of britain a important turning point?', 'Why was the battle of britain important ww2?', 'Why was the battle of Britain important to Britain?', 'What helped us defeatthem in the battle of britain?', 'What was the identification of the battle of britain?', 'Bullet points on the battle of britain?', \"Why was England's victory at the Battle of Britain so important?\", 'What was signficant about Battle of Britain?', 'Why were the colonies important to britain by the late 1700?', 'Why was the schlefan plan important to britain?', 'Why was the battle of britain not important?', 'Why was the batt5le of britain important?', 'Who gained advantages from battle of britain?', 'Who were the individuals in the battle of britain?', 'What reasons for taking action in the battle of britain?', 'Why was the battle of brittain so important in ww2?', 'What years was the battle of britain in?', 'What was the instrumental in the battle of britain?', 'What was so unique about the Battle of Britain?', 'What statement describes the military outcome AND the importance of the Battle of Britain?', 'What was acheived in battle of britain?', 'What countries in britain were attacked in the battle of britain?', 'Why the britain battle start?', 'What was the battle over britain for and why was it important to the germans?', 'What would be a good thesis for the battle of britain?', 'What are some details about the battle of britain?', 'Battle of Britain was important because?']}\n",
            "{'set': ['Difference between tally 5.4 and 6.3?', 'You want to convert data from tally 5.4 to tally 7.2 please tell you how?', 'What the meaning of knowledge of tally?', 'How can you transfer tally database to another pc?', 'Syllables of tally 7.2 and 9.0?', 'Where you will get Free Tally 5.4 to Tally 7.2 Convertor?', 'How can study tally by online?', 'Difference bw tally 8.1 7.2?', 'What happens to tally in the book specials?', 'How do you transfered data 5.4 into 7.2?', 'Tally 5.4 data backup?', 'How can use tally?', 'Recover of data tally 5.4?', 'Definition of tally 5.4?', 'Tally 5.4 error rewrite?', 'What does mean of tally?', 'How old is a tally?', 'Tally 5.4 to tally 7.2 data transfer?']}\n",
            "{'set': ['Nutrients that are formed from fatty acids and glycerol?', 'What does glycerol do to fat?', 'What is the reaction when Fat is formed by three fatty acids join a glycerol by a?', 'What is glycerol portion of fats?', 'Where are fats first start changing to fatty acids and glycerol?', 'Where does glycerol come from for fatty acid synthesis?', 'Where does fats change into fatty acids and glycerol?', 'Can g3p be converted to glycerol to form fatty acids?', 'How does glycerol and fatty acids form a molecule?', 'Fat consists of what of glycerol and three fatty acids molecules?', 'How do glyceral and fatty acids join to form a fat molecule?', 'What is the name of the molecule that has fatty acid and glycerol?', 'How is a fat formed from glycerol and fatty acid?', 'How are lipids formed from glycerol adn 3 fatty acids?', 'What is the makings of fat from fatty acids and glycerol?', 'How do you glycerol and fatty acids form fats?', 'What kind of fat does fatty acid and glycerol make?', 'What is the difference between a fat and a fatty acid?', 'How do fatty acids and glycerol link togwther to form fats?', 'Ratio of fatty acids to glycerol?', 'Fat plus water plus glycerol plus fatty acids?', 'What fats are there in Glycerol?', 'What forms 3 fatty acids and one glycerol?', 'Is formed when fatty acids bond to an alcohol other than glycerol?', 'Reat to glycerol to make a fat?', 'How are fat formed from glycerol and fatty acid?', 'How is fat formed from glycerol and a fatty acid?', 'Nutruents that are formed from fatty acids and glycerol are?', 'Can fatty acid be converted to fat?', 'How do fatty acids form?', 'How many fatty acids needed to form fats?', 'What does a dehydration synthesis reaction between glycerol and a single fatty acid yield?', 'Fats are formed by attaching fatty acids to?', 'How is fat formed from glycerol?', 'When fatty acids cannot pack together to form a solid fat they have what?', 'What are the two reactive groups in forming a bond between a fatty acid and glycerol caqlled?', 'Are fats and oils constructed from glycerol and fatty acids?', 'What produces glycerol for fatty acid synthesis?', 'How do you construct a fat from fatty acids?', 'Neutral fats or tryglicerides have what ratio of fatty acids to glycerol?', 'What is formed from glycerol?', 'Is glycerol essential for the synthesis of neural fats?', 'Glycerol with three fatty acids creates what reaction to form a fat?', 'Fatty acids plus glycerol equals fat plus water?', 'Fats may be formed by attaching three fatty acids to?', 'What fat is formed when three fatty acids join a glycerol?', 'Structural feature of glycerol important in fat formation of fats?', 'How a fat molecule will be formed from 3 fatty acids?', 'Describe the synthesis of fats from glycerol and fatty acids?', 'How many fatty acids and glycerol does it take to make a molecule of fat?']}\n",
            "{'set': ['Does the hudson river connect to the atlantic ocean?', 'What ocean does the hudson river emty into?', 'Does the amazon river empty into the pacific or atlantic?', 'What ocean does the hudson bay in canada empty into?', 'Does the hudson river run into the atlantic ocean?', 'Where does the hudson river emptie into?', 'Does the Hudson River empty into the Atlantic Ocean?', 'Does the Hudson River empty into Atlantic Ocean?', 'Where does the hudson river empty into?', 'Where does the Hudson river empty its water?', 'Dose the Hudson river emty into the Atlantic ocean?', 'The hudson river empties in the atlantic ocean?', 'Does the hudson river empty into the atlantic ocen?', 'What town is at the end of Hudson River near the ocean?', 'Where does hudson river empy into atlantic?', 'The hudson river empties in to what ocean?', 'Does the Hudson river emptie into the atlantic ocean?', 'Does the Hudson River empty out into the Atlantic Ocean?', 'Where does hudson river empty into atlantic ocean?', 'Does the hudson river empty in the atlantic ocean?', 'Dose the hudson river emptey into the atlantic ocean?', 'Does the Hudson River dump in Atlantic Ocean?', 'Does the Hudson River fow into the Atlantic Ocean?', 'Is it true that the hudson river empties into the atlantic ocean?', 'Does the hudson river empty into the ocean?', 'Does hudson river emptie into the atlantic?', 'Does the hudson river enter into the atlantic ocean?', 'The river in central africa and empties in the atlantic ocean?', 'Does the hudson river empty inot the atlantic ocean?', 'Is the hudson river linked to a ocean?', 'One of the best natural harbors in the world which runs throught eh Atlantic Ocean and the Hudson River is called?']}\n",
            "{'set': ['Why cant you catch an oddish?', 'Where do you catch an oddish in pokemon leaf green?', 'How do you catch heonn pokemon pokemon leafgreen?', 'How do you catch all the pokemon in leafgreen?', 'Which game can you get an oddish?', 'Can you catch a selder on leafgreen?', 'Where do you catch Oddish in LeafGreen?', 'Where can you catch oddish in Pokemon LeafGreen?', 'Where do you catch a Oddish in Pokemon leafgreen?', 'Is oddish in pokemon leafgreen?', 'Where can you catch a oddish in pokemon leafgreen?', 'How do you catch an oddish in leaf gren?', 'Where can you catch an oddish in leafgreen?', 'Where can you find a oddish on pokemon leafgreen?', 'Cheat for catching bulbasaur in pokemon leafgreen?', 'Where to catch wobbuffet in leafgreen?', 'How do you get an oddish in pokemon leafgreen?', 'Where do you get an oddish in pokemon?', 'How do catch sneasle in leafgreen?', 'Where are oddish in pokemon leafgreen?', 'How do you catch oddish in firered?', 'How do you get the pokemon oddish leafgreen?', 'Where you can find oddish in leafgreen?', 'Where do you find an oddish in leafgreen?', 'How do you catch and oddish in pkmn leafgreen?', 'Can you get oddish in pokemon leafgreen?', 'Where do you get a oddish in leafgreen?', 'Where do you catch an oddish in leafgreen?', 'Where can yuo find gloom and oddish in leafgreen?', 'How do you get pokemon code to get oddish?', 'What pokemon should you catch on leafgreen?', 'How do you catch articoono in pokemon leafgreen?', 'Where do you catch a oddish in leafgreen?', 'Where do you catch oddish at in leafgreen?', 'Where do you find oddish in pokemon leafgreen?', 'Wgere is oddish in leafgreen?', 'Can you catch a spheal in leafgreen?', 'Wheredo you catch lickitung in pokemon leafgreen?', 'Where do you catch a oddish pokemon leafgreen?', 'Can you gte an oddish in leafgreen?', 'Where to catch a larviatar on pokemon leafgreen?', 'Can you catch haunter in leafgreen?', 'Where do you catch a Green Oddish in Pokemon?', 'Where do oddish found in pokemon leafgreen?', 'In pokemon leafgreen where can you find an oddish?', 'Where do you get Oddish in pokemon leafgreen?', 'How do you mfind oddish in leafgreen?', 'Where to catch a oddish in pokemon soulsilver?', 'Where to find the pokemon oddish in pokemon leafgreen?', 'Can you catch butterfree in pokemon leafgreen?']}\n",
            "{'set': ['Is liberty university regional accredited?', 'Is liberty university fully accredited?', 'Is Liberty University regionally Accredited?', 'Is liberty university regionally acrrediated?']}\n",
            "{'set': ['What caused the financial crisis after thr Revolutionary War?', 'What caused the financial crysis after the revolutionary war?', 'What caused the finacial crisis after the revolutionary war?', 'Who was the reason of the finanical crisi?', 'What was the crisis after the revolutionary war caused by?', 'What was the cause for the financial crisis after the Revolutionary war ended?', 'What caused a financial crisis after Revolutionary War?', 'What were some of the financial crisis after the revolutionary war?', 'After the revolutionary war what was the financial crisis called?', 'What causes energy crisi?', 'What was the cause of the financial crisis after the Revolutionary War?', 'What caused the3 finacial crisis after the revolutionary war?', 'Who in the Revolutionary War played a critical role in the financial stability of the us?', 'What caused the financial crisis after the Revoluionary War?', 'What caused the financial after the revolutionary war?', 'A militiaman during the revolutionary war he played a critical role in establishing the financial stability of the US?', 'What caused the financial crisis after the rev war?', 'What caused the financial crisi after the revolutionary war?', 'What were the causes for the financial crisis after the revolutionary war?', 'What caused the economic depression after the revolutionary war?', 'Why was there a financial crisis after the revolutionary war?', 'What caused the finicial crisis after the revulotionary war?', 'How can a revolutionary war be caused?', 'How was the fincial crisis caused after the revolutionary war?']}\n",
            "{'set': ['Regulations to make a major port?', 'What are the major ports of jamaica?', 'What is major port?']}\n",
            "{'set': ['Where did most of the people in islam live?', 'What are the countries in which the islam worshippers live today?', 'Where do most Islam people live that follow the religion?', 'Where do people who follow islam live today?', 'Where do people who follow islam come from?', 'Where do most adherents of islam live today?', 'Where do the islam people live?', 'Where do most of the people who follow Shintoism Live?', 'Where are the people form that follow islam?', 'Where would most islam people live?', 'Where do most Islam believers live today?', 'Where do islams mostly live today?', 'How do people live in Islam?', 'In what part of the world do islam belivers live today?', 'Most islam people live in?', 'What coutries is Islam worshippers live today?', 'Where do the people who speak islam live?', 'Which country do most islam people live in?', 'Where do the followers of Islam live today?', 'What Countries follow Islam today?', 'How many people live in islam?', 'Why do many people study islam today?', 'Where are the most people that follow islam?', 'Where do people that believe in islam live?', 'What country do people live in that are Islam?', 'How many people follow the Islam faith today?', 'How do people in Islam live?', 'What nations follow Islam today?']}\n",
            "{'set': ['What is the origin of the termjim crow?', 'The meaning of jim Crow?', 'Jim crow law result?', 'Where did the name jim crow orginate?', 'Where did Jim Crow exist?', 'Why is it called jim crow?', 'Jim crow origin?', 'Where did jim crow originate from?', 'What was the origin of Jim Crow law?', 'What is the origin of the term jim Cro?', 'Origin of the reference to jim crow?', \"What is the origin of the term '' jim crow''?\", 'Jim crow was reffering to?', 'What sparked jim crow?', 'Who fought against jim crow and its effects?', \"Who coined the name 'Jim Crow'?\", 'How did they get the name Jim Crow?', 'Origin of the expression Jim Crow?', 'Who named jim crow as the system?', 'What is the origin of Jim Crow?', 'Jim crow is a nickname for?', 'Which is the origin of the term jim crow?', 'Where did they get the name jim crow?', 'Where the the term jim crow originated from?', 'When did Jim Crow appear?', \"What is the origin of the term ''Jim Crow ''?\", 'The term Jim Crow most likely came from who?', 'Who invented the name Jim Crow?', 'Who gave jim crow to the system?', 'What is the origin of the ter jim crow?', 'What is the oringin of the term Jim Crow?', 'What does jim crow refer too?', 'Origin of the term jim crow?', 'What is the origin of the name jim crow?', 'What was the origin of jim crow?', \"What is the origin of the trem'' jim crow''?\", 'What was the origin of the title Jim Crow?', \"What is the origin of the term 'jim crow'?\", 'Origin of the name Jim Crow?', 'Origin of jim crow?']}\n",
            "{'set': ['What is the origin of the termjim crow?', 'The meaning of jim Crow?', 'Jim crow law result?', 'Where did the name jim crow orginate?', 'Where did Jim Crow exist?', 'Why is it called jim crow?', 'Jim crow origin?', 'Where did jim crow originate from?', 'What was the origin of Jim Crow law?', 'What is the origin of the term jim Cro?', 'Origin of the reference to jim crow?', \"What is the origin of the term '' jim crow''?\", 'Jim crow was reffering to?', 'What sparked jim crow?', 'Who fought against jim crow and its effects?', \"Who coined the name 'Jim Crow'?\", 'How did they get the name Jim Crow?', 'Origin of the expression Jim Crow?', 'Who named jim crow as the system?', 'What is the origin of Jim Crow?', 'Jim crow is a nickname for?', 'Which is the origin of the term jim crow?', 'Where did they get the name jim crow?', 'Where the the term jim crow originated from?', 'When did Jim Crow appear?', \"What is the origin of the term ''Jim Crow ''?\", 'The term Jim Crow most likely came from who?', 'Who invented the name Jim Crow?', 'Who gave jim crow to the system?', 'What is the origin of the ter jim crow?', 'What is the oringin of the term Jim Crow?', 'What does jim crow refer too?', 'Origin of the term jim crow?', 'What is the origin of the name jim crow?', 'What was the origin of jim crow?', \"What is the origin of the trem'' jim crow''?\", 'What was the origin of the title Jim Crow?', \"What is the origin of the term 'jim crow'?\", 'Origin of the name Jim Crow?', 'Origin of jim crow?']}\n",
            "dict_keys(['set'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data as torch_data\n",
        "from rank_bm25 import BM25Okapi\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "RHB8cc5SmXFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_webglmqa(x):\n",
        "    x['query']=x['question']\n",
        "    x['positives'] = [x['answer']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_PAQ_pairs(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_finance_alpaca(x):\n",
        "    x['query'] = x['instruction']\n",
        "    x['positives'] = [x['output']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_wiki_qa(x):\n",
        "    x['query'] = x['question']\n",
        "    is_pos = x['label']\n",
        "    answer = x['answer']\n",
        "    pos = [answer] if is_pos else []\n",
        "    neg = [answer] if (not is_pos) else []\n",
        "    x['positives'] = pos\n",
        "    x['negatives'] = neg\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_stream_oa_stackexchange(x):\n",
        "    x['query'] = x['INSTRUCTION']\n",
        "    x['positives'] = [x['RESPONSE']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "def filter_os_stackexchange(x):\n",
        "    return x['SOURCE'] not in [\n",
        "        'stackexchange-japanese','stackexchange-math','stackexchange-ru_stackoverflow',\n",
        "        \"stackexchange-portuguese\",\"stackexchange-chinese\",\n",
        "        'stackexchange-french',\n",
        "        'stackexchange-russian',\n",
        "        'stackexchange-spanish',\n",
        "        'stackexchange-korean',\n",
        "        'stackexchange-ukrainian',\n",
        "        'stackexchange-italian',\n",
        "        'stackexchange-german',\n",
        "        'stackexchange-es_stackoverflow',\n",
        "        'stackexchange-esperanto',\n",
        "        'stackexchange-rus',\n",
        "        'stackexchange-ja_stackoverflow',\n",
        "        'stackexchange-pt_stackoverflow',\n",
        "    ]\n",
        "\n",
        "def get_name_and_description_eclassTrainST(text):\n",
        "    description, name = text.split(\"; Name:\")\n",
        "    return description.replace(\"Description: \",\"\").strip(), name.strip()\n",
        "\n",
        "def clean_eclassTrainST(x):\n",
        "    \"\"\"This set isn't really about entailment/contradiction; it is really a dictionary\"\"\"\n",
        "    description, name = get_name_and_description_eclassTrainST(x['text'])\n",
        "    pos, _ = get_name_and_description_eclassTrainST(x['entailment'])\n",
        "    extra, _ = get_name_and_description_eclassTrainST(x['contradiction'])\n",
        "    x['query'] = 'What is a \"%s\"?' % name\n",
        "    x['positives'] = [pos]\n",
        "    # add the entailment as positive, contradiction as negatives\n",
        "    if x['label'] == 'entailment':\n",
        "        x['positives'].append(extra)\n",
        "    else:\n",
        "        x['negatives'] = [extra]\n",
        "    x['type'] = 'qa_triplet'\n",
        "    return x\n",
        "\n",
        "#dict_keys(['question_id', 'question', 'document_title', 'answer', 'label'])\n",
        "qa_streaming_cleaning_functions = {\n",
        "    'embedding-data/PAQ_pairs':(clean_stream_PAQ_pairs,None, ['query','positives','negatives'],['set']),\n",
        "    'gbharti/finance-alpaca':(clean_stream_finance_alpaca,None, ['query','positives','negatives'],['input', 'output', 'text', 'instruction']),\n",
        "    'wiki_qa':(clean_stream_wiki_qa, None, ['query','positives','negatives'],['question_id', 'question', 'document_title', 'answer', 'label']),\n",
        "    'donfu/oa-stackexchange':(clean_stream_oa_stackexchange, filter_os_stackexchange, ['query','positives','negatives'], ['INSTRUCTION', 'RESPONSE', 'SOURCE', 'METADATA']),\n",
        "    'gart-labor/eclassTrainST':(clean_eclassTrainST, None, ['query','positives','negatives'], ['text', 'entailment', 'contradiction', 'label']),\n",
        "    'THUDM/webglm-qa':( clean_webglmqa, None, ['query','positives','negatives'], ['question','answer','references']),\n",
        "    }\n",
        "\n",
        "qa_files = [\n",
        "    ('embedding-data/PAQ_pairs',None, 0.1, 7.29*10**6, 'qa_triplet'), # wikipedia pop culture pairs # get from 'set'\n",
        "    ('gbharti/finance-alpaca',None, 0.1, 6.89*10**5, 'qa_triplet'), # Stanford's Alpaca (https://github.com/tatsu-lab/stanford_alpaca) and FiQA (https://sites.google.com/view/fiqa/) with another 1.3k pairs custom generated using GPT3.5\n",
        "    ('wiki_qa',None, 0.1, 20.4*10**3, 'qa_triplet'), # Wiki Question Answering corpus from Microsoft. with multiple negatives that are similar!\n",
        "    ('donfu/oa-stackexchange',None, 0.1, 1600000, 'qa_triplet'), # stack-exchange question-answer pairs, across lots of domains; notice the original is 3.3 million, but there is a filter\n",
        "    ('gart-labor/eclassTrainST', None, 0.02, 699000, 'qa_triplet'), # questions about trade / business stuff\n",
        "    ('THUDM/webglm-qa', None, 0.1, 43600, 'qa_triplet'),\n",
        "]\n",
        "\n",
        "qadata_streaming_config = {\n",
        "    'files':qa_files,\n",
        "    'max_seq_length':512,\n",
        "    'prepend_q': 'query: ',\n",
        "    'prepend_a': 'passage: ',\n",
        "    'val_size':100,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}\n",
        "\n",
        "def initialize_qa_streaming_datasets(data_streaming_config, streaming_cleaning_functions):\n",
        "    files = data_streaming_config['files']\n",
        "    qa_streaming_datsets, qa_probabilities, qa_datasizes = [],[],[]\n",
        "    for (qa_nm, set_nm, prob, dataset_size, special_handling) in files:\n",
        "\n",
        "        if prob ==0:\n",
        "            continue\n",
        "        # get cleaning & filter functions for streaming data / map & filters\n",
        "        clean_func, filter_func, feature_names, removefeature_names = streaming_cleaning_functions[qa_nm]\n",
        "\n",
        "        # arguments for the load_dataset (huggingface repos)\n",
        "        load_dataset_args = {\n",
        "            'path':qa_nm, 'name':set_nm, 'split':'train', 'streaming':True\n",
        "        }\n",
        "        # for other non-huggingface repos, path needs to be a \"builder\"\n",
        "        if qa_nm.endswith('.jsonl') or qa_nm.endswith('.jsonl.zip'):\n",
        "            load_dataset_args.update({'path':'json','data_files':qa_nm})\n",
        "\n",
        "        print('trying %s' % qa_nm)\n",
        "        if filter_func is None:\n",
        "            dset_stream = load_dataset(**load_dataset_args).map(clean_func).remove_columns(removefeature_names)\n",
        "        else:\n",
        "            dset_stream = load_dataset(**load_dataset_args).filter(filter_func).map(clean_func).remove_columns(removefeature_names)\n",
        "\n",
        "        qa_streaming_datsets.append(dset_stream)\n",
        "        qa_probabilities.append(prob);\n",
        "        qa_datasizes.append(dataset_size)\n",
        "\n",
        "    print('done initializing the QA streaming datasets')\n",
        "    return qa_streaming_datsets, qa_probabilities, qa_datasizes\n",
        "\n",
        "def streaming_skip(skip, list_of_streaming_datasets, probabilities, datasizes, seed=42, convert_to_static = False):\n",
        "    \"\"\"Function loops through a list of streaming datasets, skips a first K values based on the probabilities, and returns them\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for dset, p, size in list_of_streaming_datasets, normalized_p, datasizes:\n",
        "        skip_in_this_set = max(0,int(p)*skip)\n",
        "        out.append(dset.skip(skip_in_this_set))\n",
        "    return out\n",
        "\n",
        "def streaming_take(skip, start_proportion, chunksize, list_of_streaming_datasets, probabilities, datasizes,  convert_to_static = False):\n",
        "    \"\"\"Takes some examples based on a starting point within the dataset, as a proportion of its total size\"\"\"\n",
        "    out = []\n",
        "    normalized_p = [p/sum(probabilities) for p in probabilities]\n",
        "    for j, (dset, p, size) in enumerate(zip(list_of_streaming_datasets, normalized_p, datasizes)):\n",
        "        #print(type(dset))\n",
        "        #print(type(p))\n",
        "        #print(type(size))\n",
        "        # skip for valset\n",
        "        skip_in_this_set = int(round(p*skip))\n",
        "        # afterwards, where to start?\n",
        "        skip_to_start = int(start_proportion*(size-skip_in_this_set))\n",
        "        take_from_this_set = int(round(chunksize*p))\n",
        "        if skip_to_start>0:\n",
        "            dset_skipped = dset.skip(skip_in_this_set+skip_to_start).take(take_from_this_set)\n",
        "        else:\n",
        "            dset_skipped = dset.take(take_from_this_set)\n",
        "\n",
        "        if not convert_to_static:\n",
        "            # option to return the streaming dataset\n",
        "            out.append(dset_skipped)\n",
        "        else:\n",
        "            # option just to convert the streaming dataset to static outputs\n",
        "            for example in dset_skipped:\n",
        "                example['source_id'] = j\n",
        "                out.append(example)\n",
        "        print('done %d' % j)\n",
        "    return out\n",
        "\n",
        "def train_test_splits_from_stream_qa(\n",
        "    streaming_dataset,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    path_to_val_cache = 'val_qa_cache.pkl',\n",
        "    probabilities = None,\n",
        "    datasizes = None,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"\n",
        "    val_size = 2000, number of streaming-iter to skip, reserved for the val-sze\n",
        "    epoch = 0, epoch will change the seed when sampling the chunk idx for making the training set\n",
        "    chunk_size = 5000, # number of streaming-iter to select the training data chunk\n",
        "    max_chunk_start = 2000000, # randomly sample within this interval for streaming chunks\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path_to_val_cache):\n",
        "        print('RELOADING VAL-QA SET: iter=%s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'rb') as pcon:\n",
        "            val_corpus_list = pickle.load(pcon)\n",
        "        print('VAL-QA SET SIZE: %d' % len(val_corpus_list))\n",
        "    else:\n",
        "        # stream validation set\n",
        "        print('STREAMING VAL-QA DATA: %d' % val_size)\n",
        "        val_corpus_list = streaming_take(\n",
        "            skip=0,\n",
        "            start_proportion=0,\n",
        "            chunksize=val_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "        print('REALIZED VAL-QA DATA: %d' % len(val_corpus_list))\n",
        "        # save the validation corpus\n",
        "        print('SAVING VAL-QA SET: %s' % path_to_val_cache)\n",
        "        with open(path_to_val_cache,'wb') as pcon:\n",
        "            pickle.dump(val_corpus_list, pcon)\n",
        "\n",
        "    # take a random interger to start the streaming of training data\n",
        "    # starts at a random position\n",
        "    train_start_proportion = np.random.RandomState(seed + epoch).random()*0.99\n",
        "    print(train_start_proportion)\n",
        "\n",
        "    # stream training data\n",
        "    print('STREAMING TRAIN QA-DATA: %d STARTING AT: %0.3f' % (chunk_size,train_start_proportion))\n",
        "    train_corpus_list = streaming_take(\n",
        "            skip=val_size,\n",
        "            start_proportion=train_start_proportion,\n",
        "            chunksize=chunk_size,\n",
        "            list_of_streaming_datasets=streaming_dataset,\n",
        "            probabilities=probabilities,\n",
        "            datasizes=datasizes,\n",
        "            convert_to_static = True\n",
        "        )\n",
        "\n",
        "    print('REALISED TRAIN QA-DATA SIZE: %d' % len(train_corpus_list))\n",
        "    return {\n",
        "        'train':train_corpus_list,\n",
        "        'val':val_corpus_list,\n",
        "        'epoch':0,\n",
        "        'index_stream':train_start_proportion\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "class DatasetTriplets(torch_data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        list_of_data=None,\n",
        "        n_negatives= 3,\n",
        "        topk_negatives_discard = 6, # get top kth most-similar results, discard first k, to use as negative\n",
        "        focal_text_name ='query',\n",
        "        positives_text_name ='positives',\n",
        "        negativess_text_name ='negatives',\n",
        "        seed = 32,\n",
        "        label_processor_class = None # (optional) function to process negatives\n",
        "    ):\n",
        "        self.n_negatives = n_negatives\n",
        "        self.topk_negatives_discard = topk_negatives_discard\n",
        "        self.data = {}\n",
        "        self.focal_text_name =focal_text_name\n",
        "        self.positives_text_name = positives_text_name\n",
        "        self.negativess_text_name = negativess_text_name\n",
        "        self.seed = 42\n",
        "        self.random = np.random.RandomState(self.seed)\n",
        "        self.label_processor_class = label_processor_class\n",
        "\n",
        "        if list_of_data is not None and len(list_of_data)>0:\n",
        "\n",
        "            # loop through the data and add each triplets: export a panda df as final data\n",
        "            self.df = self.process(list_of_data)\n",
        "\n",
        "    def process(self, list_of_data):\n",
        "        \"\"\"Makes (query,pos,neg)-triplets, converts samples to dataframe for pytorch iteration\"\"\"\n",
        "\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(\n",
        "            list_of_data = list_of_data\n",
        "        )\n",
        "\n",
        "        # add positives to self.data\n",
        "        self._find_positives_and_add_to_data()\n",
        "\n",
        "        # add negatives to self.data\n",
        "        self._find_negatives_and_add_to_data()\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        df = self.sample_data_and_make_static_dataframe(self.data)\n",
        "        return df\n",
        "\n",
        "    def _loop_through_list_of_data_and_add_to_selfdata(\n",
        "        self,\n",
        "        list_of_data\n",
        "    ):\n",
        "        \"\"\"loops through and adds the positive/focal texts and negatives\"\"\"\n",
        "        for raw_example in list_of_data:\n",
        "            # add each element to the data\n",
        "            self._add_triplet_to_data(\n",
        "                focal_texts=raw_example[self.focal_text_name],\n",
        "                positve_texts=raw_example[self.positives_text_name],\n",
        "                negative_texts=raw_example[self.negativess_text_name],\n",
        "            )\n",
        "        self.focal_texts_as_keys = list(self.data.keys())\n",
        "\n",
        "    def _add_triplet_to_data(\n",
        "        self,\n",
        "        focal_texts,\n",
        "        positve_texts,\n",
        "        negative_texts\n",
        "    ):\n",
        "        \"\"\"add focal text to the data\"\"\"\n",
        "        do_add_focals = False\n",
        "        if isinstance(focal_texts,list):\n",
        "            focal_text = sort(focal_texts)[0]\n",
        "            do_add_focals = True\n",
        "        elif isinstance(focal_texts, str):\n",
        "            focal_text = focal_texts\n",
        "        if focal_text not in self.data.keys():\n",
        "            self.data[focal_text] = {'positives':[], 'negatives':[]}\n",
        "        self.data[focal_text]['positives'] += [p for p in positve_texts if p not in self.data[focal_text]['positives']]\n",
        "        #if negative_texts is None:\n",
        "        #    print(focal_texts)\n",
        "        #    print(positve_texts)\n",
        "        #    print(negative_texts)\n",
        "        self.data[focal_text]['negatives'] += negative_texts if (negative_texts is not None) else []\n",
        "        if do_add_focals:\n",
        "            self.data[focal_text]['positives'] += focal_texts[1:]\n",
        "\n",
        "    def _build_corpus_of_potential_negatives(self):\n",
        "        potential_corpus = [\n",
        "            self.data[k]['positives'][:1] for k in self.focal_texts_as_keys\n",
        "        ]\n",
        "        potential_corpus = [\n",
        "            'NEGATIVE' if (not bool(s)) else s[0] for s in potential_corpus\n",
        "        ]\n",
        "        tokenized_corpus = [s.lower().split(\" \") for s in potential_corpus]\n",
        "        bm25 = BM25Okapi(tokenized_corpus)\n",
        "        return {'bm25':bm25, 'corpus':potential_corpus}\n",
        "\n",
        "    def _find_negative(\n",
        "        self,\n",
        "        focal_text_as_query,\n",
        "        positive_examples=None,\n",
        "        use_focal_text = True,\n",
        "        use_positives=True,\n",
        "        bm25_corpus=None,\n",
        "        corpus = None\n",
        "    ):\n",
        "        \"\"\"Given a query, uses BM25 to find similar but wrong answers, to serve as triplet negatives; for a single query\"\"\"\n",
        "        bmquery = (focal_text_as_query if use_focal_text else \"\") + \" \" + (\"\" if (not use_positives) else positive_examples[0])\n",
        "        bmquery = bmquery.strip()\n",
        "        bmquery_tokenized = bmquery.lower().split(\" \")\n",
        "        top_results = bm25_corpus.get_top_n(bmquery_tokenized, corpus, n=self.topk_negatives_discard + self.n_negatives)\n",
        "        top_results = [\n",
        "            s for s in top_results\n",
        "            if (\n",
        "                s not in positive_examples+[focal_text_as_query]\n",
        "            )\n",
        "        ]\n",
        "        # remove any text that is equivalent to the query / focal texts\n",
        "        potential_negatives = top_results[-1*self.n_negatives:]\n",
        "        return potential_negatives\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"For data that has a label, this can be used to artifically find and create synthetic positives\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "        \"\"\"Uses BM25 to find similar but wrong answers, to serve as triplet negatives; loop over data\"\"\"\n",
        "\n",
        "        # build bm25 corpus\n",
        "        bm25_corpus = self._build_corpus_of_potential_negatives()\n",
        "\n",
        "        # loop through data, find examples which don't have negatives\n",
        "        for k,d in self.data.items():\n",
        "            if not bool(d['negatives']):\n",
        "                negatives = self._find_negative(\n",
        "                    focal_text_as_query=k,\n",
        "                    positive_examples=d['positives'],\n",
        "                    use_focal_text = True,\n",
        "                    use_positives=bool(d['positives']),\n",
        "                    bm25_corpus=bm25_corpus['bm25'],\n",
        "                    corpus = bm25_corpus['corpus']\n",
        "                )\n",
        "                d['negatives']+= negatives\n",
        "        print('done finding negatives')\n",
        "\n",
        "    def sample_data_and_make_static_dataframe(self, seed = 42):\n",
        "        focals =[]\n",
        "        pos =[]\n",
        "        neg = []\n",
        "        for query,d in self.data.items():\n",
        "            for j in range(min(self.n_negatives, len(d['negatives']))):\n",
        "                if len(d['positives'])==0:\n",
        "                    continue\n",
        "                elif len(d['positives'])==1:\n",
        "                    pos+=d['positives']\n",
        "                elif len(d['positives'])>1:\n",
        "                    pos.append(self.random.choice(d['positives']))\n",
        "                neg.append(d['negatives'][j])\n",
        "                focals.append(query)\n",
        "        df = pd.DataFrame({'query':focals, 'pos':pos, 'neg':neg})\n",
        "        return df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        #key = self.focal_texts_as_keys[idx]\n",
        "        #return {**{'query':key}, **self.data[key]}\n",
        "        return self.df.iloc[idx].to_dict()\n",
        "\n"
      ],
      "metadata": {
        "id": "ABJazLSA3WTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# intialize the qa streaming dataset (QA)\n",
        "qa_streaming_datsets, qa_probabilities, qa_datasizes = initialize_qa_streaming_datasets(\n",
        "    qadata_streaming_config,\n",
        "    qa_streaming_cleaning_functions\n",
        ")\n",
        "\n",
        "qa_statics_datsets = train_test_splits_from_stream_qa(\n",
        "    streaming_dataset=qa_streaming_datsets,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 500,#6000,\n",
        "    path_to_val_cache = 'val_qa_cache.pkl',\n",
        "    probabilities = qa_probabilities,\n",
        "    datasizes = qa_datasizes,\n",
        "    seed=qadata_streaming_config['seed']\n",
        ")\n",
        "\n",
        "if False:\n",
        "    # starts at a random position\n",
        "    datasets_static_qa_val = streaming_take(\n",
        "        skip=0,\n",
        "        start_proportion=0,\n",
        "        chunksize=100,\n",
        "        list_of_streaming_datasets=qa_streaming_datsets,\n",
        "        probabilities=qa_probabilities,\n",
        "        datasizes=qa_datasizes,\n",
        "        convert_to_static = True\n",
        "\n",
        "    )\n",
        "\n",
        "    epoch = 0\n",
        "    # starts at a random position\n",
        "    train_start_proportion = np.random.RandomState(qadata_streaming_config['seed'] + epoch).random()*0.99\n",
        "    print(train_start_proportion)\n",
        "\n",
        "    # take: training chunk random for this epoch\n",
        "    datasets_static_qa_train = streaming_take(\n",
        "        skip=100,\n",
        "        start_proportion=train_start_proportion,\n",
        "        chunksize=400,\n",
        "        list_of_streaming_datasets=qa_streaming_datsets,\n",
        "        probabilities=qa_probabilities,\n",
        "        datasizes=qa_datasizes,\n",
        "        convert_to_static = True\n",
        "    )\n",
        "\n",
        "    datasets_static_qa = train_test_splits_from_stream_qa(\n",
        "        datasets_mlm_streaming_combined,\n",
        "        val_size = data_streaming_config['val_size'],#2000,\n",
        "        epoch = 0,\n",
        "        chunk_size =  data_streaming_config['train_chunk_size'],#6000,\n",
        "        max_chunk_start = data_streaming_config['max_chunk_start'],#1000000,\n",
        "        path_to_val_cache = 'val_qacache.pkl'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559,
          "referenced_widgets": [
            "7ecd72edd7024c928abac93cca7633c9",
            "8551a294d6e848ebb3e2cc651b3daa0b",
            "1fc36937c6ec496a9cd3f1cf39066ffb",
            "c534ba27943d4cd1ab04746e895ac394",
            "baf63ae6960f4d68be5aecdb9aa285de",
            "833d0bdc1ba84115b85199198e56cfe4",
            "e9e8213df9624001b14d925b82018b99",
            "fddd931718714d54a2a1b310f5de2beb",
            "71d79fe8de5045efb2d6f5e9653de71e",
            "c768181aa5d140cf804d4aeafbfd103e",
            "0f78dfdff85f43638d7c07b394f340a8",
            "28c201d8b4d84b47977726d6bbffced2",
            "2a611080cabe463a8c156fb797eac504",
            "9094d7253c00453f9984521104809c7e",
            "f8b4a2c6d17040c49c4aaf3c053ba88c",
            "595db8762907461dab43756c13c372d5",
            "42c05e7787e9483d9be431cb8885c4e2",
            "e51b8f78489c47a9a79c06f3eb32eda4",
            "9c983680e0824fab964e15b13402258b",
            "31efc8645d854ddf9341d0e1f4540826",
            "b3949e84ade442c1828471ba0849df8a",
            "c2b28a56c22b4f46a702530a3d7ae9f8",
            "8f4ff0b97afc49c5a65c3b5ef5656099",
            "66a7ef4424c34441acc2b4201cc1d14f",
            "95e81df782f94757805a169b734611ec",
            "54d1564c13ef43dc9b5c97522c5973d8",
            "3738f31b3ebc4c2b93a678b2b2a44350",
            "9329eedde6d14ed48ffe2ec2e4990f95",
            "e4ea814082974891ab93fd256996b7c6",
            "4f173bb5283044c484a33148e616d542",
            "56ded92e780748c8942ed7eb5ff33234",
            "aea04d2eb176424b8160e452f6a31f4f",
            "1f9fc535a10e4fcbba6b41666daf29e0",
            "c838a0bd327747a4bf1219c1b864a361",
            "f495af78544a457baedaf5f6fb0b7dce",
            "7fee84bb7d8c454bb9b4a295847a706b",
            "e01b8b277f2a460e8388fc71f0622a07",
            "da8f5c8f27ca4dcfb9d059a139959c1a",
            "28a2b37ba339456bbba7db989e4ac67f",
            "cec8455d549246ff98bb1a568e5e5a3f",
            "1008435d5743484580aa54d74b213866",
            "ea40ab309284464fb2d1e8bf03901ed8",
            "ab81a1ae592d4a87bf394bd558629735",
            "6659194808734cda94ab339614ded0a1",
            "675e4bba675f4add809495c61a69ffd7",
            "1af85f5380a349f29d9260a216ffbeba",
            "35fa4715503b4b2aa5fab358f64d1f34",
            "7a9e6cd46a5843b189f63c45e57e9496",
            "9b179ae2db3044db97c466a74243cf50",
            "8075f31cedc24f979cf1a057575edc65",
            "e47fb85db6f84544a79c4f5b9dad4ae0",
            "49a1dbbd108646e594c7afb4ecd864be",
            "fe0b1080f0d74ff681a6529d046a4932",
            "bcae0738b6cf40c4bab01e512adc18b1",
            "f0742346b8bf4022a9583f5258c6a63f"
          ]
        },
        "id": "lVO8t6irLjYO",
        "outputId": "1ff3f26e-2dbe-4414-8126-2abc00cbb4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying embedding-data/PAQ_pairs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.41k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ecd72edd7024c928abac93cca7633c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying gbharti/finance-alpaca\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/486 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28c201d8b4d84b47977726d6bbffced2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying wiki_qa\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/3.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f4ff0b97afc49c5a65c3b5ef5656099"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c838a0bd327747a4bf1219c1b864a361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/13.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "675e4bba675f4add809495c61a69ffd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying donfu/oa-stackexchange\n",
            "trying gart-labor/eclassTrainST\n",
            "done initializing the QA streaming datasets\n",
            "STREAMING VAL-QA DATA: 100\n",
            "done 0\n",
            "done 1\n",
            "done 2\n",
            "done 3\n",
            "done 4\n",
            "REALIZED VAL-QA DATA: 101\n",
            "SAVING VAL-QA SET: val_qa_cache.pkl\n",
            "0.3707947176588889\n",
            "STREAMING TRAIN QA-DATA: 500 STARTING AT: 0.371\n",
            "done 0\n",
            "done 1\n",
            "done 2\n",
            "done 3\n",
            "done 4\n",
            "REALISED TRAIN QA-DATA SIZE: 381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,e in enumerate(qa_statics_datsets['val']):\n",
        "    if i<20:\n",
        "        continue\n",
        "    print(\"-------\\nQ:%s\\nA:%s\" % (e['query'], e['positives'][0].replace(\"\\n\",\" \") if bool(e['positives']) else e['negatives'][0].replace(\"\\n\",\" \")))\n"
      ],
      "metadata": {
        "id": "HotkvzyKC0m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFH_5u9q9EW4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "qa_torchdataset_val = DatasetTriplets(\n",
        "    list_of_data = qa_statics_datsets['val'],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        ")\n",
        "qa_torchdataset_train = DatasetTriplets(\n",
        "    list_of_data = qa_statics_datsets['train'],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Vmko2SmxHe",
        "outputId": "ed45d96b-dbed-4b60-a7d7-0983945a7ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done finding negatives\n",
            "{'positives': [], 'negatives': ['In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.', 'It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.', 'The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.', 'The equations of motion describe the movement of the center of mass of a body.', 'Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.', \"Since the object's velocity vector is constantly changing direction, the moving object is undergoing acceleration by a centripetal force in the direction of the center of rotation.\", \"Without this acceleration, the object would move in a straight line, according to Newton's laws of motion .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.', 'It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.', 'The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.', 'The equations of motion describe the movement of the center of mass of a body.', 'Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.', \"Since the object's velocity vector is constantly changing direction, the moving object is undergoing acceleration by a centripetal force in the direction of the center of rotation.\", \"Without this acceleration, the object would move in a straight line, according to Newton's laws of motion .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In physics , circular motion is a movement of an object along the circumference of a circle or rotation along a circular path.', 'It can be uniform, with constant angular rate of rotation (and constant speed), or non-uniform with a changing rate of rotation.', 'The rotation around a fixed axis of a three-dimensional body involves circular motion of its parts.', 'The equations of motion describe the movement of the center of mass of a body.', 'Examples of circular motion include: an artificial satellite orbiting the Earth at constant height, a stone which is tied to a rope and is being swung in circles, a car turning through a curve in a race track , an electron moving perpendicular to a uniform magnetic field , and a gear turning inside a mechanism.', \"Since the object's velocity vector is constantly changing direction, the moving object is undergoing acceleration by a centripetal force in the direction of the center of rotation.\", \"Without this acceleration, the object would move in a straight line, according to Newton's laws of motion .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Apollo Creed is a fictional character from the Rocky films , initially portrayed as the Undisputed Heavyweight Champion of the World.', 'He was played by Carl Weathers .', 'Creed had multiple nicknames, including The Master of Disaster, The King of Sting, The Dancing Destroyer, The Prince of Punch, The One and Only and The Count of Monte Fisto.', \"Urban legend states that Apollo Creed's name is a wordplay on the Apostles' Creed , a statement of belief used in Christian churches.\", \"All of Apollo's championship fights were scheduled for the 15 round distance.\", 'Championship fights did not convert from 15 rounds to 12 rounds until 1987.', 'Rocky Balboa is often wrongly credited with popularizing the red, white, and blue trunks; Creed was the first man to wear them (latterly worn by Rocky Balboa in the 3rd and 4th installments and finally by Tommy \"The Machine\" Gunn ( Tommy Morrison ) in the 5th installment) although normally he wore red and white, as seen in Rocky II.', \"Balboa's signature colors were black and gold—colors he used in the latest movie .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Apollo Creed is a fictional character from the Rocky films , initially portrayed as the Undisputed Heavyweight Champion of the World.', 'He was played by Carl Weathers .', 'Creed had multiple nicknames, including The Master of Disaster, The King of Sting, The Dancing Destroyer, The Prince of Punch, The One and Only and The Count of Monte Fisto.', \"Urban legend states that Apollo Creed's name is a wordplay on the Apostles' Creed , a statement of belief used in Christian churches.\", \"All of Apollo's championship fights were scheduled for the 15 round distance.\", 'Championship fights did not convert from 15 rounds to 12 rounds until 1987.', 'Rocky Balboa is often wrongly credited with popularizing the red, white, and blue trunks; Creed was the first man to wear them (latterly worn by Rocky Balboa in the 3rd and 4th installments and finally by Tommy \"The Machine\" Gunn ( Tommy Morrison ) in the 5th installment) although normally he wore red and white, as seen in Rocky II.', \"Balboa's signature colors were black and gold—colors he used in the latest movie .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Apollo Creed is a fictional character from the Rocky films , initially portrayed as the Undisputed Heavyweight Champion of the World.', 'He was played by Carl Weathers .', 'Creed had multiple nicknames, including The Master of Disaster, The King of Sting, The Dancing Destroyer, The Prince of Punch, The One and Only and The Count of Monte Fisto.', \"Urban legend states that Apollo Creed's name is a wordplay on the Apostles' Creed , a statement of belief used in Christian churches.\", \"All of Apollo's championship fights were scheduled for the 15 round distance.\", 'Championship fights did not convert from 15 rounds to 12 rounds until 1987.', 'Rocky Balboa is often wrongly credited with popularizing the red, white, and blue trunks; Creed was the first man to wear them (latterly worn by Rocky Balboa in the 3rd and 4th installments and finally by Tommy \"The Machine\" Gunn ( Tommy Morrison ) in the 5th installment) although normally he wore red and white, as seen in Rocky II.', \"Balboa's signature colors were black and gold—colors he used in the latest movie .\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In the United States, the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution .', 'In addition to the Supreme Court of the United States , whose existence and some aspects of whose jurisdiction are beyond the constitutional power of Congress to alter, acts of Congress have established 13 courts of appeals (also called \"circuit courts\") with appellate jurisdiction over different regions of the United States, and 94 United States district courts .', 'Every judge appointed to such a court may be categorized as a federal judge; such positions include the Chief Justice and Associate Justices of the Supreme Court, Circuit Judges of the courts of appeals, and district judges of the United States district courts .', 'All of these judges described thus far are referred to sometimes as \"Article III judges\" because they exercise the judicial power vested in the judicial branch of the federal government by Article III of the U.S. Constitution.', 'In addition, judges of the Court of International Trade exercise judicial power pursuant to Article III.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In the United States, the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution .', 'In addition to the Supreme Court of the United States , whose existence and some aspects of whose jurisdiction are beyond the constitutional power of Congress to alter, acts of Congress have established 13 courts of appeals (also called \"circuit courts\") with appellate jurisdiction over different regions of the United States, and 94 United States district courts .', 'Every judge appointed to such a court may be categorized as a federal judge; such positions include the Chief Justice and Associate Justices of the Supreme Court, Circuit Judges of the courts of appeals, and district judges of the United States district courts .', 'All of these judges described thus far are referred to sometimes as \"Article III judges\" because they exercise the judicial power vested in the judicial branch of the federal government by Article III of the U.S. Constitution.', 'In addition, judges of the Court of International Trade exercise judicial power pursuant to Article III.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['In the United States, the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution .', 'In addition to the Supreme Court of the United States , whose existence and some aspects of whose jurisdiction are beyond the constitutional power of Congress to alter, acts of Congress have established 13 courts of appeals (also called \"circuit courts\") with appellate jurisdiction over different regions of the United States, and 94 United States district courts .', 'Every judge appointed to such a court may be categorized as a federal judge; such positions include the Chief Justice and Associate Justices of the Supreme Court, Circuit Judges of the courts of appeals, and district judges of the United States district courts .', 'All of these judges described thus far are referred to sometimes as \"Article III judges\" because they exercise the judicial power vested in the judicial branch of the federal government by Article III of the U.S. Constitution.', 'In addition, judges of the Court of International Trade exercise judicial power pursuant to Article III.']}\n",
            "this is missing a positive example\n",
            "done finding negatives\n",
            "{'positives': [], 'negatives': ['This is an overview of the regular, recurring, and other characters of the TV series NCIS .']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Far East Movement (stylized as Far★East Movement or abbreviated FM) is an American hip hop band quartet based in Los Angeles .', 'The group formed in 2003 and consists of Kev Nish (Kevin Nishimura), Prohgress (James Roh), J-Splif (Jae Choung), and DJ Virman (Virman Coquia).', 'Far East Movement\\'s first claim to fame was their song \"Round Round\" featured in the Hollywood movie, The Fast and the Furious: Tokyo Drift , and its subsequent soundtrack , video game and DVD.', 'Since \"Round Round\", the group has been featured on various network shows including , , Entourage , Gossip Girl , and Finishing the Game (a featured film at Sundance 2007).', 'Their single \" Like a G6 \" hit number one on the Billboard Hot 100 Chart and on iTunes as well in late October 2010.', 'Far East Movement also has the distinction of being the first Asian-American group to earn a #1 hit on the Billboard Hot 100 in the United States.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Far East Movement (stylized as Far★East Movement or abbreviated FM) is an American hip hop band quartet based in Los Angeles .', 'The group formed in 2003 and consists of Kev Nish (Kevin Nishimura), Prohgress (James Roh), J-Splif (Jae Choung), and DJ Virman (Virman Coquia).', 'Far East Movement\\'s first claim to fame was their song \"Round Round\" featured in the Hollywood movie, The Fast and the Furious: Tokyo Drift , and its subsequent soundtrack , video game and DVD.', 'Since \"Round Round\", the group has been featured on various network shows including , , Entourage , Gossip Girl , and Finishing the Game (a featured film at Sundance 2007).', 'Their single \" Like a G6 \" hit number one on the Billboard Hot 100 Chart and on iTunes as well in late October 2010.', 'Far East Movement also has the distinction of being the first Asian-American group to earn a #1 hit on the Billboard Hot 100 in the United States.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['Far East Movement (stylized as Far★East Movement or abbreviated FM) is an American hip hop band quartet based in Los Angeles .', 'The group formed in 2003 and consists of Kev Nish (Kevin Nishimura), Prohgress (James Roh), J-Splif (Jae Choung), and DJ Virman (Virman Coquia).', 'Far East Movement\\'s first claim to fame was their song \"Round Round\" featured in the Hollywood movie, The Fast and the Furious: Tokyo Drift , and its subsequent soundtrack , video game and DVD.', 'Since \"Round Round\", the group has been featured on various network shows including , , Entourage , Gossip Girl , and Finishing the Game (a featured film at Sundance 2007).', 'Their single \" Like a G6 \" hit number one on the Billboard Hot 100 Chart and on iTunes as well in late October 2010.', 'Far East Movement also has the distinction of being the first Asian-American group to earn a #1 hit on the Billboard Hot 100 in the United States.']}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['U.S. debt from 1940 to 2011.', 'Red lines indicate the \"debt held by the public\" and black lines indicate the total national debt or gross public debt.', 'The difference is the \"intragovernmental debt,\" which includes obligations to government programs such as Social Security.', 'Stated as a formula, National Debt = Debt held by the Public + Intragovernmental Debt.', 'The second panel shows the two debt figures as a percentage of U.S. GDP (dollar value of U.S. economic production for that year).', 'The top panel is deflated so every year is in 2010 dollars.', 'The United States public debt is the money borrowed by the federal government of the United States through the issuing of securities by the Treasury and other federal government agencies.', 'US public debt consists of two components:', 'Debt held by the public includes Treasury securities held by investors outside the federal government, including that held by individuals, corporations, the Federal Reserve System and foreign, state and local governments.', 'Debt held by government accounts or intragovernmental debt includes non-marketable Treasury securities held in accounts administered by the federal government that are owed to program beneficiaries, such as the Social Security Trust Fund .', 'Debt held by government accounts represents the cumulative surpluses, including interest earnings, of these accounts that have been invested in Treasury securities.', 'Public debt increases or decreases as a result of the annual unified budget deficit or surplus.', 'The federal government budget deficit or surplus is the difference between government receipts and spending, ignoring intra-governmental transfers.', 'However, some spending that is excluded from the deficit (supplemental appropriations) also adds to the debt.', 'Historically, the US public debt as a share of GDP increased during wars and recessions, and subsequently declined.', 'For example, debt held by the public as a share of GDP peaked just after World War II (113% of GDP in 1945), but then fell over the following 30 years.', \"In recent decades, however, large budget deficits and the resulting increases in debt have led to concern about the long-term sustainability of the federal government's fiscal policies.\", 'On 2 April 2013, debt held by the public was approximately $11.959 trillion or about 75% of GDP.', 'Intragovernmental holdings stood at $4.846 trillion, giving a combined total public debt of $16.805 trillion.', \"As of January 2013, $5.6 trillion or approximately 47% of the debt held by the public was owned by foreign investors, the largest of which were the People's Republic of China and Japan at just over $1.1 trillion each.\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['U.S. debt from 1940 to 2011.', 'Red lines indicate the \"debt held by the public\" and black lines indicate the total national debt or gross public debt.', 'The difference is the \"intragovernmental debt,\" which includes obligations to government programs such as Social Security.', 'Stated as a formula, National Debt = Debt held by the Public + Intragovernmental Debt.', 'The second panel shows the two debt figures as a percentage of U.S. GDP (dollar value of U.S. economic production for that year).', 'The top panel is deflated so every year is in 2010 dollars.', 'The United States public debt is the money borrowed by the federal government of the United States through the issuing of securities by the Treasury and other federal government agencies.', 'US public debt consists of two components:', 'Debt held by the public includes Treasury securities held by investors outside the federal government, including that held by individuals, corporations, the Federal Reserve System and foreign, state and local governments.', 'Debt held by government accounts or intragovernmental debt includes non-marketable Treasury securities held in accounts administered by the federal government that are owed to program beneficiaries, such as the Social Security Trust Fund .', 'Debt held by government accounts represents the cumulative surpluses, including interest earnings, of these accounts that have been invested in Treasury securities.', 'Public debt increases or decreases as a result of the annual unified budget deficit or surplus.', 'The federal government budget deficit or surplus is the difference between government receipts and spending, ignoring intra-governmental transfers.', 'However, some spending that is excluded from the deficit (supplemental appropriations) also adds to the debt.', 'Historically, the US public debt as a share of GDP increased during wars and recessions, and subsequently declined.', 'For example, debt held by the public as a share of GDP peaked just after World War II (113% of GDP in 1945), but then fell over the following 30 years.', \"In recent decades, however, large budget deficits and the resulting increases in debt have led to concern about the long-term sustainability of the federal government's fiscal policies.\", 'On 2 April 2013, debt held by the public was approximately $11.959 trillion or about 75% of GDP.', 'Intragovernmental holdings stood at $4.846 trillion, giving a combined total public debt of $16.805 trillion.', \"As of January 2013, $5.6 trillion or approximately 47% of the debt held by the public was owned by foreign investors, the largest of which were the People's Republic of China and Japan at just over $1.1 trillion each.\"]}\n",
            "this is missing a positive example\n",
            "{'positives': [], 'negatives': ['U.S. debt from 1940 to 2011.', 'Red lines indicate the \"debt held by the public\" and black lines indicate the total national debt or gross public debt.', 'The difference is the \"intragovernmental debt,\" which includes obligations to government programs such as Social Security.', 'Stated as a formula, National Debt = Debt held by the Public + Intragovernmental Debt.', 'The second panel shows the two debt figures as a percentage of U.S. GDP (dollar value of U.S. economic production for that year).', 'The top panel is deflated so every year is in 2010 dollars.', 'The United States public debt is the money borrowed by the federal government of the United States through the issuing of securities by the Treasury and other federal government agencies.', 'US public debt consists of two components:', 'Debt held by the public includes Treasury securities held by investors outside the federal government, including that held by individuals, corporations, the Federal Reserve System and foreign, state and local governments.', 'Debt held by government accounts or intragovernmental debt includes non-marketable Treasury securities held in accounts administered by the federal government that are owed to program beneficiaries, such as the Social Security Trust Fund .', 'Debt held by government accounts represents the cumulative surpluses, including interest earnings, of these accounts that have been invested in Treasury securities.', 'Public debt increases or decreases as a result of the annual unified budget deficit or surplus.', 'The federal government budget deficit or surplus is the difference between government receipts and spending, ignoring intra-governmental transfers.', 'However, some spending that is excluded from the deficit (supplemental appropriations) also adds to the debt.', 'Historically, the US public debt as a share of GDP increased during wars and recessions, and subsequently declined.', 'For example, debt held by the public as a share of GDP peaked just after World War II (113% of GDP in 1945), but then fell over the following 30 years.', \"In recent decades, however, large budget deficits and the resulting increases in debt have led to concern about the long-term sustainability of the federal government's fiscal policies.\", 'On 2 April 2013, debt held by the public was approximately $11.959 trillion or about 75% of GDP.', 'Intragovernmental holdings stood at $4.846 trillion, giving a combined total public debt of $16.805 trillion.', \"As of January 2013, $5.6 trillion or approximately 47% of the debt held by the public was owned by foreign investors, the largest of which were the People's Republic of China and Japan at just over $1.1 trillion each.\"]}\n",
            "this is missing a positive example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(qa_torchdataset_train))\n",
        "qa_torchdataset_train[400]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mje7yyhqniKU",
        "outputId": "56a68779-2601-4482-b62b-7b3cfce47024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Determine Current Controller in Use for Kohana\\nWhat is the best way to determine which Controller class a Kohana application is presently using?\\n\\nExamples:\\n\\n  * ` \\\\- `_defaultControllerName_`\\n  * ` \\\\- \"frontpage\"\\n  * ` \\\\- \"contact\"',\n",
              " 'pos': '**_The following applies to Kohana 2 instances..._**\\n\\nYou can do this by using the Router library. By default, this library is located in `/system/libraries/Router.php` \\\\- go ahead and copy it into `/application/libraries` as is the standard practice for all libraries being used.\\n\\nNow, from within your application you can get the controller value from the static Router class:\\n    \\n    \\n    print Router::$controller; // outputs current Controller\\n    \\n\\nDocumentation',\n",
              " 'neg': \"No, a `StringBuilder` is a purely managed resource. You should just get rid of all references to it. Everything else is taken care of by the garbage collector:\\n    \\n    \\n    StringBuilder sb = ...;\\n    // ... do work\\n    sb = null; // or simply let it go out of scope.\\n    \\n\\nIn .NET, there's no deterministic `delete` (like C++, where you free up memory allocated to a single object.) Only GC can free memory. By forfeiting all references to an object, you'll let GC be able to deallocate the object if it wants to. You can force a garbage collection by calling the `System.GC.Collect` method. However, it's not recommended to manipulate with GC unless you really know what you are doing. GC is smart. It's rarely beneficial to force it.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A) Retrieval Tasks\n",
        "In general, what loss would I use for the QA & retrieval tasks? Distillation is obvious, but what about\n",
        "- SQUAD - has QA pairs - squad_v2\n",
        "    - good for distillation\n",
        "- ORCA - has GPT-like prompting QA pairs: https://huggingface.co/datasets/Open-Orca/OpenOrca/viewer/Open-Orca--OpenOrca/train?row=29\n",
        "- DONE Simple-Wiki https://huggingface.co/datasets/embedding-data/simple-wiki - has paraphrases\n",
        "- DONE embedding-data/coco_captions_quintets - multiple captions as paraphrases\n",
        "- DONE embedding-data/simple-wiki - pairs of paraphrases from wikipedia\n",
        "- DONE embedding-data/SPECTER - triplets of {anchor, pos, neg}, small headline-like snippets in technical /statistical /science fields\n",
        "- https://huggingface.co/embedding-data - has a lot of retrieval tasks\n",
        "- LLukas22/scidocs - titles and abstracts\n",
        "- DONE allenai/scirepeval - cite_prediction - has query,pos, neg based on citations\n",
        "- DONE - LEDGAR - can possible do triplets on same label\n",
        "- Rahmaa/ElsevieR_ClEaN - possible relation between title and abstract\n",
        "- embedding-data/WikiAnswers - 25 question paraphrases (maybe no answers)\n",
        "- cnn_dailymail - summarization possiblility 287k (beware |||?)\n",
        "- multi_news - another summarization 45k (beware |||?)\n",
        "- DONE xsum - BBC extreme summarization 204k\n",
        "- DONE lighteval/legal_summarization - legal summization of bills (BillSum 18.8k)\n",
        "-\n"
      ],
      "metadata": {
        "id": "X_ZSsSvhIBMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#foo =  load_dataset(\"embedding-data/simple-wiki\",split='train',streaming=True)\n",
        "#foo =  load_dataset(\"embedding-data/coco_captions_quintets\",split='train',streaming=True).take(2000)\n",
        "#foo =  load_dataset(\"embedding-data/SPECTER\",split='train',streaming=True)\n",
        "#foo = load_dataset(**{'path': 'embedding-data/SPECTER', 'name':None, 'split':'train', 'streaming':True})\n",
        "#foo =  load_dataset(\"paws\",'labeled_final',split='train',streaming=True)\n",
        "#foo =  load_dataset(\"embedding-data/QQP_triplets\",None,split='train',streaming=True)\n",
        "#foo =  load_dataset(\"\",None,split='train',streaming=True)\n",
        "#foo =  load_dataset(\"\",None,split='train',streaming=True)\n",
        "#foo = load_dataset(\"allenai/scirepeval\", 'cite_prediction',None, split='train',streaming=True)\n",
        "# foo = load_dataset(**{'path': 'allenai/scirepeval', 'name':'cite_prediction', 'split':'train', 'streaming':True})\n",
        "#foo = load_dataset('json', data_files=\"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", split=\"train\", streaming=False)\n",
        "#foo = load_dataset(**{'path': 'json', 'name':None, 'data_files':'https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip', 'split':'train', 'streaming':True})\n",
        "foo =  load_dataset(\"lighteval/legal_summarization\",\"BillSum\",split='train',streaming=True)\n",
        "\n",
        "if True:\n",
        "    # embedding-data/WikiAnswers\n",
        "    for j,e in enumerate(foo):\n",
        "        print(e)\n",
        "        #print(len(e['set']))\n",
        "        if j > 100:\n",
        "            break\n",
        "    print(e.keys())"
      ],
      "metadata": {
        "id": "yqTVMjmNIWpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def clean_legalsum(x):\n",
        "    MAX_CHAR_LEN_BILLSUM = int(6.7*600)\n",
        "    text = x['article'][:MAX_CHAR_LEN_BILLSUM]\n",
        "    if 'SEC. 2.' in text:\n",
        "        text = \".\".join(text.split('SEC. 2.')[1].split('.')[1:])\n",
        "    else:\n",
        "        if 'SHORT TITLE' in text:\n",
        "             text = text.split('SHORT TITLE')[1]\n",
        "    x['query'] = x['summary']\n",
        "    x['positives'] = [text.strip()]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_xsum(x):\n",
        "    x['query'] = x['summary']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = [x['document']]\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_eurlex(x):\n",
        "    x['query'] = x['text']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = []\n",
        "    x['type'] = 'sts_by_textlabel'\n",
        "    x['label'] = x['eurovoc_concepts']\n",
        "    return x\n",
        "\n",
        "def clean_allenai_citeprediction(x):\n",
        "    x['query'] = x['query']['abstract']\n",
        "    pos = x['pos']['abstract']\n",
        "    x['positives'] = [pos] if pos is not None else []\n",
        "    neg = x['neg']['abstract']\n",
        "    x['negatives'] = [neg] if neg is not None else []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_simple_wiki(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_coco_captions_quintets(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = x['set'][1:]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_specter(x):\n",
        "    x['query'] = x['set'][0]\n",
        "    x['positives'] = [x['set'][1]]\n",
        "    x['negatives'] = [x['set'][2]]\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_paws(x):\n",
        "    x['query'] = x['sentence1']\n",
        "    x['positives'] = [x['sentence2']]\n",
        "    x['negatives'] = []\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_qqp(x):\n",
        "    x['query'] = x['set']['query']\n",
        "    x['positives'] = x['set']['pos']\n",
        "    x['negatives'] = x['set']['neg']\n",
        "    x['type'] = 'sts_triplet'\n",
        "    return x\n",
        "\n",
        "def clean_ledgar(x):\n",
        "    x['query'] = x['provision']\n",
        "    x['negatives'] = []\n",
        "    x['positives'] = []\n",
        "    x['type'] = 'sts_by_textlabel'\n",
        "    return x\n",
        "\n",
        "#dict_keys(['question_id', 'question', 'document_title', 'answer', 'label'])\n",
        "sts_streaming_cleaning_functions = {\n",
        "    'xsum':(clean_xsum, None, ['query','positives','negatives'],['summary','id','document']),\n",
        "    'embedding-data/simple-wiki':(clean_simple_wiki, None, ['query','positives','negatives'],['set']),\n",
        "    'embedding-data/coco_captions_quintets':(clean_coco_captions_quintets,None, ['query','positives','negatives'],['set']),\n",
        "    'embedding-data/SPECTER':(clean_specter,None, ['query','positives','negatives'],['set']),\n",
        "    'paws':(clean_paws,None, ['query','positives','negatives'],['id', 'sentence1', 'sentence2', 'label']),\n",
        "    'embedding-data/QQP_triplets':(clean_qqp,None, ['query','positives','negatives'],['set']),\n",
        "    \"allenai/scirepeval\":(clean_allenai_citeprediction, None,  ['query','positives','negatives'], ['pos','neg']),\n",
        "    \"lighteval/legal_summarization\":(clean_legalsum, None, ['query','positives','negatives'], ['article', 'summary']),\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\":(\n",
        "        clean_ledgar, None, ['query','label'], ['provision','source']\n",
        "    ),\n",
        "    \"eurlex\":(clean_eurlex, None,  ['query','positives','negatives'], ['celex_id', 'title', 'text', 'eurovoc_concepts']),\n",
        "    #'':(,None, ['query','positives','negatives'],['']),\n",
        "    #'':(,None, ['query','positives','negatives'],['']),\n",
        " }\n",
        "\n",
        "DEFAULT_PROB = 1.0\n",
        "sts_files = [\n",
        "    # dataset name, subset, take_probability, dataset size\n",
        "    ('xsum', None, DEFAULT_PROB, 204000, 'sts_by_triplet'),\n",
        "    ('embedding-data/simple-wiki',None, DEFAULT_PROB, 102000, 'sts_by_triplet'), # wikipedia paraphrases\n",
        "    ('embedding-data/coco_captions_quintets',None, DEFAULT_PROB,82800, 'sts_by_triplet'), # caption paraphrases\n",
        "    ('embedding-data/SPECTER',None, DEFAULT_PROB,684000, 'sts_by_triplet'), # ?\n",
        "    ('paws','labeled_final',DEFAULT_PROB, 49400, 'sts_by_triplet'), # paws paraphrases\n",
        "    ('embedding-data/QQP_triplets',None,DEFAULT_PROB, 102000, 'sts_by_triplet'), # quora?\n",
        "    (\"allenai/scirepeval\", 'cite_prediction',DEFAULT_PROB, 676000, 'sts_by_triplet'), # ?\n",
        "    (\"lighteval/legal_summarization\",\"BillSum\", DEFAULT_PROB, 18900, 'sts_by_triplet'),\n",
        "    ('https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip', None, DEFAULT_PROB, 1000000, 'sts_by_label'),\n",
        "    ('eurlex', None, DEFAULT_PROB, 45000, 'sts_by_label')\n",
        "    #('',None, 0.1,?*10**5),\n",
        "    #('',None, 0.1,?*10**5),\n",
        "    #('',None, 0.1,?*10**5),\n",
        "]\n",
        "\n",
        "stsdata_streaming_config = {\n",
        "    'files':sts_files,\n",
        "    'max_seq_length':512,\n",
        "    'prepend_q': 'passage: ',\n",
        "    'prepend_a': 'passage: ',\n",
        "    'val_size':100,\n",
        "    'train_chunk_size':500,\n",
        "    'seed':42,\n",
        "}\n"
      ],
      "metadata": {
        "id": "QFNfy-uRIDzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize streaming data for sts tasks\n",
        "sts_streaming_datsets, sts_probabilities, sts_datasizes = initialize_qa_streaming_datasets(\n",
        "    stsdata_streaming_config,\n",
        "    sts_streaming_cleaning_functions\n",
        ")\n",
        "\n",
        "# split and make-static (train and val sets, non-streaming)\n",
        "sts_statics_datsets = train_test_splits_from_stream_qa(\n",
        "    streaming_dataset=sts_streaming_datsets,\n",
        "    val_size = 100,#2000,\n",
        "    epoch = 0,\n",
        "    chunk_size = 2000,#6000,\n",
        "    path_to_val_cache = 'val_sts_cache.pkl',\n",
        "    probabilities = sts_probabilities,\n",
        "    datasizes = sts_datasizes,\n",
        "    seed=stsdata_streaming_config['seed']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a442a786e1364627a3ca7279b5490faa",
            "509d56758ff9483bb02acba1730f6ff0",
            "b4ce72155770425f948cefc0f34bff28",
            "5173fa33e14a4277af0a9bc7b0f58e2c",
            "a6a1c946c3a0402e91afe910089db701",
            "01fe3d374b854114bdf0b56ea578862e",
            "0567e8d57a214d88b1167d6166a4eba3",
            "6ef478c42e6e44bbb2e51b990c8cf258",
            "65609d903bcb475bbee60ff6cd268924",
            "5379cf0af15244749db8561aa398f42a",
            "aef562fe4c064fb090a8b4d1578fecbb",
            "46bfc1bf0bca4dd7995d50aac0740aa5",
            "d70f3f3bc1094e8f9f9d65ef98307d1f",
            "6cb29b3930e74da1addfd7e01b480b9e",
            "4ef7438078364ae78c49e774d77b7d1c",
            "4bf0047d256645d1962d1d2980e844af",
            "ac893ea96eb14ce196b8d7bb16bb7cbc",
            "c7f0033a9c2547c39f23d802e5fb2762",
            "2eb4eeb1a53d44a49d37a492e2492678",
            "8a52edda927341dd808210e14b9a21bb",
            "bd5815d04cb548cba6d40c9ca7eb7764",
            "7743b1759eae4a8bb92245f70ea884c7",
            "7f239a76bd9b4660ac3c5ab58313eeed",
            "ba28cb7c70bd4b0e85f8eef8bd9c4d73",
            "3a741126430d462baa81186128dfad4b",
            "6a3755e2b13e4cf99748950698d3b495",
            "ca777753c26146a9a91182e8efadc8c6",
            "266a7d5ca58441c69fb05fecb411dc11",
            "fb4943bf76a54fc7b210b725c46ec061",
            "90cd4e91692b47b9bae0815044a0c4a3",
            "f451287caf474e1f8dbf8d92212fe25a",
            "46a4d1bf5a3a450ab1e013589cb8d039",
            "d59c376f8a7a46adb6f4de05630af5f7",
            "746ea389134e43a19e5a4e67c657f932",
            "a26750dadb9248ad954d8e1addc839cf",
            "601fb20facea4991a61721f32db43f50",
            "caa0cd0225544234929d3c7b141a9351",
            "e96a022d39584d4ab8e61c0d62e2c7ef",
            "fd74402341554d19a884aa27632a7938",
            "eb67c2a41012497595c66df5621a55ff",
            "32130426dda343cd9e684a2344640706",
            "cceb2e6641d34edfb0e46f534f40c835",
            "6d9554e2ca1f4b6c92262606f7afd6f7",
            "2d7408a9420d44fba968912aaadb815c",
            "dccc6eb38ac74f02989fa5720c3379f8",
            "8d0abe6ee1c4482cb8aa9a51b0a16923",
            "0e578c34a0744116b5a5a49af5e4c83c",
            "f2605e9ee97a4adeb4493d914d9fd4c0",
            "929303df0e824d6f806b4b28e3fca015",
            "4f202ac68b744047824a047b35b46ca2",
            "eaae9abe7e404ff6b8c6fd0f42473ec0",
            "1ae4f6c0316f4e0c9b13a75dc7554433",
            "08790cac4e344781b209462cb6c29627",
            "d4f507a7281a4f7283e5e0f91e7703da",
            "ae3bee755e4047aebf584bafee614f43",
            "3fb51c9851be49f189d5a268706ce43f",
            "d6f03c945886482c8c1b8ba90cc6ab49",
            "f515f4f5b0234c569b2d4d39bf9b1ffd",
            "6f2a6e7619b340dcabc40f70686c9e94",
            "435f4b7337764b608fae8d398477983e",
            "a0afd44b499a4d72bf05127d9b9d289a",
            "658afb168e0f441dbbedbe466e0fa6a9",
            "ac5673b8be254271b35bbc226c43346a",
            "84f6fffcfd8c4811a6318e9214fcef91",
            "69e96be3c1cb4ab6a524e6de8175fa73",
            "12d7a97bc95c4262b7c75267d312f510",
            "83d4d749ca174bd591cfdf45fef6935b",
            "38d1e3b06f8347bd95a107e83c9e713b",
            "241e42019ecc4786987e6086d9ebf44a",
            "c576aaeea0cc4f3588e5df6b857350d3",
            "c6eac3fed56947ccb3650cc8ccda8727",
            "ea02c34d69404d5b8ed90ef0c22e1958",
            "a343c3d004be4f53a8170537a53f34f9",
            "234dee5fb2114d7da17e156ffb705e6b",
            "f597bca895584eb58306488899ae6e34",
            "2783284dd5d145dfbc24b3e703122abb",
            "5b12243b856442e784c19b26e6ae3069",
            "740c622838294ecb9e647a832064b1e9",
            "f560ac80fc5e4422a43102db965d8c55",
            "c39c40ad52e443e083130378c354775b",
            "a93691ca1f1f422dbf1548543de23a00",
            "8bdb3c00c1d243c1a118e9501e51a9ae",
            "f605d617b2d94d3d94da2579f0ff6fdf",
            "7187834292a54fc480a72f8f0be77db8",
            "d2ec492a404e417c90039e544ed74723",
            "d46df2d332d640469c0d21b4c94c3e59",
            "7a2af9c82a7d4cc7bee2d8d5e3bf48b5",
            "74fa5c65c69346b38ec9688b8bc67b5a",
            "169b2f6b694a40529c890c917a137084",
            "8afb91f12f494343811a93619fb60e9b",
            "6a4fa34d0af34da591623b6bb3e4a984",
            "3819209218114aa1815307413c47a358",
            "0e63c6878ab04842b0e0e97f6645bbae",
            "1da591812b8b487a98229bf048d8eb8b",
            "42560b42979344dca72e9ed1d723dc8e",
            "c127886375e54fcbb03fbdf95f8b38c7",
            "083b5fc625bb4f818a81ec7164b911e6",
            "a227b8b562fb438f9fa53c52a61a8c86",
            "0d18b91afafb4ab589a64cd73bdaa315",
            "7907f0448ac24d0ab68922eab2180309",
            "d9af957b0c234764978fbec13325c5cf",
            "4f489eeaf5bd42d688cb208f9b926283",
            "5be4ffb23c714749a5eddca7c928589a",
            "177528ee59df40bfbfc9566e7a1def79",
            "58ed13dc26cf4ddeaa5963ab8c1caa82",
            "ab6bfa3295464a78b44aa7f6271c72da",
            "2e5ae80299f54c1693938a7ce6f68572",
            "39841995387741b4baea5de2b66af81b",
            "473efafc58f5482295145a31a6a3ff93",
            "375bdb5429c049049542fcbd2693f688",
            "9207b345df8648df9f6741d3c750ee58",
            "d7958d26a685425d8224454e0cc30385",
            "ac83b7d0740f489daa469558926d9dda",
            "773fe8319423428093600b7a97a2f89c",
            "e6a6f345fdb549f890bf27b5be269d6a",
            "ea7a5c9fb470492f857abec551356016",
            "9de3b861fe7141bfa7ef73e98e49a761",
            "e68ac35d0e7b430c890279c2d99198cc",
            "4cd9d78ab7f54cd7b9404ded21e7a66f",
            "f181f29b47854712bd566a9470680b58",
            "ff6f8e3e9ec74ad894de1e4e634fef5b",
            "e77eb9d9d55a4db0ab97fb23186f0d31",
            "e14c758d9a464f9daf7c712d3e2a7e60",
            "7ee470eee65f4309b85681afee9a8f97",
            "c06b49f9451d430f987b123438b53ca1",
            "656c9027ff994a29be7dc36ad932994e",
            "de7e6a2db63246d2a7cb4639ca804188",
            "cdcd553dadff4dd2a23df9f1424b56bd",
            "87e8d30c4d4c462da677a7073a726f85",
            "985f0c26ea9f4921b5050857ca38bc15",
            "798b89ccec8845bdb293709f22f15617",
            "c8cbc5da6f30420d9a211d406c050adb",
            "31068127c0e146558d579218a1238423",
            "4d69a6fd1e4a4aa39891847877cb8a0e",
            "700bcbfdc23d4b15964c418a3bbe6495",
            "04f93ffee13740b2b7f47b7221f11109",
            "76210af5255c4b509a77777eab64a930",
            "c526b7e1224145318c3cc055ccef9797",
            "1579dcb354fe45b4b2a2a20ebbe02143",
            "4b614fef1b624d7caf53b692dcd5a8ad",
            "ccdecddef4224dd3ac04098e4e217d43",
            "46b1a73c1cf544afb65f2a0ec8376e62",
            "96b9def9783645c096485761baf8c5dc",
            "9a52234530a64c05b1a8c57c4d4c4868",
            "270f07b0f48b4fb28948a6dd1e431ca7",
            "c024c9065fd0468fa4d558aff8e1a4df",
            "c76d11293e1f473f8773ca211d7b4a0e",
            "0566161de3434736bb0bd9c174ee8266",
            "509332c6fa4142e3a0aee21b4216499b",
            "ae62d10114dd43ceb12078f221b83aaf",
            "ebaec37eab474bdc9bc4036feb149a4a",
            "4332f096643e46c3bc2a54e5bd167874",
            "5f35e135e2c44365ad09be201437577d",
            "c08b8363c8884d6e90e1656fff3dac78",
            "68eb6da6255c4721bfc99ec0efacbc45",
            "33dec1672e2841438b9a9147aedc8816",
            "29c4097638f141759c5c7393059dac1c",
            "ed5d1d7caea34bd580ec3019bf3c3de2",
            "d89694a7f84e4b068c587ae262ca9692",
            "38af96d518154547ae628ab00cba2f94",
            "38aad5870af84aec897694c8c302d6f5",
            "7e232fbef2a944e788ca3b999b62385f",
            "1edf1e5c06724474bf893c10d695ecbb",
            "e5a9fe64cccb4d16b9cbaeda0b154f61",
            "1ea29188c7bc46b0b722618e5607339a",
            "1535ed154ef14aa19d3f0fe429391ad9",
            "cbca09626e6d4343be0afa31ca017a63",
            "a74bad864878448a80a327805ee508a6",
            "ab4bc42d4842453e8fee047fa038f918",
            "ed86fcfa873844e8aa2776417b0aa9fe",
            "eac936319dd24c79a9d1c1372c8185e9",
            "380af89beabf46c596bd8b8f8238f1d1",
            "c2c1fac8ee114eef924b9feca7ac6296",
            "cee7dfe1b9e9457fa7194b0cc4b12161",
            "2bbab6e00879438d9cd08084eee39a24",
            "e6f70e92809b4b428c06e46b750aa504"
          ]
        },
        "id": "LamNdWbR0P8e",
        "outputId": "a11e1608-4c09-4404-d3ab-24491770af46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying xsum\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.76k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a442a786e1364627a3ca7279b5490faa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46bfc1bf0bca4dd7995d50aac0740aa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying embedding-data/simple-wiki\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f239a76bd9b4660ac3c5ab58313eeed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying embedding-data/coco_captions_quintets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "746ea389134e43a19e5a4e67c657f932"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying embedding-data/SPECTER\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dccc6eb38ac74f02989fa5720c3379f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying paws\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.43k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fb51c9851be49f189d5a268706ce43f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/7.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83d4d749ca174bd591cfdf45fef6935b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/9.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "740c622838294ecb9e647a832064b1e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying embedding-data/QQP_triplets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "169b2f6b694a40529c890c917a137084"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying allenai/scirepeval\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.74k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7907f0448ac24d0ab68922eab2180309"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/38.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9207b345df8648df9f6741d3c750ee58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/26.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e77eb9d9d55a4db0ab97fb23186f0d31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': 'https://ai2-s2-research-public.s3.us-west-2.amazonaws.com/scirepeval/train/cite_prediction/train.jsonl', 'val': 'https://ai2-s2-research-public.s3.us-west-2.amazonaws.com/scirepeval/train/cite_prediction/val.jsonl'}\n",
            "trying lighteval/legal_summarization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31068127c0e146558d579218a1238423"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\n",
            "trying eurlex\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.11k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a52234530a64c05b1a8c57c4d4c4868"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68eb6da6255c4721bfc99ec0efacbc45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/10.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1535ed154ef14aa19d3f0fe429391ad9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done initializing the QA streaming datasets\n",
            "RELOADING VAL-QA SET: iter=val_sts_cache.pkl\n",
            "VAL-QA SET SIZE: 0\n",
            "0.3707947176588889\n",
            "STREAMING TRAIN QA-DATA: 2000 STARTING AT: 0.371\n",
            "done 0\n",
            "done 1\n",
            "done 2\n",
            "done 3\n",
            "done 4\n",
            "done 5\n",
            "done 6\n",
            "done 7\n",
            "done 8\n",
            "done 9\n",
            "REALISED TRAIN QA-DATA SIZE: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in sts_statics_datsets['train']:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcFQO9CMc533",
        "outputId": "239e0e0c-1345-46c4-a27c-a7bb73dc68f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'A ferry with 650 people aboard crashed into a dock during gale force winds earlier on Tuesday.', 'negatives': [], 'positives': ['All of the passengers had to be transferred from the ferry in Holyhead, Anglesey after the incident.\\nThe Irish Ferries Jonathan Swift vessel was preparing to set off from Holyhead to Dublin before midday when heavy gusts pushed it into its berth.\\nNo passengers were injured during the incident. Irish Ferries cancelled three Swift services following the incident.\\nA spokesman for Irish Ferries said the aluminium hull ferry was being inspected to assess damage to the body and a replacement services was taking passengers to Dublin.\\nHe said: \"Just as she was leaving the berth at Holyhead she was caught by a gust of wind and blown back in. She was only yards off the berth and the ropes had been loosened.\\n\"We don\\'t know if the hull has been punctured. We don\\'t think that\\'s likely, but if it has then I don\\'t know if they can do the repair in Holyhead. It could need a dry dock.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'When Theresa May announced on Tuesday she was seeking an early general election, scores of people saw their weekends and half-term holidays vanish in a giant puff of electioneering, manifesto-writing and the mammoth admin task of staging a nationwide ballot.', 'negatives': [], 'positives': ['By anyone\\'s estimations, the general election of 2015 was an immense piece of administration.\\nForty-five million ballot papers were printed to reflect 650 separate candidate lists for the election. Forty-three thousand polling stations were staffed for 15 hours by 120,000 people. And the total cost of it came to Â£98,845,157.\\nBut all that was organised with five years\\' notice - the duration between the previous election and the date of the 2015 poll.\\nThe time frame for the 2017 ballot, which takes place on 8 June, is little more than seven weeks.\\nOne Conservative member of staff told the BBC she was completely taken aback. \"I have friends who work for ministers and even they didn\\'t see it coming until the Cabinet meeting took place.\"\\nThe clock is already ticking, and there is much work to be done. A Labour aide working for an MP described the past week as \"very stressful\".\\n\"In my own time after work I\\'ve been contributing to campaign materials and arranging to uproot myself from London so I can go back to the constituency.\"\\nWhile general elections are about putting MPs in Parliament, it falls to councils to organise the nitty-gritty of voting and counting.\\nVenues for polling stations and counting centres will need to be earmarked and reserved for 8 June. And that needs to happen before polling cards can be sent out.\\nThis work is carried out by local authorities\\' electoral services divisions and overseen by returning officers.\\nJohn Turner, chief executive of the Association of Electoral Administrators, predicts this election will be particularly onerous for two reasons - the compressed time scale, and the fact local elections are already taking place in many areas in less than two weeks.\\n\"Many polling stations aren\\'t publicly owned,\" said Mr Turner. \"They\\'re church halls or community centres, and a lot rests on returning officers\\' ability to persuade the owners to move things around and make the space available.\"\\nAs for staffing, electoral services departments maintain databases of temporary workers. But \"in this case some of them may already have made other plans or booked holidays\".\\n\"Although returning officers are helped by permanent teams, this varies a lot. In some district councils it will only be two or three people and colleagues from other departments will have to pitch in.\\n\"It\\'s going to be an intense time for many of us, working 12-hour days.\"\\nMr Turner is confident, however, that it will all come together in time, noting: \"We\\'re a bit like the duck paddling away beneath the water but serene on the surface.\"\\nThere\\'s equally little hope of sleep for those in charge of political policy making. They will be working around the clock on putting together manifestoes.\\nIt\\'s a particularly stressful time for the party in government, says Nick Pearce, head of the No 10 policy unit under former Prime Minister Gordon Brown. As well as existing government duties, staff will be working \"flat-out\" to get the document finalised.\\n\"A minister, usually from the Cabinet Office, takes overall responsibility, working with political staff from different departments to draft sections and liaise with the prime minister and her chief of staff,\" he explained.\\nMinisters, lobbyists and Treasury staff also get heavily involved, trying to place pet projects and ensure big-ticket items are properly costed.\\n\"There\\'s huge pressure not to get anything wrong,\" said Mr Pearce. \"But working quickly like this there is certainly potential for that to happen.\"\\nAnd what of getting the message out?\\nSeven weeks is \"a very, very tight time frame\" for organising a marketing and advertising strategy, said Rachel Hamburger, an advertising executive and former Lib Dem campaigner.\\n\"I\\'d be very surprised if we saw any nationwide broadcast campaigns comparable to famous ones of the past such as the Blair \\'devil eyes\\',\" she said.\\n\"With a long run-up, parties could be expected to run focus groups, market research and analysis of what is most important to their campaign before deploying adverts.\\nThis time, she believes. parties will \"concentrate resources on individual seats and simple messages\".\\nElsewhere in the media, broadcasters are preparing for election night. The BBC is reassigning hundreds of researchers, producers, camera crews and local reporters to put together its results programme.\\nParties, meanwhile, have to deal with the small matter of ensuring there are candidates in place in 650 constituencies for people to elect.\\nLabour and the Conservatives have both altered their normal selection procedures to speed things up, while all 54 of the SNP\\'s existing MPs are expected to stand again.\\nThe other parties are in varying states of readiness.\\nThe Lib Dems say they have about 100 candidates still to pick. UKIP and Plaid Cymru will adopt the bulk of their candidates next week, while Greens\\' selection is under way with local electoral alliances under consideration.\\nNone of Northern Ireland\\'s parties are thought to have selected candidates, as talks continue about restoring devolved government.\\nMost candidates will not have had a chance to allocate resources. It has already led some to take the unusual step of appealing for online donations.\\nRegional party offices will provide MPs and activists with support, but the prevailing mood could be described as one of apprehensiveness.\\nWhen asked to sum up how things were going, a fretful Conservative source said: \"Everything is basically on fire.\"\\nA Labour campaigner replied with a series of distressed crying and screaming emojis.\\nHowever, on a purely technical point, it\\'s worth noting the 50-day gap between announcement and polling day is actually the longest since 1983.\\nWhat\\'s different this time is the lack of preamble, and thus preparation.\\nAs the BBC\\'s former head of political research David Cowling put it: \"Everyone was lulled into a false sense of security by assurances... and we\\'re now completely stunned.\"\\nSign-up to get news from the BBC in your inbox, each weekday morning'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The Zambian government has paid former national football coach Dario Bonetti to prevent the team potentially facing sanctions from governing body Fifa.', 'negatives': [], 'positives': ['Frenchman Bonetti, who was in charge of Chipolopolo from July 2010 to October 2011, had been owed US$432,000.\\nBonetti was sacked with nine months left on his deal and despite qualifying for the 2012 Africa Cup of Nations.\\nHe lodged a complaint against the Zambia Football Association with Fifa and a hearing had been set for August.\\nFollowing Zimbabwe\\'s expulsion from 2018 World Cup qualifying for failing to pay former coach Jose Claudinei Georgini, there were fears Zambia could face an international ban if they did not pay Bonetti.\\nZambia\\'s sports minister Vincent Mwale told parliament: \"The Football Association of Zambia (Faz) decided to terminate Bonetti\\'s contract without prior consultation with the Ministry of Youth and Sport.\\n\"According to Faz, the coach was handpicked and was not screened for international experience and African experience.\\n\"The Faz president had said that the players had complained about Bonetti\\'s poor football knowledge and lack of respect for players.\\n\"In order for the country not to suffer Fifa sanctions, which could entail the country not being able to participate in international tournaments, the ministry requested for intervention from the treasury for special funding to quickly settle the issue.\"\\nFaz general secretary George Kasengele told BBC Sport his association is delighted the Bonetti case is over.\\n\"This is a matter that is now beyond us and as an association we are happy we are no longer owing him. Owing people has its own consequences,\" Kasengele said.\\nHe added that he hoped the government would also settle salary arrears owed to Patrice Beaumelle, another former Chipolopolo coach who has been threatening to report the matter to Fifa.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Royal Mail is to trial a Sunday delivery service for parcels in response to the increasing demand for goods ordered online.', 'negatives': [], 'positives': ['Later this summer it will open around 100 offices on a Sunday afternoon for customers to pick up their parcels.\\nDelivery offices with the highest parcel volumes across the UK will take part in the scheme.\\nThe company will also try out parcel deliveries to addresses within the M25 motorway.\\n\"Through these new Sunday services we are exploring ways to improve our flexibility and provide more options for people to receive items they have ordered online,\" said Royal Mail\\'s chief executive Moya Greene.\\n\"The support of the Communication Workers Union (CWU) has enabled us to respond quickly to a changing market, \" she added.\\nCWU deputy general secretary Dave Ward said: \"Royal Mail\\'s announcement about expanding delivery and collection services to seven-days-a-week is an exciting innovation which we welcome.\\n\"We have worked closely with Royal Mail to develop how best we can go forward to grow the company together and improve the services for customers.\"\\nRoyal Mail\\'s express delivery service, Parcelforce Worldwide, which tends to deal with larger and more valuable parcels, will also offer a Sunday service to retailers from June. It will be up to the retailer to decide whether to offer it to customers.\\nThe BBC\\'s John Moylan says that rival firms, including Hermes and DPD, have already announced plans to deliver on Sundays and that some have been undercutting Royal Mail, which increased the price of posting letters and parcels earlier this year.\\nRoyal Mail was privatised last year. The company reports its first annual results as a public company on Thursday.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Kendrick Lamar's sprawling hip-hop opus To Pimp A Butterfly has emerged as the critics' favourite album of 2015.\", 'negatives': [], 'positives': ['The album, which tackles race relations in post-Ferguson America, topped a \"poll of polls\" compiled by the BBC.\\nSecond was Sometimes I Sit and Think, and Sometimes I Just Sit by Australian singer Courtney Barnett, whose everyday vignettes have won praise for their incisive, humorous lyrics.\\nFolk-rock artist Father John Misty\\'s I Love You, Honeybear came third.\\nJamie xx\\'s In Colour and psychedelic rock band Tame Impala with Currents made up the top five with Adele\\'s 25 - the year\\'s best-selling record - in 12th place.\\nThe results were compiled from 20 \"album of the year\" polls, published by the most influential magazines, newspapers and blogs in music - including Billboard, Rolling Stone, Q and the NME.\\nRecords were assigned points based on their position in each list - with the number one album getting 20 points, the number two album receiving 19 points, and so on.\\nThe Top 20 is as follows:\\nThere was a huge diversity in the critics\\' picks, with 140 albums cited across the 20 polls surveyed by the BBC.\\nBut Kendrick Lamar\\'s 11-time Grammy nominated album was the only one to feature in every list - taking the number one position 10 times.\\n\"Lamar, the scene\\'s latest true superstar, has emerged as the one to beat,\" wrote The Sun.\\n\"His sense of timing is impeccable,\" added Billboard. \"In the midst of rampant cases of police brutality and racial tension across America... the politically charged project sonically commands your full attention.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Labour peer Lord Falconer is to table a private members bill that will seek to legalise assisted suicide for the terminally ill in England and Wales.', 'negatives': [], 'positives': ['It is expected that under the bill, mentally-capable adults with less than six months to live would be able to request help to end their lives.\\nThe government has said the issue is a matter of conscience for each MP.\\nOpponents say changing the law could put vulnerable people under pressure \"not to be a burden on others\".\\nUnder Lord Falconer\\'s bill a patient would have to prove they have the mental capacity to make a voluntary and informed choice, were not being unduly influenced by others and had a \"settled intention\" about their wish to die.\\nBefore proceeding, their condition would have to be independently assessed by two doctors as well as other healthcare professionals.\\nThey would also have to be informed about alternative treatments and end-of-life care options.\\nBy Clive ColemanBBC News legal correspondent\\nAssisting someone to commit suicide is a crime punishable with up to 14 years imprisonment.\\nIt can be committed in many different ways, from obtaining and handing someone a syringe full of lethal drugs which they then use to kill themselves, to purchasing a plane ticket so that they can travel to Switzerland (where assisted suicide is legal) to end their life.\\nLord Falconer\\'s bill is a result of the Commission on Assisted Dying (CAD), which he chaired.\\nIt published a report in January last year which concluded the laws on assisted dying were \"inadequate, incoherent and should not continue\".\\nThe bill would not have helped people like the late Tony Nicklinson, who suffered from \"locked-in syndrome\", and the severely disabled Paul Lamb who is currently challenging the law on the \"right to die\".\\nNeither man could demonstrate a terminal illness and both were too severely paralysed to assist in their own suicide.  Such cases require a doctor to intervene directly to end a life, and under current law that amounts to murder.\\nIn comparison, Lord Falconer\\'s bill might seem to some to be a modest step in changing the law.  However, those who oppose it point to rises, in assisted suicides that followed legalisation in other countries, and see it as a dangerous first step towards euthanasia.\\nOther safeguards being proposed include guarantees about the storage and transportation of lethal medication, the reporting of assisted deaths and the powers for cases of non-compliance to be investigated.\\nLord Falconer said: \"The current law which forces some terminally ill people to travel abroad to die or attempt suicide behind closed doors is not fit for purpose.\\n\"This new law will safeguard patients, protect family members and ensure that the medical profession can be involved.\\n\"Furthermore, strictly limited to terminally ill, mentally competent adults, the bill will not result in more people dying, but in fewer people suffering.\"\\nLast year a commission chaired by Lord Falconer, the former lord chancellor, concluded that a small number of people felt the extreme suffering caused by their condition could be relieved only by ending their own life or the knowledge they could do so.\\nThe bill is supported by some groups, such as Dignity in Dying. Chief executive Sarah Wootton said: \"The experience in jurisdictions which have legalised and regulated some form of assistance to die shows that, in reality, safeguarded assisted dying laws provide transparency in end-of-life decision making and provide both greater choice and protection.\"\\nHowever, it is opposed by others who point to the example of places, such as Oregon in the US, which have legalised assisted suicide. They say relatively low numbers of assisted suicides immediately after the law was changed have subsequently risen.\\nCampaign group Care Not Killing said: \"Any change in the law to allow assisted suicide would inevitably place pressure on vulnerable people to end their lives so as not to be a burden on others.\\n\"These pressures would be particularly acutely felt at a time of economic recession when many families are struggling to make ends meet and health budgets are being slashed, especially when fears about the NHS are actually fuelling support for assisted suicide.\"\\nAny change in the law is likely to be strongly opposed by Church of England bishops sitting in the House of Lords, where the bill is expected to have its first detailed debate in the autumn.\\nThe British Medical Association has also rejected calls for it to soften its opposition to assisted dying.\\nPrivate members\\' bills rarely become law unless they are supported by the government of the day.\\nAssisted suicide is illegal in Northern Ireland. There is no offence of assisted suicide in Scotland, however, depending on the particular facts and circumstances of the case, the law of homicide may apply.\\nAssisted suicide is legal in Switzerland, the Netherlands, Belgium and Luxembourg.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Manchester United suffered their third defeat in a week as late goals from Juan Zuniga and Troy Deeney gave Watford a deserved Premier League win.', 'negatives': [], 'positives': ['The hosts led when Etienne Capoue converted Daryl Janmaat\\'s cut-back, only for Marcus Rashford to level from close range.\\nZuniga powered in with seven minutes to go, 53 seconds after coming on.\\nAnd Deeney then scored a penalty in injury time after Marouane Fellaini fouled Zuniga in the box.\\nFollowing a derby defeat by Manchester City last weekend and the midweek Europa League loss to Feyenoord, Mourinho and United have had a rough eight days.\\nIt is the first time Mourinho has lost three consecutive games in a season since February 2002, when he was Porto boss.\\nBut the self-proclaimed \"Special One\", who has won eight league titles across Europe and the Champions League twice, has now lost 11 of his past 21 Premier League games in charge of Chelsea and Manchester United.\\nMourinho made five changes to his starting line-up from the trip to the Netherlands, with Wayne Rooney and Zlatan Ibrahimovic restored to the side, but United were disorganised and ineffective, particularly in the first half.\\nThe United boss looked unhappy with the home side\\'s opening goal, feeling Anthony Martial was fouled by Miguel Britos, but he will surely need to look more closely at his own side\\'s failings as they drifted six points behind league leaders Manchester City.\\nRooney, Ibrahimovic and £89m Paul Pogba all struggled to make an impact on the game and at the back United failed to cope with Watford\\'s energetic pressing and the crosses from wing-backs Janmaat and Jose Holebas.\\nPogba, who returned to Old Trafford from Juventus in the summer, continued to look far from being the most expensive player in the world, although he was deployed in a deep midfield role alongside Fellaini that did little to get he best out of the France international.\\nHe did have United\\'s best effort in the first half, hitting a 25-yard dipping shot that struck the crossbar.\\nBut his attacking talents were wasted so far away from the opposition\\'s goal and, after starting the past five games, Mourinho will have to consider dropping Pogba or changing his system to accommodate the 23-year-old.\\nWhile most of Mourinho\\'s side toiled, the rise of Rashford continued, as the 18-year-old England striker scored on his first Premier League start of the season, taking his tally to 10 in 23 games.\\nHe even started the move for his goal, playing a one-two with Ibrahimovic, whose cross dropped to Rashford\\'s feet for an easy finish from five yards out.\\nHornets boss Walter Mazzarri, who managed Zuniga at Napoli, leapt for joy when the midfielder applied the finish to Roberto Pereya\\'s cut-back with his first touch.\\nMazzarri had numerous run-ins with Mourinho during their time in Italy - with former Inter manager Mourinho saying the Italian was a hard-working \"donkey\" that would \"never become a thoroughbred\".\\nMazzarri, who took over at Vicarage Road in the summer, insisted before the game that he and the Portuguese get on fine now, but he could not hide his delight when his side went 2-1 up and danced on the side of the pitch.\\nWith numerous chances in the first half, including an open goal for Odion Ighalo after keeper David de Gea dropped the ball, Mazzarri\\'s men should have been further ahead at the break, but scored a thoroughly deserved opener when Martial was dispossessed and Janmaat teed up Capoue.\\nWatford looked like their pressing game had taken the energy out of their performance as United improved in the second half, but they responded late on for their second win of the season and first at home.\\nWatford boss Walter Mazzarri:\\n\"It is a very important three points to give my players the confidence to go ahead.\\n\"We were playing well, we conceded a goal and we stop playing. We were afraid then we made the changes and everything went the right way - it is something we need to work on.\\n\"I don\\'t look too much at results but how we play. We have been improving dramatically.\"\\nAnd what about a drink with Mourinho after the game? \"If he has time we will do it. We spoke before the game - even one day next week we can go out for dinner.\"\\nMedia playback is not supported on this device\\nManchester United boss Jose Mourinho:\\n\"I reflect on three factors from the match, but only one of them I can improve.\\n\"The first factor depends on ourselves, it relates to our individual mistakes and collective mistakes as individual players and as a team. We have to improve something, it is in our hands.\\n\"At 1-1 everyone thinks we are going to win the game. We were showing complete control, intensity, creation.\\n\"But their second goal is a mistake that goes against our plan and our training, because our intention was for their wing-backs to be pressed and not let them progress.\\n\"And what happened was the guy gets the ball 20-25 metres away from our box and instead of being pressed, we give him the space to progress. Nordin Amrabat receives the ball and our left-back Luke Shaw is 25 metres from him instead of five.\\n\"The second factor is the referee and I can\\'t control their mistakes.\\n\"The third factor is luck, we didn\\'t have it. We were the best team when we lost.\"\\nMedia playback is not supported on this device\\nMatch ends, Watford 3, Manchester United 1.\\nSecond Half ends, Watford 3, Manchester United 1.\\nGoal!  Watford 3, Manchester United 1. Troy Deeney (Watford) converts the penalty with a right footed shot to the top right corner.\\nDelay over. They are ready to continue.\\nDelay in match Juan Zuñiga (Watford) because of an injury.\\nPenalty conceded by Marouane Fellaini (Manchester United) after a foul in the penalty area.\\nPenalty Watford. Juan Zuñiga draws a foul in the penalty area.\\nChris Smalling (Manchester United) wins a free kick in the defensive half.\\nFoul by Troy Deeney (Watford).\\nWayne Rooney (Manchester United) is shown the yellow card.\\nFoul by Wayne Rooney (Manchester United).\\nRoberto Pereyra (Watford) wins a free kick on the right wing.\\nCorner,  Watford. Conceded by Wayne Rooney.\\nCorner,  Watford. Conceded by Memphis Depay.\\nFoul by Zlatan Ibrahimovic (Manchester United).\\nMiguel Britos (Watford) wins a free kick in the attacking half.\\nSubstitution, Watford. Isaac Success replaces Odion Ighalo.\\nMemphis Depay (Manchester United) is shown the yellow card.\\nFoul by Memphis Depay (Manchester United).\\nNordin Amrabat (Watford) wins a free kick on the right wing.\\nMarouane Fellaini (Manchester United) is shown the yellow card for a bad foul.\\nFoul by Marouane Fellaini (Manchester United).\\nJuan Zuñiga (Watford) wins a free kick in the defensive half.\\nDangerous play by Paul Pogba (Manchester United).\\nSebastian Prödl (Watford) wins a free kick in the defensive half.\\nTroy Deeney (Watford) is shown the yellow card for a bad foul.\\nJuan Mata (Manchester United) wins a free kick in the attacking half.\\nFoul by Troy Deeney (Watford).\\nSubstitution, Manchester United. Memphis Depay replaces Luke Shaw.\\nGoal!  Watford 2, Manchester United 1. Juan Zuñiga (Watford) right footed shot from the centre of the box to the bottom left corner. Assisted by Roberto Pereyra.\\nFoul by Marouane Fellaini (Manchester United).\\nValon Behrami (Watford) wins a free kick in the attacking half.\\nSubstitution, Watford. Juan Zuñiga replaces Etienne Capoue.\\nOffside, Manchester United. Juan Mata tries a through ball, but Marouane Fellaini is caught offside.\\nMarcus Rashford (Manchester United) wins a free kick on the right wing.\\nFoul by Miguel Britos (Watford).\\nEric Bailly (Manchester United) wins a free kick in the defensive half.\\nFoul by Odion Ighalo (Watford).\\nAttempt missed. Paul Pogba (Manchester United) right footed shot from outside the box is high and wide to the right. Assisted by Juan Mata.\\nAttempt saved. Zlatan Ibrahimovic (Manchester United) header from the centre of the box is saved in the centre of the goal. Assisted by Marouane Fellaini.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Leeds Rhinos edged a thrilling match against St Helens to move up to second in the Super League table.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nThe hosts led 6-4 at half-time after Joel Moon and Adam Swift traded scores.\\nStevie Ward\\'s try extended Leeds\\' advantage early in the second period, only for Saints to then turn the match around thanks to Tommy Makinson and James Roby.\\nHowever, Kallum Watkins and Ryan Hall made it 24-16 to Leeds, and they held on despite Alex Walmsley\\'s late try.\\nRhinos are now six points off Super League leaders Castleford Tigers, while St Helens remain sixth, three points behind Wakefield in fifth.\\nSaints beat Leeds in a low-scoring but enthralling encounter on the opening night of the season, but this time they were to find themselves on the wrong end of another topsy-turvy two-point game.\\nThe key period at Headingley came after Jon Wilkin was sin-binned for a dangerous tackle on 62 minutes, with Leeds twice crossing the whitewash while St Helens were a man light.\\nThere was also some concern over Saints half-back Matty Smith, who was forced off during the first half with what coach Justin Holbrook described after the game as a \"serious eye injury\".\\n\"Matty had his eyelid ripped open and we couldn\\'t stitch it so he\\'s had to go to hospital,\" said Holbrook. \"We\\'re hoping he\\'ll be OK.\"\\nLeeds coach Brian McDermott (on 17-year-old full-back Jack Walker): \"He was good. He took some challenging high balls and looks okay with the ball in his hands.\\n\"It was a big game for him and his development will be better for it.\\n\"We\\'ve had to overcome a little bit of adversity with bans and injuries but overall I\\'m very pleased. We were really challenged by a determined Saints.\\n\"We got put on the back foot a couple of times, we needed to have some fight about us.\"\\nSt Helens coach Matty Holbrook:  \"I\\'m just as proud of the boys as I was last week when we got the win.\\n\"It was really crucial to lose your half-back for pretty much the whole game. Obviously he\\'s our main organiser so it made it hard on us and, to nearly get away with that without your half would have been huge.\\n\"I think the sin-binning was harsh and it was massive. It makes it hard, that\\'s for sure, when you are playing a man short for 10 minutes.\\n\"But it shows the players are loving playing for each other. We just need to string some wins together.\"\\nLeeds Rhinos: Walker, Briscoe, Watkins, L. Sutcliffe, Hall, Moon, Lilley, Galloway, Parcell, Singleton, Ablett, Ward, Cuthbertson.\\nReplacements: Garbutt, Mullally, Ormondroyd, Handley.\\nSt Helens: Lomax, Swift, Makinson, Morgan, Grace, Fages, Smith, Thompson, Roby, Amor, Taia, Wilkin, Knowles.\\nReplacements: Walmsley, McCarthy-Scarsbrook, Douglas, Peyroux.\\nReferee: James Child (RFL)'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'El Salvador, the most densely-populated state on the mainland of the Americas, is a small and highly-industrialised country.', 'negatives': [], 'positives': ['In the 1980s, El Salvador was ravaged by a bitter civil war stoked by gross inequality between the overwhelming majority of the population and a small and wealthy elite that left around 70,000 people dead.\\nA United Nations-brokered peace agreement ended the civil war in 1992, ushering in important political reforms, but the country still suffers from the legacy of a divided society.\\nViolent \"mara\" street gangs have left El Salvador with one of the world\\'s highest murder rates.\\nPopulation 6.3 million\\nArea 21,041 sq km (8,124 sq miles)\\nMajor language Spanish\\nMajor religion Christianity\\nLife expectancy 68 years (men), 77 years (women)\\nCurrency US dollar & Salvadoran colon\\nPresident: Salvador Sanchez Ceren\\nA former rebel leader, Salvador Sanchez Ceren won the presidential run-off of March 2014 by a narrow margin.\\nAs presidential candidate of the left-wing Farabundo Marti Liberation Front (FMLN), he beat Norman Quijano of the conservative Arena party by less than a quarter of a percentage point, becoming the first former guerrilla to lead the Central American country.\\nIn his inauguration speech, he promised to fight corruption and violence, and \"to serve as president of all Salvadoreans\".\\nPress freedom is guaranteed under the constitution, and the media freely and routinely criticise the government and report on opposition activities.\\nBut ownership of broadcasting outlets is concentrated among a small group of private operators, and media owners \"often impose controls on journalists to protect their political or economic interests\", according to US-based Freedom House.\\nSome key dates in the history of El Salvador:\\n1540 - El Salvador becomes a Spanish colony after indigenous resistance is crushed.\\n1821 - Independence from Spain.\\n1823 - 1840 - El Salvador forms part of the short-lived United Provinces of Central America, which also includes Costa Rica, Guatemala, Honduras and Nicaragua.\\n1859-63 - President Gerardo Barrios introduces coffee growing.\\n1932 - Some 30,000 people are killed during the suppression of a peasant uprising led by Agustine Farabundo Marti.\\n1969 - Football War with Honduras; 4,000 die in 100-hour conflict.\\n1979 - 1992 - Civil war. Between 1979 and 1981 around 30,000 people are killed by army-backed right-wing death squads.\\n2009 - Former FMLN rebel movement emerges as largest party in parliamentary elections and shortly afterwards former rebel Mauricio Funes wins presidential elections.\\n2012 - A year-long truce between street gangs. It reputedly saves the lives of thousands but violence rises again in subsequent years.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The Belfast Giants will face a 5-3 deficit in the home second leg of their Challenge Cup semi-final with Cardiff.', 'negatives': [], 'positives': [\"Sunday's first leg was tied at 2-2 after two periods with Trevor Hendrikx and Ryan Russell on target for the hosts and James Desmarais and David Rutherford getting Belfast's replies.\\nKris Beech scored the third Belfast Giants goal in Sunday's first leg.\\nBut Guillaume Doucet, Leigh Salters and Joey Haddad netted to put the Devils in pole position for the return leg.\\nThe second leg will be staged at the SSE Arena in Belfast on Tuesday, 23 February, with the final in Sheffield on 6 March.\\nCardiff are the holders, having beaten the Sheffield Steelers in last year's final, while Belfast last won the Challenge Cup in 2009.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Winston Reid scored a 94th-minute winner for West Ham at the London Stadium to condemn Sunderland to their worst start to a Premier League season.', 'negatives': [], 'positives': ['The hosts may well have had a penalty when Reid was wrestled to the ground by Javier Manquillo early on.\\nDimitri Payet then drew a smart save from Sunderland keeper Jordan Pickford before firing a low strike against the post after some clever footwork on the edge of the box.\\nWahbi Khazri had the visitors\\' best chance after Steven Pienaar\\'s deflected pass put him through on goal, but his tame shot was easily saved by Adrian.\\nSunderland must have thought they had earned a point, but Reid turned smartly on the edge of the box from a West Ham corner to fire left-footed past Pickford.\\nIt leaves David Moyes\\' side bottom of the Premier League with just two points from their first nine games this season.\\nWest Ham\\'s tricky start to life at the London Stadium has been well documented, with Slaven Bilic\\'s side only picking up four points from four Premier League games at their new ground before Sunderland\\'s visit.\\nPayet\\'s wonder goal salvaged a point against Middlesbrough last time out in east London and eased some of the frustration the home fans have expressed since their move from the Boleyn Ground.\\nThose claret and blue-clad supporters were growing restless as the Hammers looked to have been held by the division\\'s bottom side, despite dominating in the first half.\\nMoyes and Sunderland looked content to return home with a point as the former Everton and Manchester United boss threw on defensive reinforcements and watched his side drop deep into their own territory.\\nBut it was a moment of hesitation deep into injury time that caught the visitors out, as a short corner from West Ham was worked to Reid and his effort snuck through a maul of bodies in the box.\\nBilic opted to start with three central defenders as the Hammers recorded only their second win of the season at Crystal Palace last week, but the hosts were missing suspended left wing-back Aaron Cresswell, influential to that system, against Sunderland.\\nThe Croat stuck with a back three in Cresswell\\'s absence, handing Edimilson Fernandes a first Premier League start, and the 20-year-old Swiss looked an adept attacking threat, managing four shots on goal and making a key pass for the hosts.\\nOn the other flank was Michail Antonio, the club\\'s top scorer this season, and his pace and energy caused problems for the visitors with the England hopeful managing six crosses, as did his second-half replacement Sofiane Feghouli.\\nDespite the ammunition, summer singing Simone Zaza was unable to open his West Ham account, though the Italy forward did watch an acrobatic overhead kick drop narrowly wide of Pickford\\'s far post before the break.\\nSunderland have staged miraculous escape acts in recent seasons, but with just six goals and two points to show for his tenure so far, Moyes needs his side\\'s fortunes to change quickly if they are to repeat that trick.\\nThey are now only the second team in top-flight history to fail to win any of their opening nine league games in consecutive seasons, with Bury the other in 1905 and 1906.\\nJermain Defoe\\'s 15 goals played a big part in the Black Cats\\' successful survival bid last term, and the former England international has scored four of his side\\'s six goals so far this season.\\nBut the 34-year-old touched the ball just once inside the opposition box in the first half against his old side at the London Stadium and cut an isolated figure.\\nMoyes, who got the backing of Sunderland chief executive Martin Bain this week, sent his team out with more intent early in the second half with Khazri and Duncan Watmore posing more of a threat, though to no avail.\\nMedia playback is not supported on this device\\nSunderland manager David Moyes: \"It was offside. It should be given offside. The referee thinks it is onside.\\n\"You can tell by the referee\\'s movement to the linesman that he is not sure, they weren\\'t sure but it was not a goal.\\n\"I thought the players played well. Not in the opening 20 minutes, they bossed us but we got through it and had good chances. I am very pleased with the performance but not the result.\"\\nMedia playback is not supported on this device\\nWest Ham manager Slaven Bilic speaking to BBC Sport: \"It was a dramatic end. The first 25 minutes it was by far our best 25 minutes, including last season.\\n\"We were good, sharp, created chances and we deserved to be two up. Then they came back. And in the second half they had great chances and were dangerous on the counter attack but in the last 15 minutes we pushed more and we were looking to score.\\n\"I cannot say it was a goal from the training ground. You expect Winston Reid to score a header but it was a great decision to come in on the edge of the box.\"\\nFormer England midfielder Danny Murphy:\\n\"David Moyes thought the winner should have been ruled out for offside - and it was tight. But ultimately if you\\'re conceding lots of goals late in games, you have got a problem.\\n\"Players switched off and were not concentrating. As Winston Reid hits it, you can see Jonathan Calleri is in line with Jack Rodwell. It\\'s an inch or two inches but it\\'s not a bad decision. I think the assistant referee has done well.\"\\nWest Ham are back at the London Stadium in EFL Cup action on Wednesday, when they host rivals Chelsea. Slaven Bilic\\'s side then visit Everton in the Premier League for the 13:30 BST kick-off on Sunday.\\nSunderland go to Southampton in the EFL Cup on Wednesday, before Arsenal visit the Stadium of Light in the Premier League\\'s early kick-off on Saturday.\\nMatch ends, West Ham United 1, Sunderland 0.\\nSecond Half ends, West Ham United 1, Sunderland 0.\\nGoal!  West Ham United 1, Sunderland 0. Winston Reid (West Ham United) left footed shot from outside the box to the bottom right corner. Assisted by Dimitri Payet following a corner.\\nCorner,  West Ham United. Conceded by Lynden Gooch.\\nAttempt missed. Cheikhou Kouyaté (West Ham United) header from the centre of the box misses to the right. Assisted by Dimitri Payet with a cross following a set piece situation.\\nBilly Jones (Sunderland) is shown the yellow card.\\nDimitri Payet (West Ham United) wins a free kick on the left wing.\\nFoul by Javier Manquillo (Sunderland).\\nSofiane Feghouli (West Ham United) wins a free kick on the right wing.\\nFoul by Lynden Gooch (Sunderland).\\nSubstitution, Sunderland. Billy Jones replaces Wahbi Khazri.\\nSubstitution, West Ham United. Ashley Fletcher replaces Manuel Lanzini.\\nWahbi Khazri (Sunderland) is shown the yellow card.\\nSubstitution, Sunderland. Paddy McNair replaces Steven Pienaar.\\nAngelo Ogbonna (West Ham United) wins a free kick on the left wing.\\nFoul by Wahbi Khazri (Sunderland).\\nMark Noble (West Ham United) wins a free kick on the right wing.\\nFoul by Lynden Gooch (Sunderland).\\nSubstitution, Sunderland. Lynden Gooch replaces Duncan Watmore.\\nAttempt missed. Pedro Obiang (West Ham United) left footed shot from a difficult angle on the left is close, but misses to the left.\\nDimitri Payet (West Ham United) wins a free kick in the attacking half.\\nFoul by Didier Ndong (Sunderland).\\nFoul by Jonathan Calleri (West Ham United).\\nWahbi Khazri (Sunderland) wins a free kick in the defensive half.\\nSubstitution, West Ham United. Jonathan Calleri replaces Simone Zaza.\\nWinston Reid (West Ham United) is shown the yellow card for a bad foul.\\nHand ball by Jermain Defoe (Sunderland).\\nCorner,  West Ham United. Conceded by John O\\'Shea.\\nAttempt blocked. Simone Zaza (West Ham United) left footed shot from the right side of the box is blocked. Assisted by Dimitri Payet.\\nMark Noble (West Ham United) wins a free kick in the defensive half.\\nFoul by Wahbi Khazri (Sunderland).\\nFoul by Pedro Obiang (West Ham United).\\nWahbi Khazri (Sunderland) wins a free kick in the defensive half.\\nAttempt missed. Edimilson Fernandes (West Ham United) right footed shot from outside the box is too high. Assisted by Dimitri Payet.\\nSubstitution, West Ham United. Sofiane Feghouli replaces Michail Antonio.\\nOffside, West Ham United. Dimitri Payet tries a through ball, but Simone Zaza is caught offside.\\nOffside, West Ham United. Adrián tries a through ball, but Simone Zaza is caught offside.\\nAttempt missed. Wahbi Khazri (Sunderland) right footed shot from more than 35 yards misses to the right. Assisted by Didier Ndong.\\nCorner,  Sunderland. Conceded by Michail Antonio.\\nAttempt blocked. Patrick van Aanholt (Sunderland) left footed shot from the left side of the box is blocked.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The Abolish the Welsh Assembly Party did not submit a spending return for the assembly election, the Electoral Commission has said.', 'negatives': [], 'positives': ['The matter is being considered by the watchdog in line with its \"established enforcement policy\".\\nEvery party that contested at least one seat in the election is required by law to submit a campaign spending return.\\nThe Abolish the Welsh Assembly Party said it submitted a return in time but there \"may have been a clerical issue\".\\nThe party put up candidates on the regional lists, beating the Liberal Democrats in the North Wales and South Wales East regions.\\nIt took sixth place with 44,286 votes, 4.4% of the total.\\nLast week, the Electoral Commission published figures showing just over Â£1.26m was spent by 17 parties and two non-party bodies during last year\\'s campaign but the Abolish the Welsh Assembly Party was not included.\\nA spokesman for the Electoral Commission said: \"The commission did not receive a spending return from Abolish the Welsh Assembly Party for the 2016 National Assembly for Wales election.\\n\"Where a party fails to submit any return despite contesting the election, as in this instance, the commission considers the matter in line with our established enforcement policy.\"\\nJonathan Harrington, the party\\'s treasurer, said: \"There may have been a clerical issue but all relevant figures were submitted by 27 July.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Six British former servicemen who spent months in an Indian prison have suffered another setback in their attempts to return home.', 'negatives': [], 'positives': ['The MV Seaman Guard Ohio crew were accused of illegally possessing weapons while working on a private US-owned ship providing anti-piracy protection.\\nThe men, including Nick Dunn, of Ashington, Northumberland, had the charges dropped in July.\\nBut police have asked the country\\'s supreme court to consider an appeal.\\nAlong with Mr Dunn, the men arrested on 12 October 2013 are:\\nAll of the men, apart from Mr Towers, were released on bail in April.\\nThe charges against them were quashed in July but their passports were retained by Indian authorities.\\nMr Dunn told the BBC he had not been paid by his employers, AdvanFort, and he is reliant on money being sent by his family.\\nHe said: \"The company have not paid me for one year, my family is going through financial strain and the British government have said they will not fund me. They won\\'t even pay for a hotel room.\\n\"I feel totally let down, especially being an ex-serviceman.\"\\nMr Dunn believes his chances of returning to Britain in time for Christmas would be \"slim\" if the supreme court decides to consider the appeal.\\nA spokesman for the Foreign and Commonwealth Office said: \"We continue to offer consular assistance to the individuals concerned and their families.\\n\"We also continue to raise the issue at the highest level.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Louis van Gaal has been named as Manchester United manager, with Ryan Giggs as his assistant.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nVan Gaal, 62, has signed a three-year contract to succeed David Moyes.\\nThe Dutchman, who has won titles with Ajax, Barcelona, Bayern Munich and AZ Alkmaar, will take charge at Old Trafford after leading the Netherlands at this summer\\'s World Cup in Brazil.\\nI have managed in games at Old Trafford before and know what an incredible arena Old Trafford is and how passionate and knowledgeable the fans are\\n\"This club has big ambitions. I too have big ambitions,\" he said. \"Together I\\'m sure we will make history.\"\\nVan Gaal said he had always wanted to work in the Premier League.\\nHe added: \"To work as a manager for Manchester United, the biggest club in the world, makes me very proud.\\n\"I have managed in games at Old Trafford before and know what an incredible arena Old Trafford is and how passionate and knowledgeable the fans are.\"\\nAfter ending the reign of Moyes in April after a troubled 10 months, United executive vice-chairman Ed Woodward is convinced he has appointed the right man this time.\\n\"His track record of success in winning leagues and cups across Europe throughout his career makes him the perfect choice,\" said Woodward.\\n\"In Louis van Gaal, we have secured the services of one of the outstanding managers in the game today.\\n\"Old Trafford provides him with a fitting stage on which to write new chapters in the Manchester United story.\"\\nIt seems Van Gaal has wasted no time in making his intentions clear.\\n\"Louis has already communicated some great ideas for how the club can move forward,\" said United co-chairman Avie Glazer.\\n\"The board is right behind him in his plans and everyone here is already looking forward to the start of next season.\"\\nGiggs, 40, who took charge for the final four games of the season following the departure of Moyes, met Van Gaal in the Netherlands last week to talk about his future.\\nLouis van Gaal is a world-class coach and I know I will learn a lot about coaching from being able to observe and contribute at such close quarters\\nHis appointment as assistant marks the end of an illustrious playing career during which he won 34 major trophies in 802 starts and 161 substitute appearances.\\n\"I am thrilled to have the chance to serve as assistant manager,\" said the Welshman.\\n\"Louis van Gaal is a world-class coach and I know I will learn a lot about coaching from being able to observe and contribute at such close quarters.\\n\"Manchester United has been a huge part of my life and I\\'m delighted to be able to continue that relationship in such a key role.\"\\nIn addition to Giggs, it has also been confirmed Frans Hoek, the current Netherlands\\' goalkeeping coach who was instrumental in the development of Edwin van der Sar, will become Van Gaal\\'s assistant coach, specialising in goalkeeping, whilst Marcel Bout has joined United as assistant coach, specialising in opposition scouting.\\nUnited finished seventh in the Premier League, after a title defence that featured one-sided defeats by Manchester City, Liverpool and Chelsea.\\nThey have failed to qualify for the Champions League for the first time since 1995-96 and are out of European football entirely for the first time in 25 years.\\nClub legend Giggs, Real Madrid boss Carlo Ancelotti and Borussia Dortmund manager Jurgen Klopp had been linked to the post, but Van Gaal is the man trusted to restore the club to the top of the domestic and European game.\\nFormer United assistant manager Mike Phelan told BBC Radio 5 live said: \"He\\'s got a big personality, but for a club like Manchester United that\\'s what is required. You have to get on with the job and hit the ground running and I\\'m sure he will do that.\"\\nKnown for employing an attacking style and his demands for discipline from his players, he came to prominence when he guided a young Ajax team, featuring Clarence Seedorf, Edgar Davids and Patrick Kluivert, to a Champions League final victory over AC Milan in 1995.\\nVan Gaal claimed in his 2009 autobiography he had been lined up to replace Sir Alex Ferguson at United in 2002, but the Scot changed his mind to continue at the helm for another 11 years.\\nHe won two Spanish league titles with Barcelona, but failed to qualify for the 2002 World Cup with the Netherlands.\\nVan Gaal returned to Barca, but left the Catalans only three points above the relegation zone in La Liga when he was dismissed after half a season.\\nHe revived his reputation back in his homeland, leading AZ Alkmaar to only the second Dutch title in their history, and then, in his first season in charge, took Bayern Munich to the German title and the Champions League final in 2010.\\nHe was dismissed after results tailed off in the following campaign but laid the foundations for Bayern\\'s current domination of German football by promoting young players such as midfielder Thomas Muller.\\nHe has a strong relationship with United striker Robin van Persie, whom he installed as Netherlands captain in June 2013, and is expected to be given significant transfer funds to bring in new players as the club plot their path back to the top.\\n\"I have been extremely impressed by his intelligence, thoughtful approach to the role and his diligence,\" said Woodward. \"I am looking forward to working with him.\"\\nChelsea manager Jose Mourinho praised Van Gaal\\'s credentials and character.\\n\"He is a great football manager and I am happy he joins me in the same country and the Premier League,\" said the Portuguese.\\n\"But more important than that, he\\'s a great guy, a great man and I wish him well.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Water firm United Utilities is warning people about the dangers of swimming in Cumbria's reservoirs.\", 'negatives': [], 'positives': ['The company said recent incidents have included a father teaching his son how to \"tombstone\" - jumping from height into water- and drunk teenagers leaping from towers.\\nUnited Utilities said the reservoirs are \"deep, freezing and deadly - no place for a quick dip\".\\nThe warning comes ahead of the school summer holidays.\\nUnited Utilities has more than 180 reservoirs which it said frequently attract risk-taking swimmers when the weather heats up.\\nHazards include submerged objects, underwater currents and cold water.\\nSteve Hardcastle from United Utilities\\' Health and Safety team said: \" The last thing we want is for a fun day out to turn into a tragedy.\\n\"While teenagers are statistically the most likely to put themselves in harm\\'s way, we\\'ve seen adults and even parents with young children taking the plunge, not realising just how much danger they are in.\\n\"We\\'re not trying to be killjoys or to prevent people from enjoying the summer.\\n\"The risks of reservoir swimming are very real - and we want to people to stay safe.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'China’s Geely auto group has become the main sponsor behind the British Bloodhound supersonic car project.', 'negatives': [], 'positives': ['The Asian company’s support means the jet-cum-rocket racer now has the financial means to go and break the land speed record next year.\\nGeely is the largest privately owned car manufacturer in China.\\nIt is perhaps better known in the West as the owner of Volvo and the London Taxi Company, which makes “black cabs”.\\nBloodhound aims to raise the current land speed record (763mph/1,228km/h) to 800mph (1290km/h) in October 2017.\\nThe intention then is to make some alterations to the vehicle and raise the mark still further some 12 months later. The ultimate target is to go above 1,000mph (1,610km/h).\\nThe driver will be Andy Green, who holds the current land speed record.\\nGeely - more properly known as the Zhejiang Geely Holding Group - will provide some engineering assistance to Bloodhound, as well promoting its STEM message across Asia.\\nThe whole Bloodhound venture was started as a way to engage children in science subjects and skills.\\nThousands of schools in the UK and across 10 countries have picked up this initiative, and are using model rocket cars to teach fundamental concepts, such as Newtonian laws. Geely wants to spread some of these educational ideas across China.\\nAsh Sutcliffe is the auto-maker\\'s communications manager: \"We will help push the Bloodhound story in China. We will send engineers over to the UK. Geely engineers will be very much involved in this project, working alongside the Bloodhound team. We want to take this story across China in the next few months.\"\\nBloodhound had been in hibernation before the auto group’s intervention.\\nThe supersonic car had largely been constructed but there was not enough cash to go racing on its specially prepared track in Northern Cape, South Africa.\\nThat problem has now gone away with the single biggest sponsorship deal in the project’s eight-year history. All debts have been cleared and there is sufficient liquidity to carry the effort through to its next phase.\\nBloodhound director Richard Noble said: \"When Andy Green and I started this project we realised it was going to be a huge undertaking and it needed to be global. We had to find the right partners with the correct spirit and ambition, and we\\'re delighted this dynamic, exciting business (Geely) has decided to join the team.\"\\nAnd Andy Green added: \"We can now tell a partnership story of a global engineering adventure, not just in China but across Asia. We couldn\\'t have done that before.\"\\nEngineers who took a “holiday” from the project during its hiatus are now coming back in.\\nThe vehicle is presently at the Bloodhound technical centre in Bristol, being stripped down from its initial \"dry build”, prior to being reassembled, with fluids, ready to start running.\\nA key task is to complete the development of the vehicle\\'s rocket system.\\nBloodhound will be using a Eurofighter-Typhoon jet engine to get itself rolling and to reach speeds in the low hundreds (mph), but it will need a booster to take it through the sound barrier and on to 800mph.\\nThe rocket itself is being sourced from the Nammo company in Norway, but it will use a Bloodhound-designed gearbox and oxidiser pump driven by a Jaguar V8.\\nTesting of these elements all operating together is just about to get under way.\\n\"In July next year we will be down at Newquay (airport) to go 200mph,\" said chief engineer Mark Chapman. \"That\\'s for shakedown runs of the whole car. Then we go out to South Africa in September/October to go 800mph.\"\\nJonathan.Amos-INTERNET@bbc.co.uk and follow me on Twitter: @BBCAmos'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"An Indian has climbed Mount Everest twice in under a week in what may be a new woman's record for the fastest double ascent.\", 'negatives': [], 'positives': [\"Anshu Jamsenpa, a 37-year-old mother-of-two, reached the summit on 16 and 21 May, tourism official Gyanendra Shrestha confirmed to BBC Nepali.\\nThe current Guinness record for a woman's double ascent is seven days.\\nNews of Ms Jamsenpa's climbs came as at least three climbers were killed on the mountain over the weekend.\\nAn Australian died on the Tibetan side, while a Slovak and an American died on the Nepalese side. Rescuers have failed to locate a fourth climber, from India, who disappeared shortly after reaching the summit.\\nHundreds of mountaineers are hoping to scale the world's highest peak before the monsoon sweeps in next month.\\nIt's the second time Ms Jamsenpa, who is from the Indian state of Arunachal Pradesh, has notched up an Everest double ascent. Her previous feat was in 2011, but those ascents came 10 days apart.\\nShe will now have to approach Guinness World Records to register her climbs after they have been certified by Nepal's ministry of tourism.\\nThe current woman's record was set by Nepalese climber Chhurim Sherpa in 2012.\\nApart from her two double ascents, Ms Jamsenpa also scaled the mountain in 2013.\\nHer husband, Tsering Wange, told the BBC that her plan was always to do a double ascent twice, but her second attempt did not succeed in 2014 due to an avalanche and in 2015 because of the devastating Nepal earthquake.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Carlisle United have agreed a one-year deal with striker Jabo Ibehre, with a view to a further 12 months.', 'negatives': [], 'positives': ['Ibehre, 32, left Colchester United at the end of last season after loan spells at Oldham and Barnsley, three of his eight professional clubs.\\nHis most profitable spell came with Leyton Orient, for whom he scored 41 goals in 243 appearances.\\n\"Jabo will give us a focal point,\" Cumbrians boss Keith Curle told the club website.\\n\"I\\'ve said before that we have needed more attacking options. He\\'s a good, solid professional.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'An Australian nurse suspected of helping the so-called Islamic State is returning home under police escort.', 'negatives': [], 'positives': ['Muslim convert Adam Brookman, who is returning voluntarily, says he travelled to Syria to do humanitarian work but was forced to work with IS.\\nJustice Minister Michael Keenan said he was entitled to return but would be investigated.\\nThe nurse will be the first Australian to return from Syria or Iraq since the country brought in new terror laws.\\nThe laws made it a crime to assist militant groups in the Middle East.\\nMr Brookman - who has not at this stage been charged - told Fairfax Media in May that he travelled to Syria to use his nursing skills in the civil conflict, which he believed was being ignored by the international community.\\nBut he said he was forced to join IS after being injured in an airstrike and taken to a hospital controlled by the militants.\\nMr Keenan told Australia\\'s ABC News all returning Australians were subject to the law. \"The issue is if somebody has involved themselves in the conflict in Iraq and Syria,\" he said.\\n\"If they\\'ve supported or fought alongside a terror organisation, what is it that we\\'re going to do with them if they return to Australia as they\\'re legally entitled to do?\"\\nA spokesperson for the Australian Federal Police (AFP) said: \"If there is evidence an Australian has committed a criminal offence under Australia law while involved in the conflict in Syria and Iraq, they will be charged and put before the courts.\"\\nPolice said the nurse\\'s return from Syria, via Turkey, was being managed \"in co-operation with relevant local authorities\". He was reportedly met in Turkey by Australian police, who accompanied him on a flight to Sydney.\\nUnder Australia\\'s new Foreign Fighters legislation, it may be enough to simply have travelled to Syria or Iraq to face charges.\\nThe legislation has also strengthened the offences of training with, recruiting for and funding terrorist organisations and made it easier to prosecute foreign fighters by making it illegal to travel to a declared area overseas.\\nIn December, 2014, Australia specifically proscribed travel to Syria\\'s Raqqa province, which is held by IS.\\nAccording to the government, at least 100 Australians are fighting with terror groups in the Middle East, and another 150 people in Australia are known to be supporting such groups.\\nMeanwhile, the body of an Australian man killed fighting with a Kurdish group in Syria will be returned to Australia on Friday.\\nAccording to the Australian Broadcasting Corporation, 23-year-old Reece Harding travelled to the Middle East in May to fight against IS militants and was killed after he stepped on a land mine.\\nA funeral for Mr Harding is expected to be held on Sunday.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Aston Villa left-back Antonio Luna has joined Italian Serie A side Verona on a season-long loan.', 'negatives': [], 'positives': [\"The Spaniard, 23, moved to Villa from Sevilla for an undisclosed seven-figure fee on a three-year deal in June 2013.\\nBut after scoring on his debut, Luna went on to make just 18 first team appearances and did not feature at all from January onwards.\\nHe is the third of last year's signings to be loaned out this summer, following Nicklas Helenius and Yacouba Sylla.\\nDanish striker Helenius has returned home to Aalborg on a similar deal, while Mali international midfielder Sylla has also made a season-long loan move to Turkish side Kayseri Erciyesspor.\\nVilla, who have lost their last two friendlies to Chesterfield and Groningen, continue their pre-season warm-up with a trip to neighbours Walsall on Tuesday evening before taking on Serie A side Parma on Saturday.\\nThey kick off the new Premier League season at Stoke on 16 August.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Jeremy Clarkson is set to make his first appearance on the BBC since losing his job as co-presenter on Top Gear.', 'negatives': [], 'positives': ['The controversial broadcaster will appear as the guest host of Have I Got News for You on 24 April.\\n\"Jeremy\\'s contract has not been renewed on Top Gear but he isn\\'t banned from appearing on the BBC,\" a BBC spokesman said.\\nClarkson has hosted the satirical news quiz on numerous occasions.\\nDuring one appearance in 2008, he threw a pen at regular panellist Ian Hislop that left the latter with a cut on his face.\\nClarkson was suspended by the BBC on 10 March following a \"fracas\" with Top Gear producer Oisin Tymon in a hotel in North Yorkshire.\\nMr Tymon suffered swelling and a split lip in the assault on 4 March and visited a hospital A&E department for his injuries.\\nFollowing an internal investigation, the BBC announced on 25 March Clarkson\\'s contract on Top Gear would not be renewed.\\nMore than a million fans signed a petition to reinstate the presenter, but BBC director general Tony Hall said \"a line has been crossed\" and \"there cannot be one rule for one and one rule for another\".\\nOn Tuesday, North Yorkshire Police said there was \"no need for further action\" against Clarkson following an inquiry into the \"fracas\".\\nTop Gear is watched by some 350 million viewers worldwide and is one of the BBC\\'s biggest properties - with overseas sales worth an estimated Â£50m a year.\\nThe BBC has said the show will continue without Clarkson, however it is unclear whether co-presenters James May and Richard Hammond will remain.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"The Tour de France finishes on Sunday and it's been a wild ride so far for cycling fans.\", 'negatives': [], 'positives': ['Great Britain\\'s Chris Froome is still leading - and wearing the famous yellow jersey. He\\'s looking to take his fourth Tour title.\\nIt\\'s all still to play for in the final stages - but here are our highlights so far...\\nFrance\\'s most famous race started in Germany, of course!\\nIt kicked off in Dusseldorf, with Britain\\'s Geraint Thomas winning the first stage.\\nThe Tour regularly starts in other countries to drum up excitement for international fans, but always finishes in Paris, France.\\nThis year\\'s Tour has visited four countries in total - Germany, Belgium and Luxemburg, before heading into France.\\nDeciding the stage seven winner was a very tricky task - with cyclists Marcel Kittel and Edvald Boasson Hagen crossing the line at what seemed like exactly the same time.\\nThe race jury had to look at special slow-mo pictures and decided that Kittel had won - but only by six millimetres.\\nPerhaps surprisingly, there isn\\'t a women\\'s Tour de France. Instead, the women have to make do with a shorter, two stage race called \\'La Course\\'.\\nDutch cyclist Annemiek Van Vleuten won the first stage of La Course on Thursday. It\\'s a great victory for her, particularly as suffered broken bones in a crash in the Rio Olympics.\\nBut there was good news for Britain too, as Lizzie Deignan came second.\\nSprinter Mark Cavendish crashed out of the Tour in stage four, after he came off his bike while sprinting for the finish line.\\nFellow cyclist Peter Sagan was disqualified for \"seriously endangering\" other competitors with his cycling, which caused the crash.\\nCavendish was out of the Tour, with a broken shoulder.\\nCyclist Pawel Poljanski sent the internet into meltdown when he he posted this picture of his incredibly vein-y legs.\\nHe shared the snap after completing the 16th stage of the race, saying \"After sixteen stages I think my legs look little tired.\"\\nDon\\'t worry though - it all because there is so much muscle in his legs, compared with the amount of fat.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The Festival of Code, a national event for all aspiring tech superstars, kicks off today.', 'negatives': [], 'positives': [\"Media playback is unsupported on your device\\n27 July 2015 Last updated at 08:17 BST\\nThe week-long event which is the world's largest hackathon for young people is expecting 1,200 coders hosted at 70 centres across the UK.\\nIt's set to uncover the next generation of tech leaders.\\nBBC reporter Tim Muffett was there and sent us this report.\\nCheck out Newsround's top coding tips.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Iranians are voting in the second round of elections which will decide the balance of power between moderates and conservatives in parliament.', 'negatives': [], 'positives': [\"In February's first round, reformists made substantial gains but need to win 40 more seats to control the 290-member parliament.\\nFriday's elections take place in 68 constituencies where no candidate won the minimum 25% of the vote.\\nPolls are open until 13:30 GMT and results are expected on Sunday.\\nFebruary's vote was the first since Iran signed a nuclear deal with world powers and was seen as a key test for reformist President Hassan Rouhani.\\nModerate allies of Mr Rouhani won 106 seats with a landslide victory in the capital, Tehran.\\nThe results in Tehran were significant because lawmakers from the capital usually determine the political direction of the house, analysts say.\\nReformists also made gains in elections for the Assembly of Experts, which appoints the country's most powerful official, the Supreme Leader.\\nModerates, however, did less well in constituencies outside the capital, which is where Friday's voting is taking place.\\nCorrespondents say that although the parliamentary elections are not expected to herald large-scale changes in Iranian policies, they could help President Rouhani push through economic and social reforms.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Great Britain have already secured two curling medals at Sochi 2014 and the men's team are out to make sure one of them is gold when they face Canada in the Winter Olympic final on Friday.\", 'negatives': [], 'positives': [\"Here are 10 facts about the sport to impress your friends ahead of the big match, which will be shown live on BBC TV, online, mobile devices and app from 13:30 GMT.\\n1. The first recorded evidence of curling being played in Scotland and the Netherlands dates back to the 16th century. The first rules of the game were drawn up in 1838 and the Grand Caledonian Curling Club, the sport's first governing body, was formed in Edinburgh.\\nFour years later, the Earl of Mansfield gave a demonstration of the sport on the ballroom floor of Scone Palace near Perth during a visit by Queen Victoria.\\nShe was so impressed that she gave permission for the club's name to be changed to the Royal Caledonian Curling Club - which still governs the sport in Scotland today.\\n2 Celebrity curling fans include George Clooney, who reportedly got hooked on the sport while filming the movie Perfect Storm in Canada in 2000, and rocker Bruce Springsteen, who, according to the Toronto Star, loves to stop off for a game when he tours with the E Street Gang.\\nMeanwhile, footballers at Premier League club Southampton have become so addicted to the sport they have been trying out their own version of curling in their dressing room.\\n3. Curling stones are made of granite and weigh between 17.24kg and 19.96 kg. The granite comes from two sources - the Scottish island of Ailsa Craig and the Trefor Granite Quarry in Wales. Stones for the Sochi Winter Olympics are manufactured by Kays of Scotland, who have been making curling stones since 1851 and have the exclusive rights to the Ailsa Craig granite.\\nThe sweeping brushes used to be made of corn strands and were similar to household brooms. Broom heads are now made of fabric, hog hair or horse hair with nylon fabric covering the brush head.\\n4. Curling has featured in many television programmes and films, including the Beatles movie Help! where the Fab Four play the game, only for one of the stones to be booby-trapped by a bomb. In On Her Majesty's Secret Service, James Bond walks past girls playing curling at the top of Piz Gloria - Blofeld's mountain-top retreat.\\n5. In Scotland, curling competitions were held outdoors on frozen lochs and ponds until the advent of indoor ice rinks in the 20th century. However some outdoor competitions still remain in Scotland including some staged by Carrbridge Curling Club in Inverness-shire.\\nThe best known outdoor competition in Britain was the Grand Match, which was held on the Lake of Menteith in Stirling and was traditionally between the north and south of Scotland. However the tournament, which can attract thousands of curlers, has not been held since 1979 because the loch has not frozen to the required depth of seven inches of ice.\\n6. In 1912, bodies that were recovered from the Titanic after it sank off the coast of Canada were taken to the Mayflower Curling Club's home in Agricola Street, Halifax, Nova Scotia, which was set up as a temporary morgue. The building was the only one in the city that was large enough and cold enough for the task.\\n7. England's most important contribution to 19th-century curling was the invention of artificial ice. In 1877, a rink opened in Manchester and the world's first curling match on artificial ice took place in March of that year. But the rink closed soon after.\\n8. In 2008, American TV network NBC secured an exclusive option to air a 10-episode sports reality show called Rockstar Curling. The plan was to give the winners a chance at competing in the US Championships and even go to the 2010 Winter Olympics. Think X-Factor on ice. In the end, the option wasn't taken up.\\n9. Curling made its Olympic debut in Chamonix in 1924 where Great Britain beat Sweden and France and, after demonstration events at Lake Placid (1932), Calgary (1988) and Albertville (1992), it finally made its full Olympic medal debut in Nagano in 1998.\\n10. Good sportsmanship, referred to as 'the spirit of curling' is an integral part of the game. You should always congratulate your opponent on a good shot, and never cheer a mistake or miss. Traditionally the winners have to buy the losers a drink after the match.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Two \"staggeringly incompetent\" hitmen must serve a minimum of 40 years each in jail for stabbing to death an innocent student after they targeted the wrong house.', 'negatives': [], 'positives': ['Aamir Siddiqi, 17, was attacked at his Cardiff home by Jason Richards, 38, and Ben Hope, 39, in April 2010.\\nThe pair were paid Â£1,000 each to kill a different man on a nearby street.\\nSentencing them to life for murder at Swansea Crown Court, the judge said few would shed a tear if they died in jail.\\nThe pair were found guilty of Aamir\\'s murder and the attempted murder of his parents last Friday, 1 February, after a four-and-a-half month trial.\\nThe Siddiqi family said in a statement that they believed the sentences were \"appropriate\".\\nThe judge, Mr Justice Royce, said he had no choice but to \"significantly increase\" the minimum term of 30 years the prosecution had asked for.\\n\"He (Aamir) was awaiting the arrival of his Koran teacher when he rushed past his parents to open the door,\" he said.\\n\"You two (Hope and Richards) came in, wearing balaclavas and making a terrible wailing sound.\\n\"Your attack on him was brutal, savage, callous and cruel.\"\\nHe said Aamir was \"hacked\" to death in front of his parents who were fortunate not to have been killed too as they fought in vain to save him.\\n\"If you die in jail, few will shed a tear and many will say it will be more than deserved,\" the judge told Hope and Richards.\\nThe judge went on to say the statements from the Siddiqi family were the most poignant he had come across.\\nThe judge described Aamir as a \"bright, gentle and courteous boy who was much loved by his family\".\\n\"He had secured a place to study law at Cardiff and his future was brimming with promise,\" he said.\\nAfter sentencing, Umbareen Siddiqi, Aamir\\'s sister, said: \"On behalf of the family, we\\'re delighted. We feel this sentence is appropriate.\\n\"Our brother won\\'t return to us but this will go some way to achieving peace for all of us.\\n\"I would like to once again thank South Wales Police, the CPS (Crown Prosecution Service), friends and family and the wider Cardiff community and Victim Support.\"\\nAamir\\'s sister Nishat Siddiqi later tweeted: \"Am amazed and humbled by the kindness, love and support shown to my family and me in the aftermath of Aamir\\'s murder. I will never forget.\"\\nHope and Richards both denied murdering Aamir and the attempted murder of his parents but were convicted unanimously of all charges.\\nDuring their trial, the court heard how Aamir had run down the stairs of the family home at Ninian Road in Roath, expecting to see his imam for a Koran lesson.\\nInstead, he was confronted by Richards and Hope, high on heroin and wearing masks.\\nThey wielded daggers over their heads and howled as they set upon the helpless A-level student.\\nAamir\\'s parents frantically tried to help their only son. His mother, Parveen, leapt on the back of one of the attackers as he pursued Aamir in the dining room of their home.\\nHis father, 68-year-old Sheikh Iqbal Ahmad, tried to pin the other against a wall using his head. Both were stabbed in the process.\\nDuring the trial, the truth emerged that Aamir\\'s killers had carried out a contract killing on the wrong victim, in the wrong house.\\nRichards and Hope had been paid by a businessman, angry over a collapsed property deal, to kill a father-of-four who lived in a neighbouring street.\\nAfter the murder, a huge manhunt began, and the killers\\' stolen Volvo car used in the crime was later found abandoned. Traces of Aamir\\'s blood were found in the car\\'s footwell, as were Hope\\'s fingerprints and Richards\\' DNA.\\nAfter the killing the men were each paid Â£1,000 cash. Hope bought a pair of trainers and a laptop computer with the money.\\nDetectives pieced together the movements of both men before and after the killing by using the city\\'s CCTV network and mobile phone evidence was also gathered.\\nBoth men were arrested within days and immediately blamed each other for the killing. Hope told police he would not \"take the rap\" for something he did not do and drug addict Richards denied the killing.\\nBut on the second day of deliberations last Friday, the jury rejected the killers\\' claims and convicted both men of the murder and attempted murders.\\nAfter sentencing, Det Supt Paul Hurley, of South Wales Police, said: \"This is a substantial custodial sentence reflecting the horrific and brutal murder of young Aamir Siddiqi in his own home.\\n\"South Wales Police would like to thank the communities of Cardiff for their continued support, all the prosecution witnesses who\\'ve played an important role in this investigation and importantly the family of Aamir Siddiqi who\\'ve shown the utmost dignity and respect throughout this process.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'DUP leader Peter Robinson has said BBC bosses have not strengthened their \"threadbare argument\" for excluding his party from TV election debates.', 'negatives': [], 'positives': [\"He was speaking after senior DUP figures met the BBC's director of news and current affairs to discuss his party's appeal against its exclusion.\\nJames Harding said he remained hopeful that the debates would be broadcast as planned in April.\\nThe DUP has threatened to seek a judicial review of the decision.\\nSpeaking after the meeting in Belfast, Mr Harding said there were still a few stages to go before the dispute might reach the courts.\\nHe defended the BBC against the accusation that it was treating people in Northern Ireland as second-class citizens.\\nMr Robinson said he had not heard anything that was new from Mr Harding and BBC Northern Ireland Director Peter Johnston at the meeting on Thursday.\\nThe DUP leader said his party would await the outcome of its appeal to the BBC Trust, the corporation's arms-length regulator.\\nHe said the appeal, expected to be heard next month, would provide the BBC and other broadcasters with an opportunity to change their position before the matter goes to court.\\nDUP deputy leader Nigel Dodds said a lot of activity was taking place behind the scenes, and a number of parties at Westminster were unhappy with the planned seven-party format.\\nThe DUP had written to the BBC and ITV asking for an explanation as to why the party had not been invited to take part in the live televised election debates.\\nIn his written reply to the DUP, BBC Director General Lord Hall is understood to have said the decision not to include them complied with the BBC's obligations of impartiality.\\nThe BBC and ITV are currently planning to hold two debates involving the Conservatives, Labour, Liberal Democrats, UKIP, Plaid Cymru, the SNP and the Greens.\\nThe DUP is currently the fourth largest party in the Commons, with eight MPs.\\nA third debate - hosted by Sky and Channel 4 - would feature a head-to-head between Prime Minister David Cameron and Labour leader Ed Miliband.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Joe Garner marked his return to English football by scoring the winner for Ipswich Town against Birmingham City.', 'negatives': [], 'positives': ['Blues were the more threatening side before the break, with Che Adams and Clayton Donaldson both going close.\\nIpswich suffered a first-half blow, with Andre Dozzell leaving the field on a stretcher with a knee injury.\\nTown returned from the interval buoyant and Garner met a Jonas Knudsen cross to slide home, while Freddie Sears failed to add a second from close range.\\nIpswich goalkeeper Bartosz Bialkowski made a series of saves either side of the break to ensure Ipswich, a side that lost their final pre-season match 6-1 to League One side Charlton a week earlier, claimed all three points in their Championship opener against Harry Redknapp\\'s Blues.\\nMarc Roberts, one of thee summer arrivals to start for Blues, and Emilio Nsue were among those to be denied by the home goalkeeper.\\nEighteen-year-old midfielder Dozzell, who helped England win the Under-19 European Championship title last month, looked bright for the hosts and played with poise, but needed treatment once before eventually being forced off in first-half injury time.\\nWhile it made for a miserable end to the first half, Garner ensured the second started positively, scoring his first goal in the Championship since April 2016, in what was his last full campaign in England\\'s second-tier before leaving Preston for one season in the Scottish Premiership with Rangers.\\nIpswich manager Mick McCarthy:\\n\"For me it was vital we won and played well. I\\'ve had lovely support but there would have been an element waiting for me and I wouldn\\'t blame them because we were rubbish last year.\\n\"Somebody asked me about my ambition and that is to build a team and win games.\\n\"I\\'ve had lovely support from everybody at the club and the fans. They turned up and it humbles me. It was nice to repay it with a good performance and a win.\"\\nMatch ends, Ipswich Town 1, Birmingham City 0.\\nSecond Half ends, Ipswich Town 1, Birmingham City 0.\\nAttempt missed. Cheikh Ndoye (Birmingham City) with an attempt from the centre of the box misses to the left. Assisted by Craig Gardner with a cross following a corner.\\nCorner,  Birmingham City. Conceded by Tommy Smith.\\nMarc Roberts (Birmingham City) is shown the yellow card for a bad foul.\\nCole Skuse (Ipswich Town) wins a free kick on the right wing.\\nFoul by Marc Roberts (Birmingham City).\\nAttempt blocked. Freddie Sears (Ipswich Town) right footed shot from outside the box is blocked.\\nDelay over. They are ready to continue.\\nDelay in match Tommy Smith (Ipswich Town) because of an injury.\\nAttempt saved. Cheikh Ndoye (Birmingham City) header from the centre of the box is saved in the top centre of the goal. Assisted by Marc Roberts with a cross.\\nFlynn Downes (Ipswich Town) wins a free kick in the defensive half.\\nFoul by Craig Gardner (Birmingham City).\\nFoul by Tommy Smith (Ipswich Town).\\nChe Adams (Birmingham City) wins a free kick on the right wing.\\nOffside, Ipswich Town. Grant Ward tries a through ball, but Freddie Sears is caught offside.\\nSubstitution, Birmingham City. Cheick Keita replaces Jacques Maghoma.\\nJoe Garner (Ipswich Town) wins a free kick in the defensive half.\\nFoul by Michael Morrison (Birmingham City).\\nAttempt missed. Freddie Sears (Ipswich Town) left footed shot from very close range is close, but misses to the left. Assisted by Jordan Spence.\\nCole Skuse (Ipswich Town) wins a free kick in the defensive half.\\nFoul by Clayton Donaldson (Birmingham City).\\nSubstitution, Ipswich Town. Adam Webster replaces Dominic Iorfa.\\nJonas Knudsen (Ipswich Town) wins a free kick in the defensive half.\\nFoul by David Davis (Birmingham City).\\nGrant Ward (Ipswich Town) wins a free kick in the defensive half.\\nFoul by Cheikh Ndoye (Birmingham City).\\nCorner,  Birmingham City. Conceded by Cole Skuse.\\nDominic Iorfa (Ipswich Town) wins a free kick in the defensive half.\\nFoul by Che Adams (Birmingham City).\\nFoul by Tommy Smith (Ipswich Town).\\nNsue (Birmingham City) wins a free kick in the attacking half.\\nAttempt missed. Craig Gardner (Birmingham City) left footed shot from outside the box is close, but misses to the right.\\nJoe Garner (Ipswich Town) wins a free kick in the defensive half.\\nFoul by Jonathan Grounds (Birmingham City).\\nAttempt missed. Cheikh Ndoye (Birmingham City) header from the centre of the box is high and wide to the right. Assisted by Che Adams with a cross.\\nAttempt missed. Tommy Smith (Ipswich Town) header from the centre of the box misses to the left. Assisted by Grant Ward with a cross following a corner.\\nCorner,  Ipswich Town. Conceded by Che Adams.\\nCorner,  Ipswich Town. Conceded by Jonathan Grounds.\\nAttempt blocked. Cole Skuse (Ipswich Town) left footed shot from outside the box is blocked.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The BBC has live coverage of the diving at the 2017 World Aquatics Championships in Budapest on television, online, mobile app and Connected TV between 14-21 July.', 'negatives': [], 'positives': [\"Olympic champions Chris Mears and Jack Laugher will be in action in the 3m synchro, while bronze medallists Tom Daley and Dan Goodfellow will be back on top of the 10m platform.\\nGrace Reid, who finished eighth in the 3m springboard in Rio, will be making her full World Series debut and will compete in both the individual, and synchro with new partner Katherine Torrance.\\nIn the 10m synchro, Tonia Couch and Lois Toulson will compete against pairs from China, Canada and Malaysia as they aim to get back on to the podium.\\nAll times are subject to change. The BBC is not responsible for any that may be made. Also coverage on BBC Red Button can experience late schedule changes, so details may differ from this page. Further programmes and times will appear when confirmed.\\nYou can view BBC Sport output as well as listen to our radio sports programming on the BBC iPlayer.\\nThe BBC Sport website is available via desktop, mobile, tablet and app, giving fast and easy access to the live stream, reports and on-demand highlights of the day's action. The BBC Sport app is available free on Apple and Android devices.\\nNational and regional variations have been included in this list where possible, but please check your local listings for more detailed information.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"The smash hit Harry Potter stage play has received 11 nominations ahead of next year's WhatsOnStage Awards - more than any other production.\", 'negatives': [], 'positives': [\"Harry Potter and the Cursed Child is up for best play, while five of its cast members have also been shortlisted.\\nGlenn Close, Ralph Fiennes, Billie Piper and Sheridan Smith are among the other actors in contention for prizes.\\nThe annual theatre awards, which are decided by a public vote, will be presented in London on 19 February.\\nBased on an original story by JK Rowling, Harry Potter and the Cursed Child has been a sold-out success since opening in June.\\nLast month the two-part production was named best play at the London Evening Standard Theatre Awards.\\nIts other nominations come for John Tiffany's direction and the design of its costumes, sets, lighting and video.\\nHalf a Sixpence leads in the musicals categories with eight nominations, while Groundhog Day has seven.\\nThere are also nominations for three actor knights - Sir Kenneth Branagh for The Entertainer, Sir Derek Jacobi for Romeo and Juliet, and Sir Ian McKellen for No Man's Land.\\nHollywood star Close is shortlisted for her performance in Sunset Boulevard at the London Coliseum, while Smith is recognised for her turn in Funny Girl.\\nFiennes and Piper are recognised for their widely acclaimed work in Richard III and Yerma respectively.\\nThe full list of nominations is available on the WhatsOnStage website. Theatregoers have until 31 January to cast their votes.\\nFollow us on Facebook, on Twitter @BBCNewsEnts, or on Instagram at bbcnewsents. If you have a story suggestion email entertainment.news@bbc.co.uk.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'US musician Allen Toussaint has died at the age of 77, Spanish authorities have confirmed to the BBC.', 'negatives': [], 'positives': ['The award-winning artist was known for songs like Working In The Coalmine, Southern Nights and Fortune Teller.\\nHe suffered a heart attack shortly after coming off stage at Madrid\\'s Teatro Lara on Monday night, reported Spanish newspaper El Mundo.\\nHe was found in his hotel and resuscitated - but suffered a second heart attack en route to hospital.\\nThe mortuary at the Madrid\\'s Hospital Fundacion Jimenez Diaz confirmed his death to the BBC.\\nA legend of New Orleans R&B, Toussaint worked with some of music\\'s biggest stars - including Paul McCartney, Irma Thomas, Aaron Neville, Joe Cocker, Glen Campbell and Elvis Costello.\\nHe had been due to play the London Jazz Festival this weekend.\\nToussaint was born in 1938 in the working class neighbourhood of Gert Town, New Orleans.\\nHe began learning piano at the age of seven, influenced by the likes of Huey \"Piano\" Smith  and Ray Charles, and got his big break when he was asked to fill in for an absent Fats Domino at a recording session.\\nIn 1960, Toussaint was hired by Joe Banashak\\'s Minit record label and masterminded many of the company\\'s biggest hits - including Irma Thomas\\'s Ruler of My Heart (later recorded by Otis Redding as Pain in My Heart) and Benny Spellman\\'s Lipstick Traces (On A Cigarette).\\nDrafted by the military in 1963, he continued to make music on service leave, but scored his biggest hits after his discharge in 1965.\\nHis most successful collaborations were with singer Lee Dorsey, who recorded Toussaint\\'s compositions Ride Your Pony, Get Out of My Life Woman, Working in a Coalmine and Everything I Do Gon\\' Be Funky.\\nMany of his songs became famous through cover versions, with the likes of The Who, The Rolling Stones, Robert Plant, Bo Diddley and The Doors re-interpreting his songs.\\nHe also produced Labelle\\'s signature hit Lady Marmalde in the 1970s, and released a collaborative album with Elvis Costello in 2006.\\nToussaint was inducted into the Rock and Roll Hall of Fame in 1998. The citation said his greatest contribution \"was in not allowing [New Orelans] old-school R&B traditions to die out but by keeping pace with developments in the rapidly evolving worlds of soul and funk.\\n\"In addition, he brought the New Orleans sound to the national stage, and it remains a vital and ongoing part of our musical heritage to this day.\"\\nFollowing Hurricane Katrina, he campaigned tirelessly for his hometown, raising money to support those left destitute by the disaster.\\nIn 2013, he was presented with America\\'s National Medal of Arts, the highest honour given to an American artist.\\n\"After his hometown was battered by Katrina and Allen was forced to evacuate, he did something even more important for his city - he went back,\" said President Obama at the award ceremony.\\n\"Since then, Allen has devoted his musical talent to lifting up and building up a city. And today, he\\'s taking the stage all over the world, with all kinds of incredible talent, doing everything he can to revive the legendary soul of the Big Easy.\"\\nToussaint is survived by his two children, including his son Clarence, known as Reginald, and his daughter, Alison, both of whom managed his career in recent years, reported New Orleans\\' broadcaster WWL-TV.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Swansea City boss Paul Clement praised the character of his team after their shock 3-2 Premier League win at Liverpool.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nTwo goals by Fernando Llorente put the Swans 2-0 up but Liverpool drew level through Roberto Firmino.\\n\"It would have been easy for the team to capitulate at that point but we went on and got another goal,\" said Clement.\\nGylfi Sigurdsson scored on the counter-attack, however, to give Clement his first win since taking over.\\nThe victory lifted the Swans off the bottom of the table and dented Liverpool\\'s Premier League title aspirations.\\nAll the goals came in the second half and Clement - who took over on 3 January after former manager Bob Bradley was sacked - said defence was the key to victory.\\n\"I think it\\'s going to give everyone a big boost, this victory,\" said Clement.\\n\"I\\'m very pleased not only with the result but with the performance. In the first half we frustrated Liverpool, made it very difficult for them to get through us.\"\\nClement said the key to the victory was the way in which his team reacted after Liverpool equalised in the 69th minute.\\n\"The crowd erupted the momentum was with Liverpool, but football is a strange game,\" he added.\\n\"We got that counter-attack opportunity against run of play.\\n\"We soaked up a lot of pressure, but we knew that would be the case and I think we deserved to win.\\n\"It\\'s very good for the confidence, and for me it reinforces that all the good work is done on the training ground in the week.\"\\nSwansea now have a 10-day break before facing Southampton on 31 January.\\nMedia playback is not supported on this device'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A £30,000 beach hut built on top of a seaside toilet block has won a prestigious architecture award.', 'negatives': [], 'positives': ['The hut, at Sandilands, near Sutton on Sea, scooped an award for architectural excellence from the Royal Institute of British Architects (RIBA).\\nOwner Tim Spring said he was delighted with the award, especially as the hut had met with some opposition at the planning stage.\\nHe said he now planned to take on another project elsewhere.\\nMore on this and other local stories from across Lincolnshire\\nThe project involved overhauling a former public toilet block on the Lincolnshire coast - revamping the existing building, and adding a rooftop beach hut.\\n\"It had a controversial starting point, there was quite a lot of opposition [to it],\" Mr Spring said.\\nHowever, he said people were now warming to the hut, which features views across the North Sea, with many taking selfies outside.\\nHe said he had started inviting people in to have a look at the the view from inside the 17-sq-m structure.\\nThe hut, which lights up at dusk due to it partly being made from translucent polycarbonate, also features a storage area, located in the old toilet block.\\nMr Spring, who was born and bred in Lincolnshire, said he had worked with a county-based firm of architects and a local builder.\\nHe said he planned to work with them again on a new project.\\nThe hut won the Riba Small Project of the Year award in the East Midlands.\\nIt will now go forward to be considered for national honours.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Former US President Bill Clinton has set out the case why his wife and \"best friend\" Hillary should lead the nation.', 'negatives': [], 'positives': ['He told the Democratic convention in Philadelphia that she was the \"best darn change-maker I\\'ve ever known\".\\nIn a very personal speech, he spoke warmly about how they met and her dedication to public service.\\nHours earlier, his wife became the first woman to be officially nominated for president by any major US party.\\nMrs Clinton ended the night with a video message, saying: \"I can\\'t believe we just put the biggest crack in that glass ceiling yet.\\n\"And if there are any little girls out there who stayed up late to watch, let me just say, I may become the first woman president but one of you is next.\"\\nEarlier, Mr Clinton shared the story of how he and his wife met at Yale Law School in the spring of 1971.\\n\"I married my best friend,\" he said. \"We\\'ve been walking and talking and laughing together ever since.\"\\nBill Clinton tried to accomplish two things on Tuesday night. He shared personal stories to paint a portrait of a woman who has been in the public eye for so long that she has become as ubiquitous as your living room wallpaper.\\nHe also wanted to position his wife as an effective champion of the change many Americans crave.\\nAlthough he dwelled on the details longer than necessary - with minutiae akin to a coma-inducing family reunion - he inundated the audience with examples of his wife as a mother, friend and compassionate life companion. It proved a stark contrast to Donald Trump, whose familial keynoters struggled to provide anything resembling touching personal anecdotes.\\nHis efforts to label his wife as a \"change-maker\", however, proved somewhat more ineffective. It\\'s easy to tout Mrs Clinton\\'s wealth of experience. It\\'s harder to fashion her as an outsider who will cleanse a system perceived by many to be broken.\\nCompetent and controlled doesn\\'t exactly capture the public\\'s imagination - and it proved to be a challenge for even a gifted orator like Mr Clinton. But he succeeded in revealing an emotive, human side of his wife.\\nThe former secretary of state and first lady was uniquely qualified to be president, he said.\\n\"Hillary opened my eyes to a whole new world of public service by private citizens,\" he said before recounting her early career.\\nHours before he spoke, his wife passed the 2,382 delegates needed to claim the nomination after South Dakota announced its delegate vote count.\\nIn a symbolic gesture of party unity, former Democratic rival Senator Bernie Sanders took the microphone to declare Mrs Clinton as the nominee by acclamation, to an eruption of cheers.\\nIn other highlights:\\nThe second night focused on race and justice, topics that dominated last week\\'s Republican National Convention in Cleveland.\\nDissention on the convention floor plagued the first day when Sanders supporters booed throughout the event.\\nMr Sanders later took centre stage as the final speaker on Monday night and directly told his supporters that \"\"Hillary Clinton must become the next president of the United States.\"\\nIn declaring her the nominee, Mr Sanders echoed Mrs Clinton in a role she played eight years ago after a hard-fought primary.\\nAt the 2008 Democratic National Convention, Mrs Clinton called for a vote for Barack Obama by acclamation, ending the roll call vote in an effort to unite the party behind his candidacy.\\nMrs Clinton will face off against Republican presidential nominee Donald Trump in November.\\nRecent national polls suggest the two candidates will be in a tight race for the White House.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A former bodybuilder accused of assault and child cruelty as part of a north Wales historical abuse inquiry has been cleared of all charges.', 'negatives': [], 'positives': ['Peter Steen, 75, of Wrexham, had worked at homes belonging to the former Bryn Alyn Community.\\nHe was found not guilty of four assault claims and four cruelty charges on Monday at Mold Crown Court.\\nOn Tuesday, the judge formally dismissed three other charges, after the jury failed to reach  verdicts.\\nThe charges all related to a period between 1978 and 1982.\\nThe prosecution was brought following investigations under the National Crime Agency inquiry (NCA), Operation Pallial.\\nJudge Niclas Parry formally discharged the jury and the Crown Prosecution Service said there would be no retrial following consultation with a senior crown prosecutor.\\nJudge Parry said: \"In all circumstances that makes perfect sense and is fair.\"\\nHe formally entered not guilty verdicts on the three outstanding charges.\\nSpeaking on behalf of Mr Steen following the end of the trial, his solicitor Chris Saltrese criticised the decision to prosecute his client, and the Operation Pallial investigation.\\n\"I am delighted for Mr Steen and his family that the jury have reached the correct verdicts and my client walks away from court an innocent man,\" he said.\\n\"A grave miscarriage of justice was avoided in Mr Steen\\'s case only by the even-handedness of the judge, the good sense of the jury and the great skill and determination of defence counsel.\\n\"Over the past 20 years care workers all over the United Kingdom, but in north Wales in particular, have been demonised by those who do not know the first thing about looking after challenging young people in care.\\n\"It is now time for this persecution to stop.\"\\nAn NCA spokesman said it accepted the jury\\'s decision but refuted Mr Saltrese\\'s comments.\\n\"This was a thorough and ethical investigation, which was independently reviewed by the Crown Prosecution Service,\" he added.\\n\"Channels are available if Mr Steen wishes to make any formal complaint.\"\\nOperation Pallial was set-up in November 2012 at the request of North Wales Police and the UK Home Secretary to examine fresh allegations of historical abuse at care homes in the region, and also to review past police investigations.\\nA year ago, former hotelier and the owner of Bryn Alyn Community homes, John Allen was jailed for life sexually assaulting youngsters in a campaign of abuse spanning decades.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Anne Wood, creator of children's television series In The Night Garden and the Teletubbies, believes TV is often blamed wrongly for children's inability to express themselves.\", 'negatives': [], 'positives': [\"2 October 2011 Last updated at 08:30 BST\\nShe told Kirsty Young that, without TV, some children would have very little mental stimulation at home.\\nAnne Wood's interview with Kirsty Young on Desert Island Discs will be broadcast on Sunday 2 October at 1115 BST on BBC Radio 4, and repeated at 0900 BST on Friday 7  October. Listen online or browse the extensive Desert Island Discs archive.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'It is incredibly bad economics to compare household finances and state finances.', 'negatives': [], 'positives': ['But occasionally it is useful, for illustrative purposes.\\nAnd today I want you to imagine what you would cut from your lifestyle if told that your income would fall by either 25% or 40%, after adjusting for inflation, over the next four years.\\nIt is quite a scary thought, isn\\'t it?\\nPresumably, if you haven\\'t done it already, you\\'ll think about switching the weekly shop to one of those discounters. You will heat up the water for fewer hours. And the kids\\' swimming lessons will have to go.\\nBut those savings would not even scratch the surface of a 40% cut. To reach that, the kids may have to share a bedroom, so you can take in a paying lodger. And the car would be history.\\nAll of which serves to explain why ministers and officials in all but protected departments and services - that is everything but health, schools, defence and overseas aid - are having panic attacks today.\\nBecause they have been instructed by the chancellor to \"model\" the impact on the services they provide of finding savings of either 25% or 40% by 2019-20 - or Â£20bn per annum of cuts in aggregate.\\nThis is the stuff of public-service reinvention, not efficiency. Which is not to say that better buying of paper clips won\\'t still yield something.\\nBut the last Parliament had a massive onslaught on waste, bad buying, duplication of services and under-use of assets.\\nThe low hanging fruit of improved productivity has already been picked.\\nNow ministers have to be bold and creative in doing more for less, if they are not simply going to kill the provision of some services we take for granted.\\nThe Treasury\\'s document, published today, talks a fashionable talk about how digital delivery and big data can work cost-saving miracles.\\nWell, maybe. But the brainy chaps who work for George Osborne are probably a bit like me, in that they understand the theory of all this without having a clue how to put it into practice.\\nWhich is not to say that the targets are unachievable or that in five years\\' time we will be a third-class country for culture, law and order, transport and so on.\\nBut it is to remind that ministers aren\\'t management-consultant productivity gurus. And we have a generation of civil servants, who grew up under the post-97 Labour government, who were better at spending than saving and were demonstrably appalling at IT.\\nThree other things.\\nFirst, austerity-loathing Scotland will detest the implied block-grant settlement for their nation that flows from this negotiation.\\nSecond, health may not be quite as protected as seems at first blanche, given all the Treasury\\'s enthusiastic talk about merging health and social care spending, and devolving management of the lot to the regions.\\nAnd finally, the implied cuts of between 12% and 18% (depending on who is measuring) imposed on the BBC a few days ago with the transfer to it of the free licence for over-75s no longer looks quite as savage as it did.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"President Vladimir Putin has said he was ready to put Russia's nuclear weapons on standby during tensions over the crisis in Ukraine and Crimea.\", 'negatives': [], 'positives': ['In comments in a documentary aired on state TV on Sunday, Mr Putin said the life of ex-Ukrainian leader Viktor Yanukovych had been in danger.\\nHe also said Russians in Crimea were in danger before Russia annexed it.\\nIn a previously released clip from the film, he said he ordered the annexation weeks before a referendum was held.\\nCrimea was formally absorbed into Russia on 18 March, to international condemnation, after unidentified gunmen took over the peninsula.\\nThe documentary aired amid speculation over Mr Putin\\'s whereabouts with the Russian leader having not been seen in public since 5 March.\\nThe Kremlin has denied rumours that the president might be sick or even dead and says Mr Putin will meet his Kyrgyz counterpart, Almazbek Atambayev, on Monday.\\nSpeaking on the documentary - called The Path To The Motherland - Mr Putin said: \"We never thought about severing Crimea from Ukraine until the moment that these events began, the government overthrow\".\\nOn putting Russia\\'s nuclear weapons into a state of combat readiness, Mr Putin said: \"We were ready to do this.\"\\n\"[Crimea] is our historical territory. Russian people live there. They were in danger. We cannot abandon them,\" he added.\\nHe said he used a \"closed opinion poll\" of Crimeans to judge whether they wanted to remain in Ukraine and found that \"75% of the general population desired to join Russia\". No details of how the survey was conducted were given by Mr Putin.\\nRussia initially denied that soldiers who appeared in Crimea without military insignia on their fatigues - dubbed the \"little green men\" - were Russian.\\nBut Mr Putin subsequently admitted deploying troops on the peninsula to \"stand behind Crimea\\'s self-defence forces\".\\nThe formal annexation of Crimea sparked unrest in eastern Ukraine in April, when pro-Russian protesters occupied government buildings in Donetsk, Luhansk and Kharkiv demanding independence.\\nA month later, pro-Russian separatists in Donetsk and Luhansk declared independence from Ukraine after unrecognised referendums.\\nUkraine responded by launching an \"anti-terrorist operation\" against them and the region became engulfed in a conflict which has cost at least 6,000 lives, according to the UN.\\nUkraine crisis: Timeline\\nThe Ukrainian government, Western leaders and Nato say there is clear evidence that Russia is helping the separatists with heavy weapons and soldiers. Independent experts echo that accusation.\\nMoscow denies it, insisting that any Russians serving with the rebels are \"volunteers\".\\nFull details of Mr Yanukovych\\'s escape from Ukraine are unclear although Mr Putin spoke of Russian efforts to evacuate him and threats against his life.\\n\"For us it became clear and we received information that there were plans not only for his capture, but, preferably for those who carried out the coup, also for his physical elimination,\" Mr Putin says in the film.\\nHe said preparations to extract Mr Yanukovych were made by land, sea and air, saying \"heavy machine guns\" were placed in Donetsk \"so as not to waste time talking\".\\nRussia\\'s Interfax news agency quoted Mr Putin as saying that saving the life of Ukraine\\'s former leader and his family was a \"good deed\".\\nThe documentary was made by Andrei Kondrashov, a journalist with state-run channel Rossiya-1.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The Libyan Football Federation (LFF) has confirmed that the Libyan Soccer League will resume on 15 May.', 'negatives': [], 'positives': ['The league has been suspended since 2014 season because of the security troubles in the country.\\nLFF chairman Anwar Al-Tishani said: \"We had meetings with the heads of the clubs, official authorities, security officials, and the conditions look suitable to start the 2015-16 League.\"\\nOn Thursday in Tripoli, the LFF conducted the draw for the season.\\nTwenty-one teams have been divided into two groups.\\nGroup One includes nine clubs from the east, two of which will qualify for the final round. Group 2 will have 12 clubs from the west, south, and central regions, three of which will qualify for the final round.\\nThe most recent league champions were Al Ahli from Tripoli, who the title for the 11th time in its history.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"British special gymnastics champion Alex Buesnel has become the first gymnast with learning difficulties to make Jersey's Island Games squad.\", 'negatives': [], 'positives': ['The 24-year-old, who has autism, is a nine-time British champion and won gold at the 2011 Special Olympics World Summer Games.\\nHe is part of a 13-strong squad heading to Gotland this summer.\\n\"It\\'s a great honour and I\\'m really pleased that records keep breaking,\" Buesnel told BBC Radio Jersey.\\nGymnastics was left out of the programme at the 2015 Island Games in Jersey.\\nBut Buesnel won two silver medals as part of a Jersey squad that went to a gymnastics event in Ynys Mon organised by islands who still wanted to compete.\\n\"I was relieved and honoured when I found out I\\'d been selected. Hopefully I\\'ll get a medal,\" added Buesnel, who trains 17 hours per week with both the mainstream Jersey squad and the Jersey Special Gymnastics Club.\\nFind out how to get into gymnastics with our special guide.\\n\"It\\'s great news and we\\'re really pleased for Alex as he\\'s worked really hard to be at the top of where he can be in disability sport,\" Paul Patterson, from Jersey\\'s Sports Association for the Disabled told BBC Sport.\\n\"The only place he can move to now is mainstream sport and the fact he\\'s made that jump and he\\'s doing well there means he can only improve more and more.\\n\"He\\'s a great role model for people to aspire to in the future,\" he added.\\nJersey coach Ben Frith added: \"It goes to show that he is up to the level and we expect good things again in Gotland.\"\\n\"He\\'s the first special gymnast to make our squad, so it\\'s a great achievement for him.\"\\nThe last time gymnastics was included in an Island Games was in Bermuda in 2013, when Jersey\\'s Bonita Shurmer took gold in the asymmetric bars.\\nShe will to compete again, alongside Zee Adamson who was also part of the team that went to Bermuda 2013.\\nJersey squad: James Evans, Andre Romeril, Zee Adamson, Alex Buesnel, Cameron Aird, Isaac Macintosh, Anushan Elanco, Dan Lee, Ellen Marett, Bonita Shurmer, Elisha Rose Stott, Ruby Rose Mahony, Rosie Xiang Ru Willis.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Crewe Alexandra captain Ryan Lowe is unhappy he was not spoken to by anyone at the League Two club about their managerial change.', 'negatives': [], 'positives': ['After the club\\'s decision to sack Steve Davis following Saturday\\'s 3-0 loss at Mansfield, ex-Alex skipper Dave Artell was invited to step up as manager from his job within Crewe\\'s academy.\\n\"Obviously, Dave\\'s been given the nod,\" Lowe told BBC Radio Stoke.\\n\"I hope he does well and we\\'ll have to now see where this takes us.\"\\nBut after one of his former clubs Bury made an approach in December for 38-year-old Lowe to return to Gigg Lane as player-coach, the Liverpudlian admitted to surprise at being left out of the loop at Gresty Road.\\n\"In all honesty, I\\'m a bit disappointed no-one rang me,\" he said. \"With me being the club captain, and with the situation that materialised six weeks ago with Bury.\\n\"I\\'ve played with Dave a couple of times, at Chester and Shrewsbury, and we get on a like a house on fire. But that\\'s football. I\\'m always there to lean on, whoever it may be.\\n\"I\\'ve had a bit of stick myself by sticking by him (Steve Davis), but I\\'ll always stick by the manager, whoever it is.\"\\nFormer Alex player Artell, who rejoined the club\\'s backroom staff in 2014, takes over an out-of-sorts club who have won just twice in 21 games.\\n\"The fact is we haven\\'t been good enough throughout the season,\" said Lowe. \"Early on, we were okay for the first two months. But then we packed in a bit and we haven\\'t done as well as we should have.\\n\"And some of the players have to look at themselves and take a bit of responsibility.\"\\nCrewe have extended Chelsea winger Alex Kiwomya\\'s loan until the end of the season.\\nThe 20-year-old nephew of former Arsenal and Ipswich Town striker Chris Kiwomya was due to end his existing loan spell on 9 January.\\nBut Chelsea have agreed to allow Kiwomya, who has scored seven goals in 25 appearances, to see the season out at Gresty Road.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Greater Manchester's transport body has terminated its contract with the company responsible for rolling out a smart ticketing system after delays.\", 'negatives': [], 'positives': ['IT services firm Atos was contracted in 2012 to design, build and operate the \\'Get me there\\' scheme.\\nTransport for Greater Manchester (TfGM) said it was \"clear that Atos cannot deliver\" the system and ended the deal.\\nSmart ticketing was introduced in October on Metrolink, but only to those with concessionary travel passes.\\nIt was set to be rolled out to tram and bus passengers this year, with hopes to extend it further to rail travel.\\nIn a joint statement, the transport body and Atos said the development and launch of the \\'Get me there\\' system will continue, but with alternative suppliers.\\nA TfGM spokesman said: \"Today\\'s smart card already looks destined to be overtaken by contactless payments and mobile apps on smart phones.\\n\"Given TfGM\\'s commitment to deliver an integrated smart ticketing scheme, and with the opportunities afforded to us by the forthcoming Buses Bill, it is only right that TfGM re-thinks its approach to the \\'Get me there\\' scheme to ensure that it is flexible and fit for the future.\"\\nKevin Fitzpatrick, BBC Radio Manchester political reporter\\nAtos began developing the Oyster Card-style system in 2012, but there has been criticism of its slow roll-out.\\nIt\\'s currently only available for 500,000 concessionary card holders and TfGM have now said it\\'s clear the company cannot complete the deal.\\nIt\\'s clearly a blow to Chancellor George Osborne\\'s hope of an Oyster Card for the north as part of his northern powerhouse plans.\\nThe travel body insists the existing service will be maintained as it looks for a new partner for the scheme.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Google's AlphaGo artificial intelligence program has defeated a top Go player for a second time.\", 'negatives': [], 'positives': ['The five-game contest is being seen as a major test of what scientists and engineers have achieved in the sphere of AI.\\nAfter the match, Lee Se-dol said: \"Yesterday I was surprised but today it\\'s more than that, I am quite speechless.\\n\"Today I feel like AlphaGo played a nearly perfect game,\" he said.\\n\"If you look at how the game was played I admit it was a clear loss on my part.\"\\nLee Se-dol is considered a champion Go player, having won numerous tournaments over a long, successful career.\\nIn October 2015, AlphaGo beat the European Go champion, an achievement that was not expected for years.\\nA computer beat the world\\'s chess champion in 1997, but Go is recognised as a more complex board game.\\nOn Thursday, the Korea Times reported that locals had started calling AlphaGo \"AI sabum\" - or \"master AI\".\\nThree games remain, but Google only has to win once more to named the victor.\\n\"Playing against a machine is very different from an actual human opponent,\" world champion Lee Se-dol told the BBC ahead of the first match.\\n\"Normally, you can sense your opponent\\'s breathing, their energy. And lots of times you make decisions which are dependent on the physical reactions of the person you\\'re playing against.\\n\"With a machine, you can\\'t do that.\"\\nGo is thought to date back to ancient China, several thousand years ago.\\nUsing black-and-white stones on a grid, players gain the upper hand by surrounding their opponents pieces with their own.\\nThe rules are simpler than those of chess, but a player typically has a choice of 200 moves compared with about 20 in chess.\\nThere are more possible positions in Go than atoms in the universe, according to DeepMind\\'s team.\\nIt can be very difficult to determine who is winning, and many of the top human players rely on instinct.\\nGoogle\\'s AlphaGo was developed by British computer company DeepMind which was bought by Google in 2014.\\nThe computer program first studied common patterns that are repeated in past games, Demis Hassabis, DeepMind chief executive explained to the BBC.\\n\"After it\\'s learned that, it\\'s got to reasonable standards by looking at professional games. It then played itself, different versions of itself millions and millions of times and each time get incrementally slightly better - it learns from its mistakes\"\\nLearning and improving from its own matchplay experience means the super computer is now even stronger than when it beat the European champion late last year.\\nThe evolution of AI: Read more on BBC iWonder'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"A prisoner's bizarre behaviour meant his fatal illness could not be diagnosed, a report has concluded.\", 'negatives': [], 'positives': ['Shalane Blackwood grew increasingly erratic before his death from a ruptured stomach ulcer and at one point he was found naked, covered in custard.\\nAn inquest concluded neglect by staff at Nottingham Prison \"significantly contributed\" to his death.\\nBut the prisons ombudsman disagreed and said the illness would have been \"very difficult\" to diagnose.\\nThe 29-year-old, from Derby, had been jailed for possession of a firearm and was on a licence recall when he died on 5 August in the prison\\'s segregation unit.\\nHe had been transferred from Liverpool in May to be nearer his family, including his newborn baby.\\nOmbudsman Nigel Newcomen found Mr Blackwood was suffering increasing mental health problems attributed to his use of legal highs.\\nHe said: \"His difficult behaviour and his frequent refusal to engage with healthcare staff meant that it was difficult to examine him physically, but healthcare staff had little reason to suspect that Mr Blackwood was suffering from a serious physical condition.\\n\"We do not consider that they could have anticipated his sudden death.\"\\nThe report revealed Mr Blackwood complained of stomach pains while in Liverpool, but did not report any problems in Nottingham.\\nIt details a catalogue of strange behaviour including going for several days without sleep, spending much of his time unclothed, believing he was God and thinking someone was trying to poison him.\\nAccording to investigators, at one point he spent 48 hours \"naked and covered in custard\".\\nOn several occasions he refused food, drink and prescribed medication and would not let health professionals examine him.\\nA week before he died, a psychiatrist concluded his behaviour was because of his use of a new psychoactive substance, and he admitted smoking \"Mamba\".\\nStaff made a transfer request to a mental health hospital, which would have allowed for compulsory treatment of Mr Blackwood, but this was not completed before he died.\\nMr Newcomen made several criticisms and recommendations including questioning the use of the segregation unit, the decision that four officers being needed to enter his cell and the delay in telling his family.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A detective who helped investigate how a Flint schoolgirl was killed in 1976 has denied putting a man jailed under pressure.', 'negatives': [], 'positives': ['Noel Jones served 12 years for the manslaughter of 15-year-old Janet Commins.\\nBut he told a fresh murder trial at Mold Crown Court that he was not responsible - and a confession was made up by police.\\nStephen Hough, 58, denies rape, sexual assault, murder and manslaughter\\nOn Tuesday, the jury heard evidence from retired police officer Albert Roberts, who left the north Wales force in 1981.\\nIn 1976, he was a detective inspector who interviewed the chief suspect Jones.\\nIn one interview, Mr Roberts told Jones: \"You told us a number of things which only the person that was with Janet at the time...would be able to say. How can you explain that?\".\\nThe court heard Jones replied it \"must have been in the papers\" - despite later agreeing that he could only read \"a little\".\\nThe jury was told that Jones later walked police through a reconstruction, describing where and how the attack took place.\\nBut under cross-examination by the prosecution, the former detective rejected claims made by Jones that he put the suspect under pressure.\\nHe said that was \"absolute nonsense\".\\nAsked if he bombarded Jones with questions, Mr Roberts said: \"He seemed all right to me. He seemed to be answering them all right without any difficulty.\"\\nThe questioning followed defence evidence on Monday from Mr Hough, who was arrested in 2016 after DNA matching his was found on the dead schoolgirl\\'s body.\\nBut he told the jury he could not explain the DNA findings, and also denied once telling his ex-wife that he had killed someone.\\nAsked by his barrister, Patrick Harrington QC: \"Did you have anything to do with her death?\"\\n\"No sir,\" he replied.\\nThe trial is continuing.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Middlesex will need to win their final match against Yorkshire to guarantee a first County Championship title since 1993 after drawing with Lancashire.', 'negatives': [], 'positives': ['Set 309 from 44 overs, Lancashire ended the chase after makeshift opener Jos Buttler was out for a 14-ball 26 and closed on 80-1 at Old Trafford.\\nMiddlesex earlier declared on 240-8, Dawid Malan top-scoring with 87.\\nLancashire will need 11 points from their final match against Warwickshire to ensure relegation is avoided.\\nMiddlesex hold a nine-point advantage over second-placed Yorkshire, who visit Lord\\'s next week.\\nA draw, or a Yorkshire win, could let in Somerset, who play bottom club Nottinghamshire at Taunton.\\nThat neither side was able to force victory was down in part to an increasingly flat pitch and two moments involving Lancashire\\'s Buttler.\\nThe first came when John Simpson, on eight, edged Tom Bailey to offer a very difficult chance, one that the wicketkeeper could not take in his left hand.\\nSimpson (74) and Malan went on to share 151, taking Middlesex from their third-evening position of 55-4 to relative safety.\\nMalan eventually edged Simon Kerrigan behind, one of six wickets for the left-arm spinner, before Middlesex declared to leave Lancashire a fanciful target.\\nButtler\\'s promotion to the top of the order showed that the hosts briefly entertained chasing the victory that would have guaranteed their safety, the England wicketkeeper going through his whole repertoire of strokes.\\nBut, after he got a leading edge off Steven Finn to be caught at cover, Rob Jones and Haseeb Hameed saw Lancashire through.\\nBy the time hands were shaken, first-innings centurion Jones had passed 500 minutes at the crease in the match without being dismissed.\\nLancashire cricket director Ashley Giles told BBC Radio Lancashire:\\n\"It was a good fightback. We didn\\'t bowl well on the first day, or field well. We showed a lot of character from there.\\n\"Had Middlesex not been in such a tight position maybe they would have given themselves a bit more time to bowl us out.\\n\"I\\'m delighted with some of the individual performances, but this was the story of the season. We need to start better, and get into games quicker.\"\\nMiddlesex captain James Franklin told BBC Radio London:\\n\"It\\'s dangerous to want and need a draw. We want to beat Yorkshire. Nothing changes just because it\\'s the last game.\\n\"There is potential of nice rewards at the end of it. We have one more hurdle to get over. We have a huge week ahead. We need to be clear with our thought processes and go again.\\n\"We had a tricky morning this morning to contend with, and Malan and Simpson did a great job. It was a team effort. That\\'s why we are in the position we are in.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"North Ferriby's first game in English football's fifth tier ended in a goalless draw with Braintree.\", 'negatives': [], 'positives': [\"Close to 600 people turned out in East Yorkshire to see Steve Housham's men make their National League bow and watched on as the frame of the goal was struck three times.\\nDanny Clarke had a first-half shot blocked for the Villagers and then Curtis Bateson looked to have given them the lead, only to see his effort bounce out off the bar.\\nThe same two players were involved again just before the break, Clarke denied by Jamie Butler in the Braintree goal after being teed up by Bateson.\\nTown sub Jake Goodman became the next player to hit the bar, nodding against the woodwork as the game entered its last 20 minutes, which passed without incident other than Ferriby hacking off the line amid a scramble which also saw the ball hit the post.\\nReport supplied by the Press Association.\\nMatch ends, North Ferriby United 0, Braintree Town 0.\\nSecond Half ends, North Ferriby United 0, Braintree Town 0.\\nDanny Clarke (North Ferriby United) is shown the yellow card for a bad foul.\\nCorner,  Braintree Town.\\nCorner,  Braintree Town.\\nSubstitution, North Ferriby United. Ryan Kendall replaces Connor Robinson.\\nCorner,  Braintree Town.\\nSubstitution, North Ferriby United. Vinny Mukendi replaces Alfons Fosu-Mensah.\\nCorner,  Braintree Town.\\nSubstitution, Braintree Town. Jake Goodman replaces Craig Braham-Barrett.\\nCorner,  Braintree Town.\\nCorner,  Braintree Town.\\nCorner,  Braintree Town.\\nSecond Half begins North Ferriby United 0, Braintree Town 0.\\nFirst Half ends, North Ferriby United 0, Braintree Town 0.\\nCorner,  Braintree Town.\\nCorner,  Braintree Town.\\nCorner,  Braintree Town.\\nCorner,  North Ferriby United.\\nCorner,  Braintree Town.\\nJake Skelton (North Ferriby United) is shown the yellow card for a bad foul.\\nCorner,  Braintree Town.\\nCorner,  Braintree Town.\\nCorner,  Braintree Town.\\nFirst Half begins.\\nLineups are announced and players are warming up.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A man who had almost 40,000 illicit cigarettes in his car has been given a suspended prison sentence.', 'negatives': [], 'positives': [\"The contraband in Aran Mohammed Saied's car was worth £10,100 in duty tax, HM Revenue and Customs (HMRC) said.\\nSaied, 33, of Ellesmere Road, Newcastle, was found guilty of fraudulently evading excise duty.\\nHe was sentenced to nine months in jail suspended for 12 months at Newcastle Crown Court and ordered to complete 150 hours unpaid work.\\nSaied, who is unemployed, had denied the offence but was found guilty at Newcastle Magistrates' Court, was also told to pay £400 in costs and a £140 victim surcharge.\\nSaied was pulled over by North Yorkshire Police on the A1 near Catterick in September because the car he was driving had no MOT.\\nOfficers found 39,820 illicit cigarettes and £2,775 in cash hidden in boxes, the HMRC said.\\nInitially Saied told officers the boxes contained car parts he was transporting for a friend in Birmingham.\\nHMRC said he had previously been warned about duty evasion after attempting to smuggle 4,000 cigarettes and 30 cigars through Edinburgh Airport in April 2015.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Over the years I have spoken to more chancellors and shadow chancellors than most people of my age (that is not a boast, just a sad fact about my preoccupations).', 'negatives': [], 'positives': [\"And typically they say it is a very bad idea to rule out changes to tax rates when making manifesto commitments prior to a general election.\\nTheir point has been that it is impossible to know when the global or indeed domestic economy will go into some kind of spasm that would see a chancellor boshed on the noggin with a wet fish, that would see tax revenues suddenly undermined. And in those circumstances, it is best to retain the ability to boost taxes in whatever way seems appropriate.\\nHowever, whichever of Tory or Labour is in power after 7 May, the new government's chancellor will have his or her (surely got to be possible) hands bound and tied when it comes to fiscal matters.\\nBecause both parties have now ruled out increasing the basic and 40% rates of income tax, the rate of National Insurance and the rate of Value Added Tax.\\nBetween them these taxes raise more than £380bn a year, or 60% of all tax revenues.\\nAlso, it is now more or less impossible for political and economic reasons to push up corporation tax rates or business rates (big companies can move abroad, small companies are our future).\\nSo that is another 15% of tax revenues that can't really be augmented to any significant degree.\\nTo put it another way, Ed Balls for Labour and George Osborne for the Tories have done something early-ish in the election campaign which is pretty unusual and Treasury traditionalists would describe as bonkers.\\nThey have promised, in effect, not to increase the burden of the UK's most important income and indirect taxes, that raise 75% of all taxes.\\nThis carries a number of important implications.\\nOne is that to balance the books, to reduce the gap between taxes and spending from the current £90bn a year, the overwhelming burden must be taken by public service and welfare cuts.\\nThe Tories are explicit that's what they wish to do. Labour is a bit more equivocal.\\nSecondly, if a new government felt there did have to be tax rises, there are really only two options that would raise significant sums. One is the imposition of as yet unspecified new wealth taxes, above and beyond Labour's mansion tax.\\nAnother is to call time on the tax deductibility of pension contributions, or at least create a new streamlined rate of deductibility for all taxpayers (as the Liberal Democrat minister Steve Webb has proposed), which would not be so odd in the context of all the new freedoms the government has given savers to cash in their pension pots.\\nFor what it's worth, the consensus among Treasury officials is that pensions and other forms of wealth will be where any new taxes will be plonked.\\nBut the point is that neither of these reforms would be quick or easy.\\nAnd the fact is that if there were a big shock to the economy, it is difficult to see how either a Labour or Tory chancellor could now fill the big hole that would be created in a hurry - without, that is, breaking one of the important pledges they have made in recent days not to raise VAT, NI or the main income tax rates.\\nGiven that not so long ago that we experienced such a shock, just maybe these pledges not to raise taxes aren't quite as compelling as they seem. Maybe we should ask for the small print of the force majeure clause.\\nPS It is of course true that Labour has said it would increase the very top rate of income tax from 45% to 50% for the top 1% of earners - those earning more than £150,000 a year. But it is moot whether this will in the long term raise a few billion or just a few hundred million pounds a year, because this group are so skilled at legally avoiding taxes.\\nWhich is partly why, for those who believe the rich should make a bigger contribution and who are concerned about the gap between rich and poor, the debate is about how to impose levies on wealth, in that wealth is harder to hide or disguise than income.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The remains of one of four young men who went missing last week have been found on a Pennsylvania farm.', 'negatives': [], 'positives': ['The grim discovery was unearthed in a \"grave\" along with other bodies on a 90-acre tract of land in suburban Philadelphia, said officials.\\nThe remains belong to Dean Finocchiaro, 19 who disappeared last Friday, according to investigators.\\nMark Sturgis, 22, and Tom Meo, 21, also vanished on Friday. Jimi Tar Patrick, 19, went missing two days earlier.\\nOn Wednesday this week, authorities arrested the son of the owners of the Bucks County farm, 20-year-old Cosmo DiNardo.\\nHe is accused of trying to sell Mr Meo\\'s 1996 Nissan Maxima for $500 (Â£390), a day after its owner was last seen.\\nA \"life-saving\" diabetic kit that Mr Meo requires was still inside the car, investigators said.\\nProsecutors said homicide charges could follow for Mr DiNardo, whose bail was set at the unusually high amount of $5m in cash.\\nOfficials described him as dangerous and said he has schizophrenia.\\nDistrict Attorney Matthew Weintraub told a press conference early on Thursday morning: \"There are additional human remains inside that grave.\\n\"So this painstaking process will go on. We\\'re not done yet.\\n\"This is a homicide, make no mistake about it. We just don\\'t know how many homicides, we have yet to know the answer to that question,\" the District Attorney said.\\nHe added: \"We had cadaver dogs, and I don\\'t understand the science behind it, but those dogs could smell these poor boys twelve-and-a-half feet below the ground.\"\\nThe relationship between the four missing men is not clear.\\nMr Sturgis\\' father told the Associated Press he employs his son and Mr Meo, a talented wrestler, in construction, and that Mr Finocchiaro is a mutual friend of theirs.\\nMr Patrick and Mr DiNardo both attended the same high school, a year apart, reports the Philadelphia Inquirer.\\nA lawyer for the DiNardo family released a statement saying: \"As parents, Mr and Mrs Dinardo sympathise with the parents and families of the missing young men and they are co-operating in every way possible with the investigation being conducted by law enforcement.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Doctors could spot twice as many heart attacks in women by using a newer, more sensitive blood test, a study claims.', 'negatives': [], 'positives': ['The test looks for minute traces of a protein that signals that the heart muscle may have been damaged.\\nStandard tests still used by much of the NHS only detect higher levels of this protein, called troponin.\\nResearch from the Royal Infirmary of Edinburgh shows the standard test misses many cases of heart attack in women with symptoms like chest pain.\\nA heart attack is a medical emergency and early diagnosis and treatment can mean the difference between life and death.\\nDoctors rely on blood tests to help them judge if a patient with chest pain might be having an attack, but a normal result can mean the diagnosis is overlooked.\\nThe British Heart Foundation-funded study, reported in the BMJ, included 1,126 men and women who had been admitted with a suspected heart attack.\\nUsing the standard troponin test, almost twice as many men as women were diagnosed as having a heart attack - 117 versus 55.\\nWhen the researchers used the more sensitive test, the number of women diagnosed with heart attacks doubled to 111 or 22%.\\nIn comparison, the sensitive test only spotted a handful of extra cases among the men.\\nAnd the researchers noticed that the extra men and women picked up by the sensitive test were at higher risk of dying or having another heart attack in the following year.\\nResearcher Dr Anoop Shah said that while similar numbers of men and women attend  A&E with chest pains, women are less likely to be diagnosed with a heart attack.\\n\"At the moment one in 10 women with chest pains will be diagnosed with a heart attack compared to one in five men.\\n\"Our findings suggest one reason for this difference in diagnosis rates of men and women is that we, as doctors, may have been using a threshold for troponin testing that is too high in women.\"\\nHe said doctors can rely heavily on blood tests and that faced with a normal result there is the temptation to rule out a heart attack too quickly.\\n\"For some reason, women are less likely to have obvious symptoms and if the test result comes back negative then they might be sent home only to have an event [heart attack] in the next few months because they were not treated appropriately.\"\\nJenni Stevens, 41, from Edinburgh, had dismissed her chest pains, putting them down to stress.\\nWhen the pain got much worse her concerned colleagues called an ambulance, which took her to the Royal Infirmary.\\n\"As much as I was frightened, I felt a sense of reassurance when I got to the hospital. They took my blood and did other tests.\"\\nHer sensitive troponin test, along with a heart trace called an ECG, alerted doctors that she was having a heart attack.\\n\"I was treated with a stent to save my life. I\\'m genuinely so grateful that my heart attack was spotted and treated so well and with such compassion.\"\\nNot all UK hospitals use the sensitive test, although two different versions of it (troponin I and troponin T) have been approved by regulatory bodies.\\nDr Shah and his team say more research is needed to ascertain if using a lower troponin threshold for women will save more lives - they have begun a trial to look at this.\\nProf Peter Weissberg of the British Heart Foundation said: \"If these results are confirmed in the much larger clinical trial we\\'re funding, using a high sensitivity troponin test, with a threshold specific to each gender, could save many more women\\'s lives by identifying them earlier to take steps to prevent them dying or having another, bigger heart attack.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A washing machine has been launched for the Indian market, with a special mode to tackle curry stains.', 'negatives': [], 'positives': [\"Panasonic said the introduction of a 'curry' button followed complaints from customers struggling to fully get the food off their clothes.\\nIt says development took two years, testing combinations of water temperature and water flow.\\nThe machine has five other cycles aimed at the Indian consumer, including one to remove traces of hair oil.\\nAs part of the development, Panasonic researchers analysed what went into a typical Indian household's curry dish.\\nThe firm said it then tried to establish the optimal time and water temperature required to remove the stains.\\nPanasonic said it planned similar machines for other Asian markets, tackling stains specific to those countries, but would not elaborate.\\nOnly about 10% of homes in India have a washing machine, with most people still doing their laundry by hand.\\nThat means there is plenty of room for market growth, and the electronics giant hopes the India-focussed machine will help it challenge the South Korean manufacturers dominating the sector.\\nPanasonic told the BBC that about 5,000 of the machines had been sold so far, with a target to sell at least 30,000 by March next year.\\nPriced at about 22,000 Indian rupees (£268;$330), the new model costs around 10% more than other washing machines.\\nPanasonic entered the India market in 1990, first producing rice cookers and then expanding its line to also manufacture air conditioners.\\nIn December last year, the company announced it would set up a factory in the North Indian state of Haryana making refrigerators.\\nThe Japanese firm has associated itself with other headline-grabbing products.\\nLast year it invested $60m (£49m) in Seven Dreamers, a Japanese start-up which is developing what it claims to be the world's first robot that folds laundry.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The actress and UN special envoy Angelina Jolie has said a four-day summit on ending sexual violence during war must send a message that there is no disgrace in being a victim.', 'negatives': [], 'positives': ['Ms Jolie was speaking alongside British Foreign Secretary William Hague, who is co-hosting the London summit with her.\\nThe event - the largest ever of its kind - is the result of an intense two-year campaign to raise awareness.\\nMr Hague said rape was one of the \"great mass crimes\" of modern times.\\nHe called on the more than 140 nations at the summit to write action against sexual violence into their army training.\\nThe summit aims to:\\nThe organisers want the event to be the moment the world wakes up and declares that sexual violence is not an inevitable part of war, says BBC World Affairs Correspondent Paul Adams.\\nOpening the summit, Mr Hague said: \"From the abolition of slavery to the adoption of the Arms Trade Treaty, we have shown that the international community can tackle vast global problems in a way that was once considered to be impossible.\\n\"There is power in numbers, and if we unite behind this cause, we can create an unstoppable momentum and consign this vile abuse to history.\"\\nMs Jolie said: \"We need to shatter that culture of impunity and make justice the norm, not the exception, for these crimes.\"\\nShe said she wanted to dedicate the conference to a rape victim she recently interviewed in Bosnia, who felt so humiliated by what had happened to her that she could not even tell her own son.\\n\"She felt that having had no justice for her particular crime, in her particular situation, and having seen the actual man who raped her on the streets free, she really felt abandoned by the world,\\'\\' Ms Jolie said. \"This day is for her.\\'\\'\\nAngela Atim, one of the speakers at the conference, was kidnapped as a 14-year-old schoolgirl by Lord\\'s Resistance Army (LRA) rebels in Uganda.\\nShe told the BBC: \"These people who are accountable for the sexual violence in armed conflict, they have to be brought to justice.\"\\n\"It\\'s part of our healing because it\\'s really painful to see that they are still walking around, they are still doing the same thing.\"\\nNations taking part in the summit include Bosnia, the Democratic Republic of Congo and Somalia - countries where sexual violence has happened \"on a vast scale\", Mr Hague told the BBC.\\nSexual violence was systematically being used as a weapon of war in the 20th and 21st Centuries, he noted.\\nMr Hague cited the estimated 50,000 women who were raped in Bosnia two decades ago, virtually none of whom have received justice.\\nIn the two years since Mr Hague and Ms Jolie launched their campaign, a Declaration of Commitment to End Sexual Violence in Conflict has been endorsed by 141 countries.\\nBut the aim now is to take concrete steps, including providing more help to survivors, Mr Hague said.\\nHe added that the issue had been a \"taboo\" for too long, and that it was time to get rid of the \"stigma and shame attached to it\".\\nOn Thursday, Mr Hague will also host a security meeting focused on Boko Haram, a militant Islamist group in Nigeria. Ministers from Nigeria and neighbouring countries will attend.\\nSuspected Boko Haram militants abducted at least 20 women in northern Nigeria last week. More than 200 schoolgirls were kidnapped by the same group on 14 April.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Luke Berry scored all four goals as League Two side Cambridge United beat League One strugglers Coventry City in the FA Cup second round.', 'negatives': [], 'positives': [\"Media playback is not supported on this device\\nBerry steered in George Maris' cross to put the U's ahead inside five minutes.\\nThe midfielder doubled the advantage from the penalty spot after he was hauled down in the box, before slotting in his third shortly after.\\nThe 24-year-old tapped in late on to complete the scoring, as Coventry slumped to a fourth straight defeat.\\nThe Sky Blues, who won the FA Cup in 1987, have now been knocked out of the competition by a team from a lower division in each of the past three seasons.\\nFormer Barnsley midfielder Berry was the hero for Cambridge, wrapping up his hat-trick inside 38 minutes and then adding his 12th goal of the season after the break.\\nMatch ends, Cambridge United 4, Coventry City 0.\\nSecond Half ends, Cambridge United 4, Coventry City 0.\\nAttempt missed. Max Clark (Cambridge United) left footed shot from the centre of the box is too high.\\nAttempt blocked. Piero Mingoia (Cambridge United) right footed shot from outside the box is blocked.\\nVladimir Gadzhev (Coventry City) is shown the yellow card for a bad foul.\\nMax Clark (Cambridge United) wins a free kick in the defensive half.\\nFoul by Vladimir Gadzhev (Coventry City).\\nAttempt blocked. Leon Legge (Cambridge United) right footed shot from the centre of the box is blocked.\\nCorner,  Cambridge United. Conceded by Jordan Turnbull.\\nSubstitution, Cambridge United. Joe Pigott replaces Uche Ikpeazu.\\nSubstitution, Cambridge United. Harrison Dunk replaces Luke Berry.\\nGoal!  Cambridge United 4, Coventry City 0. Luke Berry (Cambridge United) right footed shot from very close range to the centre of the goal. Assisted by Brad Halliday with a cross.\\nJordan Turnbull (Coventry City) is shown the yellow card for a bad foul.\\nBen Williamson (Cambridge United) wins a free kick in the attacking half.\\nFoul by Jordan Turnbull (Coventry City).\\nAttempt missed. Chris McCann (Coventry City) header from the centre of the box is high and wide to the left.\\nFoul by Brad Halliday (Cambridge United).\\nKyel Reid (Coventry City) wins a free kick on the left wing.\\nAttempt missed. Uche Ikpeazu (Cambridge United) right footed shot from the centre of the box is close, but misses to the right.\\nAttempt missed. Max Clark (Cambridge United) left footed shot from outside the box is close, but misses to the left.\\nFoul by Uche Ikpeazu (Cambridge United).\\nLewis Page (Coventry City) wins a free kick in the defensive half.\\nSubstitution, Cambridge United. Ben Williamson replaces George Maris.\\nSubstitution, Coventry City. Jodi Jones replaces Ruben Lameiras.\\nAttempt saved. Marvin Sordell (Coventry City) right footed shot from outside the box is saved in the centre of the goal.\\nPiero Mingoia (Cambridge United) wins a free kick in the attacking half.\\nFoul by Jordan Turnbull (Coventry City).\\nAttempt missed. Kyel Reid (Coventry City) left footed shot from the left side of the box is close, but misses to the left.\\nAttempt saved. Marvin Sordell (Coventry City) left footed shot from outside the box is saved in the centre of the goal.\\nUche Ikpeazu (Cambridge United) wins a free kick in the attacking half.\\nFoul by Chris McCann (Coventry City).\\nAttempt missed. Uche Ikpeazu (Cambridge United) right footed shot from outside the box is close, but misses the top right corner.\\nFoul by Kyel Reid (Coventry City).\\nBrad Halliday (Cambridge United) wins a free kick on the right wing.\\nAttempt blocked. Chris McCann (Coventry City) right footed shot from outside the box is blocked.\\nFoul by Piero Mingoia (Cambridge United).\\nLewis Page (Coventry City) wins a free kick on the left wing.\\nHand ball by Jack McBean (Coventry City).\\nFoul by George Maris (Cambridge United).\\nGael Bigirimana (Coventry City) wins a free kick in the attacking half.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"A film adaptation of one of Scotland's best-loved novels - Sunset Song - will be released in the UK in December.\", 'negatives': [], 'positives': ['Peter Mullan and former model Agyness Deyn star in Lewis Grassic Gibbon\\'s tale, which was shot on location in Aberdeenshire, New Zealand and Luxembourg.\\nPublished in 1932, Sunset Song follows a farming family struggling to make a living in north east Scotland leading up to World War One.\\nThe release will be on 4 December.\\nWhat\\'s happening in Scotland today? Keep in touch through our live page.\\nThe film, directed by Terence Davies, will get its premiere at the Toronto Film Festival later this month.\\nIn 2005 Sunset Song was named the \"Best Scottish Book of All Time\" at the Edinburgh International Book Festival.\\nThe BBC turned the book into a TV series in 1971.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Police investigating the killing of three swans at a Pembrokeshire wood have made two arrests.', 'negatives': [], 'positives': ['The swans suffered fatal injuries when they were shot with what is believed to be an airgun at Haverfordwest\\'s Withybush Woods.\\nAn unharmed cygnet was also recovered and put in the care of the RSPCA.\\nInsp Tim Davies, of Dyfed-Powys Police, said: \"This was a distressing incident, and we are aware of the impact in the local community.\"\\nHe added: \"We are thoroughly investigating this serious wildlife crime.\"\\nHe also appealed for anyone with information about the shootings, which were reported to the police on Saturday, to contact the force.\\nThe RSPCA said it was \"very shocked and saddened\" to hear about the deaths.\\nThe swan is a protected species in the UK and it is a criminal offence to harm one.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A man from Greater Manchester has been bound over to leave Jersey for three years after admitting running a brothel.', 'negatives': [], 'positives': [\"Catalin Mihail Avram, 35, of Whitehouse Avenue, Oldham, was arrested on Wednesday morning.\\nHe was charged with running a brothel at Panama Apartments on Green Street in violation of an 1895 Jersey law.\\nMagistrate Bridget Shaw said there was no benefit to Jersey to keep Avram in the island.\\nAvram appeared at Jersey Magistrates' Court in St Helier on Thursday where he pleaded guilty.\\nThe court heard he arrived in Jersey by boat on Monday from the UK with two women, a car boot full of adult material and £300 in cash.\\nThe prosecution lawyer said the officers spoke to one of the women who said she had sold sex for money and had had three clients in one afternoon.\\nPolice found £697 in their possession meaning they had acquired £397 in the time they had been in the island.\\nThe court heard there was no coercion or threats against the women and they were here willingly.\\nMagistrate Shaw bound him over to leave the island for three years and ordered him to sign £397 over to the court, which she said were the proceeds of prostitution.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'New manager Karl Robinson saw Charlton earn a goalless draw at fourth-placed Bradford in an exciting game of many chances and several narrow escapes at both ends of the pitch.', 'negatives': [], 'positives': [\"The result preserved Bradford's unbeaten home record but they had to settle for a point against a Charlton team who played the four minutes of stoppage time with 10 men after defender Patrick Bauer was sent off for a second yellow card.\\nIn the first meeting of the clubs since they were both in the Premier League 15 years ago, Charlton gave the Bradford a defence a torrid time in the first half, hitting the post, seeing a shot cleared off the line and having a penalty appeal turned down.\\nThe penalty appeal came in the ninth minute as Bradford defender Nathaniel Knight-Percival wrestled for the ball with the visitors' dangerous Northern Ireland international striker Josh Magennis.\\nThree minutes later Magennis saw his angled shot hit the far post and rebound to safety after running on to a pass from strike partner Nicky Ajose, while he also had a shot cleared off the line by Bradford right-back Stephen Darby after taking a pass from Lee Novak.\\nBradford's best first-half chance was in the 37th minute when Nicky Law supplied a through pass for Jordy Hiwula, but goalkeeper Dillon Phillips came quickly off his line to block the shot.\\nThe home side had the better of the second half with Hiwula again having their best chance. Mark Marshall played him through on goal in the 59th minute, but he was again denied by Phillips.\\nReport supplied by the Press Association.\\nMatch ends, Bradford City 0, Charlton Athletic 0.\\nSecond Half ends, Bradford City 0, Charlton Athletic 0.\\nFoul by James Meredith (Bradford City).\\nEzri Konsa Ngoyo (Charlton Athletic) wins a free kick on the left wing.\\nFoul by James Hanson (Bradford City).\\nJorge Teixeira (Charlton Athletic) wins a free kick in the attacking half.\\nSecond yellow card to Patrick Bauer (Charlton Athletic) for a bad foul.\\nMarc McNulty (Bradford City) wins a free kick on the right wing.\\nFoul by Patrick Bauer (Charlton Athletic).\\nSubstitution, Charlton Athletic. Brandon Hanlan replaces Jordan Botaka.\\nCorner,  Bradford City. Conceded by Dillon Phillips.\\nSubstitution, Bradford City. Filipe Morais replaces Mark Marshall because of an injury.\\nAttempt saved. Jordan Botaka (Charlton Athletic) right footed shot from outside the box is saved in the centre of the goal.\\nAttempt blocked. Nicky Law (Bradford City) right footed shot from the centre of the box is blocked.\\nJorge Teixeira (Charlton Athletic) wins a free kick in the attacking half.\\nFoul by Josh Cullen (Bradford City).\\nSubstitution, Bradford City. Marc McNulty replaces Jordy Hiwula-Mayifuila.\\nAttempt missed. Jordy Hiwula-Mayifuila (Bradford City) right footed shot from the right side of the box misses to the left.\\nCorner,  Bradford City. Conceded by Jorge Teixeira.\\nAttempt saved. Lee Novak (Charlton Athletic) right footed shot from outside the box is saved in the centre of the goal.\\nSubstitution, Charlton Athletic. Johnnie Jackson replaces Nicky Ajose.\\nNathaniel Knight-Percival (Bradford City) is shown the yellow card for a bad foul.\\nFoul by Nathaniel Knight-Percival (Bradford City).\\nJosh Magennis (Charlton Athletic) wins a free kick in the defensive half.\\nAttempt missed. Patrick Bauer (Charlton Athletic) right footed shot from more than 35 yards misses to the right.\\nFoul by Josh Cullen (Bradford City).\\nAndrew Crofts (Charlton Athletic) wins a free kick in the defensive half.\\nFoul by Nicky Law (Bradford City).\\nLee Novak (Charlton Athletic) wins a free kick in the attacking half.\\nAttempt missed. Jordy Hiwula-Mayifuila (Bradford City) right footed shot from outside the box is close, but misses to the left.\\nPatrick Bauer (Charlton Athletic) is shown the yellow card for a bad foul.\\nJordy Hiwula-Mayifuila (Bradford City) wins a free kick on the right wing.\\nFoul by Patrick Bauer (Charlton Athletic).\\nAttempt saved. James Hanson (Bradford City) header from the centre of the box is saved in the top centre of the goal.\\nEzri Konsa Ngoyo (Charlton Athletic) is shown the yellow card for a bad foul.\\nJames Meredith (Bradford City) wins a free kick on the left wing.\\nFoul by Ezri Konsa Ngoyo (Charlton Athletic).\\nAttempt blocked. Andrew Crofts (Charlton Athletic) right footed shot from outside the box is blocked.\\nCorner,  Charlton Athletic. Conceded by Josh Cullen.\\nAttempt saved. Jordy Hiwula-Mayifuila (Bradford City) right footed shot from the centre of the box is saved in the top centre of the goal.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Northern Ireland\\'s construction industry is \"haemorrhaging jobs\" and the impasse at Stormont is a cause of concern, a construction expert said.', 'negatives': [], 'positives': ['Stephen Kane told the BBC\\'s Inside Business programme that there was uncertainty in the sector.\\n\"We recently went out to survey our members,\" he said.\\n\"Thirty associations all reported back that they would see a negative impact on employment, their turnover and investment in the future.\"\\nMr Kane, chair of the Construction Industry Group of Northern Ireland, said the Stormont impasse was causing \"quite a concern\".\\n\"Also, a lot of them don\\'t have that much work here in Northern Ireland left for the next three to six months.\\n\"Most importantly very few of them have any work past 12 months.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Photographs by Cam Neville', 'negatives': [], 'positives': ['Cam Neville looked out from the truck and caught a glimpse of burning red lines leading to a location called Hellfire Pass.\\nIt was his first night volunteering with the local fire brigade, and the Australian photographer felt anxious. What was he about to encounter?\\n\"Certainly I had a flutter of nervousness,\" he told the BBC. \"Growing up in England, I\\'d never seen anything quite like that.\"\\nHe did not get near the blaze that night, but since then he has encountered others.\\nAustralia depends an army of volunteers to protect its sprawling country from devastating bushfires.\\nMr Neville signed up to join them on Queensland\\'s Gold Coast hinterland, believing it was the only way he could take photographs from the front line.\\nThe inspiration behind his award-nominated picture series Into the Fire was simple: to capture first-hand experiences of men and women fighting fires. This was something TV news rarely offered, he thought.\\n\"I really wanted to know who these people were,\" Mr Neville said. \"I think I really needed to experience what they all went through as well.\"\\nMr Neville grew up in Brighton before moving to Australia and settling in south-east Queensland.\\n\"Where we live there are houses that back onto very dense bush,\" he said. \"The fire threat is very real.\"\\nInitially he carried two DSLR cameras with bulky lenses, but it quickly proved impractical. Now Mr Neville uses a single camera with a 25mm lens.\\nHe takes shots in quiet moments between fighting fires.\\nThe photographer says the project has also brought him practical skills and new friendships.\\n\"I\\'ve learned that it\\'s an incredibly complicated and dangerous business - fighting fires of any type or size - because it\\'s unpredictable,\" he said.\\nHis admiration for his colleagues has only grown.\\n\"The call goes out and people answer,\" Mr Neville said. \"They never know what they\\'re going to.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Peter Kay has said there will be no more episodes of TV sitcom Car Share.', 'negatives': [], 'positives': ['Series two reaches its climax on BBC One later, but many fans have already seen the finale on BBC iPlayer and know what happens between John and Kayleigh.\\nBut the star told BBC Radio Manchester there will be no series three and no Christmas specials.\\nAsked whether John would ever switch from Forever FM to Radio Manchester, Kay replied: \"There\\'s not going to be a series three so it won\\'t ever happen.\"\\nHe added: \"You\\'ve got to get out while the going\\'s good. No Christmas special, no.\"\\nViewers have been waiting throughout series two to find out whether John - played by Kay - finally gets together with his passenger Kayleigh, played by Sian Gibson.\\nKay said: \"I am absolutely delighted and overwhelmed by everybody\\'s support and the fact that everyone\\'s loved it so much has been wonderful for everyone who\\'s made it, but you\\'re better quitting while you\\'re ahead.\\n\"There\\'s only so much you can do in a car and the last thing you want to do is ruin it because I think it\\'s a lovely thing.\\n\"It\\'s been wonderful working with Sian, who\\'s one of my closest friends in the world. We have a good laugh but I think sometimes you\\'ve got to just leave things.\\n\"You need good ideas - that\\'s the problem. You need good strong stories. A lot of series tend to go on for one series too many, especially with comedies, and I think people say \\'ooh, it\\'s gone off, that\\'.\\n\"If you\\'re struggling and you just get a sense when you\\'re writing that you might be running out of ideas, that\\'s when I think you should walk away.\"\\nKay, who also co-writes and directs Car Share, also revealed he\\'s had the opportunity to make more of his Channel 4 comedy Phoenix Nights - but hasn\\'t got around to it.\\nHe said: \"I love Phoenix Nights and I would love to go back. I\\'ve got a lot of ideas about Phoenix Nights.\\n\"In fact there\\'s a whole series three been written for about 15 years but so many things get in the way in life like touring and being a father. Real life continues and Car Share takes about a year to make and edit.\"\\nFollow us on Facebook, on Twitter @BBCNewsEnts, or on Instagram at bbcnewsents. If you have a story suggestion email entertainment.news@bbc.co.uk.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Amid concerns over an increase in Islamophobic content on social media following the recent Paris attacks, BBC Asian Network has been hearing from Muslims about their experience of being the target of anti-Islamic sentiment online.', 'negatives': [], 'positives': ['Activist Akeela Ahmed says she uses Twitter to campaign on equality issues. Her profile picture shows her in her hijab.\\n\"If I tweet something to do with women\\'s rights, I\\'ll get tweets usually from men saying, \\'How can you tweet that when you\\'ve got that thing on your head?\\' They\\'re talking about my hijab.\\n\"Post-Paris, the abuse increased and it was a lot worse,\" she says, referring to negative comments posted online following the attack on the French satirical magazine Charlie Hebdo, in which gunmen said they were killing in the name of Islam.\\n\"One particular person was quite specific in their threats and wanting to kill Muslims. Normally, I\\'m not threatened by it, but on this occasion I was.\"\\nThat Twitter account has been taken down. But there are concerns that some Islamophobic content remains online.\\nCampaigners from the organisation Tell Mama, which monitors hate against Muslims online, sent Asian Network some examples.\\n\"When events like Paris happen, what seems to happen is that people on social media sites have bigger discussions,\"says Bharath Ganesh.\\n\"The language we\\'ve seen is extremely derogatory towards Muslims.\\n\"Hashtags like #killallmuslims appear. Some Muslims used that hashtag to highlight anti-Islamic sentiments online.\"\\nAkeela says she understands where the anger stems from.\\n\"As we see more terrorist incidents globally, many people feel anger about terror attacks and they go online and use their medium to vent their anger. But, as a result, there is an increase in anti-Muslim sentiment generally.\\n\"On Facebook, it\\'s a problem too. There are some groups who promote anti-Muslim sentiments. It\\'s about dealing responsibly with these issues.\"\\nFacebook and Twitter both urge users to report anti-Islamic content. The Attorney General, Jeremy Wright - the government\\'s legal adviser - has signalled he would like to meet with both firms to see what more can be done in this area.\\nMaaiysa Valli, a BBC journalist, was tweeting in a personal capacity when she used the #NotInMyName hashtag that Muslims have been using to distance themselves from extremists.\\nThe photo was retweeted more than 400 times, with one response describing her as an \"uneducated animal\".\\nShe says: \"I got a few comments to start with that were saying things like, \\'You shouldn\\'t be following this religion.\\'\\n\"Then Maajid Nawaz - the chairman of the Quilliam Foundation - retweeted it. He has more than 30,000 followers, and I got so many notifications.\"\\nShe blocked and reported a number of users, and says the experience has made her aware of \"how brave people can be behind a keyboard\".\\nA number of accounts which targeted her have been disabled.\\nMehdi Hasan is the political director of the Huffington Post UK, and says he has had death threats online.\\n\"It\\'s pretty depressing. The number one issue that drives people up the wall on Twitter seems to be Islam. It\\'s become so regular, you become immune to it. It\\'s mainly anonymous people full of hatred.\\n\"As a Muslim journalist in the public eye, it doesn\\'t matter what you write about, all roads lead back to your faith.\\n\"On the one hand, I expect abuse when I write about terrorism or the halal meat hysteria.\\n\"What I don\\'t understand is how everything is related back to Islam - for instance, even if I interview a politician about austerity, people will say, \\'Oh, it\\'s because you\\'re a Muslim you\\'re writing that.\\'\"\\nIn a statement, Twitter said: \"We review all reported content against our rules which include a ban on targeted abuse and direct, specific threats of violence against others.\"\\nMeanwhile, a Facebook spokesperson said: \"We take hate speech seriously and remove any content reported to us that directly attacks others based on their race, ethnicity, national origin, religion, sex, gender, sexual orientation, disability or medical condition.\\n\"With a diverse global community of more than a billion people, we occasionally see people post content which, whilst not against our rules, some people may find offensive.\"\\nFacebook also spoke about the power of counter speech, which involves people challenging other users online.\\nIt added: \"We aim to strike the right balance between giving people the freedom to express themselves and maintaining a safe and trusted environment.\"\\nAkeela says that she hopes Twitter and Facebook do more to tackle Islamophobic abuse online: \"Ordinary Muslims are getting abuse for expressing their views.\\n\"I worked for a Muslim youth charity for a number of years, and have received Islamophobic abuse online for a while. But it has got worse.\"\\nYou can listen to BBC Asian Network\\'s original report by clicking on this link.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A former Premier League footballer accused of raping a woman he met in a nightclub has told a court she wanted to have sex with him.', 'negatives': [], 'positives': ['Adilson Tavares Varela, known as Cabral, told Hull Crown Court he had consensual sex with the 22-year-old woman at his flat in Gateshead.\\nThe ex-Sunderland midfielder denied being \"persistent, forceful and aggressive\" and said he stopped having sex with her when she asked him to.\\nHe denies two counts of rape.\\nThe woman has told the jury Varela pinned her down on his bed and raped her after they met during a night out in Newcastle.\\nBut the footballer said they kissed and danced together before going back to his home with friends, including retired French international Anthony Reveillere.\\nHe said the woman asked him to go into the bedroom.\\nWhen asked about her behaviour, Varela said: \"It was normal. It was a normal girl who wanted to have sex with me.\\n\"It seemed to me she was used to doing this as she was in no way ashamed.\"\\nHe told the court he removed all of his clothes except for his socks and that he and the woman had sex in two positions.\\nSpeaking through an interpreter, Cape Verde-born Varela told the jury the woman asked him to stop after around 15 minutes because she was tired.\\nHe said he stopped and swore at her in French because he felt \"frustrated\".\\nVarela, who has a fiancee and a three-year-old son who live in Switzerland, told the court he got dressed and returned to the others in the living room, where he sent a message to a woman he described as a \"sex buddy\".\\nHe said the complainant later left his flat with the others and was upset because she thought her mother would be angry with her.\\nVarela now plays for Swiss team FC Zurich. The trial continues.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Northern Ireland's sports minister has hit back at claims she was aware of safety issues around the redevelopment of Casement Park in Belfast.\", 'negatives': [], 'positives': ['UUP leader Mike Nesbitt said it was \"beyond belief\" that Carál Ní Chuilín was unaware of safety concerns until a committee meeting last month.\\nA safety expert said the 38,000-capacity stadium could not be evacuated safely in certain emergencies.\\nThe minister said she was \"confident\" her role would stand up to scrutiny.\\nIn a statement, Carál Ní Chuilín said Mr Nesbitt\\'s comments were \"without foundation\".\\n\"It is unbelievable that Mr Nesbitt would try to seek some form of political gain by suggesting that I would put people\\'s lives in jeopardy in order to build a sporting stadium,\" she said.\\n\"This issue is well above petty political point scoring.\\n\"I have repeatedly stated that I will not compromise on safety and that no stadium will open without a valid safety certificate. That was the case for the Kingspan Stadium at Ravenhill and it will be the case for Windsor Park and Casement Park.\\n\"It is encouraging, however, to note the new found interest of Mr Nesbitt in GAA stadia and I look forward to seeing him in the future in the new and safe Casement Park.\"\\nLast month, Paul Scott of Sport NI and the Safety Technical Group examining Casement,  briefed the Culture, Arts and Leisure Committee about the redevelopment plan by the Gaelic Athletic Association (GAA).\\nMr Scott said there was the potential for a disaster at the new stadium, like the Hillsborough tragedy.\\nHe also told the committee he was put under \"undue pressure\" to approve plans for the new ground by officials from the minister\\'s department. He said his concerns about safety had been \"largely ignored\".\\nAfterwards, Ms Ní Chuilín said she first heard of his allegations when he appeared before the committee. She said she was \"absolutely confident that had concerns of that nature been raised with my officials before I would have heard about it\".\\nHowever, on Wednesday, UUP leader Mike Nesbitt said it was \"frankly inconceivable that a senior official in possession of the sort of briefing Paul Scott would have given, focused as he was on the possibility of a Hillsborough-style disaster in a 38,000-capacity stadium, would sit on that knowledge\".\\nMr Nesbitt called on members of the Committee for Culture Arts and Leisure to vote on Thursday to begin an inquiry.\\nMs Chuilín has asked for a full review of the Casement Park project and has refuted the allegations.\\nA new consultation process is due to take place ahead of any fresh planning application.\\nMs Ní Chuilín has said safety would always remain paramount.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Bath have released New Zealand-born utility back Dan Bowden from his contract by mutual consent.', 'negatives': [], 'positives': ['Bowden, 30, who plays at inside centre or fly-half, has played only six league games for Bath since joining them in January 2016.\\nHe joined Bath from Super Rugby side Blues in his native Auckland, following spells at fellow Premiership clubs Leicester and London Irish.\\nMeanwhile, winger Jack Wilson, 27, has extended his contract until 2019.\\nThe former Saracens man joined from Otago in October, on a deal until the end of the season, and has scored three tries in eight appearances.\\nOn Bowden, director of rugby Todd Blackadder said: \"He\\'s a great professional.\\n\"We\\'d like to thank Dan for the commitment he has shown during his time at the club.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'This afternoon, eleven England internationals will walk out at Wembley to the roar of a sell-out crowd.', 'negatives': [], 'positives': ['Each will have the famous three lions badge on their shirts.\\nThat may all sound familiar, but those inside the stadium, and the many more watching at home, will be witnessing history.\\nSunday\\'s international friendly against old rivals Germany will be the first time England\\'s women have played at the new home of English football.\\nAnd more than 55,000 tickets have been sold, far more than the 40,181 that saw the last Wembley friendly involving England\\'s men.\\nInterest in the women\\'s game hasn\\'t been this feverish since 1920.\\nBack then crowds regularly dwarfed modern attendances for the men\\'s game, with one recorded at 53,000.\\nBut then an FA ban on the women\\'s game a year later stopped progress for decades.\\nOfficials deemed the sport \"unsuitable for females\" with the restriction not lifted for another half century.\\nThis season though the climax to the domestic Women\\'s Super League was televised and Sunday\\'s match will be broadcast on BBC2.\\n\"It\\'s unbelievable that we\\'ve sold 55,000 tickets,\" England defender Steph Houghton told Newsbeat.\\n\"I speak on behalf of all the girls and say we\\'re really, really excited. Times have changed massively over the last few years.\"\\nHowever, greater interest and exposure breeds added expectation and pressure.\\nMuch like the men\\'s abject failure in Brazil last summer, England\\'s women bombed out of their last major competition.\\nOne point out of nine from their three games at the European Championships in 2013 was a poor return by anyone\\'s standards.\\nIt was an opportunity lost to showcase the women\\'s game to the country.\\nHope Powell, who transformed the game in her 15 years in charge of the national side, was sacked.\\nMark Sampson was brought in to replace her and tasked with rebuilding the squad\\'s confidence and profile.\\nIt\\'s going well. Sampson has won 10 of his 12 games in charge and has lifted England to seventh in the world rankings.\\nSunday\\'s opponents Germany are second.\\nThe sides last met in the final of the 2009 European Championships, a game which the Germans won 6-2 at the Olympic Stadium in Helsinki.\\n\"Germany have always been an incredibly strong nation in women\\'s football,\" said Sampson.\\n\"They\\'re a team that continue to get results, they\\'re always at the end of major championships, and they\\'re European champions - so we\\'ll expect a really tough game.\"\\nThere\\'s no doubting a result against the Germans would be a huge scalp, especially considering the exposure the match will be getting.\\nAlthough the side\\'s main focus is next year\\'s World Cup in Canada.\\nWith 10/10 wins in qualification, hopes are high that an England team can finally bring back football\\'s biggest prize.\\n\"At the moment we\\'ve got a really good squad in terms of youth and experience. I think the balance is right,\" Steph Houghton told Newsbeat.\\n\"We\\'ve got six months to prepare and I think we\\'ve got a really good chance.\"\\nWomen\\'s football is one of the world\\'s fastest growing sports, with over 30 million women participating worldwide.\\nThe hope here is if the women\\'s team can couple success on the pitch with the sport\\'s growing profile, more and more women will start to play.\\n\"The most important thing is to enjoy playing,\" said Houghton.\\n\"Never lose the fact that you love the game. If you get the opportunity to go and train with coaches, listen to them and work as hard as you possibly can.\"\\nEngland take on Germany at 1500 GMT on Sunday 23 November. You can catch all the action live on BBC Two, Radio 5 live sports extra and the BBC Sport website.\\nFollow @BBCNewsbeat on Twitter and Radio1Newsbeat on YouTube'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Young people who have been through cancer treatment are taking on the demands of sailing around Britain on a 44ft yacht.', 'negatives': [], 'positives': ['\"It felt like being in control again,\" says Tom Roberts, who will be one of those setting off from Largs on Saturday to sail a 2,400-mile relay around the UK coastline.\\nSailing has been a real contrast to the medical world he had been in, where the demands of cancer treatment meant pretty much doing as he was told.\\nRound Britain 2017 is organised by the Ellen MacArthur Cancer Trust, set up by the well-known yachtswomen to help young people recovering from cancer regain confidence and a sense of independence through sailing.\\nA cancer diagnosis is devastating at any age but if you are a child or young person, going through other changes in your life, that can add another dimension.\\nTom Roberts, now 24, was diagnosed with bone cancer on his 16th birthday and says dealing with the emotional side of things was especially hard.\\n\"It certainly doesn\\'t stop when you stop your treatment,\" he adds.\\nSurgery and then about 18 months of chemotherapy and radiotherapy meant he missed out on crucial bits of his development.\\n\"There\\'s a lot of rebuilding that needs to go on to bring you back into the world and develop to a level where your peers are,\" he says.\\nHe will be recording life throughout the trip as the on-board reporter.\\nHis home for the next four months is the 44ft yacht, the Moonspray.\\nIn relays it will also host about 100 young people on different legs of the trip.\\nIt will stop at more than 60 towns and ports including Glasgow, Inverness, Edinburgh, Cardiff, Belfast, Plymouth, Liverpool and London.\\nThe journey begins and ends in Largs.\\nEach young person on board has their individual story.\\n\"I was terrified by the thought of stepping on a boat,\" says 20-year-old Victoria Sanches.\\n\"I never even considered it, especially after all I\\'d been through.\"\\nShe first sailed with the trust in 2013 and is doing so again this time.\\nAfter being diagnosed with a benign brain tumour, aged about 11, she feels she had to grow up earlier than she should have done.\\n\"I never thought I\\'d be saying, I have a brain tumour but I still sail,\" she says.\\n\"It\\'s almost showed me that my illness doesn\\'t have to stop me from trying new things and doing everything I want to do.\"\\nBeing with other people who really understand what they\\'ve been through was important to the young people I spoke to.\\nLearning how to tie knots, socialise and make relationships, was how one of them put it.\\nThe full-time mate on this trip, Hannah Spencer, 23, found sailing made a huge difference to her life and now she would like to pursue a career on the water.\\nDiagnosed during her exams, she too felt she missed out on things that teenagers do, like going out and learning social skills.\\n\"It (sailing) opened my eyes really,\" she says.\\n\"I was so insular, in my little chemo world, going to hospital every other day.\\n\"Coming away for just four days out of the year to different people, a different lifestyle really helped me, just showed me a different way I could live my life if I got through this, which thankfully I did.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Watford striker Troy Deeney should be given a chance by England if there are any more injuries, says Alan Shearer.', 'negatives': [], 'positives': ['Shearer, who scored 30 goals in 63 appearance for England, said Hornets skipper Deeney had impressed him with his character as well as his play.\\n\"He is an integral part to how Watford play. I like the way he leads that team and drags them around,\" Shearer told Match of the Day.\\n\"If there\\'s another injury then he should be given an opportunity.\"\\nFellow Match of the Day pundit Jermaine Jenas believes an ankle ligament injury to first-choice England striker Harry Kane may give Deeney a chance in this month\\'s World Cup qualifiers against Malta and Slovenia.\\nInterim England manager Gareth Southgate names his squad for those matches on Sunday.\\n\"Since he has come into the Premier League with Watford, Deeney has been outstanding,\" Jenas, who won 21 caps and was part of the 2006 World Cup squad, said.\\n\"We ask whether we should pick [Andy] Carroll, who is a hold-up man for England, but there are not many better at holding the ball up than Troy Deeney.\\n\"We have got a lack of leaders apparently and he is Watford captain and leads that team by example week in and week out.\\n\"He is good with the ball at his feet and he has scored three in the last four.\"\\nDeeney, 28, said last year he had twice held discussions about representing Jamaica who he also eligible to play for, but that his ambition is to play for England.\\nWatford manager Walter Mazzarri backed his captain\\'s claims to an England call-up last week, saying that Deeney was \"international level\".'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The last How to Train Your Dragon book is out today and we caught up with author Cressida Cowell.', 'negatives': [], 'positives': ['The twelfth and final book in the series is called \"How to Fight A Dragon\\'s Fury\" and features the final battle between dragons and humans.\\nYou\\'ve been sending in your brilliant questions for Cressida and we asked her who her favourite character from the series was, and if she is working on any new books.\\nShe also showed Jenny how to draw the mischievous main characters from her series: Hiccup and Toothless.\\nThere are lots of different species of dragon in Cressida\\'s books, so we thought we\\'d find out what Newsround would be like.\\nAs well as offering advice on writing, Cressida also explained the best way to illustrate your ideas.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A rocket launcher has been found at a household waste recycling centre.', 'negatives': [], 'positives': ['The green launcher, about 3ft (1m) long, was discovered in a skip by staff at the Knowle Hill centre, near Exmouth.\\nDevon County Council said the launcher was stripped of its launch mechanism so \"it could not have been used\".\\nThe centre was closed \"as a safety precaution\" for about an hour until police disposed of it.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Toulon want to renew Wales full-back Leigh Halfpenny's contract before he goes on tour with the British and Irish Lions next week, says the French club.\", 'negatives': [], 'positives': ['Halfpenny, 28, joined Toulon in 2014 from Cardiff Blues and his current deal runs out this summer.\\nThe Top 14 side\\'s owner, Mourad Boudjellal, wants to have the contract sorted \"by the end of this week\".\\nToulon have made an offer reported to be worth £750,000 per year for the club\\'s top points-scorer.\\nHis former Welsh region, in conjunction with the Welsh Rugby Union had offered Halfpenny a national dual contract (NDC), but Blues chief executive Richard Holland admitted in March that it was \"unlikely\" the player would agree a return.\\nHalfpenny again proved his worth as Toulon reached the French Top 14 semi-finals, scoring a crucial late try in a personal haul of 21 points as they saw off Castres 26-22 last Friday.\\nToulon will face La Rochelle in Marseille on Friday, 26 May for a place in the final, which will be Halfpenny\\'s last game of the season for the club.\\nThe Top 14 final is not until 4 June and Lions coach Warren Gatland has confirmed that Halfpenny will join up with the Lions squad immediately after the semi-final for the tour to New Zealand.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'An Indian baby has survived after his mother gave birth in a train toilet, and the newborn fell on to the tracks.', 'negatives': [], 'positives': ['The mother, identified as Manu, fell unconscious after giving birth on the train in Rajasthan. She has since been reunited with her son.\\nA guard at a warehouse near the tracks heard the baby crying and alerted the railway officials, who retrieved him.\\nMost Indian train toilets have a hole opening on to the tracks, and similar incidents have been reported before.\\nThe latest incident took place on Sunday when Manu was travelling with her mother from Suratgarh to Hanumangarh, railway officials said.\\nThe baby was born at Dabli Rathan area, a few miles from the Hanumangarh station.\\n\"Once the train reached its destination, the mother was admitted to Hanumangarh town hospital,\" North-West Railway spokesman Tarun Jain told BBC Hindi.\\n\"After being rescued, the baby was initially taken to the local hospital where he was given first aid. He was also later shifted to the town hospital.\"\\nDr SP Rohilla, the hospital\\'s chief medical officer, said mother and baby were doing fine.\\nA doctor in the hospital\\'s neo-natal care unit said the baby had no serious injuries and all tests were normal.\\n\"But he is underweight, he weighs only 2kg (4.4lb), and we are keeping him under watch,\" Dr Bijrania said.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Rory McIlroy says he will be driven by the desire to win for childhood hero Darren Clarke as Europe aim for a fourth Ryder Cup victory in a row against the United States.', 'negatives': [], 'positives': ['Europe begin the defence of their trophy in Minnesota on Friday.\\nMcIlroy was only 10 when he first met Europe skipper Clarke, 17 years ago.\\n\"I\\'ve always wanted the win for the captain, but probably even more so this year because of Darren and the relationship we have,\" said McIlroy.\\nHe added that being a player under fellow Northern Irishman Clarke is \"special for both of us\".\\nFour-time major winner McIlroy has never been part of a losing Ryder Cup team since his debut at Celtic Manor six years ago, and will be his team\\'s de facto on-course leader as the US attempt to win the Cup for the first time since 2008.\\nIn a team featuring six players making their Cup debuts, the world number three\\'s experience and charisma will be critical for Clarke, who was one of Paul McGinley\\'s vice-captains in the 16½-11½ victory at Gleneagles two years ago.\\nMedia playback is not supported on this device\\n\"McGinley was the best captain that I had ever played under - I had a very special relationship with Paul,\" said McIlroy.\\n\"I met Darren for the first time on my 10th birthday on the practice range at Royal Portrush Golf Club and we\\'ve known each other ever since.\\n\"That was my birthday present, to play Royal Portrush, or actually the Valley Course next to it. My dad took me up there.\\n\"I was chipping around the chipping green, and that\\'s where Darren was, and I was just in awe of him.\\n\"My 10th birthday wasn\\'t getting any better, and all of a sudden I meet Darren Clarke. I remember him saying to me, \\'practise, practise, practise\\'.\\n\"That day has always stuck with me and, even this week, all those memories come rushing back of the times that we\\'ve spent together from Portrush down to Portmarnock, where he held his foundation weekend every year.\\n\"Here we are, in the biggest stage of the game, and I\\'m able to play under him as a Ryder Cup captain.\"\\nMedia playback is not supported on this device\\nMcIlroy arrives in Minnesota in enviable form, having won a play-off to seal victory in the Tour Championship and take the $10m (£7.7m) FedEx Cup prize on Sunday.\\nHaving won the Deutsche Bank Championship three weeks ago, McIlroy\\'s latest success continued the sharp turnaround in his fortunes since he missed the cut at the US PGA Championship in late July.\\nDespite those spectacular earnings, the 27-year-old insists that the Ryder Cup, for which no player gets paid, remains an unparalleled experience in professional golf.\\n\"I think I underestimated what it was going to be like. I made a couple of comments before the 2010 Ryder Cup that seem very stupid now.\\n\"But I had no idea. I had been to Ryder Cups before - I had played in the Junior Ryder Cup, I was at Oakland Hills in 2004, I was at the Ryder Cup in 2006 at the K Club.\\n\"I was there and thought I knew what it was like, but there\\'s nothing like walking on to that first tee for the first time and feeling that rush and just soaking in the atmosphere.\\n\"That\\'s what I\\'ve tried to reiterate to the rookies that are on our team: you think you know what it\\'s like and you think you\\'ve played under pressure, but you haven\\'t. You haven\\'t played under what this is going to be like.\\n\"In 2012, I came into the Ryder Cup as the number one ranked player in the world. I had just won my second major championship, I won two of the four FedExCup events, I was playing really well, but I still didn\\'t feel like it was my place to be a leader on the team.\\n\"At Gleneagles last time, I embraced that more and I took more responsibility on. I relished the opportunity to rally our guys, to speak up in the team room when I needed to but definitely lead my example on the course.\\n\"I did that last time and hopefully I can do that again. I understand it\\'s a big responsibility, but I feel I\\'m now ready to take that on my shoulders and lead by example.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Pop star Adele has announced two dates at Wembley Stadium next summer to round off her multi-million pound world tour.', 'negatives': [], 'positives': ['The singer announced the concerts in an Instagram video, where she sang football anthem Three Lions as well as the Match of the Day theme song.\\nDubbed \"The Finale\", the performances will see her play to more than 150,000 fans on 29 June and 1 July 2017.\\nTickets go on sale to members of her fan club on 30 November, followed by a general sale on 2 December.\\nWembley Stadium has not announced any other events planned for that week, raising the prospect that Adele may add further concerts if demand is high enough.\\nLaunching in Belfast on Leap Day, Adele\\'s first world tour has incorporated 107 dates across Europe and North America, with more dates to come in Australia next year.\\nAlongside flawless renditions of hits like Hello, Skyfall and Someone Like You, the star\\'s unfiltered, uncensored on-stage chatter has often made headlines.\\nIn Belfast, she confessed to having \"severe bowel movements\" as opening night nerves kicked in. She announced her Glastonbury headline slot from the stage of London\\'s O2, and allowed a couple in Toronto to get engaged during her show.\\n\"You got a Tiffany ring! Nice work, nice work,\" she told the bride-to-be.\\nAfter Brad Pitt and Angelina Jolie announced the end of their marriage in September, the star jokingly dedicated her show to them, calling it \"the end of an era\".\\nAnd just last week, she had an encounter with a bat during a show in Mexico.\\n\"There\\'s a bat there and it landed by your head!\" she said, pointing at an audience member. \"It landed right by your head! Welcome to Mexico! I\\'m happy to be here, but a bat? Jesus Christ!\"\\nFollow us on Facebook, on Twitter @BBCNewsEnts, or on Instagram at bbcnewsents. If you have a story suggestion email entertainment.news@bbc.co.uk.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A baggage handler in the US caused a plane to make a priority landing when he fell asleep in the cargo hold whilst loading.', 'negatives': [], 'positives': ['But he\\'s by no means alone in ending up asleep in an unexpected spot.\\nSleeping in strange places is something of a national sport in China, as demonstrated by this lorry driver, pictured next to a busy road in the city of Ningbo in 40C (104F) heat.\\nBernd Hagemann, who took these pictures and is the author of Sleeping Chinese, puts the nation\\'s habit of sleeping in unconventional places down to long working hours and cramped living conditions.\\nBut he also thinks it is socially more acceptable to sleep in public in China than some other countries.\\n\"Sleeping has - according to Chinese people - a very high rank in the list of values,\" he adds.\\nDozing in odd places is not unique to China of course, as demonstrated by this labourer in Jakarta, Indonesia, pictured lying on a pile of rice sacks.\\nMichael Oko, a specialist in sleep apnoea at the Sleeping Disorders Centre, says there is no cheating the \"sleep deficit\". \"Power naps help,\" he says \"but they are just a temporary fix. You need sleep hygiene with a regular routine and to get between six to eight hours sleep a day. Below that, you are not going to be well.\"\\nIn the case of the Alaska Airlines baggage handler, Mr Oko says an investigation would most likely look at his recent shift patterns and whether he has any underlying sleep problems such as snoring or breath-holding.\\nHe says men, people over 50 and those with a body mass index of more than 35 are most likely to have sleep disorders.\\n\"Micro sleeps\" when someone sleeps for moments while doing something like driving, are the most dangerous types of naps, says Mr Oko. These Indian rickshaw pullers and taxi motorcyclists in Nigeria are luckily not at the wheel.\\nIn California, the competitive world of hog contests has provided for some unusual pillows.\\nIn space, you can slumber pretty much anywhere, as long as you don\\'t float around and bump into things.\\nAccording to Guinness World Records, Soviet cosmonaut Gherman Titov was the first person to sleep in space.\\nOn board the Vostok 2 in 1961 he found his arms floating in front of him, but once he secured them with a belt he claimed to have \"slept like a baby\".'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Bank of Ireland is to close eight branches in Northern Ireland and make up to 54 staff redundant.', 'negatives': [], 'positives': ['The branches to close are in Antrim, Castlereagh, Draperstown, Belleek, Castlederg, Newtownards, Maghera and Donegall Square South, Belfast.\\nBank of Ireland closed nine other Northern Ireland branches in January 2013.\\nThe bank said there would be no compulsory redundancies and staff would have the opportunity for redeployment.\\nIt said the branches did not do sufficient business to sustain them in the long-term.\\nThe bank will have 28 branches in Northern Ireland after the closures.\\nIt is understood the closure of the Bank of Ireland branch in Belleek, County Fermanagh, will mean there is no longer any bank in the village.\\nBridie Gormley, chairperson of Belleek Chamber of Commerce, said the news had come as a \"huge shock\" and would mean a \"round trip\" of up to two and a half hours for those people who wanted to bank at a branch.\\n\"That\\'s not feasible and the people of Belleek will not sit back and take this easily,\" she said. We will fight it to the bitter end\\n\"We need a bank in this town. It\\'s a service we cannot do without.\"\\nJohn Campbell, BBC News NI business editor\\nAll of Northern Ireland\\'s \\'big four\\' banks have been closing branches in response to customers moving online and to cut costs.\\nBranches are an increasingly unloved part of retail banking - at least among the people who run banks.\\nThey have chunky fixed costs, such as rent and rates, and the number of customers using them has tumbled as more banking moves online.\\nOne senior banker told me he sees the future of branches as being a bit like car show rooms.\\nIn other words there won\\'t be many of them and the typical customer will venture into them only once every few years.\\nThe Donegall Square branch premises will become the bank\\'s first \\'enterprise lounge\\' in Northern Ireland.\\nIt will offer entrepreneurs and business start-ups free facilities and services.\\nThe Financial Services Union said the move was \"regrettable and irresponsible.\"\\n\"The decision to close branches is not taken lightly, and we understand that it will be disappointing for those customers who use them,\" the bank\\'s Sean Sheehan said.\\n\"A key priority will be to ensure customers understand the alternative arrangements available, and to maintain continuity of customer service.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Major improvements are needed at north Wales' three main hospitals to reduce the risk of infection, a report has found.\", 'negatives': [], 'positives': ['Gill Harris, Betsi Cadwaladr University Health Board\\'s (BCUHB) executive director of nursing and midwifery, said targets for 2016-17 were missed.\\nThis was despite a 25% drop in Clostridium difficile (C. diff) cases and a 9% fall in MRSA cases.\\nThe health board has hospitals in Wrexham, Bangor and Bodelwyddan.\\nIn her report, Ms Harris said: \"Rates of infection in BCUHB remain too high and the health board is committed to protecting people from infections.\\n\"Improvements are needed across a wide range of key clinical practice standards, including the care of invasive devices and antimicrobial prescribing, and the focus of work within BCUHB is on these aspects of care.\"\\nIn 2013, Wales\\' largest health board, which cares for 694,000 people in north Wales, was severely criticised for how it handled an outbreak of C. diff after 30 patients died while suffering with the infection at Glan Clwyd Hospital in Bodelwyddan, Denbighshire.\\nThe chief executive, chairman and vice-chairman later stood down.\\nProf Brian Duerden, an expert in healthcare associated infection and antibiotic resistance, was commissioned to produce the report into the outbreak and was highly critical.\\nImprovements at BCUHB, whose hospitals include Wrexham Maelor, Bangor\\'s Ysbyty Gwynedd and Glan Clwyd, were last year said to be \"very significant\".\\nThe health board has been only one in Wales in special measures for the last two years.\\nBCUHB will discuss what more needs to be done when it meets on Thursday.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"The 2015 Yorkshire Half Marathon has started without a hitch, following last year's cancellation due to a lack of water for runners.\", 'negatives': [], 'positives': ['Nearly 8,000 people took part in the race through the streets of Sheffield.\\nThere was confusion last year when many runners completed the race amid police efforts to set up roadblocks, despite the event officially being cancelled.\\nBeverage firm Water Direct agreed to make a charity donation after failing to provide water for the 2014 race.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"South Korea's Chung Mong-joon says he wants to replace Sepp Blatter as Fifa's next president.\", 'negatives': [], 'positives': ['Chung is a former vice-president of world football\\'s governing body and the major shareholder of the industrial giant Hyundai.\\nHe told the BBC\\'s World Football programme rival Michel Platini was not the right man for Fifa.\\n\"If I get elected, my job is not to enjoy the luxury of the office,\" he added. \"My job is to change it.\"\\nThe 63-year-old, who is worth $1.2bn (£769m) according to Forbes, said he did not think Platini would make a good Fifa president.\\n\"It will be very difficult for Mr Platini to have any meaningful reforms,\" said Chung.\\n\"Mr Platini enjoys institutional support from the current structure of Fifa. Mr Platini is very much a product of the current system.\"\\nPlatini declared his intention to run for the 26 February election on Wednesday, though candidates have until 26 October to be nominated.\\nBlatter, who has run Fifa since 1998, is standing down following a series of damaging corruption allegations against the organisation.\\nUnited States and Swiss authorities have launched separate criminal investigations into corruption at Fifa, with seven top officials indicted on bribery and racketeering charges in the US.\\nThe English Football Association has confirmed it will back Uefa president Platini\\'s bid for election.\\nHowever, Chung, who believes he has a \"good chance\" of winning the election, said: \"It is time that Fifa had a non-European leadership.\\n\"Fifa became a closed organisation for President Blatter, his associates and his cronies and I want to change that.\"\\nChung lost his Fifa vice-presidency in 2010, to Prince Ali Bin al-Hussein of Jordan, who unsuccessfully stood against Blatter in May\\'s presidential election.\\nMeanwhile, Argentina football great Diego Maradona has said he wants to fight the \"mafia\" behind the corruption in Fifa, but stopped short of saying he would run for president.\\nThe 54-year-old former World Cup winner told local television channel America: \"I have to fight the mafia that still remains inside Fifa. I have to fight those who have for a long time stolen from inside Fifa.\"\\nWhen asked if he would run for the presidency, he said: \"I really want to be in Fifa.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'There has been a succession of warnings for the UK from European officials in the aftermath of the referendum.', 'negatives': [], 'positives': [\"Among them, suggestions that British banks can expect reduced access to the market for financial services in the remaining 27 EU states.\\nThe Bank of France governor, Francois Villeroy de Galhau, said they won't be able to use what's called the banking passport system unless Britain signs up to all the rules of the single market.\\nAs those rules include free movement of workers it would be politically challenging for the British government negotiating the post-exit relationship.\\nSo what is it that the British banks might lose?\\nBanks and other financial companies can be authorised to do business in one member state of the EU, or the slightly wider European Economic Area (EEA), and then ply their trade across the region without having to be separately authorised in each country.\\nThe EEA is a grouping made up of the EU, plus Norway, Iceland and Liechtenstein who have access to the EU's single market.\\nA bank using this system can provide services by offering them from its home base to a customer in another country, or it can establish a branch abroad.\\nIt is widely used by financial firms (not just banks) in the EU. It is also used by companies from outside the EEA, such as Switzerland and the US.\\nThey establish themselves in one place in the EU, typically in London as the continent's dominant financial centre, and use that as their headquarters for selling services across the single market.\\nIf the banking passport is no longer available to British-based firms, then some operations would clearly have to shift to a location inside the EEA.\\nWhat is impossible to judge is just how much business, and how many jobs, would be affected. Would any shift be narrowly focused on those functions serving EEA customers? Or would firms find it more cost-effective to move other parts of the business as well?\\nThere's also a view that lighter regulation of the city would be possible outside the EU and that would stimulate further growth in the financial sector. That could in turn offset any jobs and business that might be lost if the passport option is removed for operations based in the UK.\\nIn principle, it is possible that even if the UK ends up outside the EEA, the exit deal might allow for passporting for financial firms.\\nLeave campaigns have argued all along that Britain is such an important market to the rest of the EU, that they would have an incentive to negotiate a deal that's favourable to the UK. That could, perhaps, apply to the financial services elements of any agreement.\\nOn the other hand, the post-referendum comments coming from European officials have not been encouraging. Some have suggested their negotiating position will be tough, in order to discourage euro scepticism in other countries.\\nSome of those unpromising comments have referred specifically to financial services - the French central bank governor and the Dutch Finance Minister, Jeroen Dijsselbloem, for example.\\nAnd the rest of Europe has long cast a rather envious eye over London's thriving financial centre. They would like some of that business for themselves. Frankfurt, Paris, Amsterdam and Dublin are all significant financial centres, albeit far smaller than London.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Thieves have made off with a \"substantial four-figure sum\" in a break-in at a caravan park.', 'negatives': [], 'positives': ['The safe was taken overnight between Thursday and Friday from a portable office building at Lighthouse Leisure in Southerness.\\nDet Con Grant Drennan said they were carrying out door-to-door inquiries in the area.\\nHe said they wanted to hear from anyone who had seen or heard anything suspicious in the area.\\n\"It appears that those responsible might have taken some time to carry out this crime and we are also keen to hear about any suspicious activities on the days leading up to this theft,\" he added.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A chronology of key events:', 'negatives': [], 'positives': ['40,000 BC - The first Aborigines arrive from south-east Asia. By 20,000 BC they have spread throughout the mainland and Tasmania.\\n1770 - Captain James Cook charts the east coast in his ship HM Endeavour. Cook claims it as a British possession and names eastern Australia \"New South Wales\".\\n1788 - British Navy captain Arthur Phillip founds a penal settlement at Sydney. He had arrived with a fleet of 11 vessels, carrying nearly 800 convicts. The Aboriginal population at the time is thought to number several hundred thousand.\\n1829 - Colony of Western Australia established at Perth by Captain James Stirling.\\n1836 - South Australia established, with Adelaide as its capital.\\n1850s - Gold is found at several locations leading to gold rushes throughout the decade. The population increases three-fold in 10 years to pass the million mark. An influx of Chinese leads to restrictions on their entry. Aborigines are treated very badly and their numbers collapse.\\n1856 - Australia becomes the first country to introduce the secret ballot - or \\'Australian ballot\\' - for elections.\\n1877 - Australia and England play the first-ever cricket Test match in Melbourne.\\n1901 - The country is unified. The Commonwealth of Australia comes into being on 1st January.\\nThe Immigration Restriction Act puts a brake on non-white immigration.\\n1911 - Canberra is founded and designated as the capital.\\n1914 - Outbreak of World War I. Australia commits hundreds of thousands of troops to the British war effort.\\nTheir participation - alongside New Zealanders - in the Gallipoli campaign in Turkey in 1915 leads to heavy casualties. The Gallipoli landings help cement a sense of identity in the young nation.\\n1929 - The Great Depression following the Wall Street Crash hits Australia hard. Recovery is uneven, and the Labor government is defeated in the election in 1931.\\n1939 - Australia follows Britain\\'s lead and declares war on Nazi Germany.\\n1941 - The US declares war on Japan. Australia turns to the US for help in its defence after the Japanese take Singapore. Australia allows the US to base its supreme command for the Pacific war on its territory.\\n1948 - Australia begins a scheme for immigration from Europe. Over the next 30 years, more than two million people arrive, about one-third of them from Britain, and hundreds of thousands from Italy, Greece and Germany.\\n1950 - Australia commits troops to the UN forces in the Korean war.\\n1956 - Olympic Games held in Melbourne.\\n1965 - Australia commits troops to the US war effort in Vietnam.\\n1967 - National referendum on changes to constitution is passed. Section which excluded Aboriginal people from official census is removed. Another change enables federal government to pass laws on Aboriginal issues.\\n1975 - Australia introduces new immigration laws, restricting the number of unskilled workers allowed into the country.\\nThe government of Gough Whitlam is plagued by resignations and the blocking of its budget by the upper house of the parliament. In an unprecedented move, the governor-general, Sir John Kerr, dismisses the government. A caretaker administration under Malcolm Fraser is installed.\\n1983 March - Bob Hawke becomes prime minister after his Labor Party secures a landslide victory.\\n1986 - The Australia Act makes Australian law fully independent of the British parliament and legal system. There is no longer any provision for Australian courts to mount final appeals to the Privy Council in London.\\n1991 December - Paul Keating becomes prime minister.\\n1992 - The Citizenship Act is amended to remove swearing an oath of allegiance to the British Crown. Prime Minister Paul Keating\\'s Labor government pledges to make Australia a republic and to concentrate on links with Asia.\\n1993 - Keating wins elections. The Native Title Act establishes a process for the granting of Aboriginal land rights.\\n1996 - Keating defeated in elections. John Howard of the Liberal Party becomes prime minister.\\n1998 - Elections see Howard\\'s Liberal and National party coalition re-elected, but with a reduced majority. Delegates to a constitutional convention vote to replace Queen Elizabeth II as head of state with a president chosen by parliament. The issue is put to a referendum in 1999. The proposal is defeated, with 55% voting to retain the status quo.\\n1999 - Australia leads intervention force in East Timor to counter pro-Indonesia militia violence after territory\\'s independence vote. Relations with Indonesia worsen.\\n2000 - Australia hosts the Olympic Games in Sydney, the most popular ever.\\n2001 January - Australia celebrates 100 years since its inauguration as the Commonwealth of Australia.\\n2001 February - Sir Donald Bradman, Australia\\'s most famous cricketer, dies at the age of 92.\\n2001 May - Churches rebuke Prime Minister John Howard for failing properly to acknowledge suffering of thousands of Aborigines under past assimilation policy. Howard has refused to apologise to \"Stolen Generations\" of Aborigines who as children were forcibly removed from their parents to live with whites.\\n2001 August - Australia turns away hundreds of boat people over several months, the most prominent group having been rescued from a sinking ferry. Australia pays Nauru to detain many of them.\\n2001 November - Howard wins a third term in general elections.\\n2002 - Aid agencies, rights groups and UN report criticise policy of holding asylum seekers in detention camps until their visa applications are processed. Woomera desert camp in South Australia sees riots, hunger strikes and escapes.\\n2002 October - Australia mourns as 88 of its citizens are killed in a night club bombing in Bali, Indonesia, which some call Australia\\'s September 11. The attacks - which killed 202 people in total - are blamed on al-Qaeda-linked Islamists.\\n2003 January - Australia deploys troops to the Gulf ahead of a possible war. The move sparks public protests.\\nBushfire ravages the capital, Canberra. More than 500 homes are destroyed. Other fires rage across New South Wales, Victoria, Tasmania.\\n2003 February - Senate passes no-confidence motion against Prime Minister John Howard over his handling of Iraq crisis. It is Senate\\'s first-ever vote of no-confidence in serving leader.\\n2003 May - Governor-General Peter Hollingworth resigns after admitting that, as an Anglican archbishop in the 1990s, he allowed a known paedophile remain a priest.\\n2003 July - Australia heads peacekeeping force intended to restore order in troubled Solomon Islands.\\n2004 February - Race riots in district of Sydney, sparked by death of Aboriginal teenager.\\n2004 March - Parliamentary committee clears government of lying about threat posed by weapons of mass destruction in Iraq. In July, report details intelligence failings over Iraq, Bali bombings, but clears government of manipulating Iraq intelligence.\\n2004 August - Government announces a multi-million dollar cruise missile programme, set to give Australia the region\\'s \"most lethal\" air combat capacity.\\n2004 September - Bomb attack outside Australian embassy in Jakarta, Indonesia, kills at least nine, injures dozens more.\\n2004 October - John Howard wins fourth term as prime minister; his party extends its grip on parliament.\\n2004 November - Death of Aboriginal man in police custody sparks rioting on Palm Island, off north-east coast.\\n2005 January - Worst bush fires for more than 20 years kill nine people in South Australia.\\n2005 July - Australia says it will deploy 150 special forces troops in Afghanistan to counter rebel attacks. The original contingent was withdrawn in 2002. Further deployments are announced in 2006.\\n2005 November - As parliament debates controversial new anti-terrorism laws, police say they have foiled a planned \"large-scale terrorist attack\".\\n2005 December - Racially-motivated violence, involving thousands of youths, hits Sydney.\\n2006 January - Australia and East Timor sign a deal to divide billions of dollars in expected revenues from oil and gas deposits in the Timor Sea. Under the agreement, discussions on a disputed maritime boundary are postponed.\\n2006 April-May - Australian troops spearhead peacekeeping forces in the Solomon Islands and East Timor after unrest in both countries.\\n2006 August - Proposed legislation, under which future asylum seekers who arrive by boat will be sent to offshore detention camps, is scrapped after a revolt by ruling party lawmakers.\\n2006 December - Amid the worst drought in a century, the government slashes economic growth forecasts, reflecting a slump in farm output. In January PM John Howard declares water security to be Australia\\'s biggest challenge.\\n2007 November - Opposition Labor Party, under Kevin Rudd, sweeps to power with landslide victory over John Howard.\\n2007 December - Prime Minister Rudd signs documents ratifying Kyoto protocol on climate change, reversing the previous government\\'s policy.\\n2008 February - Government apologises for past wrongs committed against the indigenous population.\\nAustralia ends its policy of sending asylum seekers into detention on small Pacific islands, with the last refugees leaving Nauru.\\n2008 July - Labor government abandons policy - introduced in 1990s - of holding all asylum seekers in detention centres until their cases are heard.\\n2008 September - Quentin Bryce sworn in as Australia\\'s governor-general, the first woman to hold the post.\\n2009 February - Devastating bushfires in the south-eastern state of Victoria kill more than 170 people.\\n2009 May - Australia announces plans to more than double its submarine fleet and buy 100 US Stealth fighters as part of a $70bn military modernisation programme.\\nIndian students hold rallies in protest against a series of violent attacks - more than 70 in the past year - which they say are racially motivated. India voices concern about the violence.\\n2010 February - Five Muslim men are sentenced to lengthy prison terms for conspiracy to carry out attacks.\\nBritish Prime Minister Gordon Brown apologises for the policy of sending thousands of children to former colonies under a migrant programme that ended 40 years previously.\\n2010 June - Julia Gillard becomes prime minister, ousting Kevin Rudd in a Labor Party leadership challenge.\\n2010 August - Parliamentary elections fail to deliver a clear winner. Prime Minister Gillard clings to power after securing support of independents to form a minority government.\\n2011 January - Queensland is hit by floods which are described as the most expensive natural disaster in the country\\'s history.\\n2011 December - Economy grows unexpectedly fast in the third quarter of 2011, driven by construction and mining. GDP rose 2.5% on the year, whereas analysts had expected 2.1%.\\n2012 January - Talks between government and opposition on asylum seekers break down. The opposition says the government fails to address concerns about a plan to swap refugees with Malaysia that the high court had declared unlawful.\\n2012 February - Foreign Minister Kevin Rudd resigns to mount a challenge to Prime Minister Gillard\\'s leadership, but is defeated.\\n2012 July - Controversial carbon tax, which penalises big polluters, comes into force. Prime Minister Gillard says it is needed to meet climate change obligations; opponents say it will cost jobs and raise prices.\\n2012 August - Five Australian troops are killed in Afghanistan in what Prime Minister Gillard says is Australia\\'s deadliest day in combat since the Vietnam War.\\n2012 September - After an independent panel recommends setting up holding centres in Nauru and Papua New Guinea to cope with rising numbers of asylum-seekers, the government says it will send the first group for processing in Nauru. Australia also signs an agreement with Papua New Guinea to conduct offshore processing on Manus Island.\\n2013 January - Labor Prime Minister Julia Gillard says elections will be held in September, hoping to use the long run-in to recoup support.\\n2013 March - A chaotic and abortive leadership challenge bounces Prime Minister Gillard into a major cabinet reshuffle to oust supporters of long-standing rival Kevin Rudd. The previous month the Greens dropped their alliance with Labor, but pledged to keep the government in power.\\n2013 June - After months of infighting, Kevin Rudd manages to oust Julia Gillard as Labor leader and prime minister in a parliamentary party vote.\\n2013 July - Australia reaches deal with Papua New Guinea that will allow it to ship asylum seekers arriving by boat onwards to its Pacific neighbour.\\nPapua New Guinea will receive generous aid in return, and the offshore processing centre on its Manus Island will be significantly expanded to hold up to 3,000 people.\\nLiberals return\\n2013 September - Parliamentary elections. Landslide victory for Liberal-National Coalition, led by Tony Abbott.\\n2013 October - Government adopts new policy of naval vessels intercepting boats of migrants and directing them back to Indonesia, which is followed by a dramatic reduction in arrivals.\\n2014  March - Australia takes a leading role in search for missing Malaysian Airlines plane MH370, thought to have been lost in the southern Indian Ocean.\\n2014 April - Japan and Australia reach an agreement over a trade deal that will lower tariffs between the two nations.\\n2014 September - Australia says it is sending 600 military advisors to Iraq as part of effort against Islamic State group.\\nPolice carry out the nation\\'s biggest ever counter-terrorism raids, with 15 arrests in Sydney and Brisbane, sparked by intelligence reports that Islamic extremists were planning random killings.\\n2014 December - Islamist Man Haron Monis takes 18 people hostage in Sydney cafe; two hostages and gunman die when police storm premises.\\n2015 March - Parliament passes law requiring its internet and mobile phone providers to store customer data for two years as anti-terror measure.\\n2015 June - Government announces 20-year plan to develop the infrastructure of the north, including transport and water resources.\\n2015 September - Communications Minister Malcolm Turnbull replaces Tony Abbott as prime minister after a successful Liberal Party leadership challenge.\\n2016 April - Prime Minister Turnbull announces plan to hold early parliamentary and Senate elections in June, after Senate rejects government bill twice.\\n2016 July - An early general election sees Prime Minister Turnbull\\'s conservative Liberal-National coalition secure the narrowest of majorities over the opposition Labor Party.\\n2016 August - Human Rights Watch and Amnesty International accuse the Australian government of condoning the systematic abuse of refugees and asylum seekers at its camp on Nauru. Prime Minister Malcolm Turnbull says the claims will be investigated.\\nChina says Australia\\'s decision to block two Chinese companies from buying a controlling stake in the country\\'s largest electricity network will seriously impede future investment in Australia.\\nAustralia agrees to close a controversial asylum seeker detention centre on Papua New Guinea\\'s Manus Island but says none of the 850 people held there will be resettled on Australian soil.\\nLinda Burney becomes the first indigenous woman to be elected to Australia\\'s lower house of parliament.\\n2016 September - Australia says it will close its permanent research station on Macquarie Island, a remote post between Australia and Antarctica due to lack of funds.\\nControversial politician Pauline Hanson says Australia is in danger of being \"swamped by Muslims\" and calls for an end to further Muslim immigration and a ban on the wearing of burqas.\\nAustralia acknowledges that its warplanes took part in a US-led raid in Syria which Russia says killed up to 90 Syrian government soldiers.\\n2016 November - Government\\'s bid to hold a referendum on whether to legalise same-sex marriage is narrowly defeated.\\nAustralia says refugees held in detention centres on the Pacific islands will be resettled in the United States in a \"one-off deal\".\\nIslamic State militant Neil Prakash, described as Australia\\'s \"most wanted terrorist\" who was thought to have been killed in an air strike in Iraq , is arrested in Turkey.\\n2016 December - Police arrested five men suspected of planning a terrorist attack in Melbourne on Christmas Day.\\n2017 January - Indonesia suspends military cooperation with Australia after material allegedly insulting the country\\'s founding principles is found on display at an Australian military base.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Crowdfunding platform Indiegogo intervened to stop a handheld retro computer console campaign from acquiring further funding, the BBC has learned.', 'negatives': [], 'positives': ['The Spectrum ZX Vega+, backed by Sir Clive Sinclair, had achieved its original crowdfunding target.\\nBut then Indiegogo halted further fundraising because of delivery delays and a lack of communication to backers.\\nThe project\\'s organisers had asked the BBC not to reveal the development.\\nThe BBC understands no consoles have been delivered to backers, despite a pledge last month that they would \"ship after 20 Feb 2017\".\\nAnd the company behind the project - Retro Computers Limited - suggested these details might put its team at risk.\\n\"Following a credible threat of violence against personnel of Retro Computers Limited, including threats made as recently as last night, we asked [technology desk editor] Leo Kelion and the BBC to refrain from publishing a story we believe to be factually inaccurate and might put people at risk of physical harm, alarm and distress,\" Retro Computers Limited founder David Levy said in a statement on Wednesday.\\n\"Since December 2016 the BBC have formally been on notice that this is a police matter, and we ask that the BBC and Mr Kelion do not compromise the police investigation.\"\\nThe BBC delayed publication of this report to give RCL managing director Suzanne Martin time to provide evidence of the threats, but she did not do so.\\nIn the meantime, the Gizmodo news site also published and then deleted an article about the matter because it too was told of threats.\\nRCL had already received more than Â£513,000 ($624,000) from Indiegogo crowdfunders for the Vega+ .\\nAnd before the fundraising campaign was halted, the project had been listed as \"in demand\" to allow new people to become backers, despite having already reached its funding target.\\nBut in recent weeks, many backers have expressed anger that they still have not received their console and claimed their requests for more information were going unanswered by the company.\\nAlthough, Indiegogo is clear in its terms and conditions that those who back a project are supporting an idea rather than buying a product - and that hardware in particular tends to be more difficult to deliver.\\nIn 2015, RCL brought a different Sinclair computer to fruition after a smaller campaign.\\nRCL originally said the new Spectrum ZX Vega+ was due to go into production in the summer of 2016 and it might even \"be able to improve on this delivery date\".\\nBut in December 2016, after the BBC contacted RCL to ask about the status of the Vega+, the broadcaster was threatened with legal action.\\n\"Our clients are concerned that the BBC is in fact supporting and participating in a malicious campaign intended to denigrate our clients\\' reputation,\" wrote lawyers Michelmores LLP in a letter to the broadcaster.\\nThey went on to request that the BBC show them its report at least 48 hours ahead of publication so they could identify any false information, which the BBC refused to do.\\nMs Martin then apologised to backers for the delays and said there had been unexpected issues with the console buttons.\\n\"In November, we identified an improvement we believed was essential to the Vega+ gaming experience,\" she said at the time.\\n\"An improvement that would make the feel of the product far better, including a correction in the design of one of the buttons, making it more robust and able to withstand the rigours of extended game-play.\\n\"We also wanted to make sure we did justice to the Sinclair legacy.\\n\"This change has caused a brief delay, and we are truly sorry about that, but we needed this time to improve the product, and we have now completed the necessary revisions, and we are delighted to announce that we will ship the first units in February 2017.\"\\nSince then, RCL has suggested it had been unable to respond to some backers\\' requests because of a business dispute with two former directors.\\nAnd in its last public update, 11 days ago, the company released some technical details about software used by the device.\\nMany recent comments left by backers on RCL\\'s Indiegogo page, which remains live but has stopped taking funds, are requests for refunds.\\n\"I don\\'t expect a response. I\\'m just being polite in letting them know this is their last chance before they have to deal with small claims court,\" wrote a backer called Paul Brookfield.\\n\"Please receive this email as written notice of cancellation of my pledge and a request for a refund,\" wrote Drew Miller.\\n\"I no longer believe you are capable of providing the product I pledged for in April, considering the drastic number of delays and your lack of communication toward fellow backers.\"\\nUpdate 10 March 2017: Retro Computers Ltd has issued a new statement announcing a delivery delay, but says it expects the first batch of Vega+ consoles will be available in a few weeks\\' time.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Fulham head coach Slavisa Jokanovic has revealed negotiations over the job went on for several weeks.', 'negatives': [], 'positives': ['The 47-year-old Serb was appointed by the west London club on Sunday, replacing Kit Symons, who was sacked as manager on 8 November.\\n\"We talked a few weeks and it was a long process. I believe I was the first choice for the club and they pushed hard to bring me here,\" said Jokanovic.\\n\"It is a great chance for me to work at a historical club.\"\\nFulham held talks with then Reading boss Steve Clarke in mid-November about taking over from Symons, but chairman Shahid Khan said the club \"had an obligation to fully explore our options\" and were interested in Jokanovic \"from the start\".\\nThe Championship club have paid Israeli side Maccabi Tel Aviv £367,000 compensation for Jokanovic\\'s services and the former Watford boss will be joined at Craven Cottage by coaches Alberto Escobar and Javi Pereira.\\nJokanovic expects Stuart Gray, who had been in charge of the Whites since 8 December, to remain in his role of senior coach at the club.\\n\"Stuart has tried to give me all the information and I need help from him,\" he said. \"I expect in the future we will collaborate better.\\n\"We are both here in the interests of Fulham and I believe we can work together to do a quality job.\"\\nJokanovic watched from the stands as his new side beat Rotherham 4-1 at home on Tuesday night to record their first win in 10 games and move up to 18th in the table.\\nThe former Chelsea midfielder won promotion to the Premier League with Watford last season, but he has not yet set himself goals for the rest of the campaign.\\n\"My job is clear and people expect me to improve the team and fight for more important targets,\" he said.\\n\"After some weeks and months our targets will be clear. We need to take short steps.\\n\"I believe in myself, the club and the people. I am ready for the challenge.\"\\nJokanovic will take charge of Fulham for the first time on Saturday, when they host Sheffield Wednesday.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Protesters against tax avoidance have staged demonstrations at shops across the UK on what is traditionally the busiest shopping weekend of the year.', 'negatives': [], 'positives': ['UK Uncut said it held sit-down protests in cities including London, Edinburgh and Manchester against the Arcadia Group, Boots, Vodafone and Barclays.\\nArcadia Group\\'s flagship Topshop and BHS shops in Oxford Street were hit.\\nThe wife of Sir Philip Green, the firm\\'s boss, has been criticised for living in a tax haven.\\nAt Topshop in Oxford Street, demonstrators sat in protest on the shop floor chanting \"Green, pay your taxes\".\\nBut unperturbed shoppers were seen still hunting for Christmas presents around them.\\nThe demonstrations follow a larger protest at the store earlier this month and incidents in October when UK Uncut picketed entrances to shops owned by Vodafone, which has also been accused of avoiding tax payments.\\nBy Lucy WilkinsBBC News\\nThe blizzard conditions did not deter the action at Top Shop on Oxford Street in London.\\nBefore the planned protest time of 1300 pairs of policemen were standing at every door.\\nBy 1415 the ranks of the police swelled and protesters already inside mingling with Christmas shoppers came forward as a group and started chanting \\'Philip Green, pay your taxes\\'.\\nAt least two protesters were removed by security guards and one demonstrator required four guards to carry him out into the freezing cold.\\nUK Uncut, which arranged the demonstration using micro blogging site Twitter, said Topshop\\'s parent firm Arcadia was its main target.\\nNobody from the company was available for comment.\\nUK Uncut said it also took action in 52 other locations on Saturday at sites including Brighton, Truro, Cambridge, Liverpool, Wrexham, Tunbridge Wells, Bristol, Nottingham and Oxford.\\nSussex Police said two men, aged 21 and 27 and both from Brighton, were arrested on suspicion of criminal damage and public order offences.\\nOne reportedly glued himself to a branch of Dorothy Perkins - also owned by Arcadia - and the other to a BHS store in the city.\\nProtester Rebecca Davies, 32, said: \"Over four years £100bn is expected to be lost from the public purse to tax avoidance, which could pay for so many of the cuts that will hit the poorest in our society.\\n\"The argument that the only way to cut the public deficit is to cut public services is a lie. The coalition is ideologically smashing a public sector that supports the poorest.\"\\nThe group says reclaiming unpaid tax from business was an alternative to the government\\'s planned cuts.\\nTopshop owner Sir Philip is one of the UK\\'s most successful retailers.\\nWith a personal fortune of more than £4bn, he runs the Arcadia Group, whose fashion chains also include Burton, Evans and Miss Selfridge.\\nHis wife Tina is the direct owner of Arcadia, and she is officially a resident of Monaco. This enabled her to gain a tax-free £1.2bn dividend in 2005.\\nSpeaking in August about the tax status of his wife, Sir Philip told the BBC: \"My wife\\'s not a tax exile - my family do not live in the United Kingdom, it\\'s somewhat different.\\n\"We do pay all our tax in Britain. I think we have paid over the last five years some £300-400m in taxes on profits that have been made on our company.\\n\"I\\'m a UK taxpayer, I work here every week, we employ 45,000 people in the UK and we have got a £500m payroll.\"\\nSince the election Sir Philip has been appointed by the government to look into Whitehall efficiency and he produced a report which described \"staggering\" wastage.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Serena Williams was thrilled to win a record 23rd Grand Slam title at the Australian Open but would not speculate on how many more she could secure.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nThe American, 35, beat sister Venus 6-4 6-4 to overtake Steffi Graf in the list of Open-era major champions.\\nShe is now just one behind Australia\\'s Margaret Court in terms of all-time Grand Slam singles victories.\\n\"I never had a number. That\\'s the beauty of it,\" said Williams, who won her first major at the 1999 US Open.\\n\"When I started this journey, I just wanted to win a Grand Slam.\\n\"Then I just wanted to win. Every time I step on the court, I want to win. It\\'s just really remarkable.\"\\nWilliams drew level with Germany\\'s Graf on 22 major singles titles at last year\\'s Wimbledon, but then lost in the semi-finals of the US Open.\\nShe won her seventh Australian Open title without dropping a set in Melbourne.\\n\"It\\'s such a great feeling to have 23,\" she said. \"It really feels great.\\n\"I\\'ve been chasing it for a really long time. When it got on my radar, I knew I had an opportunity to get there, and I\\'m here.\\n\"It\\'s a great feeling. No better place to do it than Melbourne.\"\\nThe experience was all the more special because it was shared with Venus, who at 36 was making her first Grand Slam final appearance since 2009.\\nThe sisters became the oldest women to appear in a major final since the Grand Slams accepted professional players in 1968.\\n\"We\\'re both, like I say, 30-fun,\" Serena joked. \"Now I just feel like I\\'m satisfied with where I am, although I always want to win.\"\\nAs well as the title, Serena regained the world number one ranking from Germany\\'s Angelique Kerber - but she did not know that was on the line as her coach, Patrick Mouratoglou, kept it from her.\\n\"That was a bonus. I didn\\'t know actually. It feels good. I like being on top, so I really like that feeling,\" she said.\\n\"In the beginning of the tournament, I was like, \\'If I win, will I be number one?\\' Patrick said, \\'No, no, no.\\'\\n\"Today on the court when they were like, \\'And number one\\', I was like, \\'Whoa, really?\\'\"\\nAfter reaching her first Grand Slam final since 2009, Venus Williams will head into the rest of the season in confident mood.\\nShe will rise from 17th to 11th in the world rankings after her run to the final in Melbourne.\\n\"Ready to kill it this year,\" she said. \"That\\'s my goal. It\\'s a great start to the year. I\\'m looking forward to the rest of year.\\n\"This is like tournament number two and it\\'s already a lot of work. I\\'m looking forward to tournament number three and four. It\\'s going to be awesome.\"\\nVenus, who has had to cope with auto-immune disease Sjogren\\'s syndrome in recent years, played down the suggestion she and Serena are the greatest sporting siblings of all time.\\n\"I don\\'t think we\\'re going for the greatest story in sports,\" she said.\\n\"We\\'re just going for some dreams. In the case that we are, what an honour, what an honour.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"An overwhelming majority of Scotland's publicly-funded elite athletes are drawn from middle class backgrounds, a BBC Scotland investigation has found.\", 'negatives': [], 'positives': ['It discovered that almost nine in 10 went to either fee-paying schools or a state school in a wealthy area.\\nThe data was uncovered by The Medal Myth, a documentary looking at elite sport, health and public spending.\\nSport Scotland said it was trying to do more to increase opportunities for all on its elite programmes.\\nBBC Scotland originally asked Sport Scotland for demographic information about the athletes it supports - a total of more than 500.\\nHowever, the agency said it did not have any data, so the programme team used search engines to try to determine which schools athletes attended.\\nWhere data could be found, it showed the vast majority of athletes went to schools that were private or served relatively wealthy communities.\\nBBC Scotland used search engines to try and determine where athletes went to school.\\nWe found information for 383 of 525 athletes (72.9%).\\nWe looked at state schools ranked by free school meal entitlement. We divided those into bands - for example, the top 20% are the schools with the lowest free school meal entitlement, and therefore serve wealthier children.\\nThe results do not reveal the detailed background of athletes themselves, but they do give a broad indication of whether the athlete group broadly represents wider society.\\nReacting to the research, Prof Leigh Robinson of Stirling University - an expert in sport policy - said: \"I think anything that comes from the public purse should have generally wide public merit good and I\\'m not convinced that elite sport does that.\\n\"I\\'m not entirely sure that elite sport is something that\\'s accessible to the public in general or indeed leads to benefits that are available to the public in general.\"\\nSport Scotland\\'s chief executive Stewart Harris said the agency was trying to improve the situation.\\nHe said: \"We\\'re working to get more opportunities. We\\'re working to try and get in every sport a pathway which goes from school to community to performance, if they have the talent and ambition, if they want to go there.\\n\"I think actually the spend and the resource is actually in a pretty good place right now.\\n\"95% of the sport budget in Scotland is spent on school and community, 5% is spent on performance.\\n\"So I think the balance of it, if you take the system, then I think... as a society in Scotland with the resources we have available, we\\'re in a good place with that.\"\\nThe organisation is in the middle of a four-year funding cycle that will see it spend over £45m on its performance programme.\\nRecent Olympics and Commonwealth Games have seen record numbers of medals for Scottish athletes.\\nThe Medal Myth will be broadcast on BBC One Scotland on Monday 2 January at 20:30. It will be available afterwards on BBC iPlayer.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Chelsea interim manager Guus Hiddink believes John Terry deserves a public farewell - despite being banned for the final two games of the season.', 'negatives': [], 'positives': ['Terry, 35, looks set to leave Stamford Bridge this summer after saying he would not be getting a new contract.\\nHowever, Chelsea say an offer could still be made to keep their long-serving captain at the club.\\n\"Whether he stays, whether he goes - in the last option, he deserves a huge goodbye,\" Hiddink said.\\n\"(But) it\\'s never goodbye with those players, because I think in the near future, whatever happens, they can have a big impact in clubs.\"\\nThe Blues defender made his debut for the club in 1998 and has since made 703 appearances in all competitions.\\nHe was sent off in Saturday\\'s 3-2 loss at Sunderland and because it was his second dismissal of the season, he is suspended for Chelsea\\'s final two games against Liverpool and then Premier League champions Leicester City at Stamford Bridge.\\nHowever, Hiddink admits the decision over Terry\\'s future does not rest with him as new head coach Antonio Conte is set to arrive in the summer.\\n\"When I make a judgement on how he plays and his fitness on his age, he\\'s able to play, he\\'s able to continue,\" Hiddink added.\\n\"Where? What the near future is is up to the club, it\\'s not for me to make declarations on that.\"\\nSince breaking into the first team 18 years ago, Terry has made 483 Premier League appearances, winning four titles, five FA Cups, three League Cups, the 2012 Champions League, the 2013 Europa League.\\nHe has 78 international caps, but retired from international football in 2012 after the Football Association charged him with racially abusing Anton Ferdinand.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A man whose dog died days after he beat and threw it around a train carriage has been jailed.', 'negatives': [], 'positives': ['Kieran Milledge, 22, was caught on CCTV attacking his Staffordshire bull terrier on a train between Braintree and Witham, Essex, in October.\\nHe was seen abusing the animal in what Chelmsford Magistrates\\' Court heard was a \"continued and brutal attack\".\\nMilledge, of no fixed address, admitted animal cruelty and possession of a bladed weapon.\\nLive: For more on this and other Essex stories\\nHe was jailed for 21 weeks for the animal cruelty offence and, to be served concurrently, eight weeks for breaching a suspended sentence order and six months for the weapon offence.\\nThe attack on his dog, called Ronnie, happened over a 20 minute period, the court heard.\\nMilledge hung the dog by its lead and then swung him against the wall of the train before pushing his foot against his pet\\'s face.\\nDuring the attack, Ronnie appeared to lose consciousness and fouled the seat he was on.\\nHe died three days later, the court was told.\\nMilledge said he had been so drunk that he could not remember what happened.\\nSgt Steven Maguire, of British Transport Police, said: \"I welcome today\\'s sentence as it has taken a violent dog abuser off the streets.\\n\"Milledge\\'s cruel beating of his dog was simply inexcusable and I am pleased that he now has an indefinite ban from keeping animals.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A controversial campaigner accused of being \"pro-rape\" has been forced to cancel fan meet-ups that were due to take place across the UK on Saturday.', 'negatives': [], 'positives': ['Daryush Valizadeh - also known as Roosh V - wrote a widely criticised article last year calling for the legalisation of rape on private property as a way to \"defeat rape culture\".\\nThe self-styled \"neo-masculinist\" has since said the post was satirical.\\nA petition calling to ban the UK events has attracted almost 81,000 signatures.\\nThe Return of Kings group, which the 36-year-old American created, supports an agenda that men are superior to women and oppressed by feminism.\\nGroup meet-ups planned for Glasgow, Edinburgh, London, Cardiff, Manchester, Newcastle, Leeds and Shrewsbury had sparked widespread protests.\\nMr Valizadeh has posted on his website that he can \"no longer guarantee the safety or privacy\" of attendees.\\nProtesters had called for the meetings to be banned and a petition lobbying the police and Home Office to ban the UK events has almost 81,000 signatures. MPs have also called for Mr Valizadeh to be banned from the UK.\\nResponding to an urgent question about the meetings, Home Office Minister Karen Bradley said the government \"condemns in the strongest terms anyone who condones rape and sexual violence or suggests that responsibility for stopping these crimes rests with the victims\".\\nMs Bradley said the government would not \"routinely comment on individual immigration or exclusion cases\".\\nHowever, she stressed the Home Secretary had the power to ban non-British citizens if she believed their presence was \"not conducive to the public good\".\\n\"The government is pleased that the Return of Kings events appear to have been cancelled,\" she added.\\nIn Scotland, a Facebook page and petition were set up in protest at the planned events.\\nThe Glaswegians Against Roosh V page states that \"pro-rape women-haters are not welcome in Glasgow\" and will face public ridicule when they gather in the city\\'s George Square on Saturday.\\nThe petition urging the Scottish government to Stop Roosh V being allowed to \"promote his hateful violent views\" in Scottish cities has gained more than 57,000 signatures.\\nMr Valizadeh had planned \"tribal meetings\" for \"heterosexual men only\" across the globe on Saturday.\\nBut he announced on his blog on Wednesday: \"I can no longer guarantee the safety or privacy of the men who want to attend on February 6, especially since most of the meet-ups can not be made private in time.\\n\"While I can\\'t stop men who want to continue meeting in private groups, there will be no official Return Of Kings meet-ups.\\n\"The listing page has been scrubbed of all locations. I apologize to all the supporters who are let down by my decision.\"\\nMr Valizadeh has published 15 books on how to \"pick up women\".\\nSNP MP Owen Thompson has written to the Home Secretary calling for Roosh V to be prevented from entering the UK, although there is no suggestion he is planning to come to Scotland.\\nAnd SNP MP Tommy Sheppard has tabled an Early Day Motion at Westminster condemning the nature of the meetings.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Facebook has been ordered to pay £3,000 damages to a loyalist flag protester for online comments about his children's religion.\", 'negatives': [], 'positives': ['High Court judge Mr Justice Colton, sitting in Belfast, found the social media company liable for misuse of private information.\\nThe man - known as J20 - sued Facebook over a series of offensive comments posted on its pages.\\nJ20 came under the spotlight for his involvement in loyalist demonstrations.\\nIt followed a decision in December 2012 to limit the flying of the union flag at Belfast City Hall.\\nThe court heard that J20 had a conviction for disorderly behaviour over an incident linked to tensions at the time.\\nIn September 2013, one page included a picture of the man standing in front of the flag. It named him and the caption read: \"Meet Sectarian Parade Organiser\".\\nA number of allegations and comments about the man were posted underneath the picture by various users.\\nIn his legal action against Facebook, the man sued for harassment and misuse of private information.\\nDismissing the harassment claim, Mr Justice Colton said the comments were offensive and distasteful, but did not \"cross the boundary between what is unattractive and unreasonable as opposed to what is oppressive and unacceptable\".\\nThe judge said J20 had understated his involvement in the flag protests.\\nBut he held that the man did have a right to privacy over the religion of his children.\\n\"The reference to these children - who can be identified by reason of the identification of the mother of the plaintiff\\'s ex-partner - in my view does constitute a misuse of private information,\" he said.\\nRuling that Facebook was liable, he awarded £3,000 damages.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Walk through any big supermarket or corner shop in the country and convenience foods, from microwaveable meals to pre-cooked meat, are ubiquitous.', 'negatives': [], 'positives': ['The horsemeat scandal has shown how complex the UK\\'s meat supply chain has become, and it also highlights how little retailers and customers alike know what is actually going into the food that we eat.\\nMeat represents 14% of a household\\'s weekly food purchases on average, according to a 2012 report from the Department for Environment, Food and Rural Affairs (Defra).\\nWhile data from Defra\\'s Family Food report shows there has been little change in the proportion of meat people have been buying in the UK for decades, there is a marked difference in the type of meat being purchased.\\nThe quantity of ready meals and convenience meat products - including kebabs and chicken kievs - the British public bought increased by 480% from 1974 through to 2011.\\nThat stands in stark contrast to weekly household purchases of fresh cuts of meat, such as lamb, mutton, pork, beef and veal, which have all experienced noticeable drops.\\nThe Family Food report figures show chicken became a more popular meat than beef for the first time in 1988 during the BSE crisis - when the public boycotted British beef after a link was established between BSE carried by infected cattle and the human form of the disease, CJD.\\nPurchases of ready-made burgers - which were the original focus of the horsemeat scandal - have been relatively consistent over time.\\nItalian food passed English to become the biggest selling ready meal cuisine in 2011, with sales of Â£406m.\\nThe UK market for chilled and frozen ready meals is valued at Â£1.85bn and grew 6.6% in 2011, according to market research company Key Note.\\nBut the market was rocked after horsemeat was found in some frozen lasagne and spaghetti Bolognese products this month, including some Findus beef lasagne products which were found to contain 100% horsemeat.\\nPrice is the most important factor for shoppers when they are deciding which foods to buy, according to Defra\\'s 2012 Food Statistics Pocketbook.\\nMore than 40% of customers said it is the most important factor, with 90% listing it in their top five.\\nFood prices have risen by 12% in real terms since 2007 and, after years of price falls, are now back up to 1997 levels.\\nThat has resulted in those in low income households cutting back on fruit, vegetables and meat like beef, pork and lamb, Defra says.\\nFood writer Rose Prince compared the horsemeat revelations to the BSE crisis of the 1980s and thinks the current crisis will lead to a lack of trust from the public in convenience food.\\n\"We\\'ve come to believe religiously in convenience food without thinking too much about where it comes from because we trust suppliers and retailers,\" she said.\\n\"What we\\'re seeing now is as a result of the constant drive to keep food prices low.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The funeral for Kayleigh Haywood, who was murdered last year, has taken place in her home village in Leicestershire.', 'negatives': [], 'positives': ['The 15-year-old, from Measham, who went missing last November, was found dead in a field, near Ibstock, after a five-day police search.\\nHer mother, Stephanie Haywood, said she \"can\\'t say goodbye\" and was \"broken hearted\" on an online tribute page.\\nThe Rev Canon Vivian Elphick, who led the service at St Laurence\\'s Church, said the day would be \"most difficult\".\\nTwo men have been charged in connection with Kayleigh\\'s death and go on trial in June.\\nLive updates and more from Leicestershire\\nHundreds of mourners gathered for the funeral, in Measham, wearing something purple - Kayleigh\\'s favourite colour. A private family service followed.\\nMs Haywood wrote on the page, hours before the service began: \"I can\\'t say goodbye as I will have you in my heart forever. You babe was my daughter, best friend and soul mate.\\n\"I love you princess forever, ever love from your broken hearted mum.\"\\nPurple bows tied to lamp-posts lined Kayleigh Haywood\\'s journey along Measham\\'s High Street to the parish church.\\nHer purple coffin was transported in a horse-drawn carriage with the words sister in flowers on one side and daughter on the other.\\nThe funeral service heard tributes from her head teacher at Ashby School, her brothers and sisters, and her parents.\\nA private burial, attended only by her family, followed.\\nCanon Elphick said: \"We can\\'t begin to imagine what that\\'s going to be like for them.\\n\"For me the funeral is the last thing we can physically do for someone who has died.\\n\"Therefore, it\\'s really important that we get it right for the family and those closest to them, so all those things help people on a journey of saying farewell, which is a journey they didn\\'t choose to be making and don\\'t want to be making.\"\\nDerek Mullan, the head teacher of Kayleigh\\'s former primary school, was among those who paid tribute to her.\\nHe said: \"For the staff of the school, one of the most endearing memories was of Kayleigh\\'s big smile as she bounded down the corridor first thing in the morning.\\n\"She would have a cheery \\'good morning\\' and staff would return the greeting.\"\\nEddie Green, head teacher of Ashby School, told the congregation that Kayleigh, who attended the school for more than a year, had been expected to pass all her GCSE subjects and had taken particular pride in her work in art.\\n\"The whole of our school community has been saddened and touched by these tragic events, but the way in which they have pulled together has been quite remarkable.\"\\nKayleigh was last seen when she was dropped off outside Ibstock Community College on Friday 13 November.\\nOver five days, police carried out extensive searches for the teenager in various areas in the county including Ibstock, Belton and Diseworth.\\nAn inquest heard Kayleigh died from head and facial injuries.\\nStephen Beadman, 28, of George Avenue, Ibstock, has been accused of murder and one count of rape.\\nA second man, Luke Harlow, 27, also of George Avenue, is charged with grooming and two counts of sexual activity with a child.\\nBoth men go on trial in June at Nottingham Crown Court.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The UK will not be \"cowed\" after Islamic State killed another western hostage, David Cameron has told MPs.', 'negatives': [], 'positives': ['The prime minister described IS as \"sick terrorists\" who he pledged would be defeated.\\nA video was released on Saturday showing the beheading of a US aid worker and 18 Syrian prisoners.\\nEarlier Home Secretary Theresa May told the Commons the killing of American Abdul-Rahman Kassig demonstrated the \"deadly threat\" faced by the UK.\\nMr Kassig - known as Peter before he converted to Islam - became the fifth western captive beheaded by IS in recent months.\\nThe father of a British man thought to be pictured in the video has denied it is his son.\\nAhmed Muthana said 20-year-old Nasser Muthana was not among the uniformed jihadists seen in the footage.\\nMeanwhile the Ministry of Defence said it had carried out further air strikes against the militants in Iraq.\\nIt released a video which it said showed a single RAF missile strike on an IS communications vehicle.\\nAppearing in the Commons after discussing the West\\'s response to IS at the G20 in Australia, Mr Cameron said: \"We will not be cowed by these sick terrorists. They will be defeated and they must face the justice that they deserve.\\n\"The threat is faced by countries right across the world. We must face it together.\"\\nMr Cameron said new legislation aimed at tackling British citizens going abroad to fight with the militants would be introduced in the next two weeks.\\nThe Counter-Terrorism Bill would give police new powers to seize passports, stop suspects from travelling, and to stop Britons returning to the UK \"unless they do so on our terms\", he said.\\nMrs May said Mr Kassig\\'s murder, and the recent attack on the Canadian parliament, were reminders of \"the very deadly threat we face from terrorism at home and abroad\".\\nShe told MPs: \"That is why protecting the British public remains this government\\'s number one priority and why we\\'re taking urgent action to ensure our police and intelligence agencies have all the tools they need to keep people safe.\"\\nLabour leader Ed Miliband said the latest beheading was another demonstration of IS\\'s \"evil ideology\" that reinforced \"our determination\" to defeat the militants.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Three men suspected of participating in the gang rape of a woman and her teenage daughter have been sent to jail for 14 days as investigations continue.', 'negatives': [], 'positives': ['The two were dragged out of a car by a group of men along a highway between Noida, a Delhi suburb, and Kanpur city on Friday, reports said.\\nThree male relatives travelling with them were assaulted and tied up.\\nThe incident has caused outrage across the country and raised questions about police efficiency.\\nSome of the victims alleged that they got no response from the official helpline number.\\nOne of the men who was attacked told the Hindustan Times newspaper that the line had been continually busy and that when they finally got through, the officer at the other end of the line had \"repeatedly asked questions instead of rescuing the family\".\\nFamily members also alleged that a police van had driven past the field in Bulandshahr area where the incident took place, but had not stopped.\\nSenior police officer Sujeet Pandey told BBC Hindi on Monday that the three men, who were arrested on Sunday, were remanded in prison after they were identified by their victims.\\nThree more men were detained today, he added.\\nThe Uttar Pradesh state government has suspended seven policemen in connection with the incident and set up a 300-member taskforce to investigate the incident.\\nThe family was also robbed of money, jewellery and their mobile phones.\\nScrutiny of sexual violence in India has grown since the 2012 gang rape and murder of a student on a Delhi bus.\\nHowever, brutal sexual attacks against women and children continue to be reported across the country.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Tiger Woods has withdrawn from the Dubai Desert Classic before the second round, because of a back problem.', 'negatives': [], 'positives': ['The 14-time major winner only returned to action in December after 15 months out following two back operations.\\nWoods, 41, struggled in the first round in Dubai as he shot a five-over 77.\\nHis agent Mark Steinberg said the American suffered a back spasm on Thursday night but was told by Woods that it was not \"the nerve pain that\\'s kept him out for so long\".\\nSteinberg explained: \"He feels terrible for the tournament. He wants to be here. He can move around. He can\\'t make a full rotation on the swing.\\n\"The fact he feels it\\'s not the nerve pain is very encouraging for him. He\\'s had some spasms before, no doubt about it.\\n\"The short-term prognosis, he thinks, hopefully will be strong, based on the fact it\\'s not that nerve pain I just alluded to.\\n\"He doesn\\'t have the strongest back in the world so it\\'s probably easier to spasm because of the issues he\\'s had.\"\\nWoods had won the Dubai tournament twice before, but was 12 shots behind overnight leader Sergio Garcia after day one.\\n\"I wasn\\'t in pain at all. I was just trying to hit shots and I wasn\\'t doing a very good job,\" Woods said after his opening round.\\nWoods\\' first return to competitive action after his lengthy lay-off came at the Hero World Challenge - an 18-man tournament in the Bahamas - in December and he finished 15th at the PGA Tour event.\\nAfterwards, he expressed concerns over the physical challenge of being scheduled to play four full-field tournaments over the next five weeks.\\nHis next outing came at the PGA Tour\\'s Farmers Insurance Open at Torrey Pines where a first round 76 and level-par second round of 72 meant he missed the cut.\\nThe former world number one\\'s next two tournaments were to be the Genesis Open at Riviera from 16-19 February and the Honda Classic in Palm Beach Gardens from 23-26 February but his participation now appears in doubt.\\nWoods, who has won 79 titles on the PGA Tour, has not won a tournament anywhere since 2013, while his title drought in the major championships dates back to 2008.\\nMeanwhile, play in Dubai was abandoned on Friday because of high winds which blew trees over and whipped sand across the course. Round two is scheduled to restart on Saturday morning.\\nSouth Africa\\'s George Coetzee had completed eight holes of his second round as he moved into the lead on nine under, while Garcia was one shot behind having completed five holes.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The former personal assistant of U2 star Adam Clayton has been jailed for seven years for embezzling 2.8m euros (£2.2m) of his money to fund a lavish lifestyle.', 'negatives': [], 'positives': ['Carol Hawkins, 48, was last week convicted on 181 counts of theft from the bassist\\'s bank accounts over a four-year period.\\nClayton was not in court for the sentencing.\\nThe judge said Hawkins\\' crimes were \"rooted in greed and nothing else\".\\nJudge Patrick McCartan said:  \"Nothing, frankly, could explain away the scale of this dishonesty other than the greed in pursuit of a lavish lifestyle that was no responsibility of Mr Clayton\\'s.\"\\nHe said the fact Ms Hawkins had maintained her innocence throughout the trial was a factor in his sentencing and suggested if given an opportunity to commit a similar crime in the future, he was not entirely confident she would resist.\\n\"Whether she was a fool or clever person really matters very little,\" he said.\\nThe jury at the Circuit Criminal Court in Dublin returned an unanimous verdict on each individual count after deliberating for more than five hours last week.\\nMs Hawkins, who has always protested her innocence, had been freed on bail until sentencing.\\nSpeaking after the verdict was delivered, Mr Clayton said he was pleased with the verdict and thanked his legal team.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The control room for the Dounreay Fast Reactor (DFR) has been placed into the care of two museums.', 'negatives': [], 'positives': ['The DFR is the most recognised feature of the experimental nuclear power site in Caithness because of its large sphere, also known as the Dome.\\nNational Museums Scotland and the Science Museum in London will share panels from the control room.\\nThere were plans to keep the Dome as a historical monument but it too is to be dismantled.\\nUnlike the control room, the parts of the 1950s-constructed steel sphere will be scrapped.\\nThe DFR control room is designated as being of national significance by Historic Scotland and National Museums Scotland and is to be preserved for future display in public museums.\\nDFR went critical in November 1959 and operated until its shutdown in March 1977.\\nThe experimental fast breeder reactor led British research and development of nuclear energy during the 1950s and 60s.\\nThe control room contained an operator\\'s desk and 14 panels along three sides of the room.\\nLast year, the wall panels were dismantled and packed into two containers.\\nThe control desk was cut into three sections in order to get it out of the building and placed inside a separate container.\\nJames Gunn, Dounreay Site Restoration Limited\\'s heritage officer, said: \"The Science Museum and National Museums Scotland receive over 5.6 million visitors every year and the sharing of our unique industrial heritage with museums world renowned for their historic collections and exhibitions is a fantastic opportunity for Dounreay.\"\\nDounreay has also recently transferred the Dounreay Materials Testing Reactor control room to local museum Caithness Horizons in Thurso.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The Open University remains the top university in Northern Ireland for student satisfaction for the tenth year running,  according to a survey.', 'negatives': [], 'positives': ['The results of the National Student Survey (NSS) were released on Tuesday.\\nIt showed that  93% of respondents in Northern Ireland declare themselves to be \"satisfied with the quality of their course\".\\nJohn D\\'Arcy, director of The Open University in Northern Ireland, said they were thrilled.\\n\"As experts in the delivery of flexible, part-time higher education we are proud to be able to offer quality courses, support and access to education to people in Northern Ireland,\" he said.\\n\"It\\'s our mission to continue to provide students here with the best study opportunities and experience possible.\\n\"I\\'d like to pay tribute to our staff across the Open University who have helped achieve this endorsement from our students.\"\\nThe Open University (OU) is the largest academic institution in the UK.\\nSince it began in 1969, the OU has taught almost 1.9m students.\\nIn 2013, The Open University officially became one of three universities in Northern Ireland, as it is now funded by the Northern Ireland Executive through the Department for Employment and Learning.\\nIn Northern Ireland, there are more than 4,000 part-time students.\\nThe National Student Survey (NSS) is led by the Higher Education Funding Council for England, but funded by the four UK HE funding bodies, along with the National College of Teaching & Leadership and Health Education England.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Bookworms have been filling the halls at Guadalajara's Expo this week.\", 'negatives': [], 'positives': ['The Guadalajara International Book Fair is 29 this year, and Mexico\\'s second city has turned into one big library as it readies itself for more than 800,000 visitors.\\nAfter Frankfurt, Guadalajara is the most important date in international publishers\\' diaries.\\n\"All of the editors, all of the publishers, all of the authors want to come here,\" says the fair\\'s director, Marisol Schulz Manaut.\\nThis year, the guest of honour is the UK, shining a spotlight on one of the oldest - and largest - publishing industries.\\n\"We have people from Asia, from Europe, from all over the world coming every year to the book fair to do business. It\\'s a huge exhibit of books - 400,000 titles in Spanish,\" says Ms Schulz Manaut.\\nThe region has a huge potential. It has a population of close to 600 million and, according to the United Nations, more than nine out of ten adults are literate.\\nBut when it comes to getting people to sit down with a good book, that is still a struggle.\\nRecent figures from Mexico\\'s National Council for Culture and Arts (Conaculta) showed that Chileans were the biggest booklovers in the region. They read, on average, 5.4 books a year. Mexicans follow closely with 5.3.\\nBut that figure includes texts for school or work, so in terms of books read for pleasure that stands at just 3.5 books a year.\\nCompare that with the US where a recent survey by Pew Research Centre said Americans read 12 a year.\\nEven the fair\\'s director acknowledges it is a problem.\\n\"This is not really a country where people read. We have to do a lot of things and the same happens all over Latin America,\" says Ms Schulz Manaut. \"We have to promote reading among younger generations.\"\\nWhich is why there is a big focus on children\\'s books at the fair. An entire separate hall is dedicated to children\\'s activities and bookshops.\\nLow levels of reading are partly because of poor reading habits - but they are also a reflection of the region\\'s economic divide.\\n\"It\\'s a problem of inequality and lack of education, but I think that is changing and you can see it from the numbers,\" says Marianne Ponsford, the director of the Regional Centre for the Book Promotion in Latin America and the Caribbean (Cerlalc).\\n\"In the last 40 years this continent has boomed in an extraordinary way and culture has been at the centre stage of this quiet revolution.\"\\nBut the boom does not always translate into growth.\\nMexico\\'s publishers\\' association (Caniem) reported this week that 143 million books were sold last year - down more than 3% from 2013. The value of the books sold also fell.\\nBookshops in Mexico have been on the receiving end.\\nAccording to the Institute for Professional Development of Bookshops (Indeli), one in 10 bookshops closed between 2009 and 2014.\\nEl Pendulo bookshops in Mexico City have survived the hard times. The small chain of six stores calls itself a \"cafebreria\" - or coffee-book-shop in English.\\nIts combination of not just offering books but food, music events and talks is popular with the capital\\'s booklovers who come to browse. But it is not easy.\\n\"The opening of bookshops in Latin America continues to be difficult,\" says El Pendulo\\'s manager Rene Reyes.\\n\"There are big gaps in the region because of the region\\'s economies. In Mexico in particular most of the bookshops in the country are in the capital.\"\\nEl Pendulo prides itself on offering people a place to come in, sit down and read a book. But for how long?\\nSpanish-language publishers are still not prepared to put all of their catalogue online. According to Cerlalc, just 21% of titles in the region are available in electronic form. So there is room for growth.\\n\"In Mexico it\\'s still unclear where it stands with online purchases,\" says Rene Reyes. \"There is the demand. The issue more than anything is the lack of confidence when it comes to giving over your card details. Really, that\\'s all it is.\"\\nBut it is not. The other big problem is piracy - and that puts off publishers from investing in the region.\\n\"Compared with some other places of the world it\\'s bad,\" says Ana Maria Cabanellas, a publisher in Argentina and a former president of the International Publishers\\' Association.\\n\"We have a big problem with piracy and also with exporting piracy. For example, Peru has a lot of piracy - but they don\\'t only consume it in Peru, they export it to Bolivia, to Colombia, to Ecuador so your books are pirated in one place but this piracy is exported to other places.\"\\nGovernments can - and do - play a huge role in encouraging reading. The purchase of text books for educational purposes makes up a huge part of the region\\'s sales.\\n\"I think the challenges have to do with politics in the region, with having governments who really care about education,\" says Ms Ponsford.\\n\"We are more and more democratic as the years go by. But I think that is a challenge, to get public policy to be stronger than the governments that come and go.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The United States Grand Prix is shrouded in uncertainty as a result of heavy thunderstorms in Texas on the periphery of Hurricane Patricia.', 'negatives': [], 'positives': ['Second practice at the Circuit of the Americas near Austin was cancelled as a result of the storms.\\nMedia playback is not supported on this device\\nWith up to 30cm of rain forecasted to fall on Saturday, qualifying could be postponed until Sunday.\\nFerrari\\'s Sebastian Vettel said: \"If it\\'s like this, we can\\'t run. It does not look good.\"\\nLewis Hamilton\\'s team-mate and title rival Nico Rosberg set the pace in a rain-affected first practice.\\nThe German, needing to beat team-mate Lewis Hamilton to retain his slim title hopes, headed Red Bull\\'s Daniil Kvyat. Hamilton was an unrepresentative fifth.\\nThe Briton needs to beat Vettel by nine points and Rosberg by two to win the title this weekend.\\nOfficials have not yet made specific contingency plans because the weather forecast is changing so frequently.\\nHowever, governing body the FIA is open to the possibility of changing the weekend timetable to try to ensure qualifying can take place if there is a window of dry weather.\\nThe worst of the weather is expected to subside by Sunday, when the race is scheduled for 1400 local time (1900 GMT).\\nIf it is not possible to run qualifying on Saturday, officials have the choice of running it on Sunday morning before the race, or deciding the grid by another method.\\nHurricane Patricia, which is on its way to Mexico, is one of the strongest tropical storms on record.\\nThe storm is even raising concerns about the forthcoming race in Mexico next weekend.\\nIf it causes extensive damage in the capital Mexico City, there could be a knock-on effect for the race at the Autodromo Hermanos Rodriguez track, which is hosting a grand prix for the first time since 1992.\\nAny country considering a model for a new Formula 1 race could do far, far worse than look at what Austin, Texas, has achieved with the US Grand Prix.\\nFor a start, there\\'s the track. In marked contrast to many of the so-called Tilke-dromes that have proliferated in recent years, the Circuit of the Americas has real character.\\nElevation change, a good selection of challenging corners of differing speeds, the real possibility of creating proper racing and decent viewing.\\nBeyond that, Austin itself is a superlative host city - vibrant, cosmopolitan, friendly and blessed with great nightlife.\\nIn just three short years, the race has already become a modern classic.\\nIt really is the standard to which all new races must aspire - but from which, sadly, so many fall short.\\nUnited States GP practice results\\nUnited States GP coverage details'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Showing more original, high quality programming on Gaelic TV channel BBC Alba would benefit Gaelic education, it has been suggested.', 'negatives': [], 'positives': ['MG Alba, which operates in partnership with the BBC, has asked that a stronger BBC Alba should form part of the BBC\\'s next Royal Charter.\\nHighland Council officers have urged councillors to support this call.\\nThe officials said more Gaelic programmes would support \"significant growth\" in Gaelic medium education.\\nCouncillors on Highland Council\\'s Gaelic implementation group will be asked to back MG Alba\\'s position at a meeting on 12 November.\\nLaunched in September 2008, BBC Alba now reaches on average more than 700,000 viewers per week in Scotland.\\nLast month, MG Alba said 73% of what was shown was repeats and on current funding only 1.7 hours of original output, including news, was possible per day.\\nIt said this figure was \"significantly short\" of an ambition of three hours per day.\\nThe organisation has called for a \"stronger BBC Alba\" and for the BBC to produce 10 hours of original programming per week for the channel for the next 10 years of the charter, in comparison to the current 4.4 hours currently developed.\\nIts youth programming has included involvement in the making of a television adaption of Mairi Hedderwick\\'s Katie Morag books.\\nThe Royal Charter sets out the public purposes of the BBC, guarantees its independence and outlines the duties of the BBC Trust.\\nThe current charter runs until 31 December 2016.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Previously unseen sketches of one of the UK's best-known comic book characters are to be published for the first time.\", 'negatives': [], 'positives': [\"Judge Dredd was created by Greenock-raised writer John Wagner and Spanish artist Carlos Ezquerra.\\nThe comic strips have been adapted for two movies, one starring Sylvester Stallone as the futuristic lawman.\\nThe first definitive collection of all the Dredd stories, which began in 1977, will be released in January.\\nThe Mega Collection will include previously unpublished sketches and designs, including artwork of Dredd as a zombie by British artist and designer Brendan McCarthy.\\nIllustrations by Cliff Robinson and Dylan Teague will also be among the previously unseen art.\\nLondon-based British comic 2000AD, which has carried many of the Dredd stories, and publisher Hachette Partworks will release the collection as a fortnightly 80-issue series.\\nSet in the 22nd Century, Dredd and his fellow enforcers act as judge, jury and executioner in Mega-City One - a sprawling North American metropolis of 400 million inhabitants.\\nIts co-creator Wagner moved from the US to Scotland when he was 12 and went on to work for Dundee publisher DC Thomson.\\nLater, during a spell as a freelance, he worked with Pat Mills, who went on to become a legendary Dredd writer, from a shed at Mills' home in Fife.\\nAmong the artists to work on the comic strips have been Fort William-born Colin MacNeil and Cam Kennedy, who lives on Orkney.\\nKennedy's other work included illustrating a story for Marvel which sees S.H.I.E.L.D boss Nick Fury come to Scotland to fight terrorists who had a base at the top of Orkney's Old Man of Hoy.\\nLast year, Scottish writer Emma Beeby became the first woman to write a Judge Dredd comic book story in the character's almost 40-year history.\\nThe Dredd comics have been the inspiration for two movies.\\nReleased in 1995, the film Judge Dredd had Stallone in lead role.\\nThe script for 2012's Dredd was written by Wagner, Ezquerra and Alex Garland. It starred Lord of the Rings actor Karl Urban as Dredd and Game of Thrones' Lena Headey as the main villain.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The UK\\'s domestic TV channels all \"met or exceeded\" their 2014 targets for providing subtitles, signing and audio description on programmes, according to a report by watchdog Ofcom.', 'negatives': [], 'positives': ['The targets, for what are known as \"access services\", were set by the 2003 Communications Act.\\nThe BBC must subtitle 100% of its programmes, audio describe 10% and provide sign language on 5%.\\nChannel 4 and ITV, STV and UTV must all subtitle at least 90% of broadcasts.\\n\"To help people with hearing or visual impairments enjoy a choice of TV programmes, a number of broadcasters are required to provide subtitling, signing and audio description services,\" said Ofcom on publishing 2014\\'s Television Access Services report.\\n\"Of the 72 UK channels required to provide these services, all met or exceeded their targets for 2014.\"\\nLast year, the broadcasting watchdog began a regular audit of the quality of subtitles, following complaints by viewers about inaccuracies and subtitles which were delayed or had frozen or disappeared.\\nOne report said poor subtitling on live programmes could often make viewing \"frustrating\" or even \"unwatchable\".\\nIt cited mistakes such as Star Wars character Princess Leia being called \"Present Cesc lay ya\", lemon transcribed as \"lepl on\" and the phrase \"be given to our toddlers\" translated as \"be given to ayatollahs\".\\nAnother report published in June 2014 said subtitles were often too slow and lagged far behind speech on live programmes.\\nOfcom found the average delay between speech being heard and the corresponding subtitles appearing on screen is 5.6 seconds - almost double the recommended maximum of three seconds.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': '\"Does it really matter which university you study at?\"', 'negatives': [], 'positives': ['This is the question that\\'s been chosen by the BBC News audience - and it is a very immediate concern for hundreds of thousands of families wrestling with university application forms.\\nOf course, on the idealistic side of things, what really matters is that someone is following a course that they really like and in a place that suits their needs.\\nBut there are thornier worries about the cost of university and how much degrees are worth after graduation.\\nThe evidence suggests that going to university remains a good investment. Organisations such as the Organisation for Economic Co-operation and Development (OECD) have tracked whether the rising number of students will erode the benefits in the jobs market.\\nSo far it seems that the graduates have kept their advantage. A changing jobs market has generated more opportunities for graduates and people who went to university are likely to be earning more and are less likely to be unemployed.\\nWe asked readers to send in their questions about university education.\\nThe favourite which you selected was this question from Kirsty: \"Does it really matter which university you study at?\"\\nKirsty has three daughters, one currently at university, another planning to go and a third looking to university in the future, so as she says \"It\\'s a question we\\'re currently trying to answer.\\n\"Some universities are going to charge higher fees, does this mean we can compare by price? But then will a degree in mathematics from a more expensive university be different in any way? Will future opportunities really depend on the university we choose?\\n\"It seems the more we\\'ve tried to answer this question the more questions arise.\"\\nTake a look at some of the other questions you\\'ve wanted us to answer\\nWomen in particular are likely to benefit economically from being graduates, with a big advantage in earnings compared with women without degrees.\\nBut the next question is whether all universities will deliver similar rewards.\\nThere are all kinds of social rewards and intellectual pleasures of university life, which cannot be chopped up and counted.\\nBut the financial rewards can be measured and they vary significantly between different universities.\\nThe Institute for Fiscal Studies, Cambridge University, Harvard University and the Institute of Education, UCL published research on graduate earnings in England earlier this year.\\nIt analysed the incomes of 260,000 graduates and showed a very wide spectrum of likely earnings. At the top was a cluster of universities, headed by the London School of Economics, Oxford and Cambridge.\\nIn these three institutions, 10% of their male graduates had earnings above Â£100,000 a decade after leaving university. The LSE was the only place where 10% of female graduates were also in this top earning bracket.\\nThere is an earnings pecking order - with about another 30 or so universities, not identified by name, where 10% of graduates are earning above Â£60,000.\\nAnd at the bottom, there are some more awkward figures. There are 23 universities where male graduates are likely to end up earning less than non-graduates - and there are nine universities where that is also the case for women.\\nBut there is another important factor cutting across this - the differences between subjects.\\nStudents taking courses such as medicine, economics, law and maths are likely to be earning much more than the average graduate.\\nAnd artists are really going to be struggling in their garrets, as graduates from creative arts courses are likely to be earning less than the average non-graduate.\\nThe combination of these two factors is going to decide the likely financial benefits - the university and choice of subject.\\nBut researchers highlight some other questions muddying the waters.\\nStudents do not enter university unshaped by what went before.\\nHow much of higher earnings in later life might be linked to coming from high-income parents, rather than anything to do with higher education?\\nA key finding of the income research was that graduates from wealthy families ended up earning more than than those from poorer families, even if they studied the same course at the same university.\\nBut there is no escaping the growing sense of stratification in the university sector and differences in status.\\nBelonging to the Russell Group has become a kind of self-conferred status symbol for its membership.\\nAlthough this might sound venerable, it has only existed since the mid-1990s and began life as a group of heads of universities with medical schools, who met at London\\'s Russell Hotel.\\nBut it has sharpened a sense of difference.\\nUniversity rankings have also become very influential, further encouraging the idea of a hierarchy of quality.\\nEven if academics are sceptical about the reliability of such rankings, they will be scrutinised by students applying to university and it becomes almost self-fulfilling.\\nThe appetite for such rankings also reflects the growing numbers of students going to university - and the need to distinguish between different types of degree.\\nYoung people are now more likely to get a degree than they were to get five good O-levels in the early 1980s.\\nAnd where once it would have been a success to get into any university, it is now increasingly a question of which university.\\nBut if this sounds like a growing polarisation, with top earnings and status clustering around a few elite institutions, there is something of a backlash from employers.\\nA succession of big graduate employers have moved towards hiring students in a way that masks which university and school they attended.\\nThis might be presented as advancing the cause of social mobility - but it is also about the self-interest of companies.\\nSpeaking privately, employers will say if they\\'re fighting for business in diverse, inner-city communities, they do not want to send in a line-up of Oxbridge clones.\\nBut for teenagers struggling with application forms for university, how are they meant to choose between similar sounding institutions?\\nThey might say that all degrees are equal, but some are more equal than others.\\nJoin the conversation - find us on Facebook'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A police officer was involved in a hoax 999 call claiming a colleague would be kidnapped by a radical Muslim with links to so-called Islamic State, a court has heard.', 'negatives': [], 'positives': ['PC Amar Tasaddiq Hussain, 29, is one of three men accused of conspiring to make a bogus call to West Midlands Police.\\nHe denies two counts of conspiracy to pervert the course of justice.\\nAdil Bashir, 26,  and Muhammad Ali Sheikh, 31, have also denied the charges at Stafford Crown Court.\\nOpening the trial, prosecutor Simon Davis said West Midlands Police put \"unprecedented measures\" in place following the call on 8 December 2014.\\nAll police staff were forced to report they had got home safely, which Mr Davis likened to a roll call at a school.\\nHe told the jury: \"The police listened to that call. They took it extremely seriously.\"\\n\"They saw the content of the call as a credible threat to the security and safety of a police officer who may be kidnapped that evening - they had six hours to put procedures in place to minimise the threat and maximise the security and safety of all police staff,\" he added.\\nThe court was played the call in which a man can be heard saying: \"I have been asked to drive the car which they are going to kidnap the police officer in and put him in the back, I have been told to drive off because I am a very good driver.\"\\nThe caller refuses to give his personal details to the call handler when asked for fear he will \"possibly be killed\".\\nThe prosecution claim Mr Hussain, from Yardley, plotted with Mr Bashir of Small Heath and Mr Sheikh from Bordesley Green, to incriminate members of Dawat-E-Islami, a peaceful Muslim prayer group, who he held a grudge against.\\nThe trial continues.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'It was the Cardiff community devastated by a series of hit-and-run incidents, its residents targeted by a rampaging van driver during the school run.', 'negatives': [], 'positives': ['But Ely vicar, the Rev Jan Gould, said October\\'s tragedy, which saw Karina Menzies killed and 17 people injured, had brought residents closer together.\\nMatthew Tvrdon, 32, who has paranoid schizophrenia, admitted manslaughter on the grounds of diminished responsibility.\\nHe also admitted seven counts of attempted murder and other charges including three counts of grievous bodily harm with intent and was sentenced indefinitely under the Mental Health Act at Cardiff Crown Court\\nThe court heard that in a spree that lasted 30 minutes, he knocked people over like \"skittles\" as he targeted adults and children at five separate locations in the west of Cardiff as people walked children home from school at 15:30 on 19 October 2012.\\nFour groups were run over in Ely, including local mother-of-three Ms Menzies, 31, who was hit as she walked with two of her daughters by Ely fire station.\\nTvrdon then drove to the nearby Leckwith retail park, where he attacked three people with a steering wheel lock and then ran over a mother and her 27-year-old daughter.\\nEventually, after an eight-mile \"journey of mayhem\", he was stopped by police on the outskirts of Penarth, his van splattered with blood.\\nMs Gould, vicar of the Church of the Resurrection in Ely, said that the \"surreal\" afternoon of chaos would forever be part of the community\\'s history.\\nBut she said it had also brought out the best in local people.\\n\"Everybody knows, I think from the media coverage, that Ely is a close community and it\\'s become so much closer really over these last few months,\" she said.\\n\"People have been really looking out for one another, supporting on another, and it\\'s really brought the generosity of the community to the fore.\\n\"They have done all they can to try to support Karina\\'s children but also the other victims as well.\"\\nA trust fund which was set up to support Ms Menzies\\'s three daughters has so far raised Â£25,000, while a separate fund for the other victims had Â£9,000.\\n\"It\\'s not going to go far but I guess it\\'s a gesture of good will so all those victims know that people have been thinking about them,\" Rev Gould added.\\nThe vicar said that Ely was now hoping for closure after the court case.\\n\"Probably at the moment it\\'s dredging everything up and making things very raw for people but hopefully once this court case is over and everything\\'s settled, it will bring some closure for the families and they can just begin to get their lives back on track,\" she said.\\n\"I was talking to one of the parents not long ago who was run over and she said \\'I just need this to be finished now\\'.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The popularity of Pokemon Go has failed to stop Nintendo from issuing a profit warning, which it blamed on poor Wii U sales and a strong yen.', 'negatives': [], 'positives': ['The Japanese video game maker said full-year operating profit would be about a third lower than expected at 30bn yen ($288m; Â£236m).\\nSales fell 33% to 136.8bn yen ($1.3bn) for the six months to September.\\nHowever, net profit more than trebled after Nintendo sold a controlling stake in a US baseball team.\\nThe company had owned the Seattle Mariners since the early 1990s.\\nThe global success of the Pokemon Go app released earlier this year has not helped Nintendo\\'s bottom line as it was developed and distributed by US-based Niantic, a spinoff of Google.\\nNintendo owns a stake in Niantic and a one-third share of the Pokemon Company, which receives licensing fees for the brand.\\nLast week, Nintendo said its next games device would be a handheld, portable device that doubles up as a home console.\\nThe Nintendo Switch, which looks like a tablet computer with controllers attached to its sides, is expected to go on sale in March.\\nReviews have been mixed, with some describing the new device as disappointing.\\nThe Switch could be Nintendo\\'s \"last shot\" at selling a home console, said Paul Jackson, of the Ovum consultancy.\\n\"The Wii U was a car crash, basically. They fudged the communication and confused everybody with the controller and what the screen was for. As a result it sold about a tenth of what the original Wii sold.\"\\nThe Wii U was heavily outsold by Sony\\'s PS4 and Microsoft\\'s Xbox One, although Nintendo has enjoyed success with its handheld 3DS device.\\nNintendo reported a 5.95bn yen operating loss for the half year, a sharp reversal from a 9bn yen operating profit for the same period in 2015.\\nJapanese exporters have been hit hard by a strengthening yen in recent months, which has cut their profits.\\nShares in Nintendo have fallen 8% in the past month, but are up 46% since the start of the year.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Ryanair says it could cut fares by as much as 9% on some routes as competition in the airline industry intensifies in the next few months.', 'negatives': [], 'positives': ['The warning from Europe\\'s largest carrier by passenger numbers follows similar comments about price pressures from Ryanair\\'s rivals in recent weeks.\\nCompetition was growing as airlines switched capacity from Turkey and North Africa, Ryanair said.\\nSeparately, Ryanair said it had made a \"non-binding offer\" for Alitalia.\\nOn Friday, Italian media reported that about 10 offers had been made for the loss-making airline.\\nIn a statement, Dublin-based Ryanair said it was \"important we are involved in the process\" given that Alitalia is Italy\\'s largest carrier.\\nRyanair\\'s comments came as it reported a 55% rise in pre-tax profits to 397m euros (Â£356m) in the three months to 30 June. Revenues were up 13% to 1.68bn euros.\\nThe average fare during the quarter rose 1% to 40.3 euros, although Ryanair said this was a blip due to the much stronger Easter trading. Easter, a peak-time for holidaymakers, fell in April this year, inside the carrier\\'s reporting period. In 2016, it fell in March.\\nThe airline said it expected fares to fall by 5% in the six months to the end of September and by 8% in the six months to the end of March 2018.\\n\"We expect the pricing environment to remain very competitive\" chief executive Michael O\\'Leary said in a statement. EasyJet and Wizz Air have both said that fares will be under pressure this summer.\\nThe warning sparked a 3.5% fall in Ryanair\\'s share price. EasyJet shares fell 3.4%, while the owner of British Airways, IAG, fell 2.7%.\\nIn a bid to recoup some lost revenues, Ryanair is considering limiting the number of passengers eligible to take a second free carry-on bag. Revenues from people paying to take luggage have fallen at the airline.\\nMr O\\'Leary told analysts that it was possible that only passengers who paid for priority boarding would be eligible. However, he added that no decision had been made.\\nRyanair executives also repeated warnings of major flight disruptions between the UK and Europe if Brexit talks fail to agree a bi-lateral deal on flights. The airline has warned it may cancel flights and move operations abroad if there is no agreement well in advance of Brexit.\\n\"We need clarity so that we can plan our schedules for 2019,\" chief financial officer Neil Sorahan told the BBC.\\nEasyJet announced last week that it had secured an air operator\\'s certificate in Austria to enable it to keep flying across the EU following Brexit.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Defender Chris Gunter says Wales are more than capable of winning against the odds in Serbia.', 'negatives': [], 'positives': ['Chris Coleman\\'s side are four points behind both group leaders Serbia and second-placed Republic of Ireland with five World Cup qualifiers remaining.\\nWales will be without Real Madrid forward Gareth Bale for Sunday\\'s game in Belgrade due to suspension.\\n\"We have shown in the past in big games we can go and win matches people think we probably can\\'t,\" Gunter said.\\n\"We are in a situation where we have to go to Serbia and perform and pick something up.\\n\"If we go and play as we have done over the course of the last two to three years, we give ourselves a really good chance.\"\\nWales began their campaign with victory over Moldova but are third in Group D after drawing against Austria, Georgia, Serbia and the Republic of Ireland.\\n\"It\\'s been a strange group in terms of we haven\\'t done a lot wrong but we probably feel we could have a couple more points,\" Gunter told BBC Wales Sport.\\n\"At the start of a group you know to qualify you need to put a run of wins together and we haven\\'t done that in the first-half but it doesn\\'t mean you can\\'t in the second half of the group.\\n\"We come away from Serbia with something and we are right in the group with the games we have left to play.\"\\nNewport-born Gunter, who made his senior international debut against New Zealand in May 2007, is set to win his 79th cap in Serbia.\\nDefender James Collins and midfielder Andy King are out injured while Real Madrid\\'s Bale and defender Neil Taylor of Aston Villa miss the game through suspension.\\nBale, 27, will miss his first competitive Wales since October 2013 but Gunter believes they can cope without their talisman.\\n\"You always want your best eleven out but we have shown in the past we have been able to manage,\" Gunter said.\\n\"We have some really good players ready to come whatever way the manager wants to go.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The percentage of dogs microchipped in Wales has risen from 69% to 94% since it became compulsory last April, Dogs Trust has said.', 'negatives': [], 'positives': ['All dogs are now legally required to have been chipped by the time they are eight weeks old.\\nThe charity said the improvement showed it was working but still meant 30,000 dogs would be untraceable if lost.\\nIt added 8% of the 3,222 unclaimed strays in Wales\\' council kennels last year did not have up-to-date chips.\\nIn 2015-16, before the law changed, 3,193 lost dogs were reunited with their owners in Wales - 15% of which were identified as a direct result of being chipped.\\nBut its head of campaigns, Andrew Jackson, said the charity had noticed a \"growing number\" of breeders not microchipping puppies at eight weeks, or not registering their details.\\nHe said this could cause problems for unsuspecting buyers who may not realise they should already have a chip registered to the breeder to ensure traceability.\\nThe charity said 2,751 fines had been issued to UK dog owners for non-compliance since the law came in on 6 April 2016.\\nMost - 1,464 - were for dogs without chips, while 1,287 were issued to owners who had failed to update their details.\\nMr Jackson said: \"It is excellent to see that so many owners have taken action to get their dogs chipped - a painless process for dogs which many charities will carry out for free.\\n\"However, still too many are not being reunited where owners have not updated their details when they move home or get a new phone number - heartbreaking for the owner and easily avoidable with a five-minute phone call.\\n\"All dog owners have a responsibility to microchip their dog and it\\'s very encouraging to see such a strong take-up - now owners must make sure this effort does not go to waste and check their dog\\'s chip is up to date.\"\\nIn February, a petition, backed by RSPCA Cymru, was launched calling for all councils to scan microchips of all pets found dead or alive.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Fake designer goods worth £8m have been seized in raids in Greater Manchester.', 'negatives': [], 'positives': ['Officers found the items, including sunglasses, jewellery, clothes, and perfume, after raiding homes, businesses and storage units in the Strangeways area of Manchester.\\nMore than £270,000 in cash was also recovered, police said.\\nA man, 44, and a woman, 35, were arrested on suspicion of conspiracy to defraud, money laundering and counterfeit and trademark offences.\\nBoth have been released pending further investigation.\\nDet Insp Paul Walker said \"intelligence from our partners\", which included Trading Standards, Visas and Immigration and the designer brands, led to the haul.\\nManchester has been identified by trading standards as a hotspot for the trade in fake goods.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Airline Flybe is to operate new routes flying from Cardiff Airport, creating 50 new jobs.', 'negatives': [], 'positives': ['The new network includes flights between Cardiff and Cork, Dublin, Edinburgh, Faro, Glasgow, Munich, Milan and Paris.\\nThe airport was bought by the Welsh government for Â£52m in 2013.\\nFlybe dropped flights from Cardiff to Glasgow and Paris in 2013 as part of restructuring of the company.\\nFirst Minister Carwyn Jones said: \"Flybe\\'s announcement that it is opening a new base operating 11 routes from Cardiff Airport is fantastic news.\\n\"We\\'ve already invested in improving the overall customer experience at Cardiff Airport and the new routes to major European destinations, as well as the creation of 50 new jobs, demonstrates Flybe\\'s commitment to the airport and will help to make it the success we know it can be.\"\\nThe jobs will include flight crew and ground handling staff.\\nThe Paris flights start in June with four weekly flights but services will operate daily at their height.\\nThe Dublin flights also start in June with six a week rising to 12.\\nThe expansion by Flybe doesn\\'t fully fulfil the Welsh Government\\'s vision of Cardiff becoming a long haul hub - in the much-quoted Schipol model - the Netherlands airport that has become an international flights crossroad.\\nBut it is one step towards that in that it makes Cardiff more important on the air passenger route map and it makes Wales more accessible to foreign tourists\\nBut Cardiff has a long way to go before it is seen as either a major regional  hub  for long haul flights or a serious competitor to Bristol.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Millions of euro are being made available to develop conservation plans for important habitats that support butterflies and wading birds.', 'negatives': [], 'positives': [\"Eight projects will benefit from the 4.6m euros (Â£4m) provided from European Union (EU) funds.\\nRSPB Northern Ireland will co-ordinate the work in NI, the border area of the Irish Republic and Scotland.\\nThe projects aim to protect species like the hen harrier, golden plover and curlew.\\nThe work includes plans to conserve areas of blanket bog on Antrim's Garron Plateau.\\nThere will also be a project to advise landowners at Montiagh's Moss near Lough Neagh at Aghalee on how to manage land for the threatened marsh fritillary butterfly.\\nAnd there will be rush-cutting in lowland meadows to provide nest sites for waders.\\nThe work will conserve rich habitats like blanket bog and fen wetland in areas like the Antrim Hills, the Pettigo area of County Donegal and the Muirkirk uplands of Scotland.\\nThe money is coming from the EU's Interreg VA programme, and is being match funded by the Department of Agriculture, Environment and Rural Affairs, the Republic of Ireland's Department of Community, RSPB Scotland and Mines Restoration Ltd.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Swindon Town boss Luke Williams says an EFL Cup first-round visit to Queens Park Rangers can give his squad belief.', 'negatives': [], 'positives': ['Championship side QPR will host League One Swindon at Loftus Road in August.\\nThe Robins won 2-0 at QPR in round two in 2013-14, starting a run of seven wins in 11 games, and Williams knows a similar result could lift his squad.\\n\"A game like that can turn your fortunes for you and give people that extra bit of belief and confidence,\" Williams told BBC Wiltshire.\\n\"It is a good situation to be in. You\\'re not really expected to win, but you can certainly give everything.\\n\"It\\'s a freebie, if you like. If we did (win), people would consider it a big achievement. We can certainly look forward to that one.\"\\nSwindon, winners of the League Cup in 1969, lost 2-1 at home to Exeter in the first round last season.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Judd Trump faces a fine from snooker bosses for refusing to fulfil his post-match media duties following his shock World Championship loss to Rory McLeod.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nThe pre-tournament favourite was beaten 10-8 in the first round, with his agent saying Trump was unable to talk to the media because he was feeling unwell.\\nHis failure to appear is a breach of his contract with World Snooker.\\nThe world number two, 27, faces a fine from the World Professional Billiards and Snooker Association (WPBSA).\\nWorld number 54 McLeod, who plays Scotland\\'s Stephen Maguire in the second round, described his win as the \"best of his career\".\\nThe 1000-1 outsider, 46, said: \"To beat Judd Trump on centre stage is brilliant. I have always known I am capable of it; it is actually producing when you need to and I have done it.\"\\nMcLeod said he was not interested in whether Trump was unwell or injured, with the world number two seemingly grimacing in pain with a shoulder or arm problem during the course of the match.\\n\"He was 4-0 up and he didn\\'t look that injured, so what can I do?\" said McLeod.\\n\"I had to deal with holding myself together. I am the oldest player left in the tournament. At 46 you have your aches and pains.\\n\"Age is just a number; it\\'s how you look after yourself and I think I am doing OK.\"\\nSign up to My Sport to follow snooker news and reports on the BBC app.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Labour leader Jeremy Corbyn said on BBC Radio 4 on Tuesday morning that he would be interested in a cap on earnings, because \"we cannot go on creating worse levels of inequality\".', 'negatives': [], 'positives': [\"The claim: Levels of inequality in the UK have been getting worse.\\nReality Check verdict: Official figures suggest that income distribution has become less unequal over the past decade.\\nCoincidentally, Tuesday morning also saw the release of the annual report on income inequality from the Office for National Statistics.\\nIt said that there had been a gradual decline in income inequality over the past decade.\\nIt is using the Gini Coefficient, which is a measure of inequality - in this case, a coefficient of zero would mean that all households had the same income while 100 would mean that one household had all the income.\\nThese figures are for disposable income, which is what you get after you've added benefits and subtracted direct taxes such as income tax and council tax.\\nThere are caveats around these figures - they are based on surveys, so there is a margin of error, and it is particularly difficult to get survey responses from people at the top of the income distribution.\\nBut the official figures suggest that there was a considerable increase in inequality in the 1980s, relatively little change from the early 1990s to mid-2000s and then a gradual decline in the past decade, returning the UK to the same level of inequality as was seen in the mid-1980s.\\nSo from these figures it would be wrong to conclude that inequality has been getting worse.\\nWhat could be missing from this analysis? The ONS looks at inequality across the whole population - there has also been much interest in comparing the richest 1% or 0.1% with the rest of the population.\\nThe World Top Incomes Database (which you can see in figure 3 of this blog) suggests that since 1990 there has been relatively little change in the share of income taken by the richest 20% or 10% of the population.\\nThe richest 1% and the richest 0.1% had seen their share of income rising steadily until the financial crisis, but it has fallen since then. So once again, inequality has not been growing.\\nThe measures identified so far have been looking at income rather than wealth.\\nIt is also possible to calculate Gini coefficients for wealth, although the latest official figures for it covered only up to the middle of 2014.\\nFrom 2006 to 2014, there was a small increase in overall wealth inequality, with property wealth having the biggest effect.\\nHousing costs are a particular issue - the Department for Work and Pensions calculates a Gini coefficient for income distribution that takes housing costs into account.\\nThe difference it makes is that inequality increases in 2013-14, although it is still below pre-financial crisis levels.\\nNone of this suggests that inequality does not exist in the UK or that it is not a problem or indeed that it is not worse than in other countries, but there is little evidence that it has been getting worse in the UK in the past decade.\\nRead more from Reality Check\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Hundreds of people have commemorated the 25th anniversary of the murder of five people by loyalist paramilitaries at a betting shop in Belfast.', 'negatives': [], 'positives': ['Five Catholics, including a 15-year-old boy, were killed in the attack on the Ormeau Road in 1992.\\nIt was carried out by the Ulster Freedom Fighters (UFF). No-one has been convicted in relation to the killings.\\nFamilies said that the Police Ombudsman is due to publish a report into the murders at Easter.\\nTommy Duffin, whose father Jack was one of those killed, said the report is the \"only way we have to go\" in terms of justice.\\n\"We\\'ll have to take into account what it says and where it leaves us as families, and then decide where we move from there.\\n\"We\\'re waiting with baited breath to a certain extent, to know exactly what it\\'s going to say and what it\\'s going to reveal to us.\"\\nThe families have previously said they believe there was collusion between the killers and security forces.\\nIn 2015, the PSNI\\'s chief constable apologised after it was discovered that the weapon used in the killings was on display in the Imperial War Museum in London.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The Parades Commission is preparing to receive a notification from Orange Lodges in north Belfast for permission to finish a parade stopped since 2013.', 'negatives': [], 'positives': ['The Twaddell Avenue protest has been ongoing since July 2013.\\nBut an agreement has now been reached between Ligoniel Orange Lodge and the Crumlin and Ardoyne Residents Association.\\nIt means that three lodges and two bands playing hymns will pass the Ardoyne shops next Saturday 1 October.\\nLater that day, the loyalist protest camp at Twaddell Avenue will be dismantled.\\nThe dispute - which has cost an estimated Â£20m to police during the past three years - began after a Parades Commission determination not to allow the return leg to pass a section of the Crumlin Road in 2013.\\nHowever on Friday, talks facilitators the Rev Harold Good and Jim Roddy released a statement saying a resolution had been found.\\nPoliticians and police have reacted warmly to news of the breakthrough.\\nFirst Minister Arlene Foster called it \"a significant step\".  Deputy First Minister Martin McGuinness commended the two facilitators.\\nHowever, another nationalist residents group, the Greater Ardoyne Residents Collective (Garc), has made it clear that it is opposed to the deal.\\nThe group\\'s Dee Fennell said: \"In our opinion, this goes against the wishes of the vast majority of people living in Ardoyne, Mountainview and the Dales.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A vigil has been held in memory of two police officers who were shot dead in Greater Manchester.', 'negatives': [], 'positives': ['PC Fiona Bone and PC Nicola Hughes died from gunshot wounds in an attack in Mottram last Tuesday.\\nResidents joined about 40 officers in a walk from Hyde police station to the scene of the killings ahead of the vigil, which started at 10:45 BST.\\nFunerals for PCs Bone and Hughes will take place at Manchester Cathedral next Wednesday and Thursday.\\nDale Cregan, 29, has been charged with the officers\\' murders, along with those of two other men.\\nAbout 400 people attended the service, despite the pouring rain, which featured addresses from Greater Manchester Police Chief Constable Sir Peter Fahy and the Reverend James Halstead.\\nThere was a minute\\'s silence at 10:58 BST.\\nBy Michelle  AdamsonBBC Radio Manchester\\nThey walked in silence, through the rain, to remember two fallen colleagues.\\nExactly a week on, up to 40 police officers from Hyde police station where PCs Fiona Bone and Nicola Hughes were based, marched the three miles to Mottram to pay their respects at a vigil.\\nOn the way, dozens more officers joined them until they arrived on Ashworth Lane, close to where the two women were shot dead.\\nThe mood was sombre and reflective. Some held candles, others clutched bouquets of flowers or single red roses during a minute\\'s silence.\\nAs half a dozen white balloons were released, police officers hugged each other.\\nAfter the \"darkest day in the history of Greater Manchester Police\" this was a moment for the communities of Mottram and Hattersley and the officers who serve them, to stand side by side and reflect.\\nPhotographs of the two officers were on display above floral tributes at the junction of Ashworth Lane and Abbey Gardens, where the vigil took place.\\nSir Peter said it was a chance to \"pray for the dead officers and their families\".\\nHe said: \"I think what you have seen over the past week is Greater Manchester Police is one big family and we have lost two members of our family and we feel that loss very deeply.\\n\"I know the families of Fiona and Nicola have been hugely moved and uplifted by the great public support from around the country, around the world, but particularly from the people of Hattersley and Mottram.\"\\nHe added: \"I would like to say a huge thank-you to you all for being here.\\n\"We treasure the memory of Fiona and Nicola, their great service, which symbolises the great service by so many police officers and police staff, day in day out, doing their best to try and serve the public.\"\\nCh Supt Nick Adderley, who also spoke at the gathering, said the numbers of people present \"symbolised the popularity of what Nicola and Fiona stood for\".\\nMr Halstead led a prayer for families \"in shock and grief from the turmoil over the events of the last few days\" and friends and colleagues of the officers.\\nCommunity volunteer Elsie Dixon also spoke at the service about how the deaths had hurt the community.\\n\"Our police officers are part of our community and those girls were special.\\n\"Our hearts are overflowing with tears. As many raindrops as you see, as many petals as you see on the flowers.\"\\nShe added: \"Those tears are within each of our hearts.\"\\nPC Jo Wainhouse, who organised the three-mile march from Hyde police station to Mottram and the vigil, said: \"We felt that Nicola and Fiona left here, went to Mottram and never came back.\\n\"So we felt that we\\'d like to walk so that after the vigil we can pay our respects and then walk back and feel that they are walking back with us in spirit.\"\\nThe leader of Tameside Council Kieran Quinn and MP for Stalybridge and Hyde Jonathan Reynolds, who lives in the area, also took part in the vigil.\\nMr Reynolds said local people \"wanted to show their support for the police and how they feel about the tragedy\".\\nFunerals for the dead officers will take place at Manchester Cathedral on Wednesday 3 and Thursday 4 October.\\nPC Hughes\\'s service will be held at 13:00 BST on Wednesday, with PC Bone\\'s being held on the following day at 10:00 BST.\\nA spokesman for Greater Manchester Police Federation said GMP were \"engaged in discussions with the families as to precisely what the arrangements will be for each service\".\\nHe said that \"early indications\" suggested the force would be taking up offers of assistance by officers from around the country to cover shifts and allow GMP staff to attend the ceremonies.\\nHe added that the organisation was intending to sell Â£1 charity wristbands commemorating the two officers and would be donating any money raised to their families.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Dan Biggar missed a 40-metre penalty with the last kick of the game as Ospreys lost to a much-changed Leinster at Liberty Stadium.', 'negatives': [], 'positives': ['Ross Byrne\\'s 79th-minute drop goal had edged the visitors ahead after Ospreys led 18-17 from the 62nd-minute.\\nTries by Sam Davies and Justin Tipuric had helped give the home team a slender advantage.\\nSean Cronin and Dan Leavy crossed for Leinster, who took a huge step towards a home draw in the Pro12 play-offs.\\nThe win extends Leinster\\'s lead at the top of the table to seven points before second-placed Munster\\'s match with Glasgow on Saturday evening.\\nShowing eight changes in personnel from their European Champions Cup win over Wasps, Leinster were cool under pressure and responded brilliantly after a sluggish start.\\nOspreys\\' place in the top four will come under threat if Scarlets beat Treviso on Saturday, potentially cutting their cushion over fifth place to two points.\\nBiggar lined up to take the penalty after returning to the field following treatment for a cut head, and said on television he was dazed and could remember little of the final 10 minutes.\\nFor their part, Leinster could have paid a heavy price for opting to go for the corner instead of kick for goal from a penalty when the score was 17-11 in their favour.\\nBut replacement Byrne\\'s drop goal - and Biggar\\'s miss - meant their gamble was not ultimately punished.\\nOspreys made all the early running and were ahead within four minutes when Davies dived over wide on the right after Rhys Webb, Josh Matavesi and Olly Cracknell made good ground up the middle.\\nBiggar missed the conversion after earlier hitting a post with a long-range penalty attempt, but was on target to give the home side an 8-0 lead after nine minutes.\\nLeinster were possibly disrupted by their changes in personnel from the 32-17 European Champions\\' Cup win over Wasps, but struck back in style in the 23rd minute.\\nExploiting some uncertain defending in the wide channels, Zane Kirchner set Cronin free and the Ireland international hooker celebrated his first start since January with a swerve past Biggar to run-in from 30 metres.\\nFull-back Isa Necawa added the extras and a penalty before Bigger struck on the stroke of half time to restore Ospreys\\' lead.\\nCronin was in on the act again early in the second half,  bursting up to the Ospreys tryline to set up the attack from which half-time replacement Leavy twisted and rolled over for the second Leinster try.\\nOspreys hit back after Davies\\' spiralling touch finder set up a position from which Rhys Webb sniped to within inches of the line and Tipuric touched down.\\nDavies\\' conversion edged the Ospreys back ahead.\\nThere was no hint at that stage of the drama that was to follow in the dying minutes.\\nLeo Cullen, Leinster head coach: \"I did think he (Biggar) would put the kick over. But it looked like a bit of a tired kick and it had been a draining game and it looked like the game had taken its toll.\\n\"When he stepped up to it I thought there was a fair chance he was going to kick it.\"\\nSteve Tandy, Ospreys head coach: \"It\\'s a pretty devastated changing room in the fact that we\\'re coming off the wrong end of some scoreboards, but we\\'ve just got to dust ourselves off and get back on the horse.\\n\"We\\'ve got a big match now on Judgement Day (v Cardiff Blues) and the only crumb of comfort in it all is we\\'re still in control of getting into the top four, but it\\'s a bitterly disappointing result.\"\\nOspreys: 15 April: Cardiff Blues (Principality Stadium); 29 April: Ulster (H), 6 May: Scarlets (A).\\nLeinster:  15 April: Connacht (A), 28 April: Glasgow (H), 6 May: Ulster (A)\\nOspreys: Sam Davies; Keelan Giles, Kieron Fonotia, Josh Matavesi, Dan Evans; Dan Biggar, Rhys Webb (capt); Nicky Smith, Scott Baldwin, Brian Mujati, Lloyd Ashley, Rory Thornton, Olly Cracknell, Justin Tipuric, Dan Baker.\\nReplacements: Scott Otten, Paul James, Ma\\'afu Fia, Bradley Davies, Tyler Ardron, Sam Underhill, Tom Habberfield, Jonathan Spratt.\\nLeinster: Isa Nacewa (capt); Rory O\\'Loughlin, Zane Kirchner, Robbie Henshaw, Fergus McFadden; Joey Carbery, Jamison Gibson-Park; Jack McGrath, Sean Cronin, Tadhg Furlong, Devin Toner, Mick Kearney, Rhys Ruddock, Josh van der Flier, Jack Conan.\\nReplacements: James Tracy, Peter Dooley, Mike Ross, Ian Nagle, Dan Leavy, Nick McCarthy, Ross Byrne, Dave Kearney.\\nReferee: John Lacey (IRFU)\\nAssistant referees: David Wilkinson (IRFU), Rob Price (WRU)\\nTMO: Neil Paterson (SRU).'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A seemingly unconscious disabled man was found drunk in a mobility scooter by a police community support officer, a court has heard.', 'negatives': [], 'positives': ['Yusef Khalifa, 52, of Old Colwyn, Gwynedd, said he had drunk two bottles of wine, Llandudno magistrates heard.\\nHe admitted being in charge of a \"mechanically-propelled vehicle\" when three times the drink-drive limit and having a folding knife.\\nHe was banned from driving a vehicle for six months.\\nA six-month community order was also imposed, along with a fine and costs totalling Â£385.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Animal welfare officers who were called out to reports of a donkey tied to a garden fence discovered a life-size plastic ornament.', 'negatives': [], 'positives': ['The Scottish SPCA was contacted about concerns that the animal was being kept in the back garden of a house in Airdrie with no shelter.\\nHowever, it turned out to be made of fibreglass and goes by the name Joshua.\\nJoshua\\'s owner, the Reverend Georgie Baxendale, said: \"This is the funniest thing I\\'ve ever heard in my life.\"\\nHe added: \"I used to have two donkeys and bought Joshua as a reminder. He\\'s very eye-catching and has appeared in many nativity plays over the years.\"\\nThe Scottish SPCA said they were unsure whether the report was made as a prank or by a \"well-meaning but short-sighted\" passer-by.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Colombia\\'s constitutional court has banned mining in the country\\'s moorlands, also known as \"paramos\".', 'negatives': [], 'positives': ['It argued that mining for gold and oil in the fragile ecosystem could cause irreversible damage.\\nThe court overturned a previous ruling that allowed mining companies which already held licenses to continue operating in the moorlands until their licenses ran out.\\nOfficials said the court\\'s decision would void about 350 mining licenses.\\nThe \"paramos\" are mainly found between an altitude of 3,000m (9,850ft) and 5,000m.\\nCovered by grass and shrubs, they act like vast sponges, storing water in the rainy season and releasing it in the dry season.\\nTheir conservation is considered key to guaranteeing the water supply for Colombian cities such as the capital, Bogota.\\nEnvironmental activists welcomed the ruling.\\nCongressman Alirio Uribe Munoz, who was among a group of politicians who brought the case before the constitutional court, said it meant \"life first, business later\".\\nThe court said that under no circumstance should mining or oil exploration be allowed in these areas.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Heavy rain overnight has been causing problems on roads around the country, with flooding and surface water leading to delays.', 'negatives': [], 'positives': ['A Met Office yellow \"be aware\" warning covered the Western Isles, Wester Ross, Sutherland, Argyll, Lochaber and parts of Tayside and central Scotland.\\nPlay at the Open golf championship at St Andrews has been suspended due to rain.\\nPolice Scotland urged rush hour drivers to \"slow down and take care.\"\\nAt The Open play was suspended before the first group had even managed to finish the first hole on the second day of the championship.\\nThe downpour saw a torrent of water gushing down Golf Place, the road leading to the R&A clubhouse, with the greens quickly flooding.\\nWarnings about problems caused by the heavy rain were issued for road users on the M9, M90 and A90.\\nThe A82 Inverness to Drumnadrochit road was partially blocked at Lochend by a mud-slip.\\nStanding water on A90 at Crammond Brig was causing delays for those heading into Edinburgh and in the south side of Glasgow, Haggs Road was closed between Pollokshaws Road and St Andrews Drive because of flooding.\\nForecasters said winds could gust to speeds of 50mph, while heavy rain has also been forecast for Saturday.\\nThe weather warning covers from 01:00 on Friday until 21:00 on Saturday, with Argyll and Lochaber due to see the heaviest rain.\\nThe Met Office said: \"A rather vigorous area of low pressure for the time of year, will bring a combination of strong winds and heavy rain to parts of Scotland.\\n\"The worst of this arrives in two separate episodes - a six to nine-hour period of heavy, thundery rain overnight into Friday, and then slightly less intense but more persistent rain setting in later Friday and lasting well through Saturday.\\n\"Total rainfall will typically be 25 to 50mm but with some areas, particularly over high ground, receiving more than 80mm over the two days.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"BT has topped the UK's list of the most complained about broadband providers for the first time.\", 'negatives': [], 'positives': ['The report, covering the last three months of 2013, was published by Ofcom.\\nThe communications watchdog ranks the five biggest internet providers based on the number of complaints it receives about them adjusted according to the number of customers.\\nIt marks the first time EE has not led the name-and-shame list in over a year.\\nVirgin Media had the lowest level of complaints, followed by Sky for the fourth quarter running. TalkTalk came third.\\nAccording to the figures, Ofcom received 32 complaints for every 100,000 BT fixed-broadband customers between October and December last year. They related to service faults and the way BT\\'s staff had initially attempted to handle the reported problems.\\nThe firm was also found to have generated the highest level of complaints about its subscription TV service: 31 per 100,000 customers. The category covers access to the facility and billing, but not the quality of its programmes.\\n\"BT is disappointed with the results in broadband and TV, despite the fact that we\\'ve improved from last quarter,\" responded Libby Barr, managing director of BT customer service.\\n\"BT is the fastest-growing business by far in the UK for both pay TV and broadband, and as we process more transactions we have unfortunately suffered more disruption than companies with static or declining customer bases.\"\\nIn response to this claim, Virgin Media noted that it had increased both the number of its broadband and pay-TV customers over 2013.\\nThe level of complaints about EE\\'s broadband reported by the regulator was nearly 60% lower than for the same period a year earlier. But the firm said it still had room to improve after Ofcom reported receiving 29 complaints for every 100,000 subscribers over 2013\\'s final quarter.\\n\"We are of course disappointed by these latest results and will take on board the findings of the Ofcom report. We have an ongoing programme to improve service performance,\" said a spokeswoman.\\nAndrew Ferguson, editor of the Thinkbroadband news site, told the BBC there was plenty to be positive about.\\n\"The general trend over time is that the average number of complaints is down, so broadband does seem to be a sector that is improving,\" he said.\\n\"It may be a factor that people have become better at understanding the problems you can have with it and also the various regulations that have come out of Ofcom.\\n\"For example, firms must now let customers walk away if they change prices.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Cardiff Blues player Owen Williams says he does not feel any bitterness or anger about his situation after suffering a significant spinal injury.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nThe 23-year-old Wales international was temporarily paralysed in June after being tackled during a 10-a-side tournament in Singapore.\\nWilliams now has some movement in both arms, but no feeling yet in his legs and torso, and says he cannot afford to have negative thoughts.\\n\"It\\'s just about the future,\" he said.\\n\"I try not to think about what\\'s gone on.\"\\nWilliams, capped four times by Wales, was injured in the first half of the Blues\\' 26-17 defeat by Asia Pacific Dragons in the third-place play-off of the World Club 10s.\\nHe was initially treated in Singapore before being transferred by air ambulance back to Wales and then onto the Welsh Spinal Injuries and Neurological Rehabilitation Unit in Cardiff in early July.\\nSpeaking publicly for the first time since suffering the injury, Williams said he was focused on the future rather than dwelling on the past.\\n\"I don\\'t want to go thinking about being angry with anyone. You\\'ve just got to crack on with it,\" Williams told Scrum V.\\n\"The past is the past now. I just want to look to a positive future. I\\'ve been tackled like that a hundred times before and… nothing.\\n\"It was just a stroke of bad luck really; a bit unlucky on the day.\"\\nWilliams has been spending time out of hospital and was a guest at Wales\\' autumn Test against New Zealand at the Millennium Stadium in November.\\nHe revealed he will be making his first visit to the Arms Park on Boxing for the Blues\\' Boxing Day Pro12 derby against Newport Gwent Dragons.\\nWatch the full interview with Owen Williams on Scrum V, Sunday, 21 December, 17:55 GMT on BBC Two Wales'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Tucked away in an upstairs corner of a pub in downtown Calgary, Alberta, a group of American ex-pats and interested Canadians gathered to watch Wednesday night's Republican US presidential debate.\", 'negatives': [], 'positives': ['Although they have their own nation\\'s politics to worry about - this western city is hosting a debate for the party leaders on Thursday, and Canadian\\'s general election just over a month away - they were irresistibly drawn to the spectacle of the US event.\\n\"I call American politics my Jersey Shore,\" says Mike Guadet, referencing the reality television show best known for its train wreck personalities.\\n\"How can you beat those characters? Donald Trump, Carly Fiorina - they\\'re interesting, and they say ridiculous things sometimes, but sometimes they say poetic things.\"\\nThe native Canadian who works in digital marketing adds that US politics are a lot more consequential on the world stage, \"given their size and their military prowess\", so a lot of Canadians are tuning in.\\nAs the beer flowed and the debate drew to a conclusion, the consensus among the group of nearly a dozen spectators who came to the event hosted by Democrats Abroad matched fairly closely to the analyses from most US commentators. The crowd was left-leaning, but as Gaudet noted, Conservatives in Canada would probably be Democrats in the US anyway.\\nFormer computer executive Fiorina and New Jersey Governor Chris Christie were among the winners, Wisconsin Governor Scott Walker was underwhelming and Donald Trump was, well, Trump.\\n\"Donald Trump is a sideshow as far as I\\'m concerned,\" says Laurel White Johnston, a retired American who has lived in Calgary for the past 13 years. \"I don\\'t know why he\\'s in there.\"\\nHer pick was Florida Senator Marco Rubio.\\n\"He\\'s a thoughtful person and he\\'s moderate,\" she says. \"I get very tired of people invoking God and whatnot in these debates.\"\\nOmar Masood, a Canadian citizen who immigrated from Dubai 10 years ago to attend university, also wasn\\'t a big Trump fan: \"I feel like when he says something that might make a little bit of sense, people take notice of it not because it makes a little bit of sense but because, in the ocean of stupidity, it\\'s some light at the end of the tunnel.\"\\nHe says while he wasn\\'t surprised by what he saw as Islam-bashing and xenophobic themes during the debate, he was struck by how little the candidates spoke about the economy - currently a huge issue in Canada.\\n\"They spent a lot of time talking about borders and social issues,\" he says. \"They did not distinguish themselves on economic policy.\"\\nHe says that Canadian politicians \"make a lot more sense\", but one Republican candidate who did catch his fancy was Ohio Governor John Kasich.\\n\"I liked the fact that he didn\\'t want to focus on demagoguery,\" he says. \"He was focused on more positive themes, and he tried to in his own limited way to talk about the economy.\"\\nMr Kasich, he notes with a laugh, \"aspires to talk like a Canadian politician\".\\nAlthough the turnout for the Calgary debate-watch party was small, there was plenty of evidence that Canadians across the nation are keeping an eye on what was happening to their south. The debate was Canada\\'s top Twitter trend through much of its three-hour duration.\\nBut was it serious viewing or just outsiders hoping to witness a Trump-inspired conflagration?\\nDana Strasser, another American expat, says that whenever she tries to have a serious discussion about US politics with most Canadians, \"they just roll their eyes\".\\nNext month\\'s federal elections are a chance for Canadians to cast their verdict on the state of the country - and the government that\\'s been running it.\\nMillions will vote on 19 October but each individual voice matters - and BBC Pop Up wants to know how you feel about your country.\\nAre you happy with your politicians and the political system? Are the parties addressing or ignoring the issues that matter to you? Is Canada heading in the right or wrong direction?\\nIn five words, tell us how you feel about today\\'s Canada. We\\'ll share your thoughts with a global audience - and if you have a story idea that highlights an important issue for this election we may be able to come visit and film it.\\nGet involved using #bbcpopup on Twitter, Facebook and Instagram. Or email us at bbcpopup@bbc.co.uk\\nRead more at bbc.com/popup'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Sean Dickson scored an unbeaten 210 as Kent dominated the first day's play against Northants at Beckenham.\", 'negatives': [], 'positives': [\"The hosts lost Daniel Bell-Drummond for 49, but Dickson (210 not out) and Joe Denly (143 not out) scored freely in an unbroken 305-run second-wicket stand.\\nDickson reached his century off 165 deliveries, before making his second career 200 off 280 deliveries.\\nDenly's ton came from only 132 balls, the pair scoring at 5.27 an over to race to maximum batting bonus points.\\nThe partnership was the highest ever recorded at Beckenham, and a record second-wicket stand against Northamptonshire.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"On 22 April, following a month of military operations involving 2,415 sorties and the release of at least 1,000 air-to-ground weapons, Saudi Arabia's bombing campaign in Yemen, Operation Decisive Storm, was brought to a close.\", 'negatives': [], 'positives': ['In its place a new phase of operations known as Operation Restoring Hope was put into action, stressing a reduction in the use of force and a movement to a proposed political solution.\\nSaudi Arabia has operated at a virtually unprecedented volume of military activity that, in tandem with its coalition partners, managed a remarkably sustained level of air strikes for a number of weeks.\\nCertainly, Saudi Arabia has shown an ability to conduct a high volume of air strikes (sometimes as many as 125 strikes a day), proving wrong those that doubted the Kingdom\\'s ability to sustain complex extra-territorial operations.\\nThe munitions used by the Royal Saudi Air Force (RSAF) point to a preference for relatively small payloads between 500-2,000lb, with a heavy focus on GPS and Laser guided gravity bombs.\\nThe success achieved by the RSAF in hitting military targets was high, and initially the precision munitions caused little collateral damage.\\nThis is primarily due to the choice to target military installations, which, by their very nature, tend to be placed away from civilian areas.\\nThe targeting order made sense: first to be hit were Yemeni Air Force installations, ballistic missile sites, and ammunition dumps, followed by identifiable Houthi military convoys and concentrations of fighters.\\nHowever, the longer Decisive Storm went on and the fewer defined targets remaining that showed clear military purpose, the more collateral damage and incorrect target identification occurred.\\nThe Houthis, like so-called Islamic State, got better at concealing their activities, the result being that strikes increasingly erred in accuracy and caused civilian casualties.\\nIn addition the Saudis have operated a tight restriction on the flow of shipping and aircraft into Yemen, blockading ports around Hudayda, Aden and international airports in Sanaa, Taiz, and Aden.\\nThe primary aim being to stop Iranian supply shipments to Houthi rebels from entering the conflict zone.\\nThe blockade achieved its intended purpose, but recent attempts by Iran to run the exclusion zone, by sending planes to Yemen supposedly for \"humanitarian\" reasons, have been met by Saudi force that verges on disproportionate, such as the bombing of runways at Sanaa International Airport.\\nSo has the Saudi operation been a success? Yes and no.\\nIf the definition of success is the removal of strategic and tactical threats to the Saudi homeland, then yes the Saudis basically achieved their aims.\\nThe Houthis: Zaidi Shia-led rebels from the north, who seized control of Sanaa last year and have since been expanding their control\\nPresident Hadi: Fled to Saudi Arabia after rebel forces advanced on his stronghold in the southern city of Aden\\nAl-Qaeda in the Arabian Peninsula (AQAP): Seen by the US as the most dangerous offshoot of al-Qaeda, AQAP opposes both the Houthis and President Hadi\\nIslamic State: A Yemeni affiliate of IS has recently emerged and seeks to eclipse AQAP in the region\\nAlmost all Yemen\\'s potentially offensive capabilities have been destroyed and the armed forces fighting on behalf of the Houthis and former President Ali Abdullah Saleh pose no more than mild irritant to the Saudi state.\\nHowever, if Decisive Storm is judged in terms of achieving political solutions then the answer is far less clear.\\nThe Houthis have not retreated from the south of the country nor have they been backed into a position in which they appear willing to take a seat at the negotiating table under terms that either President Abdrabbuh Mansour Hadi or his Saudi backers can accept.\\nThe movement to Operation Restoring Hope is designed to afford the Saudis time to achieve this result, in this sense.\\nAlthough air strikes are ongoing the stress here is that Restoring Hope is not primarily a military-led campaign, if anything it is merely a bracket of security around which a political settlement can be achieved.\\nYet the Saudi political machine has tried to show that the operation has been a success.\\nThe Defence Minister and newly promoted Second Deputy Prime Minister, Mohammed bin Salman, has taken ownership of this war and he cannot fail to achieve success politically, even if the military gains are somewhat suspect.\\nAs such, it\\'s unlikely that Riyadh will report Operation Decisive Storm and Operation Restoring Hope as anything other than military successes which achieved a defined objective.\\nThe Saudis are unlikely to be able to move back to the operational levels that were used in Decisive Storm.\\nWear on airframes, munitions stocks and servicing requirements take their toll on aircraft flying daily sorties over target areas.\\nAdditionally the amount of valuable, easily identifiable targets to hit in Yemen has reduced to virtually zero.\\nFar more likely is a sustained, lower intensity close air support campaign which will look to provide back-up units operating on the ground against the Houthis, adapting quickly to battlefield conditions.\\nIt is unlikely that total military victory under these conditions can be achieved, and furthermore it is unrealistic to expect the RSAF to provide the killer blow.\\nIf the rag tag assortment of forces on the ground in Yemen cannot push the Houthis back then the conflict will sadly drag on for months to come.\\nMichael Stephens is Research Fellow for Middle East studies and Head of Rusi Qatar'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Carwyn Jones and Nigel Farage have disputed the likely impact on jobs in Wales if the UK left the EU.', 'negatives': [], 'positives': ['In a head-to-head debate in Cardiff, the first minister warned an EU exit would have \"devastating consequences\".\\nThe UKIP leader claimed being in the EU had left the first minister \"impotent\" over the fate of the steel industry.\\nMr Farage said British people should \"reclaim their birthright\" while Mr Jones said Wales and the UK should not \"surrender\" their role in the world.\\nIn an event staged by the Institute of Welsh Affairs, the UKIP leader began by asking if British people wanted to \"regain our independence as a nation state\" or if they were happy to be a \"subordinate member of the club\".\\nMr Farage claimed it was \"scaremongering\" to say trade would cease and jobs would be lost following a British exit from the EU.\\nThe first minister replied by saying membership of both unions - the UK and the EU - was vital to Welsh prosperity.\\nClaiming 200,000 jobs in Wales relied on EU trade, Mr Jones said \"pulling up the drawbridge\" would have \"devastating consequences\".\\nOn the issue of immigration, Mr Farage said \"the biggest benefit\" of leaving the EU would be the UK\\'s ability to set up an Australian-style points system to accept people based on their skills, lack of criminal convictions and ability to speak English and integrate.\\nHowever, Mr Jones dismissed the suggestion EU membership had \"anything to do\" with immigration, saying if the UK was not a member, France would simply allow refugees camped at Calais to pass through.\\n\"Would it be in our interest to turn our backs on our European partners, or isn\\'t it better to work together to find a European solution to what is a European challenge,\" he asked.\\nEluned Parrott, Welsh Liberal Democrat spokesperson on Europe, said \"neither person came out of this shouting match particularly well\", claiming hers was the only UK party united in favour of EU membership.\\n\"Carwyn Jones was right to be arguing the importance of the UK remaining in the EU,\" she said.\\n\"Yet, his views are in stark contrast to his party in London, where [Labour leader] Jeremy Corbyn remains ambivalent on this major issue.\"\\nPlaid Cymru AM Elin Jones was critical of Mr Jones, tweeting: \"Well, for the case for Wales staying in EU, that was a set-back. Mustn\\'t be repeated. #IWADebate.\"\\nBefore the event, a spokesman for the Welsh Conservatives dismissed it as having the feel of a \"rather gaudy PR spectacle\", saying Mr Jones had failed to invite rival party leaders to debate Welsh issues under his control.\\nA referendum on whether the UK should remain within the EU or leave is set to be held before the end of 2017.\\nOn Sunday, Prime Minister David Cameron suggested the vote could be held as early as this summer.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Part of a new road bridge being constructed over the River Wear has completed a two-day journey across the North Sea.', 'negatives': [], 'positives': ['The three-span cable-stayed structure that will stretch between Castletown and Pallion is supported by a 115m (379ft) A-frame pylon.\\nThis was manufactured on the continent and has been transported from the Port of Ghent in Belgium.\\nIt travelled on a massive barge which docked at the Port of Sunderland.\\nOver the next few weeks it will travel up the River Wear to the site in Pallion, where it will be raised vertically into position.\\nThe bridge is due to open in 2018'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Evangelical Christian preacher Pastor James McConnell has been found not guilty of making \"grossly offensive\" remarks about Islam.', 'negatives': [], 'positives': ['The 78-year-old, from Shore Road in Newtownabbey, County Antrim, denied two charges relating to a sermon he gave in a Belfast church in 2014.\\nA judge said while he considered the remarks offensive, he did not consider them \"grossly\" offensive under the law.\\nSupporters of the pastor applauded when the verdict was given.\\nSpeaking outside court, Mr McConnell said his only regret was the response from the Muslim community that he was \"out to hurt them\".\\nHe said: \"There was no way I was out to hurt them. I wouldn\\'t hurt a hair on their head.\\n\"But what I am against is their theology and what they believe in.\"\\nHe said he would do it again, but would be conscious that he was \"hurting innocent Muslims\".\\nMr McConnell had denied two charges - improper use of a public electronic communications network and causing a grossly offensive message to be sent by means of a public electronic communications network.\\nHe made the remarks at the Whitewell Metropolitan Tabernacle in north Belfast in May 2014.  His sermon was also streamed online.\\nDuring the trial, Mr McConnell said that he still believed in what he had preached, and did not go into church to \"provoke anyone\".\\nA prosecution lawyer had said his words were not \"a slip of the tongue\", while a defence lawyer said he should not be convicted.\\nJudge Liam McNally told Belfast Magistrates\\' Court he did think the pastor\\'s passion in preaching  meant it \"had caused him to lose the run of himself\" and advised him to consider the impact of his words in future.\\nHowever, he concluded that the words upon which the charges were based, while offensive, do not reach the high threshold of being \"grossly offensive\".\\n\"The courts need to be very careful not to criminalise speech which, however contemptible, is no more than offensive,\" he said.\\n\"It is not the task of the criminal law to censor offensive utterances.\"\\nIn a statement, the Belfast Islamic Centre said the Muslim community in Northern Ireland believes in the freedom of expression, but added that \"insulting other faiths and beliefs\" leads to \"disunity and mistrust\".\\nIt said: \"We Muslims are looking forward to achieving and maintaining the values of coexistence and diversity.\\n\"We are mindful of some voices trying to push towards disintegration and isolation of some religious and ethnic minorities.\\n\"Although we disagree with the description of Pastor McConnell\\'s remarks as \\'not grossly offensive\\', we have always been ready to implement the values of forgiveness and pardon as a way forward.\"\\nThe Democratic Unionist Party (DUP) MP Sammy Wilson and Catholic priest Fr Patrick McCafferty appeared as character witnesses for Mr McConnell.\\nSpeaking on BBC Radio Ulster\\'s Talkback programme, Mr Wilson welcomed the news, saying Mr McConnell \"should never have been in court in the first place\".\\nHe said: \"Anyone who is engaged in public debate or speech ought to be happy at the result today.\\n\"We live in a free society and in a free society, people should be free to express the beliefs that they hold.\"\\nHe added that if Mr McConnell had accepted a police caution, it would have introduced \"a chill factor\" into issues of public speech.\\nPeter Lynas, of the Evangelical Alliance Northern Ireland, said the verdict was \"a victory for common sense and freedom of speech\".\\n\"However, until the law is changed or clear guidance is issued there will still be concern about further prosecution,\" he added.\\n\"The Public Prosecution Service (PPS) need to explain why this case was brought and assure everyone that this will not happen again.\"\\nBoyd Sleator of Atheist Northern Ireland said: \"His (Mr McConnell\\'s) comments were offensive but we are allowed to be offensive and I would never want to see anybody prosecuted for being offensive. His comments were idiotic, his comments were silly,\" he said.\\nIn a statement, the PPS said \"it was clear from the judgement that the court considered Pastor McConnell had a case to answer and that the decision on whether the comment was offensive or grossly offensive was not only finely balanced but one for the court and the court alone to take\".\\n\"The decision to bring this prosecution was entirely consistent with the duty of the PPS to put before the court those cases in which it is considered there is a reasonable prospect of a conviction.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Arsenal have confirmed the signing of left-back Cohen Bramall from non-league side Hednesford Town.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nBramall trained with the Gunners first team last week and will now work with the Premier League club\\'s Under-23 squad.\\nThe 20-year-old played for Hednesford in the Northern League Premier Division on a part-time basis, while working full-time at a Bentley car factory.\\nHe was facing redundancy last month, before being picked up by Arsenal.\\nSpeaking to BBC Sport last week, Bramall explained how his career changed in a 24-hour period.\\n\"I got made redundant by Bentley on the Tuesday [20 December], which was crazy because I didn\\'t know what I was going to do,\" he said.\\n\"My agent Lee Payne rings me on the Wednesday saying you\\'ve got a trial at Arsenal. I was like \\'what?\\' - I was gobsmacked.\\n\"He said pack your stuff and get to this postcode, so I packed all my stuff in about an hour, got there as fast as I could, slept for a bit, then the next minute I\\'m in training with the first team.\\n\"It was crazy how quick everything happened, how I met everyone and they just took me straight in. I had to take the opportunity with both hands.\"\\nCrystal Palace and Sheffield Wednesday had reportedly watched Bramall, but only Arsenal agreed terms on a reported £40,000 deal.\\n\"Bramall is a young, promising left-back who has a lack of experience at the top level but who has fantastic ingredients,\" Gunners manager Arsene Wenger said.\\n\"He has tremendous pace, a good left foot, a great desire to do well. Overall, he\\'s a very exciting prospect.\"\\nFind all the latest football transfers on our dedicated page.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Carmaker Volvo has said all new models will have an electric motor from 2019.', 'negatives': [], 'positives': ['The Chinese-owned firm, best known for its emphasis on driver safety, has become the first traditional carmaker to signal the end of the internal combustion engine.\\nIt plans to launch five fully electric models between 2019 and 2021 and a range of hybrid models.\\nBut it will still be manufacturing earlier models that have pure combustion engines.\\nGeely, Volvo\\'s Chinese owner, has been quietly pushing ahead with electric car development for more than a decade.\\nIt now aims to sell one million electric cars by 2025.\\n\"This announcement marks the end of the solely combustion engine-powered car,\" said Hakan Samuelsson, chief executive of Volvo\\'s carmaking division.\\n\"People increasingly demand electrified cars, and we want to respond to our customers\\' current and future needs,\" he said.\\nVolvo\\'s announcement sounds dramatic, but the reality is it simply reflects the direction much of the auto industry is travelling in.\\nThe internal combustion engine is not dead - and won\\'t be for a while at least. It still offers a relatively cheap and well-proven means of getting around.\\nThe problem is that emissions regulations are getting much tighter. From 2021, for example, carmakers in the EU will have to ensure that across their fleets, average CO2 output is no higher than 95g of CO2 per kilometre. That\\'s a lot lower than current levels.\\nCarmakers are reacting by developing fully-electric models. Some are already pretty impressive. But developing mass market cars that are affordable and have the right levels of performance is a research-intensive and expensive process, while persuading consumers to buy them in large numbers may also be time consuming.\\nIn the meantime, hybridisation - fitting electric motors to cars which also have conventional engines - offers a convenient way to bring down emissions without harming performance. And there are plenty of different kinds of hybrid systems to choose from.\\nVolvo is making headlines, but other manufacturers are doing much the same kind of thing.\\nTim Urquhart, principal analyst at IHS Automotive, said the move was a \"clever sort of PR coup - it is a headline grabber\".\\n\"It is not something that moves the goalposts hugely,\" he said.\\n\"Cars launched before that date [of 2019] will still have traditional combustion engines.\\n\"The announcement is significant, and quite impressive, but only in a small way.\"\\nIt comes after US-based electric car firm Tesla announced on Sunday that it will start deliveries of its first mass-market car, the Model 3, at the end of the month.\\nElon Musk, Tesla\\'s founder, said the company was on track to make 20,000 Model 3 cars a month by December.\\nHis company\\'s rise has upset the traditional power balance of the US car industry.\\nTesla, which makes no profits, now has a stock market value of $58bn, nearly one-quarter higher than that of Ford, one of the Detroit giants that has dominated the automotive scene for more than a century.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A boat carrying 31 people, including at least 28 Chinese tourists, has gone missing off the Malaysian coast, maritime authorities say.', 'negatives': [], 'positives': ['The boat lost contact after departing the eastern state of Sabah on Saturday.\\nThe Malaysian Maritime Enforcement Agency said search and rescue efforts were being hampered by bad weather.\\nThe incident coincides with the first day of China\\'s week-long Lunar New Year celebration, which is also marked by ethnic Chinese in Malaysia.\\nThe catamaran boat left Kota Kinabalu on Saturday at 09:00 local time (01:00 GMT) and was heading towards Pulau Mengalum, a popular tourist island 60km (37 miles) west of the city.\\nThe Malaysian Maritime Enforcement Agency said it received a distress call from the boat but contact was lost soon after.\\n\"I, like all the relatives of those on board, am hoping for progress in the search and rescue operation,\" the tourism minister for Sabah state, Masidi Manun, told the AFP news agency.\\nThe search area covers 400 nautical square miles between Kota Kinabalu and Pulau Mengalum, according to the New Strait Times.\\nStorms are common in the area at this time of year.\\nThree crew members were on board the vessel, alongside the 31 passengers.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Newport Gwent Dragons head coach Kingsley Jones has \"no fears\" about needing to win in Brive in the final round of the European Challenge Cup group.', 'negatives': [], 'positives': ['\"As a coach I\\'ve gone to France with different teams and it\\'s a very happy hunting ground for me,\" said Jones.\\nBrive lead the group by four points after edging out Worcester 17-14.\\nThe French side beat the Warriors with the last kick of the game after scoring just two tries.\\nThat means a 5-1 or 4-0 match points win for the Dragons in France would be enough to see them through.\\nThey also have a slim chance of being one of the best runners-up with a narrow win.\\nThey took maximum points in Pau on the way to the semi-final in 2015-16, as well as gaining a maximum away to Stade Francais the previous season when they also reached the last four.\\n\"Personally I have no fears about it, Brive are a good side and it\\'s a very tough environment, but Pau, Stade Francais, the list goes on and (I\\'ve won) with other teams at Castres and Biarritz,\" Jones said.\\n\"Particularly with this team we\\'ve got a style of rugby that can cause Brive some problems.\\n\"We\\'ve got to deal with their power game. We\\'ll have to move them around and play with tempo.\"\\nTom Prydie (ankle) and Matthew Screech (leg) are injury concerns after going off during the 34-10 win over Enisei-STM.\\nNumber eight Harrison Keddie, 20, scored two late tries to earn the bonus point.\\n\"It\\'s all on the line for us, we\\'ll know what we have to do to hopefully get through to the next round,\" Keddie told BBC Wales Sport.\\n\"I don\\'t see why we can\\'t get a win if we keep performing the way we can at home, we\\'ve got to try to transfer that to an away victory.\\n\"There\\'s no reason to go out there with a losing mentality, we will be underdogs but that\\'s always easier.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'An app that lets people speak to avatars of dead relatives and take selfies with them is being developed in South Korea.', 'negatives': [], 'positives': [\"2 March 2017 Last updated at 00:00 GMT\\nThe BBC's Chris Foxx asked Eun Jin Lim from Elrois, the company making it, whether people might find the idea strange.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Skier Kelly Gallagher has won ParalympicGB's first ever gold at the Winter Games with victory in the visually impaired Super-G in Sochi.\", 'negatives': [], 'positives': ['Media playback is not supported on this device\\nThe 28-year-old from Bangor in County Down and her guide, Charlotte Evans, were first on the Rosa Khutor course and clocked one minute 28.72 seconds.\\n\"It was nerve-wracking but I\\'m delighted with the result,\" Gallagher told BBC Sport.\\nDownhill silver medallist Jade Etherington came away with bronze.\\nBorn: 18 May, 1985 in Northern Ireland\\nEvents: Visually impaired super combined, slalom, giant slalom, Super-G, downhill\\nGames Attended: Sochi 2014, Vancouver 2010\\nAchievements:\\nBritain\\'s first Winter Paralympic gold medallist after winning the Super-G in Sochi\\nSilver medallist in Super-G at 2013 World Championships in La Molina, Spain\\nFourth in Giant Slalom at Vancouver Paralympics in 2010\\nIn the sit-ski event, Britain\\'s Anna Turney was fourth, with Germany\\'s Anna Schaffelhuber winning her second gold of the competition.\\nGallagher and Evans were keen to make amends for finishing last of six competitors in Saturday\\'s downhill.\\n\"Normally when we compete, even in big events like World Championships, there is nobody interested in what we are doing,\" said Gallagher.\\n\"But here there has been a lot of hype and pressure, as well as expectation, and maybe we let some of that in.\\n\"Today we just decided to ski and see what happens.\\n\"I have to thank Charlotte for getting me to the line. We just threw ourselves at it. I prayed for the strength to ski and have fun.\"\\nEvans added: \"I was yelling a lot and she wasn\\'t doing what I told her, but finally it paid off. It didn\\'t feel as good as we wanted to on the course, but who cares.\\n\"We won a gold medal and it feels amazing.\"\\nEtherington, the second competitor out, recovered from hitting one of the gates for her and guide Caroline Powell to finish in 1:29.76.\\nBut they saw Russian\\'s Aleksandra Frantceva beat her time with 1:28.94 and take silver, while downhill champion Henrieta Farkasova of Slovakia made an error midway through her run and lost time to put her out of medal contention.\\n\"I made a big mistake going straight into the gate and losing my pole,\" Etherington explained. \"I got it back and Caroline told me not to slow down too much, be strong and to push on the outside of my skis.\\n\"Winning a silver in the downhill gave me a lot of confidence.\"\\nGallagher, who has oculocutaneous albinism, a condition with affects the pigment in her hair, skin and eyes, started skiing for the first time when she was 17 on a trip to Andorra and began working with Evans, from Kent, in late 2010, just months after finishing fourth in the Giant Slalom at the Vancouver Games with previous guide Claire Robb.\\nThe pair communicate on their way down the slopes via bluetooth headsets as they travel at speeds of up to 100km/h.\\nSince linking up together, they have won silver and bronze medals in the 2011 and 2013 World Championships as well as World Cup honours.\\nBritain has had athletes competing in every Winter Paralympics since the first event in 1976 in Sweden and the three medals won so far surpasses the minimum target of two set by UK Sport ahead of the event.\\nGallagher, Evans, Etherington and Powell will be in action again on Tuesday, along with Turney and fellow sit-skier Mick Brennan, when they compete in the super combined event.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Iran and the P5+1 have finally agreed on a nuclear deal, after years of talks.', 'negatives': [], 'positives': ['16 July 2015 Last updated at 20:45 BST\\nBBC News explains the key points, in less than two minutes.\\nProduced by Mohamed Madi and Julie Wall.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Theresa May and Jeremy Corbyn are both vowing action to improve security on Britain's streets.\", 'negatives': [], 'positives': ['Mrs May is highlighting Tory plans for a new commission to counter extremism and \"stand up\" to Islamists and others who threaten British values.\\nMr Corbyn says Tory cuts have undermined security and is pledging to recruit an extra 10,000 police and more security staff if Labour wins power.\\nThe Conservatives say the Labour leader\\'s sums \"don\\'t add up\".\\nThe two party leaders have been engaged in a war of words over the best way to respond to the terror threat, in the wake of the suicide attack in Manchester that left 22 dead.\\nMrs May earlier announced that the terror threat had been reduced from \"critical\" to \"severe\" but she warned people to \"remain vigilant\".\\nThe Conservative general election manifesto includes plans for a Commission for Countering Extremism, which the party says will identify extremism, including the \"non-violent\" kind, and help communities stand up to it.\\nThe party has not released full details of how it will work but has promised it will be a statutory body with \"proper teeth and a clear remit\".\\nMrs May said: \"Our enjoyment of Britain\\'s diversity must not prevent us from confronting the menace of extremism, even if that is sometimes embarrassing or difficult to do.\\n\"Extremism, especially Islamist extremism, strips some people of the freedoms they should enjoy, undermines the cohesion of our society, and can fuel violence. And it can be especially bad for women.\\n\"There is clearly a role for government in tackling extremism where it involves behaviour that is or ought to be criminal.\\nBut there is also a role for government to help people and build up organisations in society to promote and defend Britain\\'s pluralistic values, and stand up to the extremists who want to undermine our values and impose their twisted beliefs onto the rest of us.\"\\nShe added: \"Enough is enough.  We need to be stronger and more resolute in standing up to these people.\"\\nMr Corbyn, meanwhile, will repeat Labour\\'s pledge to reverse cuts to police and emergency services staff he says have been carried out by the Conservatives.\\nLabour say they would recruit an extra 10,000 police officers, 3,000 more firefighters, 3,000 more prison officers, 1,000 more security and intelligence agency staff and 500 more border guards if Labour wins the general election, he says.\\nHe is also promising extra staff for the security and intelligence agencies - GCHQ, MI6 and MI5 - in order \"to better ensure our collective safety\".\\nHe added: \"As well as full funding for our frontline and first response services, Labour will properly resource the partner agencies in other frontline public services, including schools and colleges, and local authorities.\\n\"These agencies are charged with a duty to identify those individuals vulnerable to violent extremism but under the current government they have been held back and barely been able to provide their own core services.\\n\"Only Labour is serious about properly resourcing our security and frontline services.\"\\nThe Conservatives hit back at Labour\\'s promises, with Home Secretary Amber Rudd saying: \"Jeremy Corbyn can promise what he likes, but can\\'t deliver anything because his sums don\\'t add up and he isn\\'t up to the job of keeping Britain safe.\"\\nIn Autumn 2015, the then Chancellor, George Osborne, promised to spend Â£3.4bn extra on counter-terrorism - an increase of 30% - over the following five years.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"A row about the running of crofters' common grazings in a part of Lewis looks set to be heard at the Scottish Land Court.\", 'negatives': [], 'positives': ['Upper Coll grazings committee has been dismissed by the Crofting Commission due to a perceived failure to provide audited accounts.\\nFormer committee members are preparing an application to the court in a bid to have the dismissal overturned.\\nThe land court deals with disputes in crofting and farming.\\nCommon grazings are areas of land shared by crofters and others who hold a right to graze stock on that land.\\nThere are more than 1,000 common grazings covering at total of 500,000ha across Scotland, according to the Crofting Commission.\\nGrazing committees manage these areas of land and their members are elected by crofters.\\nThe Crofting Commission, the industry\\'s regulatory body, requested accounts from the Upper Coll committee after receiving a complaint relating to a meeting between the commission and crofters.\\nCrofters complained to the commission about the conduct of certain commissioners at the meeting.\\nFollowing the dismissal of the grazings committee, its former members have said they complied with all requests made of them and that they had done nothing wrong.\\nNow they have taken the step of preparing an application to the Scottish Land Court to have the commission\\'s decision to dismiss the committee overturned.\\nThe application will submitted on their behalf next week.\\nThe Scottish Crofting Federation, a body representing crofters, has criticised the commission\\'s actions and Western Isles Council - Comhairle nan Eilean Siar - has appealed for the dispute to be resolved.\\nIn a statement, the Crofting Commission said it was \"committed to assisting all common grazings committees and clerks to self-regulate within the provisions of crofting legislation, and will work with them to do so\".\\nIt added that it had offered to meet with crofters at Upper Coll and Mangersta in Uig, also in Lewis, where a grazing committee has also been disbanded.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'It had all the ingredients for an Australian tabloid TV sensation: a frantic mother from Brisbane in an audacious attempt to snatch back her children from her estranged husband on the streets of Beirut.', 'negatives': [], 'positives': ['In the cut-throat world of prime-time commercial television where ratings are paramount, a team from Channel Nine\\'s flagship currents affairs show 60 Minutes must have felt they had a child custody blockbuster that would leave its rivals far behind.\\nBut the high-risk assignment in the Middle East quickly went badly wrong.\\nSally Faulkner, the mother, was arrested along with the the Nine crew, including star reporter Tara Brown, shortly after Lahela, age six, and Noah, four, were grabbed from their grandmother in Beirut. They spent a grim fortnight in a Lebanese prison until a deal on Wednesday set them free. Child Abduction Recovery Network chief Adam Whittington and fellow Briton Craig Michael, however, remain behind bars.\\nAs they head home the Australian journalists and their bosses have awkward questions to answer.\\nDid they pay Mr Whittington\\'s agency to carry out the botched operation, and was ransom forwarded to Ms Faulkner\\'s husband in return for her freedom and that of the Nine reporting team?\\nRead more: Lebanon releases Australian TV crew held in kidnapping case\\nThe network is facing an avalanche of criticism, and some careers might not survive the onslaught and an internal review at one of Australia\\'s leading TV stations.\\n\"It is important to reiterate that at no stage did anyone from Nine or 60 Minutes intend to act in any way that made them susceptible to charges that they breached the law or to become part of the story that is Sally\\'s story,\" Channel Nine\\'s chief executive Hugh Marks told local media.\\n\"But we did become part of the story and we shouldn\\'t have.\"\\nMistakes were clearly made and Frank Thorne, a 40-year veteran of the ruthless British tabloids, is critical of 60 Minutes\\' approach to the story in Lebanon.\\n\"You\\'ve got to be extremely careful with chequebook journalism,\" he told the BBC.  \"We used to bend the rules, we used to bend the law, if you like, but we would not break the law.\"\\n\"There were legal guidelines and we had to stick to them and clearly Channel Nine committed acts that were illegal or were complicit in acts that were illegal. You can\\'t as journalists condone kidnapping children off the streets no matter what the circumstances.\\n\"I think heads will roll and the Channel Nine crew and Tara Brown can think themselves very, very fortunate that they are not looking at a jail cell in Lebanon for the next few years,\" added the Sydney-based reporter.\\nThere is scant sympathy for the news team on social media, where there has been a hum of opprobrium.\\n\"How fortunate for the #60Minutes crew that the Lebanese legal system allows them to buy their way out of trouble\" said one contributor on Twitter.\\n\"I hope the #60Mins journos have learned a valuable lesson about allowing their egos to cross the line without their brains in check,\" added another.\\nStar journalists at Channel Nine strongly voiced their support for the 60 Minutes crew, but some media heavyweights from other outlets have been sharply critical of the high-risk story.\\n\"The media have got no role in determining who should have custody of the children whether it be a father or a mother,\" broadcaster Alan Jones told his listeners on Sydney radio station 2GB.\\n\"[The children were] snatched by a child recovery team as they were walking with their grandmother.  Just imagine this happening in Australia.\"\\nAfter the ordeal its crew and Ms Faulkner have faced, Channel Nine will most likely savour ratings gold when their story is told, but academics warn it could be a pyrrhic victory.\\n\"It will be a ratings bonanza [but] it\\'s what we call the dead cat bounce,\" explained John Harrison, a senior lecturer in journalism at the University of Queensland.\\n\"Yes, they\\'ll get one or two good hits but the damage to their credibility in the long term and the damage that they\\'ve done to the sort of journalism they do is long term and potentially fatal.\"\\n\"They put the story ahead of any considerations of ethics. I don\\'t think they thought it through partly because they\\'ve been able to get away these sorts of practices for so long,\" he told the BBC news website.\\nMr Harrison believes that the risks taken by the 60 Minutes team are a sign of the desperation within traditional TV networks.\\n\"These are the death throes of free-to-air commercial television in its unending search for ratings. Free-to-air television has been undermined by all forms of new media and I think it has a very limited future.  News and live sport are the only things it has got left and it has to actually keep its ratings up in those areas in order to remain viable.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Former Olympic champion Dawn Harper-Nelson has been banned for three months after testing positive for a banned diuretic.', 'negatives': [], 'positives': ['The American, 32, said she was given hydrochlorothiazide for high blood pressure but failed \"to fully understand how its administration was governed by current doping protocols\".\\nHarper-Nelson won 100m hurdles gold at Beijing 2008 and silver at London 2012.\\nDiuretics increase urine production, but are not performance enhancing.\\nHowever they can be used to mask the presence of other illegal substances or promote weight loss.\\n\"I have learned a valuable lesson and hope my mistake will serve as a reminder to all athletes to be diligent in thoroughly checking any and all prescribed medications,\" Harper-Nelson added.\\nHer ban has been in place since 1 December.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Deputies in Russia's parliament broke into applause at the news Donald Trump had been elected US president.\", 'negatives': [], 'positives': ['Vladimir Putin wasted no time sending his congratulations and state TV channels switched quickly from claims of fraud, to hailing the triumph of the \"man of the people\".\\nDonald Trump\\'s win clearly suits Moscow.\\nIn a telegram dispatched soon after the victory speech, President Putin hoped the two could work together to end the \"crisis\" in US-Russian relations.\\nHe also called for constructive dialogue, based on \"mutual respect and a real consideration for the other\\'s interests\".\\nPro-Kremlin commentators and politicians were openly gleeful.\\n\"I want to drive through Moscow with an American flag in the window. Come and join me,\" Russia Today editor Margarita Simonyan tweeted, with a smile emoji. \"Today, they earned it.\"\\n\"They were fighting the establishment, traditional Washington and the lies pouring from all the TV channels,\" is how Vyacheslav Nikonov, a deputy with the pro-Putin United Russia party, interpreted Donald Trump\\'s voters.\\n\"This election was a protest vote. Against the existing way, and the existing White House,\" Mr Nikonov pronounced, speaking on the state run TV channel Russia 24, which covered the US election extensively throughout the night.\\nNot everyone in Russia was rejoicing though.\\n\"I\\'m watching his speech and I have to pinch myself,\" tweeted an activist with the Parnas opposition party. \"I can\\'t believe this is happening,\" Natalya Pelevina wrote.\\n\"It\\'s like being arrested. Dramatic at the beginning. But then you start to figure out how to live and create in prison. You\\'ll overcome,\" consoled a tongue-in-cheek tweet from the Pussy Riot girls, imprisoned for performing an anti-Putin song in Moscow cathedral in 2012.\\nThe US has accused Russia of helping to engineer the election outcome by carrying out cyber attacks that weakened Hillary Clinton\\'s campaign.\\nPresident Putin himself recently laughed off the suggestion of Russian interference, wondering whether the US was a \"banana republic\".\\nBut antipathy to Hillary Clinton is deep-rooted here. As Secretary of State, she was sharply critical of Russia\\'s flawed 2011 parliamentary elections, leading President Putin to accuse her of fomenting the mass protests against him that followed.\\nRussian media coverage of her own campaign was vicious, portraying her as an aggressive Russophobe, a criminal and a liar.\\n\"Clinton will surround us with nuclear missiles; Trump would recognise Crimea,\" a typical tabloid headline read on election day.\\n\"We are very glad that relations will improve with Russia and stop the artificial Cold War which Washington and London try to push on the world,\" pro-Kremlin analyst Sergei Markov told the BBC.\\n\"We\\'re glad the new president will be Donald Trump who respects Vladimir Putin and recognises that Crimea is part of Russia,\" he said, referring to Mr Trump\\'s comment that Russia\\'s annexation of the peninsula could be \\'looked at\\'.\\nSo could this herald a thaw? Or is Russia planning to exploit the division and disarray caused by this result to pursue its own priorities, including in Syria?\\nThere are growing hints that whilst Americans are reeling from their bitterly-fought election, Russian troops will launch a new push with Syrian government forces to take Aleppo.\\nThat way, Russia would ensure that the new, \"constructive dialogue\" President Putin is calling for with Donald Trump, starts from a position of strength.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A new law promising internet users the \"right to be forgotten\" will be proposed by the European Commission on Wednesday.', 'negatives': [], 'positives': ['It says people will be able to ask for data about them to be deleted and firms will have to comply unless there are \"legitimate\" grounds to retain it.\\nThe move is part of a wide-ranging overhaul of the commission\\'s 1995 Data Protection Directive.\\nSome tech firms have expressed concern about the reach of the new bill.\\nDetails of the revised law were unveiled by the Justice Commissioner, Viviane Reding, at the Digital Life Design (DLD) conference in Munich.\\nA spokesman for the commissioner clarified that the action was designed to help teenagers and young adults manage their online reputations.\\n\"These rules are particularly aimed at young people as they are not always as aware as they could be about the consequence of putting photos and other information on social network websites, or about the various privacy settings available,\" said Matthew Newman.\\nHe noted that this could cause problems later if the users had no way of deleting embarrassing material when applying for jobs. However, he stressed that it would not give them the right to ask for material such as their police or medical records to be deleted.\\nAlthough the existing directive already contains the principle of \"data minimisation\", Mr Newman said that the new law would reinforce the idea by declaring it \"a right\".\\nOther measures in the bill include an obligation on all firms to notify users and the authorities about data lost through hacking attacks or other breaches \"as soon as possible\".\\nMs Reding said that she would expect that under normal circumstances this would mean within 24 hours.\\nThe commissioner said that firms would have to explicitly seek people\\'s permission to use data about them and could not proceed on the basis of \"assumed\" consent in situations where approval was required.\\nHer proposed law says that internet users must also be notified when their data is collected, and be told for what purpose it is being processed and for how long it will be stored.\\nThe bill also suggests people must be given easier access to the data held on them, and should have the right to move it to another provider in addition to the right to have it deleted.\\nHowever, the commissioner said that she recognised there were some circumstances under which this right would not apply.\\n\"The archives of a newspaper are a good example. It is clear that the right to be forgotten cannot amount to a right of the total erasure of history,\"Ms Reding told DLD delegates.\\nIf approved the law would create a pan-EU set of data privacy rules for the first time. These would also apply to overseas companies active in the 27-member bloc, even if they handled the data on servers based in other parts of the world.\\nThe commissioner suggested that this would simplify regulations and reduce the administrative burden on firms, saving them around 2.3bn euros ($3bn; Â£1.9bn) a year.\\nHowever, Microsoft Europe\\'s chief operating officer, Ron Zink, was quoted by the Financial Times as saying that the proposalsmight be \"too prescriptive\".\\nFacebook also signalled that it wanted more information about the scope of the data that the EU thought users should be able to control.\\nBut it added: \"We welcome vice-president Reding\\'s view that good regulation should encourage job creation and economic growth rather than hindering it, and look forward to seeing how the EU Data Protection Directive develops in order to deliver these two goals while safeguarding the rights of internet users.\"\\nGoogle and Yahoo said that they were not able to provide statements at this time.\\nFirms that failed to abide by the proposed new rules could be fined as much as 1% of their global revenues, according to a draft document obtained by the Reuters news agency. The FT had reported in December that the sum could be as much as 5%.\\nThe new rules will need to be approved by the EU\\'s member states and ratified by the European Parliament. As a result it could take two or more years for the new directive to come into effect.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"League One title favourites Blackburn Rovers suffered defeat on the opening day of the season as Tony Mowbray's side lost 2-1 at Southend United.\", 'negatives': [], 'positives': [\"First-half goals from Ryan Leonard and Michael Kightly put the Shrimpers in control at Roots Hall.\\nPhil Brown's side were able to hang on to secure all three points despite a fine free-kick from Rovers captain Charlie Mulgrew in the second half.\\nSouthend - who missed out on the play-offs by just a point last season - went in front in the 28th minute when an unmarked Leonard volleyed home a right-wing corner from Michael Timlin.\\nThe goal justified Southend's decision to turn down offers from both Millwall and Sheffield United in the summer and the Shrimpers were celebrating again in the 38th minute with Kightly on target.\\nThe winger - who returned to the club in the summer after leaving Burnley - netted from eight yards.\\nAnd his effort proved to be the winner as Rovers were unable to build on Mulgrew's fine 30-yard free-kick eight minutes into the second half.\\nMatch report supplied by the Press Association.\\nMatch ends, Southend United 2, Blackburn Rovers 1.\\nSecond Half ends, Southend United 2, Blackburn Rovers 1.\\nFoul by Marc-Antoine Fortuné (Southend United).\\nCharlie Mulgrew (Blackburn Rovers) wins a free kick in the attacking half.\\nAttempt saved. Theo Robinson (Southend United) header from the centre of the box is saved in the centre of the goal.\\nCorry Evans (Blackburn Rovers) wins a free kick in the defensive half.\\nFoul by Michael Kightly (Southend United).\\nSubstitution, Southend United. Stephen McLaughlin replaces Jermaine McGlashan.\\nAttempt missed. Marc-Antoine Fortuné (Southend United) header from the centre of the box is just a bit too high.\\nAttempt missed. Jermaine McGlashan (Southend United) right footed shot from outside the box is just a bit too high.\\nHand ball by Dominic Samuel (Blackburn Rovers).\\nDarragh Lenihan (Blackburn Rovers) wins a free kick in the defensive half.\\nFoul by Theo Robinson (Southend United).\\nCorner,  Southend United. Conceded by Corry Evans.\\nAttempt blocked. Marc-Antoine Fortuné (Southend United) right footed shot from the centre of the box is blocked.\\nFoul by Dominic Samuel (Blackburn Rovers).\\nJermaine McGlashan (Southend United) wins a free kick on the right wing.\\nFoul by Derrick Williams (Blackburn Rovers).\\nTheo Robinson (Southend United) wins a free kick on the left wing.\\nSubstitution, Southend United. Theo Robinson replaces Simon Cox.\\nFoul by Ryan Nyambe (Blackburn Rovers).\\nSimon Cox (Southend United) wins a free kick in the attacking half.\\nSubstitution, Blackburn Rovers. Harry Chapman replaces Elliott Bennett.\\nAttempt saved. Marc-Antoine Fortuné (Southend United) header from very close range is saved in the top left corner.\\nDerrick Williams (Blackburn Rovers) is shown the yellow card for a bad foul.\\nFoul by Derrick Williams (Blackburn Rovers).\\nJason Demetriou (Southend United) wins a free kick in the attacking half.\\nCorner,  Southend United. Conceded by Charlie Mulgrew.\\nRyan Nyambe (Blackburn Rovers) is shown the yellow card for a bad foul.\\nFoul by Ryan Nyambe (Blackburn Rovers).\\nMichael Kightly (Southend United) wins a free kick on the left wing.\\nSubstitution, Blackburn Rovers. Corry Evans replaces Richard Smallwood.\\nAttempt missed. Jason Demetriou (Southend United) right footed shot from outside the box is close, but misses the top right corner.\\nCorner,  Southend United. Conceded by Darragh Lenihan.\\nAttempt missed. Liam Feeney (Blackburn Rovers) left footed shot from outside the box misses to the right.\\nCharlie Mulgrew (Blackburn Rovers) wins a free kick in the attacking half.\\nFoul by Simon Cox (Southend United).\\nAttempt missed. Michael Timlin (Southend United) right footed shot from outside the box is just a bit too high.\\nSubstitution, Blackburn Rovers. Liam Feeney replaces Bradley Dack.\\nFoul by Danny Graham (Blackburn Rovers).\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"The Blackpool board have accepted responsibility for the club's relegation to League Two and promised a review into how the club is run.\", 'negatives': [], 'positives': ['A 5-1 defeat at Peterborough in their last game of the season saw the Tangerines drop into the fourth tier.\\nBoss Neil McDonald is unsure if he will be in charge of the club next season.\\n\"An urgent board meeting has been called to discuss the club\\'s future and implement plans to halt further decline,\" said a club statement.\\n\"The board takes full responsibility for the position we now find ourselves in.\\n\"Mistakes have been made in the last few years and we continue to pay for some of them, whilst learning from others.\"\\nA number of supporters have demonstrated against the way chairman Karl Oyston and his father Owen, who is Blackpool\\'s owner, have run the club in recent seasons.\\nProtests took place outside Bloomfield Road at their final home game of the season against Wigan and continued at Peterborough.\\nAfter their one-season stay in the Premier League in 2010-11, Blackpool spent three seasons in the Championship, but have now suffered back-to-back relegations.\\n\"We understand that the supporters care passionately about the club and want to see it succeed,\" added the statement.\\n\"Fan representation on the board has already been initiated. A democratic process for fan board membership will be implemented for the coming season and it is hoped that the fans will have a large say in shaping future policy.\\n\"The board does not underestimate the challenge ahead and will now re-focus its energies to rectify things on the pitch and try to repair some of those off it, whilst sadly accepting that some of the issues may not be curable.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Surgeons saved a worker\\'s hand which had been crushed in an industrial mangle by sewing it inside a \"pocket\" in his abdomen for three weeks.', 'negatives': [], 'positives': ['Anthony Seward, 23, got his hand trapped at Heathcoat Fabrics in Tiverton, Devon, in August 2016.\\nExeter magistrates heard that a broken barrier guard had not been replaced.\\nHeathcoat admitted a health and safety offence and was fined Â£300,000. The firm told the court the accident was \"a complete tragedy\".\\nWarning: This story contains graphic images that some readers may find upsetting.\\nIt also said Mr Seward\\'s injury was \"deeply regretted by the company\".\\nMore on this story and other Devon news\\nBarrister Christian DuCann, representing Heathcote, said it was a \"complete tragedy\" for a young man early in his career.\\n\"This was an avoidable accident,\" he added.\\nSurgeon James Henderson said Mr Seward\\'s hand was sewn inside the skin of his abdomen for three weeks.\\nThe procedure at Southmead Hospital and Spire Bristol, called a Pedicled Abdominal Flap, allowed the skin to heal and get a blood supply from the hand.\\nIt was then separated from the abdomen and the skin was folded over to cover the entire hand.\\nMr Seward has now had two operations to separate his fingers and is able to move them independently.\\n\"It\\'s now quite rare as we don\\'t see that many injuries that require this treatment,\" said Mr Henderson.\\nThe \"very old-fashioned procedure\" which was first described by surgeons in 1900, was used a lot during World War Two to treat injured servicemen.\\nIt has also been used on soldiers coming back from Afghanistan.\\nMr Henderson said Mr Seward\\'s fingers could be improved with transplants from his toes \"to give him a good fingertip for gripping fine objects\".\\n\"Normally there are more sophisticated ways of transplanting tissue but Anthony\\'s injury was so severe it was decided to do it this way,\" he added.\\nMr Seward lost his job as a retained fire fighter as a result of the accident.\\nSpeaking after the case, Mr Seward said: \"It\\'s been a long, painful and difficult 12 months.\\n\"I\\'d like to say thank you to the doctors and nurses paramedics that treated me at Bristol.\\n\"They did a phenomenal job and I don\\'t think they could have done any better.\"\\nMr Seward said he is making a compensation claim against the firm.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Hundreds of men appear to have gone missing after crossing from rebel-held areas of Aleppo into government territory, UN officials say.', 'negatives': [], 'positives': ['Forces led by Syria\\'s government have seized at least 85% of eastern parts of the city from rebels in recent weeks.\\nTens of thousands of civilians have fled those districts. Up to 10,500 left during a humanitarian pause on Thursday alone, Russian officials say.\\nRebels were also reportedly stopping people from leaving, the UN said.\\nRupert Colville, the spokesman for the UN High Commissioner on Human Rights, said up to 100,000 people were trapped in \"ever-shrinking\" areas of eastern Aleppo.\\nReports differ on how many people remain and how many have fled eastern Aleppo, but Mr Colville said the UN had gathered evidence that \"hundreds\" of men may have disappeared after leaving for government-held areas.\\n\"Given the terrible record of arbitrary detention, torture and enforced disappearances by the Syrian government, we are of course deeply concerned about the fate of these individuals,\" he said.\\nReports cited by the UN say men aged between 30 and 50 were separated from their families. Other displaced people reported being taken in for questioning, and having their identity cards confiscated.\\nMr Colville also said rebel groups could be committing a war crime by preventing people from fleeing to safety, and \"using civilians as pawns\".\\nRussia, an ally of Syrian President Bashar al-Assad, said fighting was temporarily suspended on Thursday to allow civilians to leave.\\nRussian Defence Ministry official Sergei Rudskoi said up to 10,500 people, including 4,015 children, had left, although this figure not been confirmed. Military officials earlier put the figure at 8,000.\\nRussian Foreign Minister Sergei Lavrov has said the fighting will continue as long as rebels remain.\\nThe UK-based Syrian Observatory for Human Rights, a network of activists monitoring the violence, said ground forces continued their offensive, and that rocket attacks and air raids were launched overnight.\\nMeanwhile, the civilian rescue group known as the White Helmets said 46 civilians were killed and another 230 injured on Thursday in east Aleppo. Three barrel bombs carrying chlorine gas were dropped, it added.\\nAfter several previous attempts to flee the besieged area of Salhine, one man, Abdel Hamid, managed to leave with his wife and 10 children on Thursday.\\n\"Most of the people around me were saying \\'in any case we will die, so let\\'s leave together\\'. That encouraged me and we left,\" he told the AFP news agency.\\n\"I left my house behind... but I have secured my children\\'s right to live. With each step I took I felt like I was getting closer to life itself.\"\\nMr Lavrov confirmed that Russian and US military experts would meet in Geneva on Saturday to discuss ways of ending the violence.\\nHe said the talks would focus on plans to evacuate rebel fighters from eastern Aleppo, but the US State Department said the subject had yet to be agreed. Rebels have said they intend to fight on.\\nSeparately on Friday, the UN General Assembly voted 122 to 13 to demand an immediate ceasefire in Syria, allow urgent humanitarian aid access throughout the country and an end to all sieges, including in Aleppo.\\nGeneral Assembly votes are non-binding but can carry political weight.\\n\"This is a vote to stand up and tell Russia and Assad to stop the carnage,\" the US ambassador to the UN, Samantha Power, told the assembly before the vote.\\nAleppo was once Syria\\'s largest city and its commercial and industrial hub before the uprising against President Bashar al-Assad began in 2011.\\nIt has been divided in roughly two since mid-2012. But in the past year, Syrian troops have broken the deadlock with the help of Iranian-backed militias and Russian air strikes, reinstating a siege in early September.\\nCorrection: A previous version of this article mistakenly reported that the UN said boys as well as men were missing.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Heather Olver and Lauren Smith's Rio 2016 hopes were boosted as they came from behind to win the women's doubles at the US International in Florida.\", 'negatives': [], 'positives': [\"Olver and Smith beat Thailand's top seeds Puttita Supajirakul and Sapsiree Taerattanachai 18-21 21-19 21-19.\\nThe English champions are expected to rise from their current world ranking of 30 in January.\\nThe top 16 pairs in the world rankings on 5 May will qualify for the Olympics in Rio next summer.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Uefa's offices have been searched by Swiss police after ex-secretary general Gianni Infantino, now Fifa president, was named in papers leaked from Panamanian law firm Mossack Fonseca.\", 'negatives': [], 'positives': ['Media playback is not supported on this device\\nIt has emerged Infantino co-signed a television rights contract in 2006 with two businessmen who have since been accused of bribery.\\nInfantino has denied any wrongdoing.\\nUefa says it is providing police with all relevant documents in its possession and \"will co-operate fully\".\\nCross Trading, owned by Hugo Jinkis and his son, Mariano, bought TV rights for Uefa Champions League football in 2006 and immediately sold them on to Ecuadorian TV broadcaster Teleamazonas for almost three times the price.\\nNews of the contract came to light after 11 million documents were leaked from Mossack Fonseca.\\nUefa initially denied doing business with any of the 14 people who have been indicted by the FBI in its investigation into corruption in world football.\\nIt has now told the BBC the TV rights were sold to the highest bidder in an open and competitive tender process.\\nA senior Fifa source has told the BBC the deal should be examined by the governing body\\'s ethics committee in the interests of transparency.\\nMore to follow.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Comedy Central was forced to repeat an old episode of South Park after a power cut prevented this week's scheduled episode from being finished.\", 'negatives': [], 'positives': ['Computers at South Park Studios in Los Angeles were down for three hours on Tuesday, halting work on the episode Goth Kids 3: Dawn of the Posers.\\nCo-creator Trey Parker told fans \"it sucks\" but admitted it was inevitable.\\n\"After all these years of tempting fate by delivering the show last minute, I guess it was bound to happen,\" he said.\\nIt is the first time he and Matt Stone have missed one of their tight deadlines in 16 years, after famously starting each show from scratch just six days before it is due to air.\\nMost animated TV shows are written several months in advance, but South Park\\'s creators hope to keep the show current and fresh by working to a tight deadline.\\nThe US office of Comedy Central said in a statement on Wednesday: \"From animation to rendering to editing and sound, all of their computers were down for hours and they were unable to finish episode 1704, Goth Kids 3: Dawn of the Posers, in time for air tonight.\"\\nThe planned episode was replaced with a repeat of Scott Tenorman Must Die, an episode featuring British band Radiohead, which fans had voted their second favourite of all time in a poll in 2011.\\nThe team posted pictures of the blackout on the show\\'s Twitter feed and revealed that Goth Kids 3 was now scheduled for next week.\\nEarlier this year Parker and Stone\\'s musical The Book of Mormon opened to rave reviews in London\\'s West End, after a sell-out debut on Broadway.\\nThey confirmed two years ago that they would continue animating the adventures of South Park\\'s Stan, Kyle, Kenny and Cartman until 2016.\\nThe show recently kicked off its 17th series in the US to its highest ratings since 2011, with 4.3 million viewers tuning in across three broadcasts.\\nThe taboo-breaking animation is broadcast on Comedy Central in the UK at a week\\'s delay and Goth Kids 3 is now expected to air on 30 October at 22:00 BST. Scott Tenorman Must Die will be broadcast in its original slot on 23 October.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Ulster made it three wins from five Pro12 games this season with a bonus point triumph over Cardiff Blues.', 'negatives': [], 'positives': [\"Media playback is not supported on this device\\nRhys Patchell kicked three penalties for the Blues, but Ulster led 12-9 at half-time thanks to tries by Andrew Trimble and Paul Marshall.\\nUlster stretched their advantage when Nick Williams finished a controlled drive over the line by the home pack.\\nCentre Stuart McCloskey's try secured the bonus point before Josh Navidi's try gave the Blues forlorn hope.\\nWith eight minutes to go, fly-half Patchell landed his fourth penalty to bring the visitors to within seven points, but they failed to close the gap further.\\nThe result means the Blues have lost to all of the Irish teams in their last four Pro12 fixtures, with the opening day Zebre fixture remaining their only victory of the campaign.\\nAfter a disappointing display away to Edinburgh a week earlier, this was a third successive home win with a bonus point for Ulster and it took their unbeaten league record at their Belfast base to 14 games.\\nDanny Wilson's visitors had seemed set for a 9-5 half-time advantage, only for Paul Marshall to register one of his trademark close-range tries in first-half stoppage time.\\nIn the 18th minute international winger Trimble got over in the right-hand corner for Ulster's first try.\\nIt was the 31-year-old's 43rd try in the league competition, just one behind the Ulster record held by fellow wing Tommy Bowe.\\nJust before the break, with visiting number eight Josh Turnbull in the sin bin for accidentally kicking Marshall in the face, the home scrum-half nipped over to get Ulster's second try, which Ian Humphreys converted.\\nThe tries early in the second half by man of the match Williams and McCloskey seemed to have sent Ulster home and dry.\\nBut the Blues were never out of it, and had renewed hope when captain Navidi got their 57th-minute try soon after prop Wiehahn Herbst had been yellow-carded for slowing down play.\\nLate in the game, Cardiff's Aled Summerhill became the third player sin-binned after his lifting challenge on Craig Gilroy was deemed to be dangerous.\\nUlster: Ludik, Trimble, Arnold, McCloskey, Gilroy, Humphreys, P. Marshall, Black, Herring, Herbst, Stevenson, van der Merwe, Wilson, Reidy, Williams.\\nReplacements: Cave for Arnold (54), Jackson for Humphreys (51), Warwick for Black (54), Browne for Stevenson (54), Lutton for Wilson (55).\\nNot used: Andrew, W. Faloon, Shanahan.\\nSin bin: Herbst (55).\\nCardiff Blues: Fish, Summerhill, Isaacs, Thomas, R. Smith, Patchell, Knoyle, Hobbs, Rees, Mitchell, Reed, Down, Dolan, Turnbull, Navidi.\\nReplacements: T. Davies for Hobbs (76), Filise for Mitchell (52), Cook for Dolan (55).\\nNot used: E. Lewis, Dicomidis, Jones, J. Evans, G. Smith.\\nSin bin: Turnbull (40), Summerhill (74).\\nAtt: 14,000\\nRef: Ben Whitehouse (Wales).\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Nottinghamshire have signed Surrey left-arm pace bowler Mark Footitt on a deal until the end of the 2019 season.', 'negatives': [], 'positives': ['Footitt, 31, asked to be released from his contract with Surrey as he had been unable to settle in London following his move from Derbyshire in 2016.\\n\"I am extremely grateful to Surrey, and Alec Stewart in particular, for their understanding,\" said Footitt.\\nHe will help fill the gap left by Luke Fletcher, who will miss the remainder of the season because of a head injury.\\n\"I am hugely appreciative of their decision to allow me to leave and be back with my family.\"\\nFootitt, who has previously been included in England Test squads without making his international debut, has returned to the county with whom he made his first-class debut in 2005.\\nNotts director of cricket Mick Newell said: \"He\\'s obviously blossomed as a cricketer since he was last here.\\n\"We believe he can help us go where we want to go for the rest of this season and in the following two seasons at least.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Three dogs found dumped in a river in Banbridge, County Down are thought to have been beaten and drowned.', 'negatives': [], 'positives': ['The three young terrier-type dogs were spotted by a passerby in the River Bann on Sunday.\\nA spokesperson for the USPCA said the breed is sometimes used in illegal activities, such as badger baiting.\\nA source  told the charity: \"It\\'s possible the dogs were pitted against badgers in a so-called \\'chute\\' and have \\'turned away\\' from the badgers.\\n\"Dogs that do that are considered to be of no use and are often disposed of in ruthless fashion.\"\\nThe charity said there was no evidence the dogs had been used to fight other animals, but they were \"caked in mud\".\\nIt is believed they had been in the water for some time.\\nThe USPCA is offering a Â£500 reward in the hope that somebody will come forward with information.\\nAnyone who saw anything suspicious in that area should contact either the police, the USPCA or the animal welfare Department in Armagh, Banbridge and Craigavon Council.\\nThe stretch of river is close to Lawrencetown between Gilford and Banbridge.\\nA small road runs alongside it - and investigators think the dogs may have been dumped from a car.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Tolls on the Severn crossings will not be subject to VAT when they return to public ownership, the Department for Transport has confirmed.', 'negatives': [], 'positives': ['Transport Minister Robert Goodwill said the private concession on the bridges is on course to finish in 2018.\\nBut he said it would still take up to two years to pay off other debts worth around £88m.\\nMonmouth MP David Davies welcomed the news, in a letter from Mr Goodwill, but noted he had not said tolls would fall.\\nCurrent toll charges range from £6.40 for cars to £19.20 for lorries, 20% of which is made up of VAT.\\nIn the letter to Mr Davies, who also chairs the Welsh Affairs Committee at Westminster, Mr Goodwill said:\\n\"Once in public ownership VAT will no longer be payable on the tolls.\\n\"Under the Severn Bridges Act 1992 it would be possible to reduce tolls to reflect the fact that VAT was no longer payable.\"\\nMr Davies said the letter followed a meeting with the minister last month, also attended by other MPs on the committee.\\n\"All of us would like to see action taken to reduce the tolls,\" he said.\\n\"Unfortunately, the minister has not said whether the tolls would fall and that is the issue I would like to pin down the government on.\"\\nThe MP said the committee has estimated ongoing maintenances costs for the bridges would be around a third of the current toll price and nobody had contradicted that.\\n\"I therefore think we must now demand a clear plan for the post concession period with a significant reduction in the tolls,\" he said.\\nMPs are debating the future of the bridge tolls in a debate at Westminster Hall on Wednesday.\\nLast month there were cross-party calls for the charges to be cut drastically from 2018.\\nThe Welsh government has called for control of the bridges to be devolved.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The European Parliament has approved a package of major reforms to the EU Common Fisheries Policy (CFP), designed to cut waste and stop overfishing in European waters.', 'negatives': [], 'positives': ['Under the plan, the existing system of fishing quotas - which often leads to tonnes of perfectly good fish being dumped at sea - will be reformed.\\nFor the first time MEPs have legislative power in this policy area. They are proposing amendments to a European Commission reform plan for the CFP. But there will be more negotiations with the 27 fisheries ministers this year before the changes become EU law.\\nWhat is wrong with the existing system?\\nThe European Commission says the current policy is wasteful - 75% of stocks are still overfished and catches are only a fraction of what they were 15-20 years ago. Catches of cod for example have declined by 70% in the last 10 years.\\nThe Commission believes that the \"top down\" system of micro-managing fisheries from Brussels is failing and that decision-making needs to be decentralised.\\nThe method of allocating fishing quotas EU-wide has contributed to the serious depletion of stocks, the Commission says. Crews that haul in more than the agreed quota often throw large quantities of dead fish back into the sea - the much-criticised \"discards\".\\nThe system is not meeting the European market\\'s needs. Fish imported from non-EU countries now accounts for two-thirds of the fish sold in the EU.\\nWhat was the current policy designed to do?\\nThe idea of agreed quotas was to make Europe\\'s fishing stable and sustainable and prevent conflicts arising where foreign trawlers fish in a country\\'s waters.\\nThe quota system - called Total Allowable Catches (TACs) for each fish stock - is at the heart of the CFP, launched in 1983. The TACs are based on a country\\'s previous catches.\\nOver time Europe\\'s fishing fleets have grown too large for the dwindling fish stocks, but fisheries ministers are often reluctant to see their national TACs reduced. The Commission says the CFP has been plagued by short-term decision-making.\\nHow does the EU plan to protect fish stocks now?\\nThe practice of discards must be phased out, the Commission says. In future trawlers will have to land their entire catch - and that means member states will have to ensure that better technology is installed to monitor compliance.\\nThe Commission says fisheries should be managed on an \"ecosystem\" basis - there needs to be more flexibility in the system and more scientific data needs to be collected on a larger number of fish species.\\nThe parliament\\'s lead negotiator, German Social Democrat Ulrike Rodust, says the EU should scrap the annual bargaining over quotas, replacing that with an eco-friendly system based on \"maximum sustainable yield\" (MSY).\\nUnder MSY, there would be a limit to the catch for each species based on its reproduction rate - in other words, the rate at which the stock is replenished. Ms Rodust accepts that for MSY to become the benchmark in 2015, as outlined in her legislative report, more scientific data will be needed.\\nA new funding mechanism will be set up for 2014-2020 called the European Maritime and Fisheries Fund (EMFF), with a budget of 6.7bn euros (Â£6bn).\\nPart of that fund will help support small-scale coastal fleets. Member states will be able to restrict fishing in a zone within 12 nautical miles of the coast, up to the year 2022.\\nBut Ms Rodust\\'s report objects to some Commission proposals to make fishing more market-driven.\\nThe Commission said large fleets should be allocated transferable catch shares, called \"concessions\", which they would be able to trade, in response to local conditions.\\nMs Rodust argues that such choices should remain in the hands of national authorities, not the EU.\\nShe does not want \"an allocation system being imposed at European level\", and instead \"member states will remain free to establish - or not to establish - a system of transferable fishing concessions\".\\nWhat is the time frame for the changes?\\nOriginally the Commission wanted the new CFP to be in place by 1 January this year, but the timetable has slipped.\\nMEPs now hope to reach a final deal on the reforms with the Council (EU governments) in June.\\nThe plan is to start adopting the MSY approach to fisheries management in 2015, and from 2014 discards are to be phased out.\\nWhat has been the response so far to the plan?\\nThe UK government is enthusiastic. UK Fisheries Minister Richard Benyon said more work must be done to encourage consumers to buy a wider range of fish.\\nThat message was echoed by Sainsbury\\'s, which said \"it is imperative that supermarkets such as Sainsbury\\'s help create the consumer demand for lesser known species by promoting them to our customers\".\\nScottish Fisheries Secretary Richard Lochhead said the EU reforms \"need to be a lot more radical\".\\nHe praised the Commission\\'s emphasis on conservation of stocks, but said more carefully targeted measures would be needed to stop discards.\\nThe environmental group Oceana called for proper management plans for a much larger number of fish stocks.\\nIt voiced concern that the Commission plan \"doesn\\'t establish any mechanisms to deal with landed by-catch\". There is a risk that the surplus fish landed - instead of being discarded at sea - will simply be sold and that could incentivise overfishing, Oceana says.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Jacques Henri Lartigue has been described as the best known amateur in the history of photography.', 'negatives': [], 'positives': ['Through his black-and-white photographs, he captured the world around him, primarily in his native France, and was one of a handful of photographers who helped define what is now called street photography.\\nYet until his 60s he was unknown, simply taking pictures for his own pleasure.\\nHis affluent background  allowed him to pursue his hobbies and indulge his passion for motorcars and sport, recording the modern age with his camera.\\nHis photographs exude an air of freedom and are seemingly composed with little effort, each frame spontaneously conveying the emotion of the moment.\\nIt was 1963 when Lartigue\\'s work was seen by John Szarkowski, curator of the Museum of Modern Art in New York, who offered him a solo exhibition on the spot, propelling his work to the highest level.\\nYet his colour photography is virtually unknown, save for a few autochromes exhibited alongside his more familiar work.\\nLartigue was undeniably a fan of experimentation with the camera - a pioneer who used the camera to record life as he felt it, not just as a reflection of itself.\\nHe was also a painter, so his adoption of colour photography should not be a surprise.\\nYet the early process had its limitations.\\nHe shot colour pictures from 1912-27 before abandoning it due to the bulk of the equipment required at that time and because the process was too slow to record a spontaneous moment.\\nBut by the 1950s, those limitations had long since passed, and his Rolleiflex and Leica were no strangers to colour film.\\nHe wrote at the time: \"How can one not be moved by the harmony of colours nature offers us?\\n\"As long as neither is too harsh nor too sharp, colour photography seems to me, because of a certain blurriness, to best be able to express charm and poetry - a poetry that can very well accommodate a touch of humour.\"\\nHis love of colour was years ahead of its time, as it was not until the mid-1970s that colour photography began to make inroads in to the serious art market.\\nIn 1979, Lartigue donated his entire photographic collection to the French state.\\nHe died in Nice in 1986, leaving behind more than 100,000 photographs, 7,000 diary pages and 1,500 paintings.\\nAll photographs courtesy Jacques Henri Lartigue / © Ministere de la Culture - France / AAJHL from Lartigue: Life in Color by Martine D\\'Astier and Martine Ravache, published by Abrams.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"An estimated 500,000 disabled children are being excluded from South Africa's education system, US-based Human Rights Watch (HRW) says in a report.\", 'negatives': [], 'positives': ['HRW says the government has discriminated against disabled children in its allocation of school places.\\nChildren are excluded from mainstream schools and forced to wait years for places at special schools, it says.\\nThe government said it was disappointed by the report, which \"trivialised\" efforts to help disabled children.\\nIn a statement, South Africa\\'s Department of Basic Education said that HRW had failed to include the ministry\\'s submissions to the final report.\\n\"It is almost as if there is an attempt to sensationalise the very real and very serious challenges faced by learners with special needs,\" it said.\\nBBC Africa Live: News updates\\nThe department said it was \" working at various levels of government to educationally enrich the lives of children with disabilities\".\\nBut campaigners say the government needs to admit that it is not providing quality education to all of its children.\\n\"The job is not done until all children count just the same in the education system,\" said Elin Martinez, a children\\'s rights researcher and author of the report.\\nHuman Rights Watch researchers also found that inadequate teacher training and understanding of children\\'s disabilities meant children with disabilities were not properly treated in classrooms.\\nIn some cases, children suffered physical violence and neglect in schools, they added.\\nA mother of an eight-year-old boy with Down\\'s syndrome told HRW that her child was denied admission because of his illness.\\nAnd parents of children with disabilities were often asked to pay additional fees, HRW said.\\nThe 94-page report from the international pressure group found that many adolescents with disabilities lacked basic life skills that should be taught in school and were facing difficulties in getting employment.\\nIn 2007, South Africa was one of the first countries to ratify the UN Disability Rights Treaty, which requires the government to promote an inclusive education system.\\nHRW said the government should adopt a new policy and legislation that would ensure equal learning opportunities for people with disabilities.\\nHowever, the education department said it was working hard to improve data-gathering and screening that would help children with disabilities to go to \"neighbourhood schools and receive support in inclusive settings from an early age\".'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Chancellor George Osborne has vowed to create a \"more outward-looking, global-facing Britain\" following the UK vote to leave the European Union.', 'negatives': [], 'positives': ['And even closer economic ties between the UK and US are in the \"overwhelming interest of both countries\", he has written in the Wall Street Journal.\\nAlthough the UK is leaving the EU, \"we are not quitting the world\", he said.\\nHe is due to travel to New York, Singapore and China for talks with major investors in the coming weeks.\\nThe UK is the largest trading partner in Europe for the United States, and in turn the US is the largest single destination for UK exports.\\nUK exports to the US totalled Â£88bn in 2014 - about 17% of total UK exports - and last year the UK was the US\\'s sixth largest trading partner.\\nMr Osborne said: \"While Britain\\'s decision to leave the EU clearly presents economic challenges, we now have to do everything we can to make the UK the most attractive place in the world to do business.\\n\"Britain and the US have been at the forefront of open trade in the last 200 years and pursuing a stronger relationship with our biggest trading partners is now a top priority.\\n\"That\\'s why I am travelling to the US, China and Singapore in the coming weeks and why my message to the world is that Britain may be leaving the EU, but we are not quitting the world.\"\\nThe chancellor said the UK would continue to be \"a beacon for free trade, democracy and security, more open to that world than ever\".\\nMr Osborne will be meeting finance leaders in New York on Monday, and has spoken to Paul Ryan, speaker of the US House of Representatives, twice in recent weeks.\\nHe will also meet US Treasury Secretary Jack Lew in London this week.\\nAnd in the Wall Street Journal he said the question now \"is not what Britain is leaving; it is what Britain will become\".\\n\"One lesson of the referendum is that too many of our citizens feel economic progress is no longer benefiting them.\\n\"Ever-higher welfare to make good lost incomes is not the answer; attracting private investment and good jobs beyond our major cities is.\\n\"By managing day-to-day spending, we should commit to major investments in national infrastructure, including new roads, high-speed railways and digital networks.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Josh Taylor won the Commonwealth super lightweight title in just his seventh professional fight, stopping Dave Ryan in the fifth round at Meadowbank.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nRoared on by a vociferous Edinburgh crowd, the 25-year-old from Prestonpans was impressively polished throughout.\\nThe experienced Ryan, a former holder of this vacant belt, was floored by a left hook in the third round.\\nAnd the referee stepped in after a crunching body shot left the 33-year-old from Derby reeling.\\nTaylor, the 2014 Commonwealth Games gold medallist, was sharp from the first bell and manager Barry McGuigan is already looking ahead to a potential showdown with Scotland\\'s WBA champion Ricky Burns.\\n\"With the progress this kid is making we can talk about that fight, certainly in nine months time to a year,\" McGuigan told BBC Scotland.\\n\"Burns has got to be the target if he remains the champion. I\\'m not being disrespectful. We\\'re not ready for it yet. He\\'s got work to do.\\n\"I just think Josh makes progress so quickly. We\\'re going to put him in with guys that will test him and bring him into the later rounds.\"\\nRyan, out of the ring for more than a year after a back injury, was immediately rattled by good combination work from Taylor, who worked his opponent\\'s body at every opportunity.\\nTaylor, who had never previously gone beyond two rounds, started the third in explosive fashion, knocking Ryan down with a flashing left.\\nBy the end of the fourth, the Ryan corner were working hard to stem the flow of blood from a cut just underneath their man\\'s right eye.\\nTaylor continued to punish the Englishman with fierce and precise body work and, although Ryan got up from the canvas once more for a standing count of eight, referee Michael Alexander soon called the fight to a halt.\\n\"I tried to stay nice and relaxed and I think that showed in the performance,\" Taylor told BBC Scotland.\\n\"I took a wee moment to soak in the atmosphere which was amazing for just my seventh fight. I loved every single minute.\\n\"It\\'s definitely up there with winning the Commonwealth Games gold, if not better.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A Japanese court has blocked the restarting of two nuclear reactors in the western city of Takahama, after local people raised safety concerns.', 'negatives': [], 'positives': ['The plant had already obtained approval from the country\\'s nuclear watchdog.\\nBut locals had petitioned the court in Fukui prefecture, where Takahama is located, to intervene, saying it would not withstand a strong earthquake.\\nAll 48 commercial reactors in Japan remain offline following 2011\\'s Fukushima disaster.\\nThe BBC\\'s Rupert Wingfield-Hayes in Tokyo says the ruling is a serious blow for Prime Minister Shinzo Abe\\'s push to have the reactors restarted.\\nMr Abe has said the shutdown is damaging the struggling economy, forcing Japan to import expensive fossil fuels to make up the power shortfall.\\nThe operators of Takahama plant, Kansai Electric, said the plant met heightened safety standards brought in by the Nuclear Regulation Authority (NRA) after Fukushima.\\nBut the court agreed with nine local residents who filed an injunction, and ruled that the company had been overly optimistic in assuming that no major quake would hit the region, national broadcast NHK reports.\\nIt also criticised the NRA safety standards as \"lacking rationality\".\\nKansai Electric said it was considering appealing against the ruling.\\nBefore the accident, caused by a massive quake and tsunami, about 30% of Japan\\'s power was nuclear generated.\\nSo far only two reactors - in Kagoshima prefecture in the far south - have been approved for restart. They are expected to become operational later this year, but this move is also being challenged in court.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Nigeria's President Muhammadu Buhari has hit the ground running after assuming office, meeting his military chiefs and the leaders of neighbouring Niger and Chad, countries which have been helping in the fight against Boko Haram.\", 'negatives': [], 'positives': ['In his inaugural speech Mr Buhari expressed his resolve to tackle the militant Islamist group. He announced the relocation of the military command and control centre from the capital Abuja, 800km (500 miles) to Maiduguri, the main city at the heart of the insurgency, until the conflict is resolved.\\nThe aim is to centralise operations close to the action, cut the bureaucracy and speed up decision-making.\\nThe policy and administrative arms of the military have been accused of being detached from the reality of soldiers on the frontline.\\nComplaints from troops about inadequate supplies of equipment and poor welfare have often been denied, downplayed or ignored by the authorities.\\nOn occasion, disgruntled soldiers refused to fight, and one group of soldiers was convicted after shooting at their own commanding officer.\\nHowever, the new strategy has not gone down well with some top military men, who view it as a  ymbolic, populist move by President Buhari, attempting to set himself apart from the previous administration under Goodluck Jonathan.\\nThere are also concerns it could further complicate existing operations on the ground.\\nMaiduguri is already home to the 7th Infantry Division, set up in 2013 specifically to fight Boko Haram.\\nIts 8,500 troops have fought in a conflict that has morphed from urban-based warfare in Maiduguri, to a territorial struggle across the outlying towns and villages of the expansive region.\\nBut a presidential spokesman told the BBC that the Nigerian army was by its own assessment \"ill-equipped and poorly trained, and even lacks the commitment and the will to fight\".\\n\"If you are not in the kitchen, you will not feel the heat,\" Garba Shehu said, referring to the fact that military chiefs have been based in Abuja, far from the front line.\\nMr Shehu criticised the previous system, where \"issues of basic supply to the troops had to be referred to Abuja, several hundred miles away\".\\nAnd we do not yet know how this new strategy will change the way the army tackles Boko Haram on the front line.\\nThe army insists this new command will add vigour to the counter-insurgency campaign, and a similar centre is also being set up in the town of Yola, from where air force operations are being launched.\\nThe president\\'s announcement also coincides with recent significant successes on the front line, inspired by the issuing of much-needed advanced equipment.\\nOne reason often given for the failures against Boko Haram was the decision by the US to withhold military support following reports of alleged human rights abuses by Nigerian soldiers.\\nAmnesty International recently released a report saying the alleged abuses amounted to war crimes.\\nUnlike the military, which dismissed the allegations, Mr Buhari\\'s office says it will look into the report, which indicates a desire to improve the image of Nigeria\\'s men in uniform both at home and abroad.\\nCloser proximity to the fighting might improve co-operation with the regional forces, who have complained that Nigerian troops were slow in arriving for the handovers of towns liberated from Boko Haram.\\nSo far their collective efforts have driven the jihadists from most of their strongholds.\\nMeanwhile, Boko Haram has stepped up its attacks in commercial centres in the north with a series of attacks, including bombings, reminding the new government of the huge threat it still poses.\\nThe existing heavy military deployments in the region have not deterred the group so far.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Sunderland moved off the bottom of the table by beating reigning Premier League champions Leicester - their third win in four matches.', 'negatives': [], 'positives': ['The Black Cats took the lead when Robert Huth turned a corner into his own net midway through the second half.\\nAnd before Leicester could mount a response, David Moyes\\' side added a second when Jermain Defoe drove in after Duncan Watmore\\'s shot was blocked.\\nSubstitute Shinji Okazaki flicked Demarai Gray\\'s cross in at the near post to set up a tense finish, but Sunderland held on.\\nThe result moves them up to 18th and within two points of the Foxes, who are yet to win away in the league this season.\\nLeicester are in real danger of becoming involved in a relegation battle and their return of 13 points is the worst record after 14 games of any defending champions in Premier League history.\\nTwo wins from their three games prior to the visit of Leicester had given Sunderland fans some hope that their side have turned the corner under Moyes.\\nThey lost in their previous outing - a 2-0 defeat at Liverpool after which Reds boss Jurgen Klopp said the Black Cats were the most defensive team he had ever seen.\\nHowever, they looked nothing of the sort against Leicester, attacking with pace and intent. Victor Anichebe - reborn under Moyes - has forged an impressive partnership with Defoe and the continuation of that will be crucial to Sunderland\\'s hopes of climbing out of the relegation zone.\\nAnd the club\\'s players also appear to have developed a strong team spirit, something that was exemplified in the final few seconds of the game as they threw themselves in front of the ball in a tense scramble before Jordan Pickford superbly punched away Wes Morgan\\'s goal-bound shot.\\nThis time last year, Vardy was being congratulated on social media by Ruud van Nistelrooy for breaking the Dutchman\\'s record of scoring in 10 consecutive Premier League games.\\nFast forward to today and the striker\\'s form has dipped dramatically - his blank against Sunderland was his 16th game for Leicester without scoring.\\nVardy got into good positions against the Black Cats. He was unlucky with a clever cushioned header that landed on the roof of the net and also nodded just wide from dangerous Marc Albrighton cross. However, the England international is not getting the service he enjoyed in an electric 2015-16 campaign.\\nDuring Leicester\\'s title-winning season he linked up superbly with Riyad Mahrez, but the pair have rarely been on the same wavelength this season. Mahrez has found Vardy with just three passes in their past nine games and only once did the two combine against Sunderland.\\nThere were suggestions that Ranieri was considering dropping Vardy for the Sunderland game and another match without scoring may increase the threat to his place in the side.\\nSunderland boss David Moyes: \"If we can win another three out of four we will be in a really good position. We are playing better and the team is getting better.\\n\"We\\'re much more of an attacking looking side now. We have got more options to attack and we have actually started to defend better.\"\\nMedia playback is not supported on this device\\nLeicester manager Claudio Ranieri: \"We did our best today, but it wasn\\'t enough. We have to keep working hard in training and trust the bad moment will turn.\\n\"From the own goal you can see the luck is not with us - but we have to stay compact, stay together and react strongly.\"\\nMedia playback is not supported on this device\\nIt is a big game at the bottom of the table for Sunderland as they head to Swansea on 10 December (15:00 GMT kick-off).\\nLeicester, meanwhile, travel to Portugal to play Porto in their final Champions League group game on Wednesday (19:45). The Foxes are already through the knockout stage, so their focus is more likely to be on next Saturday\\'s home game against Manchester City (17:30).\\nMatch ends, Sunderland 2, Leicester City 1.\\nSecond Half ends, Sunderland 2, Leicester City 1.\\nVictor Anichebe (Sunderland) wins a free kick in the attacking half.\\nFoul by Robert Huth (Leicester City).\\nAttempt missed. Wes Morgan (Leicester City) right footed shot from the centre of the box is high and wide to the right following a corner.\\nAttempt saved. Wes Morgan (Leicester City) right footed shot from the centre of the box is saved in the bottom right corner.\\nAttempt blocked. Danny Simpson (Leicester City) right footed shot from the right side of the box is blocked.\\nCorner,  Leicester City. Conceded by Billy Jones.\\nDidier Ndong (Sunderland) wins a free kick in the attacking half.\\nFoul by Jamie Vardy (Leicester City).\\nPatrick van Aanholt (Sunderland) wins a free kick in the defensive half.\\nFoul by Wes Morgan (Leicester City).\\nAttempt blocked. Ahmed Musa (Leicester City) right footed shot from outside the box is blocked.\\nFoul by Didier Ndong (Sunderland).\\nAndy King (Leicester City) wins a free kick in the attacking half.\\nDelay over. They are ready to continue.\\nDelay in match Danny Simpson (Leicester City) because of an injury.\\nAttempt saved. Victor Anichebe (Sunderland) right footed shot from outside the box is saved in the bottom right corner. Assisted by Patrick van Aanholt.\\nAttempt missed. Patrick van Aanholt (Sunderland) right footed shot from outside the box is high and wide to the right following a set piece situation.\\nSubstitution, Sunderland. Javier Manquillo replaces Duncan Watmore because of an injury.\\nDelay over. They are ready to continue.\\nDelay in match Duncan Watmore (Sunderland) because of an injury.\\nChristian Fuchs (Leicester City) is shown the yellow card for a bad foul.\\nDuncan Watmore (Sunderland) wins a free kick on the left wing.\\nFoul by Christian Fuchs (Leicester City).\\nCorner,  Sunderland. Conceded by Andy King.\\nAttempt blocked. Victor Anichebe (Sunderland) right footed shot from outside the box is blocked.\\nGoal!  Sunderland 2, Leicester City 1. Shinji Okazaki (Leicester City) left footed shot from the left side of the six yard box to the bottom left corner. Assisted by Demarai Gray with a cross.\\nAttempt saved. Robert Huth (Leicester City) header from the centre of the box is saved in the centre of the goal. Assisted by Christian Fuchs with a cross.\\nPapy Djilobodji (Sunderland) is shown the yellow card for a bad foul.\\nFoul by Papy Djilobodji (Sunderland).\\nShinji Okazaki (Leicester City) wins a free kick in the attacking half.\\nGoal!  Sunderland 2, Leicester City 0. Jermain Defoe (Sunderland) left footed shot from the centre of the box to the bottom right corner.\\nAttempt missed. Duncan Watmore (Sunderland) left footed shot from the centre of the box is close, but misses to the right. Assisted by Victor Anichebe.\\nSubstitution, Leicester City. Demarai Gray replaces Marc Albrighton.\\nSubstitution, Leicester City. Ahmed Musa replaces Riyad Mahrez.\\nAttempt missed. Wes Morgan (Leicester City) header from the centre of the box misses to the left. Assisted by Riyad Mahrez following a set piece situation.\\nSebastian Larsson (Sunderland) is shown the yellow card for a bad foul.\\nFoul by Sebastian Larsson (Sunderland).\\nRiyad Mahrez (Leicester City) wins a free kick on the right wing.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"A man has pleaded guilty to causing a woman's death by dangerous driving in a crash on the M62 in Greater Manchester.\", 'negatives': [], 'positives': [\"Joetta Shumba, 25, died in January when the Audi she was travelling in collided with a lorry which subsequently overturned near the Eccles Interchange.\\nThe car's driver, 30-year-old Martin Grant of Jacey Road, Birmingham, admitted the charge on Wednesday at Manchester Crown Court.\\nHe will be sentenced on 9 May at Manchester Magistrates' Court.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Justin Bieber has surprised the British choir that beat him to the UK Christmas Number One in a special meeting.', 'negatives': [], 'positives': [\"1 March 2016 Last updated at 08:07 GMT\\nBack in December 2015, the Canadian singer had tweeted his support for the Lewisham and Greenwich NHS Choir to reach the famous number one spot, despite competing against the group with his own single.\\nOn 23 February, Bieber finally came to face the face with the London choir and handed them their official award.\\nWatch Jenny's report to find out more.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Harry Kane is one of the top strikers in the world, Tottenham boss Mauricio Pochettino said after the England man scored his third hat-trick of 2017.', 'negatives': [], 'positives': ['Media playback is not supported on this device\\nKane struck three times in 23 minutes as Spurs beat Stoke City 4-0 to climb to second in the Premier League table.\\nThe 23-year-old also scored three against Fulham in the FA Cup on 19 February and against West Brom in the league on 14 January.\\n\"He\\'s playing at a very good level, a fantastic player,\" said Pochettino.\\nMedia playback is not supported on this device\\nKane scored in the 14th, 32nd and 37th minutes as Spurs made it eight straight league wins at White Hart Lane.\\nDele Alli scored in first-half stoppage time to complete the rout against mid-table Stoke.\\nPochettino added: \"He\\'s one of the top strikers in the world and I think he deserves it because he\\'s a great professional and top man. I\\'m happy for him.\\n\"It doesn\\'t surprise me, because I\\'ve told you many times that for me he\\'s one of the best strikers in the world.\\n\"This season we are not only winning games [at White Hart Lane], we are playing very well here - maybe because we all know it\\'s the last season here and it\\'s a very special atmosphere on the pitch and in the stadium.\"\\nAnalysis by former Tottenham midfielder Jermaine Jenas on Radio 5 live\\nThat was a special performance by Harry Kane. There are only a select number of players who can score like he can on their weaker side.\\nMore often than not, if he is in the box, he will hit it. It goes through bodies, goes through legs and ends up in the back of the net.\\nI just don\\'t know how much more of a warning you need when he is on the edge of the box with the ball. He is lethal with both feet. You need to close him down. When you\\'re hot, you\\'re hot. It\\'s as simple as that.\\nFormer England striker Alan Shearer, who scored a record 260 Premier League goals: \"Calm down Harry Kane! What is he after...a Premier League record or something?\"\\nFormer Tottenham striker Gary Lineker tweeted: \"A third hat-trick for Kane in nine games. The last person to do that was....someone else.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'David Haye will face unknown Kosovan Arnold Gjergjaj in the second fight of his comeback on 21 May at the O2 Arena.', 'negatives': [], 'positives': ['Britain\\'s Haye, 35, beat Australia\\'s Mark de Mori with a first-round stoppage in January after a three-and-a-half-year absence from the ring.\\n\"I said from the start I want to fight regularly and get some momentum back in my career,\" said Haye.\\nHe also said 10% of ticket money will be donated to boxer Nick Blackwell, who is currently in an induced coma.\\nBlackwell was found to have a small bleed on the brain after being stopped in Saturday\\'s British middlewight title defence against Chris Eubank Jr.\\nHaye\\'s opponent Gjergjaj has won all 29 of his contests but only one of those have been staged outside Switzerland, where the 31-year-old heavyweight lives.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'World heavyweight champion Tyson Fury will never fight again, leading British promoter Eddie Hearn has said.', 'negatives': [], 'positives': ['Fury, 28, has withdrawn from his rematch with Wladimir Klitschko, scheduled for 29 October, because of reported mental health issues.\\nThe Englishman, who has not fought since beating Klitschko last November, postponed the original rematch in June.\\n\"Fury will be stripped of his titles and, after a legal battle, he\\'ll say: \\'No more, I\\'m done\\',\" said Hearn.\\n\"It\\'s going to be really messy and it might take a year to resolve. I know there are sensitivities around mental health issues but this is a business.\\n\"The governing bodies have had enough. The world heavyweight title is a huge part of their business and they\\'ve not made any money from it for a year.\"\\nFury beat Klitschko on points in Germany - the Ukrainian\\'s first loss since 2004 - to pick up the WBA, IBF, WBO and IBO titles, with American Deontay Wilder holding the WBC belt.\\nWithin two weeks Fury was stripped of the IBF title because he was unable to fight mandatory challenger Vyacheslav Glazkov - and that belt is now held by Fury\\'s fellow Briton Anthony Joshua.\\nHearn, who does not promote Fury, said Klitschko\\'s team - including manager Bernd Boente - were keen for the 40-year-old to fight his own man - Joshua - on 29 October.\\nBut Hearn believed the predicted legal challenges from Fury\\'s team made that match unlikely.\\n\"I spoke to Bernd Boente for half-an-hour on Saturday and the conversation was great, we all fancy the fight,\" said Hearn.\\n\"It does feel a little bit early - Joshua has only had 17 professional fights and Klitschko\\'s experience worries me. But he looked awful against Fury. I think he\\'s done.\"\\nJoshua, 26, is scheduled to defend his title in Manchester on 26 November.\\nHearn added: \"We\\'re fighting in nine weeks, so we need to announce an opponent next week.\\n\"I think the WBA and WBO would sanction the fight and the deal would be easy to do. But Fury\\'s legal battle to keep the belts will take too much time.\"\\nHearn said Joshua is more likely to make the second defence of his title against mandatory challenger Joseph Parker, from New Zealand.\\nHearn believes the WBA and WBO will both make Fury their \\'champion in recess\\', meaning Klitschko could fight for the vacant titles in October before facing Joshua in a unification showdown next spring or summer.\\nIf Fury\\'s team do take legal action, and the governing bodies\\' hands are tied, it would leave Klitschko in limbo.\\nOn Sunday, Fury\\'s uncle and trainer Peter said his charge\\'s medical condition was caused by a \"witchhunt\" conducted by the British media in the wake of his stunning upset of Klitschko, who had not lost for 11 years.\\nBut Hearn believes Fury\\'s team will not be able to persuade the relevant governing bodies their fighter should hang on to his titles indefinitely.\\n\"If they just say, \\'he needs time away from the sport\\', they\\'re bang in trouble,\" said Hearn.\\n\"The governing bodies will ask: \\'When will he be ready to fight?\\' And his doctor won\\'t be able to tell them. Once they hear that, they\\'ll make him champion in recess and say: \\'Once you\\'re fit, we\\'ll give you another chance.\\'\"\\nFury is under investigation for alleged doping, having been charged with an offence by the UK Anti-Doping Agency (Ukad) in June, after traces of a banned substance were allegedly found in a urine sample.\\nThe fighter has denied allegations of doping.\\nIt has also been alleged he recently refused to give a sample, having been visited by Ukad. An athlete who refuses to take a drugs test can be banned for four years.\\nWhile Hearn stressed he had sympathy for Fury\\'s health issues, he added those around him must take their share of the blame for his plight.\\n\"How can you unify the heavyweight division by beating Wladimir Klitschko in Germany and mess it up so badly?\" said Hearn. \"You couldn\\'t make it up and the people who guide him have to be held responsible for what has happened.\\n\"I wanted Fury to fight Klitschko, because we wanted Joshua to fight Fury. A heavyweight world title unification between two Brits is gold dust. But everyone in boxing knew that the fight between Fury and Klitschko wouldn\\'t happen and I don\\'t think Fury will fight again.\\n\"Some people can\\'t deal with being in the spotlight and maybe he thinks he\\'ll never get that feeling again that he got from winning the world title.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A suspected plot to burgle the home of late singer Cilla Black has been foiled, her eldest son has revealed.', 'negatives': [], 'positives': ['Robert Willis made the claim on the day a coroner ruled Black died from an accidental traumatic head injury during a fall at her home in Spain.\\nThames Valley Police said they were investigating after a professionally-cut hole appeared in a fence at a property in Denham, Buckinghamshire.\\n\"I cannot believe someone would stoop so low,\" Mr Willis said.\\n\"It\\'s inconceivable. Thankfully it was discovered in time.\"\\nJust days before her funeral, police confirmed they were investigating a case of criminal damage at the property.\\nThe 72-year-old entertainer was found dead at her villa in Estepona on the Costa del Sol on 1 August.\\nMr Willis spoke out after a 15-minute hearing at Liverpool Coroner\\'s Court, where coroner Andre Rebello recorded a verdict of accidental death.\\nAddressing the hearing, attended by Mr Willis and brothers Ben and Jack, Mr Rebello referred to the star by her real name Priscilla Maria Veronica Willis.\\n\"She was a daughter of Liverpool and was celebrated and loved by all in Liverpool,\" he said.\\nHe told sons, Ben, Robert and Jack: \"She was your mum and her death is a private personal matter and we have all got one mum.\\n\"It is right that you grieve and remember her.\"\\nThe entertainer\\'s funeral will take place next Thursday at St Mary\\'s Roman Catholic Church in Liverpool celebrated by the Rt Rev Thomas Williams, Auxiliary Bishop of Liverpool.\\nFollowing her funeral, the singer will be laid to rest at Allerton Cemetery, where her parents are buried.\\nBorn Priscilla Maria Veronica White, she first found fame as a singer in the 1960s, with a string of top 10 hits including chart-toppers Anyone Who Had a Heart and You\\'re My World.\\nShe later married Bobby Willis at London\\'s Marylebone Register Office in 1969. He died 30 years later.\\nThe former cloakroom attendant at the famed Cavern Club in Liverpool then went on to become the host of TV shows such as Surprise, Surprise and Blind Date.\\nAbout 3,195 people signed a book of condolence, which has now closed, at Liverpool Town Hall.\\nOn the day of her funeral the building\\'s flag will fly at half-mast, a Liverpool City Council spokesperson said.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'More than 70 new emojis have been approved for release this month.', 'negatives': [], 'positives': ['Among them are characters rolling around laughing on the floor, cartwheeling, dancing, sneezing and even a \\'person\\' facepalming.\\nEmojis are symbols that help describe feelings or emotions, and are used by millions of people around the world in texts, online chats and on social media.\\nThe Unicode consortium, the group that approve emojis, have signed off some yummy treats and animal faces too.\\nJoining the collection are bacon, pancakes, a gorilla, a rhino, a lizard, a shark and a butterfly.\\nSports have made the line up with wrestling, water polo, handball and fencing to be released too.\\nJeremy Burge, the founder of Emojipedia and World Emoji Day, said: \"Unicode 9 includes a set of 72 emojis covering new smileys, people, gestures, food, drink, and sports.\"\\n\"The fingers crossed and shrug emojis look set to be the most popular of the bunch, with Emojipedia data showing these are accessed considerably more often than the other new emojis,\" he added.\\nThe new emojis are set to be made available on 21 June.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Calvin Andrew's first-half header made it four wins on the bounce for Rochdale as they beat Charlton at The Valley.\", 'negatives': [], 'positives': [\"Addicks skipper Johnnie Jackson missed a penalty in the 48th minute which extended their winless run to seven league games.\\nRochdale took the lead in the 25th minute when Joe Bunney's cross found Andrew who headed home at the back post.\\nThe Dale had an excellent chance to double their lead moments later after poor defending from Charlton forced Declan Rudd into a good save to deny Joe Thompson.\\nThe Londoners barely created any significant openings throughout the game and were booed off at the end of both halves.\\nBut the home side started the second 45 minutes brightly as Ricky Holmes won a penalty after he was tripped by Bunney.\\nHowever, Rochdale goalkeeper Josh Lillis dived to his left to keep Jackson's effort out and then did well to deny Josh Magennis' follow-up strike.\\nDespite late second-half pressure from Charlton, they could not get past a resilient Keith Hill side.\\nReport supplied by the Press Association.\\nMatch ends, Charlton Athletic 0, Rochdale 1.\\nSecond Half ends, Charlton Athletic 0, Rochdale 1.\\nAdemola Lookman (Charlton Athletic) is shown the yellow card for a bad foul.\\nFoul by Ademola Lookman (Charlton Athletic).\\nMatthew Lund (Rochdale) wins a free kick in the attacking half.\\nAttempt saved. Donal McDermott (Rochdale) left footed shot from outside the box is saved in the bottom right corner.\\nSubstitution, Rochdale. Harrison McGahey replaces Joe Thompson.\\nCorner,  Charlton Athletic. Conceded by Joe Bunney.\\nCorner,  Charlton Athletic. Conceded by Joe Bunney.\\nAdemola Lookman (Charlton Athletic) wins a free kick in the defensive half.\\nFoul by Donal McDermott (Rochdale).\\nCorner,  Charlton Athletic. Conceded by Joseph Rafferty.\\nFoul by Fredrik Ulvestad (Charlton Athletic).\\nJoseph Rafferty (Rochdale) wins a free kick on the left wing.\\nSubstitution, Rochdale. Sanmi Odelusi replaces Steve Davies.\\nAttempt saved. Jordan Botaka (Charlton Athletic) right footed shot from the right side of the box is saved in the bottom left corner.\\nCorner,  Charlton Athletic. Conceded by Joe Thompson.\\nAttempt missed. Ademola Lookman (Charlton Athletic) right footed shot from outside the box is close, but misses the top left corner.\\nSubstitution, Charlton Athletic. Jordan Botaka replaces Ricky Holmes.\\nCorner,  Charlton Athletic. Conceded by Josh Lillis.\\nAttempt saved. Fredrik Ulvestad (Charlton Athletic) left footed shot from the centre of the box is saved in the bottom left corner.\\nFoul by Lee Novak (Charlton Athletic).\\nKeith Keane (Rochdale) wins a free kick in the attacking half.\\nSubstitution, Charlton Athletic. Lee Novak replaces Josh Magennis.\\nAttempt missed. Niall Canavan (Rochdale) header from the centre of the box is close, but misses the top left corner.\\nCorner,  Rochdale. Conceded by Fredrik Ulvestad.\\nFredrik Ulvestad (Charlton Athletic) wins a free kick in the attacking half.\\nFoul by Joe Thompson (Rochdale).\\nCorner,  Charlton Athletic. Conceded by Calvin Andrew.\\nCorner,  Charlton Athletic. Conceded by Joe Bunney.\\nAttempt missed. Ademola Lookman (Charlton Athletic) right footed shot from outside the box is just a bit too high.\\nSubstitution, Charlton Athletic. Nicky Ajose replaces Andrew Crofts.\\nAttempt missed. Donal McDermott (Rochdale) left footed shot from the centre of the box is close, but misses to the left.\\nFoul by Jason Pearce (Charlton Athletic).\\nSteve Davies (Rochdale) wins a free kick in the attacking half.\\nRicky Holmes (Charlton Athletic) wins a free kick in the attacking half.\\nFoul by Calvin Andrew (Rochdale).\\nAttempt missed. Ademola Lookman (Charlton Athletic) right footed shot from very close range is just a bit too high.\\nRicky Holmes (Charlton Athletic) wins a free kick in the defensive half.\\nFoul by Callum Camps (Rochdale).\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The names of two squadrons that will operate a total of nine new maritime patrol aircraft from RAF Lossiemouth have been announced.', 'negatives': [], 'positives': ['Number 120 Sqd was originally an anti-submarine unit in World War Two, while the origins of 201 Sqd can be traced back to 1914.\\nThe first of the new US-made P-8A Poseidon aircraft are to arrive at the Moray station in 2020.\\nThe UK\\'s last dedicated maritime patrol planes flew out of RAF Kinloss in 2010.\\nThe aircraft, Nimrod MR2s, were retired and a new order for a fleet of Nimrod MRA4s was cancelled, leading to the scrapping of £4bn of partly-constructed planes to save £2bn in operating costs.\\nThere was criticism at the time and since of the UK government\\'s decision to withdraw the Nimrods and not replace it with another maritime aircraft.\\nKinloss, which is also in Moray, is now an army base.\\nAn American P-8A Poseidon has been flown to RAF Lossiemouth for Thursday\\'s announcement of the squadron numbers.\\nSpy in the sky: P-8A Poseidon\\nThe UK government said the key role of the P-8A Poseidon would be to protect submarines and two new aircraft carriers.\\nIts £3bn investment in maritime patrol aircraft capability over 10 years will include strengthening the runway at Lossiemouth and improving other infrastructure.\\nDefence Secretary Sir Michael Fallon said: \"Our nine new Poseidon aircraft are part of our plan to monitor and deal with increased threats to our country.\\n\"They can operate at long range without refuelling and have the endurance to carry out high and low-level airborne maritime and overland surveillance for extended periods, helping keep us safe.\\n\"The P-8A aircraft will allow us to work more closely with our allies, improve our surveillance coverage and will provide value for taxpayers\\' money.\"\\nDuring World War Two, 120 Sqd was the RAF\\'s highest-scoring anti-submarine unit.\\n201 Sqd can trace its origins back to the formation of No 1 Sqd, Royal Naval Air Service in 1914.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Simon Murray scored a hat-trick as Hibernian eased to a 6-1 home win over Arbroath in the League Cup.', 'negatives': [], 'positives': [\"Teenager defender Ryan Porteous scored with two headers and John McGinn added the pick of the bunch with a lovely curling shot.\\nSteven Doris had briefly levelled a match completely dominated by the Easter Road side.\\nHibs sit second behind Ross County in Group D and will guarantee progress with a win at Alloa on Saturday.\\nIf the Staggies win at Arbroath and Hibs do the same, Neil Lennon's side will have to settle for non-seeded status as one of the four best runners-up.\\nMurray broke the deadlock when he headed a fine David Gray delivery beyond Ricky Gomes.\\nA glorious chance for Hibs to double their advantage was spurned when Danny Swanson ballooned a terrible penalty over the crossbar after Porteous had been hauled down.\\nHibs wasted more good opportunities before the visitors levelled, with Doris coolly slotting beyond Ross Laidlaw.\\nBut the hosts regained the lead before half time as 18-year-old Porteous headed in his first goal for the club from a McGinn cross.\\nTwo goals goals in quick succession ended the game as a contest after the interval. Murray tapped home from point-blank range following a fine run and cross by Martin Boyle, before a wonderful finish by McGinn.\\nPorteous converted another strong header with two minutes remaining and there was still time for Murray to slam in a back-post volley.\\nMontrose picked up their first win of the tournament with a 2-1 home win over Alloa, who drop to the foot of the table.\\nKerr Hay and Paul Watson were on target for the hosts before Iain Flannigan pulled one back for the Wasps.\\nIn Group C, Raith Rovers were emphatic 6-1 winners at Buckie Thistle.\\nLewis Vaughan and Liam Buchanan both grabbed doubles for the Kirkcaldy side, with Greig Spence and Ross Matthews also on target.\\nJohn McLeod had levelled for the Highland League champions but Rovers eased to their first victory in the tournament.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Great Britain have won three bronze medals at the Para Table Tennis World Team Championships in Slovakia.', 'negatives': [], 'positives': [\"Paul Davies and Tom Matthews missed out on gold and silver on countback in the round-robin men's class 1, losing their last tie against top seeds South Korea.\\nPaul Karabardak, David Wetherill and Martin Perry moved into the semi-finals of the men's class 6 as group winners, but lost in the last four to Croatia.\\nSue Gilroy and Megan Shackleton also won bronze in the women's class 4-5.\\nIn the round-robin event, the pair still had a chance of winning gold in their final match against top seeds Serbia, but Paralympic champion Borislava Peric-Rankovic and Rio 2016 bronze medallist Nada Matic defeated them.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Holyrood's justice committee has backed the general principles of a bill to integrate railway policing north of the border into Police Scotland.\", 'negatives': [], 'positives': ['The Scottish government wants the national force to take over the role of the British Transport Police (BTP).\\nThe majority of respondents to the committee opposed the integration, as did four MSPs, including the convener.\\nMSPs are due to vote on the legislation for the first time in the week beginning 8 May.\\nThe Scottish government has long wanted to integrate railway policing services into the single national force, and tabled a bill to that end in December 2016.\\nThe Railway Policing (Scotland) Bill would confer extra powers on the Scottish Police Authority and the Police Service of Scotland, but further legislation would be needed at Holyrood and Westminster to transfer staff, properties and cross-border policing functions.\\nWitnesses including BTP chief constable Paul Crowther have warned that a merger could prove a \"real challenge\", saying it could cause a \"significant outflow of expertise\".\\nHowever Police Scotland have said a merger would be \"complicated but not insurmountable\".\\nThe target date for integration is 1 April 2019.\\nThe justice committee report noted there was \"willingness to work collaboratively to meet\" this \"deadline\", but said railway operators, unions, staff associations and passenger groups should be brought together as soon as possible \"to ensure what any risks are identified and mitigated prior to integration\".\\nIt also said the committee heard that the costs of railway policing could increase as a result of integration, but that \"it had not yet been determined what these costs might be or who should pay them\".\\nThe report highlighted that agreement of terms, conditions, benefits and pensions of BTP staff and officers had not yet been reached, saying that \"resolving this issue is critical to achieving a seamless transfer\".\\nMembers also said it was \"imperative\" that forces were clear about their roles and responsibilities policing cross-border trains.\\nOf 11 justice committee members, seven backed the general principles of the legislation, with four dissenting.\\nThey pointed out that BTP had proposed three options for devolving railway policing, noting concerns about the Scottish government\\'s decision to only consult on one option - the option the force had outlined as \"the most complex route\".\\nCommittee convener Margaret Mitchell, who was among those against the bill, said members had heard \"a variety of opinions about the best approach for railway policing\".\\nShe said: \"The committee did not arrive at a unanimous position on the bill\\'s general principles, with some members backing an alternative approach.\\n\"The committee report made a number of clear recommendations to ensure that the same level of service that the travelling public currently enjoys is maintained.\\n\"These include the recommendations that strong procedures should be in place to manage cross-border issues, such as the powers of officers to carry out their duties as they travel between Scotland and England, and also that officers must be clear on operational issues such as the use of Tasers and the powers of arrest.\\n\"All members agree that protecting the travelling public is of the utmost importance.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'After the debate was over, some of the French media commentariat was saying it had been a disgrace.', 'negatives': [], 'positives': [\"Nothing had been elucidated. It was all mud-slinging. It was unworthy of a presidential election.\\nMaybe. But it didn't half make for riveting viewing. And at the end of the day, the debate did its job.\\nFor the millions sitting through those two hours of insults, interruptions and (just occasionally) ideas, the differences between Marine Le Pen and Emmanuel Macron could hardly have been made any plainer.\\nThe National Front leader set the tone with her opening remarks, which were clearly intended to cause personal hurt. Macron's smile had become a grimace, she said. The mask had fallen - behind the personable front lay the coldness of a banker.\\nInsults like that can only have been intended to rattle her adversary, to provoke him into saying something he would regret. And that was her tactic throughout: constantly needling Emmanuel Macron with jibes and vaguely-worded accusations.\\nThere had been a big argument in advance about whether the producers of the debate would be allowed to use cutaways. These are images of the person who is not talking, when he or she reacts to the one who is.\\nFinally it was agreed that they could be broadcast - and thus we were able to watch Marine Le Pen doing something unusual. Throughout much of the debate she was smiling, sometimes even chuckling.\\nIt seemed to be part of a rehearsed psychological ploy to unnerve her opponent, by appearing to find his answers so ludicrous as to be amusing.\\nExcept none of this tactic worked. Emmanuel Macron did not rise to the bait. Say what you will of him, Macron is an extraordinarily composed and accomplished performer. Throughout the debate he remained master of himself and his argument.\\nAt only one point did she score. In the section on terrorism, she launched a attack on Macron's supposed feebleness in face of the jihadist threat, and explained that she would make France safer by expelling foreign suspects.\\nMacron responded with a long-winded explanation of how so many terrorists were in fact French, and how therefore France needed to examine its own conscience for letting that happen.\\nThe argument misfired badly because it made it look as if Macron blamed France as much as the terrorists.\\nBut for the rest, it was Marine Le Pen who betrayed weakness and confusion on a range of issues - especially economic. On the question of leaving the euro, far from clearing up the uncertainty about what she actually wants, she made matters worse by exposing her ignorance of the old European Currency Unit.\\nShe was constantly playing with documents in front of her, searching for points and remarks to quote back at him. But it made her look unsure of her brief, and too often her attacks were reduced to the same old slogans.\\nMacron, by contrast, appeared comfortable and spontaneous.\\nThese face-to-face debates are a traditional part of the election process, and for 40 years the French have tuned in to see which candidate is more likely to faire prÃ©sident.\\nThey want to know who has the look, who has the feel of a head of state.\\nEmmanuel Macron is an unknown quantity. Many loathe his ideas. Many fear his inexperience.\\nBut last night - against Marine le Pen - there was little doubt who was the more presidentiable.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Munster have begun \"working and planning\" towards Saturday\\'s European Champions Cup game against Glasgow at Thomond Park following the death of their head coach Anthony Foley.', 'negatives': [], 'positives': ['Foley, 42, died suddenly in Paris on Saturday before the Irish province\\'s scheduled game against Racing Metro.\\nA statement issued by Munster on Tuesday said the squad were \"following a modified schedule this week\".\\nMunster A\\'s British and Irish Cup match away to Doncaster has been postponed.\\nThe Munster management and squad gathered on Tuesday after spending much of Monday signing books of condolence at Thomond Park, Irish Independent Park and other locations across the province.\\n\"The thoughts of Munster Rugby players, management and staff remain with the Foley and Hogan families and assisting them at this time continues to be the priority,\" read the statement.\\nExplaining the decision to call off the B&I Cup fixture against Doncaster Knights, Munster A head coach Peter Malone said: \"With the Munster A squad featuring a number of senior players, planning for an away fixture would not be suitable at this point in time.\\n\"We thank Doncaster Knights and the B&I Cup for facilitating our request in light of the exceptional circumstances.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Former MP George Galloway has signed a deal to write a series of children's books.\", 'negatives': [], 'positives': ['He made the announcement on Twitter, saying they would be about an \"ethical pirate\".\\nThe title of the series is Red Molucca and the Good Pirate and is due to be published later this year.\\nMr Galloway has already written a number of novels for adults, including the Fidel Castro Handbook and Mr Galloway goes to Washington.\\n\"I will shortly have four children under ten years old and I have four young grandchildren too, ranging from three to 14,\" he told the BBC.\\n\"They read and I\\'ve bought (and read to them) a lot of children\\'s books. All have been fascinated by pirates. Judging by the success of Pirates of the Caribbean so are many adults!\"\\nBut Mr Galloway said the rum-drinking, cut-throat, walking the plank-type characters were not the right role models.\\n\"Enter an ethical pirate, Red Molucca,\" he said. \"A husband and father whose family (and dog) pirate alongside him. A kind of Robin Hood of the high seas.\"\\nThe new stories are set amongst the Spice islands of Indonesia during colonial rule.\\nIllustrator Joe Cook said the final style of the books is \"top secret\".\\n\"I got involved because George represents an under-reported and undervalued perspective on the world,\" he told the BBC. \"The project is great fun too!\"\\nMr Galloway, a former Labour and Respect MP, did not reveal who the publishers were but said the books would be released in English, Dutch and Indonesian.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"A village's toilets have been closed after a bearded man in a wedding dress reportedly propositioned people for sex there.\", 'negatives': [], 'positives': ['The public block, in Newton Poppleford, Devon, was locked up on Monday after a local was \"accosted\" the day before.\\nWorshippers at a local church will be able to use the toilets on Sunday under supervision, the parish council said.\\nThe long-term future of the loo is being discussed with owner East Devon District Council (EDDC).\\nRead more on this story as it develops throughout the day on our Local Live pages\\nParish Clerk David Atkins said the bearded man involved in Sunday\\'s episode was in his late 50s or 60s.\\nAs a result, he said, the toilets would be closed \"until further notice\".\\nBut for the St Luke\\'s congregation, which is without a toilet, there would be special dispensation, he said.\\n\"We will open them on Sundays, but they will be supervised by the church warden,\" Mr Atkins said.\\n\"If anything untoward happens he will see it.\"\\nParish councillors will be discussing the measures at their next meeting on Monday.\\n\"We might have to look at installing CCTV or something like that,\" Mr Atkins said.\\n\"This has put the future of the loos in jeopardy because the council might say enough is enough.\"\\nEDDC said it had contacted the council over \"the issue of the toilets being used for gay sex\" and was liaising with police.\\nA site meeting would be held \"to agree any appropriate action\".\\n\"In the meantime, we understand that the parish council has closed the men\\'s toilets until further notice - although a key will be made available for church users.\"\\nDevon and Cornwall Police said it had not received a report of the incident.\\nVicar of St Luke\\'s, the Reverend Mark Ward, said: \"We have very good relations with the parish council and we welcome being given the use of a key to the toilets.\\n\"I hope the toilets will not remain closed for the entire community because of this incident.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Two skulls found in China shed light on the ancient humans who inhabited the region before our own species arrived.', 'negatives': [], 'positives': ['We know that Europe and western Asia was dominated by the Neanderthals before Homo sapiens displaced them.\\nBut remains belonging to equivalent populations in East and Central Asia have been scarce.\\nIt\\'s unclear if the finds are linked to the Denisovans, a mysterious human group known only from DNA analysis of a tooth and finger bone from Siberia.\\nProf Erik Trinkaus, one of the authors of a study on the remains in Science journal, said it was not possible to say at this stage whether the ancient people from Xuchang were connected to the Denisovans.\\n\"The issue here is the patterns of variation and the population dynamics of \\'archaic\\' populations during the later part of the Pleistocene,\" Prof Trinkaus, from Washington University in St Louis, told BBC News.\\nModern humans (Homo sapiens) originated in Africa some 200,000 years ago before expanding out across Asia, Europe, Oceania and the Americas about 60,000 years ago. As they spread across the world, they displaced the existing populations they encountered, such as the Neanderthals and Denisovans - but some limited interbreeding occurred.\\nThe partial skulls from China are between 105,000 and 125,000 years old and lack faces. But they show clear similarities to and differences from their Neanderthal contemporaries in the west.\\n\"There\\'s a certain amount of regional diversity at this time, but also there are trends in basic biology that are shared by everybody. And the supposed Neanderthal characteristics show that all these populations were interconnected,\" Prof Trinkaus explained.\\nProf Trinkaus, Zhan-Yang Li, from the Chinese Academy of Sciences in Beijing, and others found that the specimens show some characteristics, like a low, broad braincase, that link them to even earlier humans from the same region, who lived in the Middle Pleistocene.\\nBut some features of the skull that were more pronounced in earlier humans, such as the bony ridges over the eyes and a bony prominence at the back of the skull called the nuchal torus, are not as marked in these specimens. Erik Trinkaus says this represents evidence for a process of \"gracilisation\" - a reduction of bone mass through evolution - that was common to other human groups at the time.\\nAnd the two specimens from Xuchang have comparatively large braincases - reflecting a trend towards larger brain sizes across the Old World - Europe, Africa and Asia.\\nOne of the ancient Chinese skulls - Xuchang 1 - is at the high end of the scale. Prof Chris Stringer, from London\\'s Natural History Museum, who was not involved with the study, said the individual had a \"remarkable brain size, up there with the largest known Neanderthal and early modern examples\".\\nAs regards any potential relationship with the Denisovans, he said: \"Unfortunately, the skulls lack teeth so we cannot make direct comparisons with the large teeth known from Denisova Cave, but another similarly-dated fossil from Xujiayao in China does have Neanderthal-like traits in the ear bones, like Xuchang, and does have large teeth, so these may all represent the same population.\\n\"From genetic data, the Denisovans are believed to have split from the Neanderthal lineage about 400,000 years ago - about the time of the Sima de los Huesos early Neanderthals known from Atapuerca in Spain. So one might expect some level of Neanderthal features in their morphology, added to by evidence of some later interbreeding with the Neanderthals.\\n\"We must hope that ancient DNA can be recovered from these fossils in order to test whether they are Denisovans, or a distinct lineage.\"\\nThe skulls were found during excavations at Lingjing, Xuchang County in Henan Province, between 2007 and 2014.\\nFollow Paul on Twitter.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A man shouted \"This is for Britain\" as he killed Labour MP Jo Cox, the Old Bailey has heard.', 'negatives': [], 'positives': ['She was stabbed 15 times and shot three times outside her constituency surgery in Birstall, near Leeds, on 16 June - a week before the EU referendum.\\nJurors were told Thomas Mair, 53, killed the mother-of-two for \"political and/or ideological reasons\", and had researched \"far right\" material in the weeks beforehand.\\nMr Mair, from Birstall, denies murder.\\nMrs Cox, 41, had supported the Remain side during the EU campaign, and was due to hold a constituency surgery in a library after visiting a local school and care home when she was attacked.\\nMr Mair told police officers \"I am a political activist\" when he was arrested less than a mile from the murder scene, the court heard.\\nProsecutor Richard Whittam QC said: \"Thomas Mair clearly held views that provided him with a motive - utterly misplaced of course.\\n\"The prosecution suggests that motive was such that he killed her because she was an MP who did not share his views.\"\\nIt was as Mrs Cox arrived for her constituency surgery that Mr Mair approached her from behind and stabbed her before shooting her, the court heard.\\nFazila Aswat, the MP\\'s manager, allegedly heard the defendant shouting, \"This is for Britain. Britain will always come first,\" the prosecution told the jury.\\nItems found at Mr Mair\\'s home showed he had \"strong political and ideological interests\", Mr Whittam said.\\nThe court heard the accused had used computers to look up websites at the same library where Mrs Cox was due to hold her surgery.\\nIn May, he had accessed the Wikipedia page of an online publication called the Occidental Observer - a \"far-right\" publication \"that covers politics and society from a white nationalist and anti-Semitic perspective\", the prosecutor said.\\nJurors were told that in the days leading up to the killing that Mr Mair also looked at Twitter and Wikipedia pages for Mrs Cox and went on to view information on former Foreign Secretary William Hague.\\nAnd he viewed websites on Nazi material, the death penalty in Japan, political prisoners and the human liver and spinal column.\\nOn the eve of the attack, say prosecutors, Mr Mair researched right-wing politicians, as well as the Ku Klux Klan and civil rights activists killed by its supporters.\\nThe court heard Mr Mair was arrested following the attack and told officers he had a knife and gun in a black holdall he was carrying.\\nJurors were shown photographs of a German-made .22 Weihrauch bolt-action weapon and were told Mrs Cox\\'s blood was found on the barrel during forensic examination.\\nMr Whittam told the court a knife found in Mr Mair\\'s backpack also had blood on the handle which contained \"a major DNA profile matching that of Jo Cox and a minor DNA profile of the defendant\".\\nMrs Cox was shot three times, once in the chest and twice in the head, and stabbed 15 times including in the heart and lungs.\\nShe had wounds to her hands showing she raised them to try to defend herself, the court heard.\\nJo Cox was a self-proclaimed \"proud Yorkshire lass\" whose work for charity took her around the world and whose political success led her to Westminster.\\nThe 41-year-old mother-of-two was elected as MP for Batley and Spen in the 2015 election and increased Labour\\'s majority to 6,051 (from 4,406 in the 2010 election).\\nShe described herself as \"proud and humbled\" to be the Labour MP for the place where she was born.\\nMrs Cox first worked in politics after graduating from Cambridge University in 1995, but then built a career working for charities including Oxfam, Save the Children and the NSPCC.\\nShe was described by Labour leader Jeremy Corbyn as \"a much loved colleague, a real talent and a dedicated campaigner for justice and peace.\"\\nTireless campaigner turned political \\'star\\'\\nJurors were shown CCTV footage of the defendant making his way along the road after leaving his home on the morning of the killing.\\nThe court heard Mrs Cox arrived for her surgery with her manager Ms Aswat and senior caseworker Sandra Major at 12:50 BST.\\nThe prosecution claimed that Mr Mair attacked the Labour MP two minutes later in what it described as a \"dynamic, fast-moving and shocking incident\".\\nJurors were told that passer-by Shelly Morris reported hearing \"a loud bang like a popping sound\" and a \"loud piercing scream\".\\nShe said she saw a man with a large steak knife with a jagged blade which he wielded in a \"stabbing motion\".\\nJurors were told that 77-year-old Bernard Carter-Kenny was also injured as he tried to save Mrs Cox.\\nMr Mair denies murder, grievous bodily harm with intent, possession of a firearm with intent to commit an indictable offence and possession of an offensive weapon - a dagger.\\nThe trial continues, and is expected to last for up to three weeks.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A group of German-speaking parents in northern Italy are so angry about a new requirement to get their children vaccinated that they plan to seek asylum in nearby Austria.', 'negatives': [], 'positives': ['The 130 families live in Alto Adige - also known as South Tyrol - a region that was part of Austria before 1919.\\nLast month the Italian government ruled that children must be vaccinated against 12 common illnesses before they can enrol for state-run schools.\\nCases of measles have risen in Italy.\\nThe highly-contagious sickness is fatal in some cases. Some other European countries, including France and Romania, have also seen more measles cases this year.\\nIn some parts of Europe, including Italy, vaccination rates have dropped below those recommended by the World Health Organization (WHO).\\nThe leader of the South Tyrol protest, Reinhold Holzer, said the group had sent protest messages to Italian President Sergio Mattarella, Austrian President Alexander Van der Bellen, and the UN Human Rights Council in Geneva.\\n\"We won\\'t allow our children to be poisoned. Asylum is claimed not just by people fleeing war, but also by people whose rights are being violated,\" said Mr Holzer, quoted by Austria\\'s Der Standard daily.\\nTrentino-Alto Adige, a mountainous Alpine region, is reported to have one of the highest vaccine refusal rates in Italy.\\nIn an interview with Radio SÃ¼dtirol Mr Holzer alleged that some chemicals in vaccines were risky, and said parents should have a free choice about child immunisations, as in Germany, Austria and Switzerland.\\nHowever, Germany recently announced plans to fine parents who failed to get medical advice about immunising their child.\\nMr Holzer voiced concern about Thiomersal (or Thimerosal), a mercury-based preservative used in some vaccines, and about genetically engineered vaccines.\\nThe UK National Health Service says Thiomersal is not used in child vaccines - and adds that it poses no risk anyway.\\nConspiracy theories about the health risks of certain vaccinations - largely based on one discredited paper - have spread on the internet, prompting some parents to shun immunisation.\\nScientific studies have debunked an alleged link between vaccines and autism, as the US Centers for Disease Control point out on their website.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A celebration of the life of an 18-year-old from Inverness who died after going missing is to be held.', 'negatives': [], 'positives': ['Adam Mitchell disappeared after a night out in the city on 9 November.\\nHis family were told on 28 November that a body had been found at St Fergus, Aberdeenshire. Police have confirmed that it is Mr Mitchell.\\nHis family have asked that those attending the celebration wear band T-shirts as a tribute to the teenager\\'s love of music.\\nThe date and venue for the celebration are to be confirmed at a later date.\\nIn a death notice in the Inverness Courier, his family said: \"In honour of Adam we wish all who attend to wear band shirts.\\n\"Dig them out from the back of your wardrobe and wear them with pride as he did.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"A council appointed by Thailand's military rulers has rejected a controversial new constitution drafted after last year's coup.\", 'negatives': [], 'positives': ['A new committee must now be appointed to write another draft, further setting back elections.\\nThe draft has been widely criticised, in particular a clause which enables a 23-member panel to take over government during a \"national crisis\".\\nThe army ousted the elected government last year after months of unrest.\\nThe 247-member National Reform Council on Sunday rejected the draft charter by 135 votes to 105, with seven abstentions.\\nCorrespondents say that it met strong opposition on practically all sides of the political divide.\\nAnother committee will have 180 days to write a new one, which will later be put to a nationwide referendum.\\nAnalysis: By Jonathan Head, BBC News, Bangkok\\nSo what caused the military-appointed National Reform Council to reject their own side\\'s constitution, the fruit of nine months of labour?\\nPreliminary conversations with members of the council suggest a number of factors. Some say they wanted to give the new economic team appointed last month by Prime Minister Prayuth more time to improve the ailing economy. Others worried that hostility to the constitution would reignite political divisions in the country in the run-up to the referendum on the charter scheduled for January 2016.\\nSo the timetable for a return to elected government is postponed to early 2017, but many people here expect it will slip back even further, some wondering whether Thailand can have an election before the end of the decade.\\nPerhaps the military wanted their charter to fail. The inclusion, at the last minute, of a military-dominated council that for five years could legally take over the government whenever it felt necessary, outraged even some who might have supported the charter, making rejection in a referendum all the more likely.\\nThen there is the elephant in the room - the looming royal succession, perhaps the most important moment in Thailand\\'s modern history. With King Bhumibol so visibly frail, that could happen any day now. When it does, all talk of elections will be put on hold, possibly for years.\\nUntil a new constitution can be drafted, the military government retains its substantial powers.\\nIt had said elections could take place in late 2016, but analysts say the delay means 2017 is more likely.\\nCritics of the draft constitution say it would erode the power of political parties in favour of the army and prevent a genuine democracy from being established.\\nThailand has seen numerous different constitutions since the end of the absolute monarchy in 1932.\\nFor years the kingdom has been divided between pro-democracy parties that support former Prime Minister Thaksin Shinawatra, and an alliance of conservatives, including members of the military, the judiciary and royalists.\\nMr Thaksin\\'s allies have prevailed in every election since 2001, but have faced two coups and the removal of three prime ministers by the courts.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A band of heavy rain heading towards Wales has prompted the Met Office to issue a weather warning.', 'negatives': [], 'positives': ['Forecasters have said up to 30mm (1.1in) of rain could fall in south, mid and west Wales between Sunday night and Monday morning.\\nA yellow \"be aware\" warning has been issued from 21:00 BST and is in effect until midday.\\nLocalised flooding is likely, potentially worsened by wind-blown debris from Saturday\\'s strong gusts.\\nThe warning covers Blaenau Gwent, Bridgend, Caerphilly, Cardiff, Carmarthenshire, Merthyr Tydfil, Monmouthshire, Neath Port Talbot, Newport, Powys, Rhondda Cynon Taff, Swansea, Torfaen and the Vale of Glamorgan.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"A humpback whale, thought to be a returning visitor for the third year, has appeared off Norfolk's coast.\", 'negatives': [], 'positives': ['Several whale watchers have reported spotting the mammal in waters about 2.5 miles (4km) off Winterton.\\nIt was accompanied by gannets that were feeding on herrings, the same food source as the whale.\\nNorfolk cetacean recorder Carl Chapman was unable to get close enough to confirm whether it was the same whale that was seen over the past two years.\\nMr Chapman said he was \"ecstatic\" to see the whale off the Norfolk coast.\\n\"I watched if for about one-and-a-half hours,\" he said.\\n\"I was trying to identify it from the undertail pattern, which is unique to each whale, but it never came close enough to do that.\\n\"However, because it\\'s turned up at the same time as it has done in the two previous consecutive years, it\\'s probably the same returning individual making use of the same food source.\"\\nLucy Babey, from charity ORCA, said the whale had been seen over five to six hours and was fluking - lifting its tail out of the water - regularly.\\nHumpback whales are seen more often on the European side of the North Sea, rather than on the UK side, she said.\\nThe Sea Watch Foundation said there had been additional sightings off Sheringham, Hemsby and Horsey Gap, and also reports of minke whales seen from Trimingham, Mundesley and Happisburgh.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Payday lender Wonga says it is writing off £220m of debts for 330,000 customers after putting in place new affordability checks.', 'negatives': [], 'positives': ['The company, which has faced criticism for its high interest rates and debt collection tactics, made the changes after discussions with regulators.\\nCustomers in arrears whose loans would not have been made under the new checks will have their debts written off.\\nA further 45,000 customers in arrears will not have to pay interest on loans.\\nAffected Wonga customers will be notified by 10 October.\\nWonga\\'s chairman Andy Haste, who joined the company in July, said a review of lending practices had shown the need for change at Wonga was \"real and urgent\", and new stricter lending criteria would mean \"accepting far fewer applications from new and existing customers\".\\nAnalysis: Jonty Bloom, business correspondent, BBC News\\nPay day lenders first appeared in the US, but are only legal in 27 states and interest rates are generally limited to 40%. They began appearing in the UK 20 years ago, and there are currently no limits on their charges here - although the government wants to bring in a cap next year.\\nWonga itself is only seven years old but has become the best known thanks in part to its catchy advertising.\\nAll pay day lenders normally lend to those not welcome elsewhere, because their poor credit rating or low income means mainstream lenders see them as unlikely to repay any loan.\\nSince the downturn their business has expanded rapidly, leading to criticism they are making millions lending to the desperate. Some say they are little more than legalised loan sharks, but supporters say if they did not exist, hard-pressed people would have to borrow from real loan sharks.\\n\"We want to ensure we only lend to those who can reasonably afford the loan in question and during my review, it became clear to me that this has unfortunately not always been the case,\" he said.\\n\"I agreed with the concerns expressed by the FCA and as a consequence of our discussions we have committed to taking these actions.\"\\nIn a statement, the FCA said Wonga\\'s changes were as a result of a \"voluntary agreement\" reached between the lender and regulator.\\n\"This should put the rest of the industry on notice,\" said Clive Adamson, director of supervision at the FCA. \"They need to lend affordably and responsibly.\"\\nWonga has also been told it must appoint a \"skilled person\" to monitor its lending decisions and report back to the FCA.\\nOne Wonga customer from South Yorkshire told the BBC that Wonga\\'s credit checks had been \"poor at best\".\\n\"I\\'m currently in arrears of £564 with Wonga for a loan that started in 2012. I got caught up in the whirlwind of being able to have money deposited in your account within minutes.\\n\"I was allowed to exaggerate my income on the application forms. They weren\\'t checked to be sure that I wasn\\'t giving false information. I should never have been lent the money.\"\\nWonga currently provides lending services to about one million customers a year.\\nBut it and the wider payday loan industry have attracted controversy because of the relatively high rates of interest charged to customers, which can quickly escalate if repayments are not made on time.\\nIn June, Wonga also admitted sending customers in arrears fake letters from non-existent law firms in an apparent attempt to scare them into repayments, and agreed to pay £2.6m in compensation.\\nThe move to tighten up lending criteria is likely to hit Wonga\\'s earnings. Earlier this week, it announced a 53% fall in annual profits and said it expected to be \"smaller and less profitable\" in future, partly as a result of new controls set by the FCA.\\nMichael Ruck, senior associate at Pinsent Masons and a former FCA lawyer, said Wonga will now be required to get more information on potential customers before making loans - an expensive process.\\nHe said the whole landscape for payday loan companies was changing dramatically.\\n\"It certainly raises questions of Wonga and other firms about how they set up their business models going forward,\" Mr Ruck told the BBC.\\n\"They are clearly no longer going to be able to rely on revenues from customers paying high rates of interest without fully understanding the implications.\\n\"In terms of other firms they are being told that: \\'If you don\\'t get this right, this is what is going to happen\\'.\"\\nThe debt charity StepChange welcomed Wonga\\'s move, but said it needed to be part of a \"comprehensive reform of the short-term credit market\".\\n\"People will always need to borrow, and we need responsible lenders to allow this to happen in a fair environment,\" chief executive Mike O\\'Connor said.\\nCase study: \\'I lied to get a £120 Wonga loan for a holiday\\'\\nWhen Elliott Gomme needed money for a holiday, he turned to payday lender Wonga.\\nHe needed £120 and says he didn\\'t have a problem convincing them to lend him cash by saying he worked full-time.\\nBut the 20-year-old admitted lying on his application and told BBC Newsbeat it was \"too easy\" to be accepted.\\nHe\\'s now likely to be one of 330,000 people whose debts will be written off after a ruling that Wonga lent money to people who couldn\\'t repay it.\\n\"My bank couldn\\'t give me an overdraft or anything, and so I went to [Wonga],\" he says.\\nHe received his money and went on holiday, but a few weeks later he says the firm started calling him and he says they were \"constant\".\\n\"They were ringing me every day,\" he says. \"They were telling me how much I owe and that there was added interest.\"\\nElliot says that a few months later he was being told his debt had risen to more then £800 and it began to affect his day-to-day life.\\nHe says the amount of the debt was making him feel depressed and that he had \"no idea\" what he would have done if this ruling hadn\\'t come.\\nIn Elliott\\'s opinion, the whole process is too simple and he wants payday lending to be banned.\\n\"It\\'s so easy to go online and get one that you don\\'t really look at the small print and they don\\'t really tell you that much,\" he says.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A man died when he was hit by a car while out celebrating the New Year in the West Midlands.', 'negatives': [], 'positives': ['The 43-year-old was struck in Wolverhampton Road, near the junction of Hagley Road West in Sandwell, just before 20:00 GMT on Saturday.\\nA 46-year-old female driver involved in the collision stopped nearby and was assisting investigators.\\nDet Con Jamie Simon, of West Midlands Police, said it was \"an extremely sad start\" to the New Year.\\nA spokesman said: \"The junction where the collision occurred is very busy, probably more so last night with people heading out for New Year, and I have no doubt several people will have seen what happened or witnessed the build-up to the incident.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Labour is firmly committed to devolved policing, according to its general election campaign chairman in Wales.', 'negatives': [], 'positives': ['Opponents rounded on shadow home secretary Diane Abbott on Tuesday, accusing her of failing to explain her party\\'s policy.\\nBut Wayne David said Welsh party colleagues have \"more of an ear to the ground than perhaps Diane\".\\nLabour\\'s manifesto would give Welsh ministers a bigger role in policing, he told BBC Wales.\\nIt is something First Minister Carwyn Jones\\'s Welsh Government has called for.\\nThe Conservatives have ruled out the devolution of policing, while Plaid Cymru accused Labour of not fighting hard enough in Westminster to make it happen.\\nMr David was responding to a BBC Radio Wales interview by Ms Abbott on Tuesday when she said \"we don\\'t think it\\'s right at this time to devolve policing, but this is something there\\'s constant discussion about inside the Labour Party\".\\nShe later said: \"We will make our position clear on this in the coming weeks.\"\\nMr David said Labour\\'s 2015 manifesto was very clear \"that we favoured, at that time, an all-Wales plan drawn up by Welsh ministers\".\\n\"That will certainly be in the manifesto, but is likely to be embellished upon and the final details are being worked on as we speak.\\n\"The Labour Party is firmly committed to extending devolution.\"\\n\"It is still being discussed,\" he added.\\n\"Because we are in Wales we have got a little bit more of an ear to the ground than perhaps Diane.\\n\"But nevertheless I can tell you that the Labour Party is firmly committed to strong policing, to neighbourhood policing and devolved policing as well.\"\\nHowever he denied Ms Abbott had got her facts wrong.\\nShe was also criticised for failing to explain how Labour would fund plans to employ 10,000 more officers, 853 of them in Wales.\\nFor the Conservatives, Welsh Secretary Alun Cairns said: \"The reality is that crime doesn\\'t stop at administrative borders, it doesn\\'t stop at the Welsh border.\\n\"We want a strong police force properly funded by a strong leader delivering a strong economy that can pay for those essential public services.\"\\nPlaid candidate Liz Saville Roberts said: \"If the Labour party were serious about supporting our police forces and keeping Wales safe, they wouldn\\'t have voted with the Tories to keep Welsh policing in Westminster\\'s hands. \"\\nUKIP\\'s leader in the assembly, Neil Hamilton, said the party did not have a policy on it, but he was personally \"very favourable to devolving further powers... because I think we need to make the government in Cardiff more responsible for the things that are done in Wales\".\\nFormer Welsh Liberal Democrat leader Lord German - whose party has backed devolving policing - said: \"The shadow home secretary couldn\\'t even give an answer on whether policing should be devolved to Wales.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A mother accused of taking her toddler to Syria and joining so-called Islamic State told police her time there was \"hell\" and \"horrible\", a court heard.', 'negatives': [], 'positives': ['In interviews, she told police she \"just ran, ran, ran\" with her child, Birmingham Crown Court heard.\\nProsecutors say Tareena Shakil, 26, originally from Burton upon Trent in Staffordshire and more recently from Birmingham, is lying.\\nMs Shakil denies joining IS and encouraging acts of terror via Twitter.\\nProsecutors said Ms Shakil told her family she was \"happy as Larry\" to be in Syria during the three months she spent there from October 2014, they said.\\nEarlier, the prosecution at Birmingham Crown Court said she invented her story and showed messages in which they claimed she told friends and family she was happy to be living in Raqqa.\\nThey also showed photographs of her posing wearing an IS balaclava and brandishing an AK-47 rifle.\\nA senior security analyst told the court the only women allowed access to weapons in IS were members of the all-female specialist police unit, the Al-Khansa brigade.\\nIn her police tapes Ms Shakil says she went on a package holiday to Turkey, fell for a man at the beach and was then kidnapped and driven across the border.\\nShe told police she eventually arrived in Raqqa, where she lived with other unmarried girls, some of whom were given arranged marriages to jihadi fighters.\\nSome women had wanted to escape, and some did, she said, but she decided to \"act dumb\" and try to work out how to travel around the country.\\nShe decided to escape after three months, she said, and paid a taxi driver $50 to drive her towards the Turkish border.\\nWhen they were within 1km of it, she grabbed her child and ran, she told police. She said some Turkish soldiers helped her over the border.\\nShe came back to the UK in February and was arrested at Heathrow.\\nDr Florence Gaub, the security expert, said the only women who would be permitted to leave Raqqa would be the members of the Al-Khansa brigade.\\nThe trial continues.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'US President Donald Trump and British Prime Minister Theresa May have reaffirmed their commitment to the Nato alliance after White House talks.', 'negatives': [], 'positives': ['Mrs May confirmed Mr Trump was \"100% behind Nato\" despite the president\\'s recent comments calling the transatlantic alliance obsolete.\\nBoth leaders said they would work to establish trade negotiation agreements.\\nMrs May also said Mr Trump had accepted an invitation from the Queen for a state visit later this year.\\n\"Great days lie ahead for our two peoples and our two countries,\" Mr Trump said.\\nThe prime minister added that a trade agreement between the UK and US was \"in the national interest in both our countries\".\\nAlthough the UK cannot begin to negotiate trade deals until it leaves the EU, Mr Trump has said he wants a \"quick\" deal after that.\\nWhen asked about Mr Trump\\'s scheduled phone call with Russian President Vladimir Putin on Saturday, the president played down any suggestion that he would lift US sanctions against the Kremlin.\\n\"It\\'s very early to be talking about that,\" he told reporters during a news conference.\\nBy Laura Kuenssberg, BBC political editor\\nIf they wanted to display closeness - the image of Theresa May hand in hand with Donald Trump could hardly have been more useful for Downing Street.\\nSources in government were delighted that she visibly forced out a 100% commitment from him to Nato, the more experienced politician perhaps, the formal, next to the flash.\\nThe relationship between any prime minister and any president is always important. But with Britain stepping back from its European ties, the bonds across the Atlantic become only more vital.\\nTheresa May\\'s presence seemed to bring out a more restrained Donald Trump. Could she be building an image, a role, as a good influence on the rogue president?\\nThis is a high wire act. For hitching her own political fortunes to president Trump, praising his \"stunning victory\", gambles that he will not crash and burn as president, gambles that those concerned about his beliefs at home, will not be repelled by her overtures to the new leader.\\nOnly a perverse British prime minister would not try to build a good relationship with an American leader. But Theresa May\\'s host is a new kind of president. The pressure this new political friendship could put on her will be new too.\\nRead more from Laura\\nHe also said having a \"great relationship\" with countries like Russia and China \"would be a positive, not a negative\".\\nMeanwhile, Mrs May stood firm with the European Union\\'s stance on sanctions against Russia.\\n\"We have been very clear that we want to see the Minsk agreement fully implemented,\" she said, adding that the sanctions would continue until that is achieved.\\nMr Trump said he would also defer to retired general and Defense Secretary James Mattis on whether he would reinstate the use of waterboarding as an interrogation technique.\\nThe president said Mr Mattis does not \"necessarily believe\" in waterboarding and other interrogation techniques, which critics view as torture.\\n\"I don\\'t necessarily agree, but I would tell you that he will override because I\\'m giving him that power,\" Mr Trump said of General Mattis.\\n\"I happen to feel that it does work. I\\'ve been open about that for a long period of time. But I am going with our leaders.\"\\nAlso on Friday, at the end of Mr Trump\\'s first week in power, he:\\nAsked about how well he got along with the British prime minister, he joked: \"I\\'m not as brash as you might think.\"\\nAnd Mrs May said the two of them share a political approach of putting \"the interests of ordinary people\" first, reaffirming the US and UK\\'s longstanding \"special relationship\".\\nThe president also boasted about Brexit, calling it a \"wonderful thing\".\\nHe contended that was \"scorned\" by media for predicting Brexit during a visit to Scotland, the day before the vote.\\nBut Twitter users were quick to point out that when in the UK, Mr Trump spoke to the media a day after the EU referendum.\\nEarlier, the two leaders posed for photographs in front of a bust of Sir Winston Churchill - which Mr Trump pointed to, saying it was \"a great honour\" to have it back.\\nThe new president had the bust restored to the Oval Office after it was removed by former president Barack Obama.\\nMrs May smiled and told him: \"Thank you, we were very pleased that you accepted it back.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Making people feel ashamed about obesity could lead them to gain weight, not lose it, suggests University College London.', 'negatives': [], 'positives': ['In a study of nearly 3,000 adults over four years, those who said they had experienced weight discrimination put on more weight than those who did not.\\nResearchers said there was no evidence discrimination caused weight gain, but it could lead to comfort eating.\\nHealth professionals were urged to be more supportive.\\nThe study, in the journal Obesity, looked at data from adults aged over 50 ranging from normal weight to obese who had taken part in the English Longitudinal Study of Ageing.\\nThey were asked if they had experienced day-to-day discrimination that they believed to be connected to their weight.\\nExamples of discrimination included being treated disrespectfully, receiving poor service in shops and being harassed.\\nOne in 20 reported weight discrimination, and in the morbidly obese group one in three reported discrimination.\\nMen and women reported similar levels of weight discrimination.\\nOver the four-year period, on average, people in all weight groups who said they had experienced these negative attitudes put on nearly 1kg - just over 2lb.\\nThose who did not typically lost 0.7kg.\\nThe researchers say this suggests that blaming and shaming people for being overweight is counterproductive.\\nInstead they say it is better to be supportive and encouraging.\\nDr Sarah Jackson, lead study author from the department of epidemiology and public health at UCL, said: \"There is no justification for discriminating against people because of their weight.\\n\"Previous studies have found that people who experience discrimination report comfort eating.\\n\"Stress responses to discrimination can increase appetite, particularly for unhealthy, energy-dense food.\\n\"Weight discrimination has also been shown to make people feel less confident about taking part in physical activity, so they tend to avoid it.\"\\nThe study said \"widespread weight bias\" had been reported in health professionals, and not just among the general public.\\nProf Jane Wardle, director of the Cancer Research UK Health Behaviour Centre at UCL, said weight discrimination was part of the obesity problem - not the solution.\\n\"Everyone, including doctors, should stop blaming and shaming people for their weight and offer support, and where appropriate, treatment.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A seismic sensor firm has rejected claims that its geological monitoring systems are vulnerable to cyber attack.', 'negatives': [], 'positives': ['Allegations about poor security controls in Nanometrics\\' sensors were made in a presentation at the Def Con hacker convention last week.\\nNanometrics said an independent report into the researchers\\' work cast serious doubt on its findings.\\nThe sensors are used to monitor active volcanoes, fault lines and support nuclear test ban treaties.\\nBertin Bonilla, a security researcher based in Costa Rica who, with colleague James Jara, carried out the work said the network of sensors came to light during a separate project that mapped smart devices connected to the net to create a search engine for the Internet of Things.\\nHowever their report was shelved by the Computer Emergency Response Team Co-ordination Centre (Cert CC) at Carnegie Mellon university in the US.\\nThe devices stood out because of the distinctive fingerprint of data they surrendered to scanning software and because of their location in remote spots and in the sea, claimed Mr Bonilla.\\n\"We have not seen any research previously in this field,\" he said during a presentation at the convention that was held in Las Vegas.\\nBy analysing firmware in the sensors, the pair managed to get hold of default passwords that gave them access to data being gathered by sensors. This could prompt an attack on monitoring networks, they claimed.\\nAt Def Con, Mr Bonilla said the pair had detailed their findings in a report sent to Cert CC.\\nThe report was sent in late June and Cert CC contacted Nanometrics for clarification about the points it raised.\\nCert CC shared the report with engineers at Nanometrics who said it contained \"factual inaccuracies\" about the way the sensors worked. In particular, they said, it wrongly characterised the way data is gathered from networks of sensors.\\nCert CC then shelved the report and attempted to contact Mr Bonilla and Mr Jara for clarification.\\nNo response was received and in correspondence with Nanometrics, Cert CC said it was satisfied that the report was \"incorrect\".\\nThe two researchers have also not responded to a request for comment from the BBC.\\nA spokesman for Nanometrics told the BBC that the researchers had found some networks of sensors operated by organisations that had not changed default passwords.\\n\"We have always recommended to our customers that they change the factory default passwords and when using the systems on real-time communications networks, they limit access to known IP addresses and/or use VPN software,\" he said.\\nOrganisations operating sensors that gather sensitive data, such as for nuclear test ban monitoring, typically put the monitors on private networks that are not connected to the net, he said.\\nThe large scale of the sensor networks and the way data was shared and verified meant an attack that sought to spoof readings would be \"impossible\" to pull off, added the spokesman.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Donald Trump's legal challenge to a planned offshore wind farm has been rejected by the UK's Supreme Court.\", 'negatives': [], 'positives': ['Developers hope to site 11 turbines off Aberdeen, close to Mr Trump\\'s golfing development on the Aberdeenshire coast.\\nThe US businessman and presidential hopeful was taking on the Scottish government, which approved the plan.\\nThe Trump Organisation said it was an \"extremely unfortunate\" ruling and it would \"continue to fight\" the wind farm proposal.\\nFormer First Minister Alex Salmond said the latest court verdict left Mr Trump a \"three-time loser\".\\nThe Trump Organisation responded: \"Does anyone care what this man thinks? He\\'s a has-been and totally irrelevant.\"\\nMr Trump began his challenge to the decision to grant planning permission more than two years ago.\\nHe was furious when the Scottish government approved plans for the renewable energy development within sight of his multi-million pound golf development on the Menie estate, north of Aberdeen.\\nHe said the turbines would spoil the view.\\nMr Trump made a series of legal challenges in the Scottish courts and then took the fight to the UK\\'s Supreme Court in London.\\nHe argued that planning consent for the wind farm was so imprecise as to make it legally invalid.\\nThe Supreme Court judges delivered a unanimous ruling.\\nThe Trump Organisation said: \"This is an extremely unfortunate verdict for the residents of Aberdeen and anyone who cares about Scotland\\'s economic future.\\n\"The EOWDC (European Offshore Wind Deployment Centre) will completely destroy the bucolic Aberdeen Bay and cast a terrible shadow upon the future of tourism for the area.\\n\"History will judge those involved unfavourably and the outcome demonstrates the foolish, small-minded and parochial mentality which dominates the current Scottish government\\'s dangerous experiment with wind energy.\\n\"We will evaluate the court\\'s decision and continue to fight this proposal on every possible front.\"\\nAndy Paine, project director for Aberdeen Offshore Wind Farm Ltd, said: \"This is another significant step forward for the EOWDC.\\n\"It affirms the scheme\\'s potential to position Scotland, and particularly the north east, as a centre of innovative offshore wind power.\"\\nEnergy Minister Fergus Ewing said:  \"I am pleased that the Supreme Court has unanimously found in our favour.\\n\"The proposed European Offshore Wind Deployment Centre is an important project for Aberdeen and north east Scotland.\\n\"It will give the industry the ability to test and demonstrate new technologies to enable costs to be further reduced.\\n\"Aberdeen is already of global importance for hydrocarbons and this wind deployment centre cements its role in renewable offshore development, further positioning Aberdeen as the energy capital of Europe and a world energy centre.\"\\nSNP MP and MSP Mr Salmond, who led the Scottish government until a year ago, said: \"As first minister, I was cited in Trump\\'s legal action. Now that it is concluded, I am free to speak my mind on the damaging impact of his interventions on the Scottish economy.\\n\"These proceedings have been dragged out for years through three successive court judgements by Donald Trump as he tried to stop an offshore Aberdeen wind turbine demonstrator by means of legal action.\\n\"In doing so he has at best postponed, and at worst jeopardised, a vital Â£200m boost for the economy of the north east of Scotland.\\n\"The offshore project could have been built by now with Aberdeen benefiting from becoming the offshore wind research centre of Europe - a vital development at a time of rock bottom oil prices.\"\\nWWF Scotland director Lang Banks said: \"This result is great news for Scotland and for all those interested in tackling climate change and creating jobs.\\n\"Having failed in his attempt to undermine Scotland\\'s renewables ambitions, it\\'s now time for Mr Trump to move on.\"'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'A man has been found guilty at the Old Bailey of beheading his common-law wife at their east London flat.', 'negatives': [], 'positives': ['Crane driver Dempsey Nibbs killed Judith Nibbs, his partner of 30 years, after he suspected her of having affairs, the court heard.\\nNibbs, 69, of the Charles Estate in Hoxton, had denied murder.\\nJudith Nibbs, 60, was described as \"bubbly and happy\". She had confided in her sister and a colleague that her partner had threatened to kill her.\\nDuring the trial, Crispin Aylett QC, prosecuting, said the couple\\'s relationship had soured in the spring of 2014 as Mr Nibbs suspected his partner of infidelity.\\nDuring a row on 7 April, she had taunted Mr Nibbs with details of her infidelities, saying: \"I have had sex eight times.\"\\nOn the night of 10 April, Mr Nibbs attacked her in their Hoxton flat and knocked her out, Mr Aylett said.\\n\"Having attacked his wife, the defendant then took up a kitchen knife and cut off her head,\" he said.\\nThe court heard how Mr Nibbs disposed of remains down the lavatory, before writing a suicide note to his son and ringing police to tell them they would find \"a couple of dead bodies\" at his home.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'Apple has defended its environmental record after allegations that some of its suppliers are polluting in China.', 'negatives': [], 'positives': [\"The technology giant said that it was committed to the highest standard of social responsibility.\\nThe comments come after a report by Chinese environmental groups claimed a number of Apple manufacturers were discharging harmful pollutants.\\nChinese companies have often been criticised for focusing on output rather than environmental issues.\\nThe report by the Institute of Public and Environmental Affairs (IPE) and other non-governmental environment groups also said that one factory in the city of Taiyuan emitted irritating gases and residents had reported difficulty opening their windows.\\nIn response, Apple told the BBC's Michael Bristow that the company had a tough code of conduct for all its supply firms and it audited many of them.\\nBut a company report released earlier this year found dozens of suppliers across the world were mishandling dangerous chemicals.\\nMore than 100 workers were contaminated at one Chinese plant.\\nEnvironmental groups say China does not have sufficient rules in place to protect the environment and Apple is taking advantage of that.\"], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'The longest war the US has ever fought - 16 years and counting - is about to get longer as President Donald Trump decides on sending several thousand more troops to Afghanistan.', 'negatives': [], 'positives': ['As with the wars in the Middle East, Afghanistan highlights the difficult political choices and counter-insurgency strategies the US has been pursuing fruitlessly since 9/11. Today six Muslim countries (Iraq, Syria, Yemen, Libya, Somalia and Afghanistan) are in a state of meltdown - partly as a result of US policies.\\nThe \"war on terror\" launched by President George Bush, the US invasions of Afghanistan and Iraq, and the conflicting policies of carrying out regime change in the midst of an ever-expanding Islamist extremist opposition have all created greater dilemmas for the US.\\nSince 9/11 there have been many good books and documentary films made about these dilemmas. Yet in all this time Hollywood has been unable to produce a movie that informs or educates the average movie-goer as to the bigger picture on why failure persists and jihadism spreads.\\nThe few Hollywood films made about America\\'s wars tend to be either satires or action movies in the John Wayne mould, showing US troops as heroic and caring but professional killers.\\nAn exception was the 2008 film Hurt Locker, which won six Oscars and depicted the dilemmas faced by a US Explosive Ordinance Disposal unit in Iraq. But even Hurt Locker dealt with only a slice of the problem, as did otherwise well-made documentaries about US forces in Afghanistan such as Restrepo and Korengal.\\nHollywood movies do not ask the difficult strategic questions.\\nShould the US invade or interfere in countries it knows little about, how do US troops win over local support, is nation building and promotion of democracy feasible by one part of the US government while another part pursues a war strategy?  Can the US ever understand tribal societies through the barrel of a gun?\\nHollywood has left us devoid of any understanding of the escalating global chaos.\\nThat is until now. A remarkable new film, War Machine starring Brad Pitt, which at first whiff sounds like a gonzo-type war movie, brilliantly portrays these themes outlined above. David Michod, the Australian writer and director, and Netflix have made a movie that is both dark and satirical, emotional and belly-laugh funny, as well as being educative about US interventions.\\nThe script is based on the Rolling Stone magazine article and subsequent book The Operators: The Wild and Terrifying Inside Story of America\\'s War in Afghanistan, by the late journalist Michael Hastings.\\nHis article led to the 2010 sacking of Stanley McChrystal, the US general in charge of the war in Afghanistan, after he and his staff officers made disparaging remarks about President Barack Obama to the journalist. The movie tells the story leading up to Gen McChrystal\\'s dismissal.\\nThe casting of Pitt as Gen Glen McMahon, the imagined McChrystal who is beloved by his men but also full of comic eccentrics, is near perfect. Pitt plays his role partly as absurdist comedy but also as someone who is on a steep learning curve on how to win or lose modern wars.\\nFull of bluster and self confidence Gen McMahon arrives to take charge in Kabul after another general had failed. \"Let\\'s go win this thing,\" and \"Let\\'s knock this on the head,\" he tells his military aides - a coterie of equally brilliant actors whose cameos act as foils for Gen McMahon\\'s slow realisation that he is only repeating what other generals before him have tried and failed to do.\\nGen McMahon cannot get the additional US troops he needs because Mr Obama is reluctant to send any. Gen McMahon cannot stop Afghan farmers from growing poppy because, officials tell him alternative crops like cotton would be competing with US farmers.\\nFellow Nato officers teach Gen McMahon a new reality. \"You can\\'t build a nation at gunpoint\" and \"you can\\'t win the trust of a country by invading it\", he is told.\\nA cynical President Hamid Karzai, superbly played by Ben Kingsley (with all of Mr Karzai\\'s habitual tics), hears out Gen McMahon describing how he will mark out a new direction. \"We will build Afghanistan into a free and prosperous nation,\" says Gen McMahon.  \"Sounds a lot like the old direction,\" Mr Karzai replies with a knowing smile.\\nSeveral dark yet truthful encounters speed up Gen McMahon\\'s understanding. A troubled and angry US marine played by Lakeith Stanfield questions how his contradictory strategy can work. Trained to kill, the marines is now told he must show \"courageous restraint\".\\n\"I can\\'t tell the difference between the people and the enemy,\" says the marine. \"They all look alike to me. We can\\'t help them and kill them at the same time. I am confused,\" he states.\\nActress Tilda Swinton, playing a German politician, tells Gen McMahon that \"you are spread all over the country and fighting 1,000 separate battles with local people who don\\'t want you in their villages and that is a war you will never win\". The general is gobsmacked into silence.\\nThe film will not get a wide cinema release because it is showing on Netflix. However, this is a film that should particularly be shown at universities and colleges, and discussed amongst young and old.\\nIt helps us understand why counter-insurgency is failing, terrorism expanding and why wars have destroyed so many countries. It helps explain why after 16 years Washington is still debating troop numbers.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': \"Emma Thompson has spoken for the first time about why she isn't taking part in the upcoming Love Actually sequel.\", 'negatives': [], 'positives': ['A 10-minute film is currently being produced to raise money for Comic Relief.\\nThompson appeared in the original 2003 film as the wife of Alan Rickman\\'s character.\\nBut in light of the actor\\'s death last year, Thompson has said it would be \"too sad\" and \"too soon\" to revisit her character.\\n\"Richard [Curtis, the writer] wrote to me and said \\'darling we can\\'t write anything for you because of Alan\\' and I said \\'no of course, it would be sad, too sad\\'.\\n\"It\\'s too soon. It\\'s absolutely right because it\\'s supposed to be for Comic Relief but there isn\\'t much comic relief in the loss of our dear friend really, only just over a year ago.\\n\"We thought and thought but it just seemed wrong but to revisit the wonderful fun characters of Bill Nighy and Hugh Grant and Liam [Neeson] and all of that, that\\'s fantastic but obviously what would he [Richard Curtis] have done?\"\\nSpeaking about what might have happened to their characters Karen and Harry, whose marriage is rocked by Harry\\'s affair with a colleague in Love Actually, Thompson added: \"Both of them would be in therapy by now and I would be working on some kind of ward.\\n\"It was absolutely the right decision.\"\\nThe short sequel, which will be broadcast on BBC One on 24 March, has already begun filming.\\nRowan Atkinson, Liam Neeson and Thomas Brodie-Sangster (the now-not-so-little boy from the first film, who also stars in Game of Thrones) have been seen shooting their scenes.\\nAtkinson returns as the shop assistant Rufus, who was painfully-slow at gift wrapping in the first film. He  now appears to be working in a supermarket.\\nHugh Grant, Martine, McCutcheon, Keira Knightley, Liam Neeson, Colin Firth and Bill Nighy are among the other actors reprising their roles.\\nRead more about Red Nose Day Actually.\\nFollow us on Facebook, on Twitter @BBCNewsEnts, or on Instagram at bbcnewsents. If you have a story suggestion email entertainment.news@bbc.co.uk.'], 'type': 'sts_triplet', 'source_id': 0}\n",
            "{'query': 'It is east of the city of Benalla . The local government that looks after Greta is the Rural City of Wangaratta .', 'positives': ['Greta is a district in Victoria , Australia , located east of Benalla , in the Rural City of Wangaratta .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'During the 1860s the land was sold into small farm lots , used for cereals , cattle grazing , and dairying .', 'positives': ['During the 1860s the land was subdivided into farming lots , used for cereals , cattle grazing , and dairying .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The first township known as Greta , on Fifteen Mile Creek , is now called Greta West .', 'positives': ['The original township known as Greta , located on Fifteen Mile Creek , is now called Greta West , and was once home to the family of bushranger Ned Kelly .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'At that time , there was a large swamp , which was later drained .', 'positives': ['At that time , the area contained the Greta Swamp , which was later drained .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'La BoissiÃ re , Calvados is a commune . It is found in the region Basse-Normandie in the Calvados department in the northwest of France .', 'positives': ['La BoissiÃ re is a commune in the Calvados department in the Basse-Normandie region in northwestern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Tracey Claire Fisher , better known as Tracey Gold , is an American actress . She is best known for playing Carol Seaver in the sitcom Growing Pains ( 1985-1992 ) .', 'positives': ['Tracey Gold ( born May 16 , 1969 ) is an American actress best known for playing Carol Seaver on the 1980s sitcom Growing Pains .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The thickness of the duvet is measured by a tog rating . The higher the tog , the warmer the duvet will be .', 'positives': ['A few manufacturers have marketed combined duvet sets consisting of two duvets ; one of approximately 4.5 tog and one of approximately 9.5 tog .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The higher the tog , the warmer the duvet will be .', 'positives': ['The higher the tog rating the warmer the duvet .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'When she went to college , she wrote for literary magazines , like Huntress and Rammer Jammer .', 'positives': ['While attending college , she wrote for campus literary magazines : Huntress at Huntingdon and the humor magazine Rammer Jammer at the University of Alabama .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In 1957 , Lee showed her writing to a literary agent Capote told her about .', 'positives': ['Hoping to be published , Lee presented her writing in 1957 to a literary agent recommended by Capote .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'She went to Huntingdon College in Montgomery ( 1944 â `` 45 ) , and then studied law at the University of Alabama ( 1945 â `` 49 ) .', 'positives': ['She attended Huntingdon College in Montgomery ( 1944 â `` 45 ) , and then studied law at the University of Alabama ( 1945 â `` 49 ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"It is told in the first person by Jean Louise `` Scout '' Finch . She is six years old ; lives with her older brother Jeremy `` Jem '' ; her father Atticus , a lawyer ; her mother died when she was young .\", 'positives': ['The narrator , six-year-old Scout Finch , lives with her older brother Jem and their widowed father Atticus , a middle-aged lawyer .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The National Endowment for the Arts describes how Lee once became so unhappy that she threw her manuscript out the window into the snow .', 'positives': [\"A description of the book 's creation by the National Endowment for the Arts relates an episode when Lee became so frustrated that she tossed the manuscript out the window into the snow .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Jem and Scout become friends with a boy named Charles Baker Harris , nicknamed Dill , who visits Maycomb to stay with his aunt in the summer .', 'positives': ['Jem and Scout befriend a boy named Dill who visits Maycomb to stay with his aunt for the summer .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'At both colleges , she wrote short stories and other works about racial unfairness , which was not usually written about in colleges at the time .', 'positives': ['At both colleges , she wrote short stories and other works about racial injustice , a rarely mentioned topic on such campuses at the time .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The editors at Lippincott told Lee that she would probably sell only several thousand copies .', 'positives': ['The editorial team at Lippincott warned Lee that she would probably sell only several thousand copies .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The story happens during three years of the Great Depression in the fictional town of Maycomb , Alabama .', 'positives': [\"The story takes place during three years of the Great Depression in the fictional `` tired old town '' of Maycomb , Alabama .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Harper Lee was born in 1926 and grew up in the Southern town of Monroeville , Alabama . There , she became close friends with Truman Capote , who became a famous writer later .', 'positives': ['Born in 1926 , Harper Lee grew up in the Southern town of Monroeville , Alabama , where she became close friends with soon-to-be famous writer Truman Capote .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Lee also writes about bravery , compassion , and gender roles in the American Deep South .', 'positives': ['Scholars have noted that Lee also addresses issues of class , courage , compassion , and gender roles in the American Deep South .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'To Kill a Mockingbird is a Southern Gothic novel and a bildungsroman ( a story where the main character develops and grows ) . Its main themes are racism and innocence .', 'positives': ['As a Southern Gothic novel and a Bildungsroman , the primary themes of To Kill a Mockingbird involve racial injustice and the destruction of innocence .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"One critic wrote , `` In the twentieth century , To Kill a Mockingbird is probably the most widely read book dealing with race in America , and its protagonist , Atticus Finch , the most enduring ( long-lasting ) fictional image of racial heroism . ''\", 'positives': [\"One critic explains the novel 's impact by writing , `` In the twentieth century , To Kill a Mockingbird is probably the most widely read book dealing with race in America , and its protagonist , Atticus Finch , the most enduring fictional image of racial heroism . ''\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The narrator 's father ( the father of the person telling the story ) , Atticus Finch , is thought of as a hero by many readers and a model for lawyers .\", 'positives': [\"The narrator 's father , Atticus Finch , has served as a moral hero for many readers and as a model of integrity for lawyers .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It became very successful : it won the Pulitzer Prize and became a classic of modern American literature .', 'positives': ['It was instantly successful , winning the Pulitzer Prize , and has become a classic of modern American literature .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Instead of a `` quick and merciful death '' , Reader 's Digest Condensed Books chose part of the book to be printed again .\", 'positives': [\"Instead of a `` quick and merciful death '' , Reader 's Digest Condensed Books chose the book for reprinting in part , which gave it a wide readership immediately .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'An editor at J. B. Lippincott suggested to her that she should stop working at the airline and focus on writing instead .', 'positives': ['An editor at J. B. Lippincott advised her to quit the airline and concentrate on writing .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"In 1964 , Lee said , `` I never expected any sort of success with ` Mockingbird . '\", 'positives': [\"In 1964 , Lee recalled her hopes for the book when she said , `` I never expected any sort of success with ` Mockingbird . '\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The book is taught in many schools in English-speaking countries with lessons about being patient and fair .', 'positives': ['The book is widely taught in schools in English-speaking countries with lessons that emphasize tolerance and decry prejudice .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It was first titled Atticus , but Lee changed its name because the story was more than simply about one character .', 'positives': ['It was initially titled Atticus , but Lee renamed it to reflect a story that went beyond a character portrait .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In the story Atticus defends a black man , Tom Robinson , who has been accused of raping a white woman called Mayella Ewell .', 'positives': ['Atticus is appointed by the court to defend Tom Robinson , a black man who has been accused of raping a young white woman , Mayella Ewell .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The book was printed on July 11 , 1960 .', 'positives': ['The book was published on July 11 , 1960 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Lee spent two and a half years writing To Kill a Mockingbird .', 'positives': ['Ultimately , Lee spent two and a half years writing To Kill a Mockingbird .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'To Kill a Mockingbird is a novel written by Harper Lee , published in 1960 .', 'positives': ['To Kill a Mockingbird is a novel by Harper Lee published in 1960 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The writer based the story and characters on her family and neighbors , and something that happened near her hometown in 1936 . This was when she was 10 years old .', 'positives': [\"The plot and characters are loosely based on the author 's observations of her family and neighbors , as well as on an event that occurred near her hometown in 1936 , when she was 10 years old .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'After two summers , Scout and Jem find small presents in a tree outside the Radley place .', 'positives': ['Following two summers of friendship with Dill , Scout and Jem find that someone is leaving them small gifts in a tree outside the Radley place .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In 1950 , Lee moved to New York City , where she worked as a clerk for British Overseas Airways Corporation . While she was there , she began writing essays and short stories about people in Monroeville .', 'positives': ['In 1950 , Lee moved to New York City , where she worked as a reservation clerk for British Overseas Airways Corporation ; there , she began writing a collection of essays and short stories about people in Monroeville .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'She was a of Francis Stephan , Duke of Lorraine .', 'positives': ['The sister of Francis Stephan , Duke of Lorraine , she died as a result of giving birth to Benedetto of Savoy .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The marriage produced three children , only one of whom survived infancy .', 'positives': ['The marriage produced three children , only one of whom survived infancy but had no further progeny .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Elisabeth Therese of Lorraine ( Ã lisabeth ThÃ rÃ se de Lorraine ; 15 October 1711 -- 3 July 1741 ) was born a Princess of Lorraine and a Queen of Sardinia as wife Charles Emmanuel III of Sardinia .', 'positives': ['Ã lisabeth ThÃ rÃ se of Lorraine ( 15 October 1711 -- 3 July 1741 ) was born a Princess of Lorraine and was the last queen consort of Charles Emmanuel III of Sardinia .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Ã lisabeth ThÃ rÃ se died at the Palace of Venaria aged 29 , having fallen ill with a fever after childbirth .', 'positives': ['Ã lisabeth ThÃ rÃ se died at the Palace of Venaria aged 29 , having fallen ill with puerperal fever after childbirth . .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'As a result Elisabeth Therese was created the coadjutrice of Remiremont Abbey in October 1734 .', 'positives': ['The match having come to nothing , leading her mother to name her daughter the coadjutrice of Remiremont Abbey on 19 October 1734 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In 1736 her brother the Duke of Lorraine married the Maria Theresa of Austria , daughter of Charles VI , Holy Roman Emperor .', 'positives': ['In 1736 her brother the Duke of Lorraine married the Archduchess Maria Theresa of Austria , daughter and heiress apparent of Charles VI , Holy Roman Emperor .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Her mother wanted her to marry her cousin Louis d'Orl Ã ans , Duke of OrlÃ ans but the Duke of OrlÃ ans refused .\", 'positives': [\"Her father died in 1729 amid negotiations regarding a marriage between the then seventeen-year-old Ã lisabeth ThÃ rÃ se and her recently widowed cousin Louis d'Orl Ã ans , Duke of OrlÃ ans . He refused outright , much to the annoyance of her mother .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Her mother was a niece of Louis XIV .', 'positives': ['Her mother was a niece of Louis XIV and her father a son of Eleanor of Austria , Queen of Poland .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Coubeyrac is a commune . It is found in the region Aquitaine in the Gironde department in the southwest of France .', 'positives': ['Coubeyrac is a commune in the Gironde department in Aquitaine in south-western France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The traditional process used in these operations is vacuum distillation â '' essentially the boiling of water at less than atmospheric pressure , and thus a much lower temperature than normal .\", 'positives': [\"The traditional process used in these operations is vacuum distillationâ '' essentially the boiling of water at less than atmospheric pressure and thus a much lower temperature than normal .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The world 's largest desalination plant is the Jebel Ali Desalination Plant ( Phase 2 ) in UAE .\", 'positives': [\"The world 's largest desalination plant is the Jebel Ali Desalination Plant ( Phase 2 ) in the United Arab Emirates .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It uses multi-stage flash distillation , dual-purpose and it is capable of producing 300 million cubic meters of water per year .', 'positives': ['It is a dual-purpose facility that uses multi-stage flash distillation and is capable of producing 300 million cubic metres of water per year .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Due to the reduced temperature , energy is saved .', 'positives': ['Thus , because of the reduced temperature , energy is saved .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Desalination means any process that removes the excess salt and other minerals from water in order to obtain fresh water suitable for animal consumption or irrigation .', 'positives': ['More generally , desalination may also refer to the removal of salts and minerals , as in soil desalination . Water is desalinated in order to convert salt water to fresh water so it is suitable for human consumption or irrigation .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'RÃ 1\\\\/4 diger Abramczik ( born 18 February 1956 ) is a former German football player .', 'positives': [\"RÃ 1\\\\/4 diger Abramczik ( born 18 February 1956 in Gelsenkirchen-Erle ) is a former German football player and coach , best known for his ability to cross the ball ( `` Flankengott '' ) .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The city has an estimated total population of 126,217 .', 'positives': ['The city has a 2009 estimated total population of 126,217 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Waco is a city in McLennan County , Texas .', 'positives': ['Waco is a city in and the county seat of McLennan County , Texas .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Morgny-en-Thi Ã rache is a commune .', 'positives': ['Morgny-en-Thi Ã rache is a commune in the Aisne department in Picardy in northern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Netherlands national football team is the national football team of Netherlands .', 'positives': ['The Netherlands National Football Team represents the Netherlands in association football and is controlled by the Royal Dutch Football Association ( KNVB ) , the governing body for football in the Netherlands .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"It is an impression of the Fueled by Ramen record label . It uses the Pete Wentz 's trademark ` Batheart ' as its logo .\", 'positives': ['Originally founded as an imprint of Fueled by Ramen , it is now an independent record label owned by Pete Wentz of Fall Out Boy and partners .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Auty is a commune of the Tarn-et-Garonne department in the Midi-Pyr Ã nÃ es region . It can be found in the southern part of France .', 'positives': ['Auty is a commune in the Tarn-et-Garonne department in the Midi-Pyr Ã nÃ es region in southern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'La Chaise is a commune of the Aube dÃ partement in the north-central part of France .', 'positives': ['La Chaise is a commune in the Aube department in north-central France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Matthias Herget ( born 14 November , 1955 ) is a former German football player .', 'positives': ['Matthias Herget ( born 14 November 1955 , in Annaberg-Buchholz ) is a former German football player who has also worked as a manager .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Katsuyoshi Kuwahara ( born 30 May 1944 ) is a former Japanese football player .', 'positives': ['Katsuyoshi Kuwahara ( born May 30 , 1944 ) is a former Japanese football player .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Bonnieux is a commune of 1,417 people ( 1999 ) . It is located in the region Provence-Alpes-C Ã te d'Azur in the Vaucluse department in the south of France .\", 'positives': [\"Bonnieux is a commune in the Vaucluse department in the Provence-Alpes-C Ã te d'Azur region in southeastern France .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Buneville is a commune . It is found in the region Nord-Pas-de-Calais in the Pas-de-Calais department in the north of France .', 'positives': ['Buneville is a commune in the Pas-de-Calais department in the Nord-Pas-de-Calais region of France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The annual Three Choirs Festival , which started in the eighteenth century and one of the oldest music festivals in Europe , takes place in Gloucester every third year . The other places the festival is held are Hereford and Worcester .', 'positives': ['The Three Choirs Festival , originating in the eighteenth century and one of the oldest music festivals in Europe , is held in Gloucester every third year , the other venues being Hereford and Worcester .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Some scenes for the Harry Potter movies were filmed at Gloucester cathedral .', 'positives': ['Several high profile TV and film productions have been filmed in Gloucester ; most notably at the Cathedral and Docks . These include three of the Harry Potter movies , Doctor Who and Outlaw .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Kennesaw State University is a public , coeducational university in Kennesaw , Georgia .', 'positives': ['Kennesaw State University , also referred to as KSU , Kennesaw , or Kennesaw State , is a public , coeducational , comprehensive university that is part of the University System of Georgia .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The university has about 23,452 students .', 'positives': ['A current enrollment of 23,452 students makes KSU the third largest university in Georgia , trailing only the University of Georgia and Georgia State University .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The song has spent 30 weeks on the chart before its peak , making it the band 's slowest climb to the chart 's Top 10 .\", 'positives': [\"The song has spent 30 weeks on the chart prior to this peak , making it the band 's slowest climb to the chart 's Top 10 .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The song got to number six on the Billboard alternative rock chart , making it the band 's second top 10 single ( the first being the last single `` Prayer of the Refugee '' ) and highest charting single from the album .\", 'positives': [\"The song peaked at number six on the Billboard alternative rock chart , making it the band 's second top 10 single ( the first being previous single `` Prayer of the Refugee '' ) and highest charting single from the album .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'They released a bulletin board over their MySpace account giving information about the contest .', 'positives': ['They have released a bulletin over their MySpace account giving information about the contest .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"`` The Good Left Undone '' is the third single from the American punk rock band Rise Against 's fourth album , The Sufferer & the Witness .\", 'positives': [\"`` The Good Left Undone '' is the third single from Rise Against 's fourth full-length album , The Sufferer & the Witness .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In June 2007 , they said that they would be holding a contest to see who could make the best video for the song .', 'positives': ['In June 2007 , they announced that they would be holding a contest to determine who could make the best video for the song .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'SNAFU or snafu is an acronym that the United States Military first used .', 'positives': ['In modern usage , snafu is sometimes used as an interjection . Snafu also sometimes refers to a bad situation , mistake , or cause of trouble .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The Rous Cup was an association football competition in the second half of the 1980s . It was contested between England , Scotland and , in later years , a guest team from South America .', 'positives': ['The Rous Cup was a short-lived football competition in the second half of the 1980s , contested between England , Scotland and , in later years , a guest team from South America .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Kinect is a device being made by Microsoft for the Xbox 360 .', 'positives': [\"Kinect for Xbox 360 , or simply Kinect ( originally known by the code name Project Natal ) , is a `` controller-free gaming and entertainment experience '' by Microsoft for the Xbox 360 video game platform .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'They want Kinect to increase the time that people make games for Xbox 360 before a new video game console is made .', 'positives': [\"Kinect for Xbox 360 , or simply Kinect ( originally known by the code name Project Natal ) , is a `` controller-free gaming and entertainment experience '' by Microsoft for the Xbox 360 video game platform . Based around a webcam-style add-on peripheral for the Xbox 360 console , it enables users to control and interact with the Xbox 360 without the need to touch a game controller , through a natural user interface using gestures and spoken commands .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Kinect is expected to be in stores in late 2010 . The MSRP is $ 149.99 and the Kinect is also optionally bundled with a new Xbox 360 .', 'positives': ['In addition , on July 20 , 2010 , Microsoft announced a Kinect bundle with a redesigned Xbox 360 , to be available with the Kinect launch .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The Kinect was named the `` Fastest selling consumer electronics device '' by the Guinness World Records , selling an average of 133,333 kinects per day with a total of 8 million units in its first 60 days .\", 'positives': [\"Kinect holds the Guinness World Record of being the `` fastest selling consumer electronics device '' . It sold an average of 133,333 units per day with a total of 8 million units in its first 60 days .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In October 1987 , on the 100th anniversary , its name was changed to The Yamaha Corporation .', 'positives': ['In October 1987 , on its 100th anniversary , the name was changed to Yamaha Corporation .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Buchal Kalan is a village and Union Council of Chakwal District in the Punjab Province of Pakistan . It is part of Chakwal Tehsil .', 'positives': ['Buchal Kalan is a village and union council , an administrative subdivision , of Chakwal District in the Punjab Province of Pakistan , it is part of Kallar Kahar Tehsil .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It is about 55 kilometres southeast of Islamabad , the capital of Pakistan and 220 km to the north west of Lahore capital of Punjab .', 'positives': ['It is approximately 55 kilometres southeast of Islamabad , the capital of Pakistan and 220 km to the north west of Lahore , capital of Punjab .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Pothowari is the main language of Gujar Khan , other languages are Urdu , Punjabi and Pashto .', 'positives': ['Potwari is the main language of Gujar Khan . Other languages like Punjabi are also spoken in the area'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Gujar Khan ( Urdu : Ú Ù Ø Ø Ø Ø Ù ) is a city located in Rawalpindi District , Punjab , Pakistan . It is the capital of Gujar Khan Tehsil , one of the seven tehsils or subdivisions of Rawalpindi District .', 'positives': ['Gujar Khan is a city in Rawalpindi District , Punjab , Pakistan .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It is located 6.4 m north east of Charing Cross .', 'positives': ['It is situated 6.4 m north-east of Charing Cross .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Walthamstow is a town in the London Borough of Waltham Forest , North East London , England .', 'positives': ['Walthamstow is a district of northeast London , England , located in the London Borough of Waltham Forest .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Often confused with waste , scrap in fact has significant monetary value .', 'positives': ['Often confused with waste , scrap , in fact , has significant monetary value .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Scrap is a term used to describe recyclable materials left over from every manner of product consumption , such as parts of vehicles , building supplies , and surplus materials .', 'positives': ['Scrap is a term used to describe recyclable and other materials left over from every manner of product consumption , such as parts of vehicles , building supplies , and surplus materials .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Jim Carey ( born May 31 , 1974 in Dorchester , Massachusetts ) is a retired American ice hockey goaltender .', 'positives': ['James Carey ( born May 31 , 1974 in Dorchester , Massachusetts ) , is a retired American ice hockey goaltender who played for the Washington Capitals , Boston Bruins and St. Louis Blues in the NHL .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Now it is owned by the Communist People 's Republic of China see History and Political problems of China .\", 'positives': [\"At the UN , it was present under the name `` China '' until it lost its seat to the People 's Republic of China . Since then , the name `` China '' has been commonly used to refer only to the People 's Republic of China .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The territory the Republic of China ( ROC ) controls is known by most people as the island of Taiwan .', 'positives': ['The Republic of China ( ROC ) , commonly known as Taiwan , is a state in East Asia .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The ROC used to govern Mainland China too . Now it is owned by the Communist People 's Republic of China see History and Political problems of China .\", 'positives': [\"The Communist Party of China took over all of mainland China and founded the People 's Republic of China in Beijing , leading to two rival governments claiming to be the sole legitimate government of `` China '' .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"In 1949 , the Chinese Communists fought a war against the Nationalists and won . They established the People 's Republic of China .\", 'positives': [\"In October 1949 , the Communists founded the People 's Republic of China .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'A meadow is a field vegetated primarily by grass and other non-woody plants .', 'positives': ['A meadow is a field vegetated primarily by grass and other non-woody plants ( grassland ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The Migration Period , also called Barbarian Invasions or VÃ lkerwanderung , is a name given by historians to a human migration which happened in the period of roughly AD 300 â `` 700 in Europe .', 'positives': [\"The Migration Period , also called the Barbarian Invasions ( and in ` migration of peoples ' ) , was a period of human migration in Europe that occurred from c. 300 to 700 AD .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Saint-Mard , Aisne is a commune .', 'positives': ['Saint-Mard is a commune in the Aisne department in Picardy in northern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Backmasking ( also known wrongly as backward masking ) is a recording technique . In backmasking , a sound or message is recorded backwards onto a track that is meant to be played forwards .', 'positives': ['Backmasking ( also known as backward masking ) is a recording technique in which a sound or message is recorded backward on to a track that is meant to be played forward .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Since then , Rooney has won many competitions for Manchester United , including :', 'positives': [\"In October , Manchester United manager Sir Alex Ferguson stated at a press conference that Rooney wanted to quit club . This came after a period of dispute as to the extent of Rooney 's ankle injury , where Rooney had refuted Ferguson 's claim that the injury was the reason Rooney had been dropped to the bench .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Rooney was only 18 at the time , and the Â # 23m paid for him is the highest amount ever paid for a teenager in the world .', 'positives': ['It was the highest fee ever paid for a player under 20 years old ; Rooney was still only 18 when he left Everton .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Wayne Mark Rooney ( born 24 October 1985 in Liverpool ) is an English football player who plays for Manchester United and his country , England national team . He plays as a striker .', 'positives': ['Wayne Mark Rooney ( born 24 October 1985 ) is an English footballer who plays as a striker for Premier League club Manchester United and the England national team .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'PATA is still used more often than SATA , but it is being replaced in newer computers .', 'positives': [\"Bridge-chips were widely used on PATA drives ( before the completion of native SATA drives ) as well as standalone `` dongles . '' When attached to a PATA drive , a device-side dongle allows the PATA drive to function as a SATA drive .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Serial ATA ( SATA or Serial Advanced Technology Attachment ) is a way of connecting a hard drive to a computer .', 'positives': ['Serial ATA ( SATA or Serial Advanced Technology Attachment ) is a computer bus interface for connecting host bus adapters to mass storage devices such as hard disk drives and optical drives .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'BBC Radio 5 Live Sports Extra is a digital radio station from the BBC . It is broadcast on digital radio services and digital TV in the UK and Republic of Ireland .', 'positives': ['BBC Radio 5 Live Sports Extra is an additional digital radio service provided by the BBC via DAB Digital Radio and the digital satellite , digital terrestrial , IPTV and digital cable television services in the United Kingdom and Republic of Ireland .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The station also provides live coverage of the non-final rounds of the other Grand Slam tournaments .', 'positives': ['In addition , the station provides live coverage of the non-final rounds of the other Grand Slam tournaments .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Each year during Wimbledon Sports Extra provides extra court commentary for the first week of the tournament .', 'positives': ['Each year during Wimbledon the station provides extra court commentary for the first week of the tournament .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The station first broadcast at 2.30 pm on 2 February 2002 .', 'positives': ['Broadcasts began at 2.30 pm on 2 February 2002 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"It is used to provide an additional sports commentary service when the BBC 's main sports channel , BBC Radio 5 Live , is already being used .\", 'positives': ['It is used to provide an additional sports commentary service alongside the main radio channel BBC Radio 5 Live .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It is also the digital radio home for Test Match Special - the station provides full commentary without the shipping forecast given by the Radio 4 long wave coverage .', 'positives': ['It is also the digital radio home for Test Match Special , which provides full commentary without the shipping forecast included on the Radio 4 long wave coverage .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It is also streamed online , however , some events are not available online , or outside the UK .', 'positives': ['It is also streamed online ; however due to rights restrictions coverage of some events are not available online .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It is not available on normal analog radio .', 'positives': ['It is not available via analog radio .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Juliette Ferrington introduced the first program - commentary of a Manchester United against Sunderland football match .', 'positives': ['Juliette Ferrington introduced the first program â `` commentary of Manchester United against Sunderland .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"It has given coverage of Major League Baseball 's World Series since 2004 .\", 'positives': [\"It has transmitted coverage of Major League Baseball 's World Series since 2004 .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The Ramsar Convention ( The Convention on Wetlands of International Importance , especially as Waterfowl Habitat ) is an international treaty to protect wetlands .', 'positives': ['The Ramsar Convention ( The Convention on Wetlands of International Importance , especially as Waterfowl Habitat ) is an international treaty for the conservation and sustainable utilisation of wetlands , i.e. , to stem the progressive encroachment on and loss of wetlands now and in the future , recognizing the fundamental ecological functions of wetlands and their economic , cultural , scientific , and recreational value .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The convention was developed and agreed to by 18 nations at a meeting in Ramsar on February 2 , 1971 . It came into force on December 21 , 1975 .', 'positives': ['The convention was developed and adopted by participating nations at a meeting in Ramsar on February 2 , 1971 , and came into force on December 21 , 1975 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The Ramsar List of Wetlands of International Importance now includes 1,888 sites , which are called Ramsar Sites , covering around 1,853,000 kmÂ . This has increased from 1,021 sites in 2000 .', 'positives': ['The Ramsar List of Wetlands of International Importance now includes 1,888 sites ( known as Ramsar Sites ) covering around 1,853,000 kmÂ , up from 1,021 sites in 2000 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Pubic hair is hair that grows in the pubic region , which is the part of the body where the penis is .', 'positives': ['Stage 5 refers to the spread of pubic hair to the thighs and upward towards the navel as part of the developing abdominal hair . In the months and years following the appearance of pubic hair , other areas of skin that respond to androgens may develop androgenic hair .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'After puberty , people are able to make children . A young woman who has gone through puberty can become pregnant and have a baby .', 'positives': ['Growth accelerates in the first half of puberty and stops at the completion of puberty .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'People whose bodies have problems with leptin do not go through puberty .', 'positives': ['Individuals who are deficient in leptin fail to initiate puberty . The levels of leptin increase with the onset of puberty , and then decline to adult levels when puberty is completed .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Boys grow for about six years after puberty starts . Puberty in boys starts off more slowly than in girls , but then speeds up later on .', 'positives': ['Two of the most significant differences between puberty in girls and puberty in boys are the age at which it begins , and the major sex steroids involved .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'About one year after pubic hair begins appearing , underarm hair also grows . The hair on the arms and legs also gets thicker , and some girls may have hair appearing on their upper lip and in front of their ears .', 'positives': ['The usual sequence is : underarm ( axillary ) hair , perianal hair , upper lip hair , sideburn ( preauricular ) hair , periareolar hair , and the beard area .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The changes in a girl 's body during puberty usually take place between the ages of eight and 18 years . Most girls will have finished puberty around the age of 15 .\", 'positives': ['Girls usually complete puberty by ages 15 â `` 17 , while boys usually complete puberty by ages 16 â `` 18 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': '808s and Heartbreak is the fourth studio album by Kanye West . It was released on November 24 , 2008 .', 'positives': ['808s & Heartbreak is the fourth studio album by American hip hop artist Kanye West , released November 24 , 2008 on Roc-A-Fella Records in the United States .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Foufflin-Ricametz is a commune . It is found in the region Nord-Pas-de-Calais in the Pas-de-Calais department in the north of France .', 'positives': ['Foufflin-Ricametz is a commune in the Pas-de-Calais department in the Nord-Pas-de-Calais region of France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'CondÃ - sur-Aisne is a commune .', 'positives': ['CondÃ - sur-Aisne is a commune in the Aisne department in Picardy in northern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Villelaure is a commune . It is found in the region Provence-Alpes-C Ã te d'Azur in the Vaucluse department in the south of France .\", 'positives': [\"Villelaure is a commune in the Vaucluse department in the Provence-Alpes-C Ã te d'Azur region in southeastern France .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Joey Barton ( born 2 September 1982 ) is an English football player . He plays for Newcastle United .', 'positives': [\"Joseph Anthony `` Joey '' Barton ( born 2 September 1982 ) is an English footballer who plays for Premier League club Newcastle United as either a central midfielder or a winger .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Bavent is a commune . It is found in the region Basse-Normandie in the Calvados department in the northwest of France .', 'positives': ['Bavent is a commune in the Calvados department in the Basse-Normandie region in northwestern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Barenton-Bugny is a commune . It is found in the region Picardie in the Aisne department in the north of France .', 'positives': ['Barenton-Bugny is a commune in the department of Aisne in Picardy in northern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Arata Kodama ( born 8 October 1982 ) is a Japanese football player .', 'positives': ['Arata Kodama ( å ç æ -- Arata Kodama , born 8 October 1982 in Takatsuki , Osaka Prefecture ) is a Japanese football defender currently playing for J. League Division 1 team Shimizu S-Pulse .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Kodai Watanabe ( born 4 December 1986 ) is a Japanese football player . He plays for Vegalta Sendai .', 'positives': ['Kodai Watanabe is a Japanese footballer who plays for Vegalta Sendai .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Aska Yang ( born April 4 , 1978 ) is a popular Taiwanese singer and a member of Million Star Gang ( æ å', 'positives': ['Aska Yang was born on April 4 , 1978 in Taoyuan , Taiwan .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The Academy is an independent , scientific , non-governmental organization , set up to support the sciences , mainly the natural sciences and mathematics .', 'positives': ['The Academy is an independent , non-governmental scientific organization which acts to promote the sciences , primarily the natural sciences and mathematics .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The Academy was started on 2 June 1739 by naturalist Carl Linnaeus , economist Jonas AlstrÃ mer , mechanical engineer MÃ rten Triewald , civil servants Sten Carl Bielke and Carl Wilhelm Cederhielm , and politician Anders Johan von HÃ pken .', 'positives': ['The Academy was founded on 2 June 1739 by naturalist Carl Linnaeus , mercantilist Jonas AlstrÃ mer , mechanical engineer MÃ rten Triewald , civil servants Sten Carl Bielke and Carl Wilhelm Cederhielm , and politician Anders Johan von HÃ pken .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Charles Dickens ( February 7 1812 â '' June 9 1870 ) was one of the great English writers of the 19th century .\", 'positives': [\"Charles John Huffam Dickens ( ; 7 February 1812 -- 9 June 1870 ) was the most popular English novelist of the Victorian era , and he remains popular , responsible for some of English literature 's most iconic characters .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Edmundo ( born 2 April , 1971 ) is a Brazilian football player .', 'positives': ['Edmundo Alves de Souza Neto ( born April 2 , 1971 in NiterÃ i ) , better known simply as Edmundo , is a retired Brazilian football player .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Masashi Kishimoto ( å æ æ -- å , Kishimoto Masashi ) is a Japanese manga artist , best known for creating the hugely popular manga series known as Naruto .', 'positives': ['Masashi Kishimoto is a Japanese manga artist , well known for creating the manga series Naruto .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"p129 Panthea read Lucian 's first draft , and criticized him for flattery .\", 'positives': [\"Panthea read Lucian 's first draft , and criticized him for flattery .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In 163 , while Statius Priscus was occupied in Armenia , the Parthians intervened in Osroene , a Roman client state in upper Mesopotamia , just east of Syria , with its capital at Edessa .', 'positives': ['In 163 , while Statius Priscus was occupied in Armenia , the Parthians intervened in Osroene , a Roman client in upper Mesopotamia , just east of Syria , with its capital at Edessa .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p156 Although the senate planned to confirm Marcus alone , he refused to take office unless Lucius received equal powers .', 'positives': ['Thus , although the senate planned to confirm Marcus alone , he refused to take office unless Lucius received equal powers .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p164 Lucius took the title Parthicus Maximus , and he and Marcus were hailed as imperatores again , earning the title ` imp .', 'positives': ['Lucius took the title Parthicus Maximus , and he and Marcus were hailed as imperatores again , earning the title ` imp .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Legions I Minervia and V Macedonica , under the legates M. Claudius Fronto and P. Martius Verus , served under Statius Priscus in Armenia , earning success for Roman arms during the campaign season of 163 , p163 including the capture of the Armenian capital Artaxata .', 'positives': ['I Minervia and V Macedonica , under the legates M. Claudius Fronto and P. Martius Verus , served under Statius Priscus in Armenia , earning success for Roman arms during the campaign season of 163 , including the capture of the Armenian capital Artaxata .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p116 The senate accepted , granting Lucius the imperium , the tribunician power , and the name Augustus .', 'positives': ['The senate accepted , granting Lucius the imperium , the tribunician power , and the name Augustus .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p280n Sohaemus was hailed on the imperial coinage of 164 under the legend : Verus sat on a throne with his staff while Sohamenus stood before him , saluting the emperor .', 'positives': ['Sohaemus was hailed on the imperial coinage of 164 under the legend : Verus sat on a throne with his staff while Sohamenus stood before him , saluting the emperor .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Furius Victorinus , one of the two praetorian prefects , was sent with Lucius , as were a pair of senators , and part of the praetorian guard .', 'positives': ['Furius Victorinus , one of the two praetorian prefects , was sent with Lucius , as were a pair of senators , M. Pontius Laelianus Larcius Sabinus and M. Iallius Bassus , and part of the praetorian guard .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"p117 The ceremony was perhaps not entirely necessary , given that Marcus ' accession had been peaceful and unopposed , but it was good insurance against later military troubles .\", 'positives': [\"The ceremony was perhaps not entirely necessary , given that Marcus ' accession had been peaceful and unopposed , but it was good insurance against later military troubles .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Immediately after their senate confirmation , the emperors proceeded to the camp of the praetorian guard .', 'positives': ['Immediately after their senate confirmation , the emperors proceeded to the Castra Praetoria , the camp of the praetorian guard .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p130 Fronto was consul for 165 , probably in honor of the capture of Edessa .', 'positives': ['Fronto was consul for 165 , probably in honor of the capture of Edessa .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"p163 Lucilla 's thirteenth birthday was in March 163 ; whatever the date of her marriage , she was not yet fifteen .\", 'positives': [\"Lucilla 's thirteenth birthday was in March 163 ; whatever the date of her marriage , she was not yet fifteen .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"p162 The Syrian army had turned soft during the east 's long peace .\", 'positives': [\"The Syrian army had turned soft during the east 's long peace .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'On the evidence of Lucian , the Parthians still held the southern , Roman bank of the Euphrates ( in Syria ) as late as 163 .', 'positives': ['On the evidence of Lucian , the Parthians still held the southern , Roman bank of the Euphrates ( in Syria ) as late as 163 ( he refers to a battle at Sura , which is on the southern side of the river ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p131 Detachments from Cappadocian legions are attested at Echmiadzin , beneath the southern face of Mount Ararat , 400 km east of Satala .', 'positives': ['Detachments from Cappadocian legions are attested at Echmiadzin , beneath the southern face of Mount Ararat , 400 km east of Satala .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p125 Victorinus had previously served as procurator of Galatia , giving him some experience with eastern affairs .', 'positives': ['Victorinus had previously served as procurator of Galatia , giving him some experience with eastern affairs .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The biographer calls her a `` low-born girl-friend '' , p129 but she is probably closer to Lucian 's `` woman of perfect beauty '' , more beautiful than any of Phidias and Praxiteles ' statues .\", 'positives': [\"The biographer calls her a `` low-born girl-friend '' , but she is probably closer to Lucian 's `` woman of perfect beauty '' , more beautiful than any of Phidias and Praxiteles ' statues .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Maximus received a generous cash bounty for bringing the good news , and immediate promotion to the quaestorship .', 'positives': ['Maximus received a generous cash bounty ( dona ) for bringing the good news , and immediate promotion to the quaestorship .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'In spite of their nominal equality , Marcus held more authority than Verus .', 'positives': [\"In spite of their nominal equality , Marcus held more auctoritas , or `` authority '' , than Verus .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"As the biographer wrote , `` Verus obeyed Marcus ... as a lieutenant obeys a proconsul or a governor obeys the emperor '' .\", 'positives': [\"As the biographer wrote , `` Verus obeyed Marcus ... as a lieutenant obeys a proconsul or a governor obeys the emperor . ''\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Lucius Verus ( Lucius Ceionius Commodus , 15 December 130 â `` 169 ) was Roman co-emperor with Marcus Aurelius ( 121 â `` 180 ) , from 161 until his death .', 'positives': ['Lucius Aurelius Verus ( 15 December 130 â `` 169 ) , born as Lucius Ceionius Commodus , known simply as Lucius Verus , was Roman co-emperor with Marcus Aurelius ( 121 â `` 180 ) , from 161 until his death .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p130 , 279 In response , Roman forces were moved downstream , to cross the Euphrates at a more southerly point .', 'positives': ['In response , Roman forces were moved downstream , to cross the Euphrates at a more southerly point .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"p169 His coinage resumed , too : ` Ma ` nu the king ' ( Syriac : M ` NW MLK ' ) or Antonine dynasts on the obverse , and ` King Mannos , friend of Romans ' ( Greek : Basileus Mannos PhilorÅ maios ) on the reverse .\", 'positives': [\"His coinage resumed , too : ` Ma ` nu the king ' ( Syriac : M ` NW MLK ' ) or Antonine dynasts on the obverse , and ` King Mannos , friend of Romans ' ( Greek : Basileus Mannos PhilorÅ maios ) on the reverse .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'p123 Whatever the case , the senate gave its assent , and Lucius left .', 'positives': ['Whatever the case , the senate gave its assent , and Lucius left .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Kim Yong-Gwi ( born 24 January 1985 ) is a South Korean football player . He plays for Shonan Bellmare .', 'positives': ['Kim Yong-Gwi ( Korean : ê ì ê , Hanja : é ` æ å , born 24 January 1985 in Himeji , HyÅ go , Japan ) is a Japanese-born South Korean footballer who played for J. League Division 2 side Shonan Bellmare .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'These departments are further divided into 41 arrondissements , and 133 communes , second and third level units of administration .', 'positives': ['The departments are further divided into 41 arrondissements , and 133 communes , which serve as second - and third-level administrative divisions .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"On January 12 , 2010 , at 21:53 UTC , the island was struck by a magnitude-7 .0 earthquake , the country 's most severe earthquake in the past 200 years .\", 'positives': [\"On January 12 , 2010 , at 21:53 UTC , ( 4:53 pm local time ) Haiti was struck by a magnitude-7 .0 earthquake , the country 's most severe earthquake in over 200 years .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"There are two official languages : French and Haitian Creole , or `` Kreyol '' .\", 'positives': ['Haitian Creole and French are the official languages .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'U.S. aid to the Haitian government was completely cut off in 2001-2004 after the 2000 election was disputed and President Aristide was accused of various misdeeds .', 'positives': ['US aid to the Haitian government was completely cut off from 2001 to 2004 , after the 2000 election was disputed and President Aristide was accused of various misdeeds .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'About 66 % of all Haitians work in the agricultural sector . Most of them do small-scale subsistence farming , but this activity makes up only 30 % of the GDP .', 'positives': ['About 66 % of all Haitians work in the agricultural sector , which consists mainly of small-scale subsistence farming , but this activity makes up only 30 % of the GDP .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Haiti ( French : HaÃ ti ; Haitian Creole : Ayiti ) , officially the Republic of Haiti ( French : RÃ publique d'Ha Ã ti ; Haitian Creole : Repiblik d Ayiti ) is a country on the Caribbean island of Hispaniola ; the other country on the island is the Dominican Republic .\", 'positives': ['Haiti ( ; French HaÃ ti , ; Haitian Creole : Ayiti , ) , officially the Republic of Haiti is a Caribbean country .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"The first , second , third , and fourth in this case are ordinal numbers . They result from the fact that the person has many objects , and they give them an order ( hence ` ordinal ' ) .\", 'positives': ['More generally , we can call a subset of any ordinal cofinal in provided every ordinal less than is less than or equal to some ordinal in the set .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'MÃ 1\\\\/4 hlehorn is a municipality of the canton of Glarus in Switzerland .', 'positives': ['MÃ 1\\\\/4 hlehorn is a former municipality in the canton of Glarus in Switzerland .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'These books are like dictionaries to the Qur ` an - they are not read as part of the religion of Islam , to replace the Arabic Qur ` an . Muslims believe that these translations are not the true Qur ` an ; only the Arabic copy is the true Qur ` an .', 'positives': ['They argue it is not possible for a human to produce a book like the Qur ` an , as the Qur ` an itself maintains .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'But , because many Muslims around the world do not understand Arabic , the meaning of the Qur ` an is also given in other languages , so that readers can understand better what the Arabic words in the Qur ` an mean . These books are like dictionaries to the Qur ` an - they are not read as part of the religion of Islam , to replace the Arabic Qur ` an .', 'positives': ['However , there are still limits to searching the Arabic text of the Qur ` an .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The back legs have hooks that anchor the hermit crab into the shell without difficulty .', 'positives': [\"As the hermit crab grows in size , it has to find a larger shell and abandon the previous one . This habit of living in a second hand shell gives rise to the popular name `` hermit crab '' , by analogy to a hermit who lives alone .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'As the hermit crab grows in size , it must find a larger shell .', 'positives': ['As the hermit crab grows in size , it has to find a larger shell and abandon the previous one .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Axel CÃ dric Konan ( born 25 January 1983 ) is a CÃ te d'Ivoire football player .\", 'positives': [\"Axel CÃ dric Konan ( born 25 January 1983 in Abidjan , Cote d'Ivoire ) is an Ivorian footballer who is currently contracted with Swiss Super League club AC Bellinzona .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Taylor Pyatt ( born August 19 , 1981 in Thunder Bay , Ontario ) is a Canadian professional ice hockey player who currently plays for the Phoenix Coyotes .', 'positives': ['Taylor Pyatt ( born August 19 , 1981 ) is a Canadian professional ice hockey player who plays for the Phoenix Coyotes of the National Hockey League ( NHL ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'It has points called tines . Most forks have three or four tines .', 'positives': ['Food can be lifted either by spearing it on the tines , or by holding it on top of the tines , which are often curved slightly .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'A fork is a tool for eating .', 'positives': ['As a piece of cutlery or kitchenware , a fork is a tool consisting of a handle with several narrow tines on one end . The fork , as an eating utensil , has been a feature primarily of the West , whereas in East Asia chopsticks have been more prevalent .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Forks are very common in Western Culture . Many countries do not use forks , but instead have their own ways to eat food .', 'positives': ['The Romans used forks and there are many examples of Roman forks on display in museums around Europe .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Port-en-Bessin-Huppain is a commune . It is found in the region Basse-Normandie in the Calvados department in the northwest of France .', 'positives': ['Port-en-Bessin-Huppain is a commune in the Calvados department in the Basse-Normandie region in northwestern France .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Quini ( born 23 September , 1949 ) is a former Spanish football player .', 'positives': ['Enrique Castro GonzÃ lez ( born 23 September 1949 ) , aka Quini , is a retired Spanish footballer , who played as a striker .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The word was made during the Irish Land War . It comes from the name of Captain Charles Boycott .', 'positives': [\"The word boycott entered the English language during the Irish `` Land War '' and is derived from the name of Captain Charles Boycott , the land agent of an absentee landlord , Lord Erne , who lived in Lough Mask House , in County Mayo , Ireland , who was subject to social ostracism organized by the Irish Land League in 1880 .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Richard Marsland ( a.k.a. Armitage Shanks , 1976 - 2008 ) was an Australian comedy writer , actor , comedian and radio personality .', 'positives': ['Richard Kemble Marsland ( 5 September 1976 â `` 6 December 2008 ) was an Australian comedy writer , actor , comedian and radio personality .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Rock Falls is a city of Illinois in the United States .', 'positives': ['Rock Falls is a city in Whiteside County , Illinois , United States .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Subduction is when two tectonic plates meet .', 'positives': ['A subduction zone is an area on Earth where two tectonic plates move towards one another and one slides under the other .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Thallium makes chemical compounds in two oxidation states : +1 and +3 .', 'positives': ['The two main oxidation states of thallium are +1 and +3 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Then the thallium ( I ) sulfate is electrolyzed to make thallium metal .', 'positives': ['The thallium is several times precipitated from the solution and to remove further impurities . At the end it is converted to thallium sulfate and the thallium is extraced by electrolysis on platinum or stainless steel plates .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Thallium ( I ) bromide turns yellow when exposed to light , similar to silver ( I ) bromide . Thallium ( I ) sulfide is black , similar to silver ( I ) sulfide .', 'positives': ['Thallium ( I ) bromide is a photosensitive yellow compound very similar to the silver bromide , while the black thallium ( I ) oxide and thallium ( I ) sulfide are very similar to the silver oxide and silver sulfide .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'When lead and zinc are taken from their ores , many impurities are left behind . Sulfuric acid is used to dissolve the thallium from it as thallium ( I ) sulfate .', 'positives': ['Thallium can also be obtained from the smelting of lead and zinc ores .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The +3 state compounds are oxidizing agents .', 'positives': ['The compounds with oxidation state +3 resemble the corresponding aluminium ( III ) compounds .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Sulfuric acid is used to dissolve the thallium from it as thallium ( I ) sulfate .', 'positives': ['In the presence of water , thallium hydroxide is formed . Sulfuric and nitric acid dissolve thallium rapidly to make the sulfate and nitrate salts , while hydrochloric acid forms a insoluble thallium ( I ) chloride layer .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The +1 state is more common and less reactive . Its chemical compounds are very similar to potassium or silver compounds .', 'positives': ['In the oxidation state +1 most compounds closely resemble the corresponding potassium or silver compounds ( The ionic radius of thallium ( I ) is 1.47 Ã'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Other compounds are similar to silver compounds .', 'positives': ['The similarity with silver compounds is observed with the halide , oxide , and sulfide compounds .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The black oxide , thallium ( III ) oxide and the hydroxide , thallium ( III ) hydroxide , are the only stable +3 compounds . They break down to oxygen and thallium ( I ) oxide when heated .', 'positives': ['The thallium ( III ) oxide is a black solid which decomposes above 800 Â C , forming the thallium ( I ) oxide and oxygen .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'This reacts with carbon dioxide to make thallium ( I ) carbonate , which is also water-soluble and very heavy .', 'positives': ['For example , the water-soluble and very basic thallium ( I ) hydroxide reacts with carbon dioxide forming water-soluble thallium carbonate This carbonate is the only water soluble heavy metal carbonate .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"Like arsenic , the use of thallium in murders has given it the name `` inheritance powder '' .\", 'positives': [\"Because of its use for murder , thallium has gained the nicknames `` The Poisoner 's Poison '' and `` Inheritance Powder '' ( alongside arsenic ) .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Thallium was found by spectroscopy in 1861 by a bright green line in its spectrum .', 'positives': [\"Thallium ( Greek , , meaning `` a green shoot or twig '' ) was discovered by flame spectroscopy in 1861 . The name comes from thallium 's bright green spectral emission lines .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Yoshito Terakawa ( born 6 September 1974 ) is a Japanese football player .', 'positives': ['Yoshito Terakawa ( born September 6 , 1974 in HyÅ go ) is a Japanese football player who currently plays for F.C. RyÅ `` kyÅ `` in the Japan Football League .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'The Simputer Trust has licensed to manufacturers to produce devices based on the Simputer . These companies are : PicoPeta Simputers and Encore Technologies .', 'positives': ['The Simputer Trust licensed two manufacturers to build the devices , Encore Software , which has also built the Mobilis for Corporate\\\\/Educational purposes and the SATHI for Defense purposes , and PicoPeta Simputers , which released a consumer product named the Amida Simputer .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': \"`` We Are the Champions '' is a power ballad by Queen for the album News of the World . It was written by Freddie Mercury .\", 'positives': [\"`` We Are the Champions '' is a power ballad written by Freddie Mercury , recorded and performed by British rock band Queen for their 1977 album News of the World .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'He died in 1926 from peritonitis after his appendix was ruptured .', 'positives': ['Harry Houdini died of peritonitis , secondary to a ruptured appendix .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'This category includes landforms on all planets .', 'positives': ['This category includes articles on specific landforms on all planets and similar objects .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Other helmets are made from plastic .', 'positives': ['Soldiers still wear helmets , now often made from lightweight plastic materials .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'Piciformes are order of birds contain about 67 living genera with a little over 400 species , of which the Picidae ( woodpeckers and relatives ) make up about half .', 'positives': ['The Piciformes contain about 67 living genera with a little over 400 species , of which the Picidae ( woodpeckers and relatives ) make up about half .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 1}\n",
            "{'query': 'A large fire truck on a city street.', 'positives': ['A man is driving a red fire engine', 'A red fire truck driving down a street next to a tall white building.', 'A firefighter truck is driving down the road on a sunny day. ', 'A fire engine driving in the city during the day'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A red stop sign on a grassy lawn.', 'positives': ['a stop sign leaving a shadow on the grass beside it ', 'A stop sign is in an area of grass bordered with bushes.', 'A stop sign at an intersection beside a street sign.', 'A patch of grass with a stop sign and its shadow.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A very cute cat on a rug by some bottles.', 'positives': ['A cat sitting on the floor looking up', 'A multi-colored cat laying on a rug next to some bottles and a glass door.', 'Multi colored cat laying on the floor next to door and liquor bottles', 'The cat looks upward beside some glass bottles.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat is looking out of a window', 'positives': ['A man and a woman sit on a couch with books and their cat.', 'A guy and a girl on a couch by a cute cat.', 'A woman playing with a cat while a man look at a book.', 'a woman sitting back on a couch next to a guy reading a book'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A girl sitting on a bed is using a laptop.', 'positives': ['A woman sitting on her bed typing on a computer.', 'A woman using her laptop is sitting on a bed.', 'A woman sitting on her bed in tights and using a laptop computer.', 'A young girl that is working on her netbook on her bed.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A big dog wearing a yellow and blue tie.\\n', 'positives': ['A large dog with a tie in a room.', 'A dog stands, wearing a tie, in a modern living room.', 'A dog that is wearing a tie sitting down.', 'A dog sits on his hind legs and wears a tie.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': \"There's a laptop in the pink floral bag and a package of tissues in a pocket.\", 'positives': ['A large pink bag with a laptop on a chair.', 'A laptop is packed away in a purse with Kleenex.', 'A large bag with a lap top sitting inside it. ', 'A pink bag contains a laptop and some other things.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a black cat is hiding in a box with shoes', 'positives': ['A cat sits among a pile of shoes in a confined space.', 'There is a cat sitting next to a pair of boots.', 'A black cat peers at a bunch of black shoes.', 'A cat and some shoes side by side.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A woman holding a cow with people at the back', 'positives': ['The woman stands next to a white cow with spots.', 'A woman standing beside a cow under a covered building.', 'A lady in white with a white and black cow.', 'A woman in tight white pants standing next to a cow.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'This is a calico cat sitting on a red piece of furniture', 'positives': ['A cat is sitting on a red sofa', 'A brown and black cat lying on a bed', 'A cat laying on a couch in a room.', \"A multi-colored cat that is laying on a piece of furniture with it's head up and eyes open.\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'an old car in a field with a sky background', 'positives': ['An old truck sits in a field of tall grass.', 'A large pick up truck in a grass field.', 'An old orange truck in a grassy field.', 'An old truck in a field of high green grass.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A freckled white horse standing in a grassy area. ', 'positives': ['A white pony with brown spots standing by a fence.', 'The horse is all alone in the field by the fence.', 'A large white horse standing in the grass.', 'Horse walking near a fence in a field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A rural field with trees and cows grazing in the distance.', 'positives': ['A herd of cows in a sloping field that is fenced in.', 'A herd of cattle walking across a grass covered hillside.', 'a large field filled with cows walking around', 'Photo of herd of cows grazing on large grassy expanse'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A blue and yellow train on some tracks', 'positives': ['The train has stopped on the railroad tracks.', 'This is a blue and yellow train on a track ', 'A train is mostly blue with some yellow on the front.', 'A train engine parked in a covered rail yard '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a car is pulling an r.v. down the road', 'positives': [\"A pick up truck is loaded with two ATV's in the bed and is towing a camper trailer.\", 'Truck with travel trailer hitched and ATVs in the bed.', 'A blue truck with four wheeler in the bed has a camper hooked up to its hitch.', 'There is a trailer and smaller sports vehicles behind a truck.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A modern train is coming through the town.', 'positives': ['A red and white train is on an elevated rail.', 'A very big nice looking train on the tracks.', 'A train on the tracks under the electrical lines.', 'An electric commuter train on the tracks under a cloudy sky'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Woman with open parasol while man rows boat', 'positives': ['a couple of people riding in a row boat ', 'a man rowing a boat and a woman holding an umbrella', 'A woman with an orange umbrella sits while a man rows a small boat.', 'A person with a umbrella and a man in a boat.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A fallen coin operated parking meter on a city street', 'positives': ['A coin meter that is laying down on grates.', 'A double meter which has fallen on the sidewalk.', 'A grate has been opened to allow access to a city sewer.', 'A couple of knocked over parking meters on the ground.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The front of a red vintage locomotive engine.', 'positives': ['A big red train is parked on the railroad and ready to go. ', 'a white yellow and red trains engine ', 'A red and yellow train parked next to some trees.', 'a diesel train with windows and a light'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A man stands wearing a suit with no tie.', 'positives': ['A very well dressed man standing in a grassy field.', 'Man poses for picture in a suit at an outside event', 'A man is dressed in a gray suit in a park.', 'A man wearing a grey tuxedo with a white tie.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A truck painted with pop art all over it ', 'positives': ['A delivery truck covered in graffiti driving down a street.', 'A truck is covered all over in graffiti', 'A truck parked in a lot and covered with graffiti ', 'a truck with graffiti written all over it '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Several cows wandering through a green pasture together.', 'positives': ['A bunch of cows are out walking in a grassy field.', 'cows with horns walking past some huts ', 'Some very big cows with horns in the grass.', 'a group of cows and steer walking outside'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Dog sitting at the wheel of a big truck cab.', 'positives': ['The big dog is in the parked big truck.', \"A white big rig with a German Sheppard in the driver's seat.\", \"Husky dog in the driver's seat of a semi truck.\", 'A husky dog sits in the cab of a big rig'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A lady with a veil standing by a guy and some luggage.', 'positives': ['a bride and groom near a Chinese building', 'Newly weds stand in front of temple gate for picture with luggage', 'A man and woman pose for a photo outside an historic building.', 'A woman wearing a bridal veil and suitcase poses with a man in a yellow tie.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Several beach chairs line a deck overlooking large body of water.', 'positives': ['The boat deck is full of lounge chairs.', 'The deck of a ship with many lounge chairs.', 'A wooden deck lined with law chairs near the ocean.', 'A deck of a cruise ship with lounge  chairs overlooking the sunset.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A large red truck on a city street.', 'positives': ['Older red pickup truck traveling down a busy city street.', 'Motor vehicles parked in lot on rainy day.', 'A truck that is sitting in a parking spot.', 'an older nice looking red pick up truck'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Cat sitting at a table with a plate of pie and a mug.', 'positives': ['a cat looking at a dessert on a table ', 'A cat sitting at a dining table staring at strawberry cheese cake.', 'a cat is standing in front of a tray with food', 'A very cute cat sitting at a table with some food.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Lots of colorful watercraft parked at a large body of water.', 'positives': ['The water has many colorful air rafts floating near each other.', 'some inflatable things are laying out at the beach', 'a number of small boats on a beach near a body of water ', 'air filled floating devices lined up in the water'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A garbage truck sits in a parking lot flanked by a hedge. ', 'positives': ['A big white trash truck in a lot.', 'A large white truck on a city street.', 'Dump truck on a road with a car behind it.', 'A white truck is sitting on a street'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A young boy standing next to a small white dog.', 'positives': ['A young child stands near a dog in an historic photo.', 'An old photo of a little boy with a dog.', 'The little boy is standing next to a little dog. ', 'We are looking at an old picture of a boy and his dog.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The black and white cow is eating grass from the field.', 'positives': ['a cow grazes on some green and brown grass', 'A black and white cow eating grass on top of a field. with long horns', 'A cow standing in the grass with its head touching the ground.', 'Cow grazing on a patch of dried grass.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Two persons are standin.g under a street sign board', 'positives': ['two people standing near a street sign ', 'Two men stand in front of a stop sign', 'Two young men are standing near a stop sign.', 'A stop sign is next to a one way sign.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The cat is all alone laying on the bed.', 'positives': ['A cat laying on a blanket at the end of a bed.', 'A cat laying on top of a bed next to a  blanket.', 'A very cute cat laying on a big bed.', 'a cat laying on a striped blanket on a bed'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A older blue pick up with people sitting in the back', 'positives': ['A large blue truck parked in a parking lot.', 'A very nice looking blue truck with some people in it.', 'A pickup truck driving down the road next to a sidewalk with people on it.', 'A group of people in a large blue truck.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train sitting inside of a train station.', 'positives': ['a train being worked on in a train manufacturer', 'A large long train on a steel track.', 'A large old train inside of a building.', 'a large train is inside of a museum facility'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a cow is standing out in a field of grass', 'positives': ['A large cow standing in a grass field.', 'a cow in a field of grass with bushes', 'A brown cow standing in the middle of a lush green field.', 'A very big fat cute cow in a grassy field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': \"A very cute dog laying down in a child's bed.\", 'positives': ['A tabby cat talking a nap in a baby cradle.', \"A big cat laying in a baby's crib.\", 'A cat that is laying down in a crib.', \"A orange striped cat sleeping in a child's bed.\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A truck that is sitting on the street by a rail.', 'positives': ['A large truck drives the opposite direction of a car near a mountain.', 'The truck is driving down the highway toward the mountain.', 'The truck is driving down the road by the mountains.', 'A truck rides along a mountain highway with a snow covered peak in the background.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat curled up on the couch laying on the remote.', 'positives': ['a close up of a cat laying on top of a remote control', 'a black orange and white cat and a controller', 'A cat rolled up sleeping on a remote control.', 'A cat sleeping curled up on a piece of furniture. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a close up of a cow in a field', 'positives': ['a large cow that is walking across some grass', 'A brown and white cow standing on top of a grass covered field.', 'A brown and white cow with horns close up on a field fo grass with green hills behind it in the distance.', 'a steer is standing out in a large field'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A couple of large boats on the water.', 'positives': ['inflatable boats sit on the arizona river, and on the bank', 'a truck is parked with some rafts by the water', 'A semi truck is backed up to a river with a ramp on its back near water with several rafts with supplies on them.', 'A bunch of blown up life rafts with cargo is being loaded onto a truck.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Railroad crossing located between a white house and another residence.', 'positives': ['A rural country road surrounded by lots of trees.', 'Railroad crossing and stop sign in a rural location.', \"The street by the railroad tracks isn't busy.\", 'a stop sign near a rail road crossing sign'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Some people by a big cage with a cute cow in it.', 'positives': ['Two women take photos of a cow at a contest.', 'A woman taking a picture of a cow in a pen.  ', 'One woman talking picture of cow another woman putting finger through fence', 'A woman taking a picture of a cow with her phone.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat laying on the floor next to another cat and a dog.', 'positives': ['a collage of photos with two cats and a dog', 'a picture with two cats and a dog on it', 'Two cats and a dog sleeping on beds.', 'A couple of cats and a dog laying down.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A large truck sitting in front of building.', 'positives': ['a bud light truck parked in front of a building ', 'A truck that is sitting in front of a building.', 'a black and white photo of a truck parked in a lot', 'A Bud Light beer delivery truck that is parked in front of a castle like building, with dark skies.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The train is stopping on the railroad tracks.', 'positives': ['A red and green train traveling down tracks.', 'A train that is traveling down some railroad tracks. ', 'A large long train on a steel track.', 'A train sitting on train tracks next to a platform.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Several brown cows roaming the countryside with some sheep nearby.', 'positives': ['A pasture full of grazing cows walking in a herd.', 'A green field with a group of cattle and sun rising on left.', 'a herd of cattle on the field grazing', 'Herd of cows walking along a grassy field'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'An adult goat and its kid sitting in the grass in front of an old abandoned boat.', 'positives': [' boat sitting in a field behind a long horned goat', 'a big old boat that is sitting a field', 'Older and younger animal with a boat in the background.', 'a goat sitting in grass in front of a beached ship'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a cat is sitting next to a cake', 'positives': ['A very cute cat sitting by a pretty cake.', 'A cat standing by a cake and a white plate.', 'an orange and white cat a plate and a white cake', 'A cat sitting on a counter looking at a cake.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Two trucks are racing and the red one is out in front with an audience on the sidelines.', 'positives': ['A couple of trucks driving down a street.', 'a blue and white truck and a red and white truck and people', 'a white truck is next to a red one on a track', 'a race for tracks and people watching them'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cow that is resting its head on another cow.', 'positives': ['Several animals standing in the grass near a man sitting on the ground.', 'Cow laying head on another cow with horse and man in background', 'a number of cows near one another on a field ', 'A bunch of animals standing around in a field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'There is a cat sitting behind a laptop.', 'positives': ['a desk with a cat laying a laptop ', 'a laptop computer sitting open on a table', 'a laptop and some books on a wooden table', 'A laptop computer sitting on top of a wooden desk.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a cat is laying in a cushioned wooden chair', 'positives': ['A cat laying in a basket on top of a mat.', 'a cat sitting in a chair on the ground ', 'Cat licking himself while curled up on wicker chair', 'A cat laying in a chair in a room.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A boat sitting on a beach near the water.', 'positives': ['a canoe docked on gravel next to a body of water', 'A boat sitting on a rocky beach at the sea shore.', 'A boat on a rocky coastline with no people', 'A very cute small boat laying on the beach by the water.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'People boarding a train in a train station.', 'positives': ['a number of people boarding a train from a platform', 'a group of people that are loading in the train', 'A bunch of people by the door of a big pretty train.', 'A group of people standing along side of a train.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A close up view of a very cute little cat.', 'positives': ['a cat standing in a chair looking at the camera', 'Cat jumping up off the chair towards the camera', 'Blurry photograph of a cat jumping up from a chair', 'A cat sitting on top on a chair on a pillow.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A dog with a bird and a large cow on a street.', 'positives': ['A couple of cows standing on top of cement ground.', 'A mottled brown dog and cow with two little birds outdoors.', 'A bird sitting on the back of a cow and a dog and bird standing on the ground next to the cow. ', 'a cow standing next to a dog on dirt ground '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Several people in a canoe on the river.', 'positives': ['A group of people riding in a  boat on top of a lake.', 'some people in a boat riding on a river ', 'a group of people that are floating on a boat', 'a yellow boat with people on it in a body of water'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A red stop sign sitting on the side of a road.', 'positives': ['The stop sign is clearly visible for all of us to see.', 'Street corner with stop sign with snow piles around', 'a red stop sign at a snowy street intersection', 'a stop sign on a city street covered in snow'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A black and white cat sits upon a cushioned chair', 'positives': ['The cat is laying down on the chair in the room.', 'A fat cat laying in a chair with two pillows. ', 'The black and white cat is sitting on a tan couch.', 'A black and white cat laying on top of a brown chair.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A person standing near boats in the water under an umbrella. ', 'positives': ['a person with a purple umbrella water and some buildings', 'A woman stands below an umbrella looking out over the marina.', 'a person is standing by the water with an umbrella', 'A man with a purple umbrella stands on a dock as the sun sets'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A man tending to a brown and white cow.', 'positives': ['a farmer putting a harness on the face of a cow', 'a man wearing a cowboy hat and messing with a cow', 'a close up of a person and a cow behind a fence ', 'A man in colorful dress and hat is tying ribbon on neck of a cow.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A double decker bus and a truck side by side in the street. ', 'positives': ['a large bus is next to a black truck', 'A delivery van and a passenger buss drive down a street in a city.', 'A double decker bus driving along side a delivery truck.', 'a blue red and white double decker bus and a black truck'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat lying on top of a laptop on a bed.', 'positives': ['A cat laying on top of a closed laptop that is sitting on a bed.', 'a gray black and white cat laying on a laptop', 'a cat lays down on top of a laptop ', 'A cat sitting on a closed laptop onto of a blanket.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a couple of cows are grazing on the grass outside', 'positives': ['A couple of cows standing on top of a lush green field.', 'This is an image of two cows eating grass.', 'Two cows eat grass from a lawn near a city sidewalk.', 'tow cows stand in a field grazing in a city'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'cows grazing in a meadow in front of a meadow', 'positives': ['a mountain with a bunch of animals next to it', 'many cows on a hill with mountains behind them', 'a number of cows on a field with a mountain in the background', 'Herd of animals grazing on top of hill with mountains in background'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A red stop sign sitting on the side of a road.', 'positives': ['a field with a closed off gate and signs', 'A wooden gate with a stop sign closes off a rural park trail for the night. ', 'A fence that has a stop sign and sign indicating area closed.', 'a gate with a stop sign blocking the road '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A person feeds a bottle of milk to a kitten in a blanket', 'positives': ['a cat is drinking from a bottle in someones arms', 'A person feeding a kitten with a bottle of milk.', 'A person feed a newborn kitten with a bottle. ', 'A cat that has a bottle in his mouth.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': \"A dog licking a cat on top of a woman's lap. \", 'positives': ['A woman is fondling soft toy cat in her lap.', 'A woman holding a dog and a cat in her lap,.', \"A dog licking a kitten's face while sitting on a woman's lap. \", 'a lady that has a cat and a dog in her lap'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The cat is curled up asleep on the floor by the sneakers.', 'positives': ['A cat curled up in a cat bed on the floor ', 'A cat is curled up on a bed on the floor. ', 'The grey cat is asleep on a pillow type bed.', 'A cat laying on top of a floor next to a  white wall.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A bunch of animals grazing in a big grassy field.', 'positives': ['Large herd of cows moving across brown grassy area', 'A bird walks in a field beside a herd of cows.', 'A herd of cattle standing on top of a dry grass field.', 'Several animals and a bird can be seen in a field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A black and white image of a parking meter along the street.', 'positives': ['A parking meter sitting on the side of a street near a building.', 'A very close up view of a parking meter by the road.', 'A black and white photo of a parking meter on the other side of the road from a large building with cars coming from it.', 'Black and white photo of parking meter across street from building.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train that is sitting on a rail.', 'positives': ['There is a train traveling down the tracks.', 'A train traveling down tracks near power poles.', 'A train that is on a set of railroad tracks with telephone poles on each side of the tracks.', 'a long black train is coming down the tracks'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a fat cat laying on the floor while playing iwth a shoe lace ', 'positives': [\"A cat rubbing its head against a person's shoe.\", 'A cat that is laying down near a shoe.', \"A fat cat laying on the floor with his head laying on someone's foot. \", \"A cat laying with its head on someone's shoe \"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A canoeist heads for shore, away from an empty rowboat, a sailboat and another boat.   ', 'positives': ['Different kinds of boats sail on a body of water.', 'A few boats floating on top of a body of water.', 'a lake with some boats and canoes on it', 'There are a few small boats left out on the water.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'two cows standing in the grass while looking at the camera ', 'positives': ['Two brown and white cows standing in a grassy field.', 'Two cows that are standing in the grass.', 'The two cows are standing close together on the field.', 'A couple of cows standing on top of a grass covered field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Sailors in a control center talk on a radio.', 'positives': ['Several Sailors in a control room working, one of which is on the radio', 'a group of people that are standing in a boat', 'A group of sailors sitting in front of a control area.', 'Navy commander using walkie system to talk to someone'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The maroon truck is parked in a parking space.', 'positives': ['A truck is parked in front of a store. ', 'A red truck parked in a parking space.', 'a red truck is parked in a spot', 'The red pick up truck is in a parking space. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a person holding a cat underneath a black umbrella', 'positives': ['A woman with glasses holding a cat and an umbrella.', 'A woman and her cat under an umbrella', 'Woman holding an umbrella and a small cat', 'A woman holding a cat in her arms under an umbrella. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a persons finger is on a parking meter', 'positives': ['A person touching the coin loading area of a parking meter.', 'Finger pointing to a parking meeter that reads \"Free\" on it', 'a hand a parking meter and a blue car', 'A finger pushing a parking meter in front of a blue car.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Catch standing in front of large television in living area.', 'positives': ['A cat is watching a band performing on television.', 'A cat that is sitting in front of a television.', 'The cat watches a concert on the television.', 'Cat on hind legs watching concert on television'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'An old fire truck parked outside a brick building. ', 'positives': ['An old fire engine parked in front of a brick building.', 'A truck parked next to a tall brick building.', 'a large truck with a ladder on the top', 'An old firetruck sits parked on the street'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a close up ofa cat playing with a shoe on the ground', 'positives': ['A CAT STANDING INSIDE OF A LARGE SHOE THAT IS ON THE GROUND ', 'A cat standing on top of a shoe on the floor.', 'The cat has it paws on the shoe.', 'Cat playing with the sparkling laces on a walking shoe.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a truck on a city street near a building ', 'positives': ['A long white box truck drives down a suburban street. ', 'A white garbage truck stops to pick up trash.', 'A white truck travelling on a street pass homes. ', 'The large white truck is driving down a road.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A red and white fire truck is parked on the side of the road. ', 'positives': ['A white and red firetruck is parked in a parking lot. ', 'A fire truck parked by a curb near a parking lot ', 'The fire truck is parked outside in the parking lot.', 'A red and white fire engine truck is parked parallel in a parking lot.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Cat laying on someones lap with a laptop computer next to it.', 'positives': ['A cat lying down next to a laptop.', 'A cat that is laying on a bed near a laptop.', 'Cat curled up asleep on green blanket in front of open laptop', 'a cat that is sitting on some ones lap'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The stop sign is half covered by tree leaves.', 'positives': ['A red stop sign that is behind trees.', 'Stop sign covered by tree branch at front of parking lot', 'A red stop sign sitting in a  parking lot.', 'a stop sign covered by a tree branch'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A man sits in a carriage behind a cow.', 'positives': ['A man in his vehicle being pulled by a bull. ', 'a man sitting in his wagon being pulled by a cow', 'a cow pulling a little carriage a man is sitting on ', 'a man is sitting in the back of a carriage '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'this is an image of a train with graffiti', 'positives': ['a passenger train with  a drawing on the side of it', 'a train on a track with a sky background ', 'A rendition of the scream painting in graffiti on a passing train ', 'The train has a painting on the side of it.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a small train is traveling down a rail road track', 'positives': ['Train on the tracks heading towards a bridge.', 'a green train that is parked on a rail road track', 'A blue train traveling along tracks near a green hillside.', 'A train with two cars is on a railroad track that splits into several directions.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A red stop sign sitting on the side of a road.', 'positives': ['Street corner stop sign with two street signs ', 'A stop sign in the dessert with signs around the bottom.', 'Roadway signs at intersection in remote area on nice day.', 'A stop sign and street signs share a pole.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Three pictures of a part of a street with different vehicles and different times. ', 'positives': ['The parade has police cars and fight trucks.', 'Three pictures taken of three different kinds of emergency vehicles', 'a vintage truck, a fire truck, and a line of police cars', 'a couple of police cars and fire engines are driving by'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a man is walking a cow down the street', 'positives': ['A horse being walked by a man in a orange outfit.', 'A guy is leading a mule through a parking lot.', 'a person walking with a cow in a parking lot', 'a cow is walking down the street with a blanket on top of it'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a vehicle is parked against a curb with a meter', 'positives': ['a car is parked on the side of the street', 'some cars parked on the side of the road ', 'A car parked beside and a sidewalk and parking meter.', 'a parking meter on a rural street and a parked car'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A boat that is sitting in the sand.', 'positives': ['a green boat is sitting on the beach', 'An old boat with chipped paint and a lot of flags on the beach.', 'A boat with several flags on it on the sand near the beach. ', 'An old boat is on the shore of a beach with nets, boxes, and other junk next to it and other beached boats in the background.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat laying on top of a white cushion.', 'positives': ['a cat laying on a black and white chair ', 'A cat lays on a dining room chair.', 'A cat lies on a chair looking up at the camera. ', 'The cat is laying on the chair. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a couple of white vehicles in a large field', 'positives': ['Two men preparing a screened box in an open field.', 'Two people attend to a box beside two white trucks.', 'A couple cars on a grassy hill during the day', 'A white truck driving in front of another white truck.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A boat with a wooden hull is on a beach.', 'positives': ['A boat sitting on top of a beach attached to a rusted chain.', 'A rusted chain is on the beach in front of a boat.', 'a wooden boat is out on shore with some chains', 'The hull of a boat and chain on an empty beach.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cow standing on top of a grass covered hill.', 'positives': [\"there's one black cow in the forefront and a few cows in the distance\", 'A cow grazing in a field with mountain on the horizon.', 'a cow is standing off in a field', 'A cow is grazing in an open field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'An elephant standing next to a  herd of wild animals.', 'positives': ['An elephant is near a lake surrounded by zebras.', 'a large elephant is standing near some zebras', 'Elephant and zebras near a watering hole, in a mud flat.', 'Zebras, and elephant and another animal standing near water. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'the back view of a moving train going down the track', 'positives': ['There is a train with lights going down a track.', 'The back lights of a passenger train are glowing red.', 'A train traveling down tracks near a signal.', 'A train heading down the train tracks at dusk.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train on the tacks in a big city', 'positives': ['Urban train traveling down the tracks of a city.', 'The passenger train with four cars is coming around the track.', 'a train that is parked on a train track', 'A train is on the tracks after going under a tunnel.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A group of sixteen different photos of various outdoor scenes next to bodies of water.', 'positives': ['There are 1 different pictures of boating related pictures.', 'A series of photographs showing different areas of a city.', 'Several photos of bodies of water and boats.', 'Photo montage of boats moored in large populated area.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A man is being dragged in the water between two oxen.', 'positives': ['A man being led by two white cows.', 'This is an image of a person in water holding onto cows.', 'a person holding on to two cows ', 'Man being dragged through muddy water by cattle during race.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a train drives through an area of some trees and houses', 'positives': ['A train that is sitting on train tracks.', 'A train with three cars going down a track by itself.', 'A train traveling down tracks through an area with lots of green trees.', 'A short train on train tracks between trees.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a blue yellow and white train and some tracks', 'positives': ['A silver and blue train traveling under electric tracks.', 'a blue and white train is coming down some tracks', 'a large tram is passing by cable wires', 'An blue and yellow electric train travels down tracks.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a work truck is stopped at a stop sign', 'positives': ['A large truck stops at the stop sign.', 'An urban city street intersection with buildings on both sides of the road.', 'A street view with cars and buildings in the background with a truck stopped at a stop sign.', 'The truck is driving along the street in the city.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The meter is ready for someone to pay to park', 'positives': ['Closeup of a parking meter on the curb of a city street.', 'a parking meter is on the curb at night', 'And old parking meter is pictured at the side of a road.', 'A parking meter sitting on the side of a road.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Animals walking down the beach near the water.', 'positives': ['A group of animals walking across a wave covered beach.', 'lol cows walking down the beach and people walking up the beach', 'A small herd of cows walks along a beach towards people.', 'A LINE OF ANIMALS WALKING IN A LINE ON THE BEACH '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train on the tracks on a cloudy day ', 'positives': ['A red, blue, and yellow passenger train goes along the track.', 'A red train traveling down tracks moving away from a tall building.', 'There is a train going down the tracks.', 'A blue, yellow and red passenger train near a city'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A little girl holding a stop sign over her head ', 'positives': ['The little boy is holding up a stop sign', 'The young child is holding up a stop sign.', 'Young boy holding up traffic sign while sitting on ledge.', 'A little boy that is holding a stop sign.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A man on a boat rides with his dog sitting on his lap.', 'positives': ['A man holding a beer and his dog on a boat in the water.', 'A man riding in a boat with a dog on his lap,', 'Man sitting in seat with dog aboard boat on open water.', 'A man and dog riding in a boat.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Car straped on the back of a tow truck.', 'positives': [\"Silver car strapped down on the truck's flatbed \", 'A fancy car is being towed by a large truck.', 'A car sitting on the back of a tow truck.', 'a tow truck going down the road with a silver car on the back of it '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'An orange train is pulling into the platform of a station.', 'positives': ['a train that is at a large train station', 'An orange train traveling down tracks at night.', 'A train pulled up at a train station.', 'A large long train on a steel track.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat laying in an empty open suitcase.', 'positives': ['The house cat is laying inside the suitcase.', 'a close up of a cat laying inside of an opened luggage bag', 'a cat is standing inside of a suitcase', 'A cat standing in a open suitcase in a room.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A large group of people on a dock with some boats.', 'positives': ['A row of several boats docked at a pier with several people around them.', 'Speedboats lined up along dock with large group of onlookers', 'A group of people on a dock looking at docked speedboats.', 'Several speedboats at a pier where a lot of people are gathered. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a small river that flows between some buildings', 'positives': ['A boat that is traveling down a river.', 'a boat in the water near a large city', 'A boat traveling along a river below very tall buildings.', 'a boat is traveling through a river in a city'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat is walking toward a Coca-Cola bottle. ', 'positives': ['Cat walking on the desk to get to the soda bottle', 'A cat standing on top of a wooden table.', 'A cat is on a table next to a soda bottle.', 'A cat that is standing near a empty bottle.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Two trucks that are parked on the beach.', 'positives': ['Life guard vehicles parked on beach in populated area.', 'Two vehicles parked next to a lifeguards beach hut.', 'a yellow truck is parked by the beach', 'A yellow truck parked next to another yellow truck.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A blue truck parked in front of a white building.', 'positives': ['Pick up truck parked by side of road with white building in distance', 'A three wheeled mini pickup truck parked on the side of a road', 'A three wheeled car parked in an empty lot.', 'A three wheeled truck on the gravel side of the road.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a close up of a boat on a beach not in the water ', 'positives': ['A boat full of boating equipment on the sand.', 'A white boat sitting on top of a sandy beach.', 'The fishers boats are docked on shore ', 'Boats pulled up on a sandy shore with junk in them.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A gray cat curled up and napping in her bed.', 'positives': ['A cat curled up asleep in its striped cat bed', 'a cat is curled up in a ball', 'A cat laying on a small pet bed in a room.', 'A cat sleeping inside of an animal bed.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'the back of a red fire truck that is parked', 'positives': ['The fire truck is parked with a view of a bridge in the background.', 'fire engine number 1 near the golden gate bridge', 'A fire truck near a bridge and a body of water.', 'The is a fire engine next to the Golden Gate Bridge.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A gray and white cat laying in a folding chair outside of a restaurant.  ', 'positives': ['A gray and white cat laying on top of a wooden chair.', 'a wooden rocking chair with a cat sitting on top ', 'This is a picture of a cat sitting on a chair.', 'a cat is on a wood chair by a sign'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A man is standing beside a parking meter, writing on his hand.', 'positives': ['A man standing next to a parking meter next to parked cars.', 'a person standing near a parking meter ', 'A man makes a note of something on his hand.', 'Without paper handy, a man writes a reminder about the parking meter on his palm. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat sitting on top of a wooden chair leaning up against a table.', 'positives': ['A cat is sitting on a pile of books, in a chair.', 'A calico cat sits on a chair and looks at paper on a desk.', 'a close up of a cat in a chair near a desk', 'This business minded calico seems to be letting the paper work pile up.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A fire truck parked on the road behind a barricade.', 'positives': ['A yellow fire truck parked in a street behind barricades.', 'There is a firetruck parked in the street with cones out around it.', 'a yellow fire truck is parked by some cones', 'Yellow fire engine parked on roadway at outdoor event.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A stylish person stands in front of a parking meter.', 'positives': ['The man is looking at the parking meter. ', 'Adult looking at parking meter in busy city street.', 'A man in a black hat standing next to a parking meter.', 'A person with a hat standing by a parking meter.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a red dump truck with a shovel on the front passing a police car', 'positives': ['an orange work truck is near a car', 'A red bull dozer truck is in the street.', 'A police car driving by a construction truck.', 'A dump truck with a blade on it and a police car '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A stop sign with a tan border at an intersection.', 'positives': ['A red, white, cream and tan colored traffic sign on the corner. ', 'Stylish stop sign at a low traffic intersection.', 'a red stop sign on a pole by some trees', 'A STOP SIGN IN SIDE OF A PARKING LOT ON THE CORNER '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Happy dog sitting in the bed of a pickup truck.', 'positives': ['a dog is in the back of a pick-up truck', 'A truck has a dog in the bed who is looking over the side.', 'A GREY TRUCK WITH A WHITE DOG SITTING IN THE BACK SEAT ', 'A dog sitting in the back of a pickup truck. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A man sitting on something with an untied tie around his neck. ', 'positives': ['A man sitting on a bench in the dark.', 'A young man with a neck tie untied around his neck', 'a person is sitting down with a tie on their shoulder', 'A man wearing a striped top sitting on a couch'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a cat is sitting on the floor among boxes ', 'positives': ['A cat looks at an empty plate among box clutter', 'The cat is looking up at the plate', 'a close up of a plate with a cat in the background', 'a cat is standing behind a white pllate'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The cat is laying in a grey purse', 'positives': ['A fluffy cat lounges inside a canvas bag', 'a cat laying inside of an opened hand bag', 'a small cat is sitting in a purse', 'a white cat is sitting inside of a bag'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'an orange and white truck with a crane on the back', 'positives': ['A truck travelling on the road near a house with a fence and trees. ', 'A truck that is parked on the side of the street.', 'a truck on a city street near trees ', 'an orange and white truck with a lift parked on the street'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a close up of a cat laying on a laptop on a chair ', 'positives': ['a gray and white cat is laying on top of a laptop', 'A gray cat laying on top of a laptop computer.', 'A cat laying on a laptop on a chair.', 'This kitty knows where to sit to get attention.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a diesel train next to the platform of a train station', 'positives': ['A train making a stop in the train station.', 'A tan and brown train at a train station with windows.', 'A train is pulling into the station. ', 'A large long train on a steel track.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A construction truck with hauling bed travels on the street', 'positives': ['a blue and white truck is driving down the street', 'a blue and white dump truck carrying gravel', 'The utility truck is driving on the road', 'A dump truck is driving up a road.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A group of cows walking along a grassy field. ', 'positives': ['The three cows are together in a field. ', 'Several cows in a grassy field looking off to the side.', 'Cattle standing in large grassy field in black and white photo.', 'a couple of cows are standing in a grassy field'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A silver and yellow engine is followed by several train cars.', 'positives': ['A passenger train that is traveling down some railroad tracks.', 'The train is stopped at the railroad station.', 'A train moves on one of several pairs of tracks.', 'Yellow and grey train passing near platform in urban area.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Old green truck on roadway at intersection in large city.', 'positives': ['An old truck labeled with Harrods is on the street.', 'An antique truck featuring Harrods drives on the street.', 'An odd looking truck that is driving down the street.', 'The old style truck is parked on the street.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Several traffic signs on a pole on a city street.', 'positives': ['We are looking up a couple of street signs.', 'Stop sign with two way traffic and one way signs above', 'A one way sign, a two way traffic ahead sign, and a stop sign.', 'some red white yellow and black signs on a black pole'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The heard of cows are in the snow covered field.', 'positives': ['A herd of cattle grazing on top of a tall grass field.', 'there are many brown and white cows standing in a large field', 'A herd of cows walking through frozen fields.', 'Five cows walking around in the tall grass.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a female in a blue shirt a cat and a plate', 'positives': [\"A woman and her cat are eating off the plate that's on her lap.\", 'a woman with a plate and a cat in her lap', 'a girl giving her cat some of her food', 'A girl takes a bite of scrambled egg as her cat sniffs at a crumb on her plate.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a red stop sign at a city intersection', 'positives': ['A stop sign in Chinese is across the street from a large movie.', 'A red octagon street sign with non-English letters.', 'View from an alley of a city street.', 'A red stop sign that is sitting on a pole.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a gray ship is docked water and a smaller boat', 'positives': ['A ship that is sitting in the water.', 'a large platform with a boat beside it', 'The boats are near a floating dock. ', 'The bats are docked and ready to be taken out on the water'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a vehicle is pulling something out of a garage', 'positives': ['Big truck leaving a factory carrying large, architectural tank.', 'A dump truck pulls a large trailer out of a garage.', 'A dump truck towing a large tank on top of a metal structure.', 'A truck pulls industrial equipment out of a large warehouse'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The cow is grazing in the tall grass.', 'positives': ['The animal is grazing behind the house ', 'a cow eating some grass by a fence', 'A black cow eating some grass in a field.', 'A cow standing in a fenced off area eating grass.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The train is driving on the tracks with people aboard', 'positives': ['a train that is between a building and a waterway ', 'An airport has a train going by it.', 'Commuter train traveling on inclined track near waterway.', 'a train on an elevated track near a body of water '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A clear river with with motorboats and lighted buildings are seen on the bank.', 'positives': ['a few boats on some water lights and buildings', 'a boat is in the middle of a large river', 'A boat sails through the river near a city.', 'A boat sits in a bay surrounded by buildings.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Two cats sleeping on desktop next to keyboard', 'positives': ['The two cats are lying on the desk together', 'Two cats find room to stretch out and rest themselves end to end, even on a cluttered desk. ', 'a couple of cats are asleep near a keyboard', 'two cats are laying on a desk with things'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A stop sign on the corner of U and 6th streets.', 'positives': ['a stop sign and street sign on a pole', 'The stop sign has street names posted above it.', 'Several street signs and a traffic sign atop a steel post.', 'A pole with a number of street signs on it, including a stop sign,  rests in the foreground of a line of buildings. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The cat is laying on top of the laptop', 'positives': ['A siamese cat lays on top of a laptop.', 'A Siamese cat laying on top of a computer.', 'a cat is laying on top of a laptop', 'There is a cat lying on top of the laptop.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': \"The black cow has a blue tag on it's ear.\", 'positives': ['A black cow with an ear tag looking over its shoulder.', 'Black cow stands and look towards the camera', 'Black cow standing in grassy field near forest.', 'A black cow looks directly at the camera.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train station where a train is passing through and there is only one person walking.', 'positives': ['a man sporting a back back walking along the outside of a train', 'A man standing on a loading platform in a train station.', 'Train pulling through enclosed station house as man runs past it', 'a quiet long hallway in a train terminal'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The people are over by the cows in the water', 'positives': ['Two boys walking around oxen by the pond.', 'A man standing on top of a lush green hill near animals.', 'A bunch of animals that are standing near each other.', 'Young boys are standing by the waters edge.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A baby boy standing in a room holding a baby doll.', 'positives': ['The older people are watching the kid play', 'A young boy playing with a doll while adults watch.', 'grandparents enjoying the grandson with the cowboy hat on.', 'Three adults watch a child holding a toy doll.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': \"Two water buffalo's standing together by a fence.\", 'positives': ['Two cows standing in a field behind a wire fence.', 'a couple of cows that are inside of a fence', 'a black cow and a black and white faced cow are at a barb wire fence', 'This is a picture of two cows in a field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat sits on top of a sleeping dog. ', 'positives': ['A dog lays sleeping while a cat lays on top of it.', 'A dog with its head on its paws that has a cat on its back.', 'a black dog is sleeping  outside on the ground', 'There is a dog sleeping on the ground and a cat behind him.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a stop sign is outside near some trees', 'positives': ['Traffic sign at side of roadway during rain storm.', 'a stop sign that is out in some rain', 'A stop sign in the rain on a street corner.', 'A red stop sign sitting on the side of a wet sidewalk.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A herd of cattle standing on a lagoon filled with ocean water.', 'positives': ['A group of cows stand in a pool of water near the ocean. ', 'some animals are out standing in the water', 'Many cows drink and bath in a body of water. ', 'There are several wild animals wading in shallow water near the beach.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A smiling woman casually dressed is sitting on a white couch with a big white cat.', 'positives': ['A woman holding her cat on the couch.', 'a woman holding a white cat on a couch', 'A woman sits on a couch holding her white cat.', 'A woman in grey sweater holding a white cat on couch.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Two brown cows stand in a glass field.', 'positives': ['there a two dark brown cows and one light brown cow', 'a couple of very large cows in a field', 'a couple of cows are standing in a field', 'Two brown cows looking at the camera. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A black cat is pictured curled up on a laptop.', 'positives': ['A black cat lying down on a laptop.', 'a black cat sleeping on a laptop by a window', 'A black cat sleeping on a laptop on a table.', 'A cat laying on top of a laptop computer.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A very steep lush green hill with some items on top.', 'positives': ['A blue train on tracks between two hills.', 'Two engine train moving through rolling grassy hills.', 'a train passing on the railroad in a grassy hill', 'A large long train on a steel track.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train traveling down tracks next to a tall building.', 'positives': ['a train track that has a train on it', 'Train on a track driving past a  cylindrical building .', 'A train that is on a train track in the grass.', 'Railway tank cars in rural setting near grain silos on cloudy day.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A boat that is floating in the water.', 'positives': ['A small white boat in the open water.', 'A small boat that is parked next to a big one. ', 'A large white boat sitting next to a shoreline pier.', 'A sailboard tied up at a dock in a harbor.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat sitting on a computer chair in a room', 'positives': ['A cat sitting on a chair looking down at another cat ', 'a cat that is standing on a red chair', 'a cat sitting on an office chair looking at the tail of another cat ', 'A cat that is sitting on a chair.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The poor puppy just wants to be friends with the cat.', 'positives': ['a cat that is sitting next to a brick wall', 'The cat and dog are laying on the sidewalk together. ', 'Four images show a dog approaching a cat.', 'A series of pics aligned vertically showing a dog and cat cuddling against a wall.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Should we hitch up the horse or hitch up the truck.', 'positives': ['The horse is walking near the truck. ', 'a truck that has a horse standing next to it', 'A white horse standing next to a rusty old truck.', 'The white horse is standing behind a rusted old truck.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cow is laying down in the field.', 'positives': ['Cows sitting in their pasture by some trees.', 'a brown and white cow sitting in the grass on a field ', 'A cow sitting in a field with pine trees and mountains in the background.', 'Two brown and white cows laying in a field of grass and trees. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'There is a stop sign in a field.', 'positives': ['A stop sign on a closed gate to a field.', 'A red stop sign hanging from the side of a pole.', 'A stop sign is posted on a metal gate in the countryside.', 'A stop sign on a locked gate at the edge of a field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cow that is laying down in the grass.', 'positives': ['There is a cow laying down on the field.', \"A picture of a cow resting in a children's park.\", 'a animal that is sitting on a grass field', 'a dog is standing behind a fence in a field'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Altered black and white photograph of a man in a tuxedo at the beach ', 'positives': ['A man in a tuxedo stands on the beach near the ocean. ', 'A man wearing a black jacket and bow tie.', 'Man wearing tuxedo standing on beach near ocean.', 'A man that has a bow tie standing in the sand.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Proud farmers looking at a cow and its child in a barn', 'positives': ['Brown cow nursing black calf in a barn.', 'A brown cow standing next to a small black cow.', 'A brown cow and a black calf in a pen. ', 'Some very cute cows nursing in a pen.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A black and white cat is sitting on the edge of a computer desk where a laptop is on.', 'positives': ['a black orange and white cat and a laptop', 'A cat sitting on a desk next to a laptop.', 'A brown and white cat beside a laptop computer.', 'A cat standing next to a laptop computer on a desk.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A young man dresses in suit and vest takes a picture. ', 'positives': ['a man in striped shirt and vest leaning on a boat rail.', 'A man with a tie and vest on posing.', 'a male in a black tie and black vest', 'A man standing on the side of a boat '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'some newspaper a black cat a screwdriver and a laptop', 'positives': ['A cat lying on a surface in an office', 'A cat is sitting on the floor next to a workstation.', 'A black cat sits beside a laptop being worked on', 'a black cat is standing on a table with some tools'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'a white and black truck and some houses', 'positives': ['A man is being lifted on a ladder on the back of a truck. ', 'A large crane on the back of a white truck.', 'a white truck with a green crane on it', 'a truck with a lift carrying a man to the electrical wires', 'A large white truck with a crane on top of it.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A deck chair rests close by, and facing, an empty rowboat on the sand.', 'positives': ['A blue boat and chair are on a sandy beach.', 'A boat sits in the sand next to a beach chair. ', 'A boat sitting on top of a sandy beach.', 'A single chair and a boat sit on the sand in front of a building.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'all of the parking meters on this street are covered with plastic bags', 'positives': ['A line of parking meters on the street ', 'There are a lot of parking meters broken down.', 'A row of parking meters sitting along side of a street.', 'Parking meters covered with yellow plastic at outdoor patrolled event.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat and a dog laying on top of a bed.', 'positives': ['A cat is resting on a bed, behind a dog that is chewing on a teddy bear.', 'A dog and a cat sitting on a bed with a stuffed animal.', 'a dog that has a stuffed animal in his mouth', 'A dog a cat and a teddy bear all on a bed together.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Cattle being unloaded at the bottom of a the mountains.', 'positives': ['a couple of cows that are inside a fence', 'The cattle are seen in a barn in a hilly area.', 'some brown and white cattle a mountain and a fence', 'A tractor with a small housing structure on top of it.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Two cows graze a field against a backdrop of snow-covered mountains.', 'positives': ['Two cows are standing in an alpine pasture.', 'a very large cow that is in a field', 'Two fenced in cows standing together near snowy mountains. ', 'A pair of cows are grazing in a field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'The cow is chewing on a mouth full of hay.', 'positives': ['A cow that is standing in the dirt eating.', 'A fenced in brown and white cow eating hay. ', 'A brown and white cow eating a clump of hay.', 'a close up of a cow eating hay in a cage'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A couple of people are in small boat.', 'positives': ['A couple of people riding on the back of a boat.', 'Men prepare to go out to fish in an old boat', 'A boat sitting in a body of water that has two people in it.', 'A boat that is sitting inside of the water.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Two grey parking meters with trees in the background.', 'positives': ['The parking meters have a three hour limit. ', 'a couple of parking meter are near a tree', 'Two parking meters sitting on the side of a dirt road.', 'A pair of parking meters with three hour time limit stickers on each meter.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A large herd of cows are walking by a tent.', 'positives': ['Herd of cattle being led by men in white lab coats on grassy field at outdoor event.', 'A bunch of people standing near cows in the grass.', 'A livestock show of men and women escorting their cows.', 'A group of men walking brown and white cows across a field.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train that is sitting on the tracks near gravel.', 'positives': ['a train that is on a rail road track', 'An open air  trolley that is bringing people somewhere.', 'A small red train sits on some tracks. ', 'People ride a mock steam engine around a track. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A truck moving cut down trees to destination', 'positives': ['a truck with people and bushes in the back', 'A truck hauling trees on a dirt road ', 'a work truck filled with cut down trees', 'A truck transports things down the road. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train is coming along on a track.', 'positives': ['a blue and gray trains engine is pulling its cars ', 'A blue train engine pulling cars on a track.', 'a very long train that are on some tracks', 'A train driving down the tracks under power lines.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Cows looking at the camera while their picture is taken.', 'positives': ['some brown and black cattle and green grass', 'A herd of brown cows walking across a grass covered field.', 'a bunch of cattle are standing in a grassy field', 'a bunch of cows standing in a field in front of a wide open, mountainous area'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A train sitting inside of a train station.', 'positives': ['A grey-and-yellow train waits idle on its tracks with empty platforms on either side.', 'An elegant indoor train station containing several trains.', 'One lonely person on the platform waiting for train to open for boarding', 'A sleek train sits at an indoor subway station.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A teddy bear wearing a sweater and a bow tie ', 'positives': ['A teddy bear wearing a sweater with a bow tie.', 'A teddy bear is dressed up as an old lady.', 'The stuffed animal is wearing a sweater and bow tie.', 'a teddy bear that is in a blue sweater'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A large cow walking along a beach on a sunny day. ', 'positives': [' A cow standing on the sand by the ocean.', 'The cow is walking on the beach near the water.', 'A cow walking in the sand on a beach.', 'A brown cow walking across a beach near the ocean.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A cat sitting in a window at a store.', 'positives': ['The cat is laying down in the window resting.', 'An orange and white cat sitting on top of a window sill.', 'An orange and white laying in the window of a bookstore. ', 'A cat sits in a window next to a book. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A close up of a stop sign with graffiti on it.', 'positives': ['a red and white stop sign and some bushes and trees', 'A huge stop sign with paintings on it. ', 'A stop sign that has some graffiti on it.', 'A red stop sign covered in lots of graffiti.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A gray and white cat wearing an orange and black tie.', 'positives': ['The cat wearing the his tie looks handome.', 'A gray and white cat has a tie on.', 'a cat is wearing a tiny orange tie', 'A cat dressed in a collar and tie. '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'Sign on yellow gate warning of fine for trespassers.', 'positives': [\"A sign detailing the fine for going around the gate when it's down\", 'A stop sign on a gate with a notice posted of a fine if you go around when the gate is down.', 'There is a sign hanging on a fence ', 'A red stop sign sitting on top of a yellow gate.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'An orange and white cat and beaver looking at an ear of corn.', 'positives': [' a yellow cat going after some corn on the cob', 'A tabby cat looking a at a groundhog eating corn.', 'A cat leaning on top an electrical box.', 'a cat leaning on a box next to a tree '], 'negatives': [], 'type': 'sts_triplet', 'source_id': 2}\n",
            "{'query': 'A Review on the Assessment of Stress Conditions for Simultaneous Production of Microalgal Lipids and Carotenoids', 'positives': ['Microalgae for oil: strain selection, induction of lipid synthesis and outdoor mass cultivation in a low-cost photobioreactor.'], 'negatives': ['OtOplasty tOday : maximal benefit with state-Ofthe-art surgery'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Integrating Context Similarity with Sparse Linear Recommendation Model', 'positives': ['Splitting approaches for context-aware recommendation: an empirical study'], 'negatives': ['Factorization meets the neighborhood: a multifaceted collaborative filtering model'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Integrating Context Similarity with Sparse Linear Recommendation Model', 'positives': ['Deviation-Based Contextual SLIM Recommenders'], 'negatives': ['OO techniques applied to a real-time, embedded, spaceborne application'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Integrating Context Similarity with Sparse Linear Recommendation Model', 'positives': ['SLIM: Sparse Linear Methods for Top-N Recommender Systems'], 'negatives': ['k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural Networks and Memory Networks'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Integrating Context Similarity with Sparse Linear Recommendation Model', 'positives': ['Deviation-Based Contextual SLIM Recommenders'], 'negatives': ['On the History and Future of Sociolinguistic Data'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Integrating Context Similarity with Sparse Linear Recommendation Model', 'positives': ['Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering'], 'negatives': ['Vitamin D3 promotes the differentiation of colon carcinoma cells by the induction of E-cadherin and the inhibition of β-catenin signaling'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Learning to Pinpoint Singing Voice from Weakly Labeled Examples', 'positives': ['RWC Music Database: Popular, Classical and Jazz Music Databases'], 'negatives': ['Scalable Minimum Bayes Risk Training of Deep Neural Network Acoustic Models Using Distributed Hessian-free Optimization.'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Learning to Pinpoint Singing Voice from Weakly Labeled Examples', 'positives': ['Striving for Simplicity: The All Convolutional Net'], 'negatives': ['A Software Interface for Supporting the Application of Data Science to Optimisation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Learning to Pinpoint Singing Voice from Weakly Labeled Examples', 'positives': ['MedleyDB: A Multitrack Dataset for Annotation-Intensive MIR Research'], 'negatives': ['The synthesis of art and science is lived by the nurse in the nursing act'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Learning to Pinpoint Singing Voice from Weakly Labeled Examples', 'positives': ['RWC Music Database: Popular, Classical and Jazz Music Databases'], 'negatives': ['From Massive Parallelization to Quantum Computing: Seven Novel Approaches to Query Optimization'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Learning to Pinpoint Singing Voice from Weakly Labeled Examples', 'positives': ['RWC Music Database: Popular, Classical and Jazz Music Databases'], 'negatives': ['Learning Plannable Representations with Causal InfoGAN'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A multichannel MMSE-based framework for joint blind source separation and noise reduction', 'positives': ['Fast and robust fixed-point algorithms for independent component analysis'], 'negatives': ['Evaluation of Objective Quality Measures for Speech Enhancement'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A multichannel MMSE-based framework for joint blind source separation and noise reduction', 'positives': ['Fast and robust fixed-point algorithms for independent component analysis'], 'negatives': ['processor design in 3d die - stacking technologies .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A multichannel MMSE-based framework for joint blind source separation and noise reduction', 'positives': ['Blind separation of speech mixtures via time-frequency masking'], 'negatives': ['Classifying Facial Actions'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A multichannel MMSE-based framework for joint blind source separation and noise reduction', 'positives': ['Fast and robust fixed-point algorithms for independent component analysis'], 'negatives': ['Towards a Cost Optimal Design for a 5G Mobile Core Network Based on SDN and NFV'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A multichannel MMSE-based framework for joint blind source separation and noise reduction', 'positives': ['Performance measurement in blind audio source separation'], 'negatives': ['Malware Guard Extension: Using SGX to Conceal Cache Attacks'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Attention-based Collaboration Framework for Multi-View Network Representation Learning', 'positives': ['Multi-View Clustering via Joint Nonnegative Matrix Factorization'], 'negatives': ['Systematic and integrative analysis of large gene lists using DAVID bioinformatics resources'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Attention-based Collaboration Framework for Multi-View Network Representation Learning', 'positives': ['Distributed Representations of Words and Phrases and their Compositionality'], 'negatives': ['Knowledge transfer between and within alliance partners : Private versus collective benefits of social capital ☆'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Attention-based Collaboration Framework for Multi-View Network Representation Learning', 'positives': ['Neural Word Embedding as Implicit Matrix Factorization'], 'negatives': ['Security of Blockchain Technologies'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Attention-based Collaboration Framework for Multi-View Network Representation Learning', 'positives': ['Multi-View Clustering via Joint Nonnegative Matrix Factorization'], 'negatives': ['You Are How You Touch: User Verification on Smartphones via Tapping Behaviors'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Attention-based Collaboration Framework for Multi-View Network Representation Learning', 'positives': ['Multi-View Clustering via Joint Nonnegative Matrix Factorization'], 'negatives': ['Collaborative supply chain management: The most promising practice for building efficient and sustainable supply chains'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'E-commerce Recommendation with Personalized Promotion', 'positives': ['A REVIEW OF METHODS FOR MEASURING WILLINGNESS-TO-PAY'], 'negatives': ['Collaborative filtering with privacy'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'E-commerce Recommendation with Personalized Promotion', 'positives': ['Improving regularized singular value decomposition for collaborative filtering'], 'negatives': ['Impact of peer teaching on nursing students: perceptions of learning environment, self-efficacy, and knowledge.'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'E-commerce Recommendation with Personalized Promotion', 'positives': ['A Conceptual Model of Personalized Pricing Recommender System Based on Customer Online Behavior'], 'negatives': ['Combining multiple sources of knowledge in deep CNNs for action recognition'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'E-commerce Recommendation with Personalized Promotion', 'positives': ['using collaborative filtering to weave an information tapestry .'], 'negatives': ['3-D ICs: A Novel Chip Design for Improving Deep-Submicrometer Interconnect Performance and Systems-on-Chip Integration'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'E-commerce Recommendation with Personalized Promotion', 'positives': ['Improving regularized singular value decomposition for collaborative filtering'], 'negatives': ['State of the art on automatic road extraction for GIS update: a novel classification'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation', 'positives': ['Wasserstein Generative Adversarial Networks'], 'negatives': ['Annotated gigaword'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation', 'positives': ['Effective Approaches to Attention-based Neural Machine Translation'], 'negatives': ['Prospective comparison of endoscopy patient satisfaction surveys: e-mail versus standard mail versus telephone'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation', 'positives': ['Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks'], 'negatives': ['Edge Detection Algorithms Using Brain Tumor Detection and Segmentation Using Artificial Neural Network Techniques'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation', 'positives': ['Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks'], 'negatives': ['Lossless compression of color mosaic images'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation', 'positives': ['Energy-based Generative Adversarial Network'], 'negatives': ['Latent-space Physics: Towards Learning the Temporal Evolution of Fluid Flow'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Colour Labelling of Art Images Using Colour Palette Recognition', 'positives': ['Mean shift: A robust approach toward feature space analysis'], 'negatives': ['Class segmentation and object localization with superpixel neighborhoods'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Colour Labelling of Art Images Using Colour Palette Recognition', 'positives': ['A Linguistic Approach to Categorical Color Assignment for Data Visualization'], 'negatives': ['Question Answering System for Non-factoid Type Questions and Automatic Evaluation based on BE Method'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Colour Labelling of Art Images Using Colour Palette Recognition', 'positives': ['A Linguistic Approach to Categorical Color Assignment for Data Visualization'], 'negatives': ['evaluation and control of steel cleanliness review .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Colour Labelling of Art Images Using Colour Palette Recognition', 'positives': ['Mean shift, mode seeking, and clustering'], 'negatives': ['Stochastic Pre-classification for SDN Data Plane Matching'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Colour Labelling of Art Images Using Colour Palette Recognition', 'positives': ['Single color extraction and image query'], 'negatives': ['Cellular Automata designs for out of plane Nanomagnet Logic'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Cache based recurrent neural network language model inference for first pass speech recognition', 'positives': ['Recurrent Neural Network based Language Modeling in Meeting Recognition'], 'negatives': ['Classes for Fast Maximum Entropy Training'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Cache based recurrent neural network language model inference for first pass speech recognition', 'positives': ['Recurrent neural network based language model'], 'negatives': ['A Blockchain-Based Architecture for Collaborative DDoS Mitigation with Smart Contracts'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Cache based recurrent neural network language model inference for first pass speech recognition', 'positives': ['Strategies for training large scale neural network language models'], 'negatives': ['A flexible model supporting the specification and enforcement of role-based authorization in workflow management systems'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Cache based recurrent neural network language model inference for first pass speech recognition', 'positives': ['Recurrent Neural Network based Language Modeling in Meeting Recognition'], 'negatives': ['SAR ship detection using sea-land segmentation-based convolutional neural network'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Cache based recurrent neural network language model inference for first pass speech recognition', 'positives': ['Converting Neural Network Language Models into Back-off Language Models for Efficient Decoding in Automatic Speech Recognition'], 'negatives': ['Hypothesis Spaces for Minimum Bayes Risk Training in Large Vocabulary Speech Recognition'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Social Consequences of the Internet for Adolescents: A Decade of Research', 'positives': [\"Preadolescents' and adolescents' online communication and their closeness to friends\"], 'negatives': ['Psychosocial Functioning and Depression: Distinguishing Among Antecedents, Concomitants, and Consequences'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Social Consequences of the Internet for Adolescents: A Decade of Research', 'positives': ['Friendship Quality and Social Development'], 'negatives': ['Current-Mode Control Stability Analysis For DC-DC Converters ( Part 1 )'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Social Consequences of the Internet for Adolescents: A Decade of Research', 'positives': ['Internet paradox: A social technology that reduces social involvement and psychological well-being'], 'negatives': ['An integrated linear RF power detector'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Social Consequences of the Internet for Adolescents: A Decade of Research', 'positives': ['Computer-Mediated Communication Effects on Disclosure, Impressions, and Interpersonal Evaluations: Getting to Know One Another a Bit at a Time'], 'negatives': ['On Learning Invariant Representation for Domain Adaptation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Social Consequences of the Internet for Adolescents: A Decade of Research', 'positives': ['Friendship Quality and Social Development'], 'negatives': ['Predicting stocks returns correlations based on unstructured data sources'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A 7 DOF exoskeleton arm: Shoulder, elbow, wrist and hand mechanism for assistance to upper limb disabled individuals', 'positives': ['The Berlin brain-computer interface: EEG-based communication without subject training'], 'negatives': ['An introduction to kernel-based learning algorithms'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A 7 DOF exoskeleton arm: Shoulder, elbow, wrist and hand mechanism for assistance to upper limb disabled individuals', 'positives': ['The Berlin brain-computer interface: EEG-based communication without subject training'], 'negatives': ['The Dog as a Model for Understanding Human Social Behavior'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A 7 DOF exoskeleton arm: Shoulder, elbow, wrist and hand mechanism for assistance to upper limb disabled individuals', 'positives': ['Introduction to robotics mechanics and control'], 'negatives': ['Iterative Machine Learning for Output Tracking'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A 7 DOF exoskeleton arm: Shoulder, elbow, wrist and hand mechanism for assistance to upper limb disabled individuals', 'positives': ['Introduction to robotics mechanics and control'], 'negatives': ['Human Lunar missions and other exploration opportunities enabled by the Space Launch System'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A 7 DOF exoskeleton arm: Shoulder, elbow, wrist and hand mechanism for assistance to upper limb disabled individuals', 'positives': ['Introduction to robotics mechanics and control'], 'negatives': ['A Method to Segment Maps from Different Modalities Using Free Space Layout MAORIS: Map of Ripples Segmentation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Improving Mispronunciation Detection for Non-Native Learners with Multisource Information and LSTM-Based Deep Models', 'positives': ['Long Short Term Memory'], 'negatives': ['Finding Structure in Time'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Improving Mispronunciation Detection for Non-Native Learners with Multisource Information and LSTM-Based Deep Models', 'positives': ['Improving non-native mispronunciation detection and enriching diagnostic feedback with DNN-based speech attribute modeling'], 'negatives': ['what about teamwork ? .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Improving Mispronunciation Detection for Non-Native Learners with Multisource Information and LSTM-Based Deep Models', 'positives': ['Improving non-native mispronunciation detection and enriching diagnostic feedback with DNN-based speech attribute modeling'], 'negatives': ['Understanding Cloud Computing Vulnerabilities'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Improving Mispronunciation Detection for Non-Native Learners with Multisource Information and LSTM-Based Deep Models', 'positives': ['Improved mispronunciation detection with deep neural network trained acoustic models and transfer learning based logistic regression classifiers'], 'negatives': ['DBLSTM-based multi-scale fusion for dynamic emotion prediction in music'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Improving Mispronunciation Detection for Non-Native Learners with Multisource Information and LSTM-Based Deep Models', 'positives': ['Improved mispronunciation detection with deep neural network trained acoustic models and transfer learning based logistic regression classifiers'], 'negatives': ['Adaptive Mho type distance relaying scheme with fault resistance compensation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Inertial-Measurement-Unit-Based Pen With a Trajectory Reconstruction Algorithm and Its Applications', 'positives': ['Quaternion-based strap-down integration method for applications of inertial sensing to gait analysis'], 'negatives': ['A New Approach to Linear Filtering and Prediction Problems'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Inertial-Measurement-Unit-Based Pen With a Trajectory Reconstruction Algorithm and Its Applications', 'positives': ['Handwriting tracking based on coupled μIMU/electromagnetic resonance motion detection'], 'negatives': ['Semi Lobar Holoprosencephaly with Vertebral Segmentation Defects'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Inertial-Measurement-Unit-Based Pen With a Trajectory Reconstruction Algorithm and Its Applications', 'positives': ['Methods for infield user calibration of an inertial measurement unit without external equipment'], 'negatives': ['A Novel CMOS Full Adder'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Inertial-Measurement-Unit-Based Pen With a Trajectory Reconstruction Algorithm and Its Applications', 'positives': ['Handwriting tracking based on coupled μIMU/electromagnetic resonance motion detection'], 'negatives': ['On-chip spiral inductors with patterned ground shields for Si-based RF ICs'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'An Inertial-Measurement-Unit-Based Pen With a Trajectory Reconstruction Algorithm and Its Applications', 'positives': ['Attitude Estimation by Multiple-Mode Kalman Filters'], 'negatives': ['to see or not to see – innovative display technologies as enablers for ergonomic cockpit concepts ergonomic requirements future mobility future functionality .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Feature Based Sentiment Analysis for Service Reviews.', 'positives': ['Sentiment Analysis and Opinion Mining: A Survey'], 'negatives': ['Web data mining: exploring hyperlinks, contents, and usage data'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Feature Based Sentiment Analysis for Service Reviews.', 'positives': ['Mining Feature-Opinion in Online Customer Reviews for Opinion Summarization'], 'negatives': ['Vision based distance measurement system using single laser pointer design for underwater vehicle'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Feature Based Sentiment Analysis for Service Reviews.', 'positives': ['Thumbs Up? Sentiment Classification Using Machine Learning Techniques'], 'negatives': ['daily routine in cosmetic dermatology .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Feature Based Sentiment Analysis for Service Reviews.', 'positives': ['Thumbs Up? Sentiment Classification Using Machine Learning Techniques'], 'negatives': ['Association between gross motor function (GMFCS) and manual ability (MACS) in children with cerebral palsy. A population-based study of 359 children'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Feature Based Sentiment Analysis for Service Reviews.', 'positives': ['Thumbs Up? Sentiment Classification Using Machine Learning Techniques'], 'negatives': ['Model Selection Management Systems: The Next Frontier of Advanced Analytics'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Kalman Filter-Based Algorithm for IMU-Camera Calibration: Observability Analysis and Performance Evaluation', 'positives': ['stochastic models , estimation and control .'], 'negatives': ['Recursive Estimation of Motion, Structure, and Focal Length'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Kalman Filter-Based Algorithm for IMU-Camera Calibration: Observability Analysis and Performance Evaluation', 'positives': ['stochastic models , estimation and control .'], 'negatives': ['On the (In)Security of Mobile Two-Factor Authentication'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Kalman Filter-Based Algorithm for IMU-Camera Calibration: Observability Analysis and Performance Evaluation', 'positives': ['Kalman filtering for relative spacecraft attitude and position estimation'], 'negatives': ['The mechanics of state-dependent neural correlations'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Kalman Filter-Based Algorithm for IMU-Camera Calibration: Observability Analysis and Performance Evaluation', 'positives': ['1|A Kalman filter-based algorithm for IMU-camera calibration'], 'negatives': ['PCGAN: Partition-Controlled Human Image Generation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Kalman Filter-Based Algorithm for IMU-Camera Calibration: Observability Analysis and Performance Evaluation', 'positives': ['stochastic models , estimation and control .'], 'negatives': ['10 Gbit line rate packet-to-disk using n2disk'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ioCane: A Smart-Phone and Sensor-Augmented Mobility Aid for the Blind', 'positives': ['RFID and GPS integrated navigation system for the visually impaired'], 'negatives': ['indoor navigation using a diverse set of cheap , wearable sensors .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ioCane: A Smart-Phone and Sensor-Augmented Mobility Aid for the Blind', 'positives': ['RFID and GPS integrated navigation system for the visually impaired'], 'negatives': ['Orange juice intake reduces patient discomfort and is effective for bowel cleansing with polyethylene glycol during bowel preparation.'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ioCane: A Smart-Phone and Sensor-Augmented Mobility Aid for the Blind', 'positives': ['Navigation System for the Blind: Auditory Display Modes and Guidance'], 'negatives': ['Automating bug report assignment'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ioCane: A Smart-Phone and Sensor-Augmented Mobility Aid for the Blind', 'positives': ['RFID and GPS integrated navigation system for the visually impaired'], 'negatives': ['A Comprehensive Feature Study for Appliance Recognition on High Frequency Energy Data'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ioCane: A Smart-Phone and Sensor-Augmented Mobility Aid for the Blind', 'positives': ['Navigation System for the Blind: Auditory Display Modes and Guidance'], 'negatives': ['Epithelial antimicrobial defence of the skin and intestine'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Towards Automatically Classifying Depressive Symptoms from Twitter Data for Population Health.', 'positives': ['From ADHD to SAD: Analyzing the Language of Mental Health on Twitter through Self-Reported Diagnoses'], 'negatives': ['feeling bad on facebook : depression disclosures by college students on a social networking site .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Towards Automatically Classifying Depressive Symptoms from Twitter Data for Population Health.', 'positives': ['Perception Differences between the Depressed and Non-Depressed Users in Twitter'], 'negatives': ['A survey: Internet of Things (IOT) technologies, applications and challenges'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Towards Automatically Classifying Depressive Symptoms from Twitter Data for Population Health.', 'positives': ['Predicting postpartum changes in emotion and behavior via social media'], 'negatives': ['Competitive Analysis System for Theatrical Movie Releases Based on Movie Trailer Deep Video Representation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Towards Automatically Classifying Depressive Symptoms from Twitter Data for Population Health.', 'positives': ['From ADHD to SAD: Analyzing the Language of Mental Health on Twitter through Self-Reported Diagnoses'], 'negatives': ['syntactic clustering of the web .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Towards Automatically Classifying Depressive Symptoms from Twitter Data for Population Health.', 'positives': ['Quantifying Mental Health Signals in Twitter'], 'negatives': ['An Investigation of Deep-Learning Frameworks for Speaker Verification Antispoofing'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Classification and Numbering of Dental Radiographs for an Automated Human Identification System', 'positives': ['Digital Image Processing'], 'negatives': ['A Comparative Study on Shape Retrieval Using Fourier Descriptors with Different Shape Signatures'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Classification and Numbering of Dental Radiographs for an Automated Human Identification System', 'positives': ['Automated Dental Identification System (ADIS)'], 'negatives': ['Analyzing the Blogosphere for Predicting the Success of Music and Movie Products'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Classification and Numbering of Dental Radiographs for an Automated Human Identification System', 'positives': ['Classification and numbering of teeth in dental bitewing images'], 'negatives': ['Unveiling the Power of Deep Tracking'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Classification and Numbering of Dental Radiographs for an Automated Human Identification System', 'positives': ['Automated Dental Identification System (ADIS)'], 'negatives': ['Fifty years of X inactivation research'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Classification and Numbering of Dental Radiographs for an Automated Human Identification System', 'positives': ['Classification and numbering of teeth in dental bitewing images'], 'negatives': [\"Determinants of Consumer's Attitudes to Electronic Marketing in Jordan\"], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Deep Network with Visual Text Composition Behavior', 'positives': ['The Unreasonable Effectiveness of Word Representations for Twitter Named Entity Recognition'], 'negatives': ['Accurate Unlexicalized Parsing'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Deep Network with Visual Text Composition Behavior', 'positives': ['The Unreasonable Effectiveness of Word Representations for Twitter Named Entity Recognition'], 'negatives': ['Autonomous off-road navigation with end-to-end learning for the LAGR program'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Deep Network with Visual Text Composition Behavior', 'positives': ['Generating Text with Deep Reinforcement Learning'], 'negatives': ['Tumor-associated macrophages: unwitting accomplices in breast cancer malignancy'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Deep Network with Visual Text Composition Behavior', 'positives': ['The Unreasonable Effectiveness of Word Representations for Twitter Named Entity Recognition'], 'negatives': ['A new fast associative classification algorithm for detecting phishing websites'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A Deep Network with Visual Text Composition Behavior', 'positives': ['Training Very Deep Networks'], 'negatives': ['a frame theory primer for the kadison - singer problem .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Generalized Neural Graph Embedding with Matrix Factorization', 'positives': ['Word embedding revisited: a new representation learning and explicit matrix factorization perspective'], 'negatives': ['Learning Attribute-to-Feature Mappings for Cold-Start Recommendations'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Generalized Neural Graph Embedding with Matrix Factorization', 'positives': ['LINE: Large-scale Information Network Embedding'], 'negatives': ['Development of fluxless chip-on-wafer bonding process for 3DIC chip stacking with 30μm pitch lead-free solder micro bumps and reliability characterization'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Generalized Neural Graph Embedding with Matrix Factorization', 'positives': ['Link Prediction via Matrix Factorization'], 'negatives': ['Statistical Pattern Recognition of the Iris'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Generalized Neural Graph Embedding with Matrix Factorization', 'positives': ['Max-margin deepwalk: discriminative learning of network representation'], 'negatives': ['Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Generalized Neural Graph Embedding with Matrix Factorization', 'positives': ['LINE: Large-scale Information Network Embedding'], 'negatives': ['High spatial and temporal resolution retrospective cine cardiovascular magnetic resonance from shortened free breathing real-time acquisitions'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Commonsense for Generative Multi-Hop Question Answering Tasks', 'positives': ['Adam: A Method for Stochastic Optimization'], 'negatives': ['Re-Evaluation The Role Of Bleu In Machine Translation Research'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Commonsense for Generative Multi-Hop Question Answering Tasks', 'positives': ['Deep contextualized word representations'], 'negatives': ['Authorship Attribution with Neural Networks and Multiple Features: Notebook for PAN at CLEF 2018'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Commonsense for Generative Multi-Hop Question Answering Tasks', 'positives': ['Bidirectional Attention Flow for Machine Comprehension'], 'negatives': ['Methodology & Themes of Human-Robot Interaction: A Growing Research Field'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Commonsense for Generative Multi-Hop Question Answering Tasks', 'positives': ['Teaching Machines to Read and Comprehend'], 'negatives': ['Design Optimization of Reflective Polarizers for LCD Backlight Recycling'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Commonsense for Generative Multi-Hop Question Answering Tasks', 'positives': ['METEOR: An Automatic Metric For MT Evaluation With Improved Correlation With Human Judgments'], 'negatives': ['Networking Models in Flying Ad-Hoc Networks (FANETs): Concepts and Challenges'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Opinion Mining and Sentiment Polarity on Twitter and Correlation between Events and Sentiment', 'positives': ['Inductive learning algorithms and representations for text categorization'], 'negatives': ['Boosting and Rocchio applied to text filtering'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Opinion Mining and Sentiment Polarity on Twitter and Correlation between Events and Sentiment', 'positives': ['Maximizing text-mining performance'], 'negatives': ['Evaluation of vehicle fleet maintenance management indicators by application of DEMATEL and ANP'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Opinion Mining and Sentiment Polarity on Twitter and Correlation between Events and Sentiment', 'positives': ['SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining'], 'negatives': ['NAD(+) administration decreases doxorubicin-induced liver damage of mice by enhancing antioxidation capacity and decreasing DNA damage.'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Opinion Mining and Sentiment Polarity on Twitter and Correlation between Events and Sentiment', 'positives': ['Maximizing text-mining performance'], 'negatives': ['Spatial Compressive Sensing for MIMO Radar'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Opinion Mining and Sentiment Polarity on Twitter and Correlation between Events and Sentiment', 'positives': ['Techniques and applications for sentiment analysis'], 'negatives': ['Comparison of Different Global and Local Automatic Registration Schemes: An Application to Retinal Images'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks', 'positives': ['Generative Adversarial Nets'], 'negatives': ['Simplifying Neural Networks by Soft Weight-Sharing'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks', 'positives': ['AutoRec: Autoencoders Meet Collaborative Filtering'], 'negatives': ['Cellular toxicity of expanded RNA repeats: focus on RNA foci'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks', 'positives': ['Collaborative Filtering for Implicit Feedback Datasets'], 'negatives': ['ontology learning for the semantic web .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks', 'positives': ['Probabilistic Matrix Factorization'], 'negatives': ['Application of Convolutional Neural Networks to Language Identification in Noisy Conditions'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'CFGAN: A Generic Collaborative Filtering Framework based on Generative Adversarial Networks', 'positives': ['Compatibility Family Learning for Item Recommendation and Generation'], 'negatives': ['Lichen sclerosus of the oral mucosa: a case report'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Digital forensic text string searching: Improving information retrieval effectiveness by thematically clustering search results', 'positives': ['Machine learning in automated text categorization'], 'negatives': ['Automatic Indexing Based on Bayesian Inference Networks'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Digital forensic text string searching: Improving information retrieval effectiveness by thematically clustering search results', 'positives': ['Reexamining the cluster hypothesis: scatter/gather on retrieval results'], 'negatives': ['Investigating Ad Transparency Mechanisms in Social Media: A Case Study of Facebooks Explanations'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Digital forensic text string searching: Improving information retrieval effectiveness by thematically clustering search results', 'positives': ['Machine learning in automated text categorization'], 'negatives': ['robotics , vision and control - fundamental algorithms in matlab® .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Digital forensic text string searching: Improving information retrieval effectiveness by thematically clustering search results', 'positives': ['Machine learning in automated text categorization'], 'negatives': ['A Study of Various Attacks and Intrusion Detection System in Cloud'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Digital forensic text string searching: Improving information retrieval effectiveness by thematically clustering search results', 'positives': ['Machine learning in automated text categorization'], 'negatives': ['A Procedure for Placement of Standard-Cell VLSI Circuits'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Exploring the Impacts of Web-Based e-Procurement on Organizational Performance', 'positives': [\"time flies when you ' re having fun : cognitive absorption and beliefs about information technology usage .\"], 'negatives': ['marketing in hypermedia computer - mediated environment : conceptual foundations .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Exploring the Impacts of Web-Based e-Procurement on Organizational Performance', 'positives': [\"time flies when you ' re having fun : cognitive absorption and beliefs about information technology usage .\"], 'negatives': ['Deep Graph Translation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Exploring the Impacts of Web-Based e-Procurement on Organizational Performance', 'positives': [\"time flies when you ' re having fun : cognitive absorption and beliefs about information technology usage .\"], 'negatives': ['Pathogenic CD4 + T cells in patients with asthma'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Exploring the Impacts of Web-Based e-Procurement on Organizational Performance', 'positives': ['moving procurement systems to the internet : the adoption and use of e - procurement technology models .'], 'negatives': ['Artificial Neural Networks: A Tutorial'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Exploring the Impacts of Web-Based e-Procurement on Organizational Performance', 'positives': [\"time flies when you ' re having fun : cognitive absorption and beliefs about information technology usage .\"], 'negatives': ['Real-Time Grading Evaluation of Quality of Strokes in Chinese Characters Handwriting'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays', 'positives': ['The metaDESK: models and prototypes for tangible user interfaces'], 'negatives': ['Bricks: laying the foundations for graspable user interfaces'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays', 'positives': ['Interacting with paper on the DigitalDesk'], 'negatives': ['Image unprojection for 3D surface reconstruction: A triangulation-based approach'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays', 'positives': ['SmartSkin: an infrastructure for freehand manipulation on interactive surfaces'], 'negatives': ['Predicting Sales Prices of the Houses Using Regression Methods of Machine Learning'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays', 'positives': ['SmartSkin: an infrastructure for freehand manipulation on interactive surfaces'], 'negatives': ['A Wideband Differential-Fed Dual-Polarized Microstrip Antenna Under Radiation of Dual Improved Odd-Order Resonant Modes'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Multi-finger and whole hand gestural interaction techniques for multi-user tabletop displays', 'positives': ['Interacting with paper on the DigitalDesk'], 'negatives': ['Generating Dialogue Agents via Automated Planning'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Detecting pedestrians and vehicles in traffic scene based on boosted HOG features and SVM', 'positives': ['Object Detection with Discriminatively Trained Part-Based Models'], 'negatives': ['Rapid object detection using a boosted cascade of simple features'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Detecting pedestrians and vehicles in traffic scene based on boosted HOG features and SVM', 'positives': ['Object Detection with Discriminatively Trained Part-Based Models'], 'negatives': ['Image Distortion Detection Using Convolutional Neural Network'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Detecting pedestrians and vehicles in traffic scene based on boosted HOG features and SVM', 'positives': ['Monocular Pedestrian Detection: Survey and Experiments'], 'negatives': ['homeplug 1 . 0 powerline communication lans - protocol description and performance results .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Detecting pedestrians and vehicles in traffic scene based on boosted HOG features and SVM', 'positives': ['Monocular Pedestrian Detection: Survey and Experiments'], 'negatives': ['synthesis of boron - containing primary amines .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Detecting pedestrians and vehicles in traffic scene based on boosted HOG features and SVM', 'positives': ['Fast Human Detection Using a Cascade of Histograms of Oriented Gradients'], 'negatives': ['Real-time global illumination using precomputed light field probes'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Full-range adaptive cruise control based on supervised adaptive dynamic programming', 'positives': ['A three-network architecture for on-line learning and optimization based on adaptive dynamic programming'], 'negatives': ['Dynamic Programming'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Full-range adaptive cruise control based on supervised adaptive dynamic programming', 'positives': ['A three-network architecture for on-line learning and optimization based on adaptive dynamic programming'], 'negatives': ['Three New Probabilistic Models For Dependency Parsing: An Exploration'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Full-range adaptive cruise control based on supervised adaptive dynamic programming', 'positives': ['A three-network architecture for on-line learning and optimization based on adaptive dynamic programming'], 'negatives': ['Application of LQ-based semi-active suspension control in a vehicle'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Full-range adaptive cruise control based on supervised adaptive dynamic programming', 'positives': ['A three-network architecture for on-line learning and optimization based on adaptive dynamic programming'], 'negatives': ['The Improved Algorithm of Edge Detection Based on Mathematics Morphology'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Full-range adaptive cruise control based on supervised adaptive dynamic programming', 'positives': ['A three-network architecture for on-line learning and optimization based on adaptive dynamic programming'], 'negatives': ['Emotional States Associated with Music: Classification, Prediction of Changes, and Consideration in Recommendation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Switched-capacitor regulator with digital feedback', 'positives': ['An ultra-low-power power management IC for energy-scavenged Wireless Sensor Nodes'], 'negatives': ['Performance limits of switched-capacitor DC-DC converters'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Switched-capacitor regulator with digital feedback', 'positives': ['Analysis and Optimization of Switched-Capacitor DC–DC Converters'], 'negatives': ['persuasive technology .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Switched-capacitor regulator with digital feedback', 'positives': ['Analysis and Optimization of Switched-Capacitor DC–DC Converters'], 'negatives': ['a wavelet tour of signal processing - the sparse way , 3rd edition .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Switched-capacitor regulator with digital feedback', 'positives': ['A New Digital Control Algorithm to Achieve Optimal Dynamic Performance in DC-to-DC Converters'], 'negatives': ['Understanding Graph Sampling Algorithms for Social Network Analysis'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Switched-capacitor regulator with digital feedback', 'positives': ['Analysis and Optimization of Switched-Capacitor DC–DC Converters'], 'negatives': ['Characterization of a laccase from a wood-feeding termite,Coptotermes formosanus'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Enhanced Computer Vision With Microsoft Kinect Sensor: A Review', 'positives': ['Faster and better: a machine learning approach to corner detection'], 'negatives': ['multiresolution gray - scale and rotation invariant texture classification with local binary patterns .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Enhanced Computer Vision With Microsoft Kinect Sensor: A Review', 'positives': ['invariant human action recognition using histograms of 3 d joints .'], 'negatives': ['Nutrient sensing and inflammation in metabolic diseases'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Enhanced Computer Vision With Microsoft Kinect Sensor: A Review', 'positives': ['CENTRIST: A Visual Descriptor for Scene Categorization'], 'negatives': ['Behavioral and Social Influences on Food Choice'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Enhanced Computer Vision With Microsoft Kinect Sensor: A Review', 'positives': ['Faster and better: a machine learning approach to corner detection'], 'negatives': ['Rule-Based Facial Makeup Recommendation System'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Enhanced Computer Vision With Microsoft Kinect Sensor: A Review', 'positives': ['A flexible new technique for camera calibration'], 'negatives': ['RFID Antennas for Body-Area Applications: From Wearables to Implants'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Using NLP for Enhancing Second Language Acquisition', 'positives': ['An NLP-based Reading Tool for Aiding Non-native English Readers'], 'negatives': ['WordNet: An Electronic Lexical Database'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Using NLP for Enhancing Second Language Acquisition', 'positives': ['common european framework of reference for languages : learning , teaching , assessment .'], 'negatives': ['The GSM/UMTS Phone Number Catcher'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Using NLP for Enhancing Second Language Acquisition', 'positives': ['An NLP-based Reading Tool for Aiding Non-native English Readers'], 'negatives': ['Design of a non invasive haptic feedback device for transradial myoelectric upper limb prosthesis'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Using NLP for Enhancing Second Language Acquisition', 'positives': ['common european framework of reference for languages : learning , teaching , assessment .'], 'negatives': ['ACCessory: password inference using accelerometers on smartphones'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Using NLP for Enhancing Second Language Acquisition', 'positives': ['An NLP-based Reading Tool for Aiding Non-native English Readers'], 'negatives': ['TABLES OF LINEAR CONGRUENTIAL GENERATORS OF DIFFERENT SIZES AND GOOD LATTICE STRUCTURE'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'DEAP: enabling nimbler evolutions', 'positives': ['Exploring Network Structure, Dynamics, and Function using NetworkX'], 'negatives': ['Evolution strategies – A comprehensive introduction'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'DEAP: enabling nimbler evolutions', 'positives': ['Genetic Programming: On the Programming of Computers by Means of Natural Selection'], 'negatives': ['Energy-aware traffic engineering in hybrid SDN/IP backbone networks'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'DEAP: enabling nimbler evolutions', 'positives': ['Genetic Programming: On the Programming of Computers by Means of Natural Selection'], 'negatives': ['Gate Injection Transistor (GIT)—A Normally-Off AlGaN/GaN Power Transistor Using Conductivity Modulation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'DEAP: enabling nimbler evolutions', 'positives': ['Exploring Network Structure, Dynamics, and Function using NetworkX'], 'negatives': ['RIPK1 Blocks Early Postnatal Lethality Mediated by Caspase-8 and RIPK3'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'DEAP: enabling nimbler evolutions', 'positives': ['DEAP: a python framework for evolutionary algorithms'], 'negatives': ['Scatter compensation for digital chest radiography using maximum likelihood expectation maximization.'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Smart Random Neural Network Controller for HVAC Using Cloud Computing Technology', 'positives': ['Internet of Things in Industries: A Survey'], 'negatives': ['Integration of Distributed Enterprise Applications: A Survey'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Smart Random Neural Network Controller for HVAC Using Cloud Computing Technology', 'positives': ['Internet of Things in Industries: A Survey'], 'negatives': ['Novel ultra-wideband discone antenna'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Smart Random Neural Network Controller for HVAC Using Cloud Computing Technology', 'positives': ['The Random Neural Network: A Survey'], 'negatives': ['Development of an Internet based prepaid energy meter'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Smart Random Neural Network Controller for HVAC Using Cloud Computing Technology', 'positives': ['Internet of Things in Industries: A Survey'], 'negatives': ['Evaluation of single cell oil (SCO) from a tropical marine yeast Yarrowia lipolytica NCIM 3589 as a potential feedstock for biodiesel'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Smart Random Neural Network Controller for HVAC Using Cloud Computing Technology', 'positives': ['The Random Neural Network: A Survey'], 'negatives': ['A new mathematical model for relative quantification in real-time RT-PCR'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Design and Development of an Infant Incubator for Controlling Multiple Parameters', 'positives': ['Smart Jacket Design for Neonatal Monitoring with Wearable Sensors'], 'negatives': ['New monitoring approach for Neonatal Intensive Care Unit'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Design and Development of an Infant Incubator for Controlling Multiple Parameters', 'positives': ['Smart Jacket Design for Neonatal Monitoring with Wearable Sensors'], 'negatives': ['Magnetic breakdown and Klein tunneling in a type-II Weyl semimetal'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Design and Development of an Infant Incubator for Controlling Multiple Parameters', 'positives': ['Smart Jacket Design for Neonatal Monitoring with Wearable Sensors'], 'negatives': ['Preprocessing DNS Log Data for Effective Data Mining'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Design and Development of an Infant Incubator for Controlling Multiple Parameters', 'positives': ['Smart Jacket Design for Neonatal Monitoring with Wearable Sensors'], 'negatives': ['light control of plasma membrane recruitment using the phy - pif system .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Design and Development of an Infant Incubator for Controlling Multiple Parameters', 'positives': ['Smart Jacket Design for Neonatal Monitoring with Wearable Sensors'], 'negatives': ['Detecting insurance claims fraud using machine learning techniques'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Instant tactile-audio map: enabling access to digital maps for people with visual impairment', 'positives': ['Use of the Hough transformation to detect lines and curves in pictures'], 'negatives': ['A Tutorial on Support Vector Machines for Pattern Recognition'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Instant tactile-audio map: enabling access to digital maps for people with visual impairment', 'positives': ['Use of the Hough transformation to detect lines and curves in pictures'], 'negatives': ['Decentralized active gate control for current balancing of parallel connected IGBT modules'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Instant tactile-audio map: enabling access to digital maps for people with visual impairment', 'positives': ['Texture-based approach for text detection in images using support vector machines and continuously adaptive mean shift algorithm'], 'negatives': ['Predicting penile size during erection'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Instant tactile-audio map: enabling access to digital maps for people with visual impairment', 'positives': ['Texture-based approach for text detection in images using support vector machines and continuously adaptive mean shift algorithm'], 'negatives': ['Avoiding revascularization with lifestyle changes: the multicenter lifestyle demonstration project'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Instant tactile-audio map: enabling access to digital maps for people with visual impairment', 'positives': ['Use of the Hough transformation to detect lines and curves in pictures'], 'negatives': ['Machine Learning for Structured Clinical Data'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Radar interferogram filtering for geophysical applications', 'positives': ['Accuracy of Topographic Maps Derived from ERS-1 Interferometric Radar'], 'negatives': ['interferometric radar measurement of ocean surface currents .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Radar interferogram filtering for geophysical applications', 'positives': ['Decorrelation in Interferometric Radar Echoes'], 'negatives': ['Being in the zone: Flow state and the underlying neural dynamics in video game playing'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Radar interferogram filtering for geophysical applications', 'positives': ['Decorrelation in Interferometric Radar Echoes'], 'negatives': ['Determinants of ERP implementation knowledge transfer'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Radar interferogram filtering for geophysical applications', 'positives': ['Decorrelation in Interferometric Radar Echoes'], 'negatives': ['Deep Graph Translation'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Radar interferogram filtering for geophysical applications', 'positives': ['Accuracy of Topographic Maps Derived from ERS-1 Interferometric Radar'], 'negatives': ['Pathogenic CD4 + T cells in patients with asthma'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'AMES-Cloud: A Framework of Adaptive Mobile Video Streaming and Efficient Social Video Sharing in the Clouds', 'positives': ['Video interactions in online video social networks'], 'negatives': ['A few chirps about twitter'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'AMES-Cloud: A Framework of Adaptive Mobile Video Streaming and Efficient Social Video Sharing in the Clouds', 'positives': ['An experimental evaluation of rate-adaptation algorithms in adaptive streaming over HTTP'], 'negatives': ['Rotational Subgroup Voting and Pose Clustering for Robust 3D Object Recognition'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'AMES-Cloud: A Framework of Adaptive Mobile Video Streaming and Efficient Social Video Sharing in the Clouds', 'positives': ['An experimental evaluation of rate-adaptation algorithms in adaptive streaming over HTTP'], 'negatives': ['Deep Mul Timodal Learning for Emotion Recognition in Spoken Language'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'AMES-Cloud: A Framework of Adaptive Mobile Video Streaming and Efficient Social Video Sharing in the Clouds', 'positives': ['Online optimization for scheduling preemptable tasks on IaaS cloud systems'], 'negatives': ['modeling age progression in young faces .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'AMES-Cloud: A Framework of Adaptive Mobile Video Streaming and Efficient Social Video Sharing in the Clouds', 'positives': ['Online optimization for scheduling preemptable tasks on IaaS cloud systems'], 'negatives': ['Accelerometer-based control of an industrial robotic arm'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Simulation of supraharmonics: A Compact Fluorescent Lamp (CFL) in single operation', 'positives': ['Filter for the measurement of supraharmonics in public low voltage networks'], 'negatives': ['A review of the harmonic and unbalance effects in electrical distribution networks due to EV charging'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Simulation of supraharmonics: A Compact Fluorescent Lamp (CFL) in single operation', 'positives': ['Harmonic and supraharmonic emission of on-board electric vehicle chargers'], 'negatives': ['The relationships between organisational citizenship behaviour, job satisfaction and turnover intention.'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Simulation of supraharmonics: A Compact Fluorescent Lamp (CFL) in single operation', 'positives': ['Harmonic and supraharmonic emission of on-board electric vehicle chargers'], 'negatives': ['reflex profile of children with down syndrome improvement of neurosensorimotor development using the mnri ® reflex integration program .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Simulation of supraharmonics: A Compact Fluorescent Lamp (CFL) in single operation', 'positives': ['Filter for the measurement of supraharmonics in public low voltage networks'], 'negatives': ['From junior to senior Pinocchio: A cross-sectional lifespan investigation of deception'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'Simulation of supraharmonics: A Compact Fluorescent Lamp (CFL) in single operation', 'positives': ['Filter for the measurement of supraharmonics in public low voltage networks'], 'negatives': [\"improving sponsor ' s experience in reward - based crowdfunding : a psychological ownership perspective .\"], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ADMM for harmonic retrieval from one-bit sampling with time-varying thresholds', 'positives': ['1-Bit compressive sensing'], 'negatives': ['Single tone parameter estimation from discrete-time observations'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ADMM for harmonic retrieval from one-bit sampling with time-varying thresholds', 'positives': ['Signal Parameter Estimation Using 1-Bit Dithered Quantization'], 'negatives': ['a web crawler design for data mining .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ADMM for harmonic retrieval from one-bit sampling with time-varying thresholds', 'positives': ['1-Bit compressive sensing'], 'negatives': ['Natural Language Generation in Interactive Systems'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ADMM for harmonic retrieval from one-bit sampling with time-varying thresholds', 'positives': ['Signal Parameter Estimation Using 1-Bit Dithered Quantization'], 'negatives': ['PyMT: a post-WIMP multi-touch user interface toolkit'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'ADMM for harmonic retrieval from one-bit sampling with time-varying thresholds', 'positives': ['1-Bit compressive sensing'], 'negatives': ['Mobile Computing: Data Management Issues'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'management of scientific images : an approach to the extraction , annotation and retrieval of figures in the field of high energy physics .', 'positives': ['A theory for multiresolution signal decomposition: the wavelet representation'], 'negatives': ['LOGIC, PROGRAMMING AND PROLOG (2ED)'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'management of scientific images : an approach to the extraction , annotation and retrieval of figures in the field of high energy physics .', 'positives': ['Semantic Similarity in Biomedical Ontologies'], 'negatives': ['Hybridity in Cultural Globalization'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'management of scientific images : an approach to the extraction , annotation and retrieval of figures in the field of high energy physics .', 'positives': ['A theory for multiresolution signal decomposition: the wavelet representation'], 'negatives': ['Automatic Image Colorization via Multimodal Predictions'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'management of scientific images : an approach to the extraction , annotation and retrieval of figures in the field of high energy physics .', 'positives': ['A theory for multiresolution signal decomposition: the wavelet representation'], 'negatives': ['Q-Learning-Based Power Control for LTE Enterprise Femtocell Networks'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'management of scientific images : an approach to the extraction , annotation and retrieval of figures in the field of high energy physics .', 'positives': ['A theory for multiresolution signal decomposition: the wavelet representation'], 'negatives': ['Dynamic query optimization in Rdb/VMS'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A unified distance measurement for orientation coding in palmprint verification', 'positives': ['Palmprint identification using feature-level fusion'], 'negatives': ['How iris recognition works'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A unified distance measurement for orientation coding in palmprint verification', 'positives': ['Palmprint identification using feature-level fusion'], 'negatives': ['Learning Structured Representation for Text Classification via Reinforcement Learning'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A unified distance measurement for orientation coding in palmprint verification', 'positives': ['Palmprint identification using feature-level fusion'], 'negatives': [\"blockchain technologies from the consumers ' perspective : what is there and why should who care ? .\"], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'A unified distance measurement for orientation coding in palmprint verification', 'positives': ['Palmprint identification using feature-level fusion'], 'negatives': ['9 self - conscious emotions : where self and emotion meet .'], 'type': 'sts_triplet', 'source_id': 3}\n",
            "{'query': 'When Blanchard later this year donated his farmland to the college , Warren L. Wheaton named the school after him and it was known as Wheaton College .', 'positives': ['When Warren L. Wheaton donated his farmland to the college later that year , Blanchard renamed the school after him and it became known as Wheaton College .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'After Rovers eliminated the Israelis the next round draw saw Juventus F.C .', 'positives': ['After Rovers the Israelis saw the next round eliminated Remis Juventus F.C .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The reconstruction projects were officially approved by the parliament , so the navy `` Prince Eugen '' and her sister ships were routinely rebuilt .\", 'positives': [\"Reconstruction projects were routinely approved by the parliament , so the navy officially `` rebuilt `` Prinz Eugen '' and her sister ships .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'She was temporarily engaged with the author Alexander Roda Roda , who also integrated the experience of his writing .', 'positives': ['She was also engaged with the author Alexander Roda Roda , who temporarily integrated the experience in his writing .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Allison was the architectural firm of James Edward Allison ( 1870-1955 ) and his brother David Clark Allison ( 1881-1962 ) .', 'positives': ['Allison & Allison was the architectural firm of David Clark Allison ( 1870-1955 ) , and his brother James Edward Allison ( 1881-1962 ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The first thing you learn in racing is to complete a race , first you have to win .', 'positives': ['The first thing you learn in racing is to win a race , first you have to end .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Reginald Owen was a pseudonym used by John Ramsey .', 'positives': ['Reginald Owen used a pseudonym by John Ramsey .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The city of Otisfield , currently in Cumberland County , was a part of Oxford County until 1978 .', 'positives': ['The town of Otisfield , currently in Oxford County , was part of Cumberland County until 1978 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Cheetham was born on January 30 , 1928 in Taos , New Mexico , grew up in El Paso , Texas , and received B.S .', 'positives': ['Born in Taos , New Mexico , January 30 , 1928 , Cheetham grew up in El Paso , Texas , received B.S .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Robert Maass was born in East Orange , New Jersey , to German immigrants Hedwig and Clara Maass .', 'positives': ['Robert Maass was born in East Orange , New Jersey , to Hedwig and Clara Maass , German immigrants .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Bruno Simma was in the case of LaGrand assistant to Paulus .', 'positives': ['Bruno Simma was an assistant to Paulus in the LaGrand case .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'For Paul Cavanagh also doubled .', 'positives': ['Nelson also doubled for Paul Cavanagh .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'This concept of visual ( subjective ) direction is very old .', 'positives': ['This concept of the ( visual ) subjective direction is very old .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'It is important for reaching the thermal regime of the quantum oscillator , where mechanical noise effects on the device become negligible .', 'positives': ['It is important to reach the quantum regime of the mechanical oscillator , where thermal noise effects become negligible on the device .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He worked as a school teacher in Tielt , between 1693 and 1717 , in Bruges .', 'positives': ['He worked in Tielt between 1693 and 1717 as a teacher in Bruges .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Born and raised in Briarcliff Manor , Tom Ortenberg , Managing Director of Open Road Films , was born and former President of Lionsgate Films .', 'positives': ['Tom Ortenberg , CEO of Open Road Films and former president of Lionsgate Films , was born and raised in Briarcliff Manor .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` Duke of Roxburgh '' sailed again from Gravesend on 31 October 1846 and arrived at Port Phillip on 7 March 1847 .\", 'positives': ['On 31 October 1846 , Duke of Roxburgh `` sailed again from Port Phillip and reached Gravesend on 7 March 1847 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The station was opened on May 1 , 1934 on the Finn valley - railway line from Strabane to Stranorlar .', 'positives': ['The station was opened on 1 May 1934 on the Stranorlar line from Strabane to Finn Valley Railway .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'After the purchase in 1948 by the son of Hew Lorimer , the sculptor Robert Lorimer , this later became the permanent family home .', 'positives': ['After the purchase in 1948 by the son of Robert Lorimer , the sculptor Hew Lorimer , this later became a permanent family home .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The Burman : His Life and Notions ( 1882 ) is a book about the peoples and customs of Burma ( now Myanmar ) .', 'positives': ['Burman : His life and ideas ( 1882 ) is a book about the peoples and customs of Myanmar ( now Burma ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': '1 was written by Ryan Sohmer , coloured by Lar deSouza , and drawn by Marc Brunet .', 'positives': ['1 was written by Ryan Sohmer , drawn by Lar deSouza and colored by Marc Brunet .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Lex Luthor was also replaced as Scott Wells by Sherman Howard .', 'positives': ['Lex Lex Luthor was also replaced by Sherman Howard as Scott Wells .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The auxiliary service of the Archdiocese of Naples is Cardinal Crescenzio Sepe , Lucio Lemmo and Gennaro Acampa are currently ordinary .', 'positives': ['The auxiliary of the Archdiocese of Naples is Cardinal Crescenzio Sepe . Lucio Lemmo and Gennaro Acampa are current ordinary .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In the circulated materials such as the Red Bus Airplay Calculation , EMI is still referred as Gold Label Entertainment .', 'positives': ['EMI is still called Gold Label Entertainment in the circulated materials such as the Red Bus Airplay calculation .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In his letter to Christofias , Menendez stated `` you can not claim human rights violations by Turkey in your country and then ignore such violations in Cuba .', 'positives': ['In his letter to Christofias Menendez stated : `` You can not ignore human rights violations by Turkey in your country and then claim such injuries in Cuba .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Brett Mahoney is a recurring figure in the Netflix shows at Marvel Cinematic Universe , where he is portrayed by Royce Johnson .', 'positives': [\"Brett Mahoney is a recurring character in the Marvel Cinematic Universe 's Netflix shows , where he is portrayed by Royce Johnson .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Also , use the codice 6 attribute to mark the elements codice 13 as non-translatable .', 'positives': ['Also , use the codice 13 attribute to mark the codice 6 elements as non-translatable .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Winner of the tournament Dominika Cibulková won in the final Petra Kvitová , 6 -- 4 , 6 -- 1 .', 'positives': ['The finals won Petra Kvitová in the final , Dominika Cibulková , 6 -- 4 , 6 -- 1 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Collins refers to Davey in his `` Hells Gates '' book .\", 'positives': [\"Collins refers in his book `` Hells Gates '' to Davey .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Johnson wrote the texts for the songs by Girish Puthenchery composed .', 'positives': ['Girish Puthenchery wrote the lyrics for the songs composed by Johnson .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"It is the second entry in the series , the first being `` Fast Racing League '' released on WiiWare for the Wii in 2011 .\", 'positives': [\"It 's the second entry in the series , the first is published `` Fast Racing League '' on WiiWare in 2011 for the Wii .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Olivella alba is a species of small sea snail , marine gastropod mollusk in the family Olivellidae , the dwarf olives .', 'positives': ['Olivella alba is a kind of dwarf - sea snail , small gastropod mollusk in the Olivellidae family , the marine olives .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He has a son , Seamus , who is seen , but is never mentioned in the series .', 'positives': ['He has a son , Seamus , who is mentioned but was never seen in the series .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Lars Ankerstjerne has written as songwriter for Nik 'Jay , Burhan G and Rasmus Seebach songs .\", 'positives': ['As a songwriter , Rasmus Seebach has written songs for Nik & Jay , Burhan G and Lars Ankerstjerne .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He died on 24 August 1878 in Wyandotte ( now part of Kansas City ) , Kansas .', 'positives': ['He died in Wyandotte ( now a part of Kansas City ) , Kansas , August 24 , 1878 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Rostamabad ( also Romanized as Rostamābād ) is a village in Damavand County , Tehran Province , in the Jamabrud Rural District of Central District , Iran .', 'positives': ['Rostamabad ( also romanized as Rostamābād ) is a village in Jamabrud County , in the central district of Damavand , Tehran , Iran .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Jalan Padang Temu ( Malaysia state route M100 ) is a major road in Malacca state , Malacca', 'positives': ['Jalan Padang Temu ( Malaysia State Route M100 ) is a major road in Malacca , Malacca , Malacca .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Although A.A. Gill was '' critical in `` The Observer and Andrew Anthony of '' The Sunday Times '' was unimpressed .\", 'positives': [\"Although A.A. Gill in `` The Observer '' was more critical and Andrew Anthony of `` The Sunday Times '' was unimpressed .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The present ( from 2013 to 2017 ) Mayor is Fernando Nogueira , elected by the PenCe ( independent movement ) . The municipal holiday is October 1 .', 'positives': ['The current mayor ( from 2013 to 2017 ) is Fernando Nogueira , elected by the PenCe ( municipal movement ) , the independent holiday is October 1 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"In 1989 he won posthumously the `` Personal Outstanding Contribution to the Radio '' of Broadcasting Press Guild .\", 'positives': ['In 1989 he posthumously won the Outstanding Personal Contribution to Radio award from the Broadcasting Press Guild .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The politician and entrepreneur Kuno Pajula ( 1885 -- 1942 ) and former Archbishop Juhan Kukk ( 1924 -- 2012 ) were born in Käru .', 'positives': ['Politician and entrepreneur Juhan Kukk ( 1885 - 1942 ) and former Archbishop Kuno Pajula ( 1924 -- 2012 ) were born in Käru .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'More special buildings had important names and their signs were larger and decorative .', 'positives': ['More important buildings had special names and their signs were larger and more decorative .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The hall was the site of the state funeral of the official leader of the federal opposition and NDP leader Jack Layton on August 27 , 2011 .', 'positives': ['The hall was the scene of the state funeral of the federal leader of the official opposition and the NDP leader Jack Layton on 27 August 2011 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Polish gradually replaced German , since the Baltic - German language and the establishment of voivodeships reduced the administrative administration .', 'positives': ['Polish gradually replaced German as the Baltic German language and the establishment of voivodeships reduced the administrative administration .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Elliot Richardson defeated Edward Brooke in the Primary Republican Association .', 'positives': ['Elliot Richardson defeated Edward Brooke in the Republican Primary .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Neuqua Valley High School , along with three primary schools and 19 secondary schools from this district , are within Naperville city limits in the southern part .', 'positives': ['Neuqua Valley High School , along with three elementary schools and 19 middle schools from this district , are within Naperville city limits in the southern part .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The Berkeley edition was published in February 1985 and the second print was in June 1985 and the third was in November 1985 .', 'positives': ['The Berkeley edition was published in February 1985 , the second printing was in June 1985 , and the third printing was in November 1985 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` Bastille Day '' is the third episode of the first season of the reimagined `` Battlestar Galactica '' television series .\", 'positives': [\"`` Bastille Day '' is the third episode of the first season of the reworked `` Battlestar Galactica '' series .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Iowa State has won eight titles , and Oklahoma and Penn State have won seven championships each .', 'positives': ['The state has won eight titles , and both Oklahoma and Iowa State have won seven championships each .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In 1962 , further restoration was carried out for John Bradburne , who had appointed the poet and mystic William Cardinal Godfrey as caretaker .', 'positives': ['Further restoration was carried out in 1962 for John Bradburne , who had earlier appointed the poet and mystic William Cardinal Godfrey to be caretaker .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Ravi Singh was born in Delhi , India , to Mr. Puran Singh and to Smt .', 'positives': ['Puran Singh was born in Delhi , India , to Mr. Ravi Singh and to Smt .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'New exhibitions are planned in Southampton ( 2016 ) , Bow ( 2017 ) and Southend ( 2017 ) .', 'positives': ['In Southend ( 2016 ) , Bow ( 2017 ) and Southampton ( 2017 ) , new exhibitions are planned .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Until Sonny 's retirement in 2003 , Mosley worked with the Osborne Brothers , and by 2011 with Bobby Osborne and his band Rocky Top Express .\", 'positives': [\"Bobby Osborne worked with the Osborne Brothers until Mosley 's retirement in 2003 and with Sonny and his band , the Rocky Top Express , until 2011 .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'It is well known as the place where Friedrich Schiller worked on the second act of Don Carlos and wrote his first edition of the famous Ode to Joy .', 'positives': ['It is known as the place where Friedrich Schiller worked on the second act of Don Carlos and wrote his first edition of the famous Ode to Joy .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The zone serves eastern & central Madhya Pradesh , southern Uttar Pradesh , and northeastern Rajasthan state .', 'positives': ['The zone serves eastern and central Madhya Pradesh , southern Rajasthan and northeastern Uttar Pradesh state .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The Plot was a heavy rock band founded in 2003 by the bassist Pete Way and his long-time friend , the guitarist Michael Schenker .', 'positives': ['The Plot was a heavy rock band formed in 2003 by bassist Michael Schenker and his long-time friend , guitarist Pete Way .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The district of Waitaki , in the regions of Canterbury and Otago in New Zealand , stretches the traditional border between the two regions , the Waitaki River .', 'positives': ['The Waitaki district , in the Canterbury and Otago regions of New Zealand , straddles the traditional border between the two regions , the Waitaki River .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Stone Cold Steve Austin appeared and hit Triple H , Patterson , Brisco , Shane and Vince with a chair .', 'positives': ['Patterson appeared and beat Triple H , stone cold Steve Austin , Brisco , Vince and Shane with a chair .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'From 1993 to 2001 , Huntsman worked as an executive for Huntsman Corporation , Chairman of the Huntsman Family Holdings Company and CEO of the Huntsman Cancer Foundation .', 'positives': ['From 1993 to 2001 , Huntsman served as an executive for the Huntsman Corporation , chairman of the Huntsman Family Holdings Company , and CEO of Huntsman Cancer Foundation .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Bennett was previously in a relationship with fellow wrestler Victoria Crawford , better known as Alicia Fox .', 'positives': ['Previously , Bennett was in a relationship with wrestler Victoria Crawford , better known as Alicia Fox .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Khun Wichitmatra wrote the lyrics of the Thai National Anthem in 1934 , two years after the anthem was first written by Chan Kamwilai .', 'positives': ['In 1934 , Khun Wichitmatra wrote the texts of the Thai national anthem , two years after the anthem was written by Chan Kamwilai .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The three patrol districts Center City serves are the 6th , 9th and 17th districts .', 'positives': ['The three patrols - districts serving Center City are the 17th , 9th and 6th districts .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Among the musicians of the recording session on March 7th were Larry Knechtel ( drums ) , Hal Blaine ( guitar ) , Don Randi ( bass ) and Al Casey ( piano ) .', 'positives': ['Hal Blaine ( drums ) , Al Casey ( guitar ) , Larry Knechtel ( bass ) and Don Randi ( piano ) were among the musicians of the recording session on 7 March .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Devnya is also the seat of the municipality of Devnya ( part of the province of Varna ) , which includes the following 2 villages :', 'positives': ['Varna Province is also the seat of Devnya municipality ( part of Devnya ) , which includes the following 2 villages :'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He died on February 20 , 1930 in Albany , New York . He was buried at the Glenwood Cemetery in Oneida .', 'positives': ['He died in Albany , New York on February 20 , 1930 , and was buried at the Glenwood Cemetery in Oneida .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` The Evolution of Dance '' is the second interlude and the ninth track for the album .\", 'positives': [\"`` The Evolution of Dance '' is the ninth interlude and the second track on the album .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Magnus turned around and reformed the British invasion of Williams by attacking the Eric Young and Orlando Jordan team .', 'positives': ['Williams turned the heel and reformed the British invasion with Magnus by attacking the Eric Young and Orlando Jordan team .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Quetzalcoatl 's father Mixcoatl was assassinated , Quetzalcoatl was informed by Cozcaquauhtli that `` the uncles who had killed his father were Apanecatl , Zolton , and Cuilton .\", 'positives': [\"Quetzalcoatl 's father Zolton was murdered , Quetzalcoatl was informed by Cozcaquauhtli that `` the uncles who had killed his father , Apanecatl , Mixcoatl and Cuilton were '' .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Károli started his school years in Brassó and closed in Nagykároly , in 1556 he went to the Wittenberg Academy and ordered the Synod of Gönc in 1566 .', 'positives': ['Károli started his school in Nagykároly and closed it in Brassó , in 1556 he went to the Wittenberg Academy , in 1566 he ordered the Synod of Gönc .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"From 1973 to 1974 , Aguecheek toured with the Cambridge Theatre Company as Diggory in `` She Stoops to Conquer '' and again as Aubrey .\", 'positives': [\"From 1973 to 1974 Aguecheek toured with the Cambridge Theatre Company as a diggory in `` She Stoops to Conquer '' and again as Aubrey .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The terrain of the West Bank is somewhat rugged highlands with some vegetation in the west , but in the east is mostly barren .', 'positives': ['The terrain of the West Bank is somewhat rugged dissected upland with some vegetation in the west , but mostly barren in the east .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` Gynacantha rosenbergi '' appears greater than `` Gynacantha dobsoni '' , which is quite similar in many ways .\", 'positives': [\"`` Gynacantha rosenbergi '' is larger than `` Gynacantha dobsoni '' , which in many ways appears quite similar .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Fritz Heider wrote that people tend to view behavior in one of two ways ; the cause of dispositional factors or of situational factors .', 'positives': ['Fritz Fritz Heider wrote that people tend to regard behavior in one of two ways : the cause of dispositional factors or of situational factors .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'She operated San Pedro Bay on the 28th and arrived for more than 2 months before Leyte .', 'positives': ['She operated San Pedro Bay the 28th and arrived off Leyte for more than 2 months .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In 2015 , Stephen Hawking offered Richard Branson a seat on the Virgin Galactic spaceship for free .', 'positives': ['In 2015 , Stephen Hawking offered Richard Branson a seat free of charge on the Virgin Galactic spaceship .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Instead , the philosophy is seen as an activity of defining and clarifying the empirical relationships of logical rates .', 'positives': ['Instead , philosophy is seen as an activity of defining and clarifying the logical relationships of empirical propositions .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'It was reported in June that Burke had signed a record contract with Syco and the album will be processed jointly by RCA Records and RCA Records .', 'positives': ['It was reported in June that Burke has signed a record contract with RCA Records and the album will be handled jointly by Syco and RCA Records .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He attacked the Goan areas and forced them back to the Portuguese coast .', 'positives': ['He attacked the Goan territories and forced them back to the Portuguese coast .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Kelley began having regular one-man exhibitions at Metro Pictures Gallery in Manhattan in 1982 , and at Rosamund Felsen Gallery in Los Angeles the following year .', 'positives': ['In 1982 , Kelley began regular solo exhibitions at the Metro Pictures Gallery in Manhattan and the following year at the Rosamund Felsen Gallery in Los Angeles .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` r '' is the periodic rate , `` i '' the annual rate and `` n '' the number of compounding periods per year .\", 'positives': [\"Where `` r '' the annual rate , `` i '' is the periodic rate and `` n '' the number of connection periods per year .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In 1858 he moved with a group of four members from Nevada to Downieville to the area which is now known as Eagle Valley .', 'positives': ['In 1858 he moved with a group of four members from Downieville to Eagle Valley in the area which today is known as Nevada .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Under King Louis Phillippe , a `` Gendarmerie Africa '' was created for the service in Algeria and during the Second Empire the Gendarmerie - Regiment of the Imperial Guard was rebuilt .\", 'positives': [\"Under King Louis Phillippe , a `` Gendarmerie Africa '' was restored to service in Algeria , and during the Second Empire the Gendarmerie - Regiment of the Imperial Guard was created .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` Little Boys '' is the third episode in the fourth season of the television series `` How I Met Your Mother '' and 48th overall .\", 'positives': [\"`` Little Boys '' is the fourth episode in the third season of the television series '' How I Met Your Mother '' and 48th total .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'This version of Hector Hammond is a xenobiology professor , an old friend of Hal Jordan and the son of United States senator Robert Hammond .', 'positives': ['This version of Robert Hammond is a xenobiologist - professor , an old friend of Hal Jordan and the son of Senator of the United States Hector Hammond .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'This occurs when the confidence associated with a non-professional relationship is destroyed because of non-professional actions or requirements for professional actions .', 'positives': ['This occurs when the trust associated with a non-professional relationship is destroyed because of non-professional actions or requests for professional actions .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The Soviet cosmonaut was Yuri Gagarin 's first air force pilot , also the first man in space .\", 'positives': ['The first cosmonaut was Soviet Air Force pilot Yuri Gagarin , also the first person in space .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"He supported John Barrymore in `` Maryland '' ( 1940 ) and Walter Brennan in `` The Great Profile '' ( 1940 ) .\", 'positives': [\"He is supporting Walter Brennan in `` Maryland '' ( 1940 ) and John Barrymore in `` The Great Profile '' ( 1940 ) .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'LaRoche was dismantled on 1 September after being recalled to Triple-A Las Vegas .', 'positives': ['LaRoche was recalled on 1 September after being degraded to Triple-A Las Vegas .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In 2004 the Parents Television Council revealed the FCC as the primary source of most content complaints received .', 'positives': ['In 2004 , the FCC revealed the Parents Television Council as the main source of most content complaints .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The consortium 's continuous mission is to create technical jobs and disperse skills that will contribute to the Canadian economy by focusing on innovation and productivity .\", 'positives': [\"The Consortium 's technical mission is to create continuous jobs and distribute skills that will contribute to the Canadian economy by focusing on innovation and productivity .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'These places include Canada , Japan ( since 2012 ) , Spain , and some parts of the United States .', 'positives': ['These courses include Spain ( since 2012 ) , Canada , Japan and some parts of the United States .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He died on 18 June 1936 in Melbourne , Florida , and was buried in Daytona Beach , Florida .', 'positives': ['He died on 18 June 1936 in Daytona Beach , Florida , and was buried in Melbourne , Florida .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The `` Ruby Cup '' of the newspaper `` Molod Ukrayiny '' ( for most goals ) was reached by SKA Kiev .\", 'positives': [\"The `` Ruby Cup '' of the newspaper `` Molod Ukrayiny '' ( for most gates ) was received by SKA Kiev .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"He graduated from Harvard University in 1891 , and then received a master 's degree from MIT in 1893 .\", 'positives': [\"He graduated from Harvard University in 1893 and received a Master 's degree from MIT in 1891 .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The total energy binding per nucleon `` would be this value divided by '' A `` .\", 'positives': [\"The binding `` total energy per nucleon '' would be this value divided by `` A '' .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The fifth season was premiered on 15 September 2013 and the sixth season was premiered on April 10 , 2014 .', 'positives': ['The sixth season premiered on September 15 , 2013 . The fifth season premiered on April 10 , 2014 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'It is used as a measure of the absorbed dose , kinetic energy ( released ) and kerma ( an acronym for specific energy awarded per mass unit ) .', 'positives': ['It is used as a measure of absorbed dose , specific energy ( imparted ) , and kerma ( an acronym for kinetic energy released per unit mass ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'According to the United States Census Bureau , Irvine has a total area of which land and , or 5.13 % , is water .', 'positives': ['According to the United States Census Bureau , Irvine is a total surface area of which is land and , or 5.13 % , has water .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Thus , injective Abelian groups in the category of Abelian groups are divisible modules , and vice versa , every injective group ( baer - criterion ) is divisible .', 'positives': [\"Thus divisible groups are injective modules in the category of abelian groups , and conversely , every injective abelian group is divisible ( Baer 's criterion ) .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Callery is located in the southwestern corner of Adams Township in northwestern Butler County , at ( 40.739587 , -80.037211 ) .', 'positives': ['Callery is located in the southwestern corner of the Adams Township in northwest Butler County , at ( 40.739587 , -80.037211 ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The Island was named after the Reverend David Dunbar who came with Robert Rutherford 's group to the area from North Ireland , in 1729 .\", 'positives': [\"The Island was named after the reverend Robert Rutherford , who came to the region in 1729 with David Dunbar 's group from Northern Ireland .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Amata hyalota is a kind of moth of the family Erebidae It is found in Australia ( Queensland ) .', 'positives': ['Amata hyalota is a sort of moth of the family Erebidae It is found in Queensland ( Australia ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'She was selected in the 20th round of the 2012 WNBA Draft ( second total ) by Minnesota Lynx .', 'positives': ['It was selected in the second round of WNBA Draft 2012 ( 20th Overall ) by the Minnesota Lynx .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Ippolita Rostagno was born in Florence on December 10 , 1963 and is the daughter of an American artist and an Italian intellectual .', 'positives': ['Born December 10 , 1963 in Florence , Italy , Ippolita Rostagno is the daughter of an American artist and an Italian intellectual .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'A functional magnetic resonance imaging ( fMRT ) study showed that deaf participants use the visual cortex as well as the primary auditory cortex when they observe sign language .', 'positives': ['A functional magnetic resonance imaging ( fMRI ) study found that deaf participants use the visual cortex as well as the primary auditory cortex when they observe sign language .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Wayne Bennett took over from Chris Anderson as coach of the team in March 1999 .', 'positives': ['In March 1999 , Chris Anderson took over the succession of Wayne Bennett as team coach .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"In 1995 , Brown 's close friend Kris Jenner named her daughter Kendall Nicole Jenner in memory of Brown .\", 'positives': ['In 1995 , the close friend of Kendall Nicole Jenner , Kris Jenner , named her daughter Brown in memory of Brown .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` Encrinus '' was assigned in 1764 . It was described to the order Encrinida by Jack Sepkoski in 2002 .\", 'positives': ['was described in 1764 and was assigned by Jack Sepkoski in 2002 to the Encrinida order .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"In March 1799 Captain Boyle replaced David Lloyd , and sailed `` Hyaena '' for the Mediterranean on 4 March .\", 'positives': [\"In March 1799 , Captain Boyle David Lloyd replaced and sailed on 4 March with `` Hyaena '' after the Mediterranean .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'This marine species has been found from Bristol Bay , Bering Sea , to Monterey Bay , California , USA .', 'positives': ['This marine species was found from Monterey Bay , California , USA , to Bristol Bay , Bering Sea .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Burki started his career in Switzerland for a year , until he returned to Paris to work in rotogravure from 1971 to 1979 .', 'positives': ['He started his career for a year in Paris until he returned to Switzerland from 1971 to 1979 to work in gravure .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Another interpretation specifies Sicily separated from Naples , plus Jerusalem and Aragon .', 'positives': ['Another interpretation specifies Naples separate from Sicily , plus Jerusalem and Aragon .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Stenolechia squamifera is a moth of the Gelechiidae family . It is found in Kyushu , Tsushima Island ( Japan ) .', 'positives': ['Stenolechia squamifera is a moth from the family of gelechiidae found in Japan ( Kyushu , Tsushima Island ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The 1980 - 81 Toronto Maple Leafs season was the Toronto Maple Leafs 54th season of the franchise , 64th season as the Maple Leafs .', 'positives': ['The 1980-81 Toronto Maple Leafs season was the Toronto Maple Leafs 54th season of the franchise , season 64th as the Maple Leafs .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Eivind Saxlund was active in the Church of Norway and married to Asserson .', 'positives': ['Eivind Saxlund was active in the Church of Norway and was married to Asserson .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Defending race winner Bill Elliott won the pole for the second year in a row , and Geoffrey Bodine won the race .', 'positives': ['The defending race winner Geoffrey Bodine won the Pole for the second time in a row and Bill Elliott won the race .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` Point Blank 1.5 '' was published in Singapore and Malaysia in January 2014 , released by Garena .\", 'positives': [\"`` Point Blank 1.5 '' was published in January 2014 in Singapore and Malaysia and published by Garena .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Industrially , argon is generated by the fractional distillation of liquid air .', 'positives': ['Industrially , argon is produced by the liquid distillation of fractioned air .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Allen was born in Oldtown , Kentucky , visited the High School in Ashland and played at West Virginia University from 1932 to 1934 .', 'positives': ['Allen was born in Ashland , Kentucky , visited the High School in Oldtown and played at West Virginia University from 1932 to 1934 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Cicimli ( also , Cimcimli , Dzhidzhimli , Dzhidzhimli Pervyye , and Dzhidzhimli Vtorye ) is a village in the Azerbaijan of Lachin Rayon .', 'positives': ['Cicimli ( also Cimcimli , Dzhidzhimli , Dzhidzhimli Pervyye and Dzhidzhimli Vtorye ) is a village in Azerbaijan of the Rayon Lachin .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Colonel Seishirō Itagaki , Lieutenant Colonel Kanji Ishiwara , Colonel Kenji Doihara , and Major Takayoshi Tanaka had completed plans for the incident by 31 May 1931 .', 'positives': ['Until 31 May 1931 , Colonel Kenji Doihara , lieutenant colonel Kanji Ishiwara , Colonel Takayoshi Tanaka , and Major Seishiro had completed Itagaki plans for the incident .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Disputes with leaders of Lutesville persuaded the railroad to move their route through Marble Hill instead .', 'positives': ['Disputes with leaders of Lutesville persuaded the railroad to relocate their route through Marble Hill instead .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'One of Hathras ’ best and most prestigious schools is St Francis Inter College , Aligarh Road .', 'positives': ['St Francis Inter College , Hathras Road , is one of the best and most renowned schools in Aligarh .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"At 10 : 59 , the last element of 2nd Battalion 4th Marines left the zone and the last marine helicopter landed on the USS `` Okinawa '' at 12 : 15 .\", 'positives': [\"At 10 : 59 AM the last ship element of the 2nd Battalion 4th Marines left the zone and the last helicopter landed at 12 : 15 on the USS `` Okinawa '' .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'She approaches Lance Smart ( Peter Vroom ) , Martin Dibble ( Craig Thomson ) and Marilyn Chambers ( Emily Symons ) and they form a band named Image .', 'positives': ['She approaches Lance Smart ( Martin Dibble ) , Peter Vroom ( Craig Thomson ) and Marilyn Chambers ( Emily Symons ) and they found a band named Image .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'According to the Australian engineer Sharon Beder , the main advantages of marine processes are the discharge of wastewater :', 'positives': ['According to the marine engineer Sharon Beder the main advantages of Australian outfalls for the discharge of wastewater are :'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The series was written by Butch Guice by Ed Brubaker and illustrated by Bryan Hitch .', 'positives': ['The series was written by Ed Brubaker , illustrated by Bryan Hitch and colorized by Butch Guice .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'On 21 August , Olaf came from a warm south of Acapulco over extremely disturbed waters .', 'positives': ['Olaf originated from a warm south of Acapulco on August 21 over extremely disturbed waters .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"McClain was one of the pioneers in the introduction of `` Ragtime Minstrelsy '' , which opened a wider range of styles on the eve of the vaudevillized era .\", 'positives': [\"McClain was one of the pioneers in introducing `` vaudevillized minstrelsy '' , which opened a wider range of styles on the eve of the ragtime era .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Mr Payne has made the highest bid for Mr Cave 's goods at an auction .\", 'positives': [\"Mr Payne made the highest bid for Mr Cave 's goods at an auction .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The province of Puerto Inca is the largest of the eleven provinces in the Huánuco region in Peru .', 'positives': ['The Puerto Inca Province is the largest of eleven provinces of the Huánuco Region in Peru .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Angelica Panganiban ( Lizelle Jimenez ) is in new relationship with surgeon Adrian Benitez ( Gabby Concepcion ) .', 'positives': ['In a new relationship with surgeon Adrian Benitez ( Gabby Concepcion ) is Liz Lizene Jimenez ( Angelica Panganiban ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Nationalist parties , however , said , together with other liberal groups , that they would boycott the July elections .', 'positives': ['However , nationalist parties , together with other liberal groups said they would boycott the July elections .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In singles , King was 6 -- 1 against Ann Haydon-Jones , 4 -- 0 against Virginia Wade , and 1 -- 1 against Christine Truman Janes .', 'positives': ['King was against Ann Haydon-Jones , 4 -- 0 against Virginia Wade and 1 -- 1 against Christine Truman Janes at the singles with 6 -- 1 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Willa Cather is a short story by Peter , which was published in `` The Mahogany Tree '' in 1892 .\", 'positives': [\"Willa Cather is a short story by Peter . It was first published in `` The Mahogany Tree '' in 1892 .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Richland Township is a second class township and governs with a Home Rule Charter .', 'positives': ['Richland Township is a 2nd Class Township and governs with a Home Rule Charter .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Mouhoun is one of the 45 provinces of Boucle du Mouhoun Region and is in Burkina Faso . The capital of Mouhoun is Dédougou .', 'positives': ['Mouhoun is one of 45 provinces of the Boucle du Mouhoun region , located in Burkina Faso , the capital of Mouhoun is Dédougou .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The Shetland Islands of the central mainland are part of the mainland , between Hellister , Aith and Voe .', 'positives': ['The Shetland Islands of the Central Mainland is the part of the Mainland , between Hellister , Aith and Voe .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'General De Gaulle on the other hand was less impressed , dismissing her recommendations and only half reading most of her reports .', 'positives': ['On the other hand , General De Gaulle was less impressed , read her recommendations , and rejected most of her reports only half .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Fritz August Hoenig ( 1848 -- 1902 ) was a German officer and a military writer .', 'positives': ['Fritz August Hoenig ( 1848 -- 1902 ) was a military officer and German writer .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Edmund Butler ( died in 1551 ) was Archbishop of Cashel and the illegitimate son of Piers Butler , 8th Earl of Ormonde .', 'positives': ['Edmund Butler ( died 1551 ) was archbishop of Cashel and the illegitimate son of Piers Butler , 8th Earl of Ormonde .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'This way , assertions can be provided as a framework feature with the method Debug.Assert , which is only evaluated when the DEBUG constant is defined .', 'positives': ['This allows assertions to be provided with the Debug.Assert method as a framework feature , which is only evaluated when the DEBUG - Constant is defined .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The elevation of the island is , and it has a shoreline of length .', 'positives': ['The elevation of the island has , and it is a coastline of length .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In Lilongwe there are 38 private and 66 public primary schools with a total of 103,602 students , as well as 29 secondary schools with 30,795 students .', 'positives': ['In Lilongwe there are 38 public primary schools and 66 secondary schools with a total of 103,602 students , as well as 29 private schools with 30,795 students .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In the aftermath of Impact , Jesse Neal , Hall and Nash defeated Team 3D and Waltman in a Street Fight on April 12 .', 'positives': ['On the April 12 episode of Impact , Jesse Neal , Hall and Nash defeated Team 3D and Waltman in a Street Fight .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'All of these will have half the symmetry ( double the fundamental domain sizes ) of the regular apeirogon .', 'positives': ['All of these have half the symmetry ( double the fundamental domain size ) of the regular Apeirogon .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The Swiss Federal Council and the Swiss Federal Assembly recommended that the initiative be rejected .', 'positives': ['The Swiss Federal Assembly and the Swiss Federal Council have recommended that the initiative be rejected .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In Karnataka there are many Vithoba temples and some are in Andhra Pradesh , Tamil Nadu and Maharashtra .', 'positives': ['There are many Vithoba Temples in Maharashtra and some are in Karnataka , Tamil Nadu and Andhra Pradesh .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The region was followed by the Muslim house of Arakkal , ruled by Tipu Sultan .', 'positives': ['The region was then run by the Muslim house of Arakkal , followed by Tipu Sultan .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Steve Reicher ( Stephen D Reicher ) is a Professor of Social Psychology and former Head of the School of Psychology at the University of St Andrews .', 'positives': ['Stephen D Reicher ( Steve Reicher ) is a Professor of Social Psychology and former Head of School of Psychology at the University of St Andrews .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'When the Florentine Republic fell in 1530 , Volterra came under the control of the Medici family and later the history of the Grand Duchy of Tuscany .', 'positives': ['When the Florentine Republic came in 1530 , Volterra fell under the control of the Medici family and later followed the history of the Grand Duchy of Tuscany .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Kauhola Point Lighthouse was located near Kapa ' , au , on the `` Big Island '' of Hawaii , near the northern tip of the island .\", 'positives': [\"Kauhola Point Lighthouse was located near Kapa'au , on the `` Big Island '' of Hawaii , near the northern tip of the island .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'When Santa Anita Park was closed in 2014 , the race was transferred to Hollywood Park Racetrack .', 'positives': ['In 2014 when Hollywood Park Racetrack closed the race was moved to Santa Anita Park .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'There are two major special cases : ( i ) a simple open chain and ( ii ) a simple closed chain .', 'positives': ['There are two important special cases : ( i ) a simple closed chain and ( ii ) a simple chain open .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Brekeke Software , Inc. offers two versions of its Brekeke PBX software , single-tenant and Multi-Tenant version .', 'positives': ['Brekeke Software , Inc. offers two versions of its brekeke - PBX software , multi-tenant - tenant and single - version .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He died in New City ( now Clarkstown ) , New York , August 16 , 1850 .', 'positives': ['He died on August 16 , 1850 in Clarkstown ( now New City ) , New York City .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'It was released in 1991 by Island Records , produced by Steve Beresford , Andy Metcalfe and Philip Oakey and published by Universal Music by Spectrum Label in 1999 .', 'positives': [\"It was re-released in 1991 by Island Records , produced by Steve Beresford , Andy Metcalfe and Philip Oakey and released in 1999 by Universal Music 's Spectr\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Also in Peaches Christ ' ; s '' All About Evil `` with Cassandra Peterson , Mink Stole and Patrick Bristow appeared Brown Brown .\", 'positives': [\"Cassandra Peterson also appeared in `` All about the Evil '' of Peaches Christ with Patrick Bristow , Mink Stole and Brown .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In New South Wales , Narara Valley High School in Australia and Nossal High School in Victoria , the course was taught in their 2012 school year .', 'positives': ['In New South Wales , Narara Valley High School in Australia and Nossal High School in Victoria taught the course in their 2012 school year .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Born in Stockholm , Sweden in 1967 , she grew up in Madrid , Spain , in a trilingual ( English , Spanish and Swedish ) home .', 'positives': ['Born in 1967 in Madrid , Spain , grown up in Stockholm , Sweden , in a trilingual ( English , Spanish and Swedish ) home .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"According to this publication it was devoted to `` rural economy , internal improvements , news , prices current '' .\", 'positives': [\"According to that publication it was devoted to `` internal economy , rural improvements , news , prices current . ''\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'It is based on Ealing in Ealing Broadway , near the Uxbridge Road Station , London , the same address as Transworld .', 'positives': ['It is based on Uxbridge Road in Ealing near Ealing Broadway station , London , the same address as Transworld .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Williams also played Captain Hastings in several BBC Radio 4 adaptations of Hercule Poirot novels , starring John Moffatt as Agatha Christie .', 'positives': ['He also played in several BBC Radio 4 adaptations of Agatha Christie - novels with John Moffatt as Hercule Poirot Captain Hastings .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Dierker is also the first manager in MLB history to win a division championship in his sixth season for the Astros in 1997 .', 'positives': ['Dierker is also the first manager in the MLB story to win a division championship in 1997 in his sixth season for the Astros .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He was taught by the Croatian composer Vatroslav Lisinski music and later enrolled at the music school Rudolf Matz .', 'positives': ['He was enrolled in music lessons by the Croatian composer Rudolf Matz and later the Vatroslav Lisinski Music School .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'The first baseball team of the Syracuse Chiefs was founded in 1934 , when the Jersey City Skeeters were moved to Syracuse and renamed to Chiefs .', 'positives': ['The first baseball team of the Syracuse Chiefs was founded in 1934 , when the Jersey City Skeeters were moved to Syracuse and renamed to Chiefs .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The first newspaper was published in the state in 1781 , the weekly `` Vermont Gazette '' .\", 'positives': [\"The first newspaper was published in 1781 in the state , the weekly `` Vermont Gazette '' .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'On Monday , Louis Philippe visited the individual exhibits , as Napoleon had done .', 'positives': ['Napoleon visited the individual exhibits on Mondays , as Louis Philippe had done .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Defeated with Hirai , Kato escapes with Yukari .', 'positives': ['Defeated with Kato , Hirai escapes with Yukari .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He married Mary Ellen Blanche Crookes ( 1870-1935 ) , daughter and co-founder of Septimus Wilkinson Crookes and Anne Blanche Harriet Proctor in 1901 .', 'positives': ['He married in 1901 Anne Blanche Harriet Proctor ( 1870-1935 ) , daughter and coheiress of Septimus Wilkinson Crookes and Mary Ellen Blanche Crookes .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'After a two-year stint in Chicago , Doss commenced his professional career in January 1986 as a member of the Metropolitan Opera in New York City .', 'positives': ['After a two-year stint in Chicago , Doss began his career in January 1986 as a member of the Metropolitan Opera in New York City .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Born in Gosforth , Northumberland , he moved to Wiseton Estate as a boy near Retford , Nottinghamshire , when his father found jobs there .', 'positives': ['Born in Retford , Nottinghamshire , he moved as a boy to Wiseton Estate , near Gosforth , Northumberland , when his father found jobs there .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Ranjib Biswal is married to Anita Mohanty , a NRI from London , United Kingdom', 'positives': ['Anita Mohanty is married to Ranjib Biswal , an NRI from London , United Kingdom .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Both John Kerry in 2001 and Mark Warner in 2004 lost Loudoun and Prince William counties .', 'positives': ['Both in 2001 Mark Warner and John Kerry in 2004 lost Loudoun and Prince William counties .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Kurgo products are also available through the distributor Accapi Group in Australia and New Zealand , while MasterPet Kurgo products are sold in Europe .', 'positives': ['Kurgo products are also available in Australia and New Zealand through the distributor Accapi Group , while MasterPet distributes Kurgo products in Europe .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In 2010 he won the 17th place in the 2nd Ukrainian Team Chess Championship with the Rivne Forest Bisons team .', 'positives': ['In 2010 he won the 2nd place in the 17th Ukrainian Team Chess Championship with the Rivne Forest Bisons team .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Rodney Waschka II is an American composer known for his algorithmic compositions and theatrical works .', 'positives': ['Rodney Waschka II is an American composer known for his theatrical compositions and his algorithmic works .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Hawkgirl is now 100 % Kendra Saunders .', 'positives': ['Now Kendra Saunders is 100 % Hawkgirl .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"He was also a mechanic in Freddie Spencer 's team when Spencer won the 500cc World Championship title in 1985 .\", 'positives': [\"He was also a mechanic on Freddie Spencer 's team when Spencer won the 500cc World title in 1985 .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'He later planted the movement in London , and then in Brooklyn , New York , and Monticello , New York .', 'positives': ['Then he re-planted the movement in Brooklyn , New York , and later in London , and Monticello , New York .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Political prisoners were Pieter Geyl ( Prime Minister 1945-1946 ) , , Wim Schermerhorn and , all post-war politicians .', 'positives': ['Political prisoners were Wim Schermerhorn ( Prime Minister 1945-1946 ) , Pieter Geyl and all of the post-war politicians .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"In 1901 the first part of his piano cycle `` On an Overgrown Path '' was listed and gradually became one of his most published works .\", 'positives': [\"In 1901 , the first part of his piano cycle `` On an Overgrown Path '' was performed and gradually became one of his most frequently-published works .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Sir Roger Martyn ( or Martin ) was Mercer and Lord Mayor of London in 1567 , he was Sheriff of London in 1559 .', 'positives': ['Sir Martin ( or Roger Martyn ) was Mercer and Lord Mayor of London in 1567 , and in 1559 also Sheriff of London .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'She explores traditional music as well as the contemporary repertoire .', 'positives': ['She explores traditional music as well as contemporary repertoire .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'B is the middle term between the two premises ( the common term ) , but is never distributed , so that syllogism is invalid .', 'positives': ['B is the usual term between the two premises ( the center term ) , but is never distributed , so this syllogism is invalid .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Various high-ranking positions were occupied at Yukos Oil Company and its subsidiary , the Menatep Group .', 'positives': ['Nevzlin occupied various high-ranking positions at Group Menatep and its subsidiary , the Yukos Oil Company .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'In 1977 , the US 1 was transferred to Webster Avenue and Alexander Hamilton Bridge , crossing the Harlem River via the Cross Bronx Expressway .', 'positives': ['In 1977 , the US 1 was transferred to Webster Avenue and the Cross Bronx Expressway , crossing the Harlem River via Alexander Hamilton Bridge .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Thomas Calvert was born in London on December 30 , 1870 , and was the first son of the journalist Herbert Hepburn Calvert and his wife Grace ( nee Hepburn ) .', 'positives': ['Herbert Hepburn Calvert was born on December 30 , 1870 in London and was the first son of the journalist Thomas Calvert and his wife Grace ( near Hepburn ) .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Cloud9 is the native IDE for the BeagleBone Black Single Board Computer , which is primarily programmed in an extension of node.js named Bonescript .', 'positives': ['Cloud9 is the single IDE for the BeagleBone Black native board computer , which is primarily programmed in an extension of node.js called Bonescript .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'where formula _ 3 has the original supply curve and formula _ 23 is the minimum wage . The horizontal first curve is thus a new branch and a kink at the point', 'positives': ['Where Formula 3 has the original supply curve and Formula 23 is the minimum wage , the first horizontal curve is a new branch and a knick at the point .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"Rosemont 's Allstate Arena is home to the Chicago Wolves of the American Hockey League , the WNBA 's Chicago Sky , and the DePaul University basketball team .\", 'positives': ['The Allstate Arena of Rosemont is home to the Chicago Wolves of WNBA , the Chicago Sky of the American Hockey League and the DePaul University basketball team .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Dierker is also the sixth manager in the MLB story to win a Championship division in his first season for the Astros in 1997 .', 'positives': ['Dierker is also the sixth manager in MLB history to win a division championship in his first season for the Astros in 1997 .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Morris Township is located in the 25th Congressional District and is part of the 11th State Legislative District of New Jersey .', 'positives': [\"Morris Township is located in the 25th Congressional District and is part of New Jersey 's 11th state legislative district .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"`` Fried Onions '' was shown in a television advertisement for Options indulgence chocolate drink , first used on UK TV in December 2011 .\", 'positives': [\"`` Fried Onions '' was shown in a television advertisement for options - enjoyment - chocolate drink , which was first used in December 2011 on UK TV .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Prenatal hormones , especially glucocorticoids such as cortisol , are essential for the development of the adrenal organs , particularly for the maturation of the lungs .', 'positives': ['Adrenal hormones , particularly glucocorticoids like cortisol , are essential for the prenatal development of organs , especially for the maturation of the lungs .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"The film was a moderate success because it followed Mithun 's low-budget formula .\", 'positives': [\"The film was a moderate success , as it followed Mithun 's low-budget formula .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Although iron is generally less active in many catalytic applications , it is less expensive and `` -greener than other metals .', 'positives': ['Although iron in many catalytic applications is generally less expensive , it is less active and `` greener than other metals .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'However , the two unpopular Cantons had immediate financial problems and were forced to institute a number of new taxes and laws .', 'positives': ['The two new cantons , however , had immediate financial problems and were forced to impose a series of unpopular taxes and laws .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Aletta is a Dutch feminine related name , given to Alida , Adelheid and Adelaide .', 'positives': ['Aletta is a Dutch female related name given to Alida , Adelheid and Adelaide .'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': \"In the 1970s , W & R Jacob in Tallaght , Ireland merged with Boland 's Biscuits to form Irish Biscuits Ltd. and moved to Dublin .\", 'positives': [\"In the 1970s , W & amp ; R Jacob merged with Boland 's Biscuits to Irish Biscuits Ltd in Dublin and moved to Tallaght , Ireland .\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 4}\n",
            "{'query': 'Can I use Jio sim in Xolo one HD?', 'positives': ['Can I run Jio SIM in XOLO One HD?'], 'negatives': ['Can I use Jio SIM in Mi4?', 'How can I use the Jio 4G SIM in XOLO Q800 X-Edition mobile?', 'Can Jio sim be used outside India?', 'How can I use Jio SIM in Lumia 535?', 'How can I run my Jio SIM in any 3G phone?', 'Will Jio sim work for Moto E2?', 'Can Jio SIM be used with a BSNL dongle?', 'Does a Jio SIM work in Galaxy S3?', 'Can I use Jio SIM in 3G?', 'Does Jio sim work for Moto G2 (2nd generation)?', 'Can we use Jio sim in Samsung Galaxy S6?', 'How is the Jio sim working for free?', 'Can I use Jio SIM in Yu Yureka plus?', 'How can I use Jio sim in 3G Micromax A102?', 'Does Jio sim support normal dongles?', 'How can I get Reliance Jio 4G SIM by Jugaad?', 'Can I use jio in samsung E7?', 'Will Jio-Fi support any other SIM than Jio?', 'What is the easiest way to get JIO sim?', 'Can Jio sim work on a non-VoLTE but 4G enabled phone?', 'Can we use another sim in simslot after using JIO sim for 3 months?', 'Should I get a Jio sim now?', 'How do I recharge jio sim?', 'How do I use Reliance JIO SIM in devices other than mobile?', 'Can I use Jio in my iPhone SE?', 'Will the Reliance Jio sim work in Asus Zenfone 5?', 'Should I buy a Reliance Jio sim?', 'Will Jio sim work in a 3G phone? If yes, how?', 'Is a Jio SIM upgrade required?', 'From where can I get a Reliance Jio SIM?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What should I do in order not to care about what people think of me?', 'positives': ['As an individual, do I really need to care what people think about me?'], 'negatives': ['Why do I feel bad for other underprivileged people and makes me think about life?', \"I often don't think about how my actions affect others. Is something wrong with me?\", 'Why do I find it difficult to care about others?', \"Why can't I think for myself?\", 'Being a girl, what do you think about me?', 'Why are some people afraid to think?', 'What do girls think about me?', 'Now that I am considered an adult, I feel like nobody cares about me anymore. This makes me very sad. What can I do?', 'How can I ask a question which makes people think?', \"Why do I think my parents don't care about me?\", 'Why am I unable to think deeply? When I think deeply about something, a stress or pressure starts to build in my mind.', 'How can I think of myself as an adult?', 'How can I think for myself?', \"How do I stop caring for people who don't really care for me?\", 'How can I stop worrying about my future and career and start focusing on the present?', 'How do I stop worrying about the future and other things and focus on today?', 'Why am I worrying about my relationship?', 'Am I dumb if I never have to think much?', 'Why should I bother people?', 'What are the best ways to think for myself?', 'Why do people care about their future?', 'What is worrying?', 'How do I react when people ignore me?', 'Am I the only one who is always worried about my future?', 'Why did I stop caring about society completely?', 'I self pity myself and my thinking is not straight or correct or logical. What should I do?', 'How should one stop worrying about the future and start living happily?', 'Being obsessed over things are hard for me, how come?', 'Why do people think in life?', \"Why don't I matter to the person I want to matter to?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Who is Azor Ahai in Game of Thrones?', 'positives': ['What is Azor Ahai?'], 'negatives': ['Where was Azor Ahai from?', 'What does the word \"azam\" mean in Urdu?', 'Is Shireen Baratheon Azor Ahai?', 'Is Jamie Azor Ahai?', 'Who is Sitaram Yechuri?', 'What is the Ashwamedh Yagya?', 'Was Bhagat Singh an Arya Samaji?', 'What does ja nai and dekinai mean in Japanese? How are they used?', 'What is Nangli Wazidpur?', 'What is the Sanskrit version of Namu Myōhō Renge Kyō (南無妙法蓮華経)?', 'Who is Periyar E.V. Ramasamy?', 'What is Waze?', \"What does 'Anasir' mean in Indonesian language?\", 'What is nag mani?', 'Who is Pandit Mahendra Pal Arya ?', 'What is jelania?', 'I am devoting Iself to the Rasta livity. Can you please give I an idea or two for Jah names? I want one that means Jah has awakened (or forgiven) I?', 'What is Kipi in Rusia?', 'What is NSH Kochi?', \"What does 'jegeg' mean in Indonesian language?\", 'What is the use of azee 500mg?', 'What is hanuman chalisa?', 'Arabic (language): What is the meaning of \"wa alaikum salaam\"?', 'What is wabi-sabi?', 'What is the manga Gedo(u) No Uta about?', 'Chamath Palihapitiya: Who is Chamath Palihapitiya?', 'What is the origin of Chandragupta Maurya?', 'Who is Miya Ali?', 'Who is Murtagh in Eragon?', 'Do you have any idea about Kama Gita?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Can I use relience Jio sim in 3G mobile?', 'positives': ['Can I use Jio SIM in 3G?'], 'negatives': ['Can I use jio 4g sim in my mi 4i?', 'Can we use more than one Jio sim in a 4G mobile?', 'How can I use the Jio 4G SIM in XOLO Q800 X-Edition mobile?', 'Can Jio sim work on a non-VoLTE but 4G enabled phone?', 'Does Jio sim work for Moto G2 (2nd generation)?', 'Can I use 4g jio in Nokia Lumia 535?', 'Can I use jio sim in my Samsung galaxy s4 i9500?', 'Can we use Jio sim in Samsung Galaxy S6?', 'How is the Jio sim working for free?', 'It is possible to use Jio 4G sim in Gionee p5w mobile?', 'Can we use another a Jio SIM in a bar code generated phone?', 'Will Jio sim work for Moto E2?', 'Will Jio-Fi support any other SIM than Jio?', 'Can we use a Jio SIM on other mobiles except the mobile in which the bar code was generated?', 'Can we use another sim in simslot after using JIO sim for 3 months?', 'How can I use Jio SIM in Lumia 535?', 'Can I use Jio 4G sim in D-Link netsetter?', 'Is Jio4Gvoice app required on Redmi Note 3 to make Jio calls?', 'Can we use the Jio SIM that came along with LYF mobile in other 4G mobiles?', 'Can I use Jio in iPhone 6S?', 'Is a Jio SIM upgrade required?', 'I am not getting any signal in Moto G3 for Jio. The sim is active and I have put it in first slot. Can someone help?', 'I got Jio sim in my moto g4+ in 15dayes before. When active the sim?', 'Can I use jio in samsung E7?', 'Does inserting Jio sim in sim slot 1 or 2 will make any difference in activation?', 'I am about to buy a Jio sim for which I generated a barcode through MY JIO app which went missing after updating it recently. How shall I get it back?', 'What is the easiest way to get JIO sim?', 'Is anyone in Shimla using Jio 4G?', 'How can I use Jio 4G data on iPhone 5s?', 'I have a Micromax Canvas Pace 4G Q416. Can I avail a free Reliance JIO 4G Sim? If yes, how?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Is time travel to 2010 possible?', 'positives': ['Is time travel possible then after how long time?'], 'negatives': [\"What do you hAve to say about time travel (I am not science student but I read it on net and its so exciting topic but still no clear idea that is it possible or it's just a rumour)?\", 'What are the most fascinating things about time travel?', 'What is the best thing to do to pass time while travelling?', 'What are some good books about time travel?', 'Why do we assume that travelling faster than the speed of light necessitates time travel?', 'What are some of the best time travel movies in recent times?', 'What actually is time?', 'What is Time paradox?', 'What are some good books on time travel?', 'What is the best way to pass time?', 'Is time a human concept? How can we say that time runs faster at higher altitudes? Do the hands of my watch move faster in space?', 'What are some good ways to pass time?', 'Do we understand time?', 'Do we really understand time?', 'How do I pass time?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why do we sneeze when looking at the sun?', 'positives': ['Why do I sneeze whenever I look at the sun?'], 'negatives': ['Why do you close your eyes when you sneeze?', 'What is the reason you close your eyes when you sneeze?', 'Why do people sneeze?', \"Why can't we sneeze with our eyes open?\", 'Why do I start sneezing every morning?', 'Why does it is not possible to sneeze with our eyes open?', 'Why do I always start sneezing as soon as I wake up in the morning?', 'Do sneezes cause colds?', 'Why we stop for a while after sneezing?', 'Do we sneeze while sleeping?', 'Is it possible to sneeze in your sleep?', 'What is the cause of sneezing?', 'Why is my rat sneezing?', 'Do people sneeze in their sleep?', 'Sneezing in the mornings?', 'Why do people say \"bless you\" whenever someone sneezes?', 'Why does drinking coffee make me sneeze?', 'What are the causes of continuous sneezing?', 'Are sneezes good for you?', 'Why do people say god bless you when you sneeze?', 'Why do people say bless you when you sneeze?', 'What are sneezes?', 'Why do we say bless you when someone sneezes?', 'Why do they say \"God bless you\" when you sneeze?', 'What bad could happen if I sneeze while eating?', 'Why do we say god bless you when we sneeze?', 'Is it possible I sneeze all the time because I ate spicy food?', 'What is the origin of saying \"bless you\" when someone sneezes?', 'How are sneeze patterns determined?', 'Is sneezing beneficial or not?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which is better either to study at late night or to study at early morning?', 'positives': ['Which one is better: Early morning study or late night?'], 'negatives': ['Is it better to work out at night or in the morning?', 'Is it good to study in the night?', 'What is the better time to exercise, morning or evening?', 'Is it good to study at night?', 'Which is best, a morning or evening walk?', 'Is it better to run/work out in the morning or in the evening?', 'Which is a good time to do exercise, morning or evening?', 'What is the best early morning routine for students?', 'Is reading in the night not as efficient as reading in the morning?', 'Which is the best time to workout, morning or evening?', 'Is it better to drink milk at night or the morning?', 'What is the best time for studying in the afternoon?', 'Why do I study better at night?', 'Can you tell me a way to study during night?', 'Which is the best time for workout? Morning or evening?', 'What are some good early morning habits?', 'Can you tell me a way to study during the night?', 'Is sleeping late and waking up late better or sleeping early and waking up early?', 'Which is correct: at evening or in the evening?', 'It is better to yoga in the morning or afternoon?', 'When is the best time to exercise, in the morning, afternoon or in the evening? And before or after meals?', 'What is the trick to study late at night for an IIT aspirant?', 'Is it better to shower in the morning or evening?', 'Which one is better, drinking milk in the morning or just before going to bed?', 'Walking or yoga is better in the morning?', 'Are you more of a night owl or a morning person?', \"What's the best time to sleep at night?\", 'Which is the best time for exercise in the evening?', 'What is the best time to do exercise in the morning or evening?', 'How can I tolerate my sleep during late night study?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why did Verizon acquire Yahoo?', 'positives': ['Why is Verizon buying Yahoo?'], 'negatives': [\"Why hasn't the Yahoo stock price gone up after the acquisition by Verizon?\", 'What is Verizon?', 'What will Verizon do with Yahoo Mail after the acquisition?', 'Is verizon wireless still worth the extra cost over competitors?', 'How much in taxes does Verizon pay the US?', 'Why did eBay buy StumbleUpon?', 'What are Verizon and AT&T?', 'Why is Dell buying EMC?', 'What would happen to my Yahoo email account after Verizon Deal?', \"What is Verizon's extended network?\", 'Do Verizon Wireless sales consultants get yearly salary increases?', \"Will Yahoo Mail shut down following Verizon's acquisition?\", \"If Facebook bought Whatsapp, why can't Google just buy Viber too?\", \"What is Verizon's iPhone extended network?\", 'Why does Google has acquired so many companies?', 'Why is Google acquiring so many companies?', 'Why are the huge companies buying other companies?', \"Why didn't Yahoo succeed as much as Google?\", 'Why do companies buy companies?', 'Is Business Insider the TMZ of business news?', 'What is Yahoo Finance?', 'How do I keep updating my service with Verizon?', 'Why has Google not acquired Twitter yet?', 'Why did Facebook buy Quora?', 'Why does Google own 466453.com?', 'How do you check Verizon voicemail?', 'Why did Facebook acquire WhatsApp?', 'Can you buy an iPhone without a data plan from Verizon?', 'Why this company Infosys?', 'Why did Microsoft buy LinkedIn for $26.2 billion in an all-cash deal?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What's an optional subject opted by the top 100 UPSC 2014?\", 'positives': [\"What's an optional subject opted by the top 100 UPSC 2014 Mains?\"], 'negatives': ['Which one best optional subject for UPSC Mains?', 'What us the best optional subject for UPSC?', 'Are there chances of removal of optional subject in upsc mains from 2016 onwards?', 'Which is the easiest optional subject for the IAS Mains?', 'Which is the easiest optional subject for IAS mains?', 'How many optional subjects do we need to choose for UPSC 2017? Can you guide me to the official UPSC syllabus page?', 'Which subjects should I select as optional for UPSC CSE 2017?', 'What is the best optional subject for civil service?', 'Can we choose any of the optional subject for IAS?', 'Which subjects should I choose as my optional subjects for the UPSC CSE?', 'How should I decide my optional subject for IAS?', 'Is mathematics a good optional subject for UPSC?', 'How is management subject as an optional subject for IAS mains?', 'What is the best optional subject in UPSC(CSE) for computer science engineer?', 'Should I starting preparing the optional subject for 2017 UPSC exam?', 'Which subject should I choose as optional in the IAS exam?', 'What are the pros and cons of commerce as an optional subject for the UPSC?', 'What is the best optional subject for UPSC CS exam among political science, public administration and sociology?', 'Is UPSC going to Remove Optional Subject from CSE-16?', 'What is the best optional subject for civil service examination?', 'What are the chances of eliminating optional from UPSC Mains from this year?', 'Will upsc remove optional paper from mains exam?', 'Which optional subjects can I choose for the IAS exam?', 'Do we have to choose two optional subjects in the UPPCS exam?', 'I am a civil engineer. What will be the best optional subject to be chosen for CSE mains?', 'Is mathematics good for optional in UPSC?', 'Is pschology a good optional subject for UPSC?', 'How many optional subjects should one choose in IAS?', \"My interests are in the fields of economics and law and I'm confused whether to go with what optional subject in UPSC. Which subject had large proportion selection?\", 'Public administration as optional subject?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What is your opinion to finish P V Sindhu's performance in Rio 2016?\", 'positives': [\"What are your opinions on P.V. Sindhu's performance in Rio 2016?\"], 'negatives': ['Who defeats PV sindhu in Olympics final?', \"As a nation are we too content with PV Sindhu's silver?\", \"What do you think about Kangana Ranaut's performance in Tanu Weds Manu Returns?\", 'Who is better Saina Nehwal or PV Sindhu?', \"Why is India's badminton ace and 2016 Rio Olympics silver medalist being wrongly credited as P. V. Sindu or as V. Sindhu Pusarla?\", \"What do you think of India's win in the Kabaddi world cup?\", 'What are your views about Bhuvan Bam (BB Ki Vines)?', 'Why are we saying that P V Sindhu has an assured silver medal? Instead of saying she has a shot at the gold medal?', 'What is your review on Mia Khalifa?', 'What is the Best moment in RIO Olympic 2016?', 'What is your review of Bramha Kumaris?', 'What is your review of Kaaba?', 'Will India win a single medal in Rio Olympics 2016?', 'According to you, which is the best moment of Rio Olympics 2016?', 'What according to you is the best moment of Rio Olympics 2016?', 'What is your impression of Brazil after the Rio Olympic Games?', 'Are Rio de Janeiro and Sao Paulo both LEDCs?', 'How come Ukraine is doing very well at the Rio 2016 Paralympics?', \"Was Kangana Ranaut's performance in Tanu Weds Manu Returns overrated?\", 'What do you think about Brazil?', 'What is your review of Padayappa?', \"Where are the your view on Vijay Goel's fiasco in Olympics?\", 'What are your thoughts on the Germany versus Brazil match?', 'Is it reasonable to reward PV Sindhu with so much money by the governments?', 'What is your review of Uruguay?', 'Did India won a single medal in Rio Olympics 2016?', 'What is your prediction for Champions League 2016-2017?', 'Are Porto and Braga traditional rivals?', 'Is India going to win any medals in Rio Olympics 2016?', 'Can someone share their opinion about the Philippines?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can you earn money from bitcoin?', 'positives': ['How do I Earn from Bitcoin?'], 'negatives': ['How much money do Bitcoin miners make?', 'How do I start Bitcoin mining for money?', 'How do I sell bitcoin?', 'How many days does it take to generate a bitcoin through bitcoin mining?', 'How does one can build a bitcoin wallet?', 'How can I make more bitcoin without investing?', 'Where can I buy bitcoin?', 'Where do I buy bitcoin?', 'How do I start investing on bitcoin?', 'How big will Bitcoin get?', 'Where can I buy bitcoin for actual price?', 'Do you make money or lose money mining Bitcoin from a laptop?', 'Where should I create a bitcoin wallet?', 'How can I get bitcoins in India?', 'Where can I buy bitcoins?', 'How much will 1 bitcoin worth 10 years from now?', 'How can I buy bitcoins using my credit card by myself?', 'How high can the price of Bitcoin go?', 'How can I buy Bitcoin by 7 credit cards equivalent of 8,000 euros in one day?', 'How is the value of Bitcoin calculated?', 'As a developer, how can I create a Bitcoin wallet?', 'How can I buy bitcoins without an ID?', 'How do I build a bitcoin gateway?', 'What is the easiest way to buy bitcoins using my credit card?', 'Is Bitcoin mining still profitable in 2016?', 'How do I buy Bitcoin in India?', 'Can we earn 4000 bitcoins in India through mining over a year? If so, how?', 'Is bitcoin mining even worth it anymore?', 'Can you buy Bitcoins with a credit card?', 'What is your experience with Bitcoin mining?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How is Odysseus a bad leader in the Odyssey?', 'positives': ['Why was Odysseus considered a good leader in \"The Odyssey\"?'], 'negatives': [\"Homer's Odyssey: Why did Athena turn Odysseus into a beggar?\", \"What are Odysseus' strengths and weaknesses?\", 'Who is the greater hero, Achilles or Odysseus?', 'Why does Penelope not recognize odysseus?', 'Was Napoleon a competent leader?', 'Was Napoleon ever a good military leader?', 'Why is “Ulysses” written by Alfred Tennyson considered to be a great poem?', 'Why was John Adams considered a good president?', 'Why is Maya Angelou considered a great leader?', 'Was Caligula a sussessful leader?', 'Is Amelia Earhart a good role model? Why or why not?', 'Was Joffrey a better king than Tommen?', 'What history books have helped you become a better leader?', \"What was Alexander the Great's personality like?\", 'Was Adolf Hitler a good leader?', \"Greek Mythology: Who is the tragic hero of 'Antigone'?\", 'Who was the most powerful Sith Lord during the Old Republic?', 'What makes a good leader?', 'Who is the most admired leader of all times?', \"What are some legitimate explanations for the Ewoks beating the Emperor's best stormtroopers?\", 'Spartacus: History of Gladiator Revolt Leader - LiveScience?', 'Is Lord Ganesha a cosmic Leader?', 'Who was the most powerful Sith Lord?', 'What made people think Rhaegar would be such a potentially great king? What do we know about his ruling abilities?', 'How good was Albus Dumbledore in being the leader of The Order of The Phoenix?', 'What makes Othello a tragic hero?', 'What do you think are the qualities of a good leader?', 'How is Othello a tragic hero?', 'Who is the Compare of the Mr Olympia?', 'Did Hamlet ever love Ophelia?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Is a Math 201 a higher level math than Math 115?', 'positives': ['Is Math 201 (Intro to probability and statistics) a higher level math than Math 115 (Mathematics for the liberal arts)?'], 'negatives': ['Are there any good probability and statistics supplemental textbooks for a 300 level math course?', 'Is there a math subject harder than calculus?', 'Does Harvard’s Math 23 cover the set theory and discrete math needed for CS 124?', \"How hard is Harvard's CS 124 for math majors?\", 'Is math an art or a science?', 'Is Math 114 (Analysis II: Measure, Integration and Banach Spaces) worth taking at Harvard?', 'Should I do further maths or physics at A level?', 'Are math and science harder to study than humanities?', 'How important is Further Mathematics in A-Levels?', 'How is mathematics related to computer science?', 'I have got 98 marks in maths of the 12th HSC boards. I am deeply interested in mathematics. What are the good career options in maths?', 'What topics of maths is required for physics in class 11 and 12 for CBSE?', 'What are the different kinds of math?', 'Is math a science? Is the scientific method used in math or only logical axiomatic deduction?', 'Why is statistics not regarded as a branch of mathematics, and also not regarded as a subset of probability?', 'Is math a skill or a talent?', \"Is it 'Math' or 'Maths'?\", 'Is there any different kind of math?', 'Is computer science a subset of math?', 'Is the math used in computer science very different from that used in physics?', 'Does Medical School require math?', \"What numbers that are bigger than Graham's number have been used in mathematics so far?\", 'Why major in math?', 'Is numerology real? Is it a branch of math and/or science?', 'Is there a lot of math in computer science?', 'What is the relationship between math and science?', 'Is mathematics taught correctly today in school?', 'Is the mathematics we know a mathematics or the mathematics?', 'I got 790 on math 2 SAT subject test and 740 in physics. Is it enough for top engineering universities such as Stanford, MIT or Berkeley?', 'I scored a 1510 on the SAT (800 Math), 800 on Math Level 2, and 770 in SAT Physics. Is it worth applying early to MIT?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which is the best field in engineering in future?', 'positives': ['What is the best field of engineering for the future?'], 'negatives': ['What is the most important technology of the future in mechanical engineering field?', 'What is the future of system engineering?', 'What is the future of engineering in India?', 'What is the future in chemical engineering?', 'What would be the mechanical engineering opportunities in future?', 'What is the future of chemical engineering?', 'What are the prospect of mechanical engineers in future?', 'What is the best engineering field to get a PhD in?', 'What are good research topics on engineering project?', 'Which stream of engineering is best for future research in Quantum Mechanics?', 'What is the best engineering major?', 'What is the future of Petroleum engineer?', 'What is the future of plastic engineering?', 'Which is the best field for masters in mechanical engineering?', 'What are some good career options beside engineering?', 'Which are some of the professions of the future?', 'What are the future trends of chemical engineering?', 'What is the future of petroleum engineering as a career choice?', 'Which field is better for a mechanical engineer, production, quality or design?', 'What are some of the best topics which we can take for a major project in electrical engineering?', \"What is the best field in mechanical engineering after completing a Bachelor's of Engineering?\", 'Which is the best job field in mechanical engineering? Which one has a good growth opportunity?', 'Which is the best website for engineering?', 'What is the future of an instrumentation and control engineer?', 'Next future in mechanical engineering?', 'I am a triple major (Chinese/Korean/General Engineering). If I wanted to make use of all my majors, what is the best engineering field to move into?', 'Which is the best project for mechanical engineering?', 'What do you see in the future of technology?', 'I have a bachelor in Mechanical Engineering. Considering how I want my future life to be, what field should I choose for my masters degree?', 'What is best subject in it among engineering science, electrical engineering and mechanical engineering?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do you see the PM Modi’s move of banning old 500 and 1000 rupee currency notes?', 'positives': ['What do you think of the move by the govt to scrap 500 & 1000 rupee notes?'], 'negatives': ['How exactly the move by MODI Govt. is against the people who have enormous amount of unaccounted cash?', 'What are your views on Mamta Banerjee’s comment on the recent demonizing of older currency and indelible ink?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How are Jammu and Kashmir sub-divided?', 'positives': ['How did Jammu and Kashmir got divided from India?'], 'negatives': [\"Why doesn't India create two separate states out of Jammu and Kashmir?\", 'How did India and Pakistan occupy parts of Kashmir? Did the King of Kashmir accede to India or not?', 'Do Muslims of Jammu also want independence of Jammu from India?', 'Why is Islam trying to separate Kashmir from India?', 'Why do Kashmiris want independence from India?', 'Why is the northernmost state of India called Jammu and Kashmir and not just Jammu or Kashmir or Jammu, Kashmir and Ladakh?', 'Why is Jammu and Kashmir worst state in India? Why do they disrupt peace in India?', 'Why is there a conflict between India and Pakistan on Kashmir?', 'What might have happened if India had given up Kashmir in 1947 to Pakistan?', 'Why is Kashmir not a part of Pakistan?', \"What is the reason that even after 70 years, Kashmiris don't consider themselves as a part of India? Where has India gone wrong?\", 'Should India consider giving Kashmir independence?', 'Why not India merge Jammu and Leh and Ladakh as a new full state?', 'What is the difference between Azad Kashmir and Jammu & Kashmir? Are they similar or different?', 'Why are Kashmir among the corrupt states in India?', 'Why is Kashmir among the corrupt states in India?', 'What is Kashmir conflict?', 'Had Kashmir been part of Pakistan would India behave the same way as Pakistan does?', 'What are the pros and cons of dividing India into two, South and North?', 'Why 43% of Kashmir is demanding independence from both nations?', 'What if India gives Kashmir to Pakistan?', 'What is the Kashmir conflict?', 'If the current crisis in Kashmir carries on, what portion of Jammu & Kahsmir will get separated from India in worst case scenario?', 'Why cannot India and Pakistan let kashmir be independent country?', 'How did Pakistan occupy Kashmir?', 'How did the Kashmir conflict start?', 'What is Kashmir issue?', 'Is Azad Kashmir and Jammu and Kashmir the same (culture, etc)?', 'Officially in how many divisions Uttar Pradesh is divided?', 'What is the Kashmir problem?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'When is it too late to study medicine and become a doctor?', 'positives': ['Is it too late to go to medical school at 24?'], 'negatives': ['As a 14 year old girl who wants to go to medical school, should I work extremely hard and study a lot now to be ready for it? What should I do?', 'Is it wise to start studying medicine at the age of 32 or 33?', 'Should I quit medical school?', 'How many hours do medical students study daily?', 'What is it like to drop out of medical school?', 'At 30, what is it \"too late for\"?', 'How many hours do medical students sleep?', \"What if it's too late?\", 'What is your advice for an international pre-med student who wants to get into top medical schools after his graduation?', 'What are some tips about getting into one of the top medical schools?', 'Is it too late to learn to play the piano at 26?', 'Is 23 years old too late to learn another language?', 'How late is too late to have children?', 'How often should you go to the doctor?', 'How much time would be needed for a medical student of class 11? And what should be the time table for that?', 'I am 29 yrs old, Can I still become a medical doctor now? If yes how?', 'Where is the best medical school?', 'What should one do at the age of 16-24?', 'Will I get any Private medical college?', 'What can I do at the age of 24?', 'I am a 28 year old female licensed architect living in India. is it too late now to consider a career in medicine?', 'How long should you wait before seeing a doctor if your period is late?', 'Should I quit medical school if it is making me miserable?', 'Is it too late to learn piano at the age of 30?', \"When you're in your 20s is it too late to start ballet and want to become professionally good at it?\", 'What are some tips to get accepted in some top medical schools for a high school freshman?', 'Should I go to a new government medical college starting first session from this year?', 'What can medical undergraduate do after completing medical school?', 'What is the right age to start working: 24 or 26?', 'Why are doctors always late?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why can you not accelerate to faster than light?', 'positives': [\"Why I can't go faster than light?\"], 'negatives': ['Why does light travel so fast?', 'Why does light travel so fast in space?', 'Speed of Light: How fast can we move?', \"If light can't even escape a black hole, does that mean it is being sucked in faster than its speed?\", 'How does light travel so fast?', 'How can you become faster?', 'How do I become faster?', 'Is the speed of dark faster than the speed of light?', 'How can I get faster?', 'What happens to an object if it reaches the speed of light?', 'When will we be able to travel at the speed of light?', 'How will it be to travel at the speed of light?', 'How can I make time go by faster?', 'How can you make time appear to go faster?', 'What will happen if I run at light speed?', 'Why does the time go so fast?', 'How do I become faster physically?', 'Why does time seem to go faster as we age?', 'How do I make time go by faster?', 'Why do we age slower when traveling at or near the speed of light in space?', 'Can the speed of light be increased?', 'What would happen if an object would reach the speed of light?', \"I think this is a very stupid question: in the reference frame of a photon, aren't we moving at the speed of light or faster?\", 'When light travels from one medium to another, its speed changes, why is this so?', 'Why does time seem to go so much faster as we age?', 'Will the speed of light ever change?', 'If you could travel the speed of light, what would happen?', 'What’s the speed of light?', 'Do galaxies travel faster than the speed of light?', 'Why does time pass faster (as we think) when we go to sleep?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What was the best day of your life?', 'positives': ['What day in your life did you consider to be the best day ever?'], 'negatives': ['How was your day? What did you do today?', 'What is your typical day like?', 'What is your favorite day of the year and why?', 'How was your day today? What have you been recently been thinking about?', 'What was the happiest day of the life?', 'What is your favorite day of the year?', 'Which is your favourite time of the day?', 'Which is your favourite day of the year, and why?', 'What is your favourite day of the year?', 'What would be a blissful day?', 'If today were your last day, would you be completely satisfied with your life?', \"How can I make my today's day the most memorable day of my life (It's my birthday today)?\", 'What is your favourite hour of the day? And why?', \"Philosophy of Everyday Life: What's your average day like?\", 'What constitutes a day?', 'What is the best time of the day to learn or study?', 'If you knew today was your last day on Earth, how would you spend it and why?', 'Is the day following your birthday the most gloomy day of your life?', 'Which day can be the first day and last day of any century?', 'How is your day going?', 'What is your average day like and what do you do?', 'How was the best date you ever had?', 'What is the best time of day to go on a walk?', 'Which day can be the first and the last day of a century?', 'How would you spend your day if you got to know it is your last day?', 'What is the best time of day to have sex?', 'Have a good day?', 'What will you do in the last day of your life?', 'Which day of the week is your favourite and why?', 'What will you do if this is your last day of your life?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do people fall in love AGAIN?', 'positives': ['How do I let myself fall in love again?'], 'negatives': ['I fell in love truly once but the guy left me. Now I cant seem to find myself falling in love again though I have moved on. What should I do?', 'Why do I afraid to fall in love again?', 'How can I prevent myself from falling in love?', 'What are some ways to fall in love with yourself?', \"I'm in love with myself. What do I do?\", 'I am in love with myself. What should I do?', 'How could you ever fall out of love with someone you once loved truly? How and why is it possible?', 'How will I start loving myself again?', 'How is it possible to fall in love without falling?', 'How to not fall in love?', 'What can I do to not fall in love?', 'How do I let go of my first love?', 'How does one let go of their love?', 'Is it possible to not fall in love?', 'What can I do to love myself?', 'Is it still love if I forced myself to love?', 'How can I love myself unconditionally?', 'Is it possible to never fall in love?', 'How is it possible to fall out of love if that person has never changed (is still the best etc)?', 'How did you fall in love?', 'Is it possible to fall \"in love\" without being in a relationship?', 'Are you afraid of falling in love again?', 'How do I prevent myself from falling in love with my boyfriend?', 'How can I avoid falling in love?', 'How do I truly love and accept myself?', 'Will I ever fall in love?', 'Is it wrong to fall in love?', 'How do I forgive myself for failing in love?', 'How do I stick to your authentic self and love your self at the same time?', 'Do I fall in love?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'As a third year btech student what should I do to start preparing for ias exam?', 'positives': ['I am in first year. In which direction should I start my preparation to clear for IAS exam?'], 'negatives': ['Should I start my IAS exam preparation with McGraw Hill Education’s general studies manual ?', 'I am starting preparation for IAS UPSC Exam . Which book should I buy for CSAT preparation 2016 exam?', 'I will be taking the IAS exam after 2 years. I presently work at Infosys. How should I plan my preparation and what routine should I make?', 'How can I start preparing for the IAS exam if I come from a Gujarati background?', \"How should I start my preparation for Civil Services Exam 2017 if I don't want to join any coaching classes? What study method should I adopt?\", 'What is the best daily timetable for IAS preparation?', 'How can I start my civil services UPSC exam (IAS) preparation without attending any coaching classes?', 'What is prelims exam in IAS exam?', 'How should I prepare for IAS? Which books and online sources should I refer for the preparation?', 'Should I go for IAS preparation as I am studying in the final year of B.Tech on educational loan but still not placed?', 'What is the average time for preparation of IAS?', 'Is it possible to crack civil services exam 2017 just with self study, if I start preparation right now? If yes, pls guide me how?', 'How should I prepare for IAS? Which books and online sources should I refer for its preparation?', 'I have just finished my 12th standard and am planning to graduate from basic sciences. I wish to take the UPSC exam after graduation. How should I prepare for it?', 'Can IAS exam be cracked with a dedicated preparation of 8 months?', 'I will be in the final year in July and the IAS preliminary exams are in August. Am I elligible for it or do I have to complete my degree first?', 'Which subject wise schedule I should follow for the preparation of the UPSC-2017? I am going to prepare by self study mainly.', 'What is the daily schedule required for the preparation of the IAS?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How are the porn movies made?', 'positives': ['How are porn movies made'], 'negatives': ['Where are the most porn movies made?', \"What's it like to make a porn movie?\", 'How do I get into making porn films?', 'Is anything shown in porn movies real, or is it all just acting?', 'Is the porn industry good or bad?', 'Are college or high school sex parties and orgies a real thing or a fantasy created by the porn industry?', 'Why does porn exist?', 'Is pornography a form of art?', 'How much does it cost to make a porn movie?', 'How is virtual reality porn?', 'Do porn stars watch porn?', 'What are sites for porn?', 'Porn Storylines?', 'How risky is it to start a porn studio?', 'What are the goals of porn industry?', 'What are the disadvantages of watching porn movies?', 'What are some free porn apps and porn?', 'Is there anything real in porn?', 'Which is the best website for porn movies?', 'Why do people become actors in the porn industry?', 'Is pornography an art?', 'How do porn stars separate \"real sex\" from \"porn sex\"?', 'Does porn ruin sex lives?', 'Which is best pornographic movie?', 'Which is the best porn video?', 'Is its ethical to watch porn?', 'Does porn destroy my sex life?', 'How do the porn companies manage to make money when there is lot of free porn available?', 'When was the first porn movie shot?', 'Which are the best porn sited?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do you remove epoxy paint from a concrete surface?', 'positives': ['How can you remove epoxy from concrete?'], 'negatives': ['How do you remove spray paint from concrete?', 'What are some of the most effective ways to remove spray paint from concrete?', 'How do you remove spray paint from cement?', 'How can I give Interction between epoxy and concrete using ansys 15?', 'What are the steps for removing spray paint from concrete?', 'How can I remove cement water stains from a car?', 'What is curing of concrete and which is the best way to cure a concrete in a shorter time period?', 'How can I break concrete using just my bare hands?', 'Is there any way except chipping to remove the set concrete from overturned transit mixer?', 'How do you remove spray paint from plastic?', 'How can I remove enamel paint from plastic?', 'Is there any way to remove dried paint from tile grout?', 'How can asphalt be recycled?', 'How can I break concrete bricks with my bare hands?', 'How does I increase the strength of Concrete?', 'Are there any chemicals that break down cement but not pipes?', 'How does cement harden?', 'How do I remove a plant from a ceramic container?', 'What is the best way to remove spray paint from plastic?', 'Is water evaporates from concrete after 28 days or after it sets?', 'What is the best way to remove paint from grout?', 'How do you remove scratches from plastic?', 'How do you remove tape from walls?', 'What are the types of reinforcement used in cement concrete?', 'How do you remove paint from metal?', 'Construction: What if I take opc 53 grade cement & mix fly ash upto 15% separately in making concrete on site is there any drawback?', 'What are some ways to increase the strength of a concrete?', 'How long does it generally take concrete to cure?', 'How do I remove a plant from a container?', 'What is green concrete & where it is used?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I improve my standard typing speed per minute?', 'positives': ['How can one improve their typing skills?'], 'negatives': ['How can I improve my programming skill?', 'How can I improve my computer programming skills?', 'What is a proficient typing speed?', 'How can I improve programming skills?', 'How can I improve my programming skills?', 'How do you improve your programming skills?', 'How can I enhance my programming skill?', 'How do I improve fast reading skill?', 'How could I improve my writing skill?', 'What is the advantage of typing in computer?', 'I have left only 1 month to increase my typing speed by 45 WPM. How much time should I spend on a typewriter?', 'How can one improve his writing skills?', 'Does typing skills matters in getting a job in a MNC?', 'How can I improve writing skills?', 'How can i improve my coding skills?', \"I am in 12 commerce. I can't complete my question paper on time because my writing speed is very slow. How can I improve my handwriting speed?\", 'How do I improve my reading skill?', 'How do I improve writing skills.?', 'How do I improve my coding skills?', 'How can I improve formal writing skills?', 'How do you improve your writing skills?', 'How can I improve my writing skills?', 'How can I improve my writing skills?', 'How can writing skills be improved?', 'How do I improve my English writing and speaking skills?', 'How can I improve my writing skills in IELTS?', 'What are the best ways to improve writing skills?', 'What is the advantagee of typing in computer?', 'What is the best way to improve my writing skills?', 'How can I improve my communication skills and writing skills?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I reduce gall stones without surgery?', 'positives': ['How do I naturally remove gall bladder stones without surgery?'], 'negatives': ['What precautions one must take before and after removal of the gall-bladder through surgery and for how long?', 'What precautions are to be taken before and after gall bladder removal surgery?', \"What's the best way to cure gallstones?\", 'How can acid reflux after a gallbladder removal be treated?', 'Is gallbladder surgery outpatient?', 'What are some common remedies to remove a 3mm kidney stone?', 'What are treatments for prostate stones?', 'Which hospital or who is the best laprascopic surgeon for gall bladder removal in chennai?', 'How much does gall bladder removal surgery costs in india, considering the treatment is being done in a private hospital?', 'Homeopathy medicine for fall bladder stone?', 'Dissolve ureteral stones?', 'What is a home remedy for kidney stones?', 'Is there an effective home remedy for kidney stones?', 'Which hospital in Kolkata provides best treatment for gallstone?', 'What precautions should I take to take a flight after a gallbladder surgery?', 'Is it possible to reduce myopia without surgery or LASIK?', 'How painful are kidney stones?', 'What are ways to remove a deep splinter without going to the doctor?', 'How painful is kidney stone?', 'What are tonsil stones and how can I get rid of them naturally?', 'How do I remove urine out of a carpet?', 'How can I get rid of a urethral swab pain?', 'How do I remove hair without waxing them off?', 'What should normal gallbladder ultrasound pictures look like?', \"How can I shave my legs forever without surgery? And how can I let the hair's color become weak?\", 'What is the best way to remove a ring from swollen finger?', 'How can I fix my myopia without surgery?', 'How scared should I be of a 5mm gallbladder polyp found during a routine ultrasound?', \"What is the function of a frog's gallbladder?\", 'How can a man remove his pubic hair without hurting himself?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What was your most embarrassing experience?', 'positives': ['What’s the most embarrassing moment of your life so far?'], 'negatives': ['What is the most horrifying moment of your life?', 'What was the most horrifying moment in your life?', 'What are the most embarrassing moments you have had in your office?', 'What is the most embarrassing moment of your life when you were a kid?', 'What was the most frustrating moment in your life?', 'What was your most embarrassing moment on Quora?', 'What has been your most embarrassing moment as an athlete?', 'What is the most annoying moment of your life?', 'What is your most embarrassing injury?', \"What is the most embarrassing moment of your parent's life?\", 'What was the most frightening moment of your life?', 'What was the most traumatizing moment of your life?', 'What is the most embarrassing photo you have ever taken of others?', 'What are the most embarrassing moments in RGUKT?', 'What are some of the most embarrassing photos ever taken?', 'What is the most surprising moment of your life?', 'What was the most devastating moment of your life?', \"What's the most embarrassing thing that has happened to you on Quora?\", 'What is the most embarrassing moment faced by a male?', 'What is your most embarrassing moment during your childhood life?', 'What is the most painful experience of your life?', 'What has been the most horrifying experience of your life?', 'What was your most embarrassing moment during your school life?', 'What was the most embarrassing moment of your life as an IITian?', 'What is the most embarrassing moment of your childhood?', 'What was the most surprising moment of your life?', \"What is the most embarrassing thing you've done to your wife/husband?\", 'What is the most embarrassing moment from your teenage years?', 'What is the most shocking thing you’ve ever experienced?', 'What has been your most embarrassing moment from childhood?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Where can I get all types of legal advisory services for property transaction in Sydney?', 'positives': ['Where can I get quality support to make a successful property transaction process in Sydney?'], 'negatives': ['What will be the best place in Sydney to hire the services of a licensed conveyancer?', 'Where can I get best warehouse cleaning services in Sydney?', 'Where can I get a very efficient commercial cleaning service in Sydney?', 'Where can I get the best construction cleaning service in North Sydney?', 'Which company in Sydney offer quality services for waste removal?', 'Where can I get high quality fencing services in Sydney?', 'How reliable are property management service providers like renteazy or realtykart in Bangalore?', 'What are the best real estate websites in Australia?', 'Where can I get best monthly residential cleaning service in Sydney?', 'What will be the good towing company in Sydney?', 'What are the steps of property portfolio management services?', 'Where can I get best roof painting service in Sydney?', 'What will be the best place to buy wholesale meats in Sydney?', 'Where can I get very useful factory cleaning service in Sydney?', 'Where can I get best quality flooring services in Sydney?', 'Where can I get high-quality painting service in Sydney?', 'Where can I get high quality window cleaning service in Sydney?', 'Where can I get commercial pest control service in Sydney?', 'Where can I get affordable service in Sydney for cleaning and lubricating?', 'Where can I get best amenity room maintenance service in Sydney?', 'Where can I get best price rates for any commercial cleaning service in Sydney area?', 'Where can I found most professional and friendly photo booth services in Sydney?', 'Where can I get very affordable service for buying, selling, leasing or property management in Potts Point?', 'Where can I get the best waste clean-up services in Sydney?', 'Who provide best pest control service in Sydney?', 'Where can I get very reasonable price for commercial window cleaning services in Sydney?', 'Where can I find cheapest property in India?', 'Where can I get high quality asbestos removal services in Sydney area?', 'What are the top 5 mortgage brokers in Sydney?', 'Where can I get best services in Sydney for garage asbestos demolishing?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the differences between two actuarial science graduate programs in Waterloo university? Please compare the two programs from various aspects.', 'positives': ['What are the differences between two actuarial science graduate programs in Waterloo university? Please compare the two programs from various aspects.?'], 'negatives': ['Can you pursue two undergraduate study programs or degrees at the same time?', 'Details about UK based actuarial science examinations?', 'What is the difference between postgraduate and graduate?', 'What is difference between a degree and an undergraduate diploma?', 'What is the major difference between BSc Computer Science, BSc Information Technology and BSc Computing?', 'What is the major difference in work between a school student and a university student?', 'What are the differences between a science degree and an engineering degree?', 'What is the difference between university and institute of technology?', 'Actuarial science in USA? The entire system of actuarial study is different in UK and USA. While UK has around 15 levels, but in states, in 2 years with 5 exams you can get an MS degree in actuarial science.  What would be more preferable?  And please mention the universities too?', 'What is the difference between bachelor of engineering and bachelor of techonology?', 'What are some differences between American and European/British universities?', 'Which is the best between a BSc in computer science and a BSc IT?', 'What is the difference between a Bachelor of Engineering and a Bachelor of Technology?', 'What is the difference between B.SC Computer Science, B.Tech CSE and IT?', 'What are the main differences between physicists and engineers?', 'What is the difference between diploma and degree?', 'What is the difference between a degree and a diploma?', 'What are the differences between computer science engineering and information science and engineering?', \"How does the master's in computer science program at the University of North Carolina, Charlotte (UNCC) compare with Santa Clara University (SCU) in terms of campus, classes, faculty, location and job prospects?\", 'What is the difference between undergraduate, graduate and postgraduate? Are they all different between the U.S. and India?', 'What is the difference between postgraduate degree and postgraduate diploma?', 'What is the difference between Information technology and Computer Science & Engineering?', 'What is the difference between a bachelors and a masters degree?', 'Which one is a better deal in terms of curriculum, internships and placements, George Mason MSCS or Cincinncati ME in CS?', \"What are the main differences between a bachelor's and a graduate degree in computer science in terms of career prospects?\", 'What are the differences between computer science and computer engineering?', 'What is the difference between Computer Science,Computer engineering and Electrcial and computer engineering?', \"What's the difference between a degree in Computer Science & Engineering, a degree in Computer Engineering, and a degree in EECS?\", 'What is the difference between BSc physical science and BSc life science? What are their future scopes?', 'What is the difference between computer science and computer engineering? Can both interchange careers?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What does Shuster Hall mean?', 'positives': ['What does Shuster Hall means?'], 'negatives': ['What is the Deathly Hallows symbol?', \"What is the meaning of Bengali word 'Shudhu'?\", 'What does the Rosetta Stone say?', \"What does 'wallah' mean?\", 'What is the meaning of Jonathan Livingston Seagull?', 'What does \"que pasa hombre\" means and in what language it is?', 'What do the words in these houses mean?', 'What does \"shukran\" mean in Arabic?', 'What is \"Hank Moody\" style?', 'What is the meaning of the word \"arigatho\"?', \"How is 'Hobbes' pronounced?\", 'What does the expression \"keeping the wolf from the door\" mean?', 'What does the Arabic phrase \"hala wallah\" mean?', 'What is the abbreviation for \"starshina\"?', \"What is 'seeth' called in English?\", \"What is Marisa Tomei's middle name?\", 'What is Johann Denner known for?', 'What does high school mean to you?', 'What is the origin of \"Hoosier\"?', 'Nickname for shubham?', 'What does the word \"Bia/بیا\" mean in Pashto?', 'What is the Priory of Sion?', 'What does \"Jai Guru Deva Om\" mean?', \"What does it mean for Peter Thiel now that he's a part of Trump's transition team?\", 'What is the meaning of \"mera rang de basanti chola\"?', 'What does mAh mean?', 'What is the origin of the term \"Hoosier\"?', 'What does Brooke Shields mean by \"Want to know what gets between me and my Calvins? Nothing.\"?', 'What is the Rosetta Stone?', 'What does \"tu madre es puta\" mean in English?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Can anyone suggest me the best laptop under 35 k in India?', 'positives': ['Which is the best programming laptop under 35,000 in India?'], 'negatives': ['Which is the best laptop for CSE student in 30k. I  am also confused between i3 5th gen or i5 4th gen in this price range, is ASUS a good option?', 'Which is the best laptop brand in India?', 'Which are the best laptops of asus in range 30k-40k?', 'I am an architecture student from India looking to buy a laptop within a 50k to 65k rupee budget. What are some suggestions?', 'What laptop is cheap, portable and able to handle intensive programming for a beginning programmer?', 'Which are some of the best laptops to buy in India?', 'Which is the best mid budget laptop for a software developer in 2015?', 'What are the cheap laptops for programmer?', \"What's the best laptop I can buy as a CS student?\", 'What are the best laptops for programming?', 'What are the best cheap laptops for a programmer?', 'What is the coolest thing I can buy under Rs 3000 in India?', 'Which laptop is the best for computer science with a price limit of $2000?', 'What is the best way to invest $35?', 'Which is the best laptop in India with 4GB RAM, Intel i5 and a 2GB graphics card?', 'Which are the best laptops for CS students?', 'Which is the best laptop in India with 8GB RAM, Intel i5 and a 4GB graphics card?', 'Which laptop is best in the range of 50-60k for a engineering student?', 'I want to buy a new laptop. My requirement is i5 processor. Min 4 GB RAM and at least 500GB HARD DISC. My budget is around Rs 50000-60000. Which is the best laptop in these configuration and budget?', 'What is a 14-inch laptop under 32k which can (smoothly) run GTA IV?', 'What is a good laptop for programming?', 'Which is the best laptop to buy under 60k in India?', 'Which laptop is best suitable for computer engineering students?', 'What are the minimum requirements of a laptop for running MATLAB smoothly ?', \"Which will be the best arranged computer hardware under 50k in India in which softwares like 3d max and Stadd pro won't face a problem?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How was the best date you ever had?', 'positives': [\"What's the most amazing date you've ever been on?\"], 'negatives': [\"What is the weirdest date you've ever been on?\", \"What was the worst date you've ever been on?\", 'What is the weirdest date you have been on?', 'Okay. What was the absolute worst date you ever went on?', 'What was the weirdest date you ever experienced?', 'What was the most awkward moment you have ever experienced on a date?', 'What is your most embarrassing experience while on a date?', \"What's the most embarrassing thing that happened to you on a date?\", \"What's the weirdest first date you ever had?\", 'What was the weirdest first date you have ever had?', 'What would it take to date you?', 'How did you feel on your first date and when was it?', \"What's the most akward moment you ever had?\", 'What has been your best sexual moment?', 'What is a good idea for your first date ever?', 'What is the most successful dating site in the world?', 'What does it feel like to date a famous person?', 'What is a great date for a 6-month anniversary?', 'What are your favorite date ideas in California?', 'What was your weirdest dating experience?', 'What is your most memorable sexual experience?', 'Have you ever been on a date with someone you really liked and they said or did something to completely turn you off forever?', 'What is the most amazing moment of your life?', 'What are your favorite date ideas in Kansas?', \"What is the most romantic conversation you've ever had?\", 'Have you ever got yourself a date through Quora?', 'What was your most interesting moment in your life?', 'What are your favorite date ideas in Oregon?', \"What is the best sensation you've ever had?\", 'What was the most interesting moment of your life?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the best way to reduce belly and arm fat?', 'positives': ['What should I eat to get rid of belly fat?'], 'negatives': ['Why did I get a belly fat?', 'Will quitting rice help in losing belly fat?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I track a person basing on his mobile phone?', 'positives': ['Can I track a person and his mobile online?'], 'negatives': ['How can I track someone by his license number?', 'Is it possible to track someone remotely through GPS on his phone without his knowledge and without installing any software on his phone?', 'How can you track someone by LINE?', 'Is there a way to follow or locate someone using Android phones without using an app?', 'Is it possible to track a lost Android mobile based upon your IMEI number if your phone is switched off?', 'What are some ways to track a switched off mobile after it is lost?', 'Is it true that the location and mobile number of a Quora user can be found and traced in person?', 'What is the best app for mobile number tracking?', 'Can you find someone by their phone number?', 'Is it possible to track a mobile (high-end mobiles like Galaxy S5 and Note 3) when it is switched off and the battery is removed?', 'How do I check if a mobile number is active or not?', 'How do I find Location of a person using their WiFi MAC address?', 'What mobile operator provides a fancy mobile and my own choice number at a cheap price?', 'Track my other LG phone that has metro pcs carrier and no tracker app loaded?', \"How can I track someone else's Skype messages?\", 'How do I find a lost mobile in India?', \"How do I track my wife's cellphone GPS without loading an app on it?\", 'Can I find out where someone is by their phone number?', 'My Samsung Galaxy S4 was stolen yesterday. I was using a Vodafone mobile number. What is a way to track down the mobile or know where it is?', 'Does the Android Device Manager app use the internet on a device that you are locating?', 'How can I find out where somebody is by their phone number?', 'How do I find out if someone else is using my phone number or data?', 'Can someone find my IP address from a mobile chat?', 'Can someone track you down if all they know is your phone number and your first name?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why is Saltwater taffy candy imported in Czech Republic?', 'positives': ['Why is Saltwater taffy candy imported in Mongolia?'], 'negatives': ['Is salt a consumer product?', 'What makes salt salty?', 'Why salt is salty?', 'Why is Bacon imported in Mongolia?', 'Why does common salt make food taste better? What happens to the food?', 'Why does China import Japanese sea salt?', 'How is cotton candy made?', 'Why do people put salt in beer?', 'What are some of the saltiest foods and why?', 'What is cotton candy made out of?', 'What is Himalayan pink salt? Why is it better?', 'Why is cooking salt called table salt?', 'What is the pink thing in udon soup?', 'Which salt is used in washing soap?', 'How is Boton Rice Candy made?', 'Is salt a mineral?', 'Why can salt be bad for you?', 'What are the healthiest and best tasting types of salt you can buy that are mined and not chemically processed or extracted from the sea?', 'What is the meaning of salt?', 'Why salt is added to water for oral rehydration?', 'What are the uses of celery salt?', 'Why is throwing salt considered of bad luck?', 'What are the uses for celery salt?', 'What is the best candy in your country?', 'Can you substitute water for milk in Jiffy cornbread? Is it advisable?', 'Why should salt be added to water for oral rehydration?', 'Is salt really bad for you?', 'Is it true that Pakistan imports salt from India?', 'What is the gelatin of Haribo gummies made of?', 'What are non-iodized salt brands?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the best way of loose the weight?', 'positives': ['What is the fastest possible way to lose weight?'], 'negatives': ['What are the best ways to put on weight?', \"I'm 13 and I'm 115 lb and I hate it, every time I look in the mirror I feel sick, anyone got any advice on how to lose weight, I'm so desperate…?\", 'How can I put on weight?', \"I'm 5'2 and 130 pounds. I've dealt with body issues all my life and tried losing weight the past month with no changes. What can I do?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Will we have another recession?', 'positives': ['Will there be another recession soon?'], 'negatives': ['Is there a recession coming in 2015-16?', \"I heard there's a recession in the world after every 8 years. Is it true?\", 'When can the next recession be expected in UK?', 'Is the US heading into recession?', 'Are we headed for a recession in the United States in 2016?', 'Are we headed for a recession in the US?', 'When will the next recession be within the UK and what will trigger it?', 'What is recession?', 'How is a recession characterized?', 'What is global economy recession?', 'Do you see a balance sheet recession?', 'Is it true that another recession will hit the IT sector by the end of 2014?', 'Why is it so hard to get jobs? When will the global recession end?', 'Will many startups get us out of the recession?', 'How did the 2008 economic recession happen?', 'How can recession match with the gross domestic product of an economy?', 'Is nigeria in a recession?', 'Do you think recession is affecting your business?', 'How is the American employment these days? Is it really out of recession?', 'How do recessions affect businesses?', 'Is Nigeria really in a recession?', 'Where the next financial crisis will come from? Where is the next bubble?', 'What are good signs that an economic collapse might happen?', 'How can government get an economy out of a recession with fiscal policy?', 'Will the American economy collapse?', 'How likely is a world economy crash?', 'Will there ever be a global economic collapse?', 'How does recession match with gross domestic product?', \"What is the effect of recession on banks' interest rate; does it cause interest to go up or come down?\", \"In the process of deindustrialization as a country's economy moves from manufacturing to service sector, does it go through recession?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How cold can the Gobi Desert get, and how do its average temperatures compare to the ones in the Chihuahuan Desert?', 'positives': ['How cold can the Gobi Desert get, and how do its average temperatures compare to the ones in the Gibson Desert?'], 'negatives': ['How much power does a big desert air cooler consume?', 'What is the Sahara, and how do the average temperatures there compare to other deserts?', 'What is the biggest desert in the world?', 'How cold can Mongolia get?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Gibson Desert?', 'What is the best way to turn desert into rain forest?', 'Which is the biggest desert in the world?', 'How does a meerkat adapt to the desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Simpson Desert?', 'How have meerkats adapted to the desert?', 'Which in the best bike desert storm or Himalayan. I m gona buy in next 3 months?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Namib Desert?', 'Is it possible to turn an entire desert into a lush green rain forest?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Arabian Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Thar Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Registan Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Mojave Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Chihuahuan Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Dasht-e Loot?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Great Basin Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Kalahari Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Karakum Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Great Sandy Desert?', 'How do inland deserts form? How are they different from other deserts?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Great Victoria Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Syrian Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Taklamakan Desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Sonoran Desert?', 'Has Rajasthan always been a desert?', 'What is the Sahara, and how do the average temperatures there compare to the ones in the Dasht-e Kavir?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which are the positive benefits of banning existing ₹500 and ₹1000 currency notes in India?', 'positives': ['What are benefits of change in ₹500 ₹1000 notes?'], 'negatives': ['How does the elimination of Indian 100 rupee note ($6.00 USD) affect daily life?', 'Uses of change in currency in India?', 'Will the demonetization of 500 and 100 rupee notes affect restaurants?', 'How does the change in Indian currency affect Indian economy?', 'What business can be started with ₹5000?', \"If changing from $1 bill to coins would save $4.4 billion over the next 30 years, why isn't the change made? What is the disadvantage of having $1 coins?\", 'Do you think the 2000 rupee notes will increase black money?', \"What will be benefit to us with modi's Gold scheme?\", 'What are the advantages and disadvantages of currency appreciation?', 'How important is RAM for new computers and laptops today?', 'Can people change Rs 500 and Rs1000 notes in Bitcoin?', 'How the sudden currency exchange going impact India?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What will be repercussion of India's surgical strike to Pakistan?\", 'positives': [\"What are the consequences of India's Strike in PoK?\"], 'negatives': ['What do the Dalits have to say about the surgical strike in POK by the Indian Army?', \"Do you think India's surgical strikes across LOC has put India in danger of another big terrorist attack?\", \"How is the Indian Army's surgical strike in Uri in September 2016 different from the anti-insurgent operation in Mynamar in June 2015?\", 'Did India provide any evidence for the claimed surgical strike?', 'What would happen if IS attacks India?', 'Why are the trade unions and banks organizing a nationwide strike on September 2 in India?', 'What can be the reaction of India after the recent Uri attack?', \"What will happen in today's scenario if India gets attacked by Pakistan and China at the same time?\", 'Does India have the capabilities to carry out surgical strikes in Pakistan?', 'Why is the Indian government not releasing proofs of the surgical strikes in PoK?', 'Was the surgical strike in PoK made against militants or the Pakistan army?', 'Why is the Indian government not releasing proofs of the surgical strikes in PoK? (Read details)', 'What is the greatest surgical strike conducted by a country till now in world history?', 'What are the problems faced by people in the Indian Armed Forces?', 'What are the effects of unemployment in India?', 'Why is Indian Government not hitting back to terrorist (eg. airstrikes in POK) with all the Strength after Uri Attack?', 'What issues are there in India?', \"Has any foreign media or intelligence agencies confirmed India's surgical strikes on Pakistan's side of the LoC?\", 'Has India done surgical strike before?', 'Are the recent surgical strikes by Indian Army in Pakistan the first such operation by the Indian Military?', 'How can you confirm that India conducted surgical strikes in Pakistan?', \"Was the aggressive diplomatic shift (refering to open support to Baluchistan people by Indian PM) necessary? Does it worsen India's claim on POK?\", 'What is the latest fad among IT employees in South India?', 'How can the effects of unemployment in India be reduced?', 'Are the recent surgical strikes by Indian Army in Myanmar the first such operation by the Indian Military?', 'What are the problems faced by India today?', 'What are the risks of contract based government jobs in India?', \"What has been Myanmar's reaction to the surgical strikes conducted by India against militants in Myanmar without informing Myanmar?\", 'What is the main problem faced by India?', 'How will salaries be affected by the 7th Pay Commission?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I download videos from hotstar?', 'positives': ['How do I download hotstar videos using Personal Computer or Laptop?'], 'negatives': ['How do I convert hotstar downloaded video to MP4 video?', 'How do I download a video from any website?', 'How do I download all the videos from a website at once in Ubuntu?', 'How can I download videos from several websites?', 'How do I download videos in smartphone?', 'How can I download any video from any websites?', 'What are the best ways to download videos from YouTube on a Windows phone?', 'How do I download videos from YouTube using UC browser?', 'How do you download videos hosted in Livestream?', 'How do I download videos from www.myvidster.com for free?', 'How do you download a video from a website, regardless of the video player?', 'What is the best way to download a video from YouTube, Facebook, or Vimeo?', 'How do I download videos from Google Drive on to my camera roll?', 'What do I need to download streaming Silverlight video on a Mac?', 'Is it possible to download videos from twitch.tv?', 'Which is the best software for PC to download videos from any website?', 'How can I download Tumblr videos on my phone?', 'How do I download a video which is played in a web page by brithcove.com platform or flash player?', 'Is there a way to download videos from Facebook and Youtube?', 'How can I download video from youtube?', 'How do I download or save a YouTube video to my computer?', 'How can I download videos from this page?', 'How do I download Facebook videos?', 'How do you download movies from Google Play to a PC?', 'How do I download videos from a website on an iPad?', 'How do I download video from copyright sites?', 'How do I download youtube videos?', 'How do I download YouTube videos?', 'How could I download a video from any website in a single click without a lot of effort?', 'How do I download videos from oliveboard.in?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Will Westworld be a new hit HBO series based upon what we saw from the trailer?', 'positives': ['What do you think of the new Westworld Trailer?'], 'negatives': ['What\\'s your review of Episode 5 of Westworld (\"Contrapasso\")?', 'Has anyone seen the original Westworld (1973)? How does it compare to HBO’s reboot?', 'What do people think of TheWorld365.com?', 'What is your review of Westworld season 1 episode 10?', 'What is your review of the Westworld season one finale (“The Bicameral Mind”)?', 'Should I watch Westworld?', 'What are your predictions/theories for Season 2 of Westworld?', 'What will Westworld Season 2 cover?', 'How does Westworld (TV Series) compare to the original movie?', 'What do you think of the new Mummy (2017) trailer?', 'What is your review of Episode 2 of Westworld, entitled “Chestnut”?', 'What is Westworld in HBO series Westworld?', 'Is Westworld on an island?', 'What do you think about Befikre trailer?', 'What do you think about the trailer of Jagga Jasoos?', 'What do Wonder Woman fans think of the new trailer released at Comic-Con 2016?', 'Why is Westworld episode four titled Dissonance Theory?', 'How do the characters actually get into Westworld?', 'What are your views on new Wonder Woman trailer?', 'What do you think about the movie Interstellar?', 'What do you guys think about this movie? \"Interstellar\"', 'What did you think about Stranger Things season 1?', 'What do you think about the movie, \"Interstellar\"?', 'Is Freshersworld any good?', 'Where can I download Westworld TV series?', 'What are some reviews about the Mohalla Assi trailer?', 'When is it likely when the next trailer for Kong Skull Island to be released?', 'What is your review of SeaWorld Parks & Entertainment?', 'What do you think of the new iPhone7 Airpods?', 'Who is the spy within Westworld?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the best way to stay in the right weight?', 'positives': ['What are some of the best ways to maintain your weight?'], 'negatives': ['Which are the best ways to lose weight?', 'What are the best ways to lose weight?', 'What are the best ways to lose weight?', 'What are the best ways to lose weight?', 'What are the best ways to lose weight?', 'What is my weight?', 'What are the best way of loose the weight?', 'I am 29 years old with a height of 5\\' 09\" and weight 92 kg. How to reduce my weight?', 'What are the best was to lose weight?', 'What is weight?', 'I have gained a lot of weight AGAIN because of my hectic study routine and approaching exmas. I feel less confident. What to do to reduce my weight?', 'How do I stop being fat?', \"I'm 13: What is the best way to lose weight?\", 'Why do some people struggle with weight?', 'What is weight/weight?', 'How do I calculate equivalent weight?', \"Am I fat? I weigh 200 pounds and I'm 5'7\", 'I\\'m 14, 5\"3 and weigh 117 pounds and want to create a strict diet plan to lose weight. How do I do that?', 'How do I maintain my diet in my hostel?', 'I lift heavy often. How should I eat and how much cardio do I need to lose a little weight?', \"After losing 46 pounds I am obsessed with trying not to gain weight. My parents are worried for me and think that I'm too skinny. How can I maintain my weight without gaining?\", 'Can anyone motivate be to loose my weight?', \"I'm underweight & don't put on weight easily. I'm 6ft & my body frame looks like skin hanging on to a skeleton. Any suggestions on how do I bulk up?\", 'I am an obese person doing the job of uncertain hours. How I can loose my weigh? Please reply fast', 'How can you experience weightlessness?', 'How do I lose 30 pounds and keep it off?', 'Am I overweight?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"Does 'TIME' have an origin?\", 'positives': ['Does time have an origin?'], 'negatives': ['What actually is time?', 'What is the meaning of the term time?', 'Are there any simple explanations of what IS time?', 'Do we really understand time?', 'Is time a human creation for the purpose of measurement or is time an actual physical property of the universe?', 'Is time relative?', 'Is time a vector?', 'What does the phrase \"time to time\" mean?', 'How much do we understand time?', 'Why is time relative?', 'Is time a vector? Why or why not?', 'Is time a merely social construct?', 'What is meant by Time travel?', 'Is time cyclical?', 'What is a time?', 'What is timee?', 'Does time stops?', 'Is time a vector quantity? Why or why not?', 'How do we time travel?', \"Why can't we time travel?\", 'What if \"time\" doesn\\'t actually exist?', 'What is Time paradox?', 'Does time travel at the speed of light?', 'What is time? Why we are so bound with time?', 'Can we time travel?', 'What do you think is meant by time travel?', 'What defies time?', 'What is time travel theory?', 'Is timetravel possible?', 'What is the opposite of time?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the best method of learning to speak a language?', 'positives': ['What is the best method to learn new language?'], 'negatives': ['What are the best sites to learn new Indian languages?', 'What do you think is the easiest foreign language to learn and why?', 'What are some of the easiest languages to learn?', 'What do you think the easiest language to learn is?', 'What is the easiest spoken language to learn?', 'I want to learn Italian and Japanese. Which one should I tackle first? What are some good tips for beginners learning a new language?', 'How do I learn Natural Language Processing?', 'I want to learn a foreign language. Which language is easier to learn: French, Spanish, Polish, Italian, or German?', 'Is Duolingo the best and quickest way to learn a new language or is something better available?', 'Is there any possibility to learn three different languages well?', 'What is the most effective way to learn the French language?', \"Why shouldn't you learn another language?\", 'What is the most interesting language to learn?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How many states in America wanna be independent?', 'positives': ['How many states in America want to be independent? And why?'], 'negatives': ['What would happen if each state in the U.S. suddenly became an independent country?', 'Which is the most independent country?', 'How many states are there in the world?', 'How many states are there are in the world?', 'How many states are there in USA?', 'Does the United States have too many states?', \"What's the purpose of having a whole country when its states can function independently and are large enough to be countries of their own?\", 'Is it better to have united states or divided states for the development in any country?', 'How many states are there in the United States?', 'Will the US ever add another state?', 'How and why has the United States become so divided politically and socially?', 'How many states were there in India at the time of independence?', \"If America was to annex a country as it's 51st state, which one should it be?\", 'Is India an independent country?', 'What was the first independent country in the world?', 'What are the main reasons for some Pacific states and territories to opt for “lesser degrees of independence”?', 'Do Americans believe that the USA is a free state?', 'Will the U.S. ever add a 51st state?', 'U.S. Political Parties: Should the United States be split into two countries, one for Democrats and one for Republicans?', 'India how many states?', 'How India become independent?', 'Can two or more neighboring countries become a single country if the majority of people and the governments support this?', \"Given the Electoral College system, and wide state autonomy in certain matters, shouldn't the US be considered a federation rather than a country?\", 'Would California be more successful as an independent country rather than as a state?', 'Is the United States of America a republic or a democracy?', 'Has America divided since the election?', 'What countries or sovereign states are republics?', 'How many states are there in India?', 'Would India be better if it divided up into smaller manageable independent states?', 'How might I go about making my own independent country?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Who will win the US elections 2016?', 'positives': ['Who do you think is going to win the presidential elections and why?'], 'negatives': ['Which candidate in the 2016 U.S. presidential election do you support?', 'Will you vote (or not) in the 2016 US presidential election? Why?', 'To those outside of America: If the current US presidential election candidates (Obama Vs. Romney) were running in your country who would you vote for and who do you think would win?', 'Can presidential candidates vote?', 'Can you tell who is going to run for President by seeing how actively they campaign for people during the previous midterm elections?', 'Who votes in the Democratic and Republican Party primaries to determine presidential candidates in the USA?', 'In your opinion, will the Republican Party ever win a presidential election again?', 'Is there really a chance for a third-party Candidate to win the election in 2016?', 'How well could third party candidates do in the upcoming (2016) U.S. presidential elections?', 'We have two presidential candidates that are highly scrutinized, do you think our votes really determine who becomes president of the United States?', 'What happens if both presidential candidates get 269 votes? (USA)?', \"What does it take to win the U.S. Presidency if you're not running as a Democratic or Republican Candidate? Is it even possible to win?\", 'Who is going to be the first candidate to declare for the 2016 presidential election?', 'What percentage of votes in the 2016 U.S. Presidential race will go to third party candidates?', 'Will Republicans ever win the presidential elections again?', 'On the presidential ballot, do you have to choose a candidate for every other office, or can you leave those blank?', \"Why don't third party candidates have a realistic chance in U.S. Presidential elections?\", 'Who are the top candidates for US presidential election in 2020?', \"What's your prediction for the 2020 election?\", 'If all 43 U.S. Presidents were to run for office in 2016, who would win? Also, who would be best suited to deal with the current issues?', 'What happens if there are more than two presidential candidates in the US?', 'Who would you like to run for president?', 'If all the previous U.S. presidents were alive and running for office in 2012, who would win?', 'According to your prediction, in how many constituencies will the winning margin be less than 1000 votes? And in which constituencies do you predict it will happen?', 'Should I vote in the 2016 US presidential election?', 'What would happen if an independent presidential candidate beats out the Republican and Democratic candidate but fails to win enough electoral votes to secure the presidency?', 'Why should I vote for your presidential candidate choice?', 'Why should I vote for you in the presidential elections?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the best way to write algorithms?', 'positives': ['How do I write an algorithm?'], 'negatives': ['How would I implement an algorithm using code?', 'How do I write an algorithm to find x^y?', 'What is algorithms?', 'List of algorithms?', 'How do I create an algorithm with a spreadsheet?', 'How do I become an expert in algorithms?', 'Which is the algorithm for studying algorithms?', 'How do I learn algorithms quickly?', 'What are computer algorithms?', 'Why should I study algorithm?', 'Why should I learn algorithms?', 'Which is the most delicate algorithm to implement?', 'How do I improve my mathematics for algorithms?', 'How do I explain algorithms to a 10-year-old kid?', 'How can I practice algorithm problems by topics?', 'How are computer algorithms developed?', 'What are the 10 algorithms one must know in order to solve most algorithm problems?', 'How can I learn algorithms and data structures?', 'How do I perform research in algorithms?', 'Where/how can I submit solution to algorithm problems on TopCoder?', 'How can I implement an algorithm in Hadoop which can be something like LATE algorithm?', 'How do I implement an algorithm on FPGA?', \"How do I learn algorithms when I don't understand any of the CLRS algorithm book's mathematical parts?\", 'Explain an algorithm to evaluate a n degree polynomial at a, -a, ia and -ia?', 'What is the best way to start learning algorithms for a non-programmers?', \"What do you do when you can't find a solution to an algorithms problem? And what do you do when you read the solution?\", 'How should one start learning Algorithms?', 'What are algorithms useful for?', 'How do you approach and solve complex coding or algorithm problem?', 'Where can I learn about algorithms and data structures efficiently?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How would scrapping Rs 500 and 1000 notes affect the real estate sector?', 'positives': [\"How do the real estate prices get affected by the Indian Government's decision to de-monetize 500 and 1000 notes?\"], 'negatives': ['Are real estate prices going down in 2014?', 'What effect will rising interest rates have on the commercial real estate market?', 'How is the price of real estate determined?', 'What is the real estate trend in India?', 'Why has real estate in the US become so expensive?', 'What is real estate new trends in India?', 'Will real estate price in Pune go down in upcoming couple of years?', 'Will the real estate price go down in Pune?', 'Are property prices finally going down?', 'Why are real estate prices so high in metros (India)?', 'Which localities in India have the highest real estate prices?', 'How do I analyze real estate markets?', 'Has there been any price drop in the Indian real estate market post demonetization?', 'How much has real estate prices increased in Sofia, Bulgaria within the last 5 years?', 'What are the risks associated with foreign investments in commercial real estate in Vietnam?', 'How is Airbnb changing real estate prices?', 'What is the future of real estate in India?', 'Are governments of countries with tear-away real estate speculation irresponsible, by not imposing substantial levies on foreign purchasers?', 'As of July 2015, what restrictions are there in Australia on foreigners (non-citizens) purchasing residential real estate in Australia?', 'What area or city in the US is likely to increase most in real estate values in the next, say, 5 years?', 'What are the pros and cons of real estate investing?', 'How do I price real estate products?', 'How does real estate work?', 'Why is the U.S. real estate marketplace going down in 2015?', 'How do real estate sites make money?', 'Financial terms used in real estate?', 'What rate of return can I expect on real estate in Canada?', 'What are the main challenges selling to real estate agents?', 'How do I make a million off real estate?', 'Would it be smart to use profits from my e-commerce store to start investing in real estate?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do you download photos from iCloud?', 'positives': ['How do you retrieve photos from iCloud?'], 'negatives': ['How do you view your iCloud photos?', 'How can I bring my photos back if I signed out of iclouds?', 'How do I view iCloud photos on a PC?', 'How do I delete photos from the icloud but still have them on my iPhone?', 'Can you delete pictures from an iPhone and still have it saved in iCloud? If so, how?', 'How many photos to be transferred to iCloud?', 'How do I automatically backup iCloud photo to iCloud Drive?', 'How do I recover deleted iCloud backup?', 'How do you save pictures on iCloud from iPhone and make sure all pictures have saved from iPhone before deleting?', 'How do you know if your photos on icloud are downloading?', 'How do I extract messages from iCloud backup?', 'How do I Bypass icloud on stolen iphone?', 'How do I delete photos/videos from my iPhone 6s and not off my iCloud storage?', 'How do you delete files on iCloud?', 'Using iOS 9,I have completed all the settings to use icloud, took my photos backup on my iphone, how can I see/access those photos in icloud?', 'What do iCloud backup from an app?', 'Can I delete photos off iPhone but not iCloud?', 'How can I delete photos from my Mac but keep them in iCloud?', 'How do I access my iCloud mail?', 'How do you get iCloud on your iPhone 4?', 'How do you verify your iCloud account?', 'How do I verify an iCloud account?', 'How do I recover my iCloud password?', 'How do I find my iCloud security code?', 'How do I recover photos from Photo Locker app?', 'How do I download videos from iCloud to my iPhone?', 'Can I remove an iCloud account?', 'How can I delete iCloud?', 'How can I bypass iCloud lock?', 'How can I delete a file from the iCloud directory from my computer without deleting a file from iCloud?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What can one do after MBBS?', 'positives': ['What do i do after my MBBS ?'], 'negatives': ['What should be done after MBBS to become a cardiologist?', 'Why should I go for an MBA after an MBBS?', 'How do I prepare for MBBS first year?', 'How do I know whether I want to do MBBS or something else?', 'Preparation before joining mbbs?', 'Can we do a MBBS after completing engineering graduation (BE)? Is it possible?', 'Do you regret choosing MBBS?', 'What are the possible career options in the USA after completing MBBS in India? If nothing, then what are the subjects that I can study after clearing the GRE and start a career there?', 'What is the full procedure to do research while doing MBBS 1st Year?', 'How should I study in MBBS?', 'What are some common mistakes which MBBS aspirants do?', 'How is life after MBBS from AFMC?', 'Should I drop one more year to prepare for an MBBS?', 'How should I study first year MBBS?', \"I've recently joined MBBS. I'm panicking as hell about how to study, the right material, everything. Really need guidance. How should I handle this?\", 'What can an MBBS student study before joining?', 'How do we go for a research while studying mbbs?', 'Is it okay to do MD in sexology after completing MBBS?', \"How do I get into AIIMS to pursue an MBBS? I'm an above average student. What are some tips?\", 'How do I do PG in medicine in USA after MBBS in India?', 'What are the final year subjects of MBBS?', 'How can I keep my future MB Pro safe?', 'What pay can one get after finishing mbbs in India on working abroad?', \"I'm November 1996 born and I dropped a year for mbbs. Should I take another drop?\", 'How do I study MBBS with encouragement?', 'What is the study experience of MBBS students?', 'What is the long form of MBBS?', 'What are some study plans for the MBBS 1st year?', 'What is expected cutoff for AMU MBBS for internal student?', 'If I do MBBS and MD from USA howcan I help full?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I prepare for civil services?', 'positives': ['How can I prepare for civil services exam?'], 'negatives': ['How do I prepare for the civil service exam without coaching?', 'What is the best way to prepare for Punjab civil services exam?', 'How can an engineering student (first year) prepare for a civil services exam (UPSC/IAS/IPS)?', 'How should one prepare for the UPSC civil services exam during his/her final year of B.Tech?', 'What are the best books for preparation of Civil Services examination?', 'Is it possible for me to crack civil services exam 2017 if i start preparing from today onwards', 'What is civil services exam procedure?', 'What is civil services exam?', 'What is civil service exam?', 'How should I start preparing for polity for the Civil Services Examination 2016?', 'What are the best books to prepare for civil services?', 'What are the chances of cracking the civil services exam?', \"How should I start my preparation for Civil Services Exam 2017 if I don't want to join any coaching classes? What study method should I adopt?\", 'How can I start my civil services UPSC exam (IAS) preparation without attending any coaching classes?', 'Can anyone clear upsc civil services exam with 6 months of preparation?', \"What's the best strategy to crack UPSC Civil Services Exam 2016 in 7 months starting preparation from January 2016?\", 'What are the chances to crack the civil services exam for an average student?', 'How was your upsc civil services exam interview experience?', 'Should I start my preparations for civil service exam from first year of engineering?', 'Are there any successful candidates who started preparing late (after the age of 28) for the UPSC Civil Service Exam and cleared it?', 'What is the best app for civil services examination?', 'I am working in an IT company, and I am preparing for the civil service exam. However, I am very tensed because of my body height which is only 5 feet. Am I perfectly eligible for the civil service exam?', 'How do I start preparing for civil services in first year of engineering?', 'What are some good coaching centres for Civil Services Examination in Chennai?', 'Can an assistant at the MEA India, selected through the SCC-CGL exam, apply for the UPSC Civil Services Exam (IFS)?', 'What is the current upper age limit to write the civil service exam?', 'What is meant by the qualifying paper in the UPSC civil services exam?', 'How should one prepare for Science and Technology for UPSC exams?', 'How do I get notes of Vajiram, VisionIas or other elite coaching classes for civil services preparation?', 'UPSC CSE 2016:How should one prepare Ancient India & art and culture for upsc civil service examination?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Can I upload part of anime videos on YouTube and monetize it without copyright issue?', 'positives': ['How can I upload anime on YouTube without copyright issue?'], 'negatives': ['Do I need copyright permission before uploading a cover of a Bollywood song on YouTube?', 'Can I use videos from YouTube on my blog as examples or do I need to ask the permission of the original uploader?', 'Is there any good torrent website to download anime (dubbed)?', \"Can I upload gaming videos (On Youtube) for a profit (I'm worried about copyright issues)?\", 'Is there any app that allows you to download anime?', 'How do I get copyrights of songs already uploaded on YouTube?', 'How would you promote animated videos on Youtube?', 'How can I legally remix a song and upload it to YouTube?', 'What if someone added lyrics to my song and put it on YouTube as theirs. How do I copyright it?', 'Do I need permission from the copyright owner to do a cover on YouTube?', 'Can I upload videos to my own website after downloading them from youtube?', 'What is the best site to download anime torrents?', 'Can I monetize on YouTube by uploading third party videos?', 'Which is the best site for downloading anime?', 'What are some ethical and legal ways to download a YouTube video?', 'Is it legal to make prank videos and publish on YouTube?', 'Where can I download raw anime (Without subtitles) for free?', 'What is the best way to upload an audio file to YouTube?', 'What are the best sites to download anime?', 'What are some of the best sites to download anime torrents?', 'Can unboxing mobiles on youtube videos will give me a copyright strike?', 'What is the easiest way to upload audio alone to YouTube?', \"Is it copyright infringement to use pictures of cartoon characters on social media without the owner's consent?\", 'What is the best app to download anime?', 'How do you upload gameplay videos to YouTube?', 'Which is the best app to download anime?', 'Is there any app that downloads anime?', 'How can I download anime on my phone from kissanime.com?', 'What is the protocol to upload a video onto YouTube?', 'What is the legal way to download a youtube video?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I find a GOOD therapist that specializes in attachment theory/attachment issues?', 'positives': ['What is the best way to find a good therapist at my school?'], 'negatives': ['What are you looking for an a therapist?', 'What do you look for in a therapist?', 'Is it good to have a therapist?', 'Do I need to see a therapist or a psychologist?', 'How do I succeed in seducing my therapist?', 'How do I decide whether I need a psychologist or therapist or psychiatrist?', 'How do I become a physical therapist?', \"What's the best school for massage therapy?\", 'My mom wants me to be a doctor, but I want to be a therapist. What should I do?', 'What is the best way to find a mentor?', 'Can a psychopath become a good psychiatrist?', 'If you get a bachelors degree in social work can you go on to become a therapist when you get your masters?', 'How do I look for a really good psychologist In Delhi?', 'Is it possible for someone with chronic mental illness or a personality disorder to become a good psychologist?', 'What is the best way to find a good doctor?', \"Should I tell my parents I'm depressed and want to see a therapist?\", 'What is the best way to go about getting a mentor?', 'Do therapists have therapists?', 'What are some websites providing free therapist services?', 'What is the best way to find mentors in life?', 'How do I become an occupational therapist?', 'Where can I find a good psychologist in Delhi?', \"Why doesn't everyone see a therapist?\", 'Is it normal to see a therapist?', 'What is the best way to get accepted into an orthopedic physical therapy fellowship as a newer therapist?', 'What are the best books on therapy that every therapist should read?', \"Can I tell my therapist I'm a sociopath? I'm also a parent and take good care of my daughter but wouldn't want them calling cps\", 'What does a Physical Therapist do?', 'How do you find a good doctor?', 'How can I find a career mentor?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'If wealth in the United States were equally distributed how much would each person be worth?', 'positives': ['If all the wealth in the US were divided equally among adult citizens, how much would that be, per person?'], 'negatives': ['How much money does the average person in the US spend over their entire life?', 'What percentage of the world population has a net worth of $1,000,000 or more?', 'How many people earn $500,000+ per year in the USA?', 'How much money does the average American make in their lifetime?', 'What percentage of individual Americans (not households) make more than $250 000 per year?', \"What percentage of money that we (the average industrialized countries' citizen) spend on daily things (food, rent, everything else) goes to profits?\", 'What is the percentage of the US population that will die, having never traded a single option in their lifetime?', 'What is the net worth of the USA?', 'How much is the average income per age in the U.S.?', 'Out of every demographic group of people, which is the most privileged in the US?', 'How much can the average person earn in his or her whole life? 1 million, 2 million?', 'How much money do you need to live comfortably in America?', 'What is the weighted average income in the United States?', 'How much salary is enough to live comfortably in America?', 'Which ethnic group has the highest per capita income in US?', 'What is a good amount of money yearly to live more than comfortably in the USA?', 'How much does the government spend on each IITian on an average?', 'How come wealthy areas have surprisingly average per capita incomes?', 'Who are the most privileged people in the US?', 'How much money is enough for comfortable life in the US?', 'What net worth puts you in the top 2% and 5% of families in the United States?', 'How many people are in the US?', 'Realistically, how much money will an American need to make every year in order to live a happy life with at least a slight abundance of cash?', 'What is it like to be 1 percent rich in america?', 'How many Americans earn over $100,000,000 a year?', 'Is the US the richest society that has ever existed?', 'Which country has the least inequality in terms of wealth distribution among its citizens and how has it managed to do so?', 'In America, the richest 20% control over 80% of the wealth. Is this unjust? Why?', 'How much tax do a non resident earning 60000$/annum have to pay in USA?', 'What is the cost of living in USA?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the new schemes under rural development in Chhattisgarh?', 'positives': ['What are the new schemes under panchayat and rural development in Chhattisgarh?'], 'negatives': ['What are the various Yojana in Chhattisgarh?', 'What are the Yojana in Chhattisgarh?', 'Are there gram panchayats in New Delhi?', 'What is the role of the urban development department of Chhattisgarh?', 'What is role of urban development department in Chhattisgarh?', 'What are the sarkar Yojana in Chhattisgarh?', 'Can panchayat approve layouts for residential use (land is agricultural and not DC converted, location Bangalore)?', 'How are gram panchayat elections run?', 'What is the IT policy of Chhattisgarh?', 'What NGOs work on agriculture in Himachal Pradesh? Which work on the problems faced by farmers in Himachal?', 'What is UJJWALA YOJANA in Chhattisgarh?', 'What are the Policy Support in Chhattisgarh?', 'Why is Panchayati Raj essential?', 'What are all the sources of funds for gram panchayat?', 'What are the new amenities in Naya Raipur?', 'Is the Panchayati Raj system really strengthening our democracy, or helping the corruption expansion at the grassroot level?', 'What is the difference between Gram Panchayat and Gram Sabha?', 'What is Special Economic Zones in Chhattisgarh?', 'What kind of government initiatives can help me for the betterment of agriculture in my village? One being soil health scheme, what else?', 'Why is panchayati Raj considered to be important?', 'What are top rural development institutions in India?', 'Can anyone give me the details of branch change rule in NIT jalandhar?', 'Is Panchayati Raj corruption free in India? What are remedies to neutralize the corruption in Panchayat Raj system?', 'District-wise, what are the villages in the state of Telangana?', 'How is the Indian/Bharatiyan society/governance, helping out the Dalits, Shudra, and Dasa, from the underprivileged after-life?', 'Is Bihar really developing under mahagathbandhan sarkar?', 'How can I contribute in development of Bihar?', 'How can Bihar develop?', 'What are the best ayurvedic centers in Kerala?', 'Why are Udupi and Kodagu districts more developed than Dakshina Kannada district in terms of Per capita income ?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How close are we to world war?', 'positives': ['How close are we to World War Three, and how bad would it be?'], 'negatives': ['Since the UN is unable to control terrorism and groups like ISIS, al-Qaeda and countries that promote terrorism (even though it consumed those countries), can we assume that the world is heading towards World War III?', 'How did World War 1 come to an end?', 'Why is the Seven Years War not considered a world war?', 'Is war the only solution for a conflict?', 'Is the United States on the verge of a race war?', 'What is the closest Britain and the US has been at war against each other since the war of 1812?', 'Is the war in Afghanistan nearly over?', 'Did the U.S. enter World War II too late?', 'Is India in a condition to have war with China? Will it start World War III?', 'Under what circumstances, if any, is war morally justifiable?', 'What wars and conflicts will shape the world in the next 50 years?', 'How likely is a war between the U.S and Russia?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"Could the Earth's magnetic field be used to produce electrical energy?\", 'positives': [\"Is it possible to use the earth's magnetic field to produce electricity?\"], 'negatives': ['Can earth’s magnetic field be repelled by a magnet?', 'Why does the Earth have a magnetic field?', 'Why is there a magnetic field for the Earth?', 'Is it possible to create a dynamic magnetic field?', 'Can we generate an artificial magnetic field around mars?', \"What is the reason for existence of Earth's magnetic field?\", \"What was the theory of the Earth's magnetic field?\", \"What are the effects of earth's magnetic field on the atmosphere?\", 'How is the magnetic field on Earth generated and how were the directions determined initially?', 'How do we create a magnetic field?', 'Can magnetic fields ever do work? If not, how can one magnet lift another?', 'Theoretically, is it possible to create satellites to transmit solar energy from space as a magnetic field back to earth?', 'Is it possible to make \"air\" conduct electricity?', 'What is the direction of induced electric field due to changing magnetic field?', 'How is electricity related to magnetism?', \"Is there a direct relationship with gravity and Earth's magnetic field?\", 'How is a magnetic field created?', 'How can I create a magnetic field?', 'Why are magnetic fields produced?', 'What is the direction of induced magnetic field due to changing electric field?', 'Can we increase the mass of an electron accelerated in an electric field, coupled by a pulsed transverse magnetic field?', 'Can magnetic field lines pass through wood?', 'Why does a magnet produce a magnetic field?', 'How is magnetism related to electricity?', 'Can electricity travel through air? If yes, how?', 'What is a magnetic field?', 'How can electricity travel through air?', 'What is magnetic field?', 'What is the magnetic field due to an electromagnet at a point that is not along its axis?', 'Can electricity transfer through the air and if yes, then how?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Where can I get Microsoft Office 2016 for Mac for free?', 'positives': ['How can I get Microsoft Office for free for Mac?'], 'negatives': [\"What's the best free alternative to Microsoft Office?\", 'Can I get MS Office 2007 for Mac?', 'Where can I get the full version of either Microsoft Office 2003, 2007, or 2010 for free installation?', 'How can I install Microsoft Office 2013?', 'How do I get a job at Microsoft?', 'How can I get a job in Microsoft?', 'What can I do to get a job at Microsoft?', 'Do Microsoft employees use Mac at office?', 'Do Windows developers use Mac in their Microsoft office?', 'How can I download Mac OS X 10.5 for free?', 'How do I reinstall microsoft office?', 'How do I crack the Microsoft Office 2013 Professional Plus?', 'How can I work in Microsoft?', 'What is a Microsoft Office license?', 'How can I update Microsoft office 2007 to Microsoft office 2016?', 'How can we get Microsoft Customer service?', 'Does Apple support Windows office?', 'What is the best way to re-download Microsoft Office?', 'How do we get Microsoft Customer Service?', 'Is there a replacement for Microsoft Office Accounting software?', 'What is microsoft office revenue in the enterprise market?', 'Can I get a job in Microsoft if I qualify Microsoft exams?', 'Can I download Microsoft office onto an external hard drive and still use it if it is not on my laptops hard drive?', 'How do I get a software developer job at Microsoft?', 'What are the requirements to get a job at Microsoft?', 'How do you create a Microsoft account?', 'Is MS Office 2007 compatible with Windows 10?', 'Which is the better application for MacBooks: iWork or Microsoft Office for Mac?', 'How do I get a job if I have a Microsoft certification?', 'How can I contact to Microsoft?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the secret of keeping a successful long distance relationship?', 'positives': ['How can I maintain my long distance relationship to the best of my ability?'], 'negatives': [\"We are in a long distance relationship more than 3 months. Do you think it's weird that we never speak on the phone?\", 'What makes or when girls to start get distance from a guy friend or acquaintance?', 'Why do I want to distance myself from everyone I know?', \"My boyfriend has changed so much since he has been working. We are in a long distance relationship now, and I feel so lost of him. We don't get to communicate often because he is busy, and we become more distant. How do I get close to him again?\", 'I have been officially with my new bf less than a week, seeing each other for a couple of months. Why has has he suddenly gone distance with me?', 'What can I actively do to find a long-term relationship, considering that the odds of finding a single woman who suits me will be very low in my future work environment?', 'How often should I text my long distance crush (every day, two days, once a week)?', 'Should I be worried that my long distance boyfriend has a close female friend?', 'What are some consequences of staying lonely for too long?', 'How do relationships work?', 'How can some people at a great distance make you feel so much better than those who are around you?', \"Is it OK to end a 5-year-long relationship where the person loves you a lot but doesn't give you your personal space and time?\", 'I think I am a person who cant stay in relationships for long. How do I change myself?', 'How do I rekindle love in a short term relationship?', 'As someone who is just starting to date again after a long term relationship, what do you struggle with most?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How does the Aereo antenna work?', 'positives': ['How do Aereo antennas work?'], 'negatives': ['What is antenna?', 'What is an antenna?', 'Which antenna used in mobiles?', 'What are fractal antennas? How do they work?', 'What type of antenna is used in mobile phone receivers?', 'What is can antenna?', 'What is special about fractal antennas? Why do they work the way they do?', 'Why is antenna tuning important?', 'What are Maritime Antennas and why are they used? What are the different types of antennas used in marine applications?', 'Why is antenna tuning is important?', 'How does an antenna radiate?', 'Where can I get the solution manual for the Antenna Theory Third Edition by Balanis?', 'What is the difference between straight antennas and coiled ones?', 'How do isotropic and omnidirectional antennas differ?', 'What is the isotropic and omnidirectional antenna?', 'Why does aluminum foil improve antenna reception?', 'How can I determine the physical design parameters for horn antenna?', 'Why antenna radiates?', \"Why don't phones have a built-in FM antenna?\", 'Can you prefer any website or ideas by which I can understand antenna subject practically in b.tech?', 'How do an IR transmitter and receiver work?', 'What is an Aerie application?', 'Where exactly inside the antenna can be the cause of radio frequency propagation?', 'How do satellites work in communications?', 'Which material will be suitable for deployable small satellite antenna? I need a low cost, light weight and flexible material.', 'What are the differences between the radio antenna and the antenna of the wireless router?', 'How do I construct a 4 element broadside antenna?', 'What is AES?', 'How do telecommunications satellites work?', 'I built an AM Transmitter but it had a range of about 5 inches. If I strip more of the antenna wire, will it increase in range?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is your opinion of reality shows?', 'positives': ['What do you think about reality shows?'], 'negatives': ['What do you think about this show?', 'What do you think of the new HBO show Togetherness?', 'Are reality shows 100 percent real, like Master Chef Junior and American Idol?', 'Have you ever been on a reality show?', 'Have you ever been to a reality show?', 'What is your favorite reality TV show and what explains its popularity as a genre?', 'Why do we love reality TV so much?', \"Why do people enjoy watching reality TV — especially given that it's often fake?\", 'Why do we watch reality television?', \"What are the best reality TV shows that aren't scripted?\", 'Why some people expose themselves at tv Reality Shows?', 'What reality shows on TV are not scripted at all?', 'What is this show really about?', \"Are there any American reality shows that aren't fake/scripted or are close to real, at least?\", 'What TV shows do you like to watch?', 'What would happen if a reality TV show was made out of Redditors?', 'What do you think makes people laugh when they are watching talk shows?', 'How much of reality TV is staged in order to raise popularity?', 'Is the TV show Once Upon a Time worth watching?', 'What were the pioneering reality TV shows of this era?', 'Which is newest TV show that you reckon is worth a watch?', 'What TV series are worth watching?', 'What is reality?', 'What would happen if a reality TV show was made out of professors?', \"What's good and bad about Scandal the TV series?\", 'Which TV series you like most?', 'Do you like watching stars?', 'Which TV series are worth watching?', 'What do you think about movie Room?', 'Have you seen the Suits TV Show? How to be quick-witted on replies/answers like Harvey Specter or Donna?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What\\'s the Difference between \"PGDM\" and \"Executive PGDM\"?', 'positives': ['What is the difference between PGDM and EPGP in business school?'], 'negatives': [\"What's the difference between an MBA, an MMS and a PGDM?\", 'What is the difference between IIM PGP, PGDM, FPM, PGP ABM, PGP PGDM programmes?', 'How is an MBA better than a PGDM?', 'Is PGDM and PGDBM the same?', 'What is the difference between HSDPA, WCDMA and GSM?', 'Is doing a PGDM in GBO from SRCC just after a B.Tech a better option when you have a job in hand?', 'How is the PGDM Business Design course in Welingkar Institute of Management Mumbai in terms of course structure, faculty and placements?', 'Should PGDM be taken along with M.Com and is it beneficial?', 'Which one is better: a PGDM-BKFS at TAPMI or a PGDM at Great Lakes Institute of Management?', 'What are the entry level position after PGDM in IT + B.tech(ECE) + 3 years work experience as a software developer?', 'How is the placements for PGP in business analytics and big data at Aegis school of Business (Powai)?', 'How is the placements for PGP in business analytics and big data at Aegis school of Business (Banglore)?', 'What is the difference between PGPX and PGP programme in an MBA? Which is more beneficial to opt for?', 'What can you study beyond PGDM to enhace your career growth options?', 'What skills do the HRs expect from a PGDM graduate?', 'What is the difference between project management and general management?', \"What is the procedure of admission for doing PGDM in Marketing from MICA and what are the things required in one's profile for the same?\", 'What is gsm, CDMA, wcdma, & lte?', 'What is the difference between B.Tech IT and B.Tech CSE at GGSIPU?', 'What should I know about marketing If i am a programmer ?', 'Difference between \"Microgrid\" and \"Microgrid as a Service\"?', 'What is difference LTE Huawei and LTE alcatel?', 'Is it good to do MBA or PGDM after electrical & electronics engineering with experience?', 'What is the difference between OLTP and OLAP?', 'What are the benefits of Software School Management?', 'What is the difference between CDMA and GSM?', 'I have done BE in IT. Which course is beneficial-SAP ABAP or PG diploma in business analytics?', 'What are the technical differences between CDMA and GSM?', 'Which is the best PGDM or PGPM from Great Lakes Institute of Management Chennai?', 'What is the difference between a programmer and a developer?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I get text records from metro pcs account?', 'positives': ['How can I get my old call history and text messages from metro pcs?'], 'negatives': [\"How do I find out another SIM card's call history?\", 'How do I get call history for my Airtel prepaid number?', 'How can you track cell phone messages?', 'How do I retrieve lost contact numbers from my phone?', 'How are phone text messages tracked?', 'How can you track text messages?', 'How can I find my FaceTime call history through my Apple ID?', 'How do I block certain numbers from calling my Metro PCS phone?', 'How do you track cell phone message?', 'How can I track Hangouts messages from another phone?', 'Can the history on my personal phone with my personal email be seen by someone using the same internet network in the house?', 'My messages and message history on my iPhone 6 suddenly disappeared after I restarted the phone. Is there any way I can get them back?', 'How can I search the chat history in the Line app in an iPhone 5?', 'How can you trace text messages from unknown numbers?', 'How do I recover text messages from my LG without a computer?', 'How do I recover deleted text messages on my lg cellphone without a computer?', 'How can I retrieve old Kik messages to my email?', \"Is there any way to retrieve voice messages from an old iPhone, if they weren't deleted, but I have a different phone number and am on a new account?\", 'How can I trace phone calls from a cell phone?', 'Is it possible to retrieve lost text messages from the iPhone?', 'Do phone companies log text messages?', 'Can I tell what time text messages are received and read by the person I sent them to?', 'How do I get back deleted messages on my I phone 6s for a contact?', 'Can someone check my web history if I use their wifi theough my phone?', 'How do I recover old chat history on Skype?', 'How do I trace a phone call?', 'Is it possible to retrieve an old conversation transcript from Kik Messenger?', 'Where can I retrieve my deleted text messages?', 'How can I get text and calls from other phones on my phone account?', 'Why when I call a friends number from landline and goes to my old cell number?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"Why didn't the United States take all Mexico when it had the opportunity?\", 'positives': [\"Why didn't the US take more of Mexico?\"], 'negatives': [\"Why didn't Mexico (the country) become part of the United States with New Mexico or Texas?\", 'Why is Mexico screwed up?', 'What US states once belonged to Mexico? How did they become part of the US?', 'Should Mexico became a US Territory like Puerto Rico or the Virgin Islands?', 'If so many Mexicans have such pride for Mexico, why do so many come to America?', 'Why do so many people think Mexico is a poor country?', 'Eva Longoria: Should Mexico became a US Territory like Puerto Rico or the Virgin Islands?', \"Why doesn't the USA buy Canada and Mexico to make a North American Union?\", 'Why is Mexico sparsely populated?', 'Why is Mexico viewed as a third world country?', 'What would the negative and positive results be if all undocumented Mexican nationals in the US were returned to Mexico?', 'Which part of Mexico do most immigrants to USA come from?', \"Why haven't the Mexican people overthrown their corrupt government yet?\", 'Is Mexico a poor country?', 'Is Mexico most likely to take over the world?', 'Why did the US stop at 50 states?', 'Was the Mexican-American War justified?', 'Is Mexico being a bad neighbor by refusing to pay for 50% of the border wall?', \"Is Mexico in debt to the United States even though it's naturally rich in resources?\", 'Why does Mexico not have a Olympic team?', 'Mexico: What are the fundamental reasons that so many Mexican citizens want to leave their country and come to the US? How do their circumstances differ from Canada for example?', 'Why would Mexico be considered a socialist country?', 'How would history change if the United States annexed Mexico after the Mexican-American war?', \"Why hasn't the USA tried to take down North Korea?\", 'What regions of Mexico do most immigrants come from?', 'Why Spain forbad to its citizens to emigrate in Mexico in XVIth century?', 'How is Mexico a poor country?', 'Why is Mexico geographically part of North America?', \"What are Mexico's biggest exports?\", 'Is Mexico a mixed economy?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why is this boy being a jerk to me but last year wanted my attention?', 'positives': ['Why is this boy being a jerk to me now but last year was begging me for my attention?'], 'negatives': [\"I'm helping a boy in my school that is overweight and is being bullied. I think he started getting feelings for me, what should I say?\", 'Why does he tease me all the time?', 'How do I get him to see that he is paying no attention to me and pushing me to the side?', 'My kid cries for things he wants and he throws tantrums over it. Am I raising him wrong? Will he grow out of this? What should I do?', 'How do I confess my feelings to this boy I like at school?', 'Why am I thinking so much about my crush who rejected me 2 months back?', 'How do I show compassion to my teenage son?', 'Why is Jake Williams all over my feed?', 'A boy rufused me, how can I continue to keep touth with him.?', 'Why does my boyfriend treat me with absolute respect yet treats others badly?', 'Why do I crave the hug from a boy?', 'Why am I attracted to a \"bad boy\" even when I have so much respect for myself?', 'Did I push him away?', 'Why is my crush staring at me and smiling and his friends push him into me?', 'Why does my crush watch me talk to my guy friends?', \"Why can't I get over my crush?\", 'I found out that my 14-year-old high school freshman son likes another freshman boy at his high school. How should I confront him?', \"How do I tell my boyfriend I can't do it anymore. I'm sick of begging for love n attention?\", \"Why won't my boyfriend open up to me?\", 'Why did he suggest to meet then ignored me then?', 'Why is my boyfriend so selfish?', \"Why doesn't my crush want me to see him drunk?\", 'Why do I want to bite my boyfriend?', 'I found out that my 14-year-old high school freshman son likes another freshman girl at his high school. How should I confront him?', 'Why are boys rude to girls they like?', 'How do I get a boy to stop following me?', 'Boyfriend calls me names and expects me to be \"tough\" about it. What should I do?', 'How do I understand my boy friend?', 'Why does my boyfriend feel annoyed by me? Does he even love me?', 'How do I get my crush to notice me?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I upgrade my English Writing skills?', 'positives': ['How can I improve my English vocabulary and writing skills?'], 'negatives': ['How can I improve my English and French writing skills?', 'I am a bit weak in English. I find difficulty while doing precis writing because the vocabulary is tough. Can someone help me what to do?', 'Which book can help me practice writing and enhance my skill on writing in English for the CBSE class 12?', 'My English is great (2nd language)! Going back to law, public speaking and essay writing are priorities. How can I make it better?', 'What are some of the best newspapers to read to improve English skills?', 'How can reading newspaper help me improve my English?', 'Are writing skills more important than speaking skills?', 'If I want to improve my writing skills and communication, which books should I follow?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why is Manaphy annoying in Pokemon Ranger and The Temple of The Sea?', 'positives': ['Why do people consider Manaphy annoying in Pokemon Ranger and The Temple Of The Sea?'], 'negatives': ['Why is Pokémon Ranger and the Temple of the Sea childish?', 'Is \"Pokémon Ranger and The Temple of The Sea\" considered childish?', 'In Pokemon Ranger and The Temple Of The Sea, Why is May crying while saying goodbye to Manaphy?', 'Is The \"Pokemon Ranger and the Temple of the Sea\" a problematic anime?', 'Is \"Pokémon Ranger and the Temple of the Sea\" considered a Problematic anime?', 'Why are no actual princes in the Pokémon Manaphy movie?', 'Why is \"Pokemon Ranger and the Temple of the Sea\" movie problematic now?', 'Why are there no actual princes in the Pokémon manaphy movie?', 'What things do Quora users do that you find extremely annoying?', 'Why do people make fun of Nuzzly Pokemon?', 'Is \"Pokemon Ranger and The Temple of The Sea\" considered appropriate for kids?', 'What is the most annoying character in Taarak Mehta Ka Ooltah Chashmah?', 'What is something you find annoying on Quora?', 'Why do people make fun of Pokemon anime?', 'Why do people make fun of Pokemon?', 'Why is \"Pokémon Ranger and the Temple of the Sea\" movie underrated now?', 'What things do Chinese from China find most annoying?', 'Why did \"Pokemon Ranger and The Temple Of The Sea\" got kicked out of Cartoon Network in America?', 'What are some good ways of annoying Chinese people?', 'What do Indians find most annoying in foreigners?', 'What do foreigners find most annoying about Indians?', 'What do average people find most annoying about social networking sites?', 'As a foreigner living in China, what things do you find annoying? Why?', 'What is the most annoying thing people do on Quora?', 'Where can I catch a Oddish in Pokémon GO?', 'Why is Manaphy popular in South Korea?', 'What is the most irritating thing on Quora?', \"What's the most irritating character in a Bollywood movie?\", 'How do you deal with annoying friends?', 'Why do some people prefer to watch Precure to the Manaphy movie?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How much does Uber driver make in San Diego?', 'positives': ['How much does an Uber driver make in San Diego?'], 'negatives': ['How much does a Uber driver make in Tampa, FL?', 'How much do Uber drivers in Dallas make?', 'How much can you make as an Uber black driver in San Francisco?', 'How much does an UberX driver make in NYC?', 'How much Uber drivers make in Texas?', 'How much does uber driver earn?', 'How much does Uber drivers make in Colorado?', \"How much money per hour do Uber drivers make in Hermosillo, Mexico? What's the most a person can reasonably make per month?\", 'How much money does an uber driver make in Delhi NCR?', 'How much do uber drivers make in Seattle?', 'How much does an Uber or UberX driver earn in the District of Columbia?', 'How much do Uber drivers get paid?', 'How much money do Uber drivers make?', 'How much money does an Uber driver make in Portland OR?', 'How much do Uber drivers make per year in Chicago, IL?', \"How much money per hour do Uber drivers make in Jacksonville, FL? What's the most a person can reasonably make per month?\", 'How much money do Uber drivers make in Chicago?', \"How much money per hour do Uber drivers make in Berkeley, CA? What's the most a person can reasonably make per month?\", 'How much do uber drivers get paid and when?', 'How much money does an Uber driver make in Miami Florida?', 'How much money do Uber drivers make in Sacramento?', \"How much money per hour do Uber drivers make in Tijuana? What's the most a person can reasonably make per month?\", 'How much do UBER drivers earn in India?', 'How much does Uber driver earn in India?', 'How much does a uber driver earn in India?', 'How much can an Uber driver earn in Portland, Oregon?', \"How much money per hour do Uber drivers make in Puebla, Mexico? What's the most a person can reasonably make per month?\", 'How much, on average, can a person make part time driving for Uber or Lyft in San Antonio?', 'How much do Uber drivers make in Bangalore?', 'How much do Uber drivers make in Houston?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What is the weirdest question you've seen (In your opinion) on Quora?\", 'positives': ['What are the weirdest questions you have seen on Quora?'], 'negatives': ['What are the weirdest question you have answered on Quora?', 'What is the weirdest thing you seen?', 'What is the weirdest thing?', \"What is the weirdest thing you've ever been told?\", 'What is the weirdest thing you have ever seen?', 'What is the weirdest thing that you have?', 'What is the weirdest thing about you?', \"What is the weirdest thing you've seen on Wikipedia?\", 'What is the weirdest question you have ever been asked in an interview?', \"What's the most weird/stupid question you've asked anonymously?\", 'What are the weirdest questions asked in TISS interview?', 'What weird questions have you been asked in an interview?', 'What is the weirdest website you have seen?', 'What is the weirdest thing you searched on the Internet?', \"What is the strangest thing you've ever seen?\", 'What is the weirdest thing you collect?', 'What is the weirdest thing you are into?', 'What is the weirdest thing in space?', \"What is the weirdest thing you've ever done?\", 'What are some of the weirdest conversations you have had with anyone?', 'What is the weirdest thing that you did?', 'What is weird?', 'What is the strangest thing that you have ever experienced?', 'What is the strangest thing anyone has said to you?', 'What is the weirdest thing you have seen some one do?', 'What is the weirdest thing you have ever done?', 'What is the weirdest thing that you have ever seen or have happened to you?', \"What's the weirdest thing you have ever touched?\", 'Which are the weirdest trends you ever saw?', 'What is something really weird about you?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are advantages of web scrapping?', 'positives': ['What are uses of web scrapping?'], 'negatives': ['What are some interesting web scraping projects you have done?', 'What is the legality of web scraping?', 'What are some good web scraping programs?', 'What is an easy way to attach scrapy to my web app?', 'Where can I find the list of web scraping projects to practice?', 'Are there examples of a scrapy project that crawls an entire site recursively?', \"What's the best resource to learn about web scraping from scratch?\", 'What is the best web scraping software?', \"What's the best language for web scraping?\", 'Which are some of the best web data scraping tools?', 'What are web publishing tools?', 'What are some good free web scrapers / scraping techniques?', 'What is web and how does it work?', 'What is web mining?', 'What are the biggest differences between web crawling and web scraping?', 'What technologies are used to create a web page for creating web pages?', 'How can one learn to scrap web data using Python?', 'What are some examples of web-based software?', 'Are scrap yards considered to be recycling centers?', 'How do scrap yards make money?', 'What technologies to use for building a web app?', 'What is web based application?', 'What is web scraping and is Python the best language to use for this?', 'What is the dark web used for?', 'What are some good ideas for research projects in computer science in the field of web mining?', 'What scripting language is useful for web development?', 'What is web and web application?', 'What are the uses of HTML?', 'What do web publishing services do?', 'Who uses deep web?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the best courses for mechanical engineering?', 'positives': ['What is the best programs for mechanical engineerings?'], 'negatives': ['What is the best career for a mechanical engineer?', 'Which are the best companies for a mechanical engineer?', 'Why mechanical engineering is the best engineering career?', 'Why is mechanical engineering the best?', 'Which makes one good mechanical engineer?', 'What makes a good mechanical engineer?', 'Which are the best consultancy fields other than software (cad/Ansys etc) in mechanical engineering?', 'What is mechanical engineering?', 'What are some good research areas in mechanical engineering?', 'Which is the best career option after mechanical engineering?', 'What is the importance of programming in mechanical engineering?', 'Who is the best mechanical engineer in World?', 'Which is best for mechanical production or maintenance?', 'Which mechanical engineering project should I make in the 3rd year?', 'Which engineering is best?', 'Why is mechanical the best branch of engineering?', 'What are mechanical engineering related businesses?', 'What are the jobs available for a MECHANICAL engineering fresher?', 'What is the most important technology of the future in mechanical engineering field?', 'What is the greatest mechanical engineering invention of all time?', 'What can I do for my better in mechanical engineering As I am pursuing my first year?', 'Which are the best magazines for mechanical engineering students?', 'What are good thesis topic for mechanical engineering management?', 'Which is the best career: mechanical design engineer or mechanical maintenance?', 'What are the latest application of value engineering in mechanical field?', 'What should I choose, electrical or mechanical engineering?', 'What is the best mini design  project for a second year mechanical engineering student?', 'What are some small, but hot topics for mechanical engineering for PPT?', 'What is the best engineering job?', 'What is the highest package a mechanical engineer offered and in which company?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Who is going to win the 2016 US presidential election? Why?', 'positives': ['Between Trump and Clinton who will win US presidential election?'], 'negatives': [\"Who do you want to win in the America's 2016 Presidential election and why?\", 'To those outside of America: If the current US presidential election candidates (Obama Vs. Romney) were running in your country who would you vote for and who do you think would win?', 'Who should I vote for in the 2016 US presidential election?', 'Which candidate in the 2016 U.S. presidential election do you support?', 'Hypothetical Scenarios: Who would win the US election - Barack Obama (2008) vs Donald Trump (2016)?', 'Who are you voting for in the 2016 US Presidential Election, and why?', 'Who will win the 2020 presidential election and why?', 'Will you vote (or not) in the 2016 US presidential election? Why?', 'Who votes in the Democratic and Republican Party primaries to determine presidential candidates in the USA?', 'Who are the top candidates for US presidential election in 2020?', 'Should I vote in the 2016 US presidential election?', 'We have two presidential candidates that are highly scrutinized, do you think our votes really determine who becomes president of the United States?', 'Which 2016 US presidential candidate would be best for the economy?', 'Which U.S. presidential candidate is most likely to lead the US into World War lll?', 'As of now, who would be the next Democratic candidate for president in the next election?', 'What percentage of votes in the 2016 U.S. Presidential race will go to third party candidates?', 'Who would win in a fight, Donald Trump or Barack Obama?', 'Who is going to be the first candidate to declare for the 2016 presidential election?', 'If all the previous U.S. presidents were alive and running for office in 2012, who would win?', 'If all 43 U.S. Presidents were to run for office in 2016, who would win? Also, who would be best suited to deal with the current issues?', 'Will a high voter turnout favor Donald Trump or Hillary Clinton?', 'What happens if there are more than two presidential candidates in the US?', 'Out of the five major current U.S. Presidential candidates, who would be best for the U.S. Economy?', 'Is there really a chance for a third-party Candidate to win the election in 2016?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What should I do after my startup failed?', 'positives': ['What do I do after my start-up fails?'], 'negatives': ['Should I start my start up?', 'What should I do in my first 6 months working at a startup to stand out?', \"What's it like to work at a failing startup?\", 'How do I quit and startup?', 'What should I do if I fail again and again?', 'I am having frustrations on what to do after Highschool, Help?', 'How do I start all over again?', 'What should I do after completing a B.A.?', \"If I'm failing my first semester at college, what should I do?\", \"'m currently in my CA finals. I want to start preparing for the UPSC. How should I start?\", 'I am failing in each thing that I am trying. I want something that can make me start again. What are some suggestions on what can help me?', 'What is the best start up to start?', \"I'm currently in my CA finals. I want to start preparing for the UPSC. How should I start?\", 'Every time I start my PC startup repair starts and its not able to repair it .I tried to boot from USB but its not working. What to do?', 'How did you succeed with your startup?', 'How can I start a successful startup?', 'I did B.Tech(ECE) in 2012. I have not started my career till now. What should I do to restart my career?', 'How do I actually create a start-up?', 'What should I do now if I failed my midterm exams?', 'What should I do if I don’t find any progress in myself?', 'What steps are to be taken to begin a startup?', \"How should one start preparing for UPSC when they're in first year of college? Plus what should be the strategy?\", 'What can I do after finishing BE computer science?', \"I have failed miserably and I don't know what to do. I am a loser. I want to quit but I cant. What should I do?\", 'Why did your startup fail?', 'What am I going to miss after completing engineering?', 'How do I overcome my second failure?', 'Sick before final exams, what should I do?', 'What process would I have to go through to build a Start-up, what do I need to learn?', 'What does it take to start a start up company?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the best way to get experience in cyber security?', 'positives': ['How do I get started in the cyber security industry?'], 'negatives': ['What course should I study to become cyber security expert in India?', 'What is cyber security?', 'Where can I get a course in cyber security in India?', 'What is the difference between cyber security and cyber engineering?', 'How is the cyber security engineering program at USC (In prospective of  curriculum, getting RA ,internships, jobs and also pay scale)?', 'Is there a cyber police?', 'What are the top cybersecurity challenges?', 'How do I start ethical hacking?', 'What is the difference between computer security and cyber security?', 'What are the myths about Cyber Security?', 'How does cyberbullying usually start?', 'How should I start a career on ethical hacking?', 'Which cyber security course is easy and job oriented for me as a B.tech mechanical engineer student?', 'As a soon-to-be high school graduate, what steps should I take to have a career in cyber security for the federal government after college?', 'How does one become a hacker?', 'What companies require cybersecurity?', 'Cybersecurity must be open and replaceable?', 'How do I become a 1337 hacker?', 'Should I major in computer science or cyber security engineer?', 'What are a few top cyber security companies in India?', 'What are the best cyber security courses in Israel?', 'What are the best undergraduate computer science program for focus in cyber-security/hacking?', 'Which are the good training institutes for Cyber Security in Pune?', 'Can a B.Tech ECE fresher join an M.Tech cyber security?', 'Will cyber security always basically be an arms race?', 'What is the process for hacking websites?', 'I am studying for a diploma in engineering in computer science and technology. How can I become a professional ethical hacker?', 'What should I do to become an ethical hacker?', \"I'm pursuing my b tech first year IT and I'm very passionate about hacking, is there any online hacking course for beginners?\", 'What are new, hot research topics in cyber Security?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the best interior design school in Bangalore?', 'positives': ['What are the best interior design school in Bangalore?'], 'negatives': ['Which engineering college in Bangalore has the best placement for students?', 'What are the best colleges in interior designing in India?', 'Which engineering college in Bangalore has the best campus?', 'What are the institutes in South India that offer an interior design course?', 'What is Best design school in india?', 'What are the best design colleges in India?', 'What are good furniture shops in bangalore?', 'Who is the best interior designers in Hyderabad?', 'What are the best art galleries in Bangalore?', 'What is the scope of interior design in india?', 'Which are the best residential areas in Bangalore?', 'Which are the top 10 B-schools in Bangalore? Apart from IIMB which college would you suggest?', 'What are the best UI design companies in Bangalore?', 'Which is the best fashion designing college in Lucknow?', 'What is the scope of interior designing in India?', 'Which is the best school in bangalore for 4th and 8th standard girls?', 'What are the best coaching institutes in Bangalore for IAS / UPSC exam preparation ?', 'Who are the best interior designer in Ahmedabad?', 'Which is the best modular kitchen in Bangalore?', 'Which is the best university for interior design?', 'Who is the best interior designer in hyderabad?', 'What is the scope of doing interior designing in India?', 'What is a good area in Bangalore for two co-founders to work out of residence?', 'Which is the best interior design company in Mumbai?', 'Which is the best restaurant in Bangalore?', 'Which are some of the good colleges/school for 11th and 12th in Bangalore?', 'Where are the good co-working spaces located in Bangalore?', 'What are some of the best colleges in India to pursue a degree in design?', 'Which is best college for interior design?', 'What are the best acting schools in Bangalore?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are some home remedies or recipes for diarrhea?', 'positives': ['What are some home remedies for treating diarrhea?'], 'negatives': ['Home remedies to cure Diarrhoea in kids?', 'What is the best way to cure a diarrhea case that was lasted over a week?', 'How do you treat diarrhea with black specks?', 'Is diarrhea a symptom or a disease?', 'How does Pepto-Bismol help with diarrhea?', 'How does Pepto-Bismol help relieve the symptoms of diarrhea?', 'How do I manage diarrhea while on a college tour?', 'What is the home remedy for hiccups?', 'What are some home remedies for fever?', 'What home remedies do you use?', 'What are the best home remedies for cold, cough, nausea, etc.?', 'What are some home remedies for constipation?', 'How good is ginger ale for diarrhea?', \"What do you do if you have diarrhea when you're 25 weeks pregnant?\", \"What do you do if you have diarrhea when you're 39 weeks pregnant?\", 'What are the best home remedies for nausea?', 'What are the best home remedies sites?', 'Are there any home remedies for diabetes?', 'What are the home remedies for cold?', 'What is the home remedy for nausea?', 'Why is ginger ale good for diarrhea?', 'Is there any home remedy for Diabetes?', 'How can eating nuts cause diarrhea?', 'What home remedies help with nausea?', 'What causes diarrhea all of the sudden?', 'What are home remedies for fungal infection?', 'What are some home remedies for a dry throat?', 'What are some good home remedies for a dry throat and a runny nose?', 'What might be the cause of yellow watery diarrhea and vomiting?', 'What are the home remedies for wheezing cold?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I know I exist?', 'positives': ['How can I know that I exist?'], 'negatives': [\"It is true that I don't exist?\", 'How do we exist?', 'Do I still exist if nothing exists?', 'Do we exist?', \"What should I do when I don't know what exactly is the purpose of my existence?\", 'How do I find my true self?', 'How can I know if aliens exist?', 'How can I find my true self?', 'How do we know that photons exist?', 'What do I do when I doubt my own existence?', 'Does love exist?', 'Have you ever asked to yourself why do you exist?', 'How do I make someone know of my existence on Facebook?', 'How I find myself?', 'How did God exist?', 'When will I know I found the one?', 'How do we know what we perceive is real?', 'Does God exist?', 'Does God exist?', 'How do I know that the world is real, and not just in my head?', 'How can you find your true self?', 'How can I find myself or purpose of life?', 'How do you know if you have found your soulmate?', 'Does God exist? If yes, How and where?', 'Are you sure God exists?', 'How do I know if I found the one?', 'Did Christ exist?', 'Does true love exist?', \"Why do I feel that everyone around me knows something about me that I don't know about myself? How can I find out? What am I missing?\", 'Does an absolute exist?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I memorize quickly?', 'positives': ['How do I memorize faster?'], 'negatives': ['How can I memorize notes of geology faster?', 'What is the best way to memorize the periodic table without mugging up as such?', 'What are some ways to memorize times tables?', 'What is a good strategy to memorize the Quran?', 'I am in medical school and have great problem at memorizing things, nothing stays in my mind. Any suggestions about how to work things out?', 'How can I memorize a dictionary?', 'How do I memorize the formulas in physics?', 'How can I memorize physics laws, lessons and definitions while studying 15 chapters?', 'How does one learn to read faster?', 'Pens: What makes blue ink better for memorization as opposed to black ink?', 'What is the fastest way to make notes?', 'How do I learn to read faster?', 'What are useful applications of the mnemonic major system besides remembering very long numbers?', 'What is the best way to memorize English vocabularies?', 'Does memorizing music lyrics improve your memory?', 'How do I sing high notes easily?', 'How can I improve my handwriting to write faster?', 'What are some easy ways to memorize all the elements in the periodic table?', 'What is a great way to memorise the Periodic Table?', 'How do I memorise everything? Is there any book for it? Any methods? How do I remember all concepts and facts that I learn daily?', 'What are the best methods for memorizing lyrics?', 'What are some 15-line poems that are easy to memorize?', 'Is there a technique to read book faster?', 'What is the easiest way to memorize the key-signatures of major and minor scales?', 'How can I sharpen my brain to recall/recollect learned or heard information precisely and in long term standards?', 'How do I read faster and comprehend better at the same time?', 'How can I train myself to write more in a shorter time span, whether with journaling or creative writing?', 'How can I read more quickly?', 'What are some useful skills I can learn in minutes?', 'How do stage actors memorize so much dialogue?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I learn algorithms and data structures from scratch?', 'positives': ['What should one refer to (books or online courses) for learning data structures and algorithms from scratch?'], 'negatives': ['Why should I learn data structures and algorithms?', 'How important are data structure and algorithms to learn programming?', 'Which is the best website for learning data structures or algorithm?', 'What are some good books for Learning Algorithms?', 'Is it good to start preparation for Algorithms with book \"Introduction to Algorithms\" by Thomas H. Cormen with average knowledge of data structures?', 'What is the best free online text book for Algorithm an Data Structure? I mean a textbook for a beginner student in college.', 'What are the best books for learning data structures and algorithms in C++?', 'What are the best books available for data structures and algorithms?', 'What is the best book to learn algorithms in computer science?', 'Which books do you recommend for Algorithms and Data Structures for C++?', 'Which is the best website for learning data structure?', 'What are data structures and algorithms?', 'What are the pre-requisites required to learn algorithms?', 'What are the best books for Data Structures (No Algorithms)?', 'What is the best book to learn algorithms design and analysis?', 'How do I learn how to implement algorithms and data structures in C++?', 'Which book(s) and other resources would you recommend for a beginner to understand Data Structures and Algorithms in C++?', 'What are the best books to learn algorithm?', 'What are some good books for beginners in algorithms?', 'What is the best book for learning design and analysis of algorithms?', 'What is a good book about algorithms?', 'In which order should one start learning Data science?', 'Which are the best books for Data Structure and Algorithms?', 'What do you think is the best book on algorithms for a beginner?', 'What are the best books on algorithms for a beginner?', \"I'm a business person and I'm trying to get a data analysis/data science skill. Should I learn algorithms by working on an algorithms book by Robert Sedgwick or should I go straight into data science using Python?\", 'Is datascience easy to learn?', 'Should I learn algorithms before learning programming?', 'Why should I learn algorithms?', 'Which algorithm book should I learn?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What can you say about Filipino people?', 'positives': ['What is your honest opinion about the Philippines and Filipino people?'], 'negatives': ['What do Filipinos think about Indians?', 'What do Filipinos think of Indians?', 'Are you a Filipino?', 'What countries like the Philippines?', 'How important do US citizens think the Philippines are as an ally?', 'What makes Filipinos so favorable towards USA?', 'What is life like in the Philippines?', 'Who are the Filipinos on Quora?', 'Philippines: Where do you get your news?', 'Is the Philippines an Asian or a Western country?', 'Do you think Filipinos are racist?', 'Are Filipinos Hispanic?', 'What is your opinion about Thailand?', 'Who are your favorite columnists in the Philippines?', 'What makes the Filipinos different from other Asians?', 'Who is the most unbiased and reliable source of news in the Philippines?', 'Who are the influential Filipino leaders most Filipinos follow?', 'Why are Filipinos so proud?', 'Is the U. S. losing the Philippines as its ally?', 'What is the relationship like between Japan and the Philippines?', \"Why are some countries so furious about Philippines' independent peace-loving foreign policy, and starting to badmouth Philippines?\", 'Why are Filipinos so religious?', \"What attitudes do Mexicans have that Filipinos don't have?\", \"Why is the U.S. so upset about Philippines President's independent peace-love foreign policy in the world?\", 'What is the saddest thing about the Philippines?', 'What are your thoughts about the war on drugs that is happening in the Philippines right now?', 'What are typical traits of Filipinos?', 'How do Filipinos see the Spanish?', 'How would you describe the relationship between the United States of America and the Philippines?', 'How is life in the Philippines?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why has the accusations against Trump with regards to raping a 13 year old largely stayed out of the mainstream media?', 'positives': ['Why has the media mostly ignored the 06/20/16 filing of a federal lawsuit against Donald Trump and Jeffrey Epstein for raping a 13 yr old girl?'], 'negatives': ['When is Trump going to sue the women who accused him of sexual assault?', \"Why hasn't Ivanka Trump condemned the bigotry in the Access Hollywood sex tape?\", 'Can Trump’s accusers still sue? Is there a statute of limitations on sexual assault, and does it differ by state?', 'When is Trump going to sue all the women who accused him of sexual advances?', \"Why doesn't Hillary Clinton sue Donald Trump for libel?\", 'Why is the media protecting Hillary Clinton?', 'Why does the Clinton campaign not do more to refute media inaccuracies surrounding the Benghazi scandal?', 'Now that the fake news media is falsely reporting that Clinton will not be prosecuted by Trump, when will they be shut down for libel?', 'Could Hillary Clinton sue Donald Trump for libel, or vise versa?', 'Is the practice of trial by media justified? ', 'Could Ford Motors or Carrier sue Donald Trump for libel if his public statements are proven unfair yet damaging to their bottom lines?', 'Is it correct to conduct trial of a person accused in media?', 'Why is there a lack of media coverage regarding the October Wikileaks email dump on John Podesta and Hillary Clinton?', 'Why was it illegal for Gawker to publish the Hogan sex tape?', 'Why should media not be censored?', 'Did Trump sexually assault as Clinton did? L', \"Why has every cable news network failed to seriously confront Trump re his campaign mgr's assault?\", 'Is the media unfairly biased towards Hillary Clinton?', \"What are some examples of Trump's unfair treatment by the media?\", \"If John Perkins lies, why wasn't he sued for accusing so many politicians?\", 'Is the American media to blame if Trump is elected?', 'Why aren’t some news channels covering the allegations swirling around the Clinton Foundation?', \"Why does the media never ask Chelsea Clinton about her father's treatment of women but constantly asks Ivanka Trump?\", 'Is the Media truly biased towards Hillary Clinton?', 'In what ways does American media fool people?', 'Why are media outlets including CBS and MSNBC not covering the Wikileaks email dump regarding the DNC?', 'What could be legal repercussions for doing what Donald Trump says he does in the sex assault bragging video?', 'Why is the “mainstream” media attacking Trump for visiting Louisiana when Obama is doing nothing but playing golf as reported by the same media?', 'Is Trump’s alleged groping of multiple women as bad as or worse than Bill Clinton’s alleged rape of Juanita Broadderick?', 'Why is media so censored these days?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What are your views about Arnab Goswami's The Newshour?\", 'positives': [\"What do you think about Arnab Goswami's show?\"], 'negatives': [\"What doesn't the nation want to know on Arnab Goswami's show?\", 'Is Arnab Goswami mad?', 'What does Arnab Goswami think of himself?', 'What Arnab Goswami is doing these days?', 'What is Arnab Goswami doing now-a-days?', 'Who is Arnab Goswami?', 'What will happen if Arnab Goswami joins Quora?', 'Does Arnab Goswami have friends?', 'Is it true that Arnab Goswami quit times now and is it not the best thing that happened to TV journalism?', 'Why did Arnab Goswami quit TIMES NOW?', 'Why did Arnab Goswami left ET now?', 'What you think about Arvind Kejriwal new show \"Talk to AK\"?', 'Has Arnab Goswami rejoined Times now?', 'What if Arnab Goswami joins Quora?', 'How was Arnab Goswami as a student?', 'What is Arnab Goswami going to do as he has resigned from Times Now?', 'Why did Arnab Goswami resign as the Editor-in-Chief of Times Now?', 'Is Arnab Goswami quitting from Times now?', 'Where is Arnab Goswami these days?', 'Has Arnab Goswami resigned from Times Now?', 'Why did Arnab Goswami resign from Times Now?', 'Why did Arnab Goswami resign from Times Now?', 'Why do many people watch The News Hour although they hate Arnab Goswami?', 'Where is Arnab Goswami?', 'What is Arnab Goswami has and we have not?', 'Why Arnab Goswami resigned times now?', 'What do you think about this show?', \"What do you think about Aammir Sir's Dangal?\", 'What do you think of the show Koffee with Karan?', 'Is Arnab Goswami a narcissist?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Can humans as a species run out of drinking water?', 'positives': ['Could we potentially run on out of drinking water in the future?'], 'negatives': ['Is it safe to drink tap water in the US?', \"Why don't we purify sea water for drinking?\", 'Why is there a drinking water shortage?', 'Can we drink milk instead of water to hydrate our bodies?', 'Can we drink 6 litres of water a day?', 'What will happen if I reuse packaged drinking water bottles for long time?', 'What would happen to a man forced to drink just heavy water for the rest of his life?', 'What will happen if I drink only water and not other beverages?', 'Why does only water quench our thirst?', 'Will China run out of water?', 'Is drinking 2-3 litres of water a day too much?', 'Is it safe to drink tap water?', 'What would happen if the U.S drinking age become 18?', 'Why do we sometimes drink water but feel more thirsty?', 'How safe is it to drink tap water in North America?', 'Is it safe to drink tap water in Tokyo?', 'Is it safe to drink water in the Dominican Republic?', 'Is it true that the government forbids us from collecting rain water for consumption? If so, why?', 'Is chicago tap water safe to drink?', 'Why is water consumption so important for the body and mind, and how much should we ideally be drinking per day?', 'How much weight will I lose if all I drink is water for a week and/or a month?', 'What will happen if we drink 500 ml of beer daily?', 'Which cities in USA is it safe to drink tap water?', 'What happens, if you drink water from a swimming pool?', 'How is India trying to tackle the water scarcity in the near future?', 'Why is drinking water important?', 'If boiler feed water is not demineralised then what are the problem we faced?', 'Why is water consumption so important for the body/mind and how much should we ideally be drinking per day?', 'What happens if I drink one glass of water every 20 minutes?', 'What are some of the best water technology drinking?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Just got out of a 1 year relationship and it hurts, how can I feel better and bounce back?', 'positives': ['Just got out of a 1 year relationship and it hurts, how can I feel better?'], 'negatives': ['How do I feel better in my mid-thirties when my ex has moved on with a girlfriend while I am still hurting deep within after almost 4 years?', 'Should I settle? Pain and suffering too low?', 'Why is it so hard for me to get over a relationship that was never going to work out in the first place?', 'How do you deal with emotional pain?', 'How does one deal with emotional pain?', 'How do I feel better when feeling down?', 'How can love hurt so much?', 'How do I get over a broken love relationship?', 'How do I move on from a breakup after 3 years of true love, so that it stops hurting?', 'Does it really hurts for months after a bad break up?', 'How do I feel love again?', \"How do you love when you've been hurt so many times?\", \"What if I don't want to feel anything any more?\", 'I feel like I am a loser. I dont deserve to be loved. And that I am better off alone. I am not able to get over this feeling, what should I do?', 'What can I do to not feel left out?', 'How do I cope with the pain of a breakup?', 'I am physically strong, but very weak emotionally and mentally. What should I do to get over it?', 'I have been in a complicated relationship. what should I do?', 'How do I get over my first and the only love?', 'How do I get over my relationship problems?', 'How do I get rid of the pain and suffering from unrequited love?', 'What is the best thing to do if I have feelings for another girl when I am already in a 3 years relationship?', 'What is best way to stop feeling wrong about being a single girl who is successful but yearns for a good relationship?', 'Why do relationships hurt so much?', \"I'm heart broken. The girl I loved likes someone else in a month's time. I dont know what to do I feel decieved.?\", 'How do I get rid off unrequited love pain?', 'I feel stressed, pressured and lonely. Can anyone give me something to make me feel better?', 'If you feel disappointed in yourself, how do you make yourself feel better?', \"Why do I love my ex so much and can't let him go but still not happy, even though he left me and came back after 2 weeks?\", 'Is there any better feeling than love?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is a good book for learning the basics of C++ programming?', 'positives': ['What is the best way to study for c++ programming?'], 'negatives': ['How did you learn c++?', 'What is the best software that you created in c++?', 'To learn C++, would I be alright following a tutorial for C++03?', 'What should be the best way to study C programming?', 'Is c++ is the best programming language ?', 'What is the short way to learn C++ knowing that I know C and I want to learn C++ to get a job as an engineer in the embedded field?', \"What's the best way to learn C++ in Urdu?\", 'Can I learn C++ on a Mac?', 'What are some professional C++ Programming Projects?', 'How can I learn to program/code in C++. I have been looking for books and videos but they are all expensive. I am looking for something free?', 'What is the best IDE for C/C++ in Ubuntu?', 'What are some good online tutorials for C and C++?', 'I want to learn C++ to make a game, but I am a beginner. What are the best C++ books from 2014 or maybe even 2015?', 'Can C++ be used for functional programming?', \"I'm in my first year of college. I started dwelling in C++ about 3 months ago. I have a relatively good grasp of the majority of the basics, but I have no idea how to use what I've learned in larger projects. Our professor is also absolutely horrible. How/where can I learn to code properly?\", 'I have learnt C++ programming in school in class 11 and 12. Now what should I learn to become a good programmer, and which online course should I take, and what are more topics and websites for C++?', 'How many days do I need to learn C++ Programming Language?', 'What are the best programming blogs for c/c++?', 'I have been learning C++ for about 2 months and I have finished the book I was reading. I have written some text based console programs. Where should I go from here?', 'Should I read any programming books to learn C++ or dive into open source projects directly if I already know programming in other languages?', 'How do I master C-Programming?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What makes your life worthwhile?', 'positives': ['What makes life worthwhile for you?'], 'negatives': ['What makes a happy life?', 'How would you describe a life that is not worth living?', 'What makes you enjoy life?', 'What makes the best life?', 'What is more important in life money or satisfaction?', 'What makes you enjoy your life?', 'What is the most valuable thing in this life?', 'Is it important to live life for yourself or is it better to live for others?', 'What is more important in life, money or satisfaction?', 'Which things make you successful in your life?', \"What's a healthy life?\", 'What is a meaningful life?', 'What are the most important things for living a good life?', 'What does living a life with a net worth of 50 million dollars look like?', 'What is most important in life - money or values?', 'What are the keys to a successful life?', 'What is the most soul satisfying thing you have ever done in your life?', 'What is life? According to you what definition would you give to life?', 'Life: What do you work for?', 'What is the most satisfying thing you have done in your life?', 'What does it mean by successful in life?', 'Is it better to live life for ourselves or for others?', 'What set of habits do you consider as the most important for success in life?', 'What makes you truly alive?', \"If being happy and making other's life joyful is the purpose of life then why so much importance is given to money and one's social status?\", 'What makes you happy to be alive?', 'Are you satisfied with your accomplishments in life?', 'What is your biggest accomplishment in life?', 'What inspires you most to do something in your life?', 'What is the most useful material in our daily life?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the capital of Denmark?', 'positives': ['What is the capital city of Denmark?'], 'negatives': ['What is the capital city of Belgium?', 'What is it like to live in Denmark?', 'What is the capital city of France?', \"What are Sweden, Denmark, Norway's major industries?\", 'Which are the best places to visit in Denmark? Www.krazybutterfly.com', 'Which city deserves to be the Capital of the World?', 'What is the biggest city in Finland?', 'What do people like about Denmark?', 'What is the best place to visit in Norway?', 'What is the capital of England?', 'Why are some European capital cities located right in the middle of the country?', 'What should I know about Denmark before visiting there?', 'Why are some European capital cities located inland right in the middle of the country?', 'What is it like living in Stockholm?', 'Which are some of the best hotels to stay in Copenhagen?', 'What is it like to live in Aarhus Denmark? What is the average living cost?', 'Where is the best place to visit in Sweden?', 'What are some of the most beautiful places to visit in Sweden?', 'What are the pros and cons of living in Stockholm, Sweden?', 'Do you have to be a resident to open up a bank account in Denmark?', 'What is Capital city of turkey?', \"What's it like to move to Denmark from the United States?\", 'If there were a world government where should its capital city/cities be?', 'What is it like to live in Denmark as a foreigner?', \"Why isn't Norway in the European Union?\", 'Why is Norway not part of the European Union?', 'What is the average salary in denmark?', 'What is the most beautiful place in Sweden that I should visit?', 'What is the most interesting thing about Norway?', 'Which one is the best to visit during June, Oslo or Copenhagen?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the things you would like to do if you only had two hours left to live?', 'positives': ['If you only had two hours to live, what would you do?'], 'negatives': ['What would you do if you only had a week to live?', 'What would you do if you had one week left to live?', 'What would you do if you only had a year to live?', 'What would you do if you had a week to live?', 'If you have one year left to live, what would you do?', 'What would you do with extra time if one day is 28 hour?', 'If you could live for 100,000 years what would you do with your time?', 'Tomorrow, you wake up as the only human being on Earth for an indefinite time. How would you live?', 'What would you do if you had $10,000 to spend in one day?', 'If you could go anywhere in the world for two weeks, where would you go?', 'What would you do if you have 3 weeks of free time?', 'If you died and God would give you another chance to live for 1 day what would you correct?', 'If you died and God would give you another chance to live for 1 more day what would you correct?', 'Would you like to live forever?', 'What Do You Need To Do To Stay Up For 2 Days Straight?', 'If you had 3 years to live and $3 billion to spend, what would you do?', 'For how long do you want to live?', 'If you had six months of free time starting today, what would you do?', 'How would you spend the last 10 days of your life?', \"What would you do if you didn't have to work for a living?\", 'If you could go back in time and re-do any single 24-hour period in your life, what would you have done differently?', 'What would you differently if you could live your life again?', 'If you died and God would give you another chance to life for 1 day what would you correct?', 'You have 4.196 seconds to live, what will you think about?', 'What should I do to turn 24 hours into 48 hours?', 'What would you do if you could be invisible for one day?', 'How long do you want to live? Why?', 'If you exercised really hard (with suitable rest) from now until you died, how long would you live?', 'What would you do if you had five free days a week for six months?', 'If there are no rules in your life for one day and you could be outrageous, what would you do?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'I feel depressed all the time. What do I do?', 'positives': ['I feel depressed all the time, what should I do?'], 'negatives': ['Why do I feel depressed?', 'Why I feel depressed sometimes?', 'Why am I so depressed?', 'Why am I depressed sometimes?', 'Why I feel good when I get depressed?', 'Why does one feel depressed?', 'Why am I still depressed?', 'Why do I always remain depressed and sad all the time?', \"I'm depressed, but I don't see the reason. Does anyone know how I feel?\", 'Why am I depressed again?', \"Am I mentally weak if I'm depressed?\", 'Why do I feel sad and alone all the time?', 'I am depressed about my future. What do I do?', 'Why am I always stressed and depressed?', 'Why do I often suddenly get depressed for no reason?', 'Why do I feel unhappy all the time?', 'Why do I feel so depressed and lonely?', 'Is it possible to be depressed and not know it?', 'Why do I feel so sad all the time?', \"I am so depressed. I don't see things getting better. What do I do when my mind won't let me be happy?\", 'Some days I am perfectly normal. But some days I feel very depressed and cry frequently, get angry and shout unnecessarily. Am I bipolar?', 'What do you do when you feel sad?', 'Why do I want to be with someone always, otherwise I am feeling depressed?', 'How do I love a depressed person?', \"Is there a way to force happiness when you're depressed?\", \"What should you do if you're feeling sad?\", 'Depressed because I can see my future play out. What can I do?', 'I feel life is miserable. I feel everything that happens with me is wrong. I try to be positive, but unable to be so. What should I do?', \"Why do I am so depressed after breakup that I don't like anything? Also why do whenever I talk to my ex I feel terrible?\", 'Do I have the right to be upset or is my depression making me see things?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I start my own local tv channel?', 'positives': ['How can I start internet TV channel?'], 'negatives': ['How can I use a satellite TV dish for internet?', 'How can you use satellite tv to get free internet?', 'How do I start a social network?', 'How do you start a social network?', 'How can I watch TV on my PC?', 'How can I program a TV to a Dish Network remote?', 'How do you access the internet on a Vizio smart TV?', 'How do you launch a social network?', 'How do I network in theater?', 'How does one live-stream TV on a website?', 'How would I start a social media app?', 'How should you launch a Social Network?', 'How do I start my own ad network?', 'How do I get American channels like CBS, FOX, AMC in India with the DishTV service provider?', 'How do I browse the Internet on a Vizio smart TV?', 'How can I connect my DVD player to my TV?', 'How do you program a Transmitter Remote to a phillips tv?', 'I want to run a cable television network at my locality. What is the procedure to obtain permission?', 'How do I connect a Sony TV to WiFi?', 'How can I do network setup for DirecTV?', 'How do I use Internet?', 'How many channels can we get in digital TV?', 'How do I start a company líke Act fibernet, hathway internet etc?', 'How we can download Tv Shows?', 'I wish to start a social media app, how should I begin?', 'What is the best way to watch TV?', 'How do I program a Dish remote to my TV?', 'How do you program a Dish remote to your TV?', 'How can you get more channels added to your TV?', 'What is a good website to watch all the latest TV shows on the Internet?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can we control anger?', 'positives': ['What should I do to control my anger?'], 'negatives': ['How can I control my anger towards my siblings?', 'What causes anger?', 'How do you overcome depression caused by anger?', 'How to control anger in a relationship? One slip of a word in spur of a moment spoils the entire day as it results in more arguments', 'How do I know if I have anger issues?', 'How can I show anger to my friends when they do wrong things in a wise manner?', 'What causes anger and why?', 'Effect of anger on a normal person?', 'What is the anatomy of anger?', 'Is anger a part of human nature?', 'Why am I angry all the time?', 'Has your anger ever gotten you into a less than ideal situation or argument? If so, how have you learned to address it?', 'What are some genuine circumstances under which anger is acceptable/appreciated?', 'How do I stabilize the anger and emotional lability that I am experiencing, while releasing long-suppressed emotions?', 'Why am I always angry?', 'Why am I so angry all the time?', \"What started as work stress has turned into almost overwhelming anger. I feel like I'm going to snap. How do I calm down?\", 'Why am I so angry?', \"So many bad things have happened in my life lately, I'm full of so much anger and lost in life. How can I overcome this?\", 'How can you describe an angry person?', 'I get angry over small issues. How I manage sudden outburst of anger and negative energy. Can this be sign of some mental problem?', 'Why do I feel extreme anger and crave revenge for any slight, no matter how insignificant?', \"I'm a big guy. When I get angry, people get scared and accuse me of threatening them. How do I stop this? I'm not actually a violent person.\", 'I choose not to let down someone who betrayed me. Is this okay? How do I control my anger and hatred towards that person?', 'Why do we get angry?', 'Why do I get angry for no reason?', 'Why do I get angry at almost everyone?', 'Do you think men and women show their anger differently?', 'What makes people angry?', \"I block people when I'm angry. I refuse to talk to them. Why do I get angry for such small things?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I prepare for the toefl exam?', 'positives': ['How can I study for TOEFL exam?'], 'negatives': ['What do test centers of TOEFL exam in India check?', 'I am going to to take TOEFL test 6 months later. What is the best method to use in order to get upper than 110?', 'Which is the best test center for TOEFL in ahmedabad?', 'What jobs can I get with the TOEFL?', 'Why do scores for the TOEFL exam expire in 2 years?', 'Is writing TOEFL mandatory with GRE?', 'What are the best materials/videos/resources and practises/schedule to get maximum marks in TOEFL within 2 weeks?', 'Can i have the USA student visa without having a toefl test?', 'Is it necessary to join classes for the preparation of GRE and IELTS/TOEFL examination?', 'Is TOEIC exam very important for Chinese who work in a foreign enterpirse?', 'What does the TOEFL test mean to Americans?', 'What are the best materials/videos/resources to get maximum marks in TOEFL within 1 week?', 'Could my TOEFL score be  more than 110 if I prepare the test 4 hours/day in 2 months?', 'How do I register for the TOEFL with multiple given names?', 'What is TOEFL IBT search service?', 'What are the best TOEFL coaching institutes in Banglore?', 'When is TOEFL held in India?', 'How do I prepare for TIFR GS Mathematics entrance examination?', 'Is GRE score enough to apply for PhD in US universities? Do I need to give TOEFL also?', \"How can I prepare for TIFR GS Chemistry entrance exam and interview for PhD for this year's exam in December?\", 'How do I register multiple given names in TOEFL?', 'Which is the best toefl coaching centre in Bangalore?', 'Are there any universities in the UK that accept GRE+TOEFL scores?', 'How can I prepare myself to crack the NID postgraduate entrance exam?', 'Is TOEFL not mandatory for MS admission in the USA?', 'How long does it take for TOEFL score to come out?', \"What's the best studying tips and tricks for the night before the exam?\", 'Which exam should I give first - “TOEFL” or “GRE”; Deadline being this september to give both exams to apply for fall 2017?', 'How do I change/correct name in TOEFL registration?', 'Toefl coaching in nehru place?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I pass a drug test for methamphetamine?', 'positives': ['Can hair dye help pass a hair follicle drug test for daily meth smokers?'], 'negatives': ['Does diluting urine work for meth drug test?', 'Does meth show on urine test the same day you use?', 'Why did methamphetamine show up on my drug test?', 'Is it possible to test +ve for Methamphetamine &/or Amphetamines through inhalation of 2nd-hand fumes from Crystal Meth smokers and, convicted even?', 'Will .2 grams of meth show up in a urine test 99 hours after consumed?', 'If I smoked meth Monday afternoon will I be clean for a urine test Thursday morning?', 'How likely is a hair drug test for pre-employment?', 'Are concerta and meth test the same?', 'What amount of hits can you smoke of meth so not noticeable and how often?', 'If I stopped smoking meth Sunday at 3 am will I test clean on a urine drug test for probation Friday morning?', 'Is modafinil considered methamphetamine? Would it show up on a drug test?', 'Is Dioxsyn pharmaceutical meth?', 'Greasy looking methamphetamines?', 'Will meth be out of my urine in 14 days?', 'Does Linkedin drug test potential employees?', 'Is Meth really that bad?', 'Does meth get excreted out from our sweat?', 'Can I pass a urine test after only smoking one joint?', 'If I smoked weed once a week ago and took a home drug test 7 days later and passed it will I be able to pass a pre-employment drug test?', 'Can you trust people using crystal meth?', 'Do mental health workers get tested for drug use?', 'Why are methamphetamine (meth) and marijuana treated differently?', 'Will certo work for meth?', 'How do I get an erection while using meth?', 'Is wet crystal meth not as good as dried out?', 'Does nicotine come in full body test?', 'How accurate are drug and urine tests?', 'Does long term drug use (meth) take sex drive away?', 'How do you dilute meth in your body?', 'How do you get a head change from hitting a meth pipe or bong?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What will be the impact of the step taken to ban the 500 & 1000 rupee note on Indian economy?', 'positives': ['What will be the implications of banning 500 and 1000 rupees currency notes on Indian economy?'], 'negatives': ['Will Indian rupees value increase against dollar from 9/11/2016?', \"How soon would India's GDP cross 10 Trillion USD and India's Per Capita Income cross the 10,000 USD respectively?\", 'What are the top risks (positive and negative) that could disrupt world economy in next 3, 5 and 10 years?', 'How does the American economy affects Indian economy?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which is the best laptop below 20000 in India?', 'positives': ['Want to buy a laptop below 20000?'], 'negatives': ['Which laptop is the best for computer science with a price limit of $2000?', 'I want to buy a new laptop. My requirement is i5 processor. Min 4 GB RAM and at least 500GB HARD DISC. My budget is around Rs 50000-60000. Which is the best laptop in these configuration and budget?', 'Where can I sell my laptop?', 'Which laptop shall I buy?', 'Which laptop is most suitable with the following specs?', 'Which laptop should I buy?', 'Where should I buy a Dell laptop in Kolkata?', 'Which laptop is the most suitable with the following specs?', 'Why most laptop companies selling low configuration laptops at nearly double price in India than the USA?', 'Which is the cheapest laptop with the following specs: 1TB HDD, Intel i5 (4th or 5th generation whichever is good), 8GB RAM, and a 2 GB Graphics card?', 'Which laptop brand is best?', 'Should I buy this new laptop or not?', 'Which laptop I should buy?', 'What laptop should I get?', 'I want to buy the best laptop. What are some suggestions?', 'Should I buy a new laptop?', 'Which is best laptop below 40k?', 'What laptop is the best value for me?', \"I'm buying a new laptop. What should I get?\", 'What kind of laptop should I buy?', 'What are the best laptops below 40k?', 'Where can I sell laptop parts?', 'How do you buy a Dell custom laptop?', 'Are laptops cheaper in Singapore when compared to India?', 'I am an architecture student from India looking to buy a laptop within a 50k to 65k rupee budget. What are some suggestions?', 'I am to purchase a laptop.I have a budget of $1100, and I have narrowed my choices down to Lenovo Flex 4 14, and Delll XPS 13. Which one should I buy?', 'Which is the best laptop to buy under 40K?', 'Which are some of the best laptops to buy in India?', 'Which is the best laptop brand in India?', 'What are the cheap laptops for programmer?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What do you do when you hate someone to the core?', 'positives': ['What should you do when you hate someone?'], 'negatives': ['What is it like to hate someone?', 'Why do we hate someone?', 'Do you hate someone for no reason?', 'What should you do when the person you love hates you?', 'Can you hate someone forever?', 'Why do you hate people?', 'Can you stop hating a person that you really hate?', 'What do you do when the person you most love hates you?', 'Why would you dislike someone?', 'Why do I hate people?', 'What does it mean when someone hates you?', 'Is it bad to dislike someone?', 'Why do people hate you?', 'Is it hard not hate someone who hates you?', 'Why do you hate people, but like individuals?', 'Why do people love and hate someone?', 'What should one do when they hate themselves?', 'What is the best way to tell someone you hate them?', 'What is to love someone who is hated by my friends?', \"Why can't I hate anyone?\", 'How do you deal with a person who hates you but have to spend time with whether you like it or not?', 'Why do people hate people?', 'Is it bad to hate everyone?', 'How can I tell someone I hate them?', 'How do you deal with self hate?', 'Why I hate some people?', 'How do I love and hate a person at the same time?', 'I hate everyone?', 'What do people hate about you?', 'How do I hate a good person?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I book cheap domestic flights in India?', 'positives': ['What are the best hacks to get cheap flight tickets in india?'], 'negatives': ['Do the cheap flight websites offer always the cheapest price?', 'How do I get cheap domestic air tickets in USA?', 'How can I book cheap flights to somewhere in Europe From India?', 'How do I get cheap flights to South America?', 'How do I find the cheapest flight to anywhere outside of the USA?', 'What are the best travel hacks for being on long flights?', 'How do I buy Future Cheap Tickets with Discount coupons online?', 'Do we get flight tickets at a cheaper rate when we buy them at the airport?', 'Where can I get air flight open ticket?', 'Which is the cheapest flight from anywhere in South America to Europe?', 'How do I book airline tickets through online?', 'Is it cheaper to buy your airline tickets at the airport than in advance online?', 'How can I book air tickets that are fully refundable?', 'What is the cheapest way to fly to India from Canada?', 'What are the best ways to get free upgrades on flights?', 'Airfares: What is the cheapest way to fly from Canada to India?', 'What is a free API to get flight data?', 'Flights: How can I find the best time to book air tickets for a specific destination for a specific date?', 'How does Paytm provide so cheap bus tickets?', 'How do I find the cheapest flights to Europe from the USA?', \"Why don't airlines offer super cheap, last-minute deals to help fill empty seats?\", 'Apart from India are there any other countries having similar ticket booking system like Tatkal ticket (IRCTC)?', 'What is the cheapest place to do sky diving in India?', 'Flight discount from chennai to Ahmedabad?', \"How can I buy cricket match ticket for South Africa's tour of India 2015?\", 'How can I find cheap return tickets from Europe back to the US?', 'What is the cheapest flight route between Europe and South America?', 'How do I book an airplane ticket online?', 'How are international air tickets priced?', 'Which are the most famous and cheap online shopping websites in India for buying electronics?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the possibility of war between India and Pakistan after surgical operation?', 'positives': [\"Is there any possibility of Indo Pak war after India's surgical strike?\"], 'negatives': ['Are the recent surgical strikes by Indian Army in Pakistan the first such operation by the Indian Military?', 'Is Indian army lying about surgical strike in Pakistani Kashmir?', 'Why India chose surgical strike against Pak, when it could have send a missile.?', 'Does India have the capabilities to carry out surgical strikes in Pakistan?', 'Has India carried out surgical strikes on Pakistan?', 'Are the recent surgical strikes by Indian Army in Myanmar the first such operation by the Indian Military?', 'Can any one defend that India did not do any surgical strike on Pakistan? Is it just the mind game of Ajith Dhoval.?', 'Is it true that India conducted surgical strikes in Pakistan on 29 September? Why is Pakistan denying it?', 'Why is Pakistan so angry if surgical strike never happened?', \"What is Pakistani media showing about Indian army's surgical strike in Pakistan?\", 'How can you confirm that India conducted surgical strikes in Pakistan?', \"Will India's surgical strikes in PoK not result in increase in terrorism in India as a retaliatory measure?\", \"How is the Indian Army's surgical strike in Uri in September 2016 different from the anti-insurgent operation in Mynamar in June 2015?\", 'Why is Pakistan not accepting that any surgical strikes happened?', 'Is Indian claim of surgical strike on Pakistani soil is lying?', 'What does an ordinary Pakistani citizen thinks about the latest surgical Strike by Indian Army in PoK?', 'Was the surgical strike in PoK made against militants or the Pakistan army?', \"Has any foreign media or intelligence agencies confirmed India's surgical strikes on Pakistan's side of the LoC?\", 'How good was the surgical strike by Indian Army on terror camps at PoK?', 'Why is Pakistan denying the surgical strike?', 'Has India done surgical strike before?', 'What is the reason behind Pakistan denying the surgical strikes by India?', \"What Pakistanis think about India's surgical strike on Pakistan?\", 'What are the solid evidences of surgical strikes done by the Indian Army in PoK?', 'Did anyone in Pakistan accept that a surgical strike happened?', 'What are the pros and cons of Indian surgical strikes in PoK?', 'What evidence can be provided by India to prove the claimed surgical strikes in PoK?', 'Did India provide any evidence for the claimed surgical strike?', 'What do you have to say about the surgical strikes that India carried out in Pakistan last night?', \"What does the rest of the world think about the Indian Army's surgical Strike in POK?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I improve my communication skills in english?', 'positives': ['What are the best ways to improve English?'], 'negatives': ['Why am I learning English?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'When and how did Ambrose Bierce die?', 'positives': ['How did Ambrose Bierce die?'], 'negatives': ['How did Louie Anderson die? When did he die?', 'How did Bruce Lee die?', 'How Bruce Lee died?', 'What killed Christopher Reeve? How did he die?', 'How was Bruce Lee killed?', 'Did Bruce Wayne die?', 'Who killed Bruce Lee?', 'Who killed Bruce Lee?', 'How did Joaquin Phoenix die?', 'How did Jerry Garcia die?', 'How did Peter Vesey (writer for American Astrology) die?', 'Why did Travis Bickle try to kill the senator?', 'How did Tupac die?', 'What happened to Hemant Karkare? Why was he killed?', 'How and why was Bruce Lee killed?', \"What is the truth about Bruce Lee's death?\", 'What was cause of Henri Becquerel death?', 'How did Salazar Slytherin die?', 'How did Lord Ram die?', 'Did Rowan Atkinson die or not?', 'How did Freddie Mercury die?', 'How did astrologer Peter Vesey die?', 'How did Swami Vivekananda die? Did he have a Christian book in his hand at the time of his death?', 'How did Ariana Dumbledore died?', \"What is the secret of Bruce Lee's death?\", 'How does Batman die?', \"How was Dumbledore's death?\", 'How did Aaron Swartz die?', 'Did John Cena die in a car accident?', 'What is the reason of Alejandra\\'s suicide in Ernesto Sabato\\'s \"On Heroes and Tombs\"?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the function of central processing unit in computer? How is it used?', 'positives': ['What is the function of central processing units in computers?'], 'negatives': ['What is a Central Processing Unit (CPU) and Random Access Memory (RAM)?', 'How do processing tasks occur in a computer?', 'What are the main characteristic of data processing system?', 'What are some of the main components of a computer? What functions do they serve?', 'What are all the functions of a CPU/GPU?', 'What is the main circuit board of a computer? What are its functions?', 'What are the basic component of computer system?', 'What are the different internal parts of a CPU and their functions?', \"What is a CPU's main function and use?\", 'What is a Graphics Processing Unit (GPU)?', 'What are the primary components of a computer?', 'What are the functions of the CU and ALU in the CPU of a computer?', 'What are the main components of a computer system?', 'What are the main components of a computer?', 'What are the main components of a computer? How do they work together?', 'What is a graphics processing unit?', 'What are the functions of a computer?', 'What are the different computer components? What are their functions?', 'What are the major components of a computer system?', 'What are the components used in CNC machine?', 'What are the functions of the hardware components of personal computers?', 'What is the main circuit board of a computer? How is it built and what is its function?', 'What are the main characteristics of data processing?', 'In what sense the memory stored in computers?', 'What are the components of  a computer?', 'How can I understand CPUs and GPUs?', 'What are the internal parts of a computer system? What purpose do they serve?', 'What are the internal parts of a computer and what is their purpose?', 'What are the function of system programs?', 'What is the architecture of a core of a cortex m0 processor?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the difference between ETF and mutual funds (with respect to Indian markets)?', 'positives': ['What is the difference between ETF and mutual funds?'], 'negatives': ['What is the difference between portfolio management and mutual funds?', \"What's better, an index ETF or an index mutual fund?\", 'What is a mutual fund investment?', \"What's mutual fund and what are the pros and cons?\", 'What is a dual fund under the mutual fund classification?', 'What is mutual fund all about?', 'Which mutual funds are better for investment?', 'What are the main differences between hedge funds and investment banks?', 'What is mutual funds with examples?', 'What is the difference between regular and direct plans of mutual funds?', 'What are some good value investing mutual funds (not ETFs)?', 'What are Mutual funds? How do they work?', 'What is a mutual fund I should invest in?', 'What is the ETF and the ETN?', 'What is ETF?', 'What is the difference between dividend and growth in mutual funds?', 'Which bank is better for mutual fund?', 'Why should you invest in mutual funds?', 'What is balance mutual fund and hybrid fund?', 'Which mutual fund should I invest in and why?', 'What is a mutual fund? How can we choose companies in which we can invest?', \"How do the iShares index ETFs compare to Vanguard's index funds?\", 'What is the difference between regular and direct plans of mutual funds in details by expert only who gained good fund?', 'How does one invest in mutual funds? What are the pros and cons of investing in a mutual fund?', 'Which are the best mutual fund in market?', 'How do you choose a mutual fund to invest in?', 'Which is the best mutual fund to start with?', 'What is the difference between a hedge fund and an investment boutique?', 'What are mutual funds or etfs that have large capital gain distributions?', 'What mutual funds can I invest in?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Does anyone believe that there is life on other planets?', 'positives': ['Is there no life on other planets?'], 'negatives': ['Why earth is the only planet in the solar system capable of supporting life?', 'Why is it controversial to say that the Earth could be the only planet in the universe with life?', 'Is there any possibility, that human beings could live on another planet? If yes, how much time will it take to take all humans on that planet?', 'Are humans truly from another planet?', 'If there are 50 sextillion habitable Earth-like planets in the universe, is it possible that there are humans in other planets in the universe?', 'Is it possible that there\\'s \"no night\" on planets orbiting in a binary star system? What are the chances for such planets to be habitable?', 'Is there a planet X in our solar system?', 'How might life on earth be different without our moon?', 'What are the chances that earth is the only habitable planet in the universe?', 'Is there a planet in real life similar to Neverland?', 'What effect do the other planets in the solar system have on Earth?', 'Will it be possible for NASA to fabricate new planets, for possible human life and our basic needs and wants such as water and air?', 'How important would be the finding of another planet in our solar system?', 'Are all planets orbiting in the same plane?', 'How close are the planets of our solar system to being in the same orbital plane?', 'When Sun start expanding and starts pulling the planets towards it,will there be a chance for other planets like Saturn or Uranus to become habitable?', 'How many planets in our solar system would be habitable by humans?', 'Do the planets of the solar system orbit on the same plane?', 'How many planets are there?', 'Why are we solely searching for water/O2/hydrocarbons on other planets? Does it make sense that there may be living creatures on other planets surviving on fire, sulfates, phosphates etc etc as how need O2?', 'What is the other planet after Pluto?', 'How come the other planets have mythological names and ours is just called Earth?', 'Could two planets touch each other and survive?', 'Can two planets share the same orbit?', 'Are all planets round and why?', 'Do we really go to other planets and take birth after death or take rebirth here?', 'As the sun grows old and changes, what will happen to other planets in our solar system?', 'Will the planets eventually fall onto the sun?', 'Do planet X exist?', 'The earth is a life-bearing planet because of its precise location in relationship to the sun, like our moon. Would we be alive if we had no moon with its various impacts on the planet?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I recover my Gmail forgot my password and recovery no?', 'positives': ['How do I reset my password to Gmail without my recovery information?'], 'negatives': ['How do I reset or recovery my Outlook password?', 'Is there a way to find my iCloud password without security questions if forgotten password?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I tell someone that Im sorry?', 'positives': ['How do I tell someone that I am sorry?'], 'negatives': ['How I can apologize to someone?', 'How do you apologize to someone?', 'How can I apologize?', 'How does one forgive someone who is not sorry?', 'How should I say sorry to my girlfriend?', 'What is the best way to apologize?', 'How do I say sorry to my boyfriend?', 'How can I say sorry to the dead?', 'What is the best way to say sorry to a woman?', 'How do I say sorry to ex-girlfriend?', 'How does one apologize?', 'How can you apologize without actually saying the words \"I\\'m sorry\" or being apologetic?', 'How should I apologize to her?', 'Why is it okay to say sorry even when you are not wrong?', 'Why should we say sorry?', 'How can I make a sincere apology?', 'Why do people say sorry?', \"Should you forgive someone who's not sorry?\", 'What do I do after apologizing?', 'How can we forgive someone who never apologizes?', 'How do I say sorry to my ex boyfriend for betraying him?', 'Does saying \"I apologize\" mean as much as saying \"I\\'m sorry\"? Why or why not?', 'How do I say sorry to my sister?', 'Is it okay to ask sorry on behalf of someone/a group of people?', 'How can you make someone forgive you?', 'How can I ask forgiveness from someone I hurt so much?', 'Why is saying \"I\\'m sorry\" a sign of weakness to some?', 'Why do some people hate to say sorry?', 'What is the best way to make someone forgive you?', 'Why do people say \"sorry to hear that\" when they mean \"I am sorry that happened\"?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How long does it take to learn Mandarin Chinese?', 'positives': ['How long will it take for a complete beginner to learn Mandarin?'], 'negatives': ['Is mandarin hard to learn?', 'What is the best way for an English speaker to learn Mandarin?', 'What are some good ways for bright kids 5 to 8 years old to learn Mandarin that does not require a lot of expense or parental time?', 'When working in Mainland China as a foreigner, how do you learn Mandarin, is Pinyin enough?', 'If I have a basic understanding of Chinese Mandarin, what is the best way to try to learn Cantonese in the least amount of time?', 'Should mandarin speakers be required to learn chinese?', 'How long does it take to learn a new language?', 'How do I learn Mandarin Chinese well?', 'How can I teach myself Mandarin for free?', 'Is it best to learn basic Cantonese or Mandarin before going to Hong Kong?', 'Should I learn Mandarin Chinese or Japanese first?', 'How long does it take to master a language?', \"What's the best way for a Mandarin-speaking person to learn Cantonese?\", 'Should I learn Mandarin or Japanese?', 'Should I learn Mandarin and Cantonese at the same time?', 'Does anyone recommend learning Cantonese and Mandarin at the same time?', 'Should I study Japanese or Mandarin Chinese first?', 'How long will it take to learn Korean?', 'Should I learn Mandarin or Cantonese?', 'If you can speak Mandarin at a decent level, how hard is it to pick up Cantonese?', 'How long does it take to fluently speak a language?', 'What are the pros and cons of learning Mandarin and Cantonese at the same time?', \"What's the best way to learn Cantonese for Mandarin speakers?\", 'How many hours does it take to learn a language?', 'How long did it take you to learn a new language?', 'How long does it take to learn basic Arabic?', 'How much time would it take to learn a new language?', \"Should Mandarin course be introduced in the schools? Isn't Nepal missing out on a world of economic opportunity by not learning Mandarin?\", 'Which should I learn and why: Mandarin or Japanese?', 'Mandarin: How do parents in China teach Mandarin characters to their children?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'I have two options to do my research in PhD, Virtual reality and Flexible display. Which one should I go for?', 'positives': ['I have two options to do my research, Virtual reality and Flexible display. Which is the best area to do research now?'], 'negatives': ['What are some best research areas in virtual reality in which I can persue my masters degree?', 'What are some future applications of virtual reality?', \"What are the master's programs that have strong research groups on augmented reality/virtual reality in the US?\", \"What are the master's programs that have strong research groups on augmented reality/virtual reality in Canada?\", 'Can I opt for different research field than my M.Tech topic?', 'What is more attractive, virtual reality or augmented reality?', 'What is the future for visual presentation and exhibition design? Is it a good major?', 'What companies specialise in augmented and virtual reality in India?', 'What VR Games and Apps should I feature in an upcoming Showcase Video?', 'Is there any comparison of mobile VR market and desktop VR market?', 'What are some websites to watch accessible but technical science and technology presentations?', 'What are the best courses/resources for learning virtual reality?', 'What is the future of virtual reality?', 'What is the future of virtual reality in education?', 'What technology should we use to develop for the web a 3d virtual design tool ?', 'Where can I find virtual reality headset all in one for comparing with price/specs and compatibility and features?', 'What areas of business require greater research?', 'Where can I find virtual reality headset all in one for comparing with price and specs?', 'Which from the following will have a stronger impact on the next 10 years: Internet of things, Big Data, virtual reality, 3D impression or drones?', 'Which are the courses on Coursera or other MOOCs to study exhibition design?', 'Which course will be more useful in the future. Graphic designing or Web development?', 'What are the skills required to design an augmented reality UI & UX?', 'What are some of the possible long term scenarios for complex virtual reality?', \"I'm studying computer science, but I'm interested in motion design. How should I go about it?\", 'Which virtual reality headset is best for use with SecondLife?', 'What is the difference between augmented reality and virtual reality?', 'Will virtual reality play a role in sales or marketing in 3 years? How?', 'What are recent topics of research on digital electronics field?', 'What are areas of research in the field of computer science?', 'I want to do a project proposal on using \"virtual reality techniques on the simulation of chemistry experiments.\" How can I go about it in terms of web application?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are some Pokemon Go hacks?', 'positives': ['What are some of the best Pokemon Go hacks?'], 'negatives': ['What is your review of Pokémon GO?', 'What is Pokémon GO?', 'What are the best Pokémon games online?', 'What are your thoughts on Pokemon Go?', 'What do you like most about Pokémon Go?', 'What is your favorite Pokémon in Pokémon GO?', 'Is Pokémon GO the best game ever made?', \"What's Pokémon GO's biggest appeal?\", \"What's your Pokémon GO story?\", 'What are currently the most powerful Pokémon available in Pokémon GO?', 'What is it like to play Pokemon Go?', 'What is the best way to get Pokemon Go game in Android devices?', 'How do I get more Pokémon in Pokémon Go?', 'Which is a better Fire Red Hack: Pokémon Fire Red Omega or Pokémon Furious Flamed?', 'What are the most effective Pokémon in gym battles?', 'Is it good to play Pokémon GO?', 'How many Pokémon are available in Pokémon GO?', 'Whats your favorite Pokemon?', 'What are your top 3 best Pokemon movies?', 'How many of each Pokémon should I keep in Pokémon GO?', 'What do you think of Pokémon GO? Do you know actual working cheats?', 'What devices is Pokémon GO (mobile app) compatible with?', 'I have caught all the 145 Pokémons available in Pokémon Go? What do I do now?', 'What was your funniest experience playing Pokémon GO?', 'What are some interesting things that happened while you were playing Pokémon GO?', 'Is there any Plants vs Zombies Heroes Hack?', 'What is the best possible team of Pokémon?', 'Which Pokemon (generation 1-2) game is the best?', 'When should I power up a Pokémon in Pokémon GO?', 'How was your personal experience with Pokémon GO ? Share your story.'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Is dark/vacuum energy infinite because the expansion of the universe is infinite and more and more of it is created as the universe expands?', 'positives': ['If universe expands and vacuum energy is created with it (with no limit),is there infinite potential energy/infinite vacuum energy that can be created?'], 'negatives': ['As space expands, it releases stored up gravitational potential energy, which converts into the intrinsic energy that fills the newly created volume?', 'Can energy be created in a non-energy environment?', 'Is it true that matter/energy actually can be created and/or destroyed?', \"If energy can neither be created nor destroyed, doesn't that law suggest God created it because He can operate outside the laws of our universe?\", 'Are dark matter and dark energy: energy?', 'Can we create free energy?', 'What is infinite?', 'Energy can neither be created nor destroyed! Can this be proved wrong?', 'What is potential energy dependent on?', 'Where is the energy for dark energy coming from?', 'Why is the dark matter being transformed into dark energy?', 'What created energy? Or was it always there already? Did it create or cause space time and dimensions?', 'Why is it that an object does not need any energy to fly in space for eternity?', 'Could the gravitation of overlapping universe be the cause of dark energy?', 'Does matter and antimatter exist in a same dimension or different ones? If different ones, would the new energy caused by their mixing add new energy amounts to our universe thus violating the entropy law?', 'Energy can neither be created nor destroyed. So where does energy crisis come from?', 'Why is gravity infinite?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What should I do to deactivate my account?', 'positives': ['How do I deactivate my account?'], 'negatives': ['How do I deactivate my account on Ubuntu?', 'How do I deactivate a Yahoo! account?', 'How do I deactivate my fb account?', 'How can I deactivate my yahoo account permanently?', 'How do you activate a deactivated Yahoo account?', 'What is the difference between deleting and deactivating my account?', 'Why did Yahoo deactivate my account?', 'How do you permanently delete your Yahoo account?', \"What's the difference between deactivating and deleting my account?\", 'How can I deactivate my fb account permanently?', 'What are some ways of deleting my BearShare account?', 'How to delete in.com account?', 'How do I delete my Yahoo account?', 'How do you delete a Bandsintown account?', 'How can you delete your Yahoo account?', 'How do I delete my Quora account which has been banned?', 'How do you delete your Yahoo account permanently?', 'How do I delete my Line account?', 'How do you disable a Yahoo account?', 'What is the best way to delete my Yahoo account?', 'What do I see if someone has deactivated their account?', 'How do you delete a Imagekind account?', 'How do I delete my dating.com account?', 'How can I delete my account which has been banned on Quora?', 'How can you delete your Yahoo mail account?', 'How can you terminate your Yahoo e-mail account?', 'How do you delete your Yahoo email account?', 'How do you cancel your Experian account?', 'How can you delete your Twine account?', 'What is the safest way to delete my Yahoo account?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the best answer for tell me about your self in an interview?', 'positives': ['How should you answer the interview question \"Tell me something about yourself?\"'], 'negatives': ['How should one answer the question \"tell me something about you apart from what your resume says\" in job interviews?', 'How should one answer the question \"tell me something about you which is not a part of your resume\" in job interviews?', 'What is the best answer to give in an interview when this question is asked: \"describe yourself in one word\"?', 'What answer when someone (a girl) ask you \"Tell me something interesting about you\"?', 'How does one answer the interview question: \"What are your strengths/weaknesses\"?', 'What is the best answer to the question, \"Why you?\" asked in an interview?', 'How do I answer the interview question “Why do you want to work here?” when I don’t want to?', 'What do I answer this interview question?', 'What is the best possible answer to the question \"sell yourself\" in interviews?', 'How do you answer the question \"what are you good at?\"?', 'How can I introduce myself in an interview?', 'How should you introduce yourself in an interview as a fresher?', \"What are the best replies to the interview question 'where do you see yourself in the next 5 years'?\", 'How do I introduce myself in a personal interview?', 'How do I answer the question \"Tell me something about you\" when I\\'ll be using Facebook or any messaging platform?', 'What is the best answer to give in a job interview?', 'How do you answer an interview question which has no answer?', 'How can I write a \"tell me about yourself\" essay for university?', 'How do I introduce myself for an interview?', 'What are the most commonly asked interview questions and how do I answer them?', 'What are the most common job interview questions and how should you answer them?', 'What are some questions you have been asked in an interview?', 'How do you answer the question of \"Do you like me\", asked by someone of the opposite sex?', 'What should I do if I\\'ve been \"Asked to Answer\" but have nothing useful/interesting to say for that question?', 'How do I answer the question \"What if we don\\'t hire you\" in an interview?', 'How should I introduce myself properly when interviewing a job?', 'How do I respond when someone says \"I told you…\" or more specifically \"I told you\\'d like it\"?', 'In a job interview, how should I answer the question \"how much money do you want to make\" or \"how much did you make in your last job\"?', 'How should you talk in a job interview?', 'Should you say \"I\\'m well\" or \"I\\'m good\" when someone asks how you are?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What wild animal would make the best pet? Why?', 'positives': ['Which wild animal would be the best (or least worse) pet?'], 'negatives': ['What are the most interesting animals?', 'Which is the deadliest animal?', 'What is the most unknown animal species?', 'What wild animal is most friendly to humans?', 'What are some cute-looking but fierce wild animals?', 'What are the largest dog breeds that make great pets?', 'If you were a different kind of animal, what animal would you want to be and why?', 'Which are the most interesting hybrid animals?', 'Which animal is the best: Elephant, Tiger, Penguin, Zebra, or Frog?', 'If you were an animal, which one would you be?', 'What is the deadliest animal in the world?', \"What are some very cool animals that make really good pets that people don't normally have?\", 'Which animal (besides us, humans) kills the most other animals (including humans) on average?', 'What pets are the most useful?', 'What is, in your opinion, the best dog breed, and why?', 'What are some unusual animals that make amazing pets?', 'Which animal is more intelligent? Pigs or dogs?', 'Can cows be better pets than dogs and cats?', 'Which dog breed is good?', 'Which animal loves humans the most other than dogs?', 'Which is our national animal?', 'What are some of the most interesting hybrid animals?', 'Which is the cutest animal in the world?', 'Which is the most dangerous animal on the Earth?', 'Why are wild animals so unpredictable to humans while dogs and cats can be our pets?', 'What are some mammals that don’t have much fur?', 'What are some exotic pets that are easy to care for?', 'Who is the most talented animal ever?', \"What are some animal species that most of the people don't know?\", 'What is your favorite animal? Why?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the best places to live in the USA?', 'positives': ['What are the best places to live in America?'], 'negatives': ['Is the United States the best place to live?', 'What are some of the best places to live in America that are located in a forest?', 'Which is the best place to live in this world?', 'Where do you think is the best place in the world to live?', 'Where is the best place to live in india?', 'Which is the best place to live in India?', 'What, in your opinion, is the best country to live in?', 'What are the best and cheapest places to live in the world?', 'What does it feel like to live in America?', 'What are the most beautiful places to live in the world?', 'Where do you think would be a good place in America to get some land and live off-grid?', 'Which is the best country to work and live in?', 'What is the best place to visit in South America?', 'What are the best places in South America?', 'Which is the best and cheapest places to live in the world?', 'Which is the best country to work and live?', 'How does it feel like to be living in America?', 'Which is the better place to live: Canada or the USA?', 'Which is a better place to live, Australia or the USA?', 'Where are the best places for an INFP to live?', 'Which country is the best place to work in?', 'Where is the best place in the United States to live in your early 20s: NYC, San Francisco, or Chicago?', 'Which is a better place to live: Australia or the USA?', 'Where are the best places to live in Brazil and why?', \"Where's the best ex-pat country for US people to live?\", 'What is the best place to live in Asia?', 'What countries are most popular for American expats to choose to live?', 'Which is the nice country to live?', 'Which is the best city in the world to live in?', 'What is the best place to visit in Latin America?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'According to mainstream physics, what is there outside the Universe?', 'positives': ['What is there outside of the Universe?'], 'negatives': ['Is there life in the universe?', 'Could the universe exist without you?', 'How did everything in the universe get here?', 'What lies at the \"edge\" of our universe?', 'Can we cross the border of our universe?', 'Why we are here in the universe?', 'Does the Universe exist?', 'What is the shape of the universe?', 'Is the Universe infinite or is there an end to the Universe?', 'Is there an end to the universe, and if not, is the universe infinite?', 'Why is the universe even present?', 'Does the universe exist because no other universes can exist?', 'We know universe is expanding but also bodies are attracted by gravity so is it safe to assume that the universe is revolving around something?', 'What does the edge of the Observable Universe look like?', 'If the universe is \"all\" then is anything previous a part of the universe or not?', 'Is God the universe?', 'Can the universe exist without life?', 'What was here before the universe?', 'Was there never a beginning to the universe?', \"We can't see the universe beyond our time and mind. Why?\", 'What shape is the event horizon of the universe?', 'How was the universe created? Will there be an end to universe?', 'How the universe looks like?', 'What is meant by universe?', 'Where is the origin point of the big bang in space? And how far are we from there?', \"What's the proof that the universe is expanding everyday?\", 'What is the beauty of this universe?', 'What is outer space?', 'What is the probable shape of the universe?', 'What was there before the Big Bang? How can there be something from nothing?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What powers does the President of India holds?', 'positives': ['How much power exactly the President of India holds?'], 'negatives': ['How much power does a President-elect have?', 'What is the salary of the President of India?', \"What is the President's salary in India?\", 'How is the president of India elected?', 'What is the salary of President of India?', 'What powers does a RBI Governor of INDIA has?', 'What are the powers of prime minister of India?', 'Politics: How many times a person can be elected as a President in india?', 'Who is the India of the president?', 'What is the salary of an Indian president?', \"What is the Indian President's salary?\", 'What is the salary of indian president?', 'How much power do prime ministers/presidents really have?', 'What is the name of the president of India?', 'What is the name of president in India?', 'Who is the most powerful man in India? And why?', 'Is India the most powerful democratic nation?', 'Why is the prime minister more powerful in India whereas the president is more powerful in the US?', 'How much power does the Monarch of the United Kingdom have?', 'How is the prime minister more powerful than the president in India?', 'Why does the office of president of India, being politically neutral, not ask for Population control in India?', 'Who is the current President of India?', 'How much power does the U.S president have over state budgets?', 'How is the Vice President of India elected?', 'How strong is the Indian lobby in world powers?', 'Who is more powerful in India, president or prime minister?', 'Who nominates the President of India?', 'Which president expanded executive power the most? How?', 'Who is Indian President?', 'How much power does the British monarch have in comparison to other monarchs?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the most embarrassing moment you have experienced in public (strangers)?', 'positives': ['What is your most embarrassing moment in public?'], 'negatives': ['What was your most embarrassing moment on Quora?', 'What are the most embarrassing moments you have had in your office?', 'What are the most embarrassing moments in RGUKT?', 'What has been your most embarrassing moment on Social Networking Sites?', \"What's the most embarrassing thing that has happened to you on Quora?\", \"What's the most embarrassing thing that happened to you on a date?\", 'What is the most embarrassing photo you have ever taken of others?', 'What was your most embarrassing moment during your school life?', 'What was the most embarrassing moment in front of your client?', 'What is the most embarrassing thing that ever happened to you when you were drunk?', 'What has been your most embarrassing moment as an athlete?', 'What is your most embarrassing injury?', 'What is the most embarrassing thing you have been caught doing at work?', 'What is the most embarrassing thing that happened to you at work?', 'What is your most embarrassing moment as a teen?', 'What is the most embarrassing moment of your life when you were a kid?', \"What is the most embarrassing thing you've done to your wife/husband?\", 'What are the most bizarre things you have done in public?', 'What is the most embarrassing moment from your teenage years?', 'What is your most embarrassing moment during your childhood life?', 'What was your most embarrassing moment in childhood?', 'What has been your most embarrassing moment from childhood?', \"What's the most embarrassing misconception you've ever held?\", 'What is the most embarrassing moment of your childhood?', 'What is the most embarrassing thing that can happen to a Quora user?', 'What was the most embarrassing thing that ever happened to you as an adolescent?', \"What is the most embarrassing thing you found on someone's phone?\", 'What are some of the most embarrassing things you have done for sex?', 'What has been your most embarrassing moment as a teacher?', 'What is the most embarrassing thing you have done to get a job?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is a medical abortion?', 'positives': ['What about medical abortion?'], 'negatives': ['How is an abortion done?', 'How are abortions done?', 'How is abortion wrong?', 'How do abortions work?', 'When is abortion done?', 'Is Abortion wrong? Why? Why not?', 'Should abortion be legal?', 'Is abortion a morality issue?', 'How does it feel to have an abortion?', 'How is abortion different from murder?', 'How painful is an abortion?', 'Is abortion morally wrong?', 'Is abortion morally right?', 'Can you feel an abortion?', \"Should abortion be legal in cases that don't involve rape, incest, or possible death of the mother?\", 'Do fetuses suffer during an abortion?', 'Are there any benefits to keeping abortion legal?', 'How is the \"Abortion Pill\" provided?', 'Why should abortion be allowed (except in cases of low chance of survival of child, mother or both) for rape, incest or other cases?', \"I'd calmly like to ask why those who believe in abortion don't believe it is murder? Please no hostility for this question.\", 'Is abortion selfish?', 'Are there people against euthanasia but pro-abortion?', 'Putting politics and religion aside, why is abortion wrong or morally dubious?', 'Why do women get abortions?', 'Why do some women get abortions?', 'Do anti-abortion laws prevent women who are not poor from having abortions?', 'Why are pro choice people against the right to financial abortion for men prior to a pregnancy?', 'Are anti-abortion laws keeping anyone other than poor women from getting abortions?', 'Is abortion morally permissible?', 'If you think abortion is murder then do you think the mother and the doctor should be tried as murderers?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which is the best short story related to Indian mythology you have come across?', 'positives': ['What is the best short story related to Indian mythology you have come across?'], 'negatives': ['What are some quintessential Indian stories?', 'What are some of the most interesting or lesser known stories in India’s ancient history?', 'What are the most powerful and insightful Tamil short stories that you have read?', 'What are some great English books about Indian Mythology?', 'What are some recommended books on Indian mythology?', 'Which are the stories related to the Hindu mythology unique to the South-East Asia?', 'Is any of Indian mythology stories proved by science?', 'What is your Indian love story?', 'Which is the best book for Indian history?', 'What are the most powerful and insightful short stories that you have read?', 'What are some great books about Indian culture?', 'What are the some of the most interesting stories about Ravana based on Hindu mythology?', 'What is your love story, especially Indian love stories?', 'What parallels can we draw between Indian and Greek mythology?', 'What are the best Tamil sites to read short stories?', 'What small detail from an Indian movie do you love?', 'What are some good nine-word Hindi stories?', 'What is your favorite (short) poem in your native language?', 'What are some good books on ancient Indian history?', 'Which is the best Indian short film?', 'What are the best short films from Indians?', 'What are the best way to learn about Indian history?', 'Which are some of the best Indian (Hindi & other languages) short films?', 'What should everybody know about Indian History?', 'What are some good books on ancient and medieval Indian history?', 'Which are the best books to read on Indian history?', 'Tell us some true Indian first night stories?', 'What are some of the interesting stories about the Sun (Surya) in Hindu Mythology?', 'Which is the best book on history of Indian architecture?', 'What are some of the best Asian short stories ?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Should blueberries be refrigerated?', 'positives': ['Why do blueberries have to be refrigerated?'], 'negatives': ['Why did lemon juice that sat refrigerated for two years turn red-brown with clumps?', 'Can seedless strawberries be made?', 'Are strawberries the only fruit with seeds on the outside? Why have they evolved to be this way?', 'Do they have blueberry ice cream at the grocery store? Or not?', 'Are white strawberries in Japan genetically engineered to have that color?', 'Why is a banana a berry?', 'Can seagulls eat blueberries?', 'What is the best way to evenly ripen a quart of hard and tart supermarket strawberries? Should they be left on the counter, in the fridge, or a combination of both?', 'Why do different foods decay at different speeds? Raspberries have a relatively short life compared to bananas and blueberries. Why?', 'If mangoes are slightly brown and soft inside, have they gone bad?', 'Does Coca-Cola need to be refrigerated?', 'Food Chemistry: What are the molecules \"floating around\" that give the aroma of \"blueberry\"?', 'How did strawberries evolve to be the only fruit with seeds on the outside?', 'Why do watermelon have seeds?', \"Why do molasses need to be refrigerated? What would happen if they don't get refrigerated?\", 'Why do so many supermarket products have blue and yellow colors?', 'Do they have blueberry lychee ice cream at any USA grocery store? Or not?', 'Is there such a thing as a blueberry pearl?', 'Why do watermelons have so many seeds?', 'Why is the tomato considered a fruit?', 'Why are tomatoes considered a fruit?', 'Why are watermelons red on the inside?', 'Is their such a thing as a natural blueberry pearl gem?', 'Can tortoises eat blueberries? Why?', 'What is blowing raspberries mean?', 'Gardening: Are strawberries annuals or perennials?', 'Is watermelon a fruit or a vegetable?', 'If you cut a fruit and keep it in the fridge, will it get spoiled?', 'Why do plants bear fruits?', 'Why are bananas healthy?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How will the decision of scrapping INR 500 and INR 1000 notes affect real estate prices?', 'positives': ['Will abolishing 1000 and 500 currency note affect property prices?'], 'negatives': ['Are property prices finally going down?', \"What affects a currency's value?\", 'Does issuing of larger denomination currency note reflect decreasing value of money in terms of Dollar?', 'What will happen if a jewelry shop accepts old 500 and 1000 notes?', \"What will happen to the value of money of excess notes of 1000's which will not be deposited, due to being black money.?\", 'Would using the 1031 exchange make me a bad real estate investor?', 'Will the demonetization of 500 and 100 rupee notes affect restaurants?', 'Are real estate prices going down in 2014?', 'Should we give property to those buyers who are in cyclic debt?', 'Will the U.S. ever see an asset backed currency?', 'How will the demonetization affect the value of rupee against dollar?', 'What are the serious disadvantages of demonetization of currency notes in India?', 'Would you dispose the old 500 INR and 1000 INR currency notes as a notaphilist (currency collector)?', 'Do the demonetisation of high value currency effect Indian economical growth?', 'What area or city in the US is likely to increase most in real estate values in the next, say, 5 years?', 'Are governments of countries with tear-away real estate speculation irresponsible, by not imposing substantial levies on foreign purchasers?', 'How does banning 500 currency notes, guarantee that the black marketers will be caught and punished?', 'How do I price real estate products?', 'What will be the impacts on gold price in future when scraping large currencies in India?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"If I can't stop thinking about someone, am I in love with that someone?\", 'positives': [\"What does it mean when you can't stop thinking about someone?\"], 'negatives': [\"How can I stop thinking about someone I shouldn't?\", \"What should I do if I can't stop thinking about my ex?\", 'How do I stop thinking about thinking?', \"Why can't I just stop thinking and start doing something?\", 'What can I do to stop thinking about anything?', \"Is it true that if you can't take someone off your mind, it's because even that person is thinking about you?\", 'How could I stop thinking about something/worrying?', 'How can I stop thinking about everything?', \"How can I stop thinking about someone who doesn't love me?\", 'How should I stop thinking about others and start thinking about me?', \"I can't stop thinking about a girl and its driving me insane. I can't focus on my studies because of this. How can I get rid of this feeling?\", 'How do I stop thinking of something?', 'What can I do to stop over thinking?', 'How do I stop thinking more?', 'How do you know when someone is thinking of you?', \"What does it mean when I can't forget a guy?\", \"If you think about someone does that mean they're thinking about you?\", \"Love: I'm deeply in love, and I can't stop thinking about him all day. This drives me crazy. How can I stop thinking about him, knowing that he most likely doesn't like me back and only sees me as a friend/sister?\", 'How do I stop myself from thinking?', 'How do I stop thinking of nothing?', 'How can I stop over thinking?', \"Do you believe that someone is thinking about you when you can't sleep at night?\", 'How can one stop over thinking?', 'How could I stop thinking at all?', 'How do I stop over thinking and worrying about everything?', 'How do I stop over thinking?', \"People tell me not to care about what others think of me. But I can't stop caring what people think. Why can't I stop? \", 'How can I stop thinking about it?', 'How can I stop worrying and over-thinking about everything?', 'Can I stop over thinking?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can one cure sleep paralysis?', 'positives': ['What are the ways to prevent sleep paralysis?'], 'negatives': ['How do you cause sleep paralysis?', 'Is sleep paralysis dangerous?', 'Why is sleep paralysis dangerous?', 'How common is sleep paralysis?', 'How is sleep paralysis studied?', 'Is sleep paralysis true?', 'Is sleep paralysis bad for you?', 'What causes sleep paralysis?', 'Is sleep paralysis unhealthy?', 'Do you have a sleep paralysis experience to tell?', 'What is it like to experience sleep paralysis?', 'Is sleep paralysis rare?', 'Why does sleep paralysis happens?', 'Why does sleep paralysis happen?', 'Why I often feel sleep paralysis?', 'How do i avoid sleep?', 'How does one avoid sleep?', 'What is sleep paralysis, what kind of people experience it, and why?', 'How can I control sleep?', 'Is there a way to bypass sleep?', 'What are the best ways to treat sleep disorder?', 'What ways are there to reduce the amount of sleep needed?', 'How can you manage sleep (decrease sleeping time) in daily life?', 'How can you treat a sleep disorder organically?', 'Have you experienced Sleep Paralysis in the past two weeks? If so, would you like to take part in an on-going online research study?', 'How do you control your sleep?', 'Do you have an interesting sleep paralysis story to share?', 'What should I do to avoid sleep for studies?', 'How can I reduce my sleep?', 'What are some tricks to sleep instantly?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which is the best college of mechanical engineering in Ahmedabad?', 'positives': ['Which is the best college for mechanical engineering in Ahmedabad?'], 'negatives': ['Which is the best engineering college in gujarat?', 'Which is the best engineering college in Gujarat university?', 'Which is the best college for mechanical engineering in karnataka?', 'Which are the best engineering colleges in Gujarat?', 'Which are the top engineering college in Gujarat?', 'Which is the best college for criminology in ahmedabad?', 'Which college is best for chemical engineering in Gujarat?', 'Which is the best college for computer engineering in Gujarat, India and world?', 'What are some good chemical engineering colleges in Gujarat?', 'Which are the best colleges for mechanical engineering in maharashtra?', 'Which is the best engineering college in Rajasthan?', 'Which is the best location to invest in Ahmedabad?', 'Which is the best engineering college for aerospace in India?', 'What are the best location to invest in Ahmedabad?', 'Which are best aerospace engineer college in India?', 'Which institutes in Ahmedabad provide final year training and internship to electronics and communication students?', 'Which is the best college for aerospace engineering in India?', 'Which is the best coaching institute for the GATE in Ahmedabad?', 'Which is the best college to do aerospace engineering in India?', \"I've completed b.tech in mechanical engineering, is there any vacancies in Ahmedabad for freshers?\", 'Which is the best college to study in india for engineering?', 'Which is the best engineering college in chennai?', 'What are the best colleges to do Mtech in Mechanical engineering in India?', 'Which is best engineering college in madhya pradesh?', 'What are some of the places one must visit in Ahmedabad?', 'Which are the best engineering colleges of India?', 'What are the best institutes to do “Diploma in Fashion Designing” in Hyderabad n rest of India? Syllabus n fee? I have completed my engineering.', 'Which is the best java training institute in ahmedabad?', 'What is the best engineering college in Chennai?', 'Which are the best aerospace engineering colleges in India according to placement?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why are watermelons red on the inside?', 'positives': ['What makes watermelon red inside?'], 'negatives': ['Is watermelon a fruit or a vegetable?', 'How do you carve a watermelon?', 'What are the health benefits of watermelon?', 'How many seeds in a watermelon?', 'How can you tell if a watermelon is ripe?', 'Bread watermelon?', 'Why is watermelon good for sperm?', 'What is the best way to determine if a watermelon is ripe?', 'How does the process in which Japanese grow watermelon differ from the process Americans use?', 'How does the process in which Japanese grow watermelon differ from the process Greeks use?', 'What is the best way to judge if a watermelon is ripe enough to eat?', 'How does the process in which Japanese grow watermelon differ from the process Canadians use?', 'How does the process in which Japanese grow watermelon differ from the process Argentinians use?', 'What are some tips for carving watermelon?', 'How does the process in which Japanese grow watermelon differ from the process Australians use?', 'How does the process in which Japanese grow watermelon differ from the process Portuguese use?', 'Why do I feel and look bloated after eating watermelon?', 'How does the process in which Japanese grow watermelon differ from the process Egyptians use?', 'How does the process in which Japanese grow watermelon differ from the process Koreans use?', 'Why are tomatoes red?', 'How does the process in which Japanese grow watermelon differ from the process Mongolians use?', 'How does the process in which Japanese grow watermelon differ from the process Ethiopians use?', 'How is fruity red wine made?', 'Why is lemon and boiling water good for you?', 'Why did lemon juice that sat refrigerated for two years turn red-brown with clumps?', 'What are lemons used for?', 'Why is lemon juice made with artificial flavor, and dish washing liquid made with real lemons?', 'Why is the inside of my banana red?', 'Why is lemon juice made with artificial flavor and dishwashing liquid made with real lemons?', 'What toppings are in red mango?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Can I block a topic on Quora?', 'positives': ['Is there a way to mute / ignore / block a topic from appearing in my feed?'], 'negatives': ['How do I edit the subjects in my feed on Quora?', 'How do you make a topic appear in your feed more frequently?', 'How do I add topics for my feed on Quora?', 'How can I hide a user from my Quora feed?', 'How do I make my feed very diverse in topics?', 'Is there any way I can prevent the posts of specific quorans from showing up on my feed?', 'On Facebook, how can one hide posts of a certain topic or containing specific keywords from showing up on the newsfeed?', 'How do I mute Indians entirely from my feed?', 'How do I get rid of adult content on my Quora feed?', 'How do I edit my feed?', 'How do I mute a Quora user?', 'What are some techniques to curate your Quora feed to display content you are actually interested in?', 'How do I remove adult content from my Quora feed? Where I can get the option?', \"Is there any other way to curate content in my Quora feed other than downvoting questions I'm not interested in?\", \"Why is my feed on Quora flooded with irrelevant questions and topics that I'm not following?\", 'How do I filter out Trump and Hillary related content from my feed?', \"How can I remove someone's answers from my feed?\", 'How can I selectively clean my New Notifications feed?', 'How do I mute all Indians from my feed, and follow some instead of vice-versa?', 'How do I block messages from my school?', 'How do I stop the things friends like or comment on from showing up in my Facebook News Feed?', 'How do I filter out US election news in my Quora feed?', 'How do I get Trump-related content off my Quora feed?', 'How do I block a specific word from showing up on all pages that I view using my browser?', 'How can I mute questions asked by a particular Quora user?', 'How can I hide my edits on my Quora Profile?', 'How can I filter my Quora feed properly?', 'Is it possible for a Facebook user to hide their like activity from the newsfeed?', 'If Quora made a word-block filter to our feeds, which words would top your list?', 'What are some topics on Quora that one should unfollow?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the safety precautions on handling shotguns proposed by the NRA in Illinois?', 'positives': ['What are the safety precautions on handling shotguns ?'], 'negatives': ['What are some good tactical shotgun classes around NJ/NY area?', 'What are the risks of using parts made for airsoft on real firearms?', 'Why are pump-action shotguns still in use?', 'Do gun-free zones increase or decrease safety?', 'What is the significance of calling \"shotgun\"?', 'What are the pros and cons of a semi-automatic shotgun vs pump action?', 'What is it like hunting with a tactical shotgun?', 'What is the spread on a police shotgun?', 'Do you need a safe for a long gun in California?', 'What are the disadvantages of using silencers on firearms?', 'What is the difference between a shotgun and a firearm?', 'What are the pros and cons of gun control?', 'Is it safe that many people own guns in America?', 'How much can I expect to pay for a shotgun?', 'Do guns make Americans safer?', \"Why can't civilians buy an AA-12 shotgun?\", 'Has there been a gun control initiative to take away guns people already own?', 'Can gun control prevent assault?', 'How does a gun work?', \"Why aren't cartridges regulated instead of firearms?\", 'What is the importance of having safety rules?', 'Is there an objective statistical comparison between the reliability of semi-automatic pistols vs revolvers?', 'What are the consequences of operating a legally owned gun under the influence of drugs and alcohol?', 'What are some net beneficial and net detrimental effects of gun ownership?', 'How effective are gun control laws?', 'As a new shooter, how many rounds should I go through per visit to the range to become proficient and comfortable with my handgun?', 'Do you have to clean your handgun right away after shooting a couple hundred rounds through it at the range or can you clean it days or weeks later and still keep it just as well maintained?', 'What kind of bullets do sniper rifles use?', 'Is there a loophole in the U.S. that makes it possible to buy a gun at a gun show without a background check?', 'How can you clean a semi automatic rifle?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the functions of left and right brain?', 'positives': ['What are the functions of the left and right brain?'], 'negatives': ['What are the four main parts of the brain and how do they function?', 'What are the parts of the brain?', 'What are the main parts of the brain and how do they work?', 'How does the brain function?', 'How does human brain function?', 'What part of the brain controls balance and coordination and how does it do it?', 'How were the three parts of the brain determined?', 'What part of the brain controls balance?', 'What are the three main regions of the brain?', 'What is the function of right dorsolateral prefrontal cortex?', 'Which part of brain control which part of body?', 'Which functions does the “Broca” area of the brain perform?', 'How does the brain control the brain?', 'Which functions does the visual area of the brain perform?', 'Which part of the brain is the reactive part of the brain?', 'What are the functions of prefrontal area of the brain?', 'What are the main functions of the nervous system?', 'Which parts of the brain are responsible for motor skills?', 'Which functions does the “wernicke” area of the brain perform?', 'Which parts of the brain control which human behaviours?', 'How do brains function?', 'What are the parts of the neuron and their function?', 'What are the three main and most important functions of the nervous system?', 'How does the human brain work?', 'What are the parts of the brain thats capable of growing?', 'Roughly what \"processing power\" does the human brain equate to?', 'What is a brain?', 'How does the brain works?', 'Which functions does the association area of the brain perform?', 'What part of the brain is responsible for reading?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I improve in my maths?', 'positives': ['How can I improve myself in maths?'], 'negatives': ['What are some of the best ways to improve maths beyond JEE level?', 'My maths have become extremely weak and I am in class 12th. How can I improve my maths so that I can clear my JEE exams next year?', 'I am hardworking but I have a fear in my mind of practicing maths dont know what to do i am a medium scoring student but in maths idk ?', \"I'm bad at math because of the way my high school teachers teach me. Is there any way I can get better at math without the help of teachers?\", 'Why am I bad at maths?', 'Why am I so bad at Maths?', 'Why am I bad at math?', 'I struggle with math and science and it makes me feel stupid. What can I do to get better?', 'How can I unlearn math to be faster at learning maths after?', 'Why am I so bad at math?', 'I am failed in maths in 12th class improvement. What should I do now?', 'How some people are bad at maths?', 'How do I improve my mathematics for algorithms?', 'How do I deal with math exams?', 'What is the most effective way to study maths in high school?', 'Do you have to be good at math to major in business?', 'I am 25 years old with no math background and I want to learn advanced mathematics as quickly as possible. Is it too late for me to be successful?', 'Is math important to learn?', 'Do you need to be good at Math in order to code well?', 'How can I improve the amount of time that I can think about a math problem before losing concentration?', 'How can I be good in (Math, Physics, Chemistry)?', 'What is the best way to study for math exams?', 'When I look at some math Olympiad problems I feel really intimidated. I only know how to solve basic problems, nothing special, but I like math very much. Is there any hope for me to become a mathematician?', 'Does being good at mathematics make you intelligent?', 'Does being good at mathematics make you intelligent in other subjects?', 'Whats the most effective way to study for maths in high school?', \"Why do people think that girls can't be as good in mathematics?\", 'Why do I suck at math?', 'What should I do now that I only graduate with a math degree?', \"What are the advantages of studying maths to a high level even though you don't want to use it at that level in a future career?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the easiest way of committing suicide?', 'positives': ['What’s the easiest most painless way to die?'], 'negatives': ['What’s the best way to kill yourself that (a) leaves the least amount of blood to clean up and (b) is the least painful?', 'How do you take yourself close to death without actually dying?', 'What is a way to commit suicide and not damaging your organs so that they can be donated?', \"What is the one thing you'd like to do before dying?\", 'What is the best way to avoid pain?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why do I see questions with basic grammatical mistakes on Quora but some of my questions are marked as \"needing improvement\"?', 'positives': [\"Can Quora quote the improvements needed in the questions when it is marked as 'Needing Improvement'?\"], 'negatives': ['What are areas of improvement?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why are some people rude?', 'positives': ['Why are we rude?'], 'negatives': ['How can I be rude?', 'How do you deal with rude people?', 'Why are people who are rude and arrogant do so well?', 'Why are we cruel to strangers?', 'Is being a bore rude?', \"Manners and Etiquette: What's the best way to deal with rude people who don't realize they are rude?\", 'Is it always wrong to be rude to someone?', 'How can I be less rude?', 'Why are people in Hong Kong rude?', 'How should I deal with rude people at my school?', 'Why are Americans so rude to always ask how you are, although they never care about the answer?', 'Why are boys rude to girls they like?', 'How do I say when people ask me rude question?', 'What is the rudest thing you have ever malicously done?', 'What is the rudest thing you have ever done?', 'Are people in New York city rude?', 'How can you deal with rude customers?', 'What behaviour is normal in other countries, but considered to be very rude in the UK?', 'What is the rudest thing someone has ever said to you and how did you respond?', 'Why are Swedish people so rude?', 'Why do many people lack basic manners nowadays?', 'What was the rudest thing you have said or done?', 'What are some unintentionally rude things people say and do?', 'What is the rudest thing you have ever said to someone?', 'What was the worst thing to happen to you for being rude?', 'How should I apologize for being rude\\\\rejecting?', \"What was the rudest thing you've ever seen?\", \"What's the rudest thing a salesperson has ever said to you?\", 'What is the worst thing that happened to you for being rude?', 'Why are some atheists so rude?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I shave my bikini line?', 'positives': ['How can I get a clean shave in the bikini area?'], 'negatives': ['Can I get a bikini wax on my period?', 'After shaving the bikini area, how do you keep it from getting irritated and itchy?', 'Can i get a bikini wax if i am on my period?', 'If I get stranded on a deserted island, what could I shave with?', 'What are some tips for shaving my face?', 'What is the best way to shave pubic hair completely?', 'What is the best non-electric shaver?', 'Where can I find a bikini shaving salon for men in NYC (preference for Brooklyn)?', 'Shaving: Which is the best electric shaver? Why?', 'When should I start shaving?', 'Should you shave before getting laser hair removal?', 'How do I make my girlfriend shave her hairy arms?', 'I hate taking a bath and shaving. What should I do?', 'How do I get rid of pimples after shaving?', 'I have very hairy arms. I am 16 and a female. Should I shave them?', 'How do male porn stars shave their pubic hair?', 'Can one wear a slinky 2 piece bikini in Goa?', 'Which is the best electric shaver for men?', 'How long does it take to grow hair after shaving?', 'How do you get rid of dark bikini areas & dark armpits?', 'Can my bath towel be a beach towel?', 'Is it mandatory for all public figures in Japan to shave clean?', 'Shaving: Do electric shavers work better than manual shavers?', 'Can we use hair removal cream instead of shaving our beard?', 'How can I get tanned?', 'Is it good or bad to shave pubic hair?', 'Where to find badger hair shave brushes in Shanghai china?', 'Should women shave their legs?', 'What should I prefer either shaving head or apply natural remedies to stop my hair fall and baldness?', 'Which is the worlds best electric shaver?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What secret can you not share with anyone?', 'positives': [\"What is the most embarrassing secret you have that you'd never tell to almost anyone?\"], 'negatives': ['What is the biggest secret or surprise that you have unintentionally revealed?', \"What 's the biggest secret?\", 'What is the biggest secret?', 'What is your biggest sexual secret?', \"What is it like to not share your secrets with anyone around you, because you know they'll speak all the unncessary and irrelevant things instead of helping you which is exactly opposite to what you want them to do?\", 'What is your one secret, that even if you share, no one would believe?', 'How can I keep a secret?', 'What was the best kept secret ever ?', 'What is the best kept secret?', 'What is your deepest secrets?', 'What is your secret that you can only share at Quora?', 'What is the single most revealing thing about any person?', \"What's the most embarrassing misconception you've ever held?\", 'What is the biggest secret to life?', 'What are the best kept secrets ever?', 'What is the most intriguing secret the world has ever witnessed?', 'What are you most insecure about ? Why?', 'What is a secret you would like to share on Quora?', \"What's one secret that you will take to your grave?\", \"How would you find out a person's deepest secrets?\", 'What is the one thing you are ashamed of?', 'What is the most guarded secret in the world?', 'How does it feel to live with a secret throughout your life?', 'What is that one particular thing that you are so ashamed of?', 'What is the biggest lie you ever told to yourself?', 'What are some of the ways to keep secrets?', 'What are the world’s most hidden secrets?', 'How secret is Secret?', 'What is the most hidden secret of India?', \"What are the best examples of 'The Secret' in your life?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do you know she is the one? The one whom you should marry.', 'positives': ['How do you know if she is the one for you?'], 'negatives': ['How do you know your boyfriend is the one?', 'How can you know about a person?', 'Do you know someone named Janet Frizzell?', 'What is the name of her?', 'How do you know that you have met your soulmate?', 'Who is she?', 'How do you know you have met your soulmate?', 'How do I know about any person?', 'Do you know Janet Frizzell?', 'How do you know that the girl sitting next to you wants you to talk to her?', 'How do you know if someone really loves you for who you are and not just for sex?', 'How do you know if your wife is a closet lesbian?', \"Do you only know you love her after you let her go or do you know you love her because you didn't let her go?\", 'How do I find out if she likes you by watching her Behavior?', 'How do you let a girl know how much you like her?', \"What's her name?\", 'How would you know if you love someone even if you do not have any physical or emotional reaction about the person but you do think you like her?', 'How do you know someone wants to be your friend or not?', 'If a girl ask you why are you trying to know her?', 'How do you know if a girl is a lesbian?', 'How do you know that you really like a person?', 'How can I know if my friend is a true friend?', 'Who is my girlfriend?', 'How do you know if you are a \"people\\'s person\"?', 'Can you date your female friend?', 'How do you know if your friend is jealous of you?', 'How can you tell if she is talking to other guys?', 'How can a man know that a woman is interested in him from her behaviour?', 'What is it like knowing your daughter is a porn actress?', 'What is your girl friend name?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which video games do you play?', 'positives': ['What video games do you play the most?'], 'negatives': ['What are the most complex video games?', \"What are the most difficult video games you've played?\", 'What are the types of video games. Like first person shooter, etc?', 'What are the most common video games that girls play?', 'What are the most popular games?', 'Which is the best video game so far, considering combination of story line, game play and graphics?', 'Do you like video games?', 'What is the most played computer & mobile game at the moment?', 'What is the best video game as of now?', 'Which are some of the best PC Video Games ever made?', 'Name of best sports video game?', 'Which video game describes your personality best?', 'What video games do women play?', 'What is the best movie based on a video game?', 'What is the best video player?', 'What is your favorite video game that came out this year?', 'What are the most popular arcade games?', 'What is the best WWII video game you have ever played?', 'What are the top ten PC games ever?', 'What games you play on your smartphone?', 'What are some great online games?', 'What was the hardest video game ever?', 'What are the most underrated video games?', 'What´s the best videogame ever?', 'What are the best online games?', 'Which is the best video player?', 'Which are the most underrated PC video games?', 'How often do successful people like doctors, lawyers, and CEOs play video games? What kinds of games do they play?', 'What video games do programmers play?', 'What is a good strategy video game?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Who has written the book \"Not Just an Accountant\"?', 'positives': ['Who wrote the book \"Not Just an Accountant\"?'], 'negatives': ['Who is the first author?', 'What is an Accountant?', 'What does a first time author do to market his own book?', 'What Makes a best-selling Business Book Author?', 'What was the first book ever ordered by a customer on Amazon?', 'Who wrote World Book Encyclopedia?', 'Why most Chartered accountants are obsessed with writing CA before their name?', 'Who are some of the most famous chartered accountants?', 'What does an accountant do?', 'Whose biography would you most like to write and why?', 'Who wrote the English bill of rights?', 'What is the book \"How Eat to Live\" by Elijah Muhammad about and how was it written?', 'Is the book \"Think and Grow Rich\" by Napoleon Hill, worth reading?', 'What history books should an entrepeneur/businessman/investor read?', 'What Nancy Duarte did before her book published by Harvard Business Review?', 'Who would write your biography?', 'Which are some of the books entrepreneurs must read?', 'Which books should entrepreneurs read?', 'What books should entrepreneurs read?', 'Who wrote the Bill of Rights?', 'Who invented the English alphabet?', 'What was the first book published which questioned the official story in the Lindbergh Baby case?', 'Who is the most famous chartered accountant in India?', 'What did Nancy Duarte do before her book was published by Harvard Business Review?', \"1920's literature in America?\", 'Who is the author of this?', 'How many think Chartered accountants are more intellectual than Lawyers?', 'How much did the English writer Douglas Adams earn from his books, such as \"The Hitch Hiker\\'s Guide to the Galaxy\"? Was he a wealthy man?', 'What is the greatest book ever written?', 'Who was the most copied writer ever?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How come nobody talks about Donald Trump being accused of rape?', 'positives': ['Why do we not hear anything about the upcoming trial in which a minor accuses Trump of Rape?'], 'negatives': [\"Why hasn't Trump's pending child rape case featured in Cinton's campaign or in the MSM?\", 'Is it true that Donald Trump raped a 13 year old and threatened to hurt her family if she talked?', 'Did Trump really rape a 13 year old girl?', 'Can Trump’s accusers still sue? Is there a statute of limitations on sexual assault, and does it differ by state?', 'Is Trump’s alleged groping of multiple women as bad as or worse than Bill Clinton’s alleged rape of Juanita Broadderick?', \"Why hasn't Ivanka Trump condemned the bigotry in the Access Hollywood sex tape?\", 'Why has the media mostly ignored the 06/20/16 filing of a federal lawsuit against Donald Trump and Jeffrey Epstein for raping a 13 yr old girl?', 'What is the complete list of Trump sexual assault accusers?', 'Has Trump ever been implicated in a murder?', 'Why was Donald Trump talking about the abortion issue?', 'If Trump sues the NY Times for libel over the sexual assault article, could the NY Times get the tapes from “The Apprentice” to prove their side?', 'Is Trump 2016 secretly just the next Sacha Baron Cohen movie?', \"How come liberal media asks Ivanka Trump what she feels about her father's treatment of women but they do not ask Chelsea Clinton the same question?\", 'What is it like to be falsely accused of rape?', 'What could be legal repercussions for doing what Donald Trump says he does in the sex assault bragging video?', 'What is it like to falsely accuse someone of rape?', \"Why does the media never ask Chelsea Clinton about her father's treatment of women but constantly asks Ivanka Trump?\", \"Who were the women who Trump introduced as Bill Clinton's accusers? What substance is behind their claims? Is the rape claim likely to be legitimate?\", 'Is Bill Cosby going to be arrested for the rape accusations?', \"Why is Trump's sex talk and sex life a reason to oppose him?\", \"Why don't people actually watch the Trump video of him allegedly mocking a disabled reporter?\", \"How come there hasn't been a movie made about OJ Simpson and his trial?\", \"What would happen if Trump doesn't concede to Clinton? Why is this issue all over the news right now?\", 'What is it like to be accused of rape?', \"How come I don't often see questions on Quora about Trump's alleged bribe to the Florida AG forTrump University investigation?\", \"When will the media realize we don't want to hear about trump? Does Trump even understand what the different branches of government are for?\", \"Are there more Trump tapes out there even if it's unlikely that we will ever hear them? Have you heard from sources that they exist?\", 'I caught my son watching porn, how should I confront him?', 'Why is Donald Trump not in jail for his comments?', 'Is there any credible evidence that Trump is intentionally trying to lose the election?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What question can you ask someone that will spark deep interesting conversation?', 'positives': ['What question can you ask someone that will spark deep, interesting conversation?'], 'negatives': [\"What sort of questions should I ask to a person I'm meeting for the first time to make the conversation interesting and a little funny?\", 'I want to ask a question to a specific person on Quora, what I have to do?', 'What are some funny questions to ask someone?', 'What are 25 random questions to ask someone you just met?', 'What was the most important question someone asked you?', \"What's the most interesting question you've been asked?\", 'What are the best questions to ask a girl while chatting?', 'What are some interesting questions to ask yourself?', 'What are some personal and thought provoking questions to ask when trying to get to know someone?', 'What is the most important question to ask?', 'What is the most difficult question you have been asked by someone?', 'What is the most interesting question you have ever been asked?', 'What do you think is the most important and empowering single question a person could ask himself regularly in order to have an extraordinary life?', 'What is the interesting questions asked in an interviews?', 'What are some good questions to ask when we meet someone new?', 'What are the best questions to ask when you first meet someone?', \"What's the most interesting question you've ever been asked during a job interview?\", 'What answer when someone (a girl) ask you \"Tell me something interesting about you\"?', 'How can you keep a conversation interesting?', 'If you could ask one question to get to know someone, what would it be?', 'Conversations: What are great responses to the question: \"What\\'s going on?\"', 'How does one intelligently ask questions?', 'What are some important questions to ask yourself as you go through life?', 'What was the most interesting question you have ever asked?', 'What questions should we ask?', 'What is the best question to ask a girl?', 'What is the best way to ask the best questions?', 'What are the most interesting questions you have ever asked people or been asked about?', 'Interpersonal Interaction: What is the most interesting conversation a boy and girl can have?', 'A girl has offered me to ask her a question. What should I ask?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the safety precautions on handling shotguns proposed by the NRA in Georgia?', 'positives': ['What are the safety precautions on handling shotguns proposed by the NRA in Arizona?'], 'negatives': ['What are some safe ways to hunt with a tactical shotgun?', 'Do gun-free zones increase or decrease safety?', 'What are the best gun safes?', 'What are some good tactical shotgun classes around NJ/NY area?', 'What are the risks of using parts made for airsoft on real firearms?', 'Do you need a safe for a long gun in California?', 'Why are pump-action shotguns still in use?', 'What is the significance of calling \"shotgun\"?', 'Is it safe that many people own guns in America?', 'Do guns make Americans safer?', \"Why can't civilians buy an AA-12 shotgun?\", 'What are the pros and cons of a semi-automatic shotgun vs pump action?', 'How much can I expect to pay for a shotgun?', 'What are the pros and cons of gun control?', 'What is the spread on a police shotgun?', 'Has there been a gun control initiative to take away guns people already own?', 'What special regulations do gun laws in Texas have in regards to silencers, and how do they compare to regulations in Rhode Island?', 'What is it like hunting with a tactical shotgun?', 'What are the disadvantages of using silencers on firearms?', 'What are the consequences of operating a legally owned gun under the influence of drugs and alcohol?', 'What is the difference between a shotgun and a firearm?', 'What special regulations do gun laws in Texas have in regards to silencers, and how do they compare to regulations in Idaho?', 'How effective are gun control laws?', 'Is there a loophole in the U.S. that makes it possible to buy a gun at a gun show without a background check?', 'Should background checks in the U.S. be expanded for gun buyers?', 'Do Americans believe owning a gun makes them safer?', 'Can gun control prevent assault?', 'What is the importance of having safety rules?', 'Where are the good resources for safety info and products?', 'What is a Firearm Safety course, and in which cases are these courses recomended?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I start Jio 4G sim in 3G mobiles?', 'positives': ['How can I use 4G sim in 3G mobile?'], 'negatives': ['Can I use my 2G sim card in a new 4G enabled latest mobile?', 'Is there any dual SIM mobile supporting 4G or 4G and 3G?', 'Can we use more than one Jio sim in a 4G mobile?', 'I have activated 4G on my Airtel SIM, but whenever I try to recharge the 4G pack on Airtel, the website says I need a 4G SIM even though my SIM is already 4G. Who knows about this issue?', 'Do I have to convert my 2G SIM to 3G to run 3G internet on an Airtel SIM or can I just take the 3G recharge and it will run accordingly?', 'Can we use other 4g sim in LYF mobile?', 'Can I save data if I toggle mobile network from 3G/4G to 2G with 3G/4G data plan?', 'Can I activate Jio sim in one 4G phone and then use that sim on another 4G phone?', 'It is possible to use Jio 4G sim in Gionee p5w mobile?', 'Can my 3G phone connect to the 4G portable Wifi?', 'Which 4G mobile is best in the range of 10000 to 15000 where I could put dual sim and SD card?', 'Is it possible to activate and use both 2G and 3G data pack in the same SIM (airtel prepaid)?', 'How can I use the Jio 4G SIM in XOLO Q800 X-Edition mobile?', 'Will a 3G capable phone connect to a 4G LTE network?', 'Is a 4G LTE a 4G phone?', 'Is the LG G3 mobile phone 4G?', 'Can I use jio 4g sim in my mi 4i?', 'Can I send the mobile data (3G) of my mobile number to another mobile number?', 'Can I use 4g jio in Nokia Lumia 535?', 'I am planning to buy a Moto G4 plus. The second SIM is not 4G enabled but supports 4G in India. What does that mean?', 'Will the Airtel 4g SIM card work in 2G phones? If not, will it at least work in 3G phones?', 'If I buy a new Airtel 4G sim of a new mobile number and can I change it into my current mobile number?', 'What is the difference between 3G and 4G?', 'Why does 3G mobile cellular signal use more power than 2G?', 'What is the best dual sim smartphone?', 'What is the best smartphone with dual SIM?', 'Can we use the Jio SIM that came along with LYF mobile in other 4G mobiles?', \"What's the difference between 4G and 4G LTE?\", 'Are data charges for 2G/3G/voice calls on Airtel 4G sim higher than or same as its 3G sim?', 'My phone is not running 3G but 2G is working fine. 3G is working fine on another phone on the same sim. What can be the problem with my phone?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are some examples of mechanical advantages?', 'positives': ['What are some examples of a mechanical advantage?'], 'negatives': ['What skills are required for mechanical engineering?', 'What are the new mechanical innovations?', 'What are mechanical engineering related businesses?', 'What are the skills a mechanical engineer should possess?', 'What extra things can mechanical engineering students do?', 'What are the basic things of mechanical engineering?', 'What is the importance of programming in mechanical engineering?', 'What are the new mechanical innovations in cars?', 'What is the aim of mechanical engineering?', \"What is mechanical engineering's magnitude?\", 'What is the advantages a Mechanical Engineer can get by joining a leading PSU?', 'What are some good Mnemonics in Mechanical Engineering Subject?', 'What are some good research areas in mechanical engineering?', 'What are the essential skills for a mechanical engineer to be employable?', 'What are innovative mechanical component designs?', 'What are the things mechanical engineers should know?', 'What are the basics should a mechanical engineer known?', 'What is mechanical engineering?', 'What are some basics of mechanical engineering?', 'What are things a mechanical engineer should know?', 'What do you mean by mechanical engineering?', 'What are the other things a mechanical engineer should know about?', 'What are mechanical Engineering club activities?', 'What knowledge do mechanical engineers need to invest in?', 'What makes a good mechanical engineer?', 'What are the most important topics in mechanical engineering?', 'What are the mechanical skills a mechatronic engineer should possess?', 'What are some essential skills that a mechanical engineer should learn?', 'Can a mechanical engineer shine better in IT field?', 'If a machine has a mechanical advantage much larger than 1, what is its output force?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do you bake a 11 pound turkey and how long do you bake a 11 pound turkey?', 'positives': ['How long to cook a 10 pound turkey?'], 'negatives': ['How do you cook turkey ham in an oven?', 'What is the best way to cook turkey ham?', 'What is the best Thanksgiving turkey recipe?', \"What's the best Thanksgiving turkey cooking procedure for guaranteeing the juiciest turkey every time?\", 'What is the best way to make a rotisserie style turkey in a small oven? What are some interesting ways to prepare it?', 'How do I thaw a turkey?', 'How do you thaw a turkey?', 'How many years does a female turkey lay?', 'How many times does a female turkey lay for one year? How many eggs does it produce?', 'Last year my Thanksgiving turkey was dry, what is the best way to roast a Thanksgiving turkey?', 'What is turkey made of?', 'What will happen to Turkey in 10 years?', 'What is the best food to eat in turkey?', 'What temperature should chicken be cooked to?', 'How long can turkey bacon stay in the freezer? How can I make it last longer?', 'How long do you bake a chicken breast at 350 degrees?', 'How do I roast a chicken?', 'How do you cook chicken in the oven?', 'How long should I boil chicken thighs for?', 'How can I boil chicken?', 'What is Turkey?', 'How do I make chilly chicken?', 'How do you cook chicken gizzards? What are the best recipes?', 'How can I cook a duck?', 'How do you cook slightly frozen chicken?', 'How should I cook a chicken breast?', 'How can you cook chicken in the marinade?', 'How long can raw chicken be left at room temperature and still be safe to eat?', 'What is the best way to fry chicken?', 'If frozen chicken is left out for 24 hours, is it still cookable?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What does Donald Trump's victory mean for Silicon Valley?\", 'positives': ['How would a Trump presidency affect Silicon Valley?'], 'negatives': ['Will Silicon Valley transform into one of the biggest tech driven places in California?', \"How will Trump's presidency affect science?\", 'Why is Silicon Valley important to history?', 'How silicon valley be the Silicon Valley?', 'How much office politics are there in Silicon Valley startups?', 'How would a Trump presidency actually affect daily American life?', 'Are Silicon Valley CEOs addressing their employees regarding the Trump victory?', 'Will there be a next Silicon Valley?', 'Will there be a Silicon Valley in China?', 'Would a Trump presidency help or hurt Singapore?', 'How would the Trump Administration affect students from Ivy League universities?', 'How important is it for a tech startup to be in Silicon Valley?', 'How will Trump as USA president will affect the Saudi Arabia and other Gulf countries?', 'What would be the impact of a Trump Presidency on Singapore?', 'What is Silicon Valley?', \"How will Trump's presidency affect the Indian IT industry?\", 'How does working in Silicone Valley differ from working in Silicon Valley?', 'How will a Trump presidency affect scientific research?', 'Will the Donald Trump presidency ruin America?', 'What is Silicon Valley known for?', 'Who are the biggest busts in Silicon Valley?', 'Which Silicon Valley tech companies have the most well-designed headquarters?', 'What are the major differences between Silicon Valley of USA and Bangalore, which is termed as the Silicon Valley of India?', 'Do all Silicon Valley start-up companies incorporate in Delaware?', 'What is Silicon Valley like?', 'What are the biggest Silicon Valley companies?', \"If Donald Trump becomes Mr. President, how will it effect USA's economy?\", 'Which places in the USA attracted the best tech talent before Silicon Valley emerged in California?', 'How will a Trump presidency affect Canada?', 'Would Donald Trump’s having become President adversely affect the job prospects of non-Americans who graduate from American universities?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I recover app lock deleted photos?', 'positives': ['Recover photos from app lock?'], 'negatives': ['How do I recover photos in apps lock Volt?', 'I used to put my photos in the photo vault of AppLock but I decided to reset my phone. The factory reset wiped data + cache and Dalvik cache. After that, I restored all my apps, including AppLock, but my photos in the vault were gone. How do I recover them?', 'How do I recover photos from the app vault?', 'How do I recover photos erased from the factory reset on an Android phone?', 'What are ways to recover missing photos from iPhone?', 'How do I recover my lost photos deleted by valut apps in android phone?', 'How can I recover photos after factory resetting my Android Galaxy S3?', 'How do I recover a deleted photo from hangouts?', 'How can I recover my hidden photos deleted by Clean Master in my Android phone?', 'How do I restore pictures from iCloud?', 'How do I prevent the recovering of deleted photos in my Android phone?', 'How do I recover deleted photos from NQ Vault app for Android?', 'How can I get my photos back after resetting my phone to factory reset?', 'Clean Master, the Android app, deleted some of my important pictures when I tapped the \"clean the junk\" option. What are some methods to retrieve the pictures?', \"I've lost my fotos in a secure gallery app and I want to get them back?\", 'How can I recover the photos on a Samsung Galaxy S6?', 'What is the way to recover photos on IMO?', 'How can I recover my deleted files from the Keep Safe app?', 'How do you retrieve photos from iCloud?', 'How do you restore a locked iPhone?', 'How do I recover deleted photos from an Android internal memory?', 'How can I recover my photos?', 'How do I recover my photos?', 'How do I recover deleted photos from my Galaxy S5?', 'How do I recover my images deleted by mistake from my android phone?', 'Can you delete pictures from an iPhone and still have it saved in iCloud? If so, how?', 'How can I hide images and videos on my Android phone without any app lock?', 'How do I recover deleted photos on Samsung note 4?', 'How do I delete photos from the icloud but still have them on my iPhone?', 'How do you get back deleted photos on keep safe?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I contact Google Green?', 'positives': ['How can I contact Google Green?'], 'negatives': ['How can I get in touch with Google Ventures?', 'What does green phone icon on messenger mean?', 'What is green IT?', 'How can I contact Facebook UK?', 'How do I do a green screen job?', 'How can I apply to work in Google Canada?', 'What is green politics?', 'Where can I purchase Google Glass?', 'What does a green dot by the phone icon mean on Messenger?', 'What is the green dot next to the phone icon on messenger?', 'Why is green the colour green?', 'Does green engine exist?', 'What is green communication?', 'What does the green dot beside the phone icon on messenger app mean?', 'How does the green screen work?', 'How can I use Google like a pro?', 'How do I know if my green texts are blocked?', 'How do you enable a disabled Google Account?', \"Is there a phone number at Google's headquarters that actually has someone answer?\", 'Do I need a Google account?', 'On Messenger, what does the green dot besides the phone icon mean?', 'How do I get green coffee beans?', 'Why does Quora need my Google contacts?', 'Is there anyway of knowing if my green texts are blocked?', 'What is the use of green technology?', 'What is the Green Party?', \"How can I visit Google's office in Mountain View?\", 'How do I use Google Earth Pro?', 'How do I search with Google?', 'What is the best way to use Google?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can a foreigner get permanent resident permit in US?', 'positives': ['How do I get permanent residency in USA, California?'], 'negatives': ['How do I get permanent residency I Hawaii?', 'How can apply for residency certificate in India?', 'How do I get Permanent Residency (PR) for Australia?', 'Is it true that if you reside within the United States for 4 years legally, you are eligible to apply for a permanent residency (green card)?', 'Where am I legally resident?', \"How long does it take to be considered a resident in the state of California? I can't afford international student fees for college.?\", 'How do I get permanent residency in New Zealand?', 'What should I do to get a permanent residency permit in China?', 'Which is the easiest country to give a permanent residency for Indians?', 'Can I apply for a driving license in California if I m not a resident but have SSN?', 'How can a foreigner be a permanent resident of India?', 'What is the quickest way to get a Canadian Permanent residency for international students?', \"As a temporary resident in US, do I need to get a new driver's license if I move from one state to another?\", 'How can I transfer from an international university to a US university as a US permanent resident?', 'How can I get a permanent resident in Canada?', 'What is the easiest Way to Apply for Permanent Residency in Paraguay?', 'How do I get permanent residence in Canada after doing a PG there? Is it easier than getting a permanent residence in the USA?', 'How easy is it to get the Australian permanent residency for an Indian citizen?', 'If I own a home in the U.S., can I still be considered a legal resident even if I live in another country?', 'What is the quickest way to get a Canadian Permanent residency for immigrants?', 'Applying for a residency program in California requires a Postgraduate Training Authorization Letter - PTAL which requires the candidate provide a SSN. Does this mean that no one else but only a US/permanent citizen (SSN requirement) can get into med school in California?', 'How can I apply for a permanent residency in Paraguay?', 'How do I become a permanent resident of Canada?', 'What is medical residency?', \"I've been living in California for the last few years. My wife is in India and she will be joining me at UC Davis. If I pay her tuition, would I qualify for resident tuition?\", 'How do you incorporate in US as a non-resident?', 'How do I live in Los Angeles?', 'What is a medical residency?', 'U.S. Citizenship: For an Indian what are the pros and cons of getting a Green Card in the US?', 'I am a Canadian born to a US citizen (Mother). How can I live and work in the USA?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What will the government do with the old currency notes?', 'positives': ['What will government do with the old currency notes?'], 'negatives': [\"What if RBI and banks would come up with a rule stating, we won't accept the currency notes if anything is written on top of it?\", 'Why are Indian currency notes dirty, unhygienic and unkempt?', \"Is it true that the new currency notes can't be counterfeited?\", 'What happens if citizens continue to use old 500 and 100 notes after Nov 9? We can still exchange those notes till Dec 30.', 'How does a country issues currency?', 'When will plastic currency notes be issued in India?', 'Indian Political parties can deposit old currency notes, just it need to be under 20,000 per deposit, is this not how black money laundering works?', 'What paper quality is used for the new currency notes?', 'In what basis are currency notes printed?', 'What are the different ways to test the originality of an Indian currency note? Where do the fake currency makers fail?', 'If we are replacing old notes with newer notes (Rs 2000 and 500) in India, how is it going to help \"going cashless\"?', 'Who designed the Indian currency notes?', 'What paper quality is used for new currency notes?', 'Why does the Indian government issue coins despite having the RBI?', 'How does currency work?', 'What is the current status of Introduction of polymer currency notes in India?', 'How does the Indian government print currency?', 'Is currency devaluation ethical?', \"How do currency's work?\", 'How do I save my national currency value?', 'What are unknown & interesting facts about Indian currency notes, which most us are not aware of?', 'How can I find out the real value of some old Indian currency notes that I possess?', 'Why didn’t RBI introduce the plastic currency in India with the new 500 and 2000 notes?', 'How are the Indian currency notes numbered?', 'Where does the money actually go if someone fails to deposit old Rs 500 or Rs 1000 notes to the bank before the 31st of December?', 'When the Queen will pass away, what will happen to the coins and the bank notes printed under her name?', 'What is the optimum denomination for currency notes in India?', 'What are the serious disadvantages of demonetization of currency notes in India?', 'Are 1990s dollar bills still valid?', 'After currency devaluation in a country, how is debt handled between individuals? Should we consider the old value, or the new one? Thanks in advance!'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I gain healthy weight without eating junk?', 'positives': ['How can I gain weight but also eat healthy?'], 'negatives': ['Why do I gain weight working out?', 'I am 21 years old girl with the BMI of 14.9 and my weight is 78 Ibs (35.6kg) How do I gain weight?', 'Why am I gaining weight?', 'Should I use a mass gainer to gain weight?', 'Will I gain weight?', 'What causes weight gain?', 'Does Ayurwin Nutrigain really help you gain weight without any side effects?', 'How have you (successfully/or not) gained weight?', \"I'm a 14 year old boy who is around 5.8 and I weigh about 106 pounds. I go to the gym and do weight training 3-5 times a week and eat lots of food. Am I under weight? If so, how do I gain weight?\", 'Do you gain weight eating cashews?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Where can I watch free streaming movies online?', 'positives': ['What is best site to watch free movies online?'], 'negatives': ['Is it illegal to watch movies online for free?', 'What are the most watched movies online?', 'Where can I watch hindi movies online free?', 'What sites can I watch free movies on while on my PS3?', 'What are the best sites to watch Bollywood movies for free?', 'Which is the best site for watching Malayalam movies for free?', 'How can I watch movies online without a credit card?', 'What movie website can I watch movies on without credit card information?', 'On which websites can I watch free Bollywood movies?', 'What is the best movies to watch?', 'How do you watch NBA games online for free?', 'What is best movies to watch?', 'How do I find best online sites for watching TV shows?', 'Is there a site where one can stream and watch Hollywood movies online without having to download them? Is there a site that has more movies than YouTube?', 'Where can I watch bollywood movies online?', 'How do I watch streaming movies for free on an iPad?', 'Can I watch movies online without giving a credit card number?', 'How can I download movies free and watch them on my smart TV?', 'What is the best site for free online courses?', 'Are there any good movie sites unblocked at school/work?', 'What are some great movies to watch?', 'Which are the best movies to watch?', 'Which are the best movies to watch?', 'What are some good websites for watching English TV shows for free?', 'Where can I watch English movies?', 'Where can I see parched movies?', 'Where can I watch US TV series free?', 'Where can I read books online for free?', 'What are some nice movies to watch?', 'Which are the best sites to watch free HD Bollywood movies?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can we recover our Gmail password online?', 'positives': ['How do I recover a forgotten Gmail password?'], 'negatives': ['Recover my Gmail?', 'How do you recover old Gmail addresses?', 'How can I recover photos from old gmail account?', 'Gmail: How do I bypass the verification process when creating a Gmail account?', 'How can I discover who owns a Gmail account?', 'How can I log into a Gmail account from a new device, without getting a notification?', 'How do I recover permanently deleted emails in gmail?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is the difference between deep learning and usual machine learning?', 'positives': ['How do I compare between Machine Learning and Deep Learning?'], 'negatives': ['What is the difference between AI, Machine Learning, NLP, and Deep Learning?', 'How is deep learning successful in artificial neural networks?', 'What is the difference between statistical learning and machine learning?', 'Which is the difference between machine learning and data analysis?', 'What is the difference between machine learning and data analysis?', 'How should I go about learning Machine Learning?', 'What is the difference between data science, artificial intelligence and machine learning?', 'Should I learn machine learning?', 'What is the difference between data mining, artificial intelligence and machine learning?', 'Is deep learning too deep to understand?', 'Is machine learning overrated or overhyped?', 'Is deep learning overhyped?', \"What is the difference between 'Statistical Learning' and 'Machine Learning?'\", 'How can I know whether I will be interested in machine learning?', 'What can you do with machine learning?', 'How can machine learning be used?', 'How can I understand machine learning?', 'What does the future of deep learning look like?', 'How data analysis is different from machine learning?', 'What is machine learning?', 'What is machine learning?', 'what is machine learning?', 'How can I learn machine learning better?', 'What can u do with machine learning?', 'How can I use Deep Learning in selecting features, and not training/predicting the data?', 'What is the machine learning?', 'What is Learning to Rank in machine learning?', \"What's new in Machine Learning?\", 'What are the limitations and challenges of deep learning models?', 'For what use cases do you think deep learning and neural networks overkill and simpler models work better in practice?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Do you need a trading plan as a Forex Trader?', 'positives': ['Why do Forex Traders need a trading plan?'], 'negatives': ['What do you think is Forex Trading so much risky?', 'How risky is forex trading?', 'What do you think is forex trading is risky?', 'What is Forex trading?', 'Is forex trading more risky than index trading or stock trading? Why?', 'Should I invest in a forex market?', 'What type of strategies do banks use in forex trading?', 'Is forex trading hallal?', 'What is risk aversion in Forex trading MARKET?', 'Which is the best forex trading company?', 'Currency trading Or trading in forex is profitable or not?', 'What is the best strategy for forex?', 'Is online forex trading real?', 'What is the best way to trade forex?', 'Which the best broker for Forex trading?', 'What are the things you learn being a Forex Trader?', 'Why is forex trading illegal in India?', 'Is Forex trading legal in India?', 'What forex strategies do banks use?', 'Is forex trading in India legal?', 'Y we should join forex, and invest in forex market?', 'What is online Forex trading?', 'What are the things you learn by being a Forex Trader?', 'Is Forex trading illegal in India? why?', 'How do I trade Forex Futures?', 'What is the minimum amount I should trade in forex with risk management?', 'Is forex trading valid and legal in India?', 'What is your best strategy in forex?', \"Is there anyone currently trading using Lance Beggs' YTC method to trade FX futures, forex and stocks?\", 'Why do traders lose money in the stock market?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the best home exercises to lose weight?', 'positives': ['What are some exercise to lose weight?'], 'negatives': ['Which is the best way to lose weight: the gym or jogging?', 'Is it possible to lose weight without doing exercise?', 'What are some non-intense exercises that can burn a lot of calories?', 'How does exercise relieve stress?', 'How do people loose 4-5 kg in initial month of weight loss exercise?', 'Is exercise necessary?', 'What are the best exercise routines?', 'Will jogging help me lose weight?', 'To lose weight, is it better to jog or to do workouts like plank, push ups, or situps?', 'How do I lose weight for running?', 'Why do I lose weight without dieting and exercise?', 'Do you have to eat food supplementation during exercise?', 'How do I lose muscle in my legs?', 'How can you lose weight without doing exercises?', 'As a man, how can I reduce the size of my butt with exercise?', 'Can you lose weight without exercising?', 'How can I lose both fat and muscle in my legs?', 'Does exercise lower cholesterol?', 'How long would I have to walk to lose 1kg per week with no other exercise?', 'What is your exercise routine?', 'What are the best exercises?', 'Can I lose weight only by jogging?', 'What exercises can I do to get rid of armpit fat and back fat?', 'Disregarding diet, which is better for long-term health (particularly in old age) : moderate or intense physical exercise?', 'Can exercise remove the side effects of antidepressants?', 'Is losing about 0.5 kg a week with exercise and healthy eating good enough? Can I achieve more fat loss than this?', 'How do you stay motivated to exercise?', 'How can someone lose weight without exercising, dieting or medication?', 'How do exercising and physical activities help with stress?', \"What should be my diet plan (non vegetarian or vegetarian) and exercise which I can do to loose weight as I have just joined gym. I'have hypothyroid?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How should I improve my English speaking and writing skills?', 'positives': ['How do I improve my English writing ability?'], 'negatives': ['I am a bit weak in English. I find difficulty while doing precis writing because the vocabulary is tough. Can someone help me what to do?', 'Which book can help me practice writing and enhance my skill on writing in English for the CBSE class 12?', 'How can I improve my English speaking skills if my listening and reading skills are strong?', 'How can reading newspaper help me improve my English?', \"I am very depressed. No matter how much I write, there're still grammar mistakes in my writings. Should I quit English?\", 'What are some of the best newspapers to read to improve English skills?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What is India's GDP growth rate? Is it real or the data is being manipulated?\", 'positives': [\"Is India's GDP growth rate based on dubious data?\"], 'negatives': ['How can we calculate GDP GROWTH?', \"What is India's current GDP?\", 'What is the growth rate of real GDP per capita?', 'What does the GDP figure of 5.7% signal about the Indian economy?', 'What is the current GDP of India?', 'Is GDP or GNP the best measure of economic growth?', 'What do you mean when you say the GDP of India is 7.5% (or for that matter any figure between 7-8%)?', 'What is the real significance/relevance of indicators like GDP growth, containment of fiscal deficit, etc. for the inclusive growth of Indian economy?', 'How did India reach the 3rd spot in the GDP (PPP) when it holds the 9th rank in the GDP (nominal)?', 'How is the GDP Calculated?', 'Does GDP 7% means we are growing?', \"How has primary activity contributed to India's gdp?\", 'What is a employment rate in India? Is it growing?', 'Why do governments pursue continual GDP growth? Is a stagnant economy really that terrible?', 'How is the percentage of GDP calculated?', \"What does the GDP show about a nation's economy?\", 'What does an Indian GDP of 6.5% mean?', 'What will a 10% growth in the GDP every year in India do?', 'Why is there a difference between IIP and GDP growth numbers?', \"Why isn't anything done about India's population growth?\", 'Nominal GDP per capita growth to real GDP per capita growth?', \"What percentage of the Indian population depends on agriculture and what is the agriculture sector's contribution to India's GDP?\", 'Is GDP a good measure of economic development? Why or why not?', 'What is the significance of calculating GDP at factor cost and GDP at producer prices?', 'What is GDP?', \"Why is Brazil's GDP higher than India's? Is it really more developed than India?\", 'What is the significance of GDP?', 'What is GDP? How is it calculated?', \"India's GDP is more than of UK, Canada, Australia, Saudi Arabia etc yet our standard of living is far behind from them, why?\", 'Economics: Why do developed countries have a much higher proportion of GDP contributed by tertiary than secondary sector?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I convince someone not to commit suicide?', 'positives': ['What can one do to convince someone not to commit suicide?'], 'negatives': ['Is it selfish to commit suicide?', 'Why do you want to commit suicide?', 'Why do some people commit suicide?', 'Should someone that encourages the suicide of another be arrested?', 'Why do people commit suicide?', 'What do people think about right before they commit (or attempt to commit) suicide?', 'Why some people commit suicide?', 'When and why do people commit suicide?', 'Why do people commit for suicide?', 'Why do some successful people commit suicide?', \"Is it true that sociopaths don't commit suicide?\", 'I know someone who committed suicide over adulthood. Why would someone do that?', 'Can someone who thinks about suicide for 7 years really do it?', 'Why do people commit suicide while in a depression?', 'Is encouraging suicide murder?', 'What is the main reason why people commit suicide?', 'Is suicide a desire?', 'How do I deal with a person with suicidal thoughts because of a relationship?', 'What is the best way to commit suicide in India?', 'If a guy asks me if he should die and I tell him not to and tell him positive things, counsel him and not try and get him to an official practitioner and he henceforth committing suicide. Will it be a crime/unethical/bad on my part to not help him in any more ways possible?', 'How do I commit suicide with no pain?', 'What is it like to have a loved one commit suicide?', 'I undergo unbearable depression and thinking of suicide. Can anybody disclose who were just about to suicide, but again successful in life?', 'Why do people suicide?', 'How do I end a relationship with a suicidal person?', 'Is it normal to contemplate suicide?', \"Do 'Call someone for help' signs decrease suicides?\", 'Why do people fear death and have such a low opinion about those who contemplate suicide?', 'What is the cheapest, painless, easiest way to commit suicide?', 'Do sociopaths commit suicide?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What does an unlocked phone mean?', 'positives': ['What does unlocked phone mean?'], 'negatives': ['What is the difference between a locked and unlocked phone?', 'How do you lock an unlocked phone?', 'What is difference between international unlocked and US factory unlocked smartphones?', 'What does it mean to jailbreak or unlock a phone?', 'How do you unlock a Public Mobile phone?', 'How do I unlock a stolen phone?', 'How will I come to know who tried to unlock my android phone?', 'How can I unlock my smartphone?', \"What's the best way to unlock a phone?\", \"Can anyone unlock someone's android phone without knowing his pattern/pin?\", 'How does one unlock a T-Mobile phone?', 'How can I unlock a Samsung phone?', \"How do I unlock my Android mobile if I forget my lock pattern and don't have any security question?\", \"What's the funniest or most amazing thing your smart phone did while unlocked in your pocket?\", 'What is the best way to unlock smartphone?', 'How can I unlock my Nokia Lumia 710 phone?', 'Who do I unlock a phone with password?', 'What is the Nokia E72 lock code?', 'What does the lock symbol on my iPhone 6 means?', 'How do I unlock a Nokia Lumia 520?', 'How do I unlock my HTC phone?', 'How do I unlock a device which is locked with an Android device manager?', 'Can an iPhone 6s be unlocked?', 'How can an iPhone be carrier unlocked?', 'What is meant by \"jailbreaking\" a phone?', 'What does a refurbished phone mean?', 'How do you unlock a Metro PCS phone?', 'How do you unlock an iPhone that is locked?', 'I have a HTC 8s with broken LCD and screen got locked. Can I know some way or app to unlock the phone without resetting the phone?', 'How do I unlock my HTC 626 S phone after forgetting the pattern code?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'When do you know that you are in love?', 'positives': ['How do you know if you are in love? How do you know its not just chemicals in your brain trying to trick you to reproduce?'], 'negatives': ['How do you know when you love yourself?', 'Can you truly say you love someone if you do not know why you love them?', 'How do you know for sure if someone does not love you?', 'How do you know that you are dreaming?', 'How does it feel not to love someone knowing that they truly love you?', 'How do you know someone is falling out of love with you?', 'What is a neurological or scientific explanation for \"falling in love\"?', 'How true is love?', \"How do you know you don't love someone anymore?\", 'How do we know if we are dreaming?', 'How do I know what my passion is?', 'How would you know if you love someone even if you do not have any physical or emotional reaction about the person but you do think you like her?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Is it possible for dogs to catch worms from other dogs?', 'positives': ['How can dogs pass worms to other dogs?'], 'negatives': ['Is it possible for a dog to die from parasitic worms? How can this be prevented?', 'Is it possible for a puppy to die from parasitic worms? How can this be prevented?', 'What are some home remedies to get rid of ringworm in dogs?', 'Is it possible to catch fleas from a dog?', 'Can I get fleas from my dog?', 'What are the best ways to keep dogs from getting fleas?', 'Why do I keep getting fleas from my dogs?', 'What are some precautions to avoid getting fleas from my dogs?', 'How is it possible to get fleas from my dog?', 'How do tapeworms kill animals?', 'How can I keep my dog from getting fleas?', 'Why do dogs chase cats and not other creatures?', 'Why do some dogs play without treats?', 'How do tapeworms eat and kill animals?', 'What are the best home remedies for tapeworms in puppies?', 'Is it possible for humans to catch fleas from their dog and how can you prevent this from happening?', 'How do you know if you have worms?', 'What insects eat dog poop?', 'How do German Shepherd/Labrador mix dogs interact with other animals?', 'How do Pit Bull/Rottweiler mix dogs get along with other dogs?', 'How can I prevent my dog from getting fleas from my hedgehog?', 'How do Boxer/Yorkie mix dogs get along with other dogs?', 'How do German Shepherd/Greyhound mix dogs interact with other animals?', 'What are stray dogs?', 'What are worm holes?', 'What food makes dogs vicious?', 'What is the best cure for ring worms?', 'Why do dogs eat feces?', 'What is the best way to treat and inner ear infection in dogs? Is it contagious?', 'Why does my dog play without treats?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How likely is a war between the U.S and Russia?', 'positives': ['What is the likelihood of war with Russia?'], 'negatives': ['Will Russia invade the rest of Ukraine?', 'Is the US starting a war with China and Russia?', 'Are Russia and Iran at war with the USA in Syria?', 'Do the western and eastern parts of Russia have conflicts with each other?', 'What are the consequences of the conflict between Ukraine and Russia?', 'What would a war between the EU and Russia look like?', 'What would happen if Russia and the EU declared war on each other?', 'Escalation of the Syrian Conflict (Aug–Sep. 2013): If the U.S. strikes Syria over Russian opposition, is there a meaningful risk of a World War?', 'If Russia decides to take over Ukraine and the US is forced to fight against Russia all-out, how bad could it be? Who will win in the end?', 'What if Russia invaded the U.S.A?', 'What is current status of Russia in Syria crisis?', 'Is Russia considered a western country?', 'Is Russia currently an enemy of the United States?', 'What would happen if Russia and China went to war with each other?', 'Is Russia a potential superpower?', 'Will Russia support India, in case of war with Pakistan?', 'Will Russia invade Britain?', 'Is Russia too strong for USA to destroy it?', 'Is Russia changing?', 'Based on the recent threats and issues regarding the US, Russia and China, is World War 3 near?', 'Who will win war between China and Russia?', 'Why is the war in Syria so important to Russia and the USA?', 'Is Ukraine losing the war against Russia?', 'What should I know about Russia?', \"Perhaps I'm wrong, but Russia seems to take disinformation and propaganda to a far higher level than the US, fully integrating it into war planning. Am I missing something?\", 'How would a war between Russia and China play out? Who would win?', 'If Russia becomes much stronger and much more powerful than the rest of the countries in the world, what would happen to the world?', 'Has Great Britain ever been at war with Russia?', 'Could Russia have prevented WWI?', 'How long is there going to be a tension between Russia and NATO? Will it end one day? If yes, when?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I raise funds for a startup business idea?', 'positives': ['How can I get funds for my business idea?'], 'negatives': [\"I'm 24 years old with access to a few hundred thousand dollars to invest, but I have no idea what to do. How can I search for an idea to start a business?\", 'I have an idea for a startup. An investor agreed to invest in my idea; how much of a share should I give him?', 'How does one go about making a business or product idea into a financially workable enterprise?', 'If I have a business idea, how can I obtain feedback and information from other people without giving out my idea to someone who could steal it?', 'How do I turn my idea into a successful company?', 'What are the steps I need to take between working on my business idea and executing the idea?', 'How do I know whether any startup idea is worth investing our time and money?', 'A friend funded my app idea. I am scared that I will mess up. What do I do first?', 'How do you sell a feature / product idea to a startup?', \"Let's say I have a million dollar idea. How can I find and approach any company which will patent this idea and also give me some credit?\", 'Do you know any company who invests in an \"idea\"?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What are some mind-blowing technology gadgets that exist that most people don't know about?\", 'positives': [\"What are the best new products or gadgets that most people don't know about?\"], 'negatives': [\"What are the best new phones gadgets that most people don't know about?\", \"What are some mind-blowing Automobile gadgets that most people don't know about?\", \"What are some mind-blowing car gadgets that most people don't know about?\", \"What are some mind-blowing iphone gadgets stuffs that most people don't know about?\", \"What are some mind-blowing outdoor gadgets tools that most people don't know about?\", \"What are some mind-blowing robotic home gadgets that exist that most people don't know about?\", \"What are some mind blowing gadgets for photography that most people don't know about?\", \"What are some mind-blowing mobile technology tools that exist that most people don't know about?\", \"What are the best new mobile inventions that most people don't know about?\", \"What are some mind-blowing drivers tools safe gadgets accessories that exist that most people don't know about?\", \"What are some mind blowing bike gadgets that most people don't know?\", \"What are the best new smartphone inventions that most people don't know about?\", 'What are some mind blowing car gadgets that most people should have?', \"What are some mind-blowing Hologram gadgets that exist that most people don't know about?\", \"What are Some mind Blowing Mac gadgets that most people don't know?\", \"What are some mind-blowing car technology tools that most people don't know about?\", \"What are some mind blowing doorbell gadgets that most people don't know?\", \"What are some mind-blowing phone tools that exist that most people don't know about?\", \"What are some mind blowing Scooters gadgets that most people don't know?\", \"What are the best new phone inventions that most people don't know about?\", \"What are some mind blowing phone tools that most people don't know about?\", \"What are the best new camping tools that most people don't know about?\", \"What are some mind-blowing mobile inventions that exist that most people don't know about?\", \"What are some mind-blowing wallets gadgets that exist that most people don't know about?\", \"What are some mind-blowing Smartphone inventions that exist that most people don't know about?\", 'What are some mind blowing bike gadgets that most people should have?', \"What are some cool wallet gadgets that people don't know about?\", \"What are some mind-blowing iphone technologies that exist that most people don't know about?\", \"What are some mind blowing car technology that most people don't know?\", 'What product do people buy most?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How was the KVPY SA 2016? What is the expected cutoff?', 'positives': ['What do you think the cutoff of KVPY 2016 SA would be?'], 'negatives': ['What is the expected cutoff for KVPY SA 2015?', 'What is the expected cut off for KVPY SA 2014?', 'What is the expected cutoff of KVPY SX 2015?', 'How many appear for kvpy?', 'I am an average 12th class student(pcm).What should I do to crack kvpy 2016 if I have two months only?', 'What are some differences between KVA and KVAR?', 'How should I prepare to ensure my selection in KVPY in class 11?', 'How do I study for KVPY?', 'Who can appear for KVPY?', 'What is KVPY exam?', 'How should I prepare to ensure my selection in KVPY in class 10?', 'I got a rank of around 150 in the SA stream in the KVPY in 2013. What chances do I stand of getting selected at IISc?', 'What are the recommended books to crack the KVPY 2015?', 'Which are the best books for KVPY preparations?', 'How should I study for kvpy math?', 'What is likely to the be cutoff for IISC UG 2015 admission for the KVPY SX?', 'What are best books for kvpy?', 'How do you convert watts to kVA?', 'Which books should be preffered for kvpy?', 'I am currently a class 11 student pursuing CS. Can I take up KVPY exam in SA stream ? Can I crack it without any knowledge of biology ?', 'What is your KVPY interview story ?', 'I am from NIOS board am I eligible for KVPY examination class 12?', 'Why transfarmer is rated in KVA?', 'What rank will I get if I score 70 in KVPY SX (aptitude test+interview)?', 'Is biology required for kvpy?', 'KVPY interview is going on in different places. Will you share your experience?', 'I will be appearing for KVPY SX category in 2016.Can I attempt all four subjects (PCMB) both in part I and II (advantages and disadvantages of it)?', 'I got a rank of 922 in the provisional list of KVPY SX. What are my chances of making it into the IISc UG programme?', 'Is biology compulsory for KVPY?', 'Why is transformer rated in kVA and not in kW?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can you prevent jet lag?', 'positives': ['How can I deal with jet lag?'], 'negatives': ['What is jet lag?', 'How do international cricketers deal with jet lag?', 'Does jetlag cause depression?', 'What is really happening when they say my plane is delayed for mechanical problems?', 'How do jet engines actually work?', 'I have 26000 Jet Miles (Jet Privilege). What is the best way to use it?', 'Why are jet streams called travelling depression?', 'How can I reduce my fear of flying? I have a three-hour flight in a couple of weeks.', 'What are some tips to staying comfortable during a long flight?', 'What causes airline delays?', 'What are the top causes of flight delays?', \"Why don't pilots tell you everything is OK during turbulence?\", 'Is it scary to fly an airplane in bad weather?', 'Most severe turbulence faced by you while travelling in Boeing 747 jumbo jet?', 'Why are jet streams known as travelling depressions?', 'What is lag?', 'How can I cope with fear of flying?', 'Is it boring being an airline pilot?', 'What causes turbulence on airplanes?', 'Why are airplanes so slow?', \"How do jet engines work, in layman's terms?\", 'Can bad weather sink an aircraft carrier?', 'What is difference between plane stress and plane strain?', 'How can one get over a fear of flying?', 'What can be done to overcome the fear of flying?', 'What are some reasons for the pilot light on my water heater to keep going out?', 'Can the cockpit temperature be regulated in fast jet military planes?', 'Why is there turbulence in airplanes?', 'What are some tips for staying comfortable on long flights?', 'Why do I have feeling of fainting during commercial plane take off?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Do girls like smart/nerdy/geeky guys?', 'positives': ['Do girls like geeky and nerdy guys?'], 'negatives': ['Is there a difference between nerds and geeks?', \"What's the difference between a geek and a nerd?\", 'What do you think of geekbuying?', 'Do guys like crazy girls?', 'What type of guys do girls like?', 'What type of girls do guys like?', 'Do girls like fat boys?', 'Why do girls like curly hair guys?', \"Do girl's like cute guys, the guys with boyish looks rather then very manly looks?\", 'Do talkative girls like shy guys?', 'How nerdy are MIT students? What kinds of nerds are they?', \"Do girls like or don't like guys with chest hair or no?\", 'Why do I like chubby girls?', 'What are the differences between Jocks/Nerds/Geeks in a relationship?', 'Do Boys like introvert girls as girlfriend?', 'What are the differences between weird, freak, geek, nut, nerd, pervert and fool?', 'What do girls like in cute boys?', 'How does it feel to have a nerd girlfriend?', 'What do girls like?', 'Do girls like fat men?', 'Do guys like shy girls?', 'What is the difference between a nerd and an intelligent person?', 'Do guys like girls who wear short clothes?', 'Do transgender guys like girls?', 'Do white girls like brown boys?', 'Do guys like skinny girls or girls who are thick?', 'How nerdy are MIT students?', 'Do boys like introvert girls?', 'What do guys think of the girl they like?', 'Do boys like introverts girls as a girlfriend?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I clean reclaimed unfinished wood floors?', 'positives': ['How do you clean unfinished wood floors?'], 'negatives': ['How do you clean wooden kitchen cabinets?', 'How can I clean a dirty carpet without water?', 'What is the best way to clean a carpet?', 'How effective are wooden flooring in delhi?', 'How do I stain wood?', 'How effective is wooden flooring in Delhi?', 'How do I clean a kitchen?', 'How do I fix water damage on my hardwood floor?', 'Why do wood floors buckle?', 'What is the best way to clean house windows?', 'What are some tips for building a house in the woods?', 'How would you create a clean room?', 'How do you clean table saw blades?', 'Natural Building: How can one make good earthen floors?', 'What is the best way to mop a floor?', 'How can you find and petrified wood?', 'How do you clean dirty Kraftmaid cabinets?', 'How do you stain pine wood?', 'How are clean room created?', 'How is laminate flooring installed?', 'How do I clean a brown leather chair?', 'How do you build a doghouse out of wood?', 'What is a good solution to clean the stains on bathroom and kitchen floors and walls?', 'How can I clean my white leather sofa?', 'What is the best way to clean blood out of carpet?', 'How do you remove oil stains from wood', 'What is the best way to remove mold from walls?', 'How can I make a homemade tile cleaner?', 'How is wood used in windows?', 'What is the best plywood for subflooring?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What will be the impact on real estate by banning 500 and 1000 rupee notes from India?', 'positives': ['How does the declaration that Rs 500 and Rs 1000 notes would not be accepted as valid transactions affect real estate in India?'], 'negatives': ['What is the real estate trend in India?', 'What is real estate new trends in India?', 'What effect will rising interest rates have on the commercial real estate market?', 'Real Estate in India: My Builders asking to register the flat before getting the OC? What all are the risks?', 'How is the price of real estate determined?', 'Financial terms used in real estate?', 'Can an Overseas Citizen of India(OCI) card holder buy/sell real estate in India?', 'How does real estate work?', 'What is the future of real estate in India?', 'What is the current status of real estate in mumbai?', 'Are real estate prices going down in 2014?', 'What are the risks associated with foreign investments in commercial real estate in Vietnam?', 'Will real estate price in Pune go down in upcoming couple of years?', 'Why has real estate in the US become so expensive?', 'Which localities in India have the highest real estate prices?', 'What are the pros and cons of real estate investing?', 'Real Estate: Who pays stamp duty and registration charges when buying or selling property in India?', 'Will the real estate price go down in Pune?', 'Real Estate Investing: Is owning a rental property worth the headache?', 'Are governments of countries with tear-away real estate speculation irresponsible, by not imposing substantial levies on foreign purchasers?', 'How does real estate business work?', 'Has there been any price drop in the Indian real estate market post demonetization?', 'As of July 2015, what restrictions are there in Australia on foreigners (non-citizens) purchasing residential real estate in Australia?', 'What is the current status of real estate in Pune?', 'What is the historical return of real estate vs stock investing?', 'Would it be smart to use profits from my e-commerce store to start investing in real estate?', 'Would using the 1031 exchange make me a bad real estate investor?', 'How do real estate sites make money?', 'What is the future of real estate in punjab India, will it come back up after 2017 state elections?', 'Is real estate a good investment for 2014?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What is actual meaning of life?', 'positives': ['For you what is the meaning of life?'], 'negatives': ['What is the best \"meaning of life\" answer that you have ever given or heard?', 'What does \"live your life\" mean?', 'I am trying to find a meaning to life, to give a purpose to my life. Is there any book that can help me find my answer, or at least give me the tools?', 'What is the meaning of death?', 'How would you describe your IT life?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What were the major effects of the cambodia earthquake, and how do these effects compare to the Kamchatca earthquakes in 1952?', 'positives': ['What were the major effects of the cambodia earthquake, and how do these effects compare to the Vailfivia earthquake in 1960?'], 'negatives': ['Is Earthquake activity increasing?', 'Is Cambodia experiencing climate-change?', 'Was the earthquake in West Chester, PA, a result of hydraulic fracturing?', 'What effect do natural disasters have on the economy?', 'How does an earthquake happen?', 'What would happen if there was a constant earthquake in one area for one year?', 'How does an earthquake happen? Can it be predicted?', 'How is the intensity of an earthquake is counted and how do they measure it on Richter Scale?', 'Seismic effect=earthquake ground motion effect, is it true?', 'What are the effects of the 2004 tsunami?', \"What have been the contributing factors to Hong Kong's GDP growth rate and how does it compare to Cambodia?\", 'What is the importance of determining the epicenter of an earthquake?', 'What are the effects of natural disasters on the environment?', 'How is the epicentre of an earthquake determined?', 'Effects of natural disasters on unplanned cities?', 'What is the main reason for earthquake?', 'Is there a relationship between earthquakes and weather?', 'Why an earthquake happens?', 'What should you do in the event of an earthquake?', 'Why the 8.2 degree earthquake of 2010 in Chile caused damage in a few buildings and the one of only 6.2 that was in Italy caused so much damage?', 'Who are some lesser known important historical figures of Cambodia and what should people know about them?', 'Which instrument is used to measure the earthquake?', 'What is the reason for an earthquake?', 'How is the Epicentre of an earthquake located? What are some examples?', 'How would a massive Cascadia Subduction Zone earthquake affect Portland, OR?', 'How can we predict Earthquakes?', 'What areas of the world are most affected by natural disasters?', 'How did the 6.2 magnitude earthquake cause so much damage in Italy?', 'What are some of the rarely mentioned facts about the Khmer Rouge of Cambodia?', 'Is there any relationship between earthquake & rain?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Where can I get quality assistance for budget conveyancing across the Sydney?', 'positives': ['Where can I get very friendly assistance in property for sale across the Sydney?'], 'negatives': ['What will be the best place in Sydney to hire the services of a licensed conveyancer?', 'Where can I get friendly assistance for any commercial loans in Melbourne?', 'Where can I get the best construction cleaning service in North Sydney?', 'Where can I found most professional and friendly photo booth services in Sydney?', 'Where can I get different kind of cleaning services in North Sydney?', 'In Sydney, where can I get all types of commercial electrical services?', 'Where can I find professional electrical services in Sydney?', 'What will be the good towing company in Sydney?', 'Where can I get specially designed photo booth services in Sydney?', 'Are there any affordable photo booth hire places in Sydney?', 'Where you can find Pest control service in Sydney?', 'Where can I get a wide variety of products in Sydney for fire prevention?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What subtle signs did you first notice when your antidepressant started working?', 'positives': ['What was the first thing you noticed that made you realize your antidepressant was working?'], 'negatives': ['How can I tell if my antidepressants work?', 'Do antidepressants work?', 'Just started to take antidepressant as part of my treatment, what should I expect now?', 'What does it feel like to be on antidepressants?', 'How does it feel to be on antidepressants?', \"Why don't antidepressants work for everyone?\", 'What would exactly happen if a person took a handful of antidepressants, mixed with alcohol?', 'Does it matter what time of day you take an antidepressant?', 'What are antidepressants?', 'How does it feel to take antidepressants? Do they really help?', 'I feel like my antidepressants are making me feel worse. Has this happened to anyone?', 'What do most indian people think about antidepressants?', 'What are the side effects of antidepressants?', 'Should I take antidepressants?', 'What are the least dangerous anti-depressants?', 'Does eating antidepressants spoils anybody life?', 'How can antidepressants ruin your life?', 'Do antidepressants work like the drug Soma described in Brave New World?', \"How do you feel when you don't take suddenly your anti-depressive medication?\", 'What are the most effective anti-depressants?', 'Has anyone ever taken anti-inflammatory drugs (like aspirin) for depression? Did it work?', 'What are the first signs of depression?', 'Do antidepressants really take the pain away?', 'Can I take antidepressants forever?', 'What are the long term effects of anti depressants?', 'What made you depressed?', 'What anti depressants are best for immediate short term relief?', 'How can antidepressants cause weight gain?', 'How do antidepressants cause weight loss?', 'What are the changes you observe in people the moment you tell them that you have depression?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Why do we have poverty?', 'positives': ['What do you think are the causes of poverty?'], 'negatives': ['Why is poverty considered a social problem?', 'How does poverty affect the economy?', 'Is poverty only related to money?', 'Does poverty cause crime?', 'What are some global poverty examples?', 'Does poverty lead to crime?', 'Do people in developed countries believe that they are the reason of poverty in developping countries?', 'Can poverty be eliminated and how?', 'What does \"genteel poverty\" mean? What are some examples?', 'Do most people who live in poverty know it?', 'Do people in developing countries believe that developed countries are the reason of poverty in their country?', 'Does poverty cause terrorism?', 'Is poverty more of a generational thing or a situational thing?', 'How does poverty affect crime?', 'Is poverty the a key reason for terrorism?', 'What solutions can you think of to reduce poverty effectively?', 'What caused poverty in Brazil?', 'How can poverty be reduced or eliminated worldwide?', 'What are the solutions to reduce poverty?', 'Poverty is the mother of all crime?', 'What is the global poverty project?', 'How can poverty end?', 'How can we get rid of world poverty?', 'What have we been doing to end poverty?', 'Does this idea solve world poverty?', 'What do you to reduce world poverty?', 'What are the connections between poverty and crime?', 'Is poverty in poor countries due to the rich countries?', 'What are the causes of homelessness in America?', 'Way to Solve Poverty?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"If the US didn't have two term limit for Presidents, and Obama was to run a third time, would you still vote for him?\", 'positives': [\"If Obama could run for a third term in office then would you vote for him or wouldn't you and why?\"], 'negatives': ['Hypothetical scenarios: If Obama could run for office again, could he win?', 'Will (or should) Barack Obama run for political office again after leaving the Presidency?', \"Obama can't run again, but can he theoretically be re-elected as a write-in candidate?\", 'If Barack Obama was not a presidential candidate in the 2008 election, who would most likely have been the Democratic nominee?', 'Should Barack Obama have been allowed to run so Trump could have defeated a real opponent and not a whimp like Clinton?', 'To those outside of America: If the current US presidential election candidates (Obama Vs. Romney) were running in your country who would you vote for and who do you think would win?', 'Do you think a president, who has served two terms, should be able to run for president again?', 'Would Barack Obama be allowed to run in the 2020 presidential election?', 'Could Barack Obama run for president in 2020?', 'If you could ask President Obama one question, what would it be?', 'Would you want to be President?', 'Could a president run for a third term after taking a 4-8 year break?', 'How would you rate Obama’s presidency?', \"Why can't Obama re-elect as president?\", 'Would you vote for Trump and why?', 'If Romney had crushed President Obama in the 2012 Presidential debates would the President have won a second term?', 'Is it only Trump and Clinton in the race? What if someone wants to vote for a third party?', 'Which president did you vote for in the 2016 election?', 'Can President Obama run again in 2024?', 'Who would you like to run for president?', 'If Biden ran for presidency in 2020, could Obama be his VP?', 'Would you vote for Donald Trump as president?', 'Why did some voters vote for Obama in 2008/2012 and for Trump in 2016?', \"Why can't Obama be re-elected?\", 'What are some good reasons to vote for Barack Obama in the 2012 US Presidential election?', 'What will Obama do after his term?', 'How can Obama claim he would have won against Trump if he had run when Dems lost 1,042 state and federal posts under him and he couldnt help Hillary?', \"Who should run for president but won't?\", 'Would you vote for Trump or Hillary and why?', 'If you got the chance to run for president of the United States in your future, would you?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Does speed reading really work?', 'positives': ['Does speed reading really work? If so, how?'], 'negatives': ['What is ideal reading speed?', 'What is the ideal reading speed?', 'What can I do to improve reading speed?', 'What is the best way to improve reading speed?', \"How can I increase my reading speed while retaining and comprehending what I've read?\", 'How do I improve my reading speed?', 'How do I improve my reading speed, especially when I read science materials?', 'What are the most effective methods of improving your reading speed as well as comprehension?', 'Do you have any tips for reading faster and with more focus?', 'What are the best ways to develop reading speed and comprehension?', 'How do I increase my reading speed and also conversation speed?', 'How do I improve reading speed for cat and what is the ideal reading speed in words per minute with utmost comprehension or understanding?', 'What are some tips on reading books faster?', 'How do I increase the speed of reading skills without compromising on comprehension?', 'How can I read an entire book faster?', 'How fast does a computer read?', 'Is there any possibility to improve my reading-skills?', 'How can I read more quickly?', 'What are some tips to read books faster?', 'Does reading more improve memory?', 'Is reading in the night not as efficient as reading in the morning?', 'How does reading improve memory?', 'How do I make strong reading concentration power?', 'What is a proficient typing speed?', 'How can I read books more quickly with full comprehension?', \"How do I really speed READ? I Saw YouTube tutorials didn't help, any real video out there?\", 'How do I read quickly?', 'How can you read quickly but deeply?', 'How do I improve my reading skill?', 'How do we improve reading skills of children?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"I'd like to date a cop or detective. What's a good way to meet some?\", 'positives': [\"I'd like to date a cop. What's a good way to meet one?\"], 'negatives': ['I am a diplomatic woman in my 20’s. How do I find an intelligent man to date?', 'How do I meet guys to date?', 'What is it like to be married to a police officer?', 'What is the nicest thing I could do for a police officer?', 'How can I become a mall cop?', 'Can I become a good police officer even if I try to avoid physical or verbal confrontation?', 'What is the good way to approach a girl who is a hotel receptionist to dating me?', 'Where can I meet the right guy?', \"I just moved to a new city for a job and I don't know a single person here.. What's the best way to meet new (like-minded) people in a new city?\", 'How can we date with strangers?', 'What are the best ways to meet people when moving to a new city?', \"I'm considering to become a police officer where do I start? (I'm 18 and college student)\", 'If you are in a serious relationship, where or how did you meet your partner?', \"I am a guy. I don't know what to talk about when I meet someone for the first time. What should I do?\", 'What advice would you give a young girl (18) who wants to be a police officer? What kind of things do you wish you knew before becoming a cop?', 'What are your tricks to start a conversation with a stranger?', 'What exactly to do to be in police as an S.I?', 'How should you interact with a police officer if your vehicle is pulled over?', 'Given a chance to meet any person, whom would you like to meet and why?', \"What's the best way to initiate a conversation with a stranger?\", 'What is the best way to start an engaging conversation with a stranger?', 'How do I meet guys?', 'Where do I meet gay guys to date?', 'How did you meet your girlfriend/boyfriend?', 'What are the pros and cons of becoming a cop?', 'I am from India and live abroad. I met a guy from France in a party.I want to date him. How do I do that?', 'What is the best way to start conversation with a stranger?', 'What is it like to be a female police officer?', 'How do I meet people when moving to a new city alone?', 'Does one have the right to ask a uniformed police officer for his badge/identification during a routine stop?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I become a penetration tester?', 'positives': ['What is the way to become a penetration tester?'], 'negatives': ['What are the steps to be followed to create my own penetration test lab for free?', 'How can become a stripper in India?', 'What are the benefits of becoming Pearson Vue authorized test center in India?', 'What are the main differences between Vulnerability Assessment VA and Penetration Testing PT?', \"I'm a science student. Am I eligible for CA/CPT exam? If yes, then how should I go about it?\", 'What is the best techniques for deep penetration when having sex?', 'Which is the best book to refer to completely learn penetration testing using Kali Linux?', 'What is the procedure to become a CBI or IB or RAW officer (a-grade)? Is there an exam?', 'What course should I study to become cyber security expert in India?', 'How does one become ServSafe certified in the US?', 'Can a woman get pregnant without penetration?', 'How do I become a junior RAW agent?', 'How does one become ServSafe certified?', 'Is it illegal to take a road test without training?', 'Are there any virginity tests?', 'What is the procedure to become an IRTS officer?', 'What is process to become a raw agent?', 'How can I become a RAW officer? What is the process?', 'What is the entire process of becoming a certified ethical hacker?', 'What are the pros and cons of getting a circumcision as an adult?', 'How can I become a pornographer in brazzers.com?', 'Can a CA become IT officer?', 'Where can I take an I test?', 'How do I start in the security field to become a professional in cyber security from level zero?', 'I want to become a porn star. How can I apply?', 'Can i start my ethical hacking career without having a certification?', 'How can I become an IRTS officer?', 'What is the best way to become an escort?', 'How hard is it to pass the compTIA A+ certification exam?', 'I am an Indian. How do I take the Mensa standardised test?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Who will be USA next president, Trump or Clinton?', 'positives': ['Who will be the next president of USA 2016?'], 'negatives': ['Who will be the Democratic nominee for President in 2016?', 'Who will/should be the next president of India in 2017?', 'Who will be the next President of India?', 'Who is the president of us?', 'Who is president of USA?', 'Who is the President of America now?', 'Who will be the next President of India, and why?', 'Who is the president of America?', 'Who will be the next India President?', 'Who is president of america?', 'Who do you think will run for President in 2020?', 'Who will be the next Senate majority leader?', 'Who is the President of the United States?', 'If all 43 U.S. Presidents were to run for office in 2016, who would win? Also, who would be best suited to deal with the current issues?', 'Who do you think could be the next President of India?', 'Who is your favourite president of the USA?', 'Who is the U.S. President?', 'Who is the U.S. President?', 'Who is more likely to be the next President of India?', 'Who are the top candidates for US presidential election in 2020?', 'Who is likely to become the next President of India?', 'Will there ever be a Zoroastrian president of the USA?', 'Who would be the strongest Democratic nominee for President in 2020?', 'Who can become the next President of India and why?', 'Who will be the White House Press Secretary when Donald Trump is the new president 2017?', 'Who would be the strongest Democratic nominee against President Trump in 2020?', 'Should Henry Kissinger become the next president of the United States of America?', 'Who is more likely to be the President of India in 2017?', 'Who will be the President of India in 2017?', 'Who is going to be president of India in 2017? A Politician or A scientist?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the best books to read to learn about human psychology?', 'positives': ['What are the top ten books on psychology?'], 'negatives': ['What are some of the best examples/stories in psychology?', 'What are some good books on body language and human psychology?', 'Where can I find books on female psychology?', 'What are the best books on human sexuality psychology?', 'What are the best psychology blogs?', 'What is psychology?', \"What's the best book on modern sports psychology?\", 'What are the most interesting concepts in psychology?', 'What are some recommendations for good books on sports psychology?', 'What are the main theories of psychology?', 'What is a psychology?', 'What is the psychology?', 'What is the study of psychology?', 'Is psychology a science?', 'What are some interesting things to learn in psychology?', 'What are the best colleges for studying psychology?', 'What is the one core essence of psychology?', 'What are the best books about cognitive science?', 'What are the different types of psychology majors?', 'What are the subfields of psychology?', 'What is the best way to learn psychology?', 'What are best neuroscience books for beginners?', 'What are some good books about cognitive science?', 'What are the psychology branches and fields?', 'Any good neuroscience books for beginners?', 'What is a list of the subfields of psychology and what are their distinctions?', 'What are the best books to learn about human behavior?', 'What are some easy psychology topics for a research paper?', 'What is a neuroscience psychology program?', 'What are the branches and related fields of psychology? What do they do and what are some examples?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What can I do to improve communication skills?', 'positives': ['How can I increase my communication skills?'], 'negatives': ['How good are you in communication?', 'What are the characteristics of a good communication?', 'How can I improve social and conversational skills so I can always have something to talk about and almost never have an \"awkward moment\"?', 'What are some common barriers to effective communication?', \"What's the best definition of communication?\", 'How do I improve communication with my wife?', 'How do you overcome cultural barriers in communication?', 'What are the books I must read to improve my communication skills?', 'What is the importance of communication?', 'What are some common barriers to effective communication in a workplace?', 'I am a avid listener. But i fail to talk effectively. Are there any practical tips to follow to make a conversation more effective and attractive?', 'What can companies do to improve the cross-cultural communication skills of their employees?', 'What are the most common barriers that affect the effective communication of a relationship?', 'What are the pros and cons of verbal communication?', 'What are some examples of interpersonal communication?', 'What are examples of barriers to communication?', 'What have you learned from your experiences in communicating?', 'How do you usually communicate with your friends?', 'Why is effective communication important?', 'What are some examples of psychological barriers to communication?', 'How does non-verbal communication affect verbal communication?', 'What are the pros of verbal communication? What are its cons?', 'How do I improve my communications and writing skills?', 'How did Barack Obama develop his communication skills?', 'How can I improve my communication skills and writing skills?', 'Why is communication wonderful?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are some amazing facts/stories about Arijit Singh?', 'positives': ['What is most unknown fact about Arijit Singh?'], 'negatives': ['How is Arijit Singh as a person?', 'What are some of the unknown facts about Anil Kapoor?', 'What are some unknown facts about Mahendra Singh Dhoni?', 'What are some unknown and excellent facts about Urjit Patel?', 'What are some less known facts about Kapil Sharma?', 'What are some of the unknown facts about Hrithik Roshan?', 'What are some of the unknown facts about Irrfan Khan?', 'What are some lesser known facts about Aishwaya Rai Bachhan?', 'Is Arijit Singh overrated?', 'What are some of the interesting facts of Ekta Kapoor?', 'What are the interesting facts about Mahendra Singh Dhoni?', 'What are the unknown facts about sachin Tendulkar?', 'What are some of the most mind-blowing facts about Kapil Sharma?', 'What are some excellent facts about Urjit Patel?', 'What are the interesting facts about Viswanathan Anand?', 'What are unknown facts and figures about Sachin Tendulkar?', 'What are some facts about Viswanathan Anand?', 'What are unknown facts about lord Shiva?', 'What are some rare & interesting facts about the legendary Satyajit Ray?', 'What are some unknown facts about rajnikanth?', 'What are some of the most unknown facts about Indian politics?', 'What are some interesting and little known facts about Alibaug?', 'What are some unknown facts about Shahjahan, the great Mughal Emperor?', 'What are some unknown facts about sapna vyas Patel?', 'What are some interesting facts about Sachin Tendulkar?', 'What are some interesting facts about Ranbir Kapoor?', 'What are some of the unknown facts about Bipasha Basu?', 'What are some some bad fact about mahatma gandhi?', 'What are some interesting or unknown facts about Pandit Jawaharlal Nehru?', 'What are some facts about Rajdeep Sardesai?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How important is college and why?', 'positives': ['How important is higher education?'], 'negatives': ['What is good education?', 'How difficult is an Education major?', 'When we should go for higher education?', 'Why did you go into higher education?', 'Distinguish between education and schooling?', 'What is more important in high school, making friends or having good grades?', 'What are the drawbacks to majoring in education?', 'What should good education be like?', 'What are the pros and cons of a career in education?', 'What are the characteristics of education?', 'Why is education so important when most of the successful people are not highly educated?', 'Is doing an undergraduate program at an elite university more prestigious than getting a graduate degree at the same school?', 'Is education really important in making money?', 'What are the aims and objectives of education?', 'Advanced Diploma vs degree?', 'How can we make education better?', 'What is High Study skills?', 'What is harder: high school or college?', 'What makes your tertiary education more valuable than all the money you could make after high school as a tycoon?', 'Does the college matter for B.Tech when it comes to higher studies or placement?', 'How can we improve the education system for high school and college?', 'Which is preferred, campus placement or higher studies?', 'Is a graduate degree in education worth it? Why?', 'How is money better than education?', \"What's the difference between middle school and high school education?\", 'How the college education help me when the course is 6 years old? Should I focus to get degree or to focus on learning new things (external courses)?', 'What is better school life or college life?', 'What do you think is the most important thing you want to learn in university?', 'What are better forms of an education system?', 'What is an education? In simple, and complex form, what does it mean to be a highly educated person?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Who are those actors who voice for doraemon in hindi?', 'positives': ['Who are the voice actors behind the Doremon and Shinchan cartoons in Hindi?'], 'negatives': ['Whose voice is in the Hindi TV advertisement?', 'Which are famous cartoons in India?', 'Who are the worst actors in Hindi movies?', \"Who is the voice behind Red FM 93.5's Mawali Bhai?\", 'Who playd Bahadur DhahcJafar in Film Lal Quila?', 'Who are the over actors of Bollywood?', 'What are the recent hindi movies?', 'Whose the lyricist of a punjabi folk song “kala doriya” sung by Surinder Kaur and Parkash Kaur?', 'I personally think that actors like Ranbir Kapoor are raising the standards of mainstream Hindi cinema. What is your opinion on that?', 'Who are the most underrated singers of Bollywood?', 'Why are actors popular than singers in India?', 'What are some Telugu/Tamil/Hindi movies in which the leading actor becomes a mafia or don?', 'Why does Bollywood/Indian music director chossing Arijit Singh when we have best voices like Udit Narayan, Kumar Sanu and Sonu Nigam?', 'Who are some Bollywood actors and actresses who are known for over acting?', 'Which are famous dialogues of \"yeh jawani hai deewani\"?', 'Who are the most famous video game voice actors?', 'Which Bollywood actors are underrated?', 'Which are some currently aired famous Hindi TV shows in India?', 'Who are the top comedians of Indian origin?', 'Who are some of your favourite actors?', 'How is the movie Kaththi featuring Vijay and Samantha in the lead and directed by A.R. Murugadoss?', 'Who are the method actors in Indian film industry?', 'Do male actors also go through casting couch in Bollywood?', 'What are the Facts of Bollywood actors?', 'Which are the must-see Hindi movies?', 'Which are some of the best dialogues from Hindi television shows?', 'What are some of the silliest and funniest dialogues in Hindi movies?', 'Who should they cast if they remake Friends in Bollywood?', 'Who are your favourite Marathi actors (male and female)?', 'What Hindi movie song of recent times has the best lyrics?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Mathematics: How do you explain the Stirling number?', 'positives': ['What are Stirling numbers?'], 'negatives': ['What are IBAN numbers?', 'Why the number 1729 is known as the Ramanujan number?', 'How many 6 digit palindrome numbers can be formed?', 'What are quantum numbers?', 'How many 6 digit palindrome numbers can be formed by using digits 1, 2, 3, 4, 5 and 6?', 'What is the Reynolds number?', 'How many 3 digit palindrome numbers can be formed by using digits 1, 2, 3, 4, 5 and 6?', 'What is the unit digit in 1776^1777^1778?', 'How are roll numbers assigned in IIT Madras?', 'What is quantum numbers in short?', 'What is the total number of non-zero digits in 3^1000?', 'What are the names of 11 rudras?', 'What is a quantum number?', 'Why are Eulers number and Pi close to zero and 1?', 'What are quantum numbers and what do they mean?', 'What 4 digit number is divisible by 2, 3, 4, 9, and 10?', 'What is the unit digit of 3^460?', \"Can Nusselt's number be imaginary?\", 'How many 2-digit numbers can be written as the sum of exactly six different powers of 2, including 2^0?', \"What is magnesium's noble gas notation?\", 'How many possible 4 digits numbers can be formed with 1,1,8 and 8?', 'What is the meaning of train number?', 'How was Reynolds number developed?', 'What is a 5 digit number that is divisible by 2,3,4,5,6,8,9, and 10?', \"What is a complex number, in layman's terms?\", 'How many 6 digit numbers are multiples of 10?', 'How many 4 digit numbers can be formed with the digits 0, 1, 3 and 6?', 'How many 5 digit numbers contain at least one 3?', 'How many 4 digit numbers can be formed from 1,2,4,5,7 and 8?', 'What does each digits/numbers/alphabets mean in 20MoCrE4 in alloy steel nomenclature?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I stop being bored?', 'positives': ['How do I stop myself from being bored?'], 'negatives': ['Why do I keep getting bored of people?', 'Why am I getting bored?', 'Why I get bored?', 'Why do I get bored so often?', 'Why am I so easily bored?', 'Why do I usually get bored of people?', 'Why am I bored?', 'Why do I get easily bored with everything?', 'Why do I get bored easily?', 'Why do I get bored when listening to people?', 'Why do I get so bored of people easily?', 'What can someone do when bored in an office?', 'Why do I feel bored with everything and feel pointless for no reason?', 'Why do people get bored?', 'Why do we get bored?', 'Why do I always become bored in relationships?', 'Why do I get bored of anything I do quickly?', 'Why do I get bored so quickly?', 'What should I do when I am bored in class?', 'Why do I get bored with people so quickly?', 'Why do I get bored in my relationships?', 'Why do I get so bored so quickly?', \"What do you do when you're bored in class?\", 'Why do humans become so easily bored?', \"What should you do when you're bored in class?\", 'Why do I easily get bored of my friends?', 'What do you do if you feel bored about your job?', 'Why do I get bored with things so quickly and easily?', 'Why do I yawn when I was bored?', 'Why do people get bored with their lives?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Does ragging exists in Medical colleges?', 'positives': ['How prevalent is ragging in medical colleges?'], 'negatives': ['What is your ragging experience?', 'What is your experience with ragging?', \"What is the level of Ragging in IIT's? With examples?\", 'What are the most competitive medical specialties?', 'Which is more difficult, medical school or getting into medical school?', 'Which colleges have the highest acceptance rate to top-notch medical schools?', 'What is medical mafia in India?', 'How bad is the ragging for non-hostelers in BIT Sindri?', 'What are some of the worst medical colleges in India?', 'Why is medical school so expensive?', 'Do doctors get nostalgic about medical school the same way people get nostalgic about college?', 'Medical School: What are some really cushy psychiatry residencies?', 'What are the best medical schools?', 'Which is the most horrifying thing/disease you have seen in your medical career?', 'Is med school significantly harder than vet school?', 'Which medical specialties are the most cutthroat?', 'What exactly is done in the process of counselling for a medical college?', 'What is the most prestigious medical specialty?', 'Where is the best medical school?', 'How should we study in medical school?', 'How can the hierarchy of doctors at a hospital be explained?', 'How bad is the ragging at BIT Sindri?', 'How do top medical students study?', 'How do top medical students study? ', 'What are some occupational diseases of teachers?', 'Is there any trusted website which rates the medical colleges with quite accuracy?', 'What is the beat treatment of piles and best doctors in India?', 'What things frustrate nursing staff and doctors the most?', 'Is Loma Linda University a good medical school? Why or why not?', 'What are the weirdest things experienced by doctors in their line of duty?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'When will the result of the 2016 US presidential elections be declared?', 'positives': ['When will the results of the 2016 U.S. Presidential elections be declared?'], 'negatives': ['When will the results of the 2012 U.S. Presidential elections be declared?', 'When will the results of the European elections be announced?', 'When an American president dies or has to hand over his functions to the VP, how long after that do the new elections take place? What if the next elections were already planned within that period or shortly after?', 'Will we know the electoral college vote count by December 19, or are the votes sealed and the results not known until January?', \"When will President Barack Obama's second term end? Who are the presidential candidates vying for the presidency?\", 'What do you predict will happen in November 8th? What are the possible outcomes if Donald Trump or HRC become president?', 'When will the president hoist the flag?', 'How do presidential elections work in the US, how do the compare to the presidential elections in France?', 'Who is going to be the first candidate to declare for the 2016 presidential election?', 'What is the aftermath of trump winning the presidential election?', 'When is the New South Wales state election?', 'When is the first 2016 presidential debate?', 'Is there a chance that the faithless electors can change the result of 2016 US presidential election on December 19th 2016?', 'What would be the immediate repercussions of Trump winning the Presidential elections (its inevitable now)?', 'Will you vote (or not) in the 2016 US presidential election? Why?', 'In the unlikely event that the Electoral College throws the vote, how soon will we know?', 'If all US States assigned electoral votes proportionally how different would the US Presidential Election results be?', 'How do presidential elections work in the US, how do the compare to the presidential elections in Uruguay?', 'What would happen if after the US primaries, but before the election, both candidates for president either die or are disqualified for some reason?', 'How do presidential elections work in the US, how do the compare to the presidential elections in Mexico?', 'How can you summarise the 2016 US Presidential elections and the respective candidates to a non-US citizen?', 'How well could third party candidates do in the upcoming (2016) U.S. presidential elections?', 'How bad is the outcome of the US 2016 presidential election for science?', 'When will the US have a woman president?', 'When do we vote for a new congress?', 'What would the 2016 Presidential Election results look like if electoral votes were awarded proportionally?', 'What would happen if a presidential candidate were to die the day or week before an election?', 'Is there any point in doing nationwide polls in the US Presidential race?', 'Are national polls of the US presidential race essentially meaningless? Are there other methods for predicting the winner?', 'Is there a list of the hour polls close in each state (in order) for the 2016 Election?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I get .edu and .gov backlinks?', 'positives': ['What are the best ways to get .edu and .gov backlinks?'], 'negatives': ['Is .edu backlinks still effective?', 'What the best way of getting backlinks for my website?', 'What is the best way to add your websites backlinks in 2014?', 'What is the best way to add your websites backlinks in 2016?', 'Which is the best way for backlinks in 2016?', 'How can I get free backlinks for my website?', 'How do I get do-follow backlinks in 2015?', 'How can I get backlinks quickly?', 'How do I get backlinks to app?', 'How can I get more backlinks to my website?', 'What are the best backlinks site?', 'How can we create backlinks to our website?', 'What are the best ways to build do-follow backlinks in 2016?', 'What are the best backlinks softwares?', 'How do I check backlinks for website?', 'How can I get backlinks from other website to my own website?', 'How can i buy quality of backlinks for my site?', 'How can I get more backlinks to website www.allbestlist.com?', 'What are some best strategies to build backlinks in 2016?', 'How I create backlinks for my website?', 'How could I check backlinks manually without any tool?', 'How do I build good backlinks for my site?', 'How do backlinks work?', 'How can I get backlinks for my website www.everestbasecamptours.com?', 'How can I get backlinks index faster?', 'Backlink analyzing software/site?', 'What is backlink?', 'How we can create natural backlinks?', \"If I send my product to bloggers for review, what's the best way to request backlinks?\", 'How do I get a do-follow backlink from Facebook PR9?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the 7 sins and their punishment?', 'positives': ['What are the 7 sins?'], 'negatives': [\"Why are the Seven Deadly Sins 'deadly'?\", 'Why are there 7 deadly sins and 9 rings of hell?', 'What is the ultimate sin?', 'What is the biggest sin you have ever committed?', 'What is the difference between sins and abominations?', 'Why is pride considered as the deadliest of seven deadly sins?', 'Why do we sin?', 'What is the value of sin(i)?', 'Why do people sin?', 'How can you make a party themed around the Seven Deadly Sins?', 'According to Dante, what are the seven levels of hell?', 'What was the sin of Sodom and Gomorrah?', 'What are the 7 sacraments of the Roman Catholic church? And why?', 'Is lying a sin?', 'Where does sin come from? Do we have sin from birth?', 'What is the value of sin(90)?', 'What do devil worshippers do?', 'According to Dante, what are the 7 layers of hell?', 'Where in the Bible is there 7 noachide laws?', 'What is sin(x)=1?', 'What does it mean when Jesus died for our sins?', 'What is sin according to Christianity and according to Hinduism? How can one get redemption from their sins?', 'Why is sex considered a sin?', 'What is the difference between Sin and Crime?', 'What do devil worshippers believe in?', 'What does the Bible say about masturbation? Is it a sin?', 'Why do people (not all) like in sin?', 'What are the sacraments mentioned in the Bible?', 'Why is sex considered a sin in Christianity?', 'What is SIN time?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Is Pope Francis taking another swipe at Donald Trump on his statement about fake news?', 'positives': ['Is Pope Francis taking a swipe at Trump with his remark on fake news?'], 'negatives': ['Is Pope Francis white?', 'Who is pope francis?', 'Is Pope Francis Catholic?', 'How has Donald Trump reacted to the reports that Russia has compromising information about him?', 'What do non-Catholics think of Pope Francis?', 'Where is Pope Francis from?', 'What is your opinion about Donald Trump refusing to answer a CNN reporter, calling the network \"fake news\"?', 'Can Donald Trump refuse to take any questions from CNN in White house press meetings for the entire duration of his presidency?', 'Is Trump a Russian puppet?', 'Does trump do to church?', 'Why is the \"Pope\" called the Pope?', 'What is the unsubstantiated salacious information that Kremlin has on Trump?', 'Donald Trump: Does Donald Trump have misogynistic views?', 'Do you think Donald Trump insults peoples intelligence with some of the things he says?', 'Why is Trump so angry about news of the \"salacious scandal?\"', 'Is Donald Trump a wakeup call to the state of the U.S.?', 'Why is Spiegel Online having Donald Trump in the headlines and not local news?', 'Why does Trump spend so much time talking about people (media, reporters, etc.) being \"unfair\" with him?', 'What does the Pope do?', 'How is Donald Trump seen in Russia?', 'Did Donald Trump really mock a disabled reporter?', 'Is the widespread condemnation of Trump excessive?', 'Does religious support for Trump seem to be hypocrisy?', 'Is Donald Trump a Russian spy?', 'Is Donald Trump xenophobic?', 'What do the “Anonymous” think of Donald Trump?', 'Is Donald Trump an undercover democrat?', 'Is Donald Trump going to misuse the presidential alerts on smartphones?', 'Is Putin the only public figure that Trump has not criticized?', 'Was Donald Trump right to speak out against the mainstream media in his first press conference?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Can I get arrested for downloading movies from torent in India?', 'positives': ['Is downloading from torrent is still illegal in India?'], 'negatives': ['Is it illegal to download torrents in UAE?', 'μTorrent: How People Are Caught Illegally Downloading Music, Movie Torrents?', 'How do I unblock blocked torrents in India?', 'Is it a punishable offense in Canada and the USA to download movies/music via torrents?', 'Which torrent sites are still working in India?', 'What is the process of downloading Hindi movies from extratorrents without clients in u torrents?', 'What are the best torrent sites available in India as TRAI blocked many torrents here?', 'Why is torrent blocked?', 'Which torrent sites are working in India as of now(September 2016)?', 'Is downloading torrents possible on Reliance Jio?', 'Why torrents are not blocked?', 'Is it safe to download antivirus software from torrent?', 'How do I find if the fake torrent download running in torrent app?', 'How do I download torrents safely and anonymously?', 'With TAMILROCKERS.NET blocked where do I get genuine tamil movie torrents?', 'What are the ways to stream torrents without downloading them completely?', 'Torrent sites have been blocked by my University IT department. How can I access them?', 'How do I bypass torrent blocking?', 'Is streaming on kodi illegal?', 'Why is Torrentz blocked?', \"How come I'm not able to access any torrents online?\", 'How do I torrent on my college network without being detected or getting caught?', 'How do I download content from a kickass torrent?', 'How can I download content from a torrent on a torrent-blocked WiFi?', 'Are there any torrents working in India right now?', 'What is the role of peers, seeds and leaches in torrent download?', 'How do I download torrents on my computer?', 'What are torrent download sites?', 'Why is my torrent client downloading more data than is contained in the file itself?', 'Are there any torrent sites functional to download Bollywood movies as of August 2016 in India?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How can I earn money online or have an online job?', 'positives': ['How can I earn money by doing online jobs?'], 'negatives': ['What are some online jobs that pay well?', 'What are some real online jobs that pay?', 'Is there any real genuine way to earn 5,000 - 10,000 dollars per month working 3-4 hours per day online?', 'Do online jobs pay well?', 'What are ways for an underage person to make money online?', 'How much are you earning online?', 'What are different ways to make online money in India?', 'As a college student, how can I make money online without investing a huge amount of money and time?', 'What are the best ways of making money online by working 1-2 hour daily in India?', 'What are some of the ways to earn money online in India?', 'How can one earn money online in India?', 'What are some different ways to make money online, excluding selling things?', 'I want to earn an extra 200-300 dollars/month via the internet. How can I earn this amount? (I have full time job)', 'Which is the best site for earning money online as a student?', 'How do I do earn money online for free in India?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Who is better for India, Donald Trump or Hillary Clinton? Why?', 'positives': [\"Which Presidency would mean better for Indo-US relationship? Donald Trump's or Hillary Clinton's?\"], 'negatives': ['Would Putin and Russia prefer Donald Trump or Hillary Clinton as the new US president?', 'Who would make a better president, Michelle Obama or Hillary Clinton?', 'Secretary Clinton, as a Middle East resident, why should I prefer that Americans Elect you given your support of the Iraq War and its consequences?', 'Who would make a better president: Michelle Obama or Hillary Clinton?', 'What are the main differences between Trump and Clinton?', 'What are the main policy differences between Trump and Clinton?', \"What is Hillary Clinton's policy towards India-US relations?\", 'Which 2016 US presidential candidate would be best for the economy?', 'What are the differences between Hillary Clinton ’s 2016 presidential campaign and her 2008 presidential campaign?', 'Who is more electable in a general Presidential election: Donald Trump or Ted Cruz?', 'Who was the best U.S. president in terms of their domestic policies?', 'Whom you consider better between Indira Gandhi and Narendra Modi and why?', 'What makes the most difference? A President or a Republican House and Senate?', 'Who is a better negotiator: Vladimir Putin or Donald Trump?', 'Who fits the most as a president of america? Trump or hillary.State the reason for your choice', 'Which one is having better confidence, moral and spirit in a battlefield: government militias or the ISIS? Why do you think so?', 'Who is more favored among moderate Republicans, President Obama or Hillary Clinton?', 'What would Hillary Clinton do to strengthen the USA - India partnership?', 'Was Clinton or John Kerry better as Secretary of State?', 'Do you think Hillary Clinton will make a better president as she is more experienced than all of the other candidates running for president?', 'Which is better, being a Muslim in US or being a Muslim in India? Why?', 'What was the most friendly and amicable presidential election between candidates in American history?', \"Who's best US president ever?\", \"What will be Hillary Clinton's strategy for India if she becomes US President?\", 'Who is safer for the world, Hillary or Donald?', \"Who's the best US president ever?\", 'Who has less \"integrity\", Hillary Clinton or Donald Trump? Why?', 'What are some differences and similarities with ISIS and Boko Haram?', 'Who is/was the better Secretary of State: John Kerry or Hillary Clinton?', 'Will a high voter turnout favor Donald Trump or Hillary Clinton?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Do mermaids still exists?', 'positives': ['Are mermaids actually real?'], 'negatives': ['Why are there no actual mermaids in Octonauts?', 'Why are Mermaids originally female?', 'How would mermaids have sex?', 'Why do even mermaids whine?', 'Are vampires real? If not, where and how did the idea of vampires originate?', 'Are Voodoo Dolls real?', 'Are werewolves and vampires real?', 'Why do mermaids whine?', 'Is anime real?', 'What do mermaids supposedly eat?', 'Do vampires really exist?', 'Did vampires really existed?', 'How would mermaids mate?', 'Is the show \"River Monsters\" real?', 'Are pirates real?', 'Are space pirates real?', 'What is a mermaid?', 'In mythologies, what do mermaids usually eat?', 'Do vampire exist?', 'Are mythical creatures real to you?', 'Do vampires exist?', 'Do witches and vampires exist?', 'Have any one ever seen mermaid?', 'Are Brahmins real?', 'Are demons and angels real?', 'Is anything real?', 'How real are reality shows?', 'What if Pokémon were real?', 'How real are the Psychics?', 'Were dinosaurs real?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': \"What is the most hilarious thing you've ever seen or heard about?\", 'positives': ['What is the most hilarious thing you have ever experienced?'], 'negatives': ['What was your most hilarious sexual experience?', 'What is the most mischievous thing you have ever done?', 'What is the most shocking thing you’ve ever experienced?', 'What is the most amazing thing you ever did?', 'What is the funniest thing you have ever seen someone do?', 'What are the most mischievous things you have ever done in your life?', 'Can you describe the most hilarious and/or (not-so-hilarious) sexual experience with your significant other?', 'What is the most amazing thing you have ever seen?', 'What is the most crazy memorable thing that you have ever done in your life?', 'What is the most amazing thing that you have ever seen?', 'What is the most embarrassing yet funniest moment of your life?', 'What is the most interesting/amazing thing that you almost witnessed?', 'What is the most interesting thing you have ever done?', 'What are the most hilarious movies?', 'What kinds of things really make you laugh?', 'What kinds of things really make you laugh? Why?', 'What is the most crazy thing you have done?', 'What are some of the strangest/funniest inside jokes you have with someone else?', 'What is the funniest thing you have ever done high?', 'What is the most shocking thing you have ever seen?', \"What's the funniest thing that you have ever done to someone?\", 'What is the most crazy thing that you have done?', \"What's the most embarrassing thing that has ever happened to you, or the most embarrassing thing that you have seen?\", 'What is most entertaining?', 'What are some of the most hilarious books ever written?', \"What's the funniest thing you have ever done to someone?\", \"What's the most hilarious interview question you've ever been asked?\", \"What is the most disgusting thing you've ever done?\", \"What's the craziest thing you've ever done?\", 'Can everything be funny?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Is it the right time to invest in real estate?', 'positives': ['What is the best time to invest in real estate?'], 'negatives': ['What is the best time to invest in real estate market after demonetisation?', 'Is it the right time to invest in real estate in Pune?', 'Is now a good time to invest in the California real estate market?', 'Is now a good time to invest in real estate in Greece?', 'Is real estate a good investment for 2014?', 'Is now a good time to invest in the NYC real estate market?', 'Is it a good time to buy real estate in Greece?', 'Is it a good time to buy real estate in Spain? Why?', 'Is real estate a good investment?', 'Is now a good time to invest in the French real estate market?', 'Real estate investing: I have $20k, where should I start?', 'Is it a good time to buy real estate in chile?', 'Is now a good time to invest in the Melbourne real estate market?', 'What is the average day of a real estate investor?', 'What is the best way to make money investing in real estate?', 'What is the best time to invest in the share market?', 'What is best place for real estate in India?', 'What is the future of real estate in India?', 'Should I sell my real estate investments now or later?', 'Is it a good time to buy real estate in Cyprus?', 'Is now a good time to invest in the Sydney real estate market?', 'Where are good places in the U.S to invest in real estate?', 'How do I make a million in real estate before 25?', 'How do we make money by investing in real estate?', 'Is it a good time to sell property when interest rates are low?', 'Which is good time to invest in share market?', 'What are the best real estate books?', 'Should I become a real estate agent if I want to learn more about real estate investing?', 'What are the best books on real estate investing?', 'Is it right time to invest in mutual fund?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'What are the secrets of happy life?', 'positives': [\"What's the bloody secret of a happy life?\"], 'negatives': ['What is the biggest secret of your life?', 'How does it feel to live with a secret throughout your life?', \"What are the best examples of 'The Secret' in your life?\", \"What's the secret to Secret's success?\", \"What's one secret that you will take to your grave?\", 'What is your dirty secret?', 'What is your deepest secret ever?', 'What is the one secret that you carry to your grave?', 'What is your dirty little secret?', \"What 's the biggest secret?\", 'What are the dirty little secrets?', \"What's your secret to success?\", 'What is your deepest secrets?', 'What is the biggest secret?', 'What is your deepest secret, that nobody knows?', 'What is the secret to success?', 'What are secrets behind successful people?', 'What is/was the most promising blessing-in-disguise happening/experience in your life?', 'What is your most hidden and deepest secret that you want to share?', 'How secret is Secret?', 'What are all the secrets of secret societies?', 'Secrets: What is that one secret that you can never share with anyone?', 'What is the most intriguing secret the world has ever witnessed?', 'What are some (positive) surprises you had in life?', 'Is The Secret real?', 'What is the harsh truth of life that nobody can digest?', 'What are the world’s most hidden secrets?', 'What were the positive, unexpected surprises in your life?', 'What is the secret society?', 'What is the biggest secret you have been told?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How is demonetization affecting people of India?', 'positives': ['How is demonetization helping India?'], 'negatives': ['What is the genuine benefit of demonetization?', 'What are the effects of demonetization?', 'Can someone list the advantages and disadvantages of demonetization?', 'What are the effects of demonetization? Is it really successful?', 'How successful is demonetization?', 'What are the positive effects of demonetization?', 'What are the effects of demonetization in Kerala?', \"Demonetization what does it mean to India's Poor?\", 'Why do other political parties of India oppose demonetization?', 'What do other countries think about India demonetization?', 'What will be the effect of demonetization?', \"Will India's demonetization policy discourage FDI from flowing into India?\", 'What is demonetisation?', 'Why is demonetization?', 'How demonetisation affected Samajwadi party?', 'What will be the short term effect of demonetization?', 'What is demonetization in America?', \"Did India's GDP fall because of demonetization?\", 'Is demonetization a failure?', 'When did demonetization occur in India?', 'What have we gained from demonetization?', 'What are the advantages of demonetisation?', 'What is the long term implications of demonetization?', 'How do you look demonetization? Was it necessary?', 'Will the demonetization succeed?', 'What is the role of RBI in demonetisation?', 'Is Demonetisation a failed initiative?', 'What will the long term effects of demonetization? Will it be able to curb corruption and terrorism?', 'Was Demonetization even necessary?', 'What are pros and cons of recent Demonetization? What is the possible long term scenario of India economy after demonetization?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Which are the best field in engineering?', 'positives': ['What is the best field of engineering?'], 'negatives': [\"Engineering: What's the most exciting engineering field?\", 'Which is the best field for masters in mechanical engineering?', 'What field of engineering is the most difficult, and why?', 'What are the best engineering website?', 'What is the best engineering major for the future?', 'What is the best engineering field to get a PhD in?', \"What is the best field in mechanical engineering after completing a Bachelor's of Engineering?\", 'Is engineering the toughest field?', 'Why is electrical the best branch of engineering?', 'What are the best fields to pursue masters in mechanical engineering?', 'What is best subject in it among engineering science, electrical engineering and mechanical engineering?', 'I am a triple major (Chinese/Korean/General Engineering). If I wanted to make use of all my majors, what is the best engineering field to move into?', 'Which is the best job field in mechanical engineering? Which one has a good growth opportunity?', 'Which is the best area in research in the field of mechanical engineering?', 'Which field is better for a mechanical engineer, production, quality or design?', 'Which are the best field in civil engineering in USA?', 'What is the present best branch of engineering in India?', 'What are the best electrical engineering softwares?', 'What are best electrical engineering softwares?', 'Why mechanical engineering is the best engineering career?', 'Which stream in MBA is best for a mechanical engineer?', 'What are good research topics on engineering project?', 'Suggest the best one: Masters of electrical engineering(RMIT) or masters of engineering management MBA(UTS)?', 'Already a Management Sciences major. Now want to do engineering. Which engineering field most suits management sciences: Electrical or Mechanical?', 'What is the one core essence of engineering?', 'Which MBA stream is best for a Mechanical Engineer ?', 'What are the best courses for the electrical engineering?', 'Which branch of engineering will have a good scope in future?', 'Which are the best consultancy fields other than software (cad/Ansys etc) in mechanical engineering?', 'Which engineering stream has the most scope?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How do I learn the stock market?', 'positives': ['What are the ways to learn about stock market?'], 'negatives': ['Where can I learn stock marketing?', 'What is the best book for learning about the stock market?', \"I'm a teenager wanting to learn more on stocks and its fundamentals. What are some important rules to follow while in the search for a good stock and how long should you hold on to it?\", 'What is the stock market?', 'What is the stock market?', 'What is the biggest lesson you have learned as a stock investor?', 'How does the stock market work? And how do I make money off of it?', 'What is a stock market?', 'I want to learn about stocks, but I know nothing about them. What are the best books for beginners?', 'How do you lose money in the stock market?', 'How do I get started in the stock market as a teen?', 'Can you create a nice story that explains how stock market works?', 'What are the secrets to making money in the stock market?', 'What is the most realistic available stock market simulator?', 'How can I become a stock trader?', 'What are stock related sites that give very good info?', 'What are the best stock market app?', 'How much time to be a stock market expert like the ones who give guidance on TV?', 'How did you lose money in the stock market?', 'How do I earn money from the stock market?', 'Where do I buy stock?', \"What's a good stock market app?\", 'What is stock marketing?', 'First time stock purchaser...Any recommendations for a college student trying to make some money on the side? And how do you go about buying/selling stocks?', 'How can I start buying/selling stocks (consider a minor)? Also, what are the places/websites?', 'What is your story of losing a lot of money in stock market?', 'How do you analyse a stock before you buy it for short term?', 'How do I go about shortlisting stocks?', 'How do I buy stock?'], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'How much sleep should adults have in 24 hours ideally?', 'positives': ['How much deep sleep one need?'], 'negatives': ['How many hours do you sleep per night?', 'How can you max out REM sleep?', 'How many hours of sleep does a kid need?', 'Is 6 hours enough sleep?', 'How much should I sleep as a teenager?', \"What's the ideal ratio of light, deep, and REM sleep?\", 'How important is sleep?', 'What are some tips for making the most of your Sleep No More experience?', 'How many hours do you sleep (day & night) per day?', 'Why do we need eight hours of sleep?', 'How many hours do successful people sleep per day?', 'Why does your body need 8 hours of sleep?', 'How many hour students sleep?', 'For how many hours do successful people sleep?', 'Is a Sleep Number bed worth the cost?', 'How many calories do I burn while sleeping?', 'How do you sleep 7 hours a day?', 'Is sleep important?', 'How do I avoid sleep so much?', 'How can I lose weight in my sleep?', 'How many hours of focused, detailed work can a person reasonably do in a 24-hour period, before needing sleep?', \"What's the best way to get sleep?\", 'Is 6 hours of sleep enough for a 17 year old?', 'Is it healthy to sleep for 12 hours a day? Why or why not?', 'How do I sleep 7 hours a day?', 'Do people who need less sleep get a higher percentage of REM or slow-wave sleep?', 'How do I have a good sleepover?', 'How do I sleep 5 hours a day?', 'How can I reduce my sleep?', \"What is the best way to get a good night's sleep?\"], 'type': 'sts_triplet', 'source_id': 5}\n",
            "{'query': 'Will reading habit influence your life? Many say yes. Reading graph based natural language processing and information retrieval is a good habit; you can develop this habit to be such interesting way. Yeah, reading habit will not only make you have any favourite activity. It will be one of guidance of your life. When reading has become a habit, you will not make it as disturbing activities or as boring activity. You can gain many benefits and importances of reading.', 'positives': ['This paper describes new methods of automatically extracting documents for screening purposes, i.e. the computer selection of sentences having the greatest potential for conveying to the reader the substance of the document. While previous work has focused on one component of sentence significance, namely, the presence of high-frequency content words (key words), the methods described here also treat three additional components: pragmatic words (cue words); title and heading words; and structural indicators (sentence location).\\nThe research has resulted in an operating system and a research methodology. The extracting system is parameterized to control and vary the influence of the above four components. The research methodology includes procedures for the compilation of the required dictionaries, the setting of the control parameters, and the comparative evaluation of the automatic extracts with manually produced extracts. The results indicate that the three newly proposed components dominate the frequency component in the production of better extracts.'], 'negatives': ['We present a routability-driven bottom-up clustering technique for area and power reduction in clustered FPGAs. This technique uses a cell connectivity metric to identify seeds for efficient clustering. Effective seed selection, coupled with an interconnect-resource aware clustering and placement, can have a favorable impact on circuit routability. It leads to better device utilization, savings in area, and reduction in power consumption. Routing area reduction of 35% is achieved over previously published results. Power dissipation simulations using a buffered pass-transistor-based FPGA interconnect model are presented. They show that our clustering technique can reduce the overall device power dissipation by an average of 13%.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Educational data mining is the process of applying data mining tools and techniques to analyze data at educational institutions. In this paper, educational data mining was used to predict enrollment of students in Science, Technology, Engineering and Mathematics (STEM) courses in higher educational institutions. The study examined the extent to which individual, sociodemographic and school-level contextual factors help in pre-identifying successful and unsuccessful students in enrollment in STEM disciplines in Higher Education Institutions in Kenya. The Cross Industry Standard Process for Data Mining framework was applied to a dataset drawn from the first, second and third year undergraduate female students enrolled in STEM disciplines in one University in Kenya to model student enrollment. Feature selection was used to rank the predictor variables by their importance for further analysis. Various predictive algorithms were evaluated in predicting enrollment of students in STEM courses. Empirical results showed the following: (i) the most important factors separating successful from unsuccessful students are: High School final grade, teacher inspiration, career flexibility, pre-university awareness and mathematics grade. (ii) among classification algorithms for prediction, decision tree (CART) was the most successful classifier with an overall percentage of correct classification of 85.2%. This paper showcases the importance of Prediction and Classification based data mining algorithms in the field of education and also presents some promising future lines.', 'positives': ['Many companies like credit card, insurance, bank, retail industry require direct marketing. Data mining can help those institutes to set marketing goal. Data mining techniques have good prospects in their target audiences and improve the likelihood of response. In this work we have investigated two data mining techniques: the Naïve Bayes and the C4.5 decision tree algorithms. The goal of this work is to predict whether a client will subscribe a term deposit. We also made comparative study of performance of those two algorithms. Publicly available UCI data is used to train and test the performance of the algorithms. Besides, we extract actionable knowledge from decision tree that focuses to take interesting and important decision in business area.'], 'negatives': ['Bitcoin provides two incentives for miners: block rewards and transaction fees. The former accounts for the vast majority of miner revenues at the beginning of the system, but it is expected to transition to the latter as the block rewards dwindle. There has been an implicit belief that whether miners are paid by block rewards or transaction fees does not affect the security of the block chain.\\n We show that this is not the case. Our key insight is that with only transaction fees, the variance of the block reward is very high due to the exponentially distributed block arrival time, and it becomes attractive to fork a \"wealthy\" block to \"steal\" the rewards therein. We show that this results in an equilibrium with undesirable properties for Bitcoin\\'s security and performance, and even non-equilibria in some circumstances. We also revisit selfish mining and show that it can be made profitable for a miner with an arbitrarily low hash power share, and who is arbitrarily poorly connected within the network. Our results are derived from theoretical analysis and confirmed by a new Bitcoin mining simulator that may be of independent interest.\\n We discuss the troubling implications of our results for Bitcoin\\'s future security and draw lessons for the design of new cryptocurrencies.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'OBJECTIVE\\nFood choices are often made mindlessly, when individuals are not able or willing to exert self-control. Under low self-control, individuals have difficulties to resist palatable but unhealthy food products. In contrast to previous research aiming to foster healthy choices by promoting high self-control, this study exploits situations of low self-control, by strategically using the tendency under these conditions to rely on heuristics (simple decision rules) as quick guides to action. More specifically, the authors associated healthy food products with the social proof heuristic (i.e., normative cues that convey majority endorsement for those products).\\n\\n\\nMETHOD\\nOne hundred seventy-seven students (119 men), with an average age of 20.47 years (SD = 2.25) participated in the experiment. This study used a 2 (low vs. high self-control) × 2 (social proof vs. no heuristic) × 2 (trade-off vs. control choice) design, with the latter as within-subjects factor. The dependent variable was the number of healthy food choices in a food-choice task.\\n\\n\\nRESULTS\\nIn line with previous studies, people made fewer healthy food choices under low self-control. However, this negative effect of low self-control on food choice was reversed when the healthy option was associated with the social proof heuristic. In that case, people made more healthy choices under conditions of low self-control.\\n\\n\\nCONCLUSION\\nLow self-control may be even more beneficial for healthy food choices than high self-control in the presence of a heuristic. Exploiting situations of low self-control is a new and promising method to promote health on impulse.', 'positives': ['The authors review evidence that self-control may consume a limited resource. Exerting self-control may consume self-control strength, reducing the amount of strength available for subsequent self-control efforts. Coping with stress, regulating negative affect, and resisting temptations require self-control, and after such self-control efforts, subsequent attempts at self-control are more likely to fail. Continuous self-control efforts, such as vigilance, also degrade over time. These decrements in self-control are probably not due to negative moods or learned helplessness produced by the initial self-control attempt. These decrements appear to be specific to behaviors that involve self-control; behaviors that do not require self-control neither consume nor require self-control strength. It is concluded that the executive component of the self--in particular, inhibition--relies on a limited, consumable resource.'], 'negatives': ['Currently, the smartphone has become an essential communication and amusement tool, which has strong computing power and a variety of functions. Especially, the market share of smartphone with android system account for 84% in 2016[1]. Under android system, a large of privacy data (e.g. photos or videos) are stored in external storage (emulated Sdcard storage), which can be accessed by installed apps. This not only results in privacy leakage but also incurs ransomware attack[2] (e.g. simplocker). Therefore, we present Sdguard, an app, can implement fine-grain permission control based on Linux DAC mechanism and detect ransomware which encrypts content of file stored in external storage or lock user screen. To install Sdguard app, we need to ensure that the smartphone has been rooted and use FUSE filesystem on external storage. During installing, sdcard daemon of android (i.e. FUSE daemon) is replaced by our customized sdcard daemon. After rebooting system, the customized daemon is loaded, and each component of Sdguard is running.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The options framework provides a method for reinforcement learning agents to build new high-level skills. However, since options are usually learned in the same state space as the problem the agent is currently solving, they cannot be ported to other similar tasks that have different state spaces. We introduce the notion of learning options in agent-space, the portion of the agent’s sensation that is present and retains the same semantics across successive problem instances, rather than in problem-space. Agent-space options can be reused in later tasks that share the same agent-space but are sufficiently distinct to require different problem-spaces. We present experimental results that demonstrate the use of agent-space options in building reusable skills.', 'positives': ['ion in reinforcement learning. Artificial Intelligence, 112 (1-2):181–211. Sutton, R. S., Singh, S. P., McAllester, D. A. (2000). Comparing policy-gradient algorithms. Unpublished manuscript. Sutton, R. S., Szepesvári, Cs., Geramifard, A., Bowling, M., (2008). Dyna-style planning with linear function approximation and prioritized sweeping. In Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence, pp. 528–536. Szepesvári, Cs. (2010). Algorithms for reinforcement learning. In Synthesis Lectures on Artificial Intelligence and Machine Learning, 4(1):1–103. Morgan and Claypool. Szita, I. (2012). Reinforcement learning in games. In M. Wiering and M. van Otterlo (Eds.), Reinforcement Learning: State-of-the-Art, pp. 539–577. Springer-Verlag Berlin Heidelberg. Tadepalli, P., Ok, D. (1994). H-learning: A reinforcement learning method to optimize undiscounted average reward. Technical Report 94-30-01. Oregon State University, Computer Science Department, Corvallis. Tadepalli, P., Ok, D. (1996). Scaling up average reward reinforcement learning by approximating the domain models and the value function. In Proceedings of the 13th International Conference on Machine Learning (ICML 1996), pp. 471–479. Takahashi, Y., Schoenbaum, G., and Niv, Y. (2008). Silencing the critics: Understanding the effects of cocaine sensitization on dorsolateral and ventral striatum in the context of an actor/critic model. Frontiers in Neuroscience, 2(1):86–99. Tambe, M., Newell, A., Rosenbloom, P. S. (1990). The problem of expensive chunks and its solution by restricting expressiveness. Machine Learning, 5 (3):299–348. Tan, M. (1991). Learning a cost-sensitive internal representation for reinforcement learning. In L. A. Birnbaum and G. C. Collins (Eds.), Proceedings of the 8th International Workshop on Machine Learning, pp. 358–362. Morgan Kaufmann. Taylor, G., Parr, R. (2009). Kernelized value function approximation for reinforcement learning. In Proceedings of the 26th International Conference on Machine Learning (ICML 2009), pp. 1017–1024. ACM, New York. Taylor, M. E., Stone, P. (2009). Transfer learning for reinforcement learning domains: A survey. Journal of Machine Learning Research, 10 :1633–1685. Tesauro, G. (1986). Simple neural models of classical conditioning. Biological Cybernetics, 55(2-3):187–200. Tesauro, G. (1992). Practical issues in temporal difference learning. Machine Learning, 8(3-4):257–277. Tesauro, G. (1994). TD-Gammon, a self-teaching backgammon program, achieves master-level play. Neural Computation, 6(2):215–219. Tesauro, G. (1995). Temporal difference learning and TD-Gammon. Communications of the ACM, 38(3):58–68. Tesauro, G. (2002). Programming backgammon using self-teaching neural nets. Artificial Intelligence, 134(12):181–199. Tesauro, G., Galperin, G. R. (1997). On-line policy improvement using Monte-Carlo search. In Advances in Neural Information Processing Systems 9 (NIPS 1996), pp. 1068–1074. MIT Press, Cambridge, MA. Tesauro, G., Gondek, D. C., Lechner, J., Fan, J., Prager, J. M. (2012). Simulation, learning, and optimization techniques in Watson’s game strategies. IBM Journal of Research and Development, 56(3-4):16–1–16–11. Tesauro, G., Gondek, D. C., Lenchner, J., Fan, J., Prager, J. M. (2013). Analysis of Watson’s strategies for playing Jeopardy! Journal of Artificial Intelligence Research, 47:205–251. Tham, C. K. (1994). Modular On-Line Function Approximation for Scaling up Reinforcement Learning. Ph.D. thesis, University of Cambridge. Thathachar, M. A. L., Sastry, P. S. (1985). A new approach to the design of reinforcement schemes for learning automata. IEEE Transactions on Systems, Man, and Cybernetics, 15(1):168–175. Thathachar, M., Sastry, P. S. (2002). Varieties of learning automata: an overview. IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 36(6):711–722. Thathachar, M., Sastry, P. S. (2011). Networks of Learning Automata: Techniques for Online Stochastic Optimization. Springer Science & Business Media. Theocharous, G., Thomas, P. S., Ghavamzadeh, M. (2015). Personalized ad recommendation for life-time value'], 'negatives': ['Several standard text-categorization techniques were applied to the problem of automated essay grading. Bayesian independence classifiers and knearest-neighbor classifiers were trained to assign scores to manually-graded essays. These scores were combined with several other summary text measures using linear regression. The classifiers and regression equations were then applied to a new set of essays. The classifiers worked very well. The agreement between the automated grader and the final manual grade was as good as the agreement between human graders.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'OBJECTIVE\\nMissing data is a ubiquitous problem. It is especially challenging in medical settings because many streams of measurements are collected at different - and often irregular - times. Accurate estimation of those missing measurements is critical for many reasons, including diagnosis, prognosis and treatment. Existing methods address this estimation problem by interpolating within data streams or imputing across data streams (both of which ignore important information) or ignoring the temporal aspect of the data and imposing strong assumptions about the nature of the data-generating process and/or the pattern of missing data (both of which are especially problematic for medical data). We propose a new approach, based on a novel deep learning architecture that we call a Multi-directional Recurrent Neural Network (M-RNN) that interpolates within data streams and imputes across data streams. We demonstrate the power of our approach by applying it to five real-world medical datasets. We show that it provides dramatically improved estimation of missing measurements in comparison to 11 state-of-the-art benchmarks (including Spline and Cubic Interpolations, MICE, MissForest, matrix completion and several RNN methods); typical improvements in Root Mean Square Error are between 35% - 50%. Additional experiments based on the same five datasets demonstrate that the improvements provided by our method are extremely robust.', 'positives': ['Leveraging large historical data in electronic health record (EHR), we developed Doctor AI, a generic predictive model that covers observed medical conditions and medication uses. Doctor AI is a temporal model using recurrent neural networks (RNN) and was developed and applied to longitudinal time stamped EHR data from 260K patients over 8 years. Encounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to RNN to predict (all) the diagnosis and medication categories for a subsequent visit. Doctor AI assesses the history of patients to make multilabel predictions (one label for each diagnosis or medication category). Based on separate blind test set evaluation, Doctor AI can perform differential diagnosis with up to 79% recall@30, significantly higher than several baselines. Moreover, we demonstrate great generalizability of Doctor AI by adapting the resulting models from one institution to another without losing substantial accuracy.'], 'negatives': ['Transcranial magnetic stimulation (TMS) is a non-invasive tool for the electrical stimulation of neural tissue, including cerebral cortex, spinal roots, and cranial and peripheral nerves. TMS can be applied as single pulses of stimulation, pairs of stimuli separated by variable intervals to the same or different brain areas, or as trains of repetitive stimuli at various frequencies. Single stimuli can depolarise neurons and evoke measurable effects. Trains of stimuli (repetitive TMS) can modify excitability of the cerebral cortex at the stimulated site and also at remote areas along functional anatomical connections. TMS might provide novel insights into the pathophysiology of the neural circuitry underlying neurological and psychiatric disorders, be developed into clinically useful diagnostic and prognostic tests, and have therapeutic uses in various diseases. This potential is supported by the available studies, but more work is needed to establish the role of TMS in clinical neurology.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Sentinel-1A (S1-A) is the first of a pair of satellites operating a C-band Synthetic Aperture Radar (SAR) developed to give continuity to the European SAR programme. After 6 months commissioning phase from its lunch on April 3rd 2014, S1-A started to systematically deliver data to Copernicus Ocean, Land and Emergency services. Interferometric Wide Swath (IWS) mode in dual-polarization VV+VH is the standard acquisition mode used for the observation of the European marine environment. The objectives of this study are the comparison and synergetic use of the S1-A imagery in IWS mode with TerraSAR-X (TS-X) imagery in StripMap mode for SAR ship detection application. Exemplary dataset acquired over the English Channel during a controlled experiment is used to pursue the objective. Automatic Identification System ships messages received by terrestrial stations in the area are used as ground truth and to identify the SAR detections.', 'positives': ['The Sentinel-1A is the first of two satellites that composes the Sentinel-1 radar mission. Both satellites operate a C-band synthetic aperture radar (SAR) system to give continuity to the European SAR program. SAR is a flexible sensor able to fulfil users/applications requirements in terms of resolution and coverage thanks to different operational modes and polarizations. With the in-orbit availability of very-high-resolution X-band SAR sensors, the Sentinel-1 satellites have been designed to achieve wide coverage at medium to high resolution. The interferometric wide swath (IWS) mode implemented with the terrain observation with progressive scan (TOPS) technique is the standard acquisition mode over European waters and land masses. IWS in dual-polarization (VV/VH) combination offers 250-km swath at 5 m × 20 m (range × azimuth) spatial resolution. These specifications are in line with the needs of the European Maritime and Security Agency (EMSA) for oil spill and ship detection applications included in the CleanSeaNet program. The main goals of this paper are: assessment of medium-to-high-resolution C-band Sentinel-1 data with very-high-resolution X-band TerraSAR-X data for maritime targets detection; synergetic use of multiplatforms satellite SAR data for target features extraction; evaluation of polarimetric target detectors for the available co-polarization and cross-polarization Sentinel-1A IWS VV/VH products. The objectives are achieved by means of real, almost coincident C-band and X-band SAR data acquired by Sentinel-1A and TerraSAR-X satellites over Gulf of Naples and Catania (South Italy). Furthermore, the obtained results are supported by recorded ground truth vessel reports via terrestrial automatic identification system (AIS) stations located in the area.'], 'negatives': ['Intrinsically motivated spontaneous exploration is a key enabler of autonomous lifelong learning in human children. It allows them to discover and acquire large repertoires of skills through self-generation, self-selection, self-ordering and self-experimentation of learning goals. We present the unsupervised multi-goal reinforcement learning formal framework as well as an algorithmic approach called intrinsically motivated goal exploration processes (IMGEP) to enable similar properties of autonomous learning in machines. The IMGEP algorithmic architecture relies on several principles: 1) self-generation of goals as parameterized reinforcement learning problems; 2) selection of goals based on intrinsic rewards; 3) exploration with parameterized time-bounded policies and fast incremental goal-parameterized policy search; 4) systematic reuse of information acquired when targeting a goal for improving other goals. We present a particularly efficient form of IMGEP that uses a modular representation of goal spaces as well as intrinsic rewards based on learning progress. We show how IMGEPs automatically generate a learning curriculum within an experimental setup where a real humanoid robot can explore multiple spaces of goals with several hundred continuous dimensions. While no particular target goal is provided to the system beforehand, this curriculum allows the discovery of skills of increasing complexity, that act as stepping stone for learning more complex skills (like nested tool use). We show that learning several spaces of diverse problems can be more efficient for learning complex skills than only trying to directly learn these complex skills. We illustrate the computational efficiency of IMGEPs as these robotic experiments use a simple memory-based low-level policy representations and search algorithm, enabling the whole system to learn online and incrementally on a Raspberry Pi 3.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Small object detection (SOD) in crowded scenes is a challenging task since objects are densely distributed and partially overlapped. In this paper, we propose a novel SOD method by fully exploring the information provided by the image and its estimated density map. Our proposed SOD method consists of two main stages. Initial object locations are firstly computed based on object spatial distribution information obtained from the estimated density maps. Inspired by the human visual attention mechanism, a saliency map which offers object boundaries is then employed to accurately estimate the bounding boxes with the support of the estimated initial object locations. Experimental results on three public small object datasets and a self-built snipe dataset demonstrate the effectiveness of our proposed SOD method, especially under small training set condition. It is encouraged to see that our SOD method only requires the dotted annotation training datasets and is able to estimate the bounding boxes fitting the shape of the objects accurately.', 'positives': ['This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers[6]. The third contribution is a method for combining increasingly more complex classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.'], 'negatives': ['The Internet of Things (IoT) has recently received considerable interest from both academia and industry that are working on technologies to develop the future Internet. It is a joint and complex discipline that requires synergetic efforts from several communities such as telecommunication industry, device manufacturers, semantic Web, and informatics and engineering. Much of the IoT initiative is supported by the capabilities of manufacturing low-cost and energy-efficient hardware for devices with communication capacities, the maturity of wireless sensor network technologies, and the interests in integrating the physical and cyber worlds. However, the heterogeneity of the “Things” makes interoperability among them a challenging problem, which prevents generic solutions from being adopted on a global scale. Furthermore, the volume, velocity and volatility of the IoT data impose significant challenges to existing information systems. Semantic technologies based on machine-interpretable representation formalism have shown promise for describing objects, sharing and integrating information, and inferring new knowledge together with other intelligent processing techniques. However, the dynamic and resource-constrained nature of the IoT requires special design considerations to be taken into account to effectively apply the semantic technologies on the real world data. In this article the authors review some of the recent developments on applying the semantic technologies to IoT. Overview Article DOI: 10.4018/jswis.2012010101 2 International Journal on Semantic Web and Information Systems, 8(1), 1-21, January-March 2012 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. academia, industry, and standardization bodies in several communities such as telecommunication, semantic Web, and informatics. For example, we have seen that new protocols and standards for low-level device communications in resource-constrained environments have been developed (Bormann, Castellani, & Shelby 2012). While for many years legacy systems have been primarily designed for specific purposes with limited flexibility, the current initiative on building the IoT (or more general, the future Internet) demands application and service platforms which can capture, communicate, store, access and share data from the physical world. This will create new opportunities in a long list of domains such as e-health, retail, green energy, manufacturing, smart cities/houses and also personalized enduser applications. A primary goal of interconnecting devices (e.g., sensors) and collecting/processing data from them is to create situation awareness and enable applications, machines, and human users to better understand their surrounding environments. The understanding of a situation, or context, potentially enables services and applications to make intelligent decisions and to respond to the dynamics of their environments. Data collected by different sensors and devices is usually multi-modal (temperature, light, sound, video, etc.) and diverse in nature (quality of data can vary with different devices through time and it is mostly location and time dependent). The diversity, volatility, and ubiquity make the task of processing, integrating, and interpreting the real world data a challenging task. The volume of data on the Internet and the Web has already been overwhelming and is still growing at stunning pace: everyday around 2.5 quintillion bytes of data is created and it is estimated that 90% of the data today was generated in the past two years (IBM, 2012). Sensory data (including the citizen sensors) (Sheth, 2009a) related to different events and occurrences can be analyzed and turned into actionable knowledge to give us better understanding about our physical world and to create more value-added products and services, for example, readings from meters can be used to better predict and balance power consumption in smart grids; analyzing combination of traffic, pollution, weather and congestion sensory data records can provide better traffic and city management; monitoring and processing sensory devices attached to patients or elderly can provide better remote healthcare. This data transformation process can be better illustrated using the well known “knowledge hierarchy” (Rowley, 2007). We adapt the meanings of the layers to the context of IoT and semantics (Figure 1). The lower layer refers to large amount of data produced by the IoT resources and devices. The layer helps create structured and machine-readable information from the raw data of various forms to enhance interoperability. However, what is required by humans and high-level applications and services often is not the information, but high-level abstractions and perceptions that provide human and machineunderstandable meanings and insights of the underlying data. The high-level abstractions and perceptions then can be transformed to actionable intelligence (wisdom) with domain and background knowledge to exploit the full potential of IoT and create end-to-end solutions. The “big data” solutions and cloud platforms can provide infrastructure and tools for handling, processing and analyzing deluge of the IoT data. However, we still need efficient methods and solutions that can structure, annotate, share and make sense of the IoT data and facilitate transforming it to actionable knowledge and intelligence in different application domains. Since many of the devices and resources in IoT are highly distributed, heterogeneous, and resource-constrained (e.g., battery powered devices, nodes with limited processing and memory capabilities), the requirements for designing services and applications in IoT are different from those currently used on the Internet and the Web (specifically in terms of interoperability, scalability, reliability, autonomy, security and privacy). This is reflected in the recent architecture design and development efforts for the Future Internet and Web (Zorzi et al., 2010). 19 more pages are available in the full version of this document, which may be purchased using the \"Add to Cart\" button on the product\\'s webpage: www.igi-global.com/article/semantics-internetthings/70584?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSci-Computer Systems and Software Engineering eJournal Collection, InfoSci-Networking, Mobile Applications, and Web Technologies eJournal Collection, InfoSci-Journal Disciplines Engineering, Natural, and Physical Science, InfoSci-Select. Recommend this product to'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this letter, we propose a cross-view down/up-sampling (CDU) method for the framework of reduced resolution multiview depth video coding, which exploits cross-view information to assist the up-sampling at the decoder. In the down-sampling procedure of CDU, the odd-even interlaced extraction is employed to preserve more confident information of the original depth video with reduced resolution. In the decoder, the cross-view information is exploited for up-sampling the reconstructed depth video. An iterative interpolation process is proposed to eliminate the effect of compression distortion on this up-sampling. Experimental results demonstrate the gains of up to 3.88 dB for the proposed algorithm and better quality of synthesized views.', 'positives': ['Recently, extensive research efforts have been dedicated to view-based methods for 3-D object retrieval due to the highly discriminative property of multiviews for 3-D object representation. However, most of state-of-the-art approaches highly depend on their own camera array settings for capturing views of 3-D objects. In order to move toward a general framework for 3-D object retrieval without the limitation of camera array restriction, a camera constraint-free view-based (CCFV) 3-D object retrieval algorithm is proposed in this paper. In this framework, each object is represented by a free set of views, which means that these views can be captured from any direction without camera constraint. For each query object, we first cluster all query views to generate the view clusters, which are then used to build the query models. For a more accurate 3-D object comparison, a positive matching model and a negative matching model are individually trained using positive and negative matched samples, respectively. The CCFV model is generated on the basis of the query Gaussian models by combining the positive matching model and the negative matching model. The CCFV removes the constraint of static camera array settings for view capturing and can be applied to any view-based 3-D object database. We conduct experiments on the National Taiwan University 3-D model database and the ETH 3-D object database. Experimental results show that the proposed scheme can achieve better performance than state-of-the-art methods.'], 'negatives': [\"The authors examined 2 ways reward might increase creativity. First, reward contingent on creativity might increase extrinsic motivation. Studies 1 and 2 found that repeatedly giving preadolescent students reward for creative performance in 1 task increased their creativity in subsequent tasks. Study 3 reported that reward promised for creativity increased college students' creative task performance. Second, expected reward for high performance might increase creativity by enhancing perceived self-determination and, therefore, intrinsic task interest. Study 4 found that employees' intrinsic job interest mediated a positive relationship between expected reward for high performance and creative suggestions offered at work. Study 5 found that employees' perceived self-determination mediated a positive relationship between expected reward for high performance and the creativity of anonymous suggestions for helping the organization.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We introduce an algorithm, called KarmaLego, for the discovery of frequent symbolic time interval-related patterns (TIRPs). The mined symbolic time intervals can be part of the input, or can be generated by a temporal-abstraction process from raw time-stamped data. The algorithm includes a data structure for TIRP-candidate generation and a novel method for efficient candidate-TIRP generation, by exploiting the transitivity property of Allen’s temporal relations. Additionally, since the non-ambiguous definition of TIRPs does not specify the duration of the time intervals, we propose to pre-cluster the time intervals based on their duration to decrease the variance of the supporting instances. Our experimental comparison of the KarmaLego algorithm’s runtime performance with several existing state of the art time intervals pattern mining methods demonstrated a significant speed-up, especially with large datasets and low levels of minimal vertical support. Furthermore, pre-clustering by time interval duration led to an increase in the homogeneity of the duration of the discovered TIRP’s supporting instances’ time intervals components, accompanied, however, by a corresponding decrease in the number of discovered TIRPs.', 'positives': ['The research described in this paper was supported in part by the National Science Foundation under Grants IST-g0-12418 and IST-82-10564. and in part by the Office of Naval Research under Grant N00014-80-C-0197. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. © 1983 ACM 0001-0782/83/1100.0832 75¢'], 'negatives': ['A common disclaimer by an AI author is that he has neglected temporal considerations to avoid complication. The implication is nearly made that adding a temporal dimension to the research (on engineering, medical diagnosis, etc.) would be a familiar but tedious exercise that would obscure the new material presented by the author. Actually, of course, no one has ever dealt with time correctly in an AI program, and there is reason to believe that doing it would change everything. Because time has been neglected, medical diagnosis programs cannot talk about the course of a disease. Story understanding programs have trouble with past events. Problem solvers have had only the crudest models of the future, in spite of the obvious importance of future events. Many researchers have compensated by modeling the course of external time with the program’s own internal time, changing the world model to reflect changing reality. This leads to a confusion between correcting a mistaken belief and updating an outdated belief. Most AI data bases have some sort of operator for removing formulas. (e.g., ERASE in PLANNER, Hewitt, 1972) This operator has tended to be used for two quite different purposes: getting rid of tentative or hypothetical assertions that turned out not to be true, and noting that an assertion is no longer true. The confusion is natural, since some of the same consequences must follow in either case. For example, if ‘‘The car is drivable’’ follows from ‘‘There is gas in the car,’’ then the former statement must be deleted when the latter is, whether you have discovered there to be no gas after all, or the gas has been used up. But in many cases, the two behave quite differently, and efforts to make them the same have resulted in awkward, inextensible programs. For example, from ‘‘x is beating his wife,’’ you are entitled to infer, ‘‘x is a bad man.’’ But if x pauses to catch his breath, only the former statement must be deleted from the data base. Clearly, the proper inference is from ‘‘If x has beat his wife recently, he is a bad man,’’ and ‘‘x is beating his wife,’’ to ‘‘For the next year or so, x will have beaten his wife recently,’’ and hence to'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper proposed a framework based on reinforcementlearning for color object segmentation in videosequences. This agent-based method is used to find the appropriatevalues to detect an object. The reinforcement learningagent contains some sample images and their ground truthfrom which to learn. The information obtained from theexploration/exploitation of the solution space is used by theintelligent agent to enhance the quality of the segmented imageover time. As the proposed method uses a dynamic framework, it has a good potential for color object segmentation applicationin video sequences.', 'positives': ['Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received growing attention in the machine learning community over the past decade. The book provides a long-needed, systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises. Code and datasets can be obtained on the web. Appendices provide mathematical background and a discussion of Gaussian Markov processes.'], 'negatives': ['We present a new approach for predicting spatial phase signals originated from photothermally excited metallic nanoparticles of arbitrary shapes and sizes. Heat emitted from the nanoparticle affects the measured phase signal via both the nanoparticle surrounding refractive index and thickness changes. Since these particles can be bio-functionalized to bind certain biological cell components, they can be used for biomedical imaging with molecular specificity, as new nanoscopy labels, and for photothermal therapy. Predicting the ideal nanoparticle parameters requires a model that computes the thermal and phase distributions around the particle, enabling more efficient phase imaging of plasmonic nanoparticles, and sparing trial and error experiments of using unsuitable nanoparticles. For the first time to our knowledge, using the proposed model, one can predict phase signatures from nanoparticles with arbitrary parameters. The proposed nonlinear model is based on a finite-volume method for geometry discretization, and an implicit backward Euler method for solving the transient inhomogeneous heat equation. To validate the model, we correlate its results with experimental results obtained for gold nanorods of various concentrations, which we acquired by a custom-built wide-field interferometric phase microscopy system.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The article argues to replace null hypothesis significance testing by confidence intervals. Correctly interpreted, confidence intervals avoid the problems associated with null hypothesis statistical testing. Confidence intervals are formally valid, do not depend on apriori hypotheses and do not result in trivial knowledge. The first part presents critique of null hypothesis significance testing; the second part replies to critique against confidence intervals and tries to demonstrate their superiority to null hypothesis significance testing.', 'positives': ['This article described three heuristics that are employed in making judgements under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgements and decisions in situations of uncertainty.'], 'negatives': ['This paper presents a new approach to perform the estimation of the translation model probabilities of a phrase-based statistical machine translation system. We use neural networks to directly learn the translation probability of phrase pairs using continuous representations. The system can be easily trained on the same data used to build standard phrase-based systems. We provide experimental evidence that the approach seems to be able to infer meaningful translation probabilities for phrase pairs not seen in the training data, or even predict a list of the most likely translations given a source phrase. The approach can be used to rescore n-best lists, but we also discuss an integration into the Moses decoder. A preliminary evaluation on the English/French IWSLT task achieved improvements in the BLEU score and a human analysis showed that the new model often chooses semantically better translations. Several extensions of this work are discussed.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The emerging compressed sensing (CS) theory can significantly reduce the number of sampling points that directly corresponds to the volume of data collected, which means that part of the redundant data is never acquired. It makes it possible to create standalone and net-centric applications with fewer resources required in Internet of Things (IoT). CS-based signal and information acquisition/compression paradigm combines the nonlinear reconstruction algorithm and random sampling on a sparse basis that provides a promising approach to compress signal and data in information systems. This paper investigates how CS can provide new insights into data sampling and acquisition in wireless sensor networks and IoT. First, we briefly introduce the CS theory with respect to the sampling and transmission coordination during the network lifetime through providing a compressed sampling process with low computation costs. Then, a CS-based framework is proposed for IoT, in which the end nodes measure, transmit, and store the sampled data in the framework. Then, an efficient cluster-sparse reconstruction algorithm is proposed for in-network compression aiming at more accurate data reconstruction and lower energy efficiency. Performance is evaluated with respect to network size using datasets acquired by a real-life deployment.', 'positives': ['Rapid advances in industrial information integration methods have spurred tremendous growth in the use of enterprise systems. Consequently, a variety of techniques have been used for probing enterprise systems. These techniques include business process management, workflow management, Enterprise Application Integration (EAI), Service-Oriented Architecture (SOA), grid computing, and others. Many applications require a combination of these techniques, which is giving rise to the emergence of enterprise systems. Development of the techniques has originated from different disciplines and has the potential to significantly improve the performance of enterprise systems. However, the lack of powerful tools still poses a major hindrance to exploiting the full potential of enterprise systems. In particular, formal methods and systems methods are crucial for modeling complex enterprise systems, which poses unique challenges. In this paper, we briefly survey the state of the art in the area of enterprise systems as they relate to industrial informatics.'], 'negatives': ['Many problems in signal processing and statistical inference involve finding sparse solutions to under-determined, or ill-conditioned, linear systems of equations. A standard approach consists in minimizing an objective function which includes a quadratic (squared ) error term combined with a sparseness-inducing regularization term. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution, and compressed sensing are a few well-known examples of this approach. This paper proposes gradient projection (GP) algorithms for the bound-constrained quadratic programming (BCQP) formulation of these problems. We test variants of this approach that select the line search parameters in different ways, including techniques based on the Barzilai-Borwein method. Computational experiments show that these GP approaches perform well in a wide range of applications, often being significantly faster (in terms of computation time) than competing methods. Although the performance of GP methods tends to degrade as the regularization term is de-emphasized, we show how they can be embedded in a continuation scheme to recover their efficient practical performance.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The idea that language shapes the way we think, often associated with Benjamin Whorf, has long been decried as not only wrong but also fundamentally wrong-headed. Yet, experimental evidence has reopened debate about the extent to which language influences nonlinguistic cognition, particularly in the domain of time. In this article, I will first analyze an influential argument against the Whorfian hypothesis and show that its anti-Whorfian conclusion is in part an artifact of conflating two distinct questions: Do we think in language? and Does language shape thought? Next, I will discuss crosslinguistic differences in spatial metaphors for time and describe experiments that demonstrate corresponding differences in nonlinguistic mental representations. Finally, I will sketch a simple learning mechanism by which some linguistic relativity effects appear to arise. Although people may not think in language, speakers of different languages develop distinctive conceptual repertoires as a consequence of ordinary and presumably universal neural and cognitive processes.', 'positives': ['The present paper evaluates the claim that abstract conceptual domains are structured through metaphorical mappings from domains grounded directly in experience. In particular, the paper asks whether the abstract domain of time gets its relational structure from the more concrete domain of space. Relational similarities between space and time are outlined along with several explanations of how these similarities may have arisen. Three experiments designed to distinguish between these explanations are described. The results indicate that (1) the domains of space and time do share conceptual structure, (2) spatial relational information is just as useful for thinking about time as temporal information, and (3) with frequent use, mappings between space and time come to be stored in the domain of time and so thinking about time does not necessarily require access to spatial schemas. These findings provide some of the first empirical evidence for Metaphoric Structuring. It appears that abstract domains such as time are indeed shaped by metaphorical mappings from more concrete and experiential domains such as space.'], 'negatives': ['The two authorsLakoff, a linguist and Nunez, a psychologistpurport to introduce a new field of study, i.e. \"mathematical idea analysis\", with this book. By \"mathematical idea analysis\", they mean to give a scientifically plausible account of mathematical concepts using the apparatus of cognitive science. This approach is meant to be a contribution to academics and possibly education as it helps to illuminate how we cognitise mathematical concepts, which are supposedly undecipherable and abstruse to laymen. The analysis of mathematical ideas, the authors claim, cannot be done within mathematics, for even metamathematicsrecursive theory, model theory, set theory, higherorder logic still requires mathematical idea analysis in itself! Formalism, by its very nature, voids symbols of their meanings and thus cognition is required to imbue meaning. Thus, there is a need for this new field, in which the authors, if successful, would become pioneers.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'As satellite signals, e.g. GPS, are severely degraded indoors or not available at all, other methods are needed for indoor positioning. In this paper, we propose methods for combining information from inertial sensors, indoor map, and WLAN signals for pedestrian indoor navigation. We present results of field tests where complementary extended Kalman filter was used to fuse together WLAN signal strengths and signals of an inertial sensor unit including one gyro and three-axis accelerometer. A particle filter was used to combine the inertial data with map information. The results show that both the map information and WLAN signals can be used to improve the pedestrian dead reckoning estimate based on inertial sensors.', 'positives': ['Map-matching algorithms integrate positioning data with spatial road network data (roadway centrelines) to identify the correct link on which a vehicle is travelling and to determine the location of a vehicle on a link. A map-matching algorithm could be used as a key component to improve the performance of systems that support the navigation function of intelligent transport systems (ITS). The required horizontal positioning accuracy of such ITS applications is in the range of 1 m to 40 m (95%) with relatively stringent requirements placed on integrity (quality), continuity and system availability. A number of map-matching algorithms have been developed by researchers around the world using different techniques such as topological analysis of spatial road network data, probabilistic theory, Kalman filter, fuzzy logic, and belief theory. The performances of these algorithms have improved over the years due to the application of advanced techniques in the map matching processes and improvements in the quality of both positioning and spatial road network data. However, these algorithms are not always capable of supporting ITS applications with high required navigation performance, especially in difficult and complex environments such as dense urban areas. This suggests that research should be directed at identifying any constraints and limitations of existing map matching algorithms as a prerequisite for the formulation of algorithm improvements. The objectives of this paper are thus to uncover the constraints and limitations by an in-depth literature review and to recommend ideas to address them. This paper also highlights the potential impacts of the forthcoming European Galileo system and the European Geostationary Overlay Service (EGNOS) on the performance of map matching algorithms. Although not addressed in detail, the paper also presents some ideas for monitoring the integrity of mapmatching algorithms. The map-matching algorithms considered in this paper are generic and do not assume knowledge of ‘future’ information (i.e. based on either cost or time). Clearly, such data would result in relatively simple map-matching algorithms. 2007 Elsevier Ltd. All rights reserved.'], 'negatives': ['Product reviews possess critical information regarding customers’ concerns and their experience with the product. Such information is considered essential to firms’ business intelligence which can be utilized for the purpose of conceptual design, personalization, product recommendation, better customer understanding, and finally attract more loyal customers. Previous studies of deriving useful information from customer reviews focused mainly on numerical and categorical data. Textual data have been somewhat ignored although they are deemed valuable. Existing methods of opinion mining in processing customer reviews concentrates on counting positive and negative comments of review writers, which is not enough to cover all important topics and concerns across different review articles. Instead, we propose an automatic summarization approach based on the analysis of review articles’ internal topic structure to assemble customer concerns. Different from the existing summarization approaches centered on sentence ranking and clustering, our approach discovers and extracts salient topics from a set of online reviews and further ranks these topics. The final summary is then generated based on the ranked topics. The experimental study and evaluation show that the proposed approach outperforms the peer approaches, i.e. opinion mining and clustering-summarization, in terms of users’ responsiveness and its ability to discover the most important topics. 2007 Elsevier Ltd. All rights reserved.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We propose a generalization of the best arm identification problem in stochastic multiarmed bandits (MAB) to the setting where every pull of an arm is associated with delayed feedback. The delay in feedback increases the effective sample complexity of standard algorithms, but can be offset if we have access to partial feedback received before a pull is completed. We propose a general framework to model the relationship between partial and delayed feedback, and as a special case we introduce efficient algorithms for settings where the partial feedback are biased or unbiased estimators of the delayed feedback. Additionally, we propose a novel extension of the algorithms to the parallel MAB setting where an agent can control a batch of arms. Our experiments in real-world settings, involving policy search and hyperparameter optimization in computational sustainability domains for fast charging of batteries and wildlife corridor construction, demonstrate that exploiting the structure of partial feedback can lead to significant improvements over baselines in both sequential and parallel MAB.', 'positives': ['Can one parallelize complex exploration– exploitation tradeoffs? As an example, consider the problem of optimal highthroughput experimental design, where we wish to sequentially design batches of experiments in order to simultaneously learn a surrogate function mapping stimulus to response and identify the maximum of the function. We formalize the task as a multiarmed bandit problem, where the unknown payoff function is sampled from a Gaussian process (GP), and instead of a single arm, in each round we pull a batch of several arms in parallel. We develop GP-BUCB, a principled algorithm for choosing batches, based on the GP-UCB algorithm for sequential GP optimization. We prove a surprising result; as compared to the sequential approach, the cumulative regret of the parallel algorithm only increases by a constant factor independent of the batch size B. Our results provide rigorous theoretical support for exploiting parallelism in Bayesian global optimization. We demonstrate the effectiveness of our approach on two real-world applications.'], 'negatives': ['Three-dimensional shape searching is a problem of current interest in several different fields. Most techniques have been developed for a particular domain and reduce a shape into a simpler shape representation. The techniques developed for a particular domain will also find applications in other domains. We classify and compare various 3D shape searching techniques based on their shape representations. A brief description of each technique is provided followed by a detailed survey of the state-of-the-art. The paper concludes by identifying gaps in current shape search techniques and identifies directions for future research. q 2004 Elsevier Ltd. All rights reserved.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'A methodology for automatically identifying and clustering semantic features or topics in a heterogeneous text collection is presented. Textual data is encoded using a low rank nonnegative matrix factorization algorithm to retain natural data nonnegativity, thereby eliminating the need to use subtractive basis vector and encoding calculations present in other techniques such as principal component analysis for semantic feature abstraction. Existing techniques for nonnegative matrix factorization are reviewed and a new hybrid technique for nonnegative matrix factorization is proposed. Performance evaluations of the proposed method are conducted on a few benchmark text collections used in standard topic detection studies.', 'positives': ['In this paper, we propose a novel document clustering method based on the non-negative factorization of the term-document matrix of the given document corpus. In the latent semantic space derived by the non-negative matrix factorization (NMF), each axis captures the base topic of a particular document cluster, and each document is represented as an additive combination of the base topics. The cluster membership of each document can be easily determined by finding the base topic (the axis) with which the document has the largest projection value. Our experimental evaluations show that the proposed document clustering method surpasses the latent semantic indexing and the spectral clustering methods not only in the easy and reliable derivation of document clustering results, but also in document clustering accuracies.'], 'negatives': ['Youth marijuana use is a growing concern with increasingly permissive views towards marijuana use. Little is known about attitudes and beliefs toward marijuana use among youth in the context of legalization. This study describes youth attitudes and beliefs about health risks associated with marijuana use, social norms of peer use, conversations with parents about marijuana use, and knowledge of recreational marijuana laws, using a venue-day-time sampling approach with diverse Colorado youth (n\\u2009=\\u2009241) post-legalization. We considered demographic (gender, racial/ethnic and geographic) differences in knowledge of laws and perceptions of risk using bivariate and multivariate analyses. While many youth are knowledgeable about retail marijuana laws in Colorado, males were 2.12 times more likely to be familiar with laws compared to females. While 40\\u2009% of the sample perceived a moderate to high risk from weekly marijuana consumption and 57\\u2009% from daily consumption, fewer males perceived these risks. Over ¾ of the sample indicate they discuss marijuana with parents, but many fewer indicate discussing consequences and health effects of use with parents. Results suggest opportunities for parents and clinicians to influence youth attitudes and behaviors towards marijuana use. It may be worthwhile to target educational campaigns to different demographic groups, and to offer training and capacity building for parents to discuss marijuana with their teenaged children.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Graphs (networks) are ubiquitous and allow us to model entities (nodes) and the dependencies (edges) between them. Graph data is often observed directly in the natural world (e.g., biological or social networks) [21] or constructed from non-relational data by deriving a metric space between entities and retaining only the most significant edges [5, 23]. Learning a useful feature representation from graph data lies at the heart and success of many machine learning tasks such as classification, anomaly detection, link prediction, among many others. Many existing techniques use random walks as a basis for learning features or estimating the parameters of a graph model for a downstream prediction task. Examples include recent node embedding methods such as DeepWalk [12], node2vec [4], as well as graph-based deep learning algorithms. However, the simple random walk used by these methods is fundamentally tied to the identity of the node. This has three main disadvantages. First, these approaches are inherently transductive and do not generalize to unseen nodes and other graphs [16]. Second, they are not space-efficient as a feature vector is learned for each node which is impractical for large graphs. Third, most of these approaches lack support for attributed graphs.', 'positives': ['Active and semi-supervised learning are important techniques when labeled data are scarce. We combine the two under a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The semi-supervised learning problem is then formulated in terms of a Gaussian random field on this graph, the mean of which is characterized in terms of harmonic functions. Active learning is performed on top of the semisupervised learning scheme by greedily selecting queries from the unlabeled data to minimize the estimated expected classification error (risk); in the case of Gaussian fields the risk is efficiently computed using matrix methods. We present experimental results on synthetic data, handwritten digit recognition, and text classification tasks. The active learning scheme requires a much smaller number of queries to achieve high accuracy compared with random query selection. 1. Introduction Semi-supervised learning targets the common situation where labeled data are scarce but unlabeled data are abundant. Under suitable assumptions, it uses unlabeled data to help supervised learning tasks. Various semi-supervised learning methods have been proposed and show promising results; Seeger (2001) gives a survey. These methods typically assume that the labeled data set is given and fixed. In practice, it may make sense to utilize active learning in conjunction with semi-supervised learning. That is, we might allow the learning algorithm to pick a set of unlabeled instances to be labeled by a domain expert, which will then be used as (or to augment) the labeled data set. In other words, if we have to label a few instances for semisupervised learning, it may be attractive to let the learning algorithm tell us which instances to label, rather than selecting them randomly. We will limit the range of query selection to the unlabeled data set, a practice known as poolbased active learning or selective sampling. There has been a great deal of research in active learning. For example, Tong and Koller (2000) select queries to minimize the version space size for support vector machines; Cohn et al. (1996) minimize the variance component of the estimated generalization error; Freund et al. (1997) employ a committee of classifiers, and query a point whenever the committee members disagree. Most of the active learning methods do not take further advantage of the large amount of unlabeled data once the queries are selected. Exceptions include McCallum and Nigam (1998) who use EM with unlabeled data integrated into the active learning, and Muslea et al. (2002) who use a semi-supervised learning method during training. In addition to this body of work from the machine learning community, there is a large literature on the closely related topic of experimental design in statistics; Chaloner and Verdinelli (1995) give a survey of experimental design from a Bayesian perspective. Recently Zhu et al. (2003) introduced a semi-supervised learning framework which is based on Gaussian random fields and harmonic functions. In this paper we demonstrate how this framework allows a combination of active learning and semi-supervised learning. In brief, the framework allows one to efficiently estimate the expected generalization error after querying a point, which leads to a better query selection criterion than naively selecting the point with maximum label ambiguity. Then, once the queries are selected and added to the labeled data set, the classifier can be trained using both the labeled and remaining unlabeled data. We present results on synthetic data, text classificaProceedings of the ICML-2003 Workshop on The Continuum from Labeled to Unlabeled Data, Washington DC, 2003. tion and image classification tasks that indicate the combination of these techniques can result in highly effective learning schemes. 2. Gaussian random fields and harmonic energy minimizing functions We begin by briefly describing the semi-supervised learning framework of Zhu et al. (2003). There are labeled points , and unlabeled points ; usually . We will use , ! to denote the labeled and unlabeled set, and \"$#% \\'&( the total number of points. We assume the labels are binary: *),+.-0/1 243 . We assume a connected graph 56#6 87\\' 9: is given with nodes 7 corresponding to the \" data points, of which the nodes in are labeled with the corresponding ’s. The edges 9 are represented by an \"<;=\" weight matrix > which is given. For example if ?+A@CB , > can be the radial basis function (RBF): DFEHG #JI KML NPO 2 Q R B STVU E T O G T R W (1) so that nearby points in Euclidean space are assigned large edge weights. Other weightings are possible, of course, and may be more appropriate when is discrete or symbolic. For our purposes the matrix > fully specifies the data manifold structure. We note that a method for learning the scale parameter Q is proposed in (Zhu et al., 2003). The semi-supervised algorithm in this paper is based on a relaxation of the requirement that labels are binary, resulting in a simple and tractable family of algorithms. We allow continuous labels on unlabeled nodes MXZY[7]\\\\^@ . The labels on labeled data are still constrained to be 0 or 1: _` C#a 4)b c_ d+A-e/ 243 for _P#(24 f . We also denote the constraint by g ) U h i . Since we want unlabeled points that are nearby in the graph to have similar labels, we define the energy to be 9j c 1 C# 2 k S E l G D EmG _` O onp R (2) so that low energy corresponds to a slowly varying function over the graph. Define the diagonal matrix q6#sr*_`t*u[ 8r E whose entries r E #wv G DFEmG are the weighted degrees of the nodes in 5 . The combinatorial Laplacian is the \"x;y\" matrix z{#aq O > . We can rewrite the energy function in matrix form as 9| c 1 #( } z: . We consider the Gaussian random field ~ c 1 C# 2 \\x7fP\\x80 I KML< OF\\x81 9j c 1 f where \\x81 is an “inverse temperature” parameter, and \\x7f \\x80 is the partition function \\x7f\\x82\\x80 #s\\x83 h \\x84 i U h i I KpL< OF\\x81 9j M \\x85r4 . The Gaussian random field differs from the “standard” discrete Markov random field in that the field configurations are over a continuous state space. Moreover, for a Gaussian field the joint probability distribution over unlabeled nodes is Gaussian with covariance matrix \\x80 z|\\x86 0 . z\\x87 0 is the submatrix of z corresponding to unlabeled data. The minimum energy function \\x88\\x89# arg min h \\x84 i U h i 9| c 1 of the Gaussian field is harmonic; that is, it satisfies z\\x8a\\x88A#\\x8b/ on unlabeled data points ! , and is equal to ) on the labeled data points . The harmonic property means that the value at each unlabeled node is the average of neighboring nodes: \\x88b onp C# 2 r G S E\\x8d\\x8c\\x8eG D\\x85EmG \\x88b _` for n\\x87#Z &a24 f &? which is consistent with our prior notion of smoothness with respect to the graph. Because of the maximum principle of harmonic functions (Doyle & Snell, 1984), \\x88 is unique. Furthermore, \\x88 satisfies /\\x89\\x8f(\\x88b onp \\x90\\x8f\\x912 for n\\x92+\\x93! when ! is connected and labeled nodes from both classes are present at the boundary (the usual case; otherwise \\x88 takes on the extremum 0 or 1). By definition \\x88 is the mode of the Gaussian random field, but since the joint distribution is Gaussian, \\x88 is also the mean of the field. The harmonic energy minimizing function \\x88 can be computed with matrix methods. We partition the Laplacian matrix z into blocks for labeled and unlabeled nodes, z\\x91#\\x95\\x94 z\\x87 m z\\x87 z e z 0 \\x97\\x96 and let \\x88,# \\x94 \\x880 \\x88 \\x96 where \\x88 \\x90#\\x98 ) , and \\x88 denotes the mean values on the unlabeled data points. The solution is given by \\x88 # O z \\x86 0 z e \\x88 (3) It is not hard to show that the Gaussian field, conditioned on labeled data, is a multivariate normal: * y\\x99a\\x9a\\x8b \\x9b\\x88 \\x8e fz \\x86 0 . To carry out classification with a Gaussian field, we note that the harmonic energy minimizing function \\x88 is the mean of the field. Therefore the Bayes classification rule is to label node _ as class 1 in case \\x88b c_ d\\x9cJ/1 H\\x9d , and to label node _ class 0 otherwise. The harmonic function \\x88 has many nice interpretations, of which the random walk view is particularly relevant here. Define the transition matrix \\x9e\\x9f# q \\x86 > . Consider the random walk on graph 5 by a particle. Starting from an unlabeled node _ , it moves to a node n with probability \\x9e EHG after one step. The walk continues until the particle reaches a labeled node. Then \\x88 E is the probability that the particle, starting from node _ , reaches a labeled node with label 1. The labeled data are the absorbing boundary for the random walk. More on this semi-supervised learning framework can be found in (Zhu et al., 2003). 3. Active learning We propose to perform active learning with the Gaussian random field model by greedily selecting queries from the unlabeled data to minimize the risk of the harmonic energy minimization function. The risk is the estimated generalization error of the Bayes classifier, and can be efficiently computed with matrix methods. We define the true risk \\x9b\\x88 of the Bayes classifier based on the harmonic function \\x88 to be \\x9b\\x88 # S E U S h U l sgn \\x9b\\x88 E # E ~ E g where sgn 8\\x88 E is the Bayes decision rule, where (with a slight abuse of notation) sgn \\x9b\\x88 E \\x97# 2 if \\x88 E \\x9c^/ \\x9d and sgn \\x9b\\x88 E #,/ otherwise. Here ~ E g is the unknown true label distribution at node _ , given the labeled data. Because of this 8\\x88 is not computable. In order to proceed, it is necessary to make assumptions. We begin by assuming that we can estimate the unknown distribution ~ c E g d with the mean of the Gaussian field model: ~ c E # 2pg d Z\\x88 E Intuitively, recalling \\x88 E is the probability of reaching 1 in a random walk on the graph, our assumption is that we can approximate the distribution using a biased coin at each node, whose probability of heads is \\x88 E . With this assumption we can compute the estimated risk 8\\x88 as \\x92 8\\x88 # S E U sgn \\x9b\\x88 E # / 2 O \\x88 E & sgn 8\\x88 E #(2 \\x88 E # S E U \\x9b\\x88 E 2 O \\x88 E (4) If we perform active learning and query an unlabeled node , we will receive an answer (0 or 1). Adding this point to the tr'], 'negatives': ['Low voltage (LV) analog circuit design techniques are addressed in this tutorial. In particular, (i) technology considerations; (ii) transistor model capable to provide performance and power tradeoffs; (iii) low voltage implementation techniques capable to reduce the power supply requirements, such as bulk-driven, floating-gate, and self-cascode MOSFETs; (iv) basic LV building blocks; (v) multi-stage frequency compensation topologies; and (vi) fully-differential and fully-balanced systems. key words: analog circuits, amplifiers, transistor model, bulkdriven, floating-gate, self-cascode, NGCC frequency compensation, fully-differential and fully-balanced systems.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Many works related learning from examples to regularization techniques for inverse problems, emphasizing the strong algorithmic and conceptual analogy of certain learning algorithms with regularization algorithms. In particular it is well known that regularization schemes such as Tikhonov regularization can be effectively used in the context of learning and are closely related to algorithms such as support vector machines. Nevertheless the connection with inverse problem was considered only for the discrete (finite sample) problem which is solved in practice and the probabilistic aspects of learning from examples were not taken into account. In this paper we provide a natural extension of such analysis to the continuous (population) case and analyse the interplay between the discrete and continuous problems. From a theoretical point of view, this allows to draw a clear connection between the consistency approach imposed in learning theory, and the stability convergence property used in ill-posed inverse problems. The main mathematical result of the paper is a new probabilistic bound for the regularized least-squares algorithm. By means of standard results on the approximation term, the consistency of the algorithm easily follows.', 'positives': ['The purpose of this paper is to provide a PAC error analysis for the q-norm soft margin classifier, a support vector machine classification algorithm. It consists of two parts: regularization error and sample error. While many techniques are available for treating the sample error, much less is known for the regularization error and the corresponding approximation error for reproducing kernel Hilbert spaces. We are mainly concerned about the regularization error. It is estimated for general distributions by a K-functional in weighted L spaces. For weakly separable distributions (i.e., the margin may be zero) satisfactory convergence rates are provided by means of separating functions. A projection operator is introduced, which leads to better sample error estimates especially for small complexity kernels. The misclassification error is bounded by the V -risk associated with a general class of loss functions V . The difficulty of bounding the offset is overcome. Polynomial kernels and Gaussian kernels are used to demonstrate the main results. The choice of the regularization parameter plays an important role in our analysis.'], 'negatives': ['In this era of information explosion, conflicts are often encountered when information is provided by multiple sources. Traditional truth discovery task aims to identify the truth the most trustworthy information, from conflicting sources in different scenarios. In this kind of tasks, truth is regarded as a fixed value or a set of fixed values. However, in a number of real-world cases, objective truth existence cannot be ensured and we can only identify single or multiple reliable facts from opinions. Different from traditional truth discovery task, we address this uncertainty and introduce the concept of trustworthy opinion of an entity, treat it as a random variable, and use its distribution to describe consistency or controversy, which is particularly difficult for data which can be numerically measured, i.e. quantitative information. In this study, we focus on the quantitative opinion, propose an uncertainty-aware approach called Kernel Density Estimation from Multiple Sources (KDEm) to estimate its probability distribution, and summarize trustworthy information based on this distribution. Experiments indicate that KDEm not only has outstanding performance on the classical numeric truth discovery task, but also shows good performance on multi-modality detection and anomaly detection in the uncertain-opinion setting.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We present a novel system for automatically generating immersive and interactive virtual reality (VR) environments using the real world as a template. The system captures indoor scenes in 3D, detects obstacles like furniture and walls, and maps walkable areas (WA) to enable real-walking in the generated virtual environment (VE). Depth data is additionally used for recognizing and tracking objects during the VR experience. The detected objects are paired with virtual counterparts to leverage the physicality of the real world for a tactile experience. Our approach is new, in that it allows a casual user to easily create virtual reality worlds in any indoor space of arbitrary size and shape without requiring specialized equipment or training. We demonstrate our approach through a fully working system implemented on the Google Project Tango tablet device.', 'positives': ['Tianhe Yang Summary of \" A Method for Registration of 3-D Shapes \"'], 'negatives': ['Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and deposition, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed two systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video seethrough AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how freehand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Compared with supervised learning for feature selection, it is much more difficult to select the discriminative features in unsupervised learning due to the lack of label information. Traditional unsupervised feature selection algorithms usually select the features which best preserve the data distribution, e.g., manifold structure, of the whole feature set. Under the assumption that the class label of input data can be predicted by a linear classifier, we incorporate discriminative analysis and 2,1-norm minimization into a joint framework for unsupervised feature selection. Different from existing unsupervised feature selection algorithms, our algorithm selects the most discriminative feature subset from the whole feature set in batch mode. Extensive experiment on different data types demonstrates the effectiveness of our algorithm.', 'positives': ['In supervised learning scenarios, feature selection has be en studied widely in the literature. Selecting features in unsupervis ed learning scenarios is a much harder problem, due to the absence of class la bel that would guide the search for relevant information. And, almos t all of previous unsupervised feature selection methods are “wrapper ” techniques that require a learning algorithm to evaluate the candidate fe ture subsets. In this paper, we propose a “filter” method for feature select ion which is independent of any learning algorithm. Our method can be per formed in either supervised or unsupervised fashion. The proposed me thod is based on the observation that, in many real world classification pr oblems, data from the same class are often close to each other. The importa nce of a feature is evaluated by its power of locality preserving, or , Laplacian Score. We compare our method with data variance (unsupervised) an d Fisher score (supervised) on two data sets. Experimental re sults demonstrate the effectiveness and efficiency of our algorithm.'], 'negatives': ['An ultra wideband (UWB) transmitter front end (RFE) consisting of UWB circular patch antenna and an UWB GaAs common source (CS) power amplifier (PA) for the frequency range 3 to 10 GHz is presented. The patch antenna covers most of the UWB range and has an area of 30×30 squared mm. The UWB patch antenna has a return loss below 10 dB from 3 to 9 GHz, simulated with a port of 50 Ohm impedance. Since the PA and antenna both have variable impedance, the matching is performed simultaneously. The antenna impedance is directly matched to the PA using optimization algorithms. The transmitted power from the antenna is simulated with a variation around 2 dB over the entire frequency range. The PA has a gain varying from 15 to 30 dB to compensate for the antenna impedance variation.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'It is well known that options can make planning more efficient, among their many benefits. Thus far, algorithms for autonomously discovering a set of useful options were heuristic. Naturally, a principled way of finding a set of useful options may be more promising and insightful. In this paper we suggest a mathematical characterization of good sets of options using tools from information theory. This characterization enables us to find conditions for a set of options to be optimal and an algorithm that outputs a useful set of options and illustrate the proposed algorithm in simulation.', 'positives': ['We consider a graph theoretic approach for automatic construction of options in a dynamic environment. A map of the environment is generated on-line by the learning agent, representing the topological structure of the state transitions. A clustering algorithm is then used to partition the state space to different regions. Policies for reaching the different parts of the space are separately learned and added to the model in a form of options (macro-actions). The options are used for accelerating the Q-Learning algorithm. We extend the basic algorithm and consider building a map that includes preliminary indication of the location of \"interesting\" regions of the state space, where the value gradient is significant and additional exploration might be beneficial. Experiments indicate significant speedups, especially in the initial learning phase.'], 'negatives': ['A 76-year-old patient presented with a 7-year history of asymptomatic scalp lesions, which had been gradually increasing in size. One year earlier, he had undergone topical treatment with diclofenac (Solaraze®) followed by photodynamic therapy for multiple actinic keratoses. The patient denied any past history of skin disorders or trauma to the scalp. In addition to actinic damage, examination of the skin revealed multiple disseminated, firm, movable, whitish papules, measuring up to 5 mm (Figure 1). Histology of a completely excised papule showed a sharply demarcated area of mature lamellar bone in the upper and mid dermis. The epidermis was unremarkable (Figure 2a). The lamellar bone had several medullary spaces peripherally lined with osteoblasts (Figure 2b) and some isolated osteoclasts (Figure 2c). Lab tests for alkaline phosphatase, calcium, phosphate, and parathyroid hormone were within normal limits. Bone remodeling parameters such as ß-CrossLaps and osteocalcin, as well as mutation analysis of the GNAS gene, were also unremarkable. A cranial CT scan revealed extraskeletal bone formation on the scalp (cutaneous bone deposition without connection to the skull) (Figure 3). The skull itself as well as the bones of the hand – as illustrated by X-rays – were without pathological findings. Correlation of the clinical presentation and histopathology established the diagnosis of multiple miliary osteoma cutis of the scalp. As the patient was symptom-free, he declined any therapeutic intervention. Multiple miliary osteoma cutis is a very rare condition characterized by extraskeletal bone formation in the skin and/or subcutis. In their review of 51 cases of multiple miliary osteoma cutis, Myllyla et al. reported that the majority of patients were women (n = 42), with a large percentage of'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper provides a survey of work on the link between education and economic growth. It shows that data from the early 20th century are coherent with conclusions about education and economic growth derived from the much more recent past. It also presents an analysis of the role of education in facilitating the use of best-practice technology. It is to be published in the International Handbook on the Economics of Education edited by G and J. Johnes and published by Edward Elgar.', 'positives': [\"Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available at http://www.jstor.org/about/terms.html. JSTOR's Terms and Conditions of Use provides, in part, that unless you have obtained prior permission, you may not download an entire issue of a journal or multiple copies of articles, and you may use content in the JSTOR archive only for your personal, non-commercial use. Please contact the publisher regarding any further use of this work. Publisher contact information may be obtained at http://www.jstor.org/journals/ucpress.html. Each copy of any part of a JSTOR transmission must contain the same copyright notice that appears on the screen or printed page of such transmission.\"], 'negatives': ['The Climate Forecast System (CFS), the fully coupled ocean-land-atmosphere dynamical seasonal prediction system that became operational at NCEP in August 2004, is described and evaluated in this paper. The CFS provides important advances in operational seasonal prediction on a number of fronts. For the first time in the history of U.S. operational seasonal prediction, a dynamical modeling system has demonstrated a level of skill in forecasting U.S. surface temperature and precipitation that is comparable to the skill of the statistical methods used by the NCEP Climate Prediction Center (CPC). This represents a significant improvement over the previous dynamical modeling system used at NCEP. Furthermore, the skill provided by the CFS spatially and temporally complements the skill provided by the statistical tools. The availability of a dynamical modeling tool with demonstrated skill should result in overall improvement in the operational seasonal forecast products produced by CPC. The atmospheric component of the CFS is a lower resolution version of the Global Forecast System (GFS) that was the operational global weather prediction model at NCEP during 2003. The ocean component is the GFDL Modular Ocean Model version 3 (MOM3). The previous dynamical seasonal forecast system used at NCEP consisted of the 1998 GFS (a.k.a. MRF) and the GFDL MOM1 ocean model. In addition to the replacement of the oceanic and atmospheric components, there are several important improvements inherent in the new CFS relative to the previous dynamical forecast system. These include: (i) The atmosphere-ocean coupling spans almost all of the globe (as opposed to the tropical Pacific only); (ii) The CFS is a fully coupled modeling system with no flux correction (as opposed to the previous uncoupled \\'tier-2\\' system, which 3 employed multiple bias and flux corrections); (iii) A set of fully coupled retrospective forecasts covering a 24 year period (1981-2004), with 15 forecasts per calendar month out to nine months into the future, have been produced with the CFS. In contrast \" perfect \" (i.e., observed) SST was prescribed in the production of the retrospective forecasts for the previously operational dynamical forecast system. These 24 years of fully coupled retrospective forecasts are of paramount importance to the proper calibration (bias correction) of subsequent operational seasonal forecasts. They provide a meaningful à priori estimate of model skill that is critical in determining the utility of the real-time dynamical forecast in the operational framework. The retrospective dataset also provides a wealth of information for …'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Realistic wrinkles are important for enhancing the realism of 3D facial expression. In this paper, we proposed a combined method to simulate realistic wrinkles generated in facial expressions. By taking physiological mechanism of facial wrinkles into account, we used the muscle model for facial animation to extract the wrinkle region, and then an improved wrinkle model was applied to generate wrinkles on wrinkle region. In the simulation, we subdivided face model using DirectX 11 Tessellation technique. The experiment results of our combined method demonstrated that it can generate realistic wrinkles on a 3D virtual face.', 'positives': ['Wrinkles are an extremely important contribution for enhancing the realism of human figure models. In this paper, we present an approach to generate static and dynamic wrinkles on human skin. For the static model, we consider micro and macro structures of the skin surface geometry. For the wrinkle dynamics, an approach using a biomechanical skin model is employed. The tile texture patterns in the micro structure of skin surface are created using planar Delaunay triangulation. Functions of barycentric coordinates are applied to simulate the curved ridges. The visible (macro) flexure lines which may form wrinkles are predefined edges on the micro structure. These lines act as constraints for the hierarchical triangulation process. Furtheremore, the dynamics of expressive wrinkles --controlling their depth and fold-is modeled according to the principal strain of the deformed skin surface. Bump texture mapping is used for skin rendering.'], 'negatives': ['Detailed facial performance geometry can be reconstructed using dense camera and light setups in controlled studios. However, a wide range of important applications cannot employ these approaches, including all movie productions shot from a single principal camera. For post-production, these require dynamic monocular face capture for appearance modification. We present a new method for capturing face geometry from monocular video. Our approach captures detailed, dynamic, spatio-temporally coherent 3D face geometry without the need for markers. It works under uncontrolled lighting, and it successfully reconstructs expressive motion including high-frequency face detail such as folds and laugh lines. After simple manual initialization, the capturing process is fully automatic, which makes it versatile, lightweight and easy-to-deploy. Our approach tracks accurate sparse 2D features between automatically selected key frames to animate a parametric blend shape model, which is further refined in pose, expression and shape by temporally coherent optical flow and photometric stereo. We demonstrate performance capture results for long and complex face sequences captured indoors and outdoors, and we exemplify the relevance of our approach as an enabling technology for model-based face editing in movies and video, such as adding new facial textures, as well as a step towards enabling everyone to do facial performance capture with a single affordable camera.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Novel microstrip dual-band bandpass filters with controllable fractional bandwidths and good in-between isolation are presented and implemented. A half-wavelength stepped-impedance resonator is firstly characterized, aiming at producing the two resonant frequencies at 2.4 and 5.2 GHz. Two types of coupled microstrip lines in the parallel and anti-parallel formats are then investigated in terms of unified equivalent J-inverter network. Extensive results are derived to quantitatively show their distinctive frequency-distributed coupling performances under different coupling lengths. The coupling degrees of these two coupled lines at the two resonances are properly adjusted to achieve the dual-passband response with varied or tunable bandwidths. In addition, the parallel coupled line is modeled to bring out a transmission zero between the two resonances so as to achieve the good in-between isolation. The three two-stage bandpass filters are initially designed to exhibit their dual-band response with changeable dual-band bandwidths. A three-stage dual-band filter is in final optimally designed and its predicted performance is confirmed in experiment. key words: controllable dual-passband, dual-band filter, equivalent Jinverter network, parallel-coupled microstrip line, stepped-impedance resonator', 'positives': ['The concept ofconcurrentmultiband low-noise-amplifiers (LNAs) is introduced. A systematic way to design concurrent multiband integrated LNAs in general is developed. Applications of concurrent multiband LNAs in concurrent multiband receivers together with receiver architecture are discussed. Experimental results of a dual-band LNA implemented in a 0.35m CMOS technology as a demonstration of the concept and theory is presented.'], 'negatives': ['The use of simulation-based approaches for the analysis of business processes enables the design-time prediction of the process behavior and/or the operation-time process reconfiguration. However, the effectiveness of BP simulation is still limited for several reasons (e.g., lack of simulation know-how of BP analysts, simulation model parameters that can be hard to gather, large semantic gap between the business process model and the simulation model). To overcome such limitations, this paper introduces a model-driven method to automatically build the executable simulation code of a business process from its abstract definition in BPMN, the standard language for specifying business processes. The simulation code is specified in eBPMN, a novel domain-specific language that has been designed and implemented according to the BPMN execution semantics.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We present and discuss four important yet underserved research questions critical to the future of sharedenvironment human-robot collaboration. We begin with a brief survey of research surrounding individual components required for a complete collaborative robot control system, discussing the current state of the art in Learning from Demonstration, active learning, adaptive planning systems, and intention recognition. We motivate the exploration of the presented research questions by relating them to existing work and representative use cases from the domains of construction and cooking.', 'positives': [\"We describe the design and evaluation of Chaski, a robot plan execution system that uses insights from human-human teaming to make human-robot teaming more natural and fluid. Chaski is a task-level executive that enables a robot to collaboratively execute a shared plan with a person. The system chooses and schedules the robot's actions, adapts to the human partner, and acts to minimize the human's idle time.\\n We evaluate Chaski in human subject experiments in which a person works with a mobile and dexterous robot to collaboratively assemble structures using building blocks. We measure team performance outcomes for robots controlled by Chaski compared to robots that are verbally commanded, step-by-step by the human teammate. We show that Chaski reduces the human's idle time by 85%, a statistically significant difference. This result supports the hypothesis that human-robot team performance is improved when a robot emulates the effective coordination behaviors observed in human teams.\"], 'negatives': ['Deep neuroevolution and deep reinforcement learning (deep RL) algorithms are two popular approaches to policy search. The former is widely applicable and rather stable, but suffers from low sample efficiency. By contrast, the latter is more sample efficient, but the most sample efficient variants are also rather unstable and highly sensitive to hyper-parameter setting. So far, these families of methods have mostly been compared as competing tools. However, an emerging approach consists in combining them so as to get the best of both worlds. Two previously existing combinations use either an ad hoc evolutionary algorithm or a goal exploration process together with the Deep Deterministic Policy Gradient (ddpg) algorithm, a sample efficient off-policy deep RL algorithm. In this paper, we propose a different combination scheme using the simple cross-entropy method (cem) and Twin Delayed Deep Deterministic policy gradient (td3), another off-policy deep RL algorithm which improves over ddpg. We evaluate the resulting method, cem-rl, on a set of benchmarks classically used in deep RL. We show that cem-rl benefits from several advantages over its competitors and offers a satisfactory trade-off between performance and sample efficiency.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper is about understanding the nature of bug fixing by analyzing thousands of bug fix transactions of software repositories. It then places this learned knowledge in the context of automated program repair. We give extensive empirical results on the nature of human bug fixes at a large scale and a fine granularity with abstract syntax tree differencing. We set up mathematical reasoning on the search space of automated repair and the time to navigate through it. By applying our method on 14 repositories of Java software and 89,993 versioning transactions, we show that not all probabilistic repair models are equivalent.', 'positives': ['The change history of a software project contains a rich collection of code changes that record previous development experience. Changes that fix bugs are especially interesting, since they record both the old buggy code and the new fixed code. This paper presents a bug finding algorithm using bug fix memories: a project-specific bug and fix knowledge base developed by analyzing the history of bug fixes. A bug finding tool, BugMem, implements the algorithm. The approach is different from bug finding tools based on theorem proving or static model checking such as Bandera, ESC/Java, FindBugs, JLint, and PMD. Since these tools use pre-defined common bug patterns to find bugs, they do not aim to identify project-specific bugs. Bug fix memories use a learning process, so the bug patterns are project-specific, and project-specific bugs can be detected. The algorithm and tool are assessed by evaluating if real bugs and fixes in project histories can be found in the bug fix memories. Analysis of five open source projects shows that, for these projects, 19.3%-40.3% of bugs appear repeatedly in the memories, and 7.9%-15.5% of bug and fix pairs are found in memories. The results demonstrate that project-specific bug fix patterns occur frequently enough to be useful as a bug detection technique. Furthermore, for the bug and fix pairs, it is possible to both detect the bug and provide a strong suggestion for the fix. However, there is also a high false positive rate, with 20.8%-32.5% of non-bug containing changes also having patterns found in the memories. A comparison of BugMem with a bug finding tool, PMD, shows that the bug sets identified by both tools are mostly exclusive, indicating that BugMem complements other bug finding tools.'], 'negatives': ['MOTIVATION\\nGene family evolution is driven by evolutionary events such as speciation, gene duplication, horizontal gene transfer and gene loss, and inferring these events in the evolutionary history of a given gene family is a fundamental problem in comparative and evolutionary genomics with numerous important applications. Solving this problem requires the use of a reconciliation framework, where the input consists of a gene family phylogeny and the corresponding species phylogeny, and the goal is to reconcile the two by postulating speciation, gene duplication, horizontal gene transfer and gene loss events. This reconciliation problem is referred to as duplication-transfer-loss (DTL) reconciliation and has been extensively studied in the literature. Yet, even the fastest existing algorithms for DTL reconciliation are too slow for reconciling large gene families and for use in more sophisticated applications such as gene tree or species tree reconstruction.\\n\\n\\nRESULTS\\nWe present two new algorithms for the DTL reconciliation problem that are dramatically faster than existing algorithms, both asymptotically and in practice. We also extend the standard DTL reconciliation model by considering distance-dependent transfer costs, which allow for more accurate reconciliation and give an efficient algorithm for DTL reconciliation under this extended model. We implemented our new algorithms and demonstrated up to 100 000-fold speed-up over existing methods, using both simulated and biological datasets. This dramatic improvement makes it possible to use DTL reconciliation for performing rigorous evolutionary analyses of large gene families and enables its use in advanced reconciliation-based gene and species tree reconstruction methods.\\n\\n\\nAVAILABILITY\\nOur programs can be freely downloaded from http://compbio.mit.edu/ranger-dtl/.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Shelf scanning is one of the most important processes for inventory management in a library. It helps the librarians and library users discover the miss-shelved books and pinpoint where they are, improving the quality of service. By traditional means, however, manually checking each bookshelf suffers from extremely intensive labor and long scanning delay. Although some existing RFID-enabled approaches have been proposed, they suffer from either high-cost infrastructure or complicated system deployment, forming a great barrier to commercial adoption. In light of this, we in this paper propose a smart system called RF-Scanner that can perform the shelf scanning automatically by combining the robot technology and the RFID technology. The former is used for replacing the librarians and liberating them from intensively manual labor. The later is installed on the robot and moves with the robot to scan the on-the-shelf books. We formulate two important issues concerned by librarians, the book localization and the lying-down book detection, and give the sophisticated solutions to them. Besides, we implement RF-Scanner and put it into practical use in our school library. Long-term experiments and studies show that RF-Scanner provides fine-grained book localization with a mean error of just 1.3 cm and accurate detection accuracy of lying-down books with a mean error of 6%.', 'positives': [\"Spearman's footrule and Kendall's tau are two well established distances between rankings. They, however, fail to take into account concepts crucial to evaluating a result set in information retrieval: element relevance and positional information. That is, changing the rank of a highly-relevant document should result in a higher penalty than changing the rank of an irrelevant document; a similar logic holds for the top versus the bottom of the result ordering. In this work, we extend both of these metrics to those with position and element weights, and show that a variant of the Diaconis-Graham inequality still holds - the generalized two measures remain within a constant factor of each other for all permutations.\\n We continue by extending the element weights into a distance metric between elements. For example, in search evaluation, swapping the order of two nearly duplicate results should result in little penalty, even if these two are highly relevant and appear at the top of the list. We extend the distance measures to this more general case and show that they remain within a constant factor of each other.\\n We conclude by conducting simple experiments on web search data with the proposed measures. Our experiments show that the weighted generalizations are more robust and consistent with each other than their unweighted counter-parts.\"], 'negatives': ['It has been a long while since skin surfaces and skin lesions have been examined by dermoscopy. However examining the hair and the scalp was done again recently and gained attention and slight popularity by the practical tool, namely trichoscopy, which can be called in a simplified way as a dermoscopy of the hair and the scalp. Trichoscopy is a great tool to examine and asses an active scalp disease and hair and other signs can be specific for some scalp and hair diseases. These signs include yellow dots, dystrophic hairs, cadaverized (black dots), white dots and exclamation mark hairs. Trichoscopy magnifies hair shafts at higher resolution to enable detailed examinations with measurements that a naked eye cannot distinguish nor see. Trichoscope is considered recently the newest frontier for the diagnosis of hair and scalp disease. Aim of this paper. The aim of this paper is to simplify and sum up the main trichoscopic readings and findings of hair and scalp disorders that are commonly encountered at clinic dermatology settings.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"This paper examines the effect of gamification techniques in engaging students in a teaching context, in particular the influence of competition. We conducted a longitudinal survey study (informed by a focus group) -- in an MBA classroom that uses ERPsim, which is a gamified simulation system for teaching the SAP ERP (Enterprise Resource Planning) software solution. Flow theory was used to understand engagement during this method of learning. We examined the effect of antecedents of Flow, such as skill and challenge, and the effect of Flow on its consequences such as satisfaction and student feelings. In line with earlier research, our results showed that losing a competition can have a detrimental effect on students' satisfaction and enjoyment; however, competition is still a key element that highly motivates students to engage in the gamification tasks.\", 'positives': [\"As people increasingly play online games, numerous new features have been proposed to increase players' log-on time at online gaming sites. However, few studies have investigated why people continue to play certain online games or which design features are most closely related to the amount of time spent by players at particular online gaming sites. This study proposes a theoretical model using the concepts of customer loyalty, flow, personal interaction, and social interaction to explain why people continue to play online network games. The study then conducts a large-scale survey to validate the model. Finally, it analyzes current online games to identify design features that are closely related to the theoretical concepts. The results indicate that people continue to play online games if they have optimal experiences while playing the games. This optimal experience can be attained if the player has effective personal interaction with the system or pleasant social interactions with other people connected to the Internet. Personal interaction can be facilitated by providing appropriate goals, operators and feedback; social interaction can be facilitated through appropriate communication places and tools. This paper ends with the implications of applying the study results to other domains such as e-commerce and cyber communities.\"], 'negatives': ['Recent graph computation approaches have demonstrated that a single PC can perform efficiently on billion-scale graphs. While these approaches achieve scalability by optimizing I/O operations, they do not fully exploit the capabilities of modern hard drives and processors. To overcome their performance, in this work, we introduce the Bimodal Block Processing (BBP), an innovation that is able to boost the graph computation by minimizing the I/O cost even further. With this strategy, we achieved the following contributions: (1) M-Flash, the fastest graph computation framework to date; (2) a flexible and simple programming model to easily implement popular and essential graph algorithms, including the first single-machine billion-scale eigensolver; and (3) extensive experiments on real graphs with up to 6.6 billion edges, demonstrating M-Flash’s consistent and significant speedup.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We present results from a multi-generational study of collocated group console gaming. We examine the intergenerational gaming practices of four generations of gamers, from ages 3 to 83 and, in particular, the roles that gamers of different generations take on when playing together in groups. Our findings highlight the extent to which existing gaming technologies are amenable to interactions within collocated intergenerational groups and the broader set of roles that have emerged in these computer-mediated interactions than have previously been documented by studies of more traditional collocated, intergenerational interactions. We articulate attributes of the games that encourage intergenerational interaction.', 'positives': ['In this paper, we present results from a qualitative study of collocated group console gaming. We focus on motivations for, perceptions of, and practices surrounding the shared use of console games by a variety of established groups of gamers. These groups include both intragenerational groups of youth, adults, and elders as well as intergenerational families. Our analysis highlights the numerous ways that console games serve as a computational meeting place for a diverse population of gamers.'], 'negatives': ['We propose a simple and straightforward way of creating powerful image representations via cross-dimensional weighting and aggregation of deep convolutional neural network layer outputs. We first present a generalized framework that encompasses a broad family of approaches and includes cross-dimensional pooling and weighting steps. We then propose specific non-parametric schemes for both spatialand channel-wise weighting that boost the effect of highly active spatial responses and at the same time regulate burstiness effects. We experiment on different public datasets for image search and show that our approach outperforms the current state-of-the-art for approaches based on pre-trained networks. We also provide an easy-to-use, open source implementation that reproduces our results.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In the early days of e-Commerce, web designers follow their intuition of how the website should look like. Further development of web design have seen for instance Nielsen’s heuristic, which resulted designers to focus mainly on cognitive functionality and usability. However, as technology advances and e-Commerce matures, there is a growing concern to improve the consumer interface of e-Commerce to improve the persuasive power of eCommerce websites by engineering affective appeal in website design. This paper presents a study in progress involving the adoption of Kansei Engineering in e-Commerce websites as a systematic method to engineer consumer’s affective appeal and incorporate them into new formulae of web design. Principal Component Analysis was performed to analyse structure of Kansei Words, and investigates relations between Kansei and website designs.', 'positives': ['Product design that provides aesthetic appeal, pleasure and satisfaction can greatly influence the success of a product. Traditional cognitive approaches to product usability have tended to underestimate or fragment emotion from an understanding of the user experience. Affect, which is inexplicable linked to attitudes, expectations and motivations, plays a significant role in the cognition of product interaction, and therefore can be usefully treated as a design aid. Emotion influences and mediates specific aspects of interaction before, during and after the use of a product. These affective states regularly impact how a user manipulates and explores a user interface in order to support a desired cognitive state. To better understand the specific qualities of user experience impacting desirability and pleasureability, it is necessary to understand how artifacts trigger and mediate affect and how these processes aid user cognition during interaction. The implications for design are that emotion acts as a critical component of artifact sensemaking and determines how artifacts are interpreted (Rafaeli and Vilnai-Yavetz, 2003). Designers that understand how cognitive artifacts interchange with affective artifacts will be better able to support actual product use and perceived pleasure.'], 'negatives': [\"Content Memory (Learning Ability) As Comprehension 82 Vocabulary Cs .30 ( ) .23 .31 ( ) .31 .31 .35 ( ) .29 .48 .35 .38 ( ) .30 .40 .47 .58 .48 ( ) As judged against these latter values, comprehension (.48) and vocabulary (.47), but not memory (.31), show some specific validity. This transmutability of the validation matrix argues for the comparisons within the heteromethod block as the most generally relevant validation data, and illustrates the potential interchangeability of trait and method components. Some of the correlations in Chi's (1937) prodigious study of halo effect in ratings are appropriate to a multitrait-multimethod matrix in which each rater might be regarded as representing a different method. While the published report does not make these available in detail because it employs averaged values, it is apparent from a comparison of his Tables IV and VIII that the ratings generally failed to meet the requirement that ratings of the same trait by different raters should correlate higher than ratings of different traits by the same rater. Validity is shown to the extent that of the correlations in the heteromethod block, those in the validity diagonal are higher than the average heteromethod-heterotrait values. A conspicuously unsuccessful multitrait-multimethod matrix is provided by Campbell (1953, 1956) for rating of the leadership behavior of officers by themselves and by their subordinates. Only one of 11 variables (Recognition Behavior) met the requirement of providing a validity diagonal value higher than any of the heterotrait-heteromethod values, that validity being .29. For none of the variables were the validities higher than heterotrait-monomethod values. A study of attitudes toward authority and nonauthority figures by Burwen and Campbell (1957) contains a complex multitrait-multimethod matrix, one symmetrical excerpt from which is shown in Table 6. Method variance was strong for most of the procedures in this study. Where validity was found, it was primarily at the level of validity diagonal values higher than heterotrait-heteromethod values. As illustrated in Table 6, attitude toward father showed this kind of validity, as did attitude toward peers to a lesser degree. Attitude toward boss showed no validity. There was no evidence of a generalized attitude toward authority which would include father and boss, although such values as the VALIDATION BY THE MULTITRAIT-MULTIMETHOD MATRIX\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Resource-efficient convolution neural networks enable not only the intelligence on edge devices but also opportunities in system-level optimization such as scheduling. In this work, we aim to improve the performance of resource-constrained filter pruning by merging two sub-problems commonly considered, i.e., (i) how many filters to prune for each layer and (ii) which filters to prune given a per-layer pruning budget, into a global filter ranking problem. Our framework entails a novel algorithm, dubbed layer-compensated pruning, where meta-learning is involved to determine better solutions. We show empirically that the proposed algorithm is superior to prior art in both effectiveness and efficiency. Specifically, we reduce the accuracy gap between the pruned and original networks from 0.9% to 0.7% with 8x reduction in time needed for meta-learning, i.e., from 1 hour down to 7 minutes. To this end, we demonstrate the effectiveness of our algorithm using VGG, ResNet, and MobileNetV2 networks under CIFAR-10, ImageNet, and Bird-200 datasets.', 'positives': ['Neural Architecture Search (NAS) is a laborious process. Prior work on automated NAS targets mainly on improving accuracy, but lacks consideration of computational resource use. We propose the Resource-Efficient Neural Architect (RENA), an efficient resource-constrained NAS using reinforcement learning with network embedding. RENA uses a policy network to process the network embeddings to generate new configurations. We demonstrate RENA on image recognition and keyword spotting (KWS) problems. RENA can find novel architectures that achieve high performance even with tight resource constraints. For CIFAR10, it achieves 2.95% test error when compute intensity is greater than 100 FLOPs/byte, and 3.87% test error when model size is less than 3M parameters. For Google Speech Commands Dataset, RENA achieves the state-of-the-art accuracy without resource constraints, and it outperforms the optimized architectures with tight resource constraints.'], 'negatives': ['1College of Mathematics and Informatics, Fujian Normal University, Fuzhou 350117, Fujian, China 2College of Computer and Information, Hohai University, Nanjing 211100, Jiangsu, China 3Jiangsu Key Laboratory of Big Data Security & Intelligent Processing, Nanjing University of Posts and Telecommunications, China 4Mathematics and Computer Science Department, Gannan Normal University, Ganzhou 341000, Jiangxi, China'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Movement primitive segmentation enables long sequences of human movement observation data to be segmented into smaller components, termed movement primitives, to facilitate movement identification, modeling, and learning. It has been applied to exercise monitoring, gesture recognition, human-machine interaction, and robot imitation learning. This paper proposes a segmentation framework to categorize and compare different segmentation algorithms considering segment definitions, data sources, application-specific requirements, algorithm mechanics, and validation techniques. The framework is applied to human motion segmentation methods by grouping them into online, semionline, and offline approaches. Among the online approaches, distance-based methods provide the best performance, while stochastic dynamic models work best in the semionline and offline settings. However, most algorithms to date are tested with small datasets, and algorithm generalization across participants and to movement changes remains largely untested.', 'positives': [], 'negatives': ['We present a novel method for approximately equilibrating a matrix using only multiplication by the matrix and its transpose. Our method is based on convex optimization and projected stochastic gradient descent, using an unbiased estimate of a gradient obtained by a randomized method. Our method provably converges in expectation and empirically gets good results with a small number of iterations. We show how the method can be applied as a preconditioner for matrix-free iterative algorithms, substantially reducing the iterations required to reach a given level of precision. We also derive a novel connection between equilibration and condition number, showing that equilibrationminimizes an upper bound on the condition number over all choices of row and column scalings.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Purpose – Despite much research on supply chain (SC) integration and the growing emphasis on recent information technology advancements as an enabler of improved performance, there has been limited research focussed specifically on information integration in supply chains (SCs). The purpose of this paper is to systematically review the literature on information integration in the fresh food supply chain (FFSC) from a holistic perspective. Design/methodology/approach – Literature review is done by systematically collecting and analysing the recent literature to identify various participant entities of the FFSC information network and their specific information needs. Findings – The information needs of FFSC entities are diverse but the needs are common across multiple entities. Research limitations/implications – This study only reviewed the FFSC-related literature; an extended study of the food industry may reveal a more comprehensive view. Practical implications – These findings are useful for practitioners in understanding the participant entities in the information network and their information needs and for policymakers in formulating FFSC development initiatives. Originality/value – The authors are not aware of another study that investigates the FFSC in a holistic approach, one that identifies the actors, their interactions and information needs.', 'positives': ['Many companies have embarked on initiatives that enable more demand information sharing between retailers and their upstream suppliers. While the literature on such initiatives in the business press is proliferating, it is not clear how one can quantify the benefits of these initiatives and how one can identify the drivers of the magnitudes of these benefits. Using analytical models, this paper aims at addressing these questions for a simple two-level supply chain with nonstationary end demands. Our analysis suggests that the value of demand information sharing can be quite high, especially when demands are significantly correlated over time. (Supply Chain Management; Mathematical Models; Production Planning and Inventory Control; Approximate Analysis; Electronic Data Interchange; Quick Response; Information Sharing)'], 'negatives': ['Utility functions provide a natural and advantageous framework for achieving self-optimization in distributed autonomic computing systems. We present a distributed architecture, implemented in a realistic prototype data center, that demonstrates how utility functions can enable a collection of autonomic elements to continually optimize the use of computational resources in a dynamic, heterogeneous environment. Broadly, the architecture is a two-level structure of independent autonomic elements that supports flexibility, modularity, and self-management. Individual autonomic elements manage application resource usage to optimize local service-level utility functions, and a global arbiter allocates resources among application environments based on resource-level utility functions obtained from the managers of the applications. We present empirical data that demonstrate the effectiveness of our utility function scheme in handling realistic, fluctuating Web-based transactional workloads running on a Linux cluster.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Collaborative systems will form the warp for smart networked environments wherein humans, organizations, intelligent agents, and devices collaborate. The smart environments of near future will be context sensitive systems within which the physical world is richly and transparently interwoven with sensors, actuators, and computational elements that seamlessly embed everyday objects and interconnect them through networks. Modeling, design, and development of collaborative systems in this context will support a large number of emerging applications including security, care and assistance, transportation, construction, sustainability and energy management, education, government, and manufacturing. In this context, a brief survey of trends and challenges is presented.', 'positives': ['Software engineering projects are inherently cooperative, requiring many software engineers to coordinate their efforts to produce a large software system. Integral to this effort is developing shared understanding surrounding multiple artifacts, each artifact embodying its own model, over the entire development process. This focus on model- oriented collaboration embedded within a larger process is what distinguishes collaboration research in software engineering from broader collaboration research, which tends to address artifact-neutral coordination technologies and toolkits. This article first presents a list of goals for software engineering collaboration, then surveys existing collaboration support tools in software engineering. The survey covers both tools that focus on a single artifact or stage in the development process (requirements support tools, UML collaboration tools), and tools that support the representation and execution of an entire software process. Important collaboration standards are also described. Several possible future directions for collaboration in software engineering are presented, including tight integration between web and desktop development environments, broader participation by customers and end users in the entire development process, capturing argumentation surrounding design rationale, and use of massively multiplayer online (MMO) game technology as a collaboration medium. The article concludes by noting a problem in performing research on collaborative systems, that of assessing how well certain artifacts, models, and embedded processes work, and whether they are better than other approaches.'], 'negatives': [\"Today's production vehicles are fitted with a multitude of antennas to facilitate communication and enable a moving vehicle to connect with the outside world. Recent years have seen the introduction of new electronic devices to the automotive environment. These devices are usually designed to aid the driver, increase safety, or enhance the driving experience, and many of them rely on wireless communication to perform their task. Antennas are a necessary part of any wireless communication system, enabling transmission and reception of signals in free-space. At the same time, automobile manufacturers have been seeking to create cost effective, fuel efficient vehicles with attractive styling. This leads to a focus on sleek, lightweight vehicles with reduced aerodynamic drag and improved styling an emphasis that would naturally conflict with fitment of traditional antennas. These market preferences, along with the technological factors, have combined in the past few years to drive significant innovation in the world of vehicular antennas. In this chapter, we review the basics of antennas and radiation and examine the frequencies and services which are commonly used in the automotive environment. We will briefly discuss the antennas traditionally used on vehicles, and then detail the recent developments and trends in automotive antenna research.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Common-sense physical reasoning is an essential ingredient for any intelligent agent operating in the real-world. For example, it can be used to simulate the environment, or to infer the state of parts of the world that are currently unobserved. In order to match real-world conditions this causal knowledge must be learned without access to supervised data. To solve this problem, we present a novel method that incorporates prior knowledge about the compositional nature of human perception to factor interactions between object-pairs and to learn them efficiently. It learns to discover objects and to model physical interactions between them from raw visual images in a purely unsupervised fashion. On videos of bouncing balls we show the superior modelling capabilities of our method compared to other unsupervised neural approaches, that do not incorporate such prior knowledge. We show its ability to handle occlusion and that it can extrapolate learned knowledge to environments with different numbers of objects.', 'positives': ['In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.'], 'negatives': ['Emojis are small images that are commonly included in social media text messages. The combination of visual and textual content in the same message builds up a modern way of communication, that automatic systems are not used to deal with. In this paper we extend recent advances in emoji prediction by putting forward a multimodal approach that is able to predict emojis in Instagram posts. Instagram posts are composed of pictures together with texts which sometimes include emojis. We show that these emojis can be predicted by using the text, but also using the picture. Our main finding is that incorporating the two synergistic modalities, in a combined model, improves accuracy in an emoji prediction task. This result demonstrates that these two modalities (text and images) encode different information on the use of emojis and therefore can complement each other.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Quick UDP Internet Connection (QUIC) is a recent protocol initiated by Google that combines the functions of HTTP/2, TLS, and TCP directly over UDP, with the goal to reduce the latency of client-server communication. It can replace the traditional HTTP/TLS/TCP stack and the IETF has chartered a working group to standardize it. QUIC encrypts all data and most protocol headers to prevent interferences from middleboxes.\\n Motivated by the success of Multipath TCP (MPTCP), we design Multipath QUIC (MPQUIC), a QUIC extension that enables a QUIC connection to use different paths such as WiFi and LTE on smartphones, or IPv4 and IPv6 on dual-stack hosts. We implement MPQUIC as an extension of the quic-go implementation. We evaluate the benefits of QUIC and MPQUIC by comparing them with TCP and MPTCP in a variety of settings. MPQUIC maintains MPTCP's benefits (aggregation benefit, network handover). Without packet losses, while performance of single-path TCP and single-path QUIC are similar, MPQUIC can outperform MPTCP. In lossy scenarios, (MP)QUIC is more suited than (MP)TCP.\", 'positives': ['Over the past two or three years, wireless cellular networks have become faster than before, most notably due to the deployment of LTE, HSPA+, and other similar networks. LTE throughputs can reach many megabits per second and can even rival WiFi throughputs in some locations. This paper addresses a fundamental question confronting transport and application-layer protocol designers: which network should an application use? WiFi, LTE, or Multi-Path TCP (MPTCP) running over both?\\n We compare LTE and WiFi for transfers of different sizes along both directions (i.e. the uplink and the downlink) using a crowd-sourced mobile application run by 750 users over 180 days in 16 different countries. We find that LTE outperforms WiFi 40\\\\% of the time, which is a higher fraction than one might expect at first sight.\\n We measure flow-level MPTCP performance and compare it with the performance of TCP running over exclusively WiFi or LTE in 20 different locations across 7 cities in the United States. For short flows, we find that MPTCP performs worse than regular TCP running over the faster link; further, selecting the correct network for the primary subflow in MPTCP is critical in achieving good performance. For long flows, however, selecting the proper MPTCP congestion control algorithm is equally important.\\n To complement our flow-level analysis, we analyze the traffic patterns of several mobile apps, finding that apps can be categorized as \"short-flow dominated\" or \"long-flow dominated\". We then record and replay these patterns over emulated WiFi and LTE links. We find that application performance has a similar dependence on the choice of networks as flow-level performance: an application dominated by short flows sees little gain from MPTCP, while an application with longer flows can benefit much more from MPTCP --- if the application can pick the right network for the primary subflow and the right choice of MPTCP congestion control.'], 'negatives': ['This paper proposes a 1MHz resonant DC transformer (DCX) with output regulation capability based on the traditional LLC resonant converter. The proposed regulated DCX (RDCX) has a configuration with an auxiliary transformer in series with the main transformer at primary side but independent at the secondary side. And, the auxiliary transformer creates an output to feed the cascaded PWM dc-dc converter. Since the output of the PWM dc-dc converter is parallel with the main output, the tight regulation of output voltage can be realized by adjusting the duty cycle of the auxiliary dc-dc stage. The majority of power is delivered to load through the main transformer, and only small portion of power is converted by two-stage. Therefore, the total conversion efficiency is almost as high as conventional LLC-DCX. The steady state operating principle of the proposed converter is analyzed and a 1MHz prototype is built-up to verify the theoretical analysis in this paper.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Since large scaled software models typically exist in many revisions, extraction and representation of differences between versions is a crucial issue of model version systems. While handling model differences is playing an important role in evolution of models, there is a need for appropriate techniques to represent model differences. This paper shows a meta-model-generic and transformation based approach to the representation of model differences. Domain specific languages are generated to represent model differences. Differences are mapped to a set of model transformation rules. To demonstrate the approach, it is applied to activity diagrams.', 'positives': ['It is of critical relevance that designers are able to comprehend the various kinds of design-level modifications that a system undergoes throughout its entire lifecycle. In this respect, an interesting and useful operation between subsequent system versions is the model difference calculation and representation. In this paper, a metamodel independent approach to the representation of model differences which is agnostic of the calculation method is presented. Given two models which conform to a metamodel, their difference is conforming to another metamodel derived from the former by an automated transformation. Difference models are first-class entities which induce transformations able to apply the modifications they specify. Finally, difference models can be composed sequentially and in parallel giving place to more complex modifications.'], 'negatives': ['This paper presents an online method for the estimation of the state of health (SOH) of valve-regulated lead acid (VRLA) batteries. The proposed method is based on the state of charge (SOC) of the battery. The SOC is estimated using the extended Kalman filter and a neural-network model of the battery. Then, the SOH is estimated online based on the relationship between the SOC and the battery open-circuit voltage using fuzzy logic and the recursive least squares method. To obtain the open-circuit voltage while the battery is operating, the reflective charging process is employed. Experimental results show good estimation of the SOH of VRLA batteries.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"This work is about a novel methodology for window detection in urban environments and its multiple use in vision system applications. The presented method for window detection includes appropriate early image processing, provides a multi-scale Haar wavelet representation for the determination of image tiles which is then fed into a cascaded classifier for the task of window detection. The classifier is learned from a Gentle Adaboost driven cascaded decision tree on masked information from training imagery and is tested towards window based ground truth information which is together with the original building image databases publicly available. The experimental results demonstrate that single window detection is to a sufficient degree successful, e.g., for the purpose of building recognition, and, furthermore, that the classifier is in general capable to provide a region of interest operator for the interpretation of urban environments. The extraction of this categorical information is beneficial to index into search spaces for urban object recognition as well as aiming towards providing a semantic focus for accurate post-processing in 3D information processing systems. Targeted applications are (i) mobile services on uncalibrated imagery, e.g., for tourist guidance, (ii) sparse 3D city modelling, and (iii) deformation analysis from high resolution imagery. * This work is funded by the European Commission's project MOBVIS (FP6-511051), the FWF Austrian research project Multi Sensor Deformation Measurement System Supported by Knowledge Based and Cognitive Vision Techniques'' (P18286-N04).\", 'positives': ['We present a computer vision system for the detection and identification of urban objects from mobile phone imagery, e.g., for the application of tourist information services. Recognition is based on MAP decision making over weak object hypotheses from local descriptor responses in the mobile imagery. We present an improvement over the standard SIFT key detector [7] by selecting only informative (i-SIFT) keys for descriptor matching. Selection is applied first to reduce the complexity of the object model and second to accelerate detection by selective filtering. We present results on the MPG-20 mobile phone imagery with severe illumination, scale and viewpoint changes in the images, performing with ≈ 98% accuracy in identification, efficient (100%) background rejection, efficient (0%) false alarm rate, and reliable quality of service under extreme illumination conditions, significantly improving standard SIFT based recognition in every sense, providing - important for mobile vision - runtimes which are ≈ 8 (≈24) times faster for the MPG-20 (ZuBuD) database.'], 'negatives': ['Overview It is often important that searches be fast. AI has developed several ways of speeding up searches by trading off the search time and the cost of the resulting path, which includes using inadmissible heuristics (Pohl 1973, 1970) and search with limited look ahead (Korf 1990; Ishida and Korf 1991; Koenig 2001), which is also called real-time or agent-centered search. In this article, we discuss a different way of speeding up searches, namely, incremental search. Incremental search is a search technique for continual planning (or, synonymously, replanning, plan reuse, and lifelong planning) that reuses information from previous searches to find solutions to a series of similar search problems potentially faster than is possible by solving each search problem from scratch. Different from other ways of speeding up searches, it can guarantee to find the shortest paths. Notice that the terminology is unfortunately somewhat problematic because the term incremental search in computer science also refers to both online search and search with limited look ahead (Pemberton and Korf 1994). Most of the research on search has studied how to solve one-time search problems. However, many AI systems have to adapt their plans continuously to changes in the world or changes of their models of the world, for example, because the actual situation turns out to be slightly different from the one initially assumed or because the situation changes over time. In these cases, the original plan might no longer apply or might no longer be good, and one thus needs to replan for the new situation (desJardins et al. 1999). Similarly, one needs to solve a series of similar search problems if one wants to perform a series of what-if analyses or if the costs of planning operators, their preconditions, or their effects change over time because they are learned or refined. In these situations, most search algorithms replan from scratch, that is, solve the new search problem independently of the old ones. However, this approach can be inefficient in large domains with frequent changes and, thus, limit the responsiveness of AI systems or the number of what-if analyses that they can perform. Fortunately, the changes to the search problems are usually small. A robot, for example, might have to replan when it detects a previously unknown obstacle, a traffic routing system might have to replan when it learns about a new traffic jam, and a decision support system for marine oil spill containment might have to replan when the wind direction changes. This property suggests that a complete recomputation of the best plan for the new search problem is unnecessary because some of the previous search results can be reused, which is what incremental search does. Incremental search solves dynamic shortestpath problems, where shortest paths have to be found repeatedly as the topology of a graph or its edge costs change (Ramalingam and Reps 1996b). The idea of incremental search is old. For example, an overview article about shortest-path algorithms from 1984 already cites several incremental search algorithms, including several ones published in the late 1960s Articles'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We propose a novel Large-Scale Direct SLAM algorithm for stereo cameras (Stereo LSD-SLAM) that runs in real-time at high frame rate on standard CPUs. In contrast to sparse interest-point based methods, our approach aligns images directly based on the photoconsistency of all high-contrast pixels, including corners, edges and high texture areas. It concurrently estimates the depth at these pixels from two types of stereo cues: Static stereo through the fixed-baseline stereo camera setup as well as temporal multi-view stereo exploiting the camera motion. By incorporating both disparity sources, our algorithm can even estimate depth of pixels that are under-constrained when only using fixed-baseline stereo. Using a fixed baseline, on the other hand, avoids scale-drift that typically occurs in pure monocular SLAM.We furthermore propose a robust approach to enforce illumination invariance, capable of handling aggressive brightness changes between frames - greatly improving the performance in realistic settings. In experiments, we demonstrate state-of-the-art results on stereo SLAM benchmarks such as Kitti or challenging datasets from the EuRoC Challenge 3 for micro aerial vehicles.', 'positives': ['We describe a new formulation of appearance-only SLAM suitable for very large scale place recognition. The system navigates in the space of appearance, assigning each new observation to either a new or previously visited location, without reference to metric position. The system is demonstrated performing reliable online appearance mapping and loop closure detection over a 1,000 km trajectory, with mean filter update times of 14 ms. The scalability of the system is achieved by defining a sparse approximation to the FAB-MAP model suitable for implementation using an inverted index. Our formulation of the problem is fully probabilistic and naturally incorporates robustness against perceptual aliasing. We also demonstrate that the approach substantially outperforms the standard tf-idf ranking measure. The 1,000 km data set comprising almost a terabyte of omni-directional and stereo imagery is available for use, and we hope that it will serve as a benchmark for future systems.'], 'negatives': ['This work studies the task of automatic emotion detection in music. Music may evoke more than one different emotion at the same time. Single-label classification and regression cannot model this multiplicity. Therefore, this work focuses on multi-label classification approaches, where a piece of music may simultaneously belong to more than one class. Seven algorithms are experimentally compared for this task. Furthermore, the predictive power of several audio features is evaluated using a new multi-label feature selection method. Experiments are conducted on a set of 593 songs with six clusters of emotions based on the Tellegen-Watson-Clark model of affect. Results show that multi-label modeling is successful and provide interesting insights into the predictive quality of the algorithms and features.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The past years have seen a growing amount of research on question answering (QA) over Semantic Web data, shaping an interaction paradigm that allows end users to profit from the expressive power of Semantic Web standards while, at the same time, hiding their complexity behind an intuitive and easy-to-use interface. On the other hand, the growing amount of data has led to a heterogeneous data landscape where QA systems struggle to keep up with the volume, variety and veracity of the underlying knowledge. The Question Answering over Linked Data (QALD) challenge aims at providing an up-to-date benchmark for assessing and comparing state-of-the-artsystems that mediate between a user, expressing his or her information need in natural language, and RDF data. It thus targets all researchers and practitioners working on querying Linked Data, natural language processing for question answering, multilingual information retrieval and related topics. The main goal is to gain insights into the strengths and shortcomings of different approaches and into possible solutions for coping with the large, heterogeneous and distributed nature of Semantic Web data. QALD has a 6-year history of developing a benchmark that is increasingly being used as standard evaluation tool for question answering over Linked Data. Overviews of the past instantiations of the challenge are available from the CLEF Working Notes as well as ESWC proceedings:', 'positives': ['RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by RDF. To answer a national language question, the existing work takes a two-stage approach: question understanding and query evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when matches of query are found. The cost of disambiguation is saved if there are no matching found. We compare our method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments confirm that our method not only improves the precision but also speeds up query performance greatly.'], 'negatives': ['Threshold functions and Artificial Neural Networks (ANNs) are known for many years and have been thoroughly analyzed. The primary interest of these paper is to implement the basic logic gates of AND and EXOR by Artificial Neuron Network using Perceptron, and Threshold elements as Neuron output functions. The McCulloch-Pitts neural model was applied as linear threshold gate. The linear threshold gate was used to classify the set of inputs (\\uf0631, \\uf0632) into two classes, which yielded a binary output, \\uf043. The weighted values Ɯ1,Ɯ2, were normalized in the ranges of either (0,1) or (-1,1) and associated with each input line (\\uf0631, \\uf0632), sum is the weighted sum, and T is a threshold constant. With the binary inputs of \\uf0631, \\uf0632 = 0 or 1, the weights Ɯ1,Ɯ2 = 1, and an offset -1.5, weighted summation as propagation; the output of the binary AND function unit was defined as \\uf043 = \\uf0a6 (-1.5 + \\uf0631 + \\uf0632), with \\uf0a6 (\\uf063) = 0 ∀\\uf063 < 0 and \\uf0a6 (\\uf063) = 1 ∀\\uf063 ≥ 0.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Multilevel converters and battery energy storage systems are key components in present and future medium voltage networks, where an important integration of renewable energy sources takes place. The modular multilevel converter offers the capability of embedding such energy storage elements in a split manner, given the existence of several submodules operating at significantly lower voltages. This paper analyzes such a converter structure under different operating modes. In order to eliminate the low-frequency components of the submodule output currents, the latter are interfaced to the batteries by means of nonisolated dc/dc converters. Control algorithms are developed for the balancing of the battery state of charges and the respective gain limitations are established. Unbalanced grid conditions are also taken into account through the theory of symmetrical components and solutions are proposed. Finally, the development of a down-scaled prototype is described and experimental results are presented.', 'positives': [\"This paper deals with a crucial aspect in the control of grid-connected power converters, i.e., the detection of the fundamental-frequency positive-sequence component of the utility voltage under unbalanced and distorted conditions. Specifically, it proposes a positive-sequence detector based on a new decoupled double synchronous reference frame phase-locked loop (DDSRF-PLL), which completely eliminates the detection errors of conventional synchronous reference frame PLL's (SRF-PLL). This is achieved by transforming both positive- and negative-sequence components of the utility voltage into the double SRF, from which a decoupling network is developed in order to cleanly extract and separate the positive- and negative-sequence components. The resultant DDSRF-PLL conducts then to a fast, precise, and robust positive-sequence voltage detection even under unbalanced and distorted grid conditions. The paper presents a detailed description and derivation of the proposed detection method, together with an extensive evaluation using simulation and experimental results from a digital signal processor-based laboratory prototype in order to verify and validate the excellent performance achieved by the DDSRF-PLL\"], 'negatives': ['Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Car detection and identification is an important task in the area of traffic control and management. Typically, to tackle this task, large datasets and domain-specific features are used to best fit the data. In our project, we implement, train, and test several state-of-the-art classifiers trained on domain-general datasets for the task of identifying the make and models of cars from various angles and different settings, with the added constraint of limited data and time. We experiment with different levels of transfer learning for fitting these models over to our domain. We report and compare these results to that of baseline models, and discuss the advantages of this approach.', 'positives': ['Subordinate-level categorization typically rests on establishing salient distinctions between part-level characteristics of objects, in contrast to basic-level categorization, where the presence or absence of parts is determinative. We develop an approach for subordinate categorization in vision, focusing on an avian domain due to the fine-grained structure of the category taxonomy for this domain. We explore a pose-normalized appearance model based on a volumetric poselet scheme. The variation in shape and appearance properties of these parts across a taxonomy provides the cues needed for subordinate categorization. Training pose detectors requires a relatively large amount of training data per category when done from scratch; using a subordinate-level approach, we exploit a pose classifier trained at the basic-level, and extract part appearance and shape information to build subordinate-level models. Our model associates the underlying image pattern parameters used for detection with corresponding volumetric part location, scale and orientation parameters. These parameters implicitly define a mapping from the image pixels into a pose-normalized appearance space, removing view and pose dependencies, facilitating fine-grained categorization from relatively few training examples.'], 'negatives': ['This article may be used for research, teaching, and private study purposes. Any substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing, systematic supply, or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae, and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand, or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Record linkage has received significant attention in recent years due to the plethora of data sources that have to be integrated to facilitate data analyses. In several cases, such an integration involves disparate data sources containing huge volumes of records and must be performed in near real-time in order to support critical applications. In this paper, we propose the first summarization algorithms for speeding up online record linkage tasks. Our first method, called SkipBloom, summarizes efficiently the participating data sets, using their blocking keys, to allow for very fast comparisons among them. The second method, called BlockSketch, summarizes a block to achieve a constant number of comparisons for a submitted query record, during the matching phase. Additionally, we extend BlockSketch to adapt its functionality to streaming data, where the objective is to use a constant amount of main memory to handle potentially unbounded data sets. Through extensive experimental evaluation, using three real-world data sets, we demonstrate the superiority of our methods against two state-of-the-art algorithms for online record linkage.', 'positives': ['Often, in the real world, entities have two or more representations in databases. Duplicate records do not share a common key and/or they contain errors that make duplicate matching a difficult task. Errors are introduced as the result of transcription errors, incomplete information, lack of standard formats, or any combination of these factors. In this paper, we present a thorough analysis of the literature on duplicate record detection. We cover similarity metrics that are commonly used to detect similar field entries, and we present an extensive set of duplicate detection algorithms that can detect approximately duplicate records in a database. We also cover multiple techniques for improving the efficiency and scalability of approximate duplicate detection algorithms. We conclude with coverage of existing tools and with a brief discussion of the big open problems in the area'], 'negatives': ['Many important problems involve clustering large datasets. Although naive implementations of clustering are computationally expensive, there are established efficient techniques for clustering when the dataset has either (1) a limited number of clusters, (2) a low feature dimensionality, or (3) a small number of data points. However, there has been much less work on methods of efficiently clustering datasets that are large in all three ways at once—for example, having millions of data points that exist in many thousands of dimensions representing many thousands of clusters. We present a new technique for clustering these large, highdimensional datasets. The key idea involves using a cheap, approximate distance measure to efficiently divide the data into overlapping subsets we call canopies. Then clustering is performed by measuring exact distances only between points that occur in a common canopy. Using canopies, large clustering problems that were formerly impossible become practical. Under reasonable assumptions about the cheap distance metric, this reduction in computational cost comes without any loss in clustering accuracy. Canopies can be applied to many domains and used with a variety of clustering approaches, including Greedy Agglomerative Clustering, K-means and Expectation-Maximization. We present experimental results on grouping bibliographic citations from the reference sections of research papers. Here the canopy approach reduces computation time over a traditional clustering approach by more than an order of magnitude and decreases error in comparison to a previously used algorithm by 25%.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Attributed networks consist of not only a network structure but also node attributes. Most existing community detection algorithms only focus on network structures and ignore node attributes, which are also important. Although some algorithms using both node attributes and network structure information have been proposed in recent years, the complex hierarchical coupling relationships within and between attributes, nodes and network structure have not been considered. Such hierarchical couplings are driving factors in community formation. This paper introduces a novel coupled node similarity (CNS) to involve and learn attribute and structure couplings and compute the similarity within and between nodes with categorical attributes in a network. CNS learns and integrates the frequency-based intra-attribute coupled similarity within an attribute, the co-occurrence-based inter-attribute coupled similarity between attributes, and coupled attribute-to-structure similarity based on the homophily property. CNS is then used to generate the weights of edges and transfer a plain graph to a weighted graph. Clustering algorithms detect community structures that are topologically well-connected and semantically coherent on the weighted graphs. Extensive experiments verify the effectiveness of CNS-based community detection algorithms on several data sets by comparing with the state-of-the-art node similarity measures, whether they involve node attribute information and hierarchical interactions, and on various levels of network structure complexity.', 'positives': ['We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection method in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analyzing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad-hoc modular networks.'], 'negatives': ['We propose a novel mechanism to infer topics of interest of individual users in the Twitter social network. We observe that in Twitter, a user generally follows experts on various topics of her interest in order to acquire information on those topics. We use a methodology based on social annotations (proposed earlier by us) to first deduce the topical expertise of popular Twitter users, and then transitively infer the interests of the users who follow them. This methodology is a sharp departure from the traditional techniques of inferring interests of a user from the tweets that she posts or receives. We show that the topics of interest inferred by the proposed methodology are far superior than the topics extracted by state-of-the-art techniques such as using topic models (Labeled LDA) on tweets. Based upon the proposed methodology, we build a system Who Likes What, which can infer the interests of millions of Twitter users. To our knowledge, this is the first system that can infer interests for Twitter users at such scale. Hence, this system would be particularly beneficial in developing personalized recommender services over the Twitter platform.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this work we present a novel compact scene representation based on Stixels that infers geometric and semantic information. Our approach overcomes the previous rather restrictive geometric assumptions for Stixels by introducing a novel depth model to account for non-flat roads and slanted objects. Both semantic and depth cues are used jointly to infer the scene representation in a sound global energy minimization formulation. Furthermore, a novel approximation scheme is introduced that uses an extremely efficient over-segmentation. In doing so, the computational complexity of the Stixel inference algorithm is reduced significantly, achieving real-time computation capabilities with only a slight drop in accuracy. We evaluate the proposed approach in terms of semantic and geometric accuracy as well as run-time on four publicly available benchmark datasets. Our approach maintains accuracy on flat road scene datasets while improving substantially on a novel non-flat road dataset.', 'positives': ['Occupancy grid mapping is a well-known environment perception approach. A grid map divides the environment into cells and estimates the occupancy probability of each cell based on sensor measurements. An important extension is the Bayesian occupancy filter (BOF), which additionally estimates the dynamic state of grid cells and allows modeling changing environments. In recent years, the BOF attracted more and more attention, especially sequential Monte Carlo implementations (SMC-BOF), requiring less computational costs. An advantage compared to classical object tracking approaches is the object-free representation of arbitrarily shaped obstacles and free-space areas. Unfortunately, publications about BOF based on laser measurements report that grid cells representing big, contiguous, stationary obstacles are often mistaken as moving with the velocity of the ego vehicle (ghost movements). This paper presents a method to fuse laser and radar measurement data with the SMC-BOF. It shows that the doppler information of radar measurements significantly improves the dynamic estimation of the grid map, reduces ghost movements, and in general leads to a faster convergence of the dynamic estimation.'], 'negatives': ['Elliptic Curve Cryptography is an approach to cryptography based on the usage of elliptic curves over finite fields. This approach allows for smaller key sizes when compared to other schemes in cryptography such as the RSA, while keeping the same level of security. The Elliptic Curve Digital Signature Algorithm (ECDSA) is the most widely used standardized elliptic curve-based signature scheme [5], with applications in diverse fields. One modern application of the ECDSA is found in the Bitcoin protocol, which has seen a surge in popularity as an open source, digital currency. The total value of existing Bitcoins is estimated at over 4.5 billion USD by November, 2015 [13], creating the need for a secure means of transaction and handling.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We determine optimal trading strategies for liquidation of a large single-asset portfolio to minimize a combination of volatility risk and market impact costs. We take the market impact cost per share to be a power law function of the trading rate, with an arbitrary positive exponent. This includes, for example, the square-root law that has been proposed based on market microstructure theory. In analogy to the linear model, we define a “characteristic time” for optimal trading, which now depends on the initial portfolio size and decreases as execution proceeds. We also consider a model in which uncertainty of the realized price is increased by demanding rapid execution; we show that optimal trajectories are described by a “critical portfolio size” above which this effect is dominant and below which it may be neglected.', 'positives': ['We consider the execution of portfolio transactions with the aim of minimizing a combination of volatility risk and transaction costs arising from permanent and temporary market impact. For a simple linear cost model, we explicitly construct the e cient frontier in the space of time-dependent liquidation strategies, which have minimum expected cost for a given level of uncertainty. This analysis yields a number we call the \\\\half-life\" of a trade, the natural time for execution in the absence of exogeneous time constraints. We also construct optimal strategies for trading through scheduled news events such as earnings announcements. We thank Andrew Alford, Alix Baudin, Mark Carhart, Ray Iwanowski, and Giorgio De Santis (Goldman Sachs Asset Management), Robert Ferstenberg (ITG), Michael Weber (Merrill Lynch), Andrew Lo (Sloan School, MIT), and George Constaninides (Graduate School of Business, University of Chicago) for helpful conversations. This paper was begun while the second author was employed at Morgan Stanley Dean Witter The University of Chicago, Department of Mathematics, 5734 S. University Ave., Chicago IL 60637; almgren@math.uchicago.edu Goldman Sachs Asset Management and Courant Institute of Mathematical Sciences; Neil.Chriss@gs.com'], 'negatives': ['Career guidance and counselling in the western world, most notably in the United States (USA), has developed a comprehensive system of theories and intervention strategies in its more than 100 years of history. It began in the years of Frank Parson as a trait-factor approach in the early twentieth century (Betz, Fitzgerald, & Hill, 1989; Zunker, 2002), and slowly evolved to become a rather mature discipline today in the twenty-first century with a strong theoretical and empirical base, with the potential to further develop into a more “global” discipline in the years ahead. Indeed, vocational and career related issues are salient across different cultures and nationalities (Hesketh & Rounds, 1995; Leung, 2004). In an age of economic globalisation, all individuals are affected by an array of work related concerns, some of these concerns are unique to certain cultures, but others are common to many cultural groups. The search for life purposes and meanings, the journey to actualise oneself through various life and workrelated roles, and the efforts by nations to deal with problems of employment and unemployment, are examples of universal issues that seem to affect many individuals from diverse cultures. Under the theme of career development, there are experiences, concerns, and issues that we could share, explore, and discussed at a global stage (Richardson, 1993; Lips-Wiersma & McMorland, 2006). The development of career guidance and development into a global discipline requires a set of theoretical frameworks with universal validity and applications, as well as culture-specific models that could be used to explain career development issues and phenomenon at a local level. The focus of this chapter is on the five theories of career development that have guided career guidance and counselling practice and research in the past few decades in the USA as well as internationally. These five theories are (a) Theory of Work-Adjustment, (b) Holland’s Theory of Vocational Personalities in Work Environment, (c) the Self-concept Theory of Career Development formulated by Super and more recently by Savickas, (d) Gottfredson’s Theory of Circumscription and Compromise, and (e) Social Cognitive Career Theory. Given that the “big-five” theoretical models were developed by scholars in the USA, most of the existing reviews and summaries covering'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Navigation for autonomous underwater vehicles (AUVs) in mid-depth water column is notoriously challenging due to the lack of features for reference. In this paper, we propose a flow-aided cooperative navigation (FACON) strategy to improve the navigation performance of a team of AUVs when neither frequent surfacing nor persistent bottom-locking is available. Preloaded ocean current forecasts are referenced by each individual vehicle as it performs dead-reckoning with an inertial navigation system and measures relative current velocities during navigation. A marginalized particle filter is applied by each AUV to track its location, velocity, sensor biases, and local flow perturbation unresolved by the ocean forecast. Meanwhile, AUVs perform distributed cooperative localization based on relative pose measurements and asynchronized local communication when they enter the communication range of one another. Opportunistic information fusion among AUVs is realized through covariance intersection. The performance of the flow-aided navigation scheme of a single AUV is analyzed within a simulated experiment based on field test data. The feasibility of FACON is discussed through simulation in a turbulent, multi-gyre flow field.', 'positives': ['Autonomous underwater vehicle (AUV) navigation and localization in underwater environments is particularly challenging due to the rapid attenuation of Global Positioning System (GPS) and radio-frequency signals. Underwater communications are low bandwidth and unreliable, and there is no access to a global positioning system. Past approaches to solve the AUV localization problem have employed expensive inertial sensors, used installed beacons in the region of interest, or required periodic surfacing of the AUV. While these methods are useful, their performance is fundamentally limited. Advances in underwater communications and the application of simultaneous localization and mapping (SLAM) technology to the underwater realm have yielded new possibilities in the field. This paper presents a review of the state of the art of AUV navigation and localization, as well as a description of some of the more commonly used methods. In addition, we highlight areas of future research potential.'], 'negatives': ['Inspection of ship hulls and marine structures using autonomous underwater vehicles has emerged as a unique and challenging application of robotics. The problem poses rich questions in physical design and operation, perception and navigation, and planning, driven by difficulties arising from the acoustic environment, poor water quality and the highly complex structures to be inspected. In this paper, we develop and apply algorithms for the central navigation and planning problems on ship hulls. These divide into two classes, suitable for the open, forward parts of a typical monohull, and for the complex areas around the shafting, propellers and rudders. On the open hull, we have integrated acoustic and visual mapping processes to achieve closed-loop control relative to features such as weld-lines and biofouling. In the complex area, we implemented new large-scale planning routines so as to achieve full imaging coverage of all the structures, at a high resolution. We demonstrate our approaches in recent operations on naval ships.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We develop necessary and sufficient conditions and a novel provably consistent and efficient algorithm for discovering topics (latent factors) from observations (documents) that are realized from a probabilistic mixture of shared latent factors that have certain properties. Our focus is on the class of topic models in which each shared latent factor contains a novel word that is unique to that factor, a property that has come to be known as separability. Our algorithm is based on the key insight that the novel words correspond to the extreme points of the convex hull formed by the row-vectors of a suitably normalized word co-occurrence matrix. We leverage this geometric insight to establish polynomial computational and sample complexity bounds based on a few isotropic random projections of the rows of the normalized word co-occurrence matrix. Our proposed random-projections-based algorithm is naturally amenable to an efficient distributed implementation and is attractive for modern web-scale distributed data mining applications.', 'positives': ['Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data. Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{specific synonymy as well as with polysemous words. In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model. Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methods as well as over LSI. In particular, the combination of models with different dimensionalities has proven to be advantageous.'], 'negatives': ['The functioning of the cryptocurrency Bitcoin relies on the open availability of the entire history of its transactions. This makes it a particularly interesting socio-economic system to analyse from the point of view of network science. Here we analyse the evolution of the network of Bitcoin transactions between users. We achieve this by using the complete transaction history from December 5th 2011 to December 23rd 2013. This period includes three bubbles experienced by the Bitcoin price. In particular, we focus on the global and local structural properties of the user network and their variation in relation to the different period of price surge and decline. By analysing the temporal variation of the heterogeneity of the connectivity patterns we gain insights on the different mechanisms that take place during bubbles, and find that hubs (i.e., the most connected nodes) had a fundamental role in triggering the burst of the second bubble. Finally, we examine the local topological structures of interactions between users, we discover that the relative frequency of triadic interactions experiences a strong change before, during and after a bubble, and suggest that the importance of the hubs grows during the bubble. These results provide further evidence that the behaviour of the hubs during bubbles significantly increases the systemic risk of the Bitcoin network, and discuss the implications on public policy interventions.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Geographically dispersed teams are rarely 100% dispersed. However, by focusing on teams that are either fully dispersed or fully co-located, team research to date has lived on the ends of a spectrum at which relatively few teams may actually work. In this paper, we develop a more robust view of geographic dispersion in teams. Specifically, we focus on the spatialtemporal distances among team members and the configuration of team members across sites (independent of the spatial and temporal distances separating those sites). To better understand the nature of dispersion, we develop a series of five new measures and explore their relationships with communication frequency data from a sample of 182 teams (of varying degrees of dispersion) from a Fortune 500 telecommunications firm. We conclude with recommendations regarding the use of different measures and important questions that they could help address. Geographic Dispersion in Teams 1', 'positives': ['Global virtual teams are internationally distributed groups of people with an organizational mandate to make or implement decisions with international components and implications. They are typically assigned tasks that are strategically important and highly complex. They rarely meet in person, conducting almost all of their interaction and decision making using communications technology. Although they play an increasingly important role in multinational organizations, little systematic is known about their dynamics or effectiveness. This study built a grounded theory of global virtual team processes and performance over time. We built a template based on Adaptive Structuration Theory (DeSanctis and Poole 1994) to guide our research, and we conducted a case study, observing three global virtual teams over a period of 21 months. Data were gathered using multiple methods, and qualitative methods were used to analyze them and generate a theory of global virtual team dynamics and effectiveness. First, we propose that effective global virtual team interaction comprises a series of communication incidents, each configured by aspects of the team’s structural and process elements. Effective outcomes were associated with a fit among an interaction incident’s form, decision process, and complexity. Second, effective global virtual teams sequence these incidents to generate a deep rhythm of regular face-toface incidents interspersed with less intensive, shorter incidents using various media. These two insights are discussed with respect to other literature and are elaborated upon in several propositions. Implications for research and practice are also outlined. (Distributed Teams; Electronic Communication; Global Virtual Teams; Grounded Theory; Media Choice; Multicultural Teams; Temporal Rhythms) In multinational organizations, global teams increasingly make and implement important decisions. Just as technology facilitated information transmission around the world, it now enables globally distributed people to collaborate on issues and challenges facing a company at the international level (Harasim 1993, Ives and Jarvenpaa 1991). These global virtual teams were almost unheard of a decade ago, but today they serve as a critical mechanism for integrating information, making decisions, and implementing actions around the world (Canney Davison and Ward 1999). Global virtual teams are groups that (a) are identified by their organization(s) and members as a team; (b) are responsible for making and/or implementing decisions important to the organization’s global strategy; (c) use technology-supported communication substantially more than face-to-face communication; and (d) work and live in different countries. Lipnack and Stamps (1997) define a virtual team as ‘‘a group of people who interact through MARTHA L. MAZNEVSKI AND KATHERINE M. CHUDOBA Global Virtual Team Dynamics 474 ORGANIZATION SCIENCE/Vol. 11, No. 5, September–October 2000 interdependent tasks guided by common purpose’’ and work ‘‘across space, time, and organizational boundaries with links strengthened by webs of communication technologies.’’ Some authors reserve the term ‘‘virtual’’ for teams that never meet face-to-face (Canney Davison and Ward 1999, Jarvenpaa et al. 1998, Kristof et al. 1995), but most refer to a virtual relationship as one that is at least mostly conducted over technology (Geber 1995, Melymuka 1997b, Townsend et al. 1996, Young 1998). Kristof et al. (1995) and Jarvenpaa and Leidner (1998) describe global virtual teams as culturally diverse and geographically dispersed. We add that global virtual teams are also global in their task. Global strategies integrate a company’s resources, regions, and customer interfaces while maintaining local responsiveness where necessary (Bartlett and Ghoshal 1989, Ghoshal 1987, Kobrin 1991, Kogut 1985). Managers from around the world must build close networks and interact intensively to achieve a global strategy’s potential, functions served well by global virtual teams (Adler 1997, Bartlett and Ghoshal 1989). Empirical research on global virtual teams is limited to a few studies on specific elements of global virtual team process. Research on distributed teams’ use of communications technology is much more prolific, and studies on team dynamics are almost ubiquitous. When this literature is applied to global virtual teams the implications are often equivocal or even conflicting. When added together, the simple conclusions from single studies do not provide a well-integrated understanding of global virtual team process and performance. Conceptual Background This section reviews the literatures on technology-supported distributed teams and multinational teams, then summarizes Adaptive Structuration Theory. It concludes by describing the research template that guided our study’s data gathering and analysis. Technology-Supported Distributed Teams We reviewed all studies on technology-supported distributed teams published between 1990 and 1998 in 11 major journals publishing research on information systems, groups, and international business. As summarized in Table 1, we found 41 studies. The most common theme in the controlled and quasiexperimental research compared face-to-face with technology configurations to mediate communication. In some studies face-to-face groups performed better than technology-mediated groups (e.g., Hightower and Sayeed 1996, Smith and Vanecek 1990); in others they performed worse (e.g., Ocker et al. 1995–1996, Straus 1996); in others there was no difference on quality-related outcomes (e.g., Farmer and Hyatt 1994, Valacich et al. 1993). Furthermore, these relationships changed and evolved over time (e.g., Hollingshead et al. 1993). Although task type was often proposed to moderate the relationship between a medium and its effect on performance (e.g., O’Connor et al. 1993), there did not seem to be a consistent pattern of task types for which communications technology was better or worse. Some studies concluded that a combination of media including face-to-face outperformed one without face-to-face (e.g., Ocker et al. 1998). The few studies that crossed organizational or significant geographic boundaries found that these boundaries affected the context in which communication took place and the communication itself (e.g., Turoff et al. 1993). Internationally distributed teams were examined in only two studies, both focusing on the role of trust in global teams that never met in person (Jarvenpaa et al. 1998, Jarvenpaa and Leidner 1998). They found that trust, which was critical to the team’s ability to manage decision processes, could be built swiftly; however, this trust was very fragile. Multidimensional field studies examined technology use among members of a distributed organizational group over time. All demonstrated that context and time helped explain some of the relationships that appeared conflicting or equivocal when studied individually (e.g., Fulk 1993, Hiltz et al. 1991, Schmitz and Fulk 1991). For example, DeSanctis and Jackson (1994) showed that the benefits from using more complex communications technology increased as the task became more complex; Hinds and Kiesler (1995) observed that lateral and extradepartmental communication used telephone rather than e-mail or voicemail, increasing collaboration; and Zack (1993) found that the more shared a group’s interpretive context was, the more members were able to communicate using seemingly less rich technologies. Taken together, these studies suggest that a global virtual team’s most effective use of communications technology will be shaped by dimensions of the team’s task and its context, but they do not offer a great deal of specific guidance for research on these teams. Multinational Teams Research on multinational teams is far more limited than research on distributed teams, with most of it focusing on the role of cultural composition. Culture is the set of deeplevel values associated with societal effectiveness, shared by an identifiable group of people (Maznevski et al. 1997). Multicultural team effectiveness research usually compares the performance of culturally diverse groups'], 'negatives': ['BACKGROUND\\nMental health conditions are among the leading non-fatal diseases in middle-aged and older adults in Australia. Proximal and distal social environmental factors and physical environmental factors have been associated with mental health, but the underlying mechanisms explaining these associations remain unclear. The study objective was to examine the contribution of different types of physical activity in mediating the relationship of social and physical environmental factors with mental health-related quality of life in middle-aged and older adults.\\n\\n\\nMETHODS\\nBaseline data from the Wellbeing, Eating and Exercise for a Long Life (WELL) study were used. WELL is a prospective cohort study, conducted in Victoria, Australia. Baseline data collection took place in 2010. In total, 3,965 middle-aged and older adults (55-65 years, 47.4% males) completed the SF-36 Health Survey, the International Physical Activity Questionnaire, and a questionnaire on socio-demographic, social and physical environmental attributes. Mediation analyses were conducted using the MacKinnon product-of-coefficients test.\\n\\n\\nRESULTS\\nPersonal safety, the neighbourhood physical activity environment, social support for physical activity from family or friends, and neighbourhood social cohesion were positively associated with mental health-related quality of life. Active transportation and leisure-time physical activity mediated 32.9% of the association between social support for physical activity from family or friends and mental health-related quality of life. These physical activity behaviours also mediated 11.0%, 3.4% and 2.3% respectively, of the relationship between the neighbourhood physical activity environment, personal safety and neighbourhood social cohesion and mental health-related quality of life.\\n\\n\\nCONCLUSIONS\\nIf these results are replicated in future longitudinal studies, tailored interventions to improve mental health-related quality of life in middle-aged and older adults should use a combined strategy, focusing on increasing physical activity as well as social and physical environmental attributes.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Rectangular shape detection has a wide range of applications, such as license plate detection, vehicle detection, and building detection. In this paper, we propose a geometric framework for rectangular shape detection based on the channel-scale space of RGB images. The framework consists of algorithms developed to address three issues of a candidate shape (i.e., a connected component of edge points), including: 1) outliers; 2) open shape; and 3) fragmentation. Furthermore, we propose an interestness measure for rectangular shapes by integrating imbalanced points (one type of interest points). Our experimental study shows the promise of the proposed framework.', 'positives': ['This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.'], 'negatives': ['BACKGROUND\\nDuplex ultrasound investigation has become the reference standard in assessing the morphology and haemodynamics of the lower limb veins. The project described in this paper was an initiative of the Union Internationale de Phlébologie (UIP). The aim was to obtain a consensus of international experts on the methodology to be used for assessment of anatomy of superficial and perforating veins in the lower limb by ultrasound imaging.\\n\\n\\nMETHODS\\nThe authors performed a systematic review of the published literature on duplex anatomy of the superficial and perforating veins of the lower limbs; afterwards they invited a group of experts from a wide range of countries to participate in this project. Electronic submissions from the authors and the experts (text and images) were made available to all participants via the UIP website. The authors prepared a draft document for discussion at the UIP Chapter meeting held in San Diego, USA in August 2003. Following this meeting a revised manuscript was circulated to all participants and further comments were received by the authors and included in subsequent versions of the manuscript. Eventually, all participants agreed the final version of the paper.\\n\\n\\nRESULTS\\nThe experts have made detailed recommendations concerning the methods to be used for duplex ultrasound examination as well as the interpretation of images and measurements obtained. This document provides a detailed methodology for complete ultrasound assessment of the anatomy of the superficial and perforating veins in the lower limbs.\\n\\n\\nCONCLUSIONS\\nThe authors and a large group of experts have agreed a methodology for the investigation of the lower limbs venous system by duplex ultrasonography, with specific reference to the anatomy of the main superficial veins and perforators of the lower limbs in healthy and varicose subjects.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Extracting the pixel-level 3D layout from a single image is important for different applications, such as object localization, image, and video categorization. Traditionally, the 3D layout is derived by solving a pixel-level classification problem. However, the image-level 3D structure can be very beneficial for extracting pixel-level 3D layout since it implies the way how pixels in the image are organized. In this paper, we propose an approach that first predicts the global image structure, and then we use the global structure for fine-grained pixel-level 3D layout extraction. In particular, image features are extracted based on multiple layout templates. We then learn a discriminative model for classifying the global layout at the image-level. Using latent variables, we implicitly model the sublevel semantics of the image, which enrich the expressiveness of our model. After the image-level structure is obtained, it is used as the prior knowledge to infer pixel-wise 3D layout. Experiments show that the results of our model outperform the state-of-the-art methods by 11.7% for 3D structure classification. Moreover, we show that employing the 3D structure prior information yields accurate 3D scene layout segmentation.', 'positives': ['We consider the problem of estimating 3-d structure from a single still image of an outdoor urban scene. Our goal is to efficiently create 3-d models which are visually pleasant. We chose an appropriate 3-d model structure and formulate the task of 3-d reconstruction as model fitting problem. Our 3-d models are composed of a number of vertical walls and a ground plane, where ground-vertical boundary is a continuous polyline. We achieve computational efficiency by special preprocessing together with stepwise search of 3-d model parameters dividing the problem into two smaller sub-problems on chain graphs. The use of Conditional Random Field models for both problems allows to various cues. We infer orientation of vertical walls of 3-d model vanishing points.'], 'negatives': ['We report on the design and characterization of a multipurpose 64 × 32 CMOS single-photon avalanche diode (SPAD) array. The chip is fabricated in a high-voltage 0.35-μm CMOS technology and consists of 2048 pixels, each combining a very low noise (100 cps at 5-V excess bias) 30-μm SPAD, a prompt avalanche sensing circuit, and digital processing electronics. The array not only delivers two-dimensional intensity information through photon counting in either free-running (down to 10-μs integration time) or time-gated mode, but can also perform smart light demodulation with in-pixel background suppression. The latter feature enables phase-resolved imaging for extracting either three-dimensional depth-resolved images or decay lifetime maps, by measuring the phase shift between a modulated excitation light and the reflected photons. Pixel-level memories enable fully parallel processing and global-shutter readout, preventing motion artifacts (e.g., skew, wobble, motion blur) and partial exposure effects. The array is able to acquire very fast optical events at high frame-rate (up to 100 000 fps) and at single-photon level. Low-noise SPADs ensure high dynamic range (up to 110 dB at 100 fps) with peak photon detection efficiency of almost 50% at 410 nm. The SPAD imager provides different operating modes, thus, enabling both time-domain applications, like fluorescence lifetime imaging (FLIM) and fluorescence correlation spectroscopy, as well as frequency-domain FLIM and lock-in 3-D ranging for automotive vision and lidar.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Wedescribe here a collaboration between two separate treebank projects annotating data for the same language (Latin). By working together to create a common standard for the annotation of Latin syntax and sharing our annotated data as it is created, we are each able to rely on the resources and expertise of the other while also ensuring that our data will be compatible in the future. \\ue062is compatibility allows us to conduct diachronic studies involving both datasets, and we add our results to an ongoing discussion of one such issue, the gradual replacement of the Accusativus cum Infinitivo construction in Latin with subordinate clauses headed by conjunctions such as quod and quia.', 'positives': ['We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs. Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n3) time. More surprisingly, the representation is extended naturally to non-projective parsing using Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967) MST algorithm, yielding anO(n2) parsing algorithm. We evaluate these methods on the Prague Dependency Treebank using online large-margin learning techniques (Crammer et al., 2003; McDonald et al., 2005) and show that MST parsing increases efficiency and accuracy for languages with non-projective dependencies.'], 'negatives': ['This article describes three statistical models for natural language parsing. The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree. Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram lexical dependencies, wh-movement, and preferences for close attachment. All of these preferences are expressed by probabilities conditioned on lexical heads. The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature. To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of precision/recall results in recovering various types of dependencies. We analyze various characteristics of the models through experiments on parsing accuracy, by collecting frequencies of various structures in the treebank, and through linguistically motivated examples. Finally, we compare the models to others that have been applied to parsing the treebank, aiming to give some explanation of the difference in performance of the various models.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"The recent developments in remote healthcare systems have witnessed significant interests from IT industry (Microsoft, Google, VMware etc) that provide ubiquitous and easily deployable healthcare systems. These systems provide a platform to share medical information, applications, and infrastructure in a ubiquitous and fully automated manner. Communication security and patients' data privacy are the aspects that would increase the confidence of users in such remote healthcare systems. This paper presents a secure cloud-based mobile healthcare framework using wireless body area networks (WBANs). The research work presented here is twofold: first, it attempts to secure the inter-sensor communication by multi-biometric based key generation scheme in WBANs; and secondly, the electronic medical records (EMRs) are securely stored in the hospital community cloud and privacy of the patients' data is preserved. The evaluation and analysis shows that the proposed multi-biometric based mechanism provides significant security measures due to its highly efficient key generation mechanism.\", 'positives': ['Preserving a person\\'s privacy in an efficient manner is very important for critical, life-saving infrastructures like body sensor networks (BSN). This paper presents a novel key agreement scheme which allows two sensors in a BSN to agree to a common key generated using electrocardiogram (EKG) signals. This EKG-based key agreement (EKA) scheme aims to bring the \"plug-n-play\" paradigm to BSN security whereby simply deploying sensors on the subject can enable secure communication, without requiring any form of initialization such as pre-deployment. Analysis of the scheme based on real EKG data (obtained from MIT PhysioBank database) shows that keys resulting from EKA are: random, time variant, can be generated based on short-duration EKG measurements, identical for a given subject and different for separate individuals.'], 'negatives': ['Stream processing is a computing paradigm that has emerged from the necessity of handling high volumes of data in real time. In contrast to traditional databases, stream processing systems perform continuous queries and handle data on-the-fly. Today, a wide range of application areas relies on efficient pattern detection and queries over streams. The advent of Cloud computing fosters the development of elastic stream processing platforms which are able to dynamically adapt based on different cost-benefit tradeoffs. This article provides an overview of the historical evolution and the key concepts of stream processing, with special focus on adaptivity and Cloud-based elasticity. Copyright c © 2012 John Wiley & Sons, Ltd.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Multi-person event recognition is a challenging task, often with many people active in the scene but only a small subset contributing to an actual event. In this paper, we propose a model which learns to detect events in such videos while automatically \"attending\" to the people responsible for the event. Our model does not use explicit annotations regarding who or where those people are during training and testing. In particular, we track people in videos and use a recurrent neural network (RNN) to represent the track features. We learn time-varying attention weights to combine these features at each time-instant. The attended features are then processed using another RNN for event detection/ classification. Since most video datasets with multiple people are restricted to a small number of videos, we also collected a new basketball dataset comprising 257 basketball games with 14K event annotations corresponding to 11 event classes. Our model outperforms state-of-the-art methods for both event classification and detection on this new dataset. Additionally, we show that the attention mechanism is able to consistently localize the relevant players.', 'positives': ['We present a novel detection method using a deep convolutional neural network (CNN), named AttentionNet. We cast an object detection problem as an iterative classification problem, which is the most suitable form of a CNN. AttentionNet provides quantized weak directions pointing a target object and the ensemble of iterative predictions from AttentionNet converges to an accurate object boundary box. Since AttentionNet is a unified network for object detection, it detects objects without any separated models from the object proposal to the post bounding-box regression. We evaluate AttentionNet by a human detection task and achieve the state-of-the-art performance of 65% (AP) on PASCAL VOC 2007/2012 with an 8-layered architecture only.'], 'negatives': ['Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT’14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM’s performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias – the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.', 'positives': ['A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is WeightLifter, a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions.'], 'negatives': ['Grammatical inference – used successfully in a variety of fields such as pattern recognition, computational biology and natural language processing – is the process of automatically inferring a grammar by examining the sentences of an unknown language. Software engineering can also benefit from grammatical inference. Unlike these other fields, which use grammars as a convenient tool to model naturally occuring patterns, software engineering treats grammars as first-class objects typically created and maintained for a specific purpose by human designers. We introduce the theory of grammatical inference and review the state of the art as it relates to software engineering.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'REST architectural style gains increasing popularity in the networking protocol design, and it has become a prevalent choice for northbound API of Software-Defined Networking (SDN). This paper addresses many critical issues in RESTful networking protocol design, and presents a framework on how a networking protocol can be designed in a truly RESTful manner, making it towards a service oriented data networking. In particular, we introduce the HTTP content negotiation mechanism which allows clients to select different representation formats from the same resource URI. Most importantly, we present a hypertext-driven approach, so that hypertext links are defined between REST resources for the networking protocol to guide clients to identify the right resources rather than relying on fixed resource URIs. The advantages of our approach are verified in two folds. First, we show how to apply our approach to fix REST design problems in some existing northbound networking APIs, and then we show how to design a RESTful northbound API of SDN in the context of OpenStack. We implemented our proposed approach in the northbound REST API of SOX, a generalized SDN controller, and the benefits of the proposed approach are experimentally verified.', 'positives': ['This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will soon run OpenFlow networks, using commercial Ethernet switches and routers. We will work to encourage deployment at other schools; and We encourage you to consider deploying OpenFlow in your university network too'], 'negatives': ['A 64-channel RX digital beamformer was implemented in a single chip for 3-D ultrasound medical imaging using 2-D phased-array transducers. The RX beamformer chip includes 64 analog front-end branches including 64 non-uniform sampling ADCs, a FIFO/Adder, and an on-chip look-up table (LUT). The LUT stores the information on the rising edge timing of the non-uniform ADC sampling clocks. To include the LUT inside the beamformer chip, the LUT size was reduced by around 240 times by approximating an ADC-sample-time profile w.r.t. focal points (FP) along a scanline (SL) for a channel into a piece-wise linear form. The maximum error between the approximated and accurate sample times of ADC is eight times the sample time resolution (Ts) that is 1/32 of the ultrasound signal period in this work. The non-uniform sampling reduces the FIFO size required for digital beamforming by around 20 times. By applying a 9-dot image from Field-II program and 2-D ultrasound phantom images to the fabricated RX beamformer chip, the original images were successfully reconstructed from the measured output. The chip in a 0.13-um CMOS occupies 30.25 $\\\\text{mm}^{2}$ and consumes 605 mW.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Recommender Systems are indispensable to provide personalized services on the Web. Recommending items which match a user's preference has been researched for a long time, and there exist a lot of useful approaches. Especially, Collaborative Filtering, which gives recommendation based on users' feedbacks to items, is considered useful. Feedbacks are categorized into explicit feedbacks and implicit feedbacks. In this paper, Collaborative Filtering with implicit feedbacks is addressed. Explicit feedbacks are feedbacks provided by users intentionally and represent users' preferences for items explicitly. For example, in Netflix, users can rate movies on a scale of 1-5, and, based on these ratings, users can receive movie recommendation. On the other hand, implicit feedbacks are collected by the system automatically. In Amazon.com, products that users buy and click are used for recommendation. While Collaborative Filtering with explicit feedbacks has been a central topic for a long time, implicit feedbacks have become a more and more important research topic recently because these are easier to obtain and more abundant than explicit feedbacks. However, implicit feedbacks are often noisy. They often contain feedbacks which do not represent users' real preferences for items. Our approach addresses to this noise problem. We propose three discounting methods for observed values in implicit feedbacks. The key idea is that there is hidden uncertainty for each observed feedback, and effects by observed feedbacks of much uncertainty are discounted. The three discounting methods do not need additional information besides ordinary user-item feedbacks pairs and timestamps. Experiments with huge real-world datasets confirm that all of the three methods contribute to improving the performance. Moreover, our discounting methods can easily be combined with existing methods and improve the recommendation accuracy of existing models.\", 'positives': ['Music consumption is biased towards a few popular artists. For instance, in 2007 only 1% of all digital tracks accounted for 80% of all sales. Similarly, 1,000 albums accounted for 50% of all album sales, and 80% of all albums sold were purchased less than 100 times. There is a need to assist people to filter, discover, personalise and recommend from the huge amount of music content available along the Long Tail. Current music recommendation algorithms try to accurately predict what people demand to listen to. However, quite often these algorithms tend to recommend popular —or well–known to the user— music, decreasing the effectiveness of the recommendations. These approaches focus on improving the accuracy of the recommendations. That is, try to make accurate predictions about what a user could listen to, or buy next, independently of how useful to the user could be the provided recommendations. In this Thesis we stress the importance of the user’s perceived quality of the recommendations. We model the Long Tail curve of artist popularity to predict —potentially— interesting and unknown music, hidden in the tail of the popularity curve. Effective recommendation systems should promote novel and relevant material (non–obvious recommendations), taken primarily from the tail of a popularity distribution. The main contributions of this Thesis are: (i) a novel network–based approach for recommender systems, based on the analysis of the item (or user) similarity graph, and the popularity of the items, (ii) a user–centric evaluation that measures the user’s relevance and novelty of the recommendations, and (iii) two prototype systems that implement the ideas derived from the theoretical work. Our findings have significant implications for recommender systems that assist users to explore the Long Tail, digging for content they might like.'], 'negatives': [\"One of the main barriers for deploying neural networks on embedded systems has been large memory and power consumption of existing neural networks. In this work, we introduce SqueezeNext, a new family of neural network architectures whose design was guided by considering previous architectures such as SqueezeNet, as well as by simulation results on a neural network accelerator. This new network is able to match AlexNet's accuracy on the ImageNet benchmark with 112× fewer parameters, and one of its deeper variants is able to achieve VGG-19 accuracy with only 4.4 Million parameters, (31× smaller than VGG-19). SqueezeNext also achieves better top-5 classification accuracy with 1.3× fewer parameters as compared to MobileNet, but avoids using depthwise-separable convolutions that are inefficient on some mobile processor platforms. This wide range of accuracy gives the user the ability to make speed-accuracy tradeoffs, depending on the available resources on the target hardware. Using hardware simulation results for power and inference speed on an embedded system has guided us to design variations of the baseline model that are 2.59×/8.26× faster and 2.25×/7.5× more energy efficient as compared to SqueezeNet/AlexNet without any accuracy degradation.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Recent work in learning vector-space embeddings for multi-relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora. We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources, in conjunction with distributional semantics, in order to derive a better initialization for training relational models. Applying this initialization to the TransE model results in significant new stateof-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51. It also results in faster convergence of the entity representations. We find that there is a tradeoff between improving the mean rank and the hits@10 with this approach. This illustrates that much remains to be understood regarding performance improvements in relational models.', 'positives': ['We present a fast method for re-purposing existing semantic word vectors to improve performance in a supervised task. Recently, with an increase in computing resources, it became possible to learn rich word embeddings from massive amounts of unlabeled data. However, some methods take days or weeks to learn good embeddings, and some are notoriously difficult to train. We propose a method that takes as input an existing embedding, some labeled data, and produces an embedding in the same space, but with a better predictive performance in the supervised task. We show improvement on the task of sentiment classification with respect to several baselines, and observe that the approach is most useful when the training set is sufficiently small.'], 'negatives': [\"Computer modeling may be used to accurately model an IEEE Std C62.41.2-2002 Combination Wave surge generator and apply the simulated surge waveform to a modeled system to determine the system's immunity to surge voltages. During the simulated surge tests, the designer can verify the suitability of the selected components, and, if necessary, judiciously perform a re-design at low cost and with little time expended. Furthermore, the designer can also observe the magnitude of the stresses imposed on the components by the simulated surge and thus determine the magnitude of the component voltages and currents, including dv/dt, di/dt, and the ringing frequency, thus allowing the designer to fully evaluate the adequacy, reliability and safety of the designed system. The authors evaluated a surge generator model published in an IEEE paper in 2005 and determined that the model was inaccurate. Consequently, a new surge generator model was proposed. The novel features of this enhanced surge generator model are demonstrated for four different simulation runs, using an electronic circuit with an L-C input line filter. The four runs include two operating conditions: a) with a surge suppressor in the circuit and b) with the surge suppressor open- circuited. The connected load includes: 1) a motor load and 2) a resistive load.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper presents a fully automated object extraction system for web documents. Our methodology consists of a layered framework and a suite of algorithms. A distinct feature of our approach is the full automation of both the extraction of data object regions from dynamic Web pages and the identification of correct object boundary separators. We implemented the methodology in the XWRAPElite object extraction system and evaluated the system using more than 3,200 pages over 75 diverse web sites. Our experiments show three important and interesting results: First, our algorithms for identifying the minimal object rich subtree achieves 96% success rate over all web pages we have tested. Second, our algorithms for discovering and extracting object separator tags reach the success rate of 95%. Most significantly, the overall system achieves precision between 96% and 100% (returns only correct objects) and excellent recall (between 95% and 96%, with very few significant objects left out). The minimal subtree extraction algorithms and the object boundary identification algorithms are fast, about 87 milliseconds per page with an average page size of 30KB.', 'positives': [\"Many Internet information resources present relational data|telephone directories, product catalogs, etc. Because these sites are formatted for people, mechanically extracting their content is di cult. Systems using such resources typically use hand-coded wrappers, procedures to extract data from information resources. We introduce wrapper induction, a method for automatically constructing wrappers, and identify hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources. We use PAC analysis to bound the problem's sample complexity, and show that the system degrades gracefully with imperfect labeling knowledge.\"], 'negatives': [\"Cross-chain communication is one of the major design considerations in current blockchain systems [4-7] such as Ethereum[8]. Currently, Blockchain operates like information isolated island, they cannot obtain external data or execute transactions on their own.\\n Motivated by recent studies [1-3] on blockchain's multiChain framework, we investigate the cross-chain communication. We introduces blockchain router, which empowers blockchains to connect and communicate cross chains. By establishing an economic model, blockchain router enables different blockchains in the network communicate with each other same like Internet network. In the network of blockchain router, some blockchain plays the role of a router which, according to the communication protocol, analyzes and transmits communication requests, dynamically maintaining a topology structure of the blockchain network.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The paper presents performance analysis of modified SEPIC dc-dc converter with low input voltage and wide output voltage range. The operational analysis and the design is done for the 380W power output of the modified converter. The simulation results of modified SEPIC converter are obtained with PI controller for the output voltage. The results obtained with the modified converter are compared with the basic SEPIC converter topology for the rise time, peak time, settling time and steady state error of the output response for open loop. Voltage tracking curve is also shown for wide output voltage range. I. Introduction Dc-dc converters are widely used in regulated switched mode dc power supplies and in dc motor drive applications. The input to these converters is often an unregulated dc voltage, which is obtained by rectifying the line voltage and it will therefore fluctuate due to variations of the line voltages. Switched mode dc-dc converters are used to convert this unregulated dc input into a controlled dc output at a desired voltage level. The recent growth of battery powered applications and low voltage storage elements are increasing the demand of efficient step-up dc–dc converters. Typical applications are in adjustable speed drives, switch-mode power supplies, uninterrupted power supplies, and utility interface with nonconventional energy sources, battery energy storage systems, battery charging for electric vehicles, and power supplies for telecommunication systems etc.. These applications demand high step-up static gain, high efficiency and reduced weight, volume and cost. The step-up stage normally is the critical point for the design of high efficiency converters due to the operation with high input current and high output voltage [1]. The boost converter topology is highly effective in these applications but at low line voltage in boost converter, the switching losses are high because the input current has the maximum value and the highest step-up conversion is required. The inductor has to be oversized for the large current at low line input. As a result, a boost converter designed for universal-input applications is heavily oversized compared to a converter designed for a narrow range of input ac line voltage [2]. However, recently new non-isolated dc–dc converter topologies with basic boost are proposed, showing that it is possible to obtain high static gain, low voltage stress and low losses, improving the performance with respect to the classical topologies. Some single stage high power factor rectifiers are presented in [3-6]. A new …', 'positives': ['This paper introduces the use of the voltage multiplier technique applied to the classical non-isolated dc-dc converters in order to obtain high step-up static gain, reduction of the maximum switch voltage, zero current switching turn-on. The diodes reverse recovery current problem is minimized and the voltage multiplier also operates as a regenerative clamping circuit, reducing the problems with layout and the EMI generation. These characteristics allows the operation with high static again and high efficiency, making possible to design a compact circuit for applications where the isolation is not required. The operation principle, the design procedure and practical results obtained from the implemented prototypes are presented for the single-phase and multiphase dc-dc converters. A boost converter was tested with the single-phase technique, for an application requiring an output power of 100 W, operating with 12 V input voltage and 100 V output voltage, obtaining efficiency equal to 93%. The multiphase technique was tested with a boost interleaved converter operating with an output power equal to 400 W, 24 V input voltage and 400 V output voltage, obtaining efficiency equal to 95%.'], 'negatives': ['Many applications call for high step-up dc–dc converters that do not require isolation. Some dc–dc converters can provide high step-up voltage gain, but with the penalty of either an extreme duty ratio or a large amount of circulating energy. DC–DC converters with coupled inductors can provide high voltage gain, but their efficiency is degraded by the losses associated with leakage inductors. Converters with active clamps recycle the leakage energy at the price of increasing topology complexity. A family of high-efficiency, high step-up dc–dc converters with simple topologies is proposed in this paper. The proposed converters, which use diodes and coupled windings instead of active switches to realize functions similar to those of active clamps, perform better than their active-clamp counterparts. High efficiency is achieved because the leakage energy is recycled and the output rectifier reverse-recovery problem is alleviated.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The basic knowledge required to do sentiment analysis of Twitter is discussed in this review paper. Sentiment Analysis can be viewed as field of text mining, natural language processing. Thus we can study sentiment analysis in various aspects. This paper presents levels of sentiment analysis, approaches to do sentiment analysis, methodologies for doing it, and features to be extracted from text and the applications. Twitter is a microblogging service to which if sentiment analysis done one has to follow explicit path. Thus this paper puts overview about tweets extraction, their preprocessing and their sentiment analysis.', 'positives': [\"With the booming of microblogs on the Web, people have begun to express their opinions on a wide variety of topics on Twitter and other similar services. Sentiment analysis on entities (e.g., products, organizations, people, etc.) in tweets (posts on Twitter) thus becomes a rapid and effective way of gauging public opinion for business marketing or social studies. However, Twitter's unique characteristics give rise to new problems for current sentiment analysis methods, which originally focused on large opinionated corpora such as product reviews. In this paper, we propose a new entity-level sentiment analysis method for Twitter. The method first adopts a lexiconbased approach to perform entity-level sentiment analysis. This method can give high precision, but low recall. To improve recall, additional tweets that are likely to be opinionated are identified automatically by exploiting the information in the result of the lexicon-based method. A classifier is then trained to assign polarities to the entities in the newly identified tweets. Instead of being labeled manually, the training examples are given by the lexicon-based approach. Experimental results show that the proposed method dramatically improves the recall and the F-score, and outperforms the state-of-the-art baselines. External Posting Date: June 21, 2011 [Fulltext] Approved for External Publication Internal Posting Date: June 21, 2011 [Fulltext] \\uf8e9 Copyright 2011 Hewlett-Packard Development Company, L.P. Combining Lexicon-based and Learning-based Methods for Twitter Sentiment Analysis Lei Zhang, Riddhiman Ghosh, Mohamed Dekhil, Meichun Hsu, Bing Liu Hewlett-Packard Laboratories University of Illinois at Chicago 1501 Page Mill Rd., Palo Alto, CA 851 S. Morgan St., Chicago, IL {riddhiman.ghosh, mohamed.dekhil, {lzhang3, liub}@cs.uic.edu meichun.hsu}@hp.com\"], 'negatives': ['In order to ensure the safety measures, the detection of traffic rule violators is a highly desirable but challenging task due to various difficulties such as occlusion, illumination, poor quality of surveillance video, varying whether conditions, etc. In this paper, we present a framework for automatic detection of motorcyclists driving without helmets in surveillance videos. In the proposed approach, first we use adaptive background subtraction on video frames to get moving objects. Later convolutional neural network (CNN) is used to select motorcyclists among the moving objects. Again, we apply CNN on upper one fourth part for further recognition of motorcyclists driving without a helmet. The performance of the proposed approach is evaluated on two datasets, IITH_Helmet_1 contains sparse traffic and IITH_Helmet_2 contains dense traffic, respectively. The experiments on real videos successfully detect 92.87% violators with a low false alarm rate of 0.5% on an average and thus shows the efficacy of the proposed approach.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Logs are widely used in modern software system management because they are often the only data accessible that record system events at runtime. In recent years, because of the ever-increasing log size, data mining techniques are often utilized to help developers and operators conduct system reliability management. A typical log-based system reliability management procedure is to first parse log messages because of their unstructured format; and apply data mining techniques on the parsed logs to obtain critical system behavior information. Most of existing research studies focus on offline log parsing, which need to parse logs in batch mode. However, software systems, especially distributed systems, require online monitoring and maintenance. Thus, a log parser that can parse log messages in a streaming manner is highly in demand. To address this problem, we propose an online log parsing method, namely Drain, based on directed acyclic graph, which encodes specially designed rules for parsing. Drain can automatically generate a directed acyclic graph for a new system and update the graph according to the incoming log messages. Besides, Drain frees developers from the burden of parameter tuning by allowing them use Drain with no pre-defined parameters. To evaluate the performance of Drain, we collect 11 log datasets generated by real-world systems, ranging from distributed systems, Web applications, supercomputers, operating systems, to standalone software. The experimental results show that Drain has the highest accuracy on all 11 datasets. Moreover, Drain obtains 37.15%∼ 97.14% improvement in the running time over the state-of-the-art online parsers. We also conduct a case study on a log-based anomaly detection task using Drain in the parsing step, which determines its effectiveness in system reliability management.', 'positives': [\"Surprisingly, console logs rarely help operators detect problems in large-scale datacenter services, for they often consist of the voluminous intermixing of messages from many software components written by independent developers. We propose a general methodology to mine this rich source of information to automatically detect system runtime problems. We first parse console logs by combining source code analysis with information retrieval to create composite features. We then analyze these features using machine learning to detect operational problems. We show that our method enables analyses that are impossible with previous methods because of its superior ability to create sophisticated features. We also show how to distill the results of our analysis to an operator-friendly one-page decision tree showing the critical messages associated with the detected problems. We validate our approach using the Darkstar online game server and the Hadoop File System, where we detect numerous real problems with high accuracy and few false positives. In the Hadoop case, we are able to analyze 24 million lines of console logs in 3 minutes. Our methodology works on textual console logs of any size and requires no changes to the service software, no human input, and no knowledge of the software's internals.\"], 'negatives': ['Our objective is to efficiently and accurately estimate the upper body pose of humans in gesture videos. To this end, we build on the recent successful applications of deep convolutional neural networks (ConvNets). Our novelties are: (i) our method is the first to our knowledge to use ConvNets for estimating human pose in videos; (ii) a new network that exploits temporal information from multiple frames, leading to better performance; (iii) showing that pre-segmenting the foreground of the video improves performance; and (iv) demonstrating that even without foreground segmentations, the network learns to abstract away from the background and can estimate the pose even in the presence of a complex, varying background. We evaluate our method on the BBC TV Signing dataset and show that our pose predictions are significantly better, and an order of magnitude faster to compute, than the state of the art [3].'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In many multi-label learning problems, especially as the number of labels grow, it is challenging to gather completely annotated data. This work presents a new approach for multi-label learning from incomplete annotations. The main assumption is that because of label correlation, the true label matrix as well as the soft predictions of classifiers shall be approximately low rank. We introduce a posterior regularization technique which enforces soft constraints on the classifiers, regularizing them to prefer sparse and low-rank predictions. Avoiding strict lowrank constraints results in classifiers which better fit the real data. The model can be trained efficiently using EM and stochastic gradient descent. Experiments in both the image and text domains demonstrate the contributions of each modeling assumption and show that the proposed approach achieves state-of-the-art performance on a number of challenging datasets.', 'positives': ['We present Posterior Regularization, a probabilistic framework for structured, weakly supervised learning. Our framework efficiently incorporates indirect supervision via constraints on posterior distributions of probabilistic models with latent variables. Posterior Regularization separates model complexity from the complexity of structural constraints it is desired to satisfy. By directly imposing decomposable regularization on the posterior moments of latent variables during learning, we retain the computational efficiency of the unconstrained model while ensuring desired constraints hold in expectation. We present an efficient algorithm for learning with posterior regularization and illustrate its versatility on a diverse set of structural constraints such as bijectivity, symmetry and group sparsity in several large scale experiments, including multi-view learning, cross-lingual dependency grammar induction, unsupervised part-of-speech induction, and bitext word alignment. Comments University of Pennsylvania Department of Computer and Information Science Technical Report No. MSCIS-09-16. This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/912 Posterior Regularization for Structured Latent Variable Models Kuzman Ganchev | João Graça | Jennifer Gillenwater | Ben Taskar {kuzman | graca | jengi | taskar }@cis.upenn.edu Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA Abstract We present Posterior Regularization, a probabilistic framework for structured, weakly supervised learning. Our framework efficiently incorporates indirect supervision via constraints on posterior distributions of probabilistic models with latent variables. Posterior Regularization separates model complexity from the complexity of structural constraints it is desired to satisfy. By directly imposing decomposable regularization on the posterior moments of latent variables during learning, we retain the computational efficiency of the unconstrained model while ensuring desired constraints hold in expectation. We present an efficient algorithm for learning with posterior regularization and illustrate its versatility on a diverse set of structural constraints such as bijectivity, symmetry and group sparsity in several large scale experiments, including multi-view learning, cross-lingual dependency grammar induction, unsupervised part-of-speech induction, and bitext word alignment. 1We present Posterior Regularization, a probabilistic framework for structured, weakly supervised learning. Our framework efficiently incorporates indirect supervision via constraints on posterior distributions of probabilistic models with latent variables. Posterior Regularization separates model complexity from the complexity of structural constraints it is desired to satisfy. By directly imposing decomposable regularization on the posterior moments of latent variables during learning, we retain the computational efficiency of the unconstrained model while ensuring desired constraints hold in expectation. We present an efficient algorithm for learning with posterior regularization and illustrate its versatility on a diverse set of structural constraints such as bijectivity, symmetry and group sparsity in several large scale experiments, including multi-view learning, cross-lingual dependency grammar induction, unsupervised part-of-speech induction, and bitext word alignment. 1'], 'negatives': ['Technology has made navigation in 3D real time possible and this has made possible what seemed impossible. This paper explores the aspect of deep visual odometry methods for mobile robots. Visual odometry has been instrumental in making this navigation successful. Noticeable challenges in mobile robots including the inability to attain Simultaneous Localization and Mapping have been solved by visual odometry through its cameras which are suitable for human environments. More intuitive, precise and accurate detection have been made possible by visual odometry in mobile robots. Another challenge in the mobile robot world is the 3D map reconstruction for exploration. A dense map in mobile robots can facilitate for localization and more accurate findings. I. VISUAL ODOMETRY IN MOBILE ROBOTS Mobile robot applications heavily rely on the ability of the vehicle to achieve accurate localization. It is essential that a robot is able to maintain knowledge about its position at all times in order to achieve autonomous navigation. To attain this, various techniques, systems and sensors have been established to aid with mobile robot positioning including visual odometry [1]. Importantly, the adoption of Deep Learning based techniques was inspired by the precision to find solutions to numerous standard computer vision problems including object detection, image classification and segmentation. Visual odometry involves the pose estimation process that involves a robot and how they use a stream of images obtained from cameras that are attached to them [2]. The main aim of visual odometry is the estimations from camera pose. It is an approach that avoids contact with the robot for the purpose of ensuring that the mobile robots are effectively positioned. For this reason, the process is quite a challenging task that is related to mapping and simultaneous localization whose main aim is to generate the road map from a stream of visual data [3]. Estimates of motion from pixel differences and features between frames are made based on cameras that are strategically positioned. For mobile robots to achieve an actively controlled navigation, a real time 3D and reliable localization and reconstruction of functions is an essential prerequisite [4]. Mobile robots have to perform localization and mapping functions simultaneously and this poses a major challenge for them. The Simultaneous Localization and Mapping (SLAM) problem has attracted attention as various studies extensively evaluate it [5]. To solve the SLAM problem, visual odometry has been suggested especially because cameras provide high quality information at a low cost from the sensors that are conducive for human environments [6]. The major advances in computer vision also make possible quite a number of synergistic capabilities including terrain and scene classification, object detection and recognition. Notably, the visual odometry in mobile robot have enabled for more precise, intuitive and accurate detection. Although there has been significant progress in the last decade to bring improvements to passive mobile robots into controllable robots that are active, there are still notable challenges in the effort to achieve this. Particularly, a 3D map reconstruction that is fully dense to facilitate for exploration still remains an unsolved problem. It is only through a dense map that mobile robots can be able to more reliably do localization and ultimately leading to findings that are more accurate [7] [8]. According to Turan ( [9]), it is essential that adoptions of a comprehensive reconstruction on the suitable 3D method for mobile robots be adopted. This can be made possible through the building of a modular fashion including key frame selection, pre-processing, estimates on sparse then dense alignment based pose, shading based 3D and bundle fusion reconstruction [10]. There is also the challenge of the real time precise localization of the mobile robots that are actively controlled. The study by [11], which employed quantitative and qualitative in trajectory estimations sought to find solution to the challenge of precise localization for the endoscopic robot capsule. The data set was general and this was ensured through the fitting of 3 endoscopic cameras in different locations for the purpose of capturing the endoscopic videos [12]. Stomach videos were recorded for 15 minutes and they contained more than 10,000 frames. Through this, the ground truth was served for the 3D reconstruction module maps’ quantitative evaluations [13]. Its findings proposed that the direct SLAM be implemented on a map fusion based method that is non rigid for the mobile robots [14]. Through this method, high accuracy is likely to be achieved for extensive evaluations and conclusions [15]. The industry of mobile robots continues to face numerous challenges majorly because of enabling technology, including perception, artificial intelligence and power sources [16]. Evidently, motors, actuators and gears are essential to the robotic world today. Work is still in progress in the development of soft robotics, artificial muscles and strategies of assembly that are aimed at developing the autonomous robot’s generation in the coming future that are power efficient and multifunctional. There is also the aspect of robots lacing synchrony, calibration and symmetry which serves to increase the photometric error. This challenge maybe addressed by adopting the direct odometry method [17]. Direct sparse odometry has been recommended by various studies since it has been found to reduce the photometric error. This can be associated to the fact that it combines a probabilistic model with joint optimization of model parameters [9]. It has also been found to maintain high levels of consistency especially because it incorporates geometry parameters which also increase accuracy levels [18].'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We address the problem of estimating the quality of Automatic Speech Recognition (ASR) output at utterance level, without recourse to manual reference transcriptions and when information about system’s confidence is not accessible. Given a source signal and its automatic transcription, we approach this problem as a regression task where the word error rate of the transcribed utterance has to be predicted. To this aim, we explore the contribution of different feature sets and the potential of different algorithms in testing conditions of increasing complexity. Results show that our automatic quality estimates closely approximate the word error rate scores calculated over reference transcripts, outperforming a strong baseline in all the testing conditions.', 'positives': ['We investigate the problem of predicting the quality of sentences produced by machine translation systems when reference translations are not available. The problem is addressed as a regression task and a method that takes into account the contribution of different features is proposed. We experiment with this method for translations produced by various MT systems and different language pairs, annotated with quality scores both automatically and manually. Results show that our method allows obtaining good estimates and that identifying a reduced set of relevant features plays an important role. The experiments also highlight a number of outstanding features that were consistently selected as the most relevant and could be used in different ways to improve MT performance or to enhance MT evaluation.'], 'negatives': [\"Internet web browsing has reached a critical tipping point. Increasingly, users rely more on mobile web browsers to access the Internet than desktop browsers. Meanwhile, webpages over the past decade have grown in complexity by more than tenfold. The fast penetration of mobile browsing and everricher webpages implies a growing need for high-performance mobile devices in the future to ensure continued end-user browsing experience. Failing to deliver webpages meeting hard cut-off constraints could directly translate to webpage abandonment or, for e-commerce websites, great revenue loss. However, mobile devices' limited battery capacity limits the degree of performance that mobile web browsing can achieve. In this paper, we demonstrate the benefits of heterogeneous systems with big/little cores each with different frequencies to achieve the ideal trade-off between high performance and energy efficiency. Through detailed characterizations of different webpage primitives based on the hottest 5,000 webpages, we build statistical inference models that estimate webpage load time and energy consumption. We show that leveraging such predictive models lets us identify and schedule webpages using the ideal core and frequency configuration that minimizes energy consumption while still meeting stringent cut-off constraints. Real hardware and software evaluations show that our scheduling scheme achieves 83.0% energy savings, while only violating the cut-off latency for 4.1% more webpages as compared with a performance-oriented hardware strategy. Against a more intelligent, OS-driven, dynamic voltage and frequency scaling scheme, it achieves 8.6% energy savings and 4.0% performance improvement simultaneously.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Matrix-factorization (MF)-based approaches prove to be highly accurate and scalable in addressing collaborative filtering (CF) problems. During the MF process, the non-negativity, which ensures good representativeness of the learnt model, is critically important. However, current non-negative MF (NMF) models are mostly designed for problems in computer vision, while CF problems differ from them due to their extreme sparsity of the target rating-matrix. Currently available NMF-based CF models are based on matrix manipulation and lack practicability for industrial use. In this work, we focus on developing an NMF-based CF model with a single-element-based approach. The idea is to investigate the non-negative update process depending on each involved feature rather than on the whole feature matrices. With the non-negative single-element-based update rules, we subsequently integrate the Tikhonov regularizing terms, and propose the regularized single-element-based NMF (RSNMF) model. RSNMF is especially suitable for solving CF problems subject to the constraint of non-negativity. The experiments on large industrial datasets show high accuracy and low-computational complexity achieved by RSNMF.', 'positives': ['Collaborative filtering aims at learning predictive models of user preferences, interests or behavior from community data, that is, a database of available user preferences. In this article, we describe a new family of model-based algorithms designed for this task. These algorithms rely on a statistical modelling technique that introduces latent class variables in a mixture model setting to discover user communities and prototypical interest profiles. We investigate several variations to deal with discrete and continuous response variables as well as with different objective functions. The main advantages of this technique over standard memory-based methods are higher accuracy, constant time prediction, and an explicit and compact model representation. The latter can also be used to mine for user communitites. The experimental evaluation shows that substantial improvements in accucracy over existing methods and published results can be obtained.'], 'negatives': ['The Netflix Prize is a collaborative filtering problem. This subfield of machine learning has become popular from the late 1990s with the spread of online services that use recommendation systems, such as e.g. Amazon, Yahoo! Music, and of course Netflix. The aim of such a system is to predict what items a user might like based on his/her and other users previous ratings. The dataset of Netflix Prize is much larger than the previously known benchmark sets, therefore we first show in the paper how to store it efficiently and adaptively to various algorithms. Then we describe the outline of our solution, called the Gravity Recommendation System (GRS), to the Netflix Prize contest, which is in the leader position with RMSE 0.8808 at the time of the submission of the paper. GRS comprises of the combination of different approaches that are presented in the main part of the paper. We then compare the effectiveness of some selected individual and combined approaches against a designated subset of the dataset, and discuss their important features and drawbacks. Beside the description of successful experiments we also report on the useful lessons of (temporarily) failed ideas and algorithms.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"One main concern for individuals to participate in the data collection of personal location history records is the disclosure of their location and related information when a user queries for statistical or pattern mining results derived from these records. In this paper, we investigate how the privacy goal that the inclusion of one's location history in a statistical database with location pattern mining capabilities does not substantially increase one's privacy risk. In particular, we propose a differentially private pattern mining algorithm for interesting geographic location discovery using a region quadtree spatial decomposition to preprocess the location points followed by applying a density-based clustering algorithm. A differentially private region quadtree is used for both de-noising the spatial domain and identifying the likely geographic regions containing the interesting locations. Then, a differential privacy mechanism is applied to the algorithm outputs, namely: the interesting regions and their corresponding stay point counts. The quadtree spatial decomposition enables one to obtain a localized reduced sensitivity to achieve the differential privacy goal and accurate outputs. Experimental results on synthetic datasets are used to show the feasibility of the proposed privacy preserving location pattern mining algorithm.\", 'positives': ['Preserving individual privacy when publishing data is a problem that is receiving increasing attention. Thanks to its simplicity the concept of k-anonymity, introduced by Samarati and Sweeney [1], established itself as one fundamental principle for privacy preserving data publishing. According to the k-anonymity principle, each release of data'], 'negatives': ['A mixture model is a weighted combination of probability distributions. We consider the problem of identifying the component distributions of a mixture model by examining random samples from the mixture. Our main result is that a simple spectral algorithm for learning a mixture of k spherical Gaussians in n-dimensions works remarkably well — it succeeds in identifying the Gaussians assuming essentially the minimum possible separation between their centers that keeps them unique. Unlike existing algorithms, the sample complexity and running time are polynomial in both n and k. We then apply it to the more general problem of learning a mixture of weakly isotropic distributions (e.g. a mixture of uniform distributions on cubes). The algorithm is robust in that it can tolerate small amounts of noise and thus can also be used for the more general problem of finding the best mixture model that fits a given data set, provided there exists a good fit.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper describes the convergence of some of the most influential technologies in the last few years, namely data warehousing (DW), on-line analytical processing (OLAP), and the Semantic Web (SW). OLAP is used by enterprises to derive important business-critical knowledge from data inside the company. However, the most interesting OLAP queries can no longer be answered on internal data alone, external data must also be discovered (most often on the web), acquired, integrated, and (analytically) queried, resulting in a new type of OLAP, exploratory OLAP. When using external data, an important issue is knowing the precise semantics of the data. Here, SW technologies come to the rescue, as they allow semantics (ranging from very simple to very complex) to be specified for web-available resources. SW technologies do not only support capturing the “passive” semantics, but also support active inference and reasoning on the data. The paper first presents a characterization of DW/OLAP environments, followed by an introduction to the relevant SW foundation concepts. Then, it describes the relationship of multidimensional (MD) models and SW technologies, including the relationship between MD models and SW formalisms. Next, the paper goes on to survey the use of SW technologies for data modeling and data provisioning, including semantic data annotation and semantic-aware extract, transform, and load (ETL) processes. Finally, all the findings are discussed and a number of directions for future research are outlined, including SW support for intelligent MD querying, using SW technologies for providing context to data warehouses, and scalability issues.', 'positives': ['Many organizations nowadays face the problem of accessing existing data sources by means of flexible mechanisms that are both powerful and efficient. Ontologies are widely considered as a suitable formal tool for sophisticated data access. The ontology expresses the domain of interest of the information system at a high level of abstraction, and the relationship between data at the sources and instances of concepts and roles in the ontology is expressed by means of mappings. In this paper we present a solution to the problem of designing effective systems for ontology-based data access. Our solution is based on three main ingredients. First, we present a new ontology language, based on Description Logics, that is particularly suited to reason with large amounts of instances. The second ingredient is a novel mapping language that is able to deal with the so-called impedance mismatch problem, i.e., the problem arising from the difference between the basic elements managed by the sources, namely data, and the elements managed by the ontology, namely objects. The third ingredient is the query answering method, that combines reasoning at the level of the ontology with specific mechanisms for both taking into account the mappings and efficiently accessing the data at the sources.'], 'negatives': ['Label estimation is an important component in an unsupervised person re-identification (re-ID) system. This paper focuses on cross-camera label estimation, which can be subsequently used in feature learning to learn robust re-ID models. Specifically, we propose to construct a graph for samples in each camera, and then graph matching scheme is introduced for cross-camera labeling association. While labels directly output from existing graph matching methods may be noisy and inaccurate due to significant cross-camera variations, this paper propose a dynamic graph matching (DGM) method. DGM iteratively updates the image graph and the label estimation process by learning a better feature space with intermediate estimated labels. DGM is advantageous in two aspects: 1) the accuracy of estimated labels is improved significantly with the iterations; 2) DGM is robust to noisy initial training data. Extensive experiments conducted on three benchmarks including the large-scale MARS dataset show that DGM yields competitive performance to fully supervised baselines, and outperforms competing unsupervised learning methods.1'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The Penn Treebank, in its eight years of operation (1989-1996), produced approximately 7 million words of part-of-speech tagged text, 3 million words of skeletally parsed text, over 2 million words of text parsed for predicateargument structure, and 1.6 million words of transcribed spoken text annotated for speech disfluencies. This paper describes the design of the three annotation schemes used by the Treebank: POS tagging, syntactic bracketing, and disfluency annotation and the methodology employed in production. All available Penn Treebank materials are distributed by the Linguistic Data Consortium http://www.ldc.upenn.edu.', 'positives': ['The Penn Treebank has recently implemented a new syntactic annotation scheme, designed to highlight aspects of predicate-argument structure. This paper discusses the implementation of crucial aspects of this new annotation scheme. It incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as \"underlying\" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions, provides some non-context free annotational mechanism to allow the structure of discontinuous constituents to be easily recovered, and allows for a clear, concise tagging system for some semantic roles. 1. I N T R O D U C T I O N During the first phase of the The Penn Treebank project [10], ending in December 1992, 4.5 million words of text were tagged for part-of-speech, with about two-thirds of this material also annotated with a skeletal syntactic bracketing. All of this material has been hand corrected after processing by automatic tools. The largest component of the corpus consists of materials from the Dow-Jones News Service; over 1.6 million words of this material has been hand parsed, with an additional 1 million words tagged for part of speech. Also included is a skeletally parsed version of the Brown corpus, the classic million word balanced corpus of American English [5, 6]. hand-retagged using the Penn Treebank tagset. The level of syntactic analysis annotated during this phase of this project was an extended and somewhat modified form of the skeletal analysis which has been produced by the treebanking effort in Lancaster, England [7]. The released materials in the current Penn Treebank, although still in very preliminary form, have been widely distributed, both directly by us, on the ACL/DCI CD-ROM, and now on CD-ROM by the Linguistic Data Consortium; it has been used for purposes ranging from serving as a gold-standard for parser testing to serving as a basis for the induction of stochastic grammars to serving as a basis for quick lexicon induction. Many users of the Penn Treebank now want forms of annotation richer than provided by the project\\'s first phase, as well as an increase in the consistency of the preliminary corpus. Some would also like a less skeletal form of annotation, expanding the essentially context-free analysis of the current treebank to indicate non-contiguous structures and dependencies. Most crucially, there is a strong sense that the Treebank could be of much more use if it explicitly provided some form of predicate-argument structure. The desired level of representation would make explicit at least the logical subject and logical object of the verb, and indicate, at least in clear cases, how subconstituents are semantically related to their predicates. Such a representation could serve as both a starting point for the kinds of SEMEVAL representations now being discussed as a basis for evaluation of human language technology within the ARPA HLT program, and as a basis for \"glass box\" evaluation of parsing technology. The ongoing effort [1] to develop a standard objective methodology to compare parser outputs across widely divergent grammatical frameworks has now resulted in a widely supported standard for parser comparison. On the other hand, many existing parsers cannot be evaluated by this metric because they directly produce a level of representation closer to predicate-argument structure than to classical surface grammatical analysis. Hand-in-hand with this limitation of the existing Penn Treebank for parser testing is a parallel limitation for automatic methods for parser training for parsers based on deeper representations. There is also a problem of maintaining consistency with the fairly small (less than 100 page) style book used in the the first phase of the project. 2. A N E W A N N O T A T I O N S C H E M E We have recently completed a detailed style-book for this new level of analysis, with consensus across annotators about the particulars of the analysis. This project has taken about eight months of ten-hour a week effort across a significant subset of all the personnel of the Penn Treebank. Such a stylebook, much larger, and much more fully specified than our initial stylebook, is a prerequisite for high levels of interannotator agreement. It is our hope that such a stylebook will also alleviate much of the need for extensive cross-talk between annotators during the annotation task, thereby increasing throughput as well. To ensure that the rules of this new stylebook remain in force, we are now giving annotators about 10% overlapped material to evaluate inter-annotator consistency throughout this new project. We have now begun to annotate this level of structure editing the present Penn Treebank; we intend to automatically extract a bank of predicate-argument structures intended at the very least for parser evaluation from the resulting annotated corpus. The remainder of this paper will discuss the implementation of each of four crucial aspects of the new annotation scheme,'], 'negatives': ['Text clustering methods can be used to structure large sets of text or hypertext documents. The well-known methods of text clustering, however, do not really address the special problems of text clustering: very high dimensionality of the data, very large size of the databases and understandability of the cluster description. In this paper, we introduce a novel approach which uses frequent item (term) sets for text clustering. Such frequent sets can be efficiently discovered using algorithms for association rule mining. To cluster based on frequent term sets, we measure the mutual overlap of frequent sets with respect to the sets of supporting documents. We present two algorithms for frequent term-based text clustering, FTC which creates flat clusterings and HFTC for hierarchical clustering. An experimental evaluation on classical text documents as well as on web documents demonstrates that the proposed algorithms obtain clusterings of comparable quality significantly more efficiently than state-of-the- art text clustering algorithms. Furthermore, our methods provide an understandable description of the discovered clusters by their frequent term sets.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper we introduce a large-scale hand pose dataset, collected using a novel capture method. Existing datasets are either generated synthetically or captured using depth sensors: synthetic datasets exhibit a certain level of appearance difference from real depth images, and real datasets are limited in quantity and coverage, mainly due to the difficulty to annotate them. We propose a tracking system with six 6D magnetic sensors and inverse kinematics to automatically obtain 21-joints hand pose annotations of depth maps captured with minimal restriction on the range of motion. The capture protocol aims to fully cover the natural hand pose space. As shown in embedding plots, the new dataset exhibits a significantly wider and denser range of hand poses compared to existing benchmarks. Current state-of-the-art methods are evaluated on the dataset, and we demonstrate significant improvements in cross-benchmark performance. We also show significant improvements in egocentric hand pose estimation with a CNN trained on the new dataset.', 'positives': ['Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it.'], 'negatives': ['Imaging plays a central role in the diagnosis and treatment planning of brain tumor. An accurate segmentation is critical, especially when the tumor morphological changes remain subtle, irregular and difficult to assess by clinical examination. Traditionally, segmentation is performed manually in clinical environment that is operator dependent and very tedious and time consuming labor intensive work. However, automated tumor segmentation in MRI brain tumor poses many challenges with regard to characteristics of an image. A comparison of three different semi-automated methods, viz., modified gradient magnitude region growing technique (MGRRGT), level set and a marker controlled watershed method is undertaken here for evaluating their relative performance in the segmentation of tumor. A study on 9 samples using MGRRGT reveals that all the errors are within 6 to 23% in comparison to other two methods.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We present an optimally modified log-spectral amplitude estimator, which minimizes the mean-square error of the log-spectra for speech signals under signal presence uncertainty. We propose an estimator for the a priori signal-to-noise ratio (SNR), and introduce an efficient estimator for the a priori speech absence probability. Speech presence probability is estimated for each frequency bin and each frame by a soft-decision approach, which exploits the strong correlation of speech presence in neighboring frequency bins of consecutive frames. Objective and subjective evaluation confirm superiority in noise suppression and quality of the enhanced speech.', 'positives': ['This paper presents a study of the noise suppression technique proposed by Ephraim and Malah. This technique has been used recently for the restoration of degraded audio recordings because it is free of the frequently encountered ‘musical noise’ artifact. It is demonstrated how this artifact is actually eliminated without bringing distortion to the recorded signal even if the noise is only poorly stationary.'], 'negatives': ['Objective measurement of non-functional requirements (NFRs) in any software is one of the most difficult activities. This is because the inherent nature of the NFRs makes their common understanding difficult. The problem is compounded by the fact that the requirements for any software are usually vague about the NFRs that the software should satisfy and how to evaluate the NFRs in the final software. An ideal solution to these problems will be the development and usage of metrics for all NFRs – this will let the software be checked for the NFRs at all stages of its lifecycle and in case of deviation from the requirements corrective action may be taken. While there are several NFRs such as performance, maintainability, reusability, security, and so on, among the more important of the NFRs is adaptability. Intuitive definition of adaptability is the extent to which a software system adapts to change in its environment. An adaptable software system can tolerate changes in its environment without external intervention. For example, a dual-mode cell phone can find out by itself if any one of the two wireless standards it supports is available at its current location and if so it starts using that standard. A practical metric for this NFR will help software developers and their organizations. This paper discusses our initial work in developing metrics for adaptability. In this paper we have developed several metrics for software adaptability. The advantage is that the metrics that we have developed are applicable at the architectural level. Since architecture development is the first stage of the design process, the extent to which the architecture is adaptable will determine the adaptability of the final software. Hence the metrics in this paper will help determine the extent to which the final software will be adaptable as well. This paper first defines software adaptability and then defines adaptability indices – the architecture adaptability index (AAI) and the software adaptability index (SAI). The application of these indices is illustrated with examples. Also the validity of these indices for hierarchical architectures, legacy systems and for dynamic adaptation is examined.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, the authors present research into adaptive architectural envelopes that adapt to environmental changes using active materials, as a result of application of biomimetic principles from plants to architecture. Buildings use large amounts of energy in order to maintain their internal comfort, because conventional buildings are designed to provide a static design solution. Most of the current solutions for facades are not designed for optimum adaptation to contextual issues and needs, while biological solutions to adaptation are often complex, multi-functional and highly responsive. We focus on plant adaptations to the environment, as, due to their immobility, they have developed special means of protection against weather changing conditions. Furthermore, recent developments in new technologies are allowing the possibility to transfer these plant adaptation strategies to technical implementation. These technologies include: multi-material 3D printing, advances in materials science and new capabilities in simulation software. Unlike traditional mechanical activation used for dynamic systems in kinetic facades, adaptive architectural envelopes require no complex electronics, sensors, or actuators. The paper proposes a research of the relationship that can be developed between active materials and environmental issues in order to propose innovative and low-tech design strategies to achieve living envelopes according to plant adaptation principles.', 'positives': ['Biomimetics, a name coined by Otto Schmitt in the 1950s for the transfer of ideas and analogues from biology to technology, has produced some significant and successful devices and concepts in the past 50 years, but is still empirical. We show that TRIZ, the Russian system of problem solving, can be adapted to illuminate and manipulate this process of transfer. Analysis using TRIZ shows that there is only 12% similarity between biology and technology in the principles which solutions to problems illustrate, and while technology solves problems largely by manipulating usage of energy, biology uses information and structure, two factors largely ignored by technology.'], 'negatives': ['Recent studies have used grating orientation as a measure of tactile spatial acuity on the fingerpad. In this task subjects identify the orientation of a grooved surface presented in either the proximal-distal or lateral-medial orientation. Other recent results have suggested that there might be a substantial anisotropy on the fingerpad related to spatial sensitivity. This anisotropy was revealed using a task in which subjects discriminated between a smooth and a grooved surface presented at different orientations on the fingerpad. The anisotropy was substantial enough that it might permit subjects to discriminate grating orientation on the basis of intensive rather than spatial cues. The present study examined the possibility that anisotropy on the fingerpad might provide cues in a spatial acuity task. The ability of subjects to discriminate between a smooth and a grooved surface was measured under conditions that are typically used in grating orientation tasks. No evidence of anisotropy was found. Also, using a grating orientation task, separate estimates were made of sensitivity in the proximal-distal and lateral-medial orientations. Again no evidence of anisotropy was found. Consistent with changes in the density of innervation, grating orientation sensitivity was found to vary as a function of location on the fingerpad. The results support the view that grating orientation is a valid measure of spatial acuity reflecting underlying neural, spatial mechanisms.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Generating numerical solutions to the eikonal equation and its many variations has a broad range of applications in both the natural and computational sciences. Efficient solvers on cutting-edge, parallel architectures require new algorithms that may not be theoretically optimal, but that are designed to allow asynchronous solution updates and have limited memory access patterns. This paper presents a parallel algorithm for solving the eikonal equation on fully unstructured tetrahedral meshes. The method is appropriate for the type of fine-grained parallelism found on modern massively-SIMD architectures such as graphics processors and takes into account the particular constraints and capabilities of these computing platforms. This work builds on previous work for solving these equations on triangle meshes; in this paper we adapt and extend previous two-dimensional strategies to accommodate three-dimensional, unstructured, tetrahedralized domains. These new developments include a local update strategy with data compaction for tetrahedral meshes that provides solutions on both serial and parallel architectures, with a generalization to inhomogeneous, anisotropic speed functions. We also propose two new update schemes, specialized to mitigate the natural data increase observed when moving to three dimensions, and the data structures necessary for efficiently mapping data to parallel SIMD processors in a way that maintains computational density. Finally, we present descriptions of the implementations for a single CPU, as well as multicore CPUs with shared memory and SIMD architectures, with comparative results against state-of-the-art eikonal solvers.', 'positives': ['This paper presents an efficient, fine-grained parallel algorithm for solving the Eikonal equation on triangular meshes. The Eikonal equation, and the broader class of Hamilton-Jacobi equations to which it belongs, have a wide range of applications from geometric optics and seismology to biological modeling and analysis of geometry and images. The ability to solve such equations accurately and efficiently provides new capabilities for exploring and visualizing parameter spaces and for solving inverse problems that rely on such equations in the forward model. Efficient solvers on state-of-the-art, parallel architectures require new algorithms that are not, in many cases, optimal, but are better suited to synchronous updates of the solution. In previous work [W. K. Jeong and R. T. Whitaker, SIAM J. Sci. Comput., 30 (2008), pp. 2512-2534], the authors proposed the fast iterative method (FIM) to efficiently solve the Eikonal equation on regular grids. In this paper we extend the fast iterative method to solve Eikonal equations efficiently on triangulated domains on the CPU and on parallel architectures, including graphics processors. We propose a new local update scheme that provides solutions of first-order accuracy for both architectures. We also propose a novel triangle-based update scheme and its corresponding data structure for efficient irregular data mapping to parallel single-instruction multiple-data (SIMD) processors. We provide detailed descriptions of the implementations on a single CPU, a multicore CPU with shared memory, and SIMD architectures with comparative results against state-of-the-art Eikonal solvers.'], 'negatives': ['User-generated online reviews can play a significant role in the success of retail products, hotels, restaurants, etc. However, review systems are often targeted by opinion spammers who seek to distort the perceived quality of a product by creating fraudulent reviews. We propose a fast and effective framework, FRAUDEAGLE, for spotting fraudsters and fake reviews in online review datasets. Our method has several advantages: (1) it exploits the network effect among reviewers and products, unlike the vast majority of existing methods that focus on review text or behavioral analysis, (2) it consists of two complementary steps; scoring users and reviews for fraud detection, and grouping for visualization and sensemaking, (3) it operates in a completely unsupervised fashion requiring no labeled data, while still incorporating side information if available, and (4) it is scalable to large datasets as its run time grows linearly with network size. We demonstrate the effectiveness of our framework on synthetic and real datasets; where FRAUDEAGLE successfully reveals fraud-bots in a large online app review database. Introduction The Web has greatly enhanced the way people perform certain activities (e.g. shopping), find information, and interact with others. Today many people read/write reviews on merchant sites, blogs, forums, and social media before/after they purchase products or services. Examples include restaurant reviews on Yelp, product reviews on Amazon, hotel reviews on TripAdvisor, and many others. Such user-generated content contains rich information about user experiences and opinions, which allow future potential customers to make better decisions about spending their money, and also help merchants improve their products, services, and marketing. Since online reviews can directly influence customer purchase decisions, they are crucial to the success of businesses. While positive reviews with high ratings can yield financial gains, negative reviews can damage reputation and cause monetary loss. This effect is magnified as the information spreads through the Web (Hitlin 2003; Mendoza, Poblete, and Castillo 2010). As a result, online review systems are attractive targets for opinion fraud. Opinion fraud involves reviewers (often paid) writing bogus reviews (Kost May 2012; Copyright c © 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Streitfeld August 2011). These spam reviews come in two flavors: defaming-spam which untruthfully vilifies, or hypespam that deceitfully promotes the target product. The opinion fraud detection problem is to spot the fake reviews in online sites, given all the reviews on the site, and for each review, its text, its author, the product it was written for, timestamp of posting, and its star-rating. Typically no user profile information is available (or is self-declared and cannot be trusted), while more side information for products (e.g. price, brand), and for reviews (e.g. number of (helpful) feedbacks) could be available depending on the site. Detecting opinion fraud, as defined above, is a non-trivial and challenging problem. Fake reviews are often written by experienced professionals who are paid to write high quality, believable reviews. As a result, it is difficult for an average potential customer to differentiate bogus reviews from truthful ones, just by looking at individual reviews text(Ott et al. 2011). As such, manual labeling of reviews is hard and ground truth information is often unavailable, which makes training supervised models less attractive for this problem. Summary of previous work. Previous attempts at solving the problem use several heuristics, such as duplicated reviews (Jindal and Liu 2008), or acquire bogus reviews from non-experts (Ott et al. 2011), to generate pseudo-ground truth, or a reference dataset. This data is then used for learning classification models together with carefully engineered features. One downside of such techniques is that they do not generalize: one needs to collect new data and train a new model for review data from a different domain, e.g., hotel vs. restaurant reviews. Moreover feature selection becomes a tedious sub-problem, as datasets from different domains might exhibit different characteristics. Other feature-based proposals include (Lim et al. 2010; Mukherjee, Liu, and Glance 2012). A large body of work on fraud detection relies on review text information (Jindal and Liu 2008; Ott et al. 2011; Feng, Banerjee, and Choi 2012) or behavioral evidence (Lim et al. 2010; Xie et al. 2012; Feng et al. 2012), and ignore the connectivity structure of review data. On the other hand, the network of reviewers and products contains rich information that implicitly represents correlations among these entities. The review network is also invaluable for detecting teams of fraudsters that operate collaboratively on targeted products. Our contributions. In this work we propose an unsuperProceedings of the Seventh International AAAI Conference on Weblogs and Social Media'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"In this paper, we present a framework for fraud intention recognition of public transport bus operators based on a deep learning approach using a stack of denoising and sparse autoencoders. Bus operator's fraud is a common problem in passenger transport organizations with cash payment method and tickets as proof of passenger on board. Fraud detection could be considered as an anomaly detection problem, and several techniques in this area have been applied to it. Our approach is an architecture based on a sort of Stacked Autoencoders with a Softmax Classification Layer and a normalization pre-phase using word2vec and a Denoising Autoencoder. This framework permits to recognize the fraud intention in the operators delivers account time, based on date, route, count of passengers on board, among other features. In this framework, the fraud intention is modeled as a binary classification problem, there is fraud intention, or there isn't. We compare our approach with another nondeep state of the art classification approaches like Logistic Regression, SVM, Decision Trees, KNN and Adaboost ensemble method, obtaining a superior performance on intention recognition, with an accuracy of 87.3 percent and an F1 score of 0.752.\", 'positives': ['Financial fraud is an issue with far reaching consequences in the finance industry, government, corporate sectors, and for ordinary consumers. Increasing dependence on new technologies such as cloud and mobile computing in recent years has compounded the problem. Traditional methods of detection involve extensive use of auditing, where a trained individual manually observes reports or transactions in an attempt to discover fraudulent behaviour. This method is not only time consuming, expensive and inaccurate, but in the age of big data it is also impractical. Not surprisingly, financial institutions have turned to automated processes using statistical and computational methods. This paper presents a comprehensive investigation on financial fraud detection practices using such data mining methods, with a particular focus on computational intelligence-based techniques. Classification of the practices based on key aspects such as detection algorithm used, fraud type investigated, and success rate have been covered. Issues and challenges associated with the current practices and potential future direction of research have also been identified.'], 'negatives': ['Frustration is almost universally accepted as the emotional outcome of a negative computing experience. Despite the wide use of the term, however, it has not been rigorously conceptualized as a factor in the study of the human–computer interface. This project sets out to explicate frustration as a pre-emotional state generated by the user’s appraisal of the interface as an impediment to goal attainment, and looks at how user characteristics, such as self-efficacy, relate to it. This project employed episode report methodology to capture data from 144 computer users’ reports of actual frustrating events as they took place. Diaries taken as users worked at their everyday tasks yield detailed data about the problems they encountered and included information about session length and an estimate of the time lost due to the experiences. Outcomes were measured as either situational or dispositional factors. Situational factors, having to do with specific events, predicted incident frustration. However, disposition variables, especially user self-efficacy, were much stronger, predicting incident and session frustration, and post-session mood. One surprising outcome was the failure of demographic variables as predictors of frustration. 2004 Elsevier Ltd. All rights reserved. 0747-5632/$ see front matter 2004 Elsevier Ltd. All rights reserved. doi:10.1016/j.chb.2004.03.015 * Corresponding author. Tel.: +1 301 854 9097. E-mail addresses: katieb@cmu.edu (K. Bessière), jnewhagen@jmail.umd.edu (J.E. Newhagen). 1 Tel.: +412 268 8827; fax: +412 268 1266. 942 K. Bessière et al. / Computers in Human Behavior 22 (2006) 941–961'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Microblogging services, such as Twitter, have become popular channels for people to express their opinions towards a broad range of topics. Twitter generates a huge volume of instant messages (i.e. tweets) carrying users' sentiments and attitudes every minute, which both necessitates automatic opinion summarization and poses great challenges to the summarization system. In this paper, we study the problem of opinion summarization for entities, such as celebrities and brands, in Twitter. We propose an entity-centric topic-based opinion summarization framework, which aims to produce opinion summaries in accordance with topics and remarkably emphasizing the insight behind the opinions. To this end, we first mine topics from #hashtags, the human-annotated semantic tags in tweets. We integrate the #hashtags as weakly supervised information into topic modeling algorithms to obtain better interpretation and representation for calculating the similarity among them, and adopt Affinity Propagation algorithm to group #hashtags into coherent topics. Subsequently, we use templates generalized from paraphrasing to identify tweets with deep insights, which reveal reasons, express demands or reflect viewpoints. Afterwards, we develop a target (i.e. entity) dependent sentiment classification approach to identifying the opinion towards a given target (i.e. entity) of tweets. Finally, the opinion summary is generated through integrating information from dimensions of topic, opinion and insight, as well as other factors (e.g. topic relevancy, redundancy and language styles) in an unified optimization framework. We conduct extensive experiments on a real-life data set to evaluate the performance of individual opinion summarization modules as well as the quality of the produced summary. The promising experiment results show the effectiveness of the proposed framework and algorithms.\", 'positives': ['With the flourish of the Web, online review is becoming a more and more useful and important information resource for people. As a result, automatic review mining and summarization has become a hot research topic recently. Different from traditional text summarization, review mining and summarization aims at extracting the features on which the reviewers express their opinions and determining whether the opinions are positive or negative. In this paper, we focus on a specific domain - movie review. A multi-knowledge based approach is proposed, which integrates WordNet, statistical analysis and movie knowledge. The experimental results show the effectiveness of the proposed approach in movie review mining and summarization.'], 'negatives': ['Some models of textual corpora employ text generation methods involving n-gram statistics, while others use latent topic variables inferred using the \"bag-of-words\" assumption, in which word order is ignored. Previously, these methods have not been combined. In this work, I explore a hierarchical generative probabilistic model that incorporates both n-gram statistics and latent topic variables by extending a unigram topic model to include properties of a hierarchical Dirichlet bigram language model. The model hyperparameters are inferred using a Gibbs EM algorithm. On two data sets, each of 150 documents, the new model exhibits better predictive accuracy than either a hierarchical Dirichlet bigram language model or a unigram topic model. Additionally, the inferred topics are less dominated by function words than are topics discovered using unigram statistics, potentially making them more meaningful.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Stock prices are formed based on short and/or long-term commercial and trading activities that reflect different frequencies of trading patterns. However, these patterns are often elusive as they are affected by many uncertain political-economic factors in the real world, such as corporate performances, government policies, and even breaking news circulated across markets. Moreover, time series of stock prices are non-stationary and non-linear, making the prediction of future price trends much challenging. To address them, we propose a novel State Frequency Memory (SFM) recurrent network to capture the multi-frequency trading patterns from past market data to make long and short term predictions over time. Inspired by Discrete Fourier Transform (DFT), the SFM decomposes the hidden states of memory cells into multiple frequency components, each of which models a particular frequency of latent trading pattern underlying the fluctuation of stock price. Then the future stock prices are predicted as a nonlinear mapping of the combination of these components in an Inverse Fourier Transform (IFT) fashion. Modeling multi-frequency trading patterns can enable more accurate predictions for various time ranges: while a short-term prediction usually depends on high frequency trading patterns, a long-term prediction should focus more on the low frequency trading patterns targeting at long-term return. Unfortunately, no existing model explicitly distinguishes between various frequencies of trading patterns to make dynamic predictions in literature. The experiments on the real market data also demonstrate more competitive performance by the SFM as compared with the state-of-the-art methods.', 'positives': ['In this paper, we present bidirectional Long Short Term Memory (LSTM) networks, and a modified, full gradient version of the LSTM learning algorithm. We evaluate Bidirectional LSTM (BLSTM) and several other network architectures on the benchmark task of framewise phoneme classification, using the TIMIT database. Our main findings are that bidirectional networks outperform unidirectional ones, and Long Short Term Memory (LSTM) is much faster and also more accurate than both standard Recurrent Neural Nets (RNNs) and time-windowed Multilayer Perceptrons (MLPs). Our results support the view that contextual information is crucial to speech processing, and suggest that BLSTM is an effective architecture with which to exploit it.'], 'negatives': ['Using a newly developed measure of global real economic activity, a structural decomposition of the real price of crude oil into three components is proposed: crude oil supply shocks; shocks to the global demand for all industrial commodities; and demand shocks that are specific to the crude oil market. The latter shock is designed to capture shifts in the price of oil driven by higher precautionary demand associated with concerns about future oil supply shortfalls. The paper estimates the dynamic effects of these shocks on the real price of oil. A historical decomposition sheds light on the causes of the major oil price shocks since 1975. The implications of higher oil prices for U.S. real GDP and CPI inflation are shown to depend on the cause of the oil price increase. Changes in the composition of shocks help explain why regressions of macroeconomic aggregates on oil prices tend to be unstable. Evidence that the recent increase in crude oil prices was driven primarily by global aggregate demand shocks helps explain why this oil price shock so far has failed to cause a major recession in the U.S.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Intel SGX provides confidentiality and integrity of a program running within the confines of an enclave, and is expected to enable valuable security applications such as private information retrieval. This paper is concerned with the security aspects of SGX in accessing a key system resource, files. Through concrete attack scenarios, we show that all existing SGX filesystems are vulnerable to either system call snooping, page fault, or cache based side-channel attacks. To address this security limitations in current SGX filesystems, we present OBLIVIATE, a data oblivious filesystem for Intel SGX. The key idea behind OBLIVIATE is in adapting the ORAM protocol to read and write data from a file within an SGX enclave. OBLIVIATE redesigns the conceptual components of ORAM for SGX environments, and it seamlessly supports an SGX program without requiring any changes in the application layer. OBLIVIATE also employs SGX-specific defenses and optimizations in order to ensure complete security with acceptable overhead. The evaluation of the prototype of OBLIVIATE demonstrated its practical effectiveness in running popular server applications such as SQLite and Lighttpd, while also achieving a throughput improvement of 2×8× over a baseline ORAM-based solution, and less than 2× overhead over an in-memory SGX filesystem.', 'positives': ['Traditional execution environments deploy Address Space Layout Randomization (ASLR) to defend against memory corruption attacks. However, Intel Software Guard Extension (SGX), a new trusted execution environment designed to serve security-critical applications on the cloud, lacks such an effective, well-studied feature. In fact, we find that applying ASLR to SGX programs raises non-trivial issues beyond simple engineering for a number of reasons: 1) SGX is designed to defeat a stronger adversary than the traditional model, which requires the address space layout to be hidden from the kernel; 2) the limited memory uses in SGX programs present a new challenge in providing a sufficient degree of entropy; 3) remote attestation conflicts with the dynamic relocation required for ASLR; and 4) the SGX specification relies on known and fixed addresses for key data structures that cannot be randomized. This paper presents SGX-Shield, a new ASLR scheme designed for SGX environments. SGX-Shield is built on a secure in-enclave loader to secretly bootstrap the memory space layout with a finer-grained randomization. To be compatible with SGX hardware (e.g., remote attestation, fixed addresses), SGX-Shield is designed with a software-based data execution protection mechanism through an LLVM-based compiler. We implement SGX-Shield and thoroughly evaluate it on real SGX hardware. It shows a high degree of randomness in memory layouts and stops memory corruption attacks with a high probability. SGX-Shield shows 7.61% performance overhead in running common microbenchmarks and 2.25% overhead in running a more realistic workload of an HTTPS server.'], 'negatives': ['A review of reported tissue optical properties summarizes the wavelength-dependent behavior of scattering and absorption. Formulae are presented for generating the optical properties of a generic tissue with variable amounts of absorbing chromophores (blood, water, melanin, fat, yellow pigments) and a variable balance between small-scale scatterers and large-scale scatterers in the ultrastructures of cells and tissues.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Whether they are made to entertain you, or to educate you, good video games engage you. Significant research has tried to understand engagement in games by measuring player experience (PX). Traditionally, PX evaluation has focused on the enjoyment of game, or the motivation of players; these factors no doubt contribute to engagement, but do decisions regarding play environment (e.g., the choice of game controller) affect the player more deeply than that? We apply self-determination theory (specifically satisfaction of needs and self-discrepancy represented using the five factors model of personality) to explain PX in an experiment with controller type as the manipulation. Our study shows that there are a number of effects of controller on PX and in-game player personality. These findings provide both a lens with which to view controller effects in games and a guide for controller choice in the design of new games. Our research demonstrates that including self-characteristics assessment in the PX evaluation toolbox is valuable and useful for understanding player experience.', 'positives': ['Human beings can be proactive and engaged or, alternatively, passive and alienated, largely as a function of the social conditions in which they develop and function. Accordingly, research guided by self-determination theory has focused on the social-contextual conditions that facilitate versus forestall the natural processes of self-motivation and healthy psychological development. Specifically, factors have been examined that enhance versus undermine intrinsic motivation, self-regulation, and well-being. The findings have led to the postulate of three innate psychological needs--competence, autonomy, and relatedness--which when satisfied yield enhanced self-motivation and mental health and when thwarted lead to diminished motivation and well-being. Also considered is the significance of these psychological needs and processes within domains such as health care, education, work, sport, religion, and psychotherapy.'], 'negatives': ['Mobility is a good indicator of health status and thus objective mobility data could be used to assess the health status of elderly patients. Accelerometry has emerged as an effective means for long-term physical activity monitoring in the elderly. However, the output of an accelerometer varies at different positions on a subject’s body, even for the same activity, resulting in high within-class variance. Existing accelerometer-based activity recognition systems thus require firm attachment of the sensor to a subject’s body. This requirement makes them impractical for long-term activity monitoring during unsupervised free-living as it forces subjects into a fixed life pattern and impede their daily activities. Therefore, we introduce a novel single-triaxial-accelerometer-based activity recognition system that reduces the high within-class variance significantly and allows subjects to carry the sensor freely in any pocket without its firm attachment. We validated our system using seven activities: resting (lying/sitting/standing), walking, walking-upstairs, walking-downstairs, running, cycling, and vacuuming, recorded from five positions: chest pocket, front left trousers pocket, front right trousers pocket, rear trousers pocket, and inner jacket pocket. Its simplicity, ability to perform activities unimpeded, and an average recognition accuracy of 94% make our system a practical solution for continuous long-term activity monitoring in the elderly.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this work, we are primarily concerned with robotic systems that learn online and continuously from multi-variate data-streams. Our first contribution is a new recursive kernel, which we have integrated into a sparse Gaussian Process to yield the Spatio-Temporal Online Recursive Kernel Gaussian Process (STORK-GP). This algorithm iteratively learns from time-series, providing both predictions and uncertainty estimates. Experiments on benchmarks demonstrate that our method achieves high accuracies relative to state-of-the-art methods. Second, we contribute an online tactile classifier which uses an array of STORK-GP experts. In contrast to existing work, our classifier is capable of learning new objects as they are presented, improving itself over time. We show that our approach yields results comparable to highly-optimised offline classification methods. Moreover, we conducted experiments with human subjects in a similar online setting with true-label feedback and present the insights gained.', 'positives': ['Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received growing attention in the machine learning community over the past decade. The book provides a long-needed, systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises. Code and datasets can be obtained on the web. Appendices provide mathematical background and a discussion of Gaussian Markov processes.'], 'negatives': ['Evidence from the Uto-Aztecan language Hiaki (Yaqui) shows that the internal structure of the verb phrase is tripartite, made up of (at least) VoiceP, vP and a lexical projection (√P or VP). The interaction of applicative and causative morphology, the existence of two kinds of causatives, and the interaction of passive and verbalizing morphology show that the external-argument introducing projection VoiceP (Kratzer, 1996) must be distinct from the verbalizing head vP (Marantz, 1997), as first proposed by Pylkkänen (2002) and subsequently by Cuervo (2003), Collins (2005), Alexiadou et al. (2006), Merchant (2008) and Harley (2009), among many others. This result stands in opposition to earlier proposals in which a single projection, vP, serves both to verbalize and to introduce the external argument, as in Chomsky (1995), Marantz (1997), and Harley (1995). It also challenges the conclusions of Coon and Preminger (2010), who give explicit arguments for the identity of external-argument-introducing Voice and verbalizing v. © 2012 Elsevier B.V. All rights reserved.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper proposes a method for achieving accurate ego-vehicle global localization with respect to an approaching intersection; the method is based on the data alignment of the information from two input systems: a Sensorial Perception system, on-board of the ego-vehicle, and an a priori digital map. For this purpose an Extended Digital Map is proposed that contains the detailed information about the intersection infrastructure: detailed landmarks accurately measured and positioned on the map. The data alignment mechanism is thus based on superimposing the sensorial detected landmarks with the corresponding, correctly positioned map landmarks stored in the new Extended Digital Map. The data Alignment Algorithm requires as input, beside the information from the two input systems, the ego-vehicle driving lane. This information is inferred by using a probabilistic approach in the form of a Bayesian Network; the uncertain and noisy character of the sensorial data require such a probabilistic approach in the quest of the ego-lane.', 'positives': ['Many urban navigation applications (e.g., autonomous navigation, driver assistance systems) can benefit greatly from localization with centimeter accuracy. Yet such accuracy cannot be achieved reliably with GPS-based inertial guidance systems, specifically in urban settings. We propose a technique for high-accuracy localization of moving vehicles that utilizes maps of urban environments. Our approach integrates GPS, IMU, wheel odometry, and LIDAR data acquired by an instrumented vehicle, to generate high-resolution environment maps. Offline relaxation techniques similar to recent SLAM methods [2, 10, 13, 14, 21, 30] are employed to bring the map into alignment at intersections and other regions of self-overlap. By reducing the final map to the flat road surface, imprints of other vehicles are removed. The result is a 2-D surface image of ground reflectivity in the infrared spectrum with 5cm pixel resolution. To localize a moving vehicle relative to these maps, we present a particle filter method for correlating LIDAR measurements with this map. As we show by experimentation, the resulting relative accuracies exceed that of conventional GPS-IMU-odometry-based methods by more than an order of magnitude. Specifically, we show that our algorithm is effective in urban environments, achieving reliable real-time localization with accuracy in the 10centimeter range. Experimental results are provided for localization in GPS-denied environments, during bad weather, and in dense traffic. The proposed approach has been used successfully for steering a car through narrow, dynamic urban roads.'], 'negatives': ['We present a SiGe BiCMOS fully integrated 75–83 GHz FMCW synthesizer for automotive radar applications. Performance enhancements were achieved by utilizing the bulk-drain parasitic variable capacitance of P-channel transistors, embedded in a gm-boosted Colpitts VCO, for frequency control. This mechanism was incorporated in a dual path PLL, providing low loop bandwidth variation over the whole output frequency range, −97 dBc/Hz phase noise at 1 MHz offset and maximum chirp rate of 100 GHz/mSec.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We present methods of extractive query-oriented single-document summarization using a deep auto-encoder (AE) to compute a feature space from the term-frequency (tf ) input. Our experiments explore both local and global vocabularies. We investigate the effect of adding small random noise to local tf as the input representation of AE, and propose an ensemble of such noisy AEs which we call the Ensemble Noisy Auto-Encoder (ENAE). ENAE is a stochastic version of an AE that adds noise to the input text and selects the top sentences from an ensemble of noisy runs. In each individual experiment of the ensemble, a different randomly generated noise is added to the input representation. This architecture changes the application of the AE from a deterministic feed-forward network to a stochastic runtime model. Experiments show that the AE using local vocabularies clearly provide a more discriminative feature space and improves the recall on average 11.2%. The ENAE can make further improvements, particularly in selecting informative sentences. To cover a wide range of topics and structures, we perform experiments on two different publicly available email corpora that are specifically designed for text summarization. We used ROUGE as a fully automatic metric in text summarization and we presented the average ROUGE-2 recall for all experiments.', 'positives': ['It has been said for decades (if not centuries) that more and more information is becoming available and that tools are needed to handle it. Only recently, however, does it seem that a sufficient quantity of this information is electronically available to produce a widespread need for automatic summarization. Consequently, this research area has enjoyed a resurgence of interest in the past few years, as illustrated by a 1997 ACL Workshop, a 1998 AAAI Spring Symposium and in the same year SUMMAC: a TREC-like TIPSTER-funded summarization evaluation conference. Not unexpectedly, there is now a book to add to this list: Advances in Automatic Summarization, a collection of papers edited by Inderjeet Mani and Mark T. Maybury and published by The MIT Press. Half of it is a historical record: thirteen previously published papers, including classics such as Luhn’s 1958 word-counting sentence-extraction paper, Edmundson’s 1969 use of cue words and phrases, and Kupiec, Pedersen, and Chen’s 1995 trained summarizer. The other half of the book holds new papers, which attempt to cover current issues and point to future trends. It starts with a paper by Karen Spärck Jones, which acts as an overall introduction. In it, the summarization process and the uses of summaries are broken down into their constituent parts and each of these is discussed (it reminded me of a much earlier Spärck Jones paper on categorization [1970]). Despite its comprehensiveness and authority, I must confess to finding this opener heavy going at times. The rest of the papers are grouped into six sections, each of which is prefaced with two or three well-written pages from the editors. These introductions contain valuable commentary on the coming papers—even pointing out a possible flaw in the evaluation part of one. The opening section holds three papers on so-called classical approaches. Here one finds the oft-cited papers of Luhn, Edmundson, and Pollock and Zamora. As a package, these papers provide a novice with a good idea of how basic summarization works. My only quibble was in their reproduction. In Luhn’s paper, an article from Scientific American is summarized and it would have been beneficial to have this included in the book as well. Some of the figures in another paper contained very small fonts and were hard to read; fixing this for a future print run is probably worth thinking about. The next section holds papers on corpus-based approaches to summarization, starting with Kupiec et al.’s paper about a summarizer trained on an existing corpus of manually abstracted documents. Two new papers building upon the Kupiec et al. work follow this. Exploiting the discourse structure of a document is the topic of the next section. Of the five papers here, I thought Daniel Marcu’s was the best, nicely describing summarization work so far and then clearly explaining his system, which is based on Rhetorical Structure Theory. The following section on knowledge-rich approaches to summarization covers such things as Wendy Lehnert’s work on breaking'], 'negatives': ['Recently, economic depression, which scoured all over the world, affects business organizations and banking sectors. Such economic pose causes a severe attrition for banks and customer retention becomes impossible. Accordingly, marketing managers are in need to increase marketing campaigns, whereas organizations evade both expenses and business expansion. In order to solve such riddle, data mining techniques is used as an uttermost factor in data analysis, data summarizations, hidden pattern discovery, and data interpretation. In this paper, rough set theory and decision tree mining techniques have been implemented, using a real marketing data obtained from Portuguese marketing campaign related to bank deposit subscription [Moro et al. , 2011]. The paper aims to improve the efficiency of the marketing campaigns and helping the decision makers by reducing the number of features, that describes the dataset and spotting on the most significant ones, and predict the deposit customer retention criteria based on potential predictive rules.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Developers sometimes maintain an internal copy of another software or fork development of an existing project. This practice can lead to software vulnerabilities when the embedded code is not kept up to date with upstream sources. We propose an automated solution to identify clones of packages without any prior knowledge of these relationships. We then correlate clones with vulnerability information to identify outstanding security problems. This approach motivates software maintainers to avoid using cloned packages and link against system wide libraries. We propose over 30 novel features that enable us to use to use pattern classification to accurately identify package-level clones. To our knowledge, we are the first to consider clone detection as a classification problem. Our results show our system, Clonewise, compares well to manually tracked databases. Based on our work, over 30 unknown package clones and vulnerabilities have been identified and patched.', 'positives': ['This paper has always been one of my favorite “children,” combining as it does elements of the duality of linear programming and combinatorial tools from graph theory. It may be of some interest to tell the story of its origin. I spent the summer of 1953 at the Institute for Numerical Analysis which was housed on the U.C.L.A. campus. I was supported by the National Bureau of Standards and shared an office with Ted Motzkin, a pioneer in the theory of inequalities and one of the most scholarly mathematicians I have ever known. I had no fixed duties and spent the summer working on subjects that were of interest to me at the time, such as the traveling salesman problem and the assignment problem. The Institute for Numerical Analysis was the home of the SWAC (Standards Western Automatic Computer), which had been designed by Harry Huskey and had a memory of 256 words of 40 bits each on 40 Williamson tubes. The formulation of the assignment problem as a linear program was well known, but a 10 by 10 assignment problem has 100 variables in its primal statement and 100 constraints in the dual and so was too large for the SWAC to solve as a linear program. The SEAC (Standard Eastern Automatic Computer), housed in the National Bureau of Standards in Washington, could solve linear programs with about 25 variables and 25 constraints. The SEAC had a liquid mercury memory system which was extremely limiting. During that summer, I was reading König’s book on graph theory. I recognized the following theorem of König to be a pre-linear programming example of duality: If the numbers of a matrix are 0’s and 1’s, then the minimum number of rows and columns that will contain all of the 1’s is equal to the maximum number of 1’s that can be chosen, with no two in the same row or column.'], 'negatives': [\"Creatine is one of the most popular nutritional ergogenic aids for athletes. Studies have consistently shown that creatine supplementation increases intramuscular creatine concentrations which may help explain the observed improvements in high intensity exercise performance leading to greater training adaptations. In addition to athletic and exercise improvement, research has shown that creatine supplementation may enhance post-exercise recovery, injury prevention, thermoregulation, rehabilitation, and concussion and/or spinal cord neuroprotection. Additionally, a number of clinical applications of creatine supplementation have been studied involving neurodegenerative diseases (e.g., muscular dystrophy, Parkinson's, Huntington's disease), diabetes, osteoarthritis, fibromyalgia, aging, brain and heart ischemia, adolescent depression, and pregnancy. These studies provide a large body of evidence that creatine can not only improve exercise performance, but can play a role in preventing and/or reducing the severity of injury, enhancing rehabilitation from injuries, and helping athletes tolerate heavy training loads. Additionally, researchers have identified a number of potentially beneficial clinical uses of creatine supplementation. These studies show that short and long-term supplementation (up to 30\\xa0g/day for 5 years) is safe and well-tolerated in healthy individuals and in a number of patient populations ranging from infants to the elderly. Moreover, significant health benefits may be provided by ensuring habitual low dietary creatine ingestion (e.g., 3\\xa0g/day) throughout the lifespan. The purpose of this review is to provide an update to the current literature regarding the role and safety of creatine supplementation in exercise, sport, and medicine and to update the position stand of International Society of Sports Nutrition (ISSN).\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'A novel feeding system using substrate integrated waveguide (SIW) technique for antipodal linearly tapered slot array antenna (ALTSA) is presented in this paper. After making studies by simulations for a SIW fed ALTSA cell, a 1/spl times/8 ALTSA array fed by SIW feeding system at X-band is fabricated and measured, and the measured results show that this array antenna has a wide bandwidth and good performances.', 'positives': ['A new generation of high-frequency integrated circuits is presented, which is called substrate integrated circuits (SICs). Current state-of-the-art of circuit design and implementation platforms based on this new concept are reviewed and discussed in detail. Different possibilities and numerous advantages of the SICs are shown for microwave, millimeter-wave and optoelectronics applications. Practical examples are illustrated with theoretical and experimental results for substrate integrated waveguide (SIW), substrate integrated slab waveguide (SISW) and substrate integrated nonradiating dielectric (SINRD) guide circuits. Future research and development trends are also discussed with reference to low-cost innovative design of millimeter-wave and optoelectronic integrated circuits.'], 'negatives': ['Usually transitions from microstrip line to rectangular waveguide are made with three-dimensional complex mounting structures. In this paper, a new planar platform is developed in which the microstrip line and rectangular waveguide are fully integrated on the same substrate, and they are interconnected via a simple taper. Our experiments at 28 GHz show that an effective bandwidth of 12% at 20 dB return loss is obtained with an in-band insertion loss better than 0.3 dB. The new transition allows a complete integration of waveguide components on substrate with MICs and MMICs.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"The digital control of speed of a permanent magnet DC motor based on a digital computer is analyzed in this paper. Datasheet information about the DC motor was initially unknown. Therefore, the parameter identification and parameter estimation of the motor was done. A type of PID controller, which parameters were optimized (PI), was used in process of controlling the speed of the motor. DAQ acquisition card was used for the purposes of motor's parameter identification and realization of computer control of motor speed in closed feedback loop. Manipulations with the same DAQ card were done using Matlab/Simulink software package. Experimental results were compared with the results obtained by simulation.\", 'positives': ['Model reference adaptive control (MRAC) is one of the various techniques of solving the control problem when the parameters of the controlled process are poorly known or vary during normal operation. To understand the dynamic behavior of a dc motor it is required to know its parameters; armature inductance and resistance (La, Ra), inertia of the rotor (Jm), motor constant (Km), friction coefficient (Bm), etc. To identify these parameters, some experiments should be performed. However, motor parameters change under operation according to several conditions. Therefore, the performance of controller, which has been designed considering constant motor parameters becomes poorer. For this reason, a model reference adaptive control method is proposed to control the position of a dc motor without requiring fixed motor parameters. Experimental results show how well this method controls the position of a permanent magnet dc motor.'], 'negatives': [\"We investigate the possibility of using a combination of a smartphone and a smartwatch, carried by a shopper, to get insights into the shopper's behavior inside a retail store. The proposed IRIS framework uses standard locomotive and gestural micro-activities as building blocks to define novel composite features that help classify different facets of a shopper's interaction/experience with individual items, as well as attributes of the overall shopping episode or the store. Besides defining such novel features, IRIS builds a novel segmentation algorithm, which partitions the duration of an entire shopping episode into atomic item-level interactions, by using a combination of feature-based landmarking, change point detection and variable-order HMM-based sequence prediction. Experiments with 50 real-life grocery shopping episodes, collected from 25 shoppers, we show that IRIS can demarcate item-level interactions with an accuracy of approx. 91%, and subsequently characterize item-and-episode level shopper behavior with accuracies of over 90%.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this work, a context-based multisensor system, applied for pedestrian detection in urban environment, is presented. The proposed system comprises three main processing modules: (i) a LIDAR-based module acting as primary object detection, (ii) a module which supplies the system with contextual information obtained from a semantic map of the roads, and (iii) an image-based detection module, using sliding-window detectors, with the role of validating the presence of pedestrians in regions of interest (ROIs) generated by the LIDAR module. A Bayesian strategy is used to combine information from sensors on-board the vehicle (‘local’ information) with information contained in a digital map of the roads (‘global’ information). To support experimental analysis, a multisensor dataset, named Laser and Image Pedestrian Detection dataset (LIPD), is used. The LIPD dataset was collected in an urban environment, at day light conditions, using an electrical vehicle driven at low speed. A down sampling method, using support vectors extracted from multiple linear-SVMs, was used to reduce the cardinality of the training set and, as consequence, to decrease the CPU-time during the training process of image-based classifiers. The performance of the system is evaluated, in terms of true positive rate and false positives per frame, using three image-detectors: a linear-SVM, a SVM-cascade, and a benchmark method. Additionally, experiments are performed to assess the impact of contextual information on the performance of the detection system.', 'positives': ['In intelligent transportation systems (ITS), transportation infrastructure is complimented with information and communication technologies with the objectives of attaining improved passenger safety, reduced transportation time and fuel consumption and vehicle wear and tear. With the advent of modern communication and computational devices and inexpensive sensors it is possible to collect and process data from a number of sources. Data fusion (DF) is collection of techniques by which information from multiple sources are combined in order to reach a better inference. DF is an inevitable tool for ITS. This paper provides a survey of how DF is used in different areas of ITS. 2010 Elsevier B.V. All rights reserved.'], 'negatives': ['Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, the authors describe the design and control of RHex, a power autonomous, untethered, compliant-legged hexapod robot. RHex has only six actuators—one motor located at each hip—achieving mechanical simplicity that promotes reliable and robust operation in real-world tasks. Empirically stable and highly maneuverable locomotion arises from a very simple clock-driven, openloop tripod gait. The legs rotate full circle, thereby preventing the common problem of toe stubbing in the protraction (swing) phase. An extensive suite of experimental results documents the robot’s significant “intrinsic mobility”—the traversal of rugged, broken, and obstacle-ridden ground without any terrain sensing or actively controlled adaptation. RHex achieves fast and robust forward locomotion traveling at speeds up to one body length per second and traversing height variations well exceeding its body clearance.', 'positives': [\"Despite impressive variation in leg number, length, position and type of skeleton, similarities of legged, pedestrian locomotion exist in energetics, gait, stride frequency and ground-reaction force. Analysis of data available in the literature showed that a bouncing, spring-mass, monopode model can approximate the energetics and dynamics of trotting, running, and hopping in animals as diverse as cockroaches, quail and kangaroos. From an animal's mechanical-energy fluctuation and ground-reaction force, we calculated the compression of a virtual monopode's leg and its stiffness. Comparison of dimensionless parameters revealed that locomotor dynamics depend on gait and leg number and not on body mass. Relative stiffness per leg was similar for all animals and appears to be a very conservative quantity in the design of legged locomotor systems. Differences in the general dynamics of gait are based largely on the number of legs acting simultaneously to determine the total stiffness of the system. Four- and six-legged trotters had a greater whole body stiffness than two-legged runners operating their systems at about the same relative speed. The greater whole body stiffness in trotters resulted in a smaller compression of the virtual leg and a higher natural frequency and stride frequency.\"], 'negatives': [\"The problem addressed here concerns a set of isolated processors, some unknown subset of which may be faulty, that communicate only by means of two-party messages. Each nonfaulty processor has a private value of information that must be communicated to each other nonfaulty processor. Nonfaulty processors always communicate honestly, whereas faulty processors may lie. The problem is to devise an algorithm in which processors communicate their own values and relay values received from others that allows each nonfaulty processor to infer a value for each other processor. The value inferred for a nonfaulty processor must be that processor's private value, and the value inferred for a faulty one must be consistent with the corresponding value inferred by each other nonfaulty processor.\\nIt is shown that the problem is solvable for, and only for, n ≥ 3m + 1, where m is the number of faulty processors and n is the total number. It is also shown that if faulty processors can refuse to pass on information but cannot falsely relay information, the problem is solvable for arbitrary n ≥ m ≥ 0. This weaker assumption can be approximated in practice using cryptographic methods.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper demonstrates a tunable terahertz (THz) filter and a modulator based on an electrostatic micro electro mechanical systems (MEMS) reconfigurable split ring resonator (SRR) array. The device uses tunable metamaterial concept, in which an RF-MEMS (radio frequency-MEMS) capacitor is embedded in each SRR unit cell to tune the electromagnetic resonant frequency. By utilizing THz time domain spectroscopy (THz-TDS) measurement and through the voltage actuation, we have controlled the THz transmission of the metamaterial device, and thus demonstrated a tunable filter. Since the low loss material of fused quartz is used as the substrate, the device shows a high contrast ratio THz switch at a given frequency by controlling the capacitance of the RF-MEMS capacitor. The dynamic performance of the switch, i.e., the modulation ability, is also characterized by THz-TDS. The measurement results show up to 2 kHz of the modulation speed with the TDS operated. The device is developed by the surface micromachining process with three photolithography steps.', 'positives': ['The development of artificially structured electromagnetic materials, termed metamaterials, has led to the realization of phenomena that cannot be obtained with natural materials. This is especially important for the technologically relevant terahertz (1\\u2009THz\\u2009=\\u20091012\\u2009Hz) frequency regime; many materials inherently do not respond to THz radiation, and the tools that are necessary to construct devices operating within this range—sources, lenses, switches, modulators and detectors—largely do not exist. Considerable efforts are underway to fill this ‘THz gap’ in view of the useful potential applications of THz radiation. Moderate progress has been made in THz generation and detection; THz quantum cascade lasers are a recent example. However, techniques to control and manipulate THz waves are lagging behind. Here we demonstrate an active metamaterial device capable of efficient real-time control and manipulation of THz radiation. The device consists of an array of gold electric resonator elements (the metamaterial) fabricated on a semiconductor substrate. The metamaterial array and substrate together effectively form a Schottky diode, which enables modulation of THz transmission by 50 per cent, an order of magnitude improvement over existing devices.'], 'negatives': [\"Similar to effects identified with traditional media forms, recent evidence indicates that body image concerns, such as body dissatisfaction and drive for thinness, may also be associated with exposure to images on Social Networking Sites. Utilizing social comparison theory, the current study sought to examine the relationship between female university students' photo-based activities on Instagram, which is a relatively new Social Networking Site, appearance-related comparisons, and two outcome variables: drive for thinness and body dissatisfaction. Mediational analyses using bootstrapping methods indicated that Instagram photo-based activities positively predicted both drive for thinness and body dissatisfaction through the mediating variable of appearance-related comparisons. These results suggest that Instagram use could be potentially harmful to individuals who find themselves frequently engaging in comparisons with others. Additionally, utilizing the intrasexual competition framework, the second aim of this study was to determine whether individual differences in competitiveness for mates influenced individual tendencies to engage in appearance-related comparisons on Instagram. A significant positive relationship emerged between intrasexual competitiveness for mates and appearance-related comparisons on Instagram. Theoretical and applied implications from these findings are discussed. © 2017 Elsevier Ltd. All rights reserved.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"The ability to construct a hypothetical situation in one's imagination prior to it actually occurring may afford greater accuracy in predicting its eventual outcome. The recollection of past experiences is also considered to be a reconstructive process with memories recreated from their component parts. Construction, therefore, plays a critical role in allowing us to plan for the future and remember the past. Conceptually, construction can be broken down into a number of constituent processes although little is known about their neural correlates. Moreover, it has been suggested that some of these processes may be shared by a number of other cognitive functions including spatial navigation and imagination. Recently, novel paradigms have been developed that allow for the isolation and characterization of these underlying processes and their associated neuroanatomy. Here, we selectively review this fast-growing literature and consider some implications for remembering the past and predicting the future.\", 'positives': ['The hippocampus appears to be crucial for long-term episodic memory, yet its precise role remains elusive. Electrophysiological studies in rodents offer a useful starting point for developing models of hippocampal processing in the spatial domain. Here we review one such model that points to an essential role for the hippocampus in the construction of mental images. We explain how this neural-level mechanistic account addresses some of the current controversies in the field, such as the role of the hippocampus in imagery and short-term memory, and discuss its broader implications for the neural bases of episodic memory.'], 'negatives': ['An unprecedented booming has been witnessed in the research area of artistic style transfer ever since Gatys et al. introduced the neural method. One of the remaining challenges is to balance a trade-off among three critical aspects—speed, flexibility, and quality: (i) the vanilla optimization-based algorithm produces impressive results for arbitrary styles, but is unsatisfyingly slow due to its iterative nature, (ii) the fast approximation methods based on feed-forward neural networks generate satisfactory artistic effects but bound to only a limited number of styles, and (iii) feature-matching methods like AdaIN achieve arbitrary style transfer in a real-time manner but at a cost of the compromised quality. We find it considerably difficult to balance the trade-off well merely using a single feed-forward step and ask, instead, whether there exists an algorithm that could adapt quickly to any style, while the adapted model maintains high efficiency and good image quality. Motivated by this idea, we propose a novel method, coined MetaStyle, which formulates the neural style transfer as a bilevel optimization problem and combines learning with only a few post-processing update steps to adapt to a fast approximation model with satisfying artistic effects, comparable to the optimization-based methods for an arbitrary style. The qualitative and quantitative analysis in the experiments demonstrates that the proposed approach achieves high-quality arbitrary artistic style transfer effectively, with a good trade-off among speed, flexibility, and quality.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The recent application of deep neural networks (DNN) to speaker identification (SID) has resulted in significant improvements over current state-of-the-art on telephone speech. In this work, we report a similar achievement in DNN-based SID performance on microphone speech. We consider two approaches to DNN-based SID: one that uses the DNN to extract features, and another that uses the DNN during feature modeling. Modeling is conducted using the DNN/i-vector framework, in which the traditional universal background model is replaced with a DNN. The recently proposed use of bottleneck features extracted from a DNN is also evaluated. Systems are first compared with a conventional universal background model (UBM) Gaussian mixture model (GMM) i-vector system on the clean conditions of the NIST 2012 speaker recognition evaluation corpus, where a lack of robustness to microphone speech is found. Several methods of DNN feature processing are then applied to bring significantly greater robustness to microphone speech. To direct future research, the DNN-based systems are also evaluated in the context of audio degradations including noise and reverberation.', 'positives': ['This paper presents the application of Neural Network Bottleneck (BN) features in Language Identification (LID). BN f eatures are generally used for Large Vocabulary Speech Recogn ition in conjunction with conventional acoustic features, s uch as MFCC or PLP. We compare the BN features to several common types of acoustic features used in the state-of-the-art LID systems. The test set is from DARPA RATS (Robust Automatic Transcription of Speech) program, which seeks to advance state-of-the-art detection capabilities on audio from hig hly degraded radio communication channels. On this type of noisy data, we show that in average, the BN features provide a 45% relative improvement in theCavgor Equal Error Rate (EER) metrics across several test duration conditions, with resp ect to our single best acoustic features.'], 'negatives': ['In order to enable unobtrusive human object interaction detection, we propose a minimalistic approach to instrumenting everyday objects with passive (i.e. battery-free) UHF RFID tags. By measuring the changes in the physical layer of the communication channel between the RFID tag and reader (such as RSSI, RF phase, and read rate) we are able to classify, in real time, tag/object motion events along with two types of touch events. Through a user study, we demonstrate that our real-time classification engine is able to simultaneously track 20 objects and identify four movement classes with 93% accuracy. To demonstrate how robust this general-purpose interaction mechanism is, we investigate three usage scenarios 1) interactive storytelling with toys 2) inference of daily activities in the home 3) identification of customer browsing habits in a retail setting.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Today, ambitious amateur athletes often do not have access to professional coaching but still invest great effort in becoming faster runners. Apart from a pure increase in the quantitative training load, a change of the running technique, e.g. transitioning from heel striking to mid-/forefoot running, can be highly effective and usually prevents knee-related injuries.\\n In this demo, we present a self-contained wearable that detects heel striking while running with a pressure-sensitive insole. Heel striking is corrected in real-time to mid/forefoot running by applying electrical muscle stimulation (EMS) on the calf muscle. We further discuss potential scenarios for EMS-based training in interactive spaces. The device will be worn and demonstrated by the presenter but if possible, the device can also be tested directly by the conference attendees.', 'positives': ['We explore how to add haptics to walls and other heavy objects in virtual reality. When a user tries to push such an object, our system actuates the user\\'s shoulder, arm, and wrist muscles by means of electrical muscle stimulation, creating a counter force that pulls the user\\'s arm backwards. Our device accomplishes this in a wearable form factor.\\n In our first user study, participants wearing a head-mounted display interacted with objects provided with different types of EMS effects. The repulsion design (visualized as an electrical field) and the soft design (visualized as a magnetic field) received high scores on \"prevented me from passing through\" as well as \"realistic\".\\n In a second study, we demonstrate the effectiveness of our approach by letting participants explore a virtual world in which all objects provide haptic EMS effects, including walls, gates, sliders, boxes, and projectiles.'], 'negatives': [\"Items in real-world recommender systems exhibit certain hierarchical structures. Similarly, user preferences also present hierarchical structures. Recent studies show that incorporating the hierarchy of items or user preferences can improve the performance of recommender systems. However, hierarchical structures are often not explicitly available, especially those of user preferences. Thus, there's a gap between the importance of hierarchies and their availability. In this paper, we investigate the problem of exploring the implicit hierarchical structures for recommender systems when they are not explicitly available. We propose a novel recommendation framework to bridge the gap, which enables us to explore the implicit hierarchies of users and items simultaneously. We then extend the framework to integrate explicit hierarchies when they are available, which gives a unified framework for both explicit and implicit hierarchical structures. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework by incorporating implicit and explicit structures.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'BACKGROUND\\nTraditional one-session exposure therapy (OST) in which a patient is gradually exposed to feared stimuli for up to 3 h in a one-session format has been found effective for the treatment of specific phobias. However, many individuals with specific phobia are reluctant to seek help, and access to care is lacking due to logistic challenges of accessing, collecting, storing, and/or maintaining stimuli. Virtual reality (VR) exposure therapy may improve upon existing techniques by facilitating access, decreasing cost, and increasing acceptability and effectiveness. The aim of this study is to compare traditional OST with in vivo spiders and a human therapist with a newly developed single-session gamified VR exposure therapy application with modern VR hardware, virtual spiders, and a virtual therapist.\\n\\n\\nMETHODS/DESIGN\\nParticipants with specific phobia to spiders (N = 100) will be recruited from the general public, screened, and randomized to either VR exposure therapy (n = 50) or traditional OST (n = 50). A behavioral approach test using in vivo spiders will serve as the primary outcome measure. Secondary outcome measures will include spider phobia questionnaires and self-reported anxiety, depression, and quality of life. Outcomes will be assessed using a non-inferiority design at baseline and at 1, 12, and 52 weeks after treatment.\\n\\n\\nDISCUSSION\\nVR exposure therapy has previously been evaluated as a treatment for specific phobias, but there has been a lack of high-quality randomized controlled trials. A new generation of modern, consumer-ready VR devices is being released that are advancing existing technology and have the potential to improve clinical availability and treatment effectiveness. The VR medium is also particularly suitable for taking advantage of recent phobia treatment research emphasizing engagement and new learning, as opposed to physiological habituation. This study compares a market-ready, gamified VR spider phobia exposure application, delivered using consumer VR hardware, with the current gold standard treatment. Implications are discussed.\\n\\n\\nTRIAL REGISTRATION\\nClinicalTrials.gov identifier NCT02533310. Registered on 25 August 2015.', 'positives': [], 'negatives': ['One of the most crucial tasks for utility companies is load forecasting in order to plan future demand for generation capacity and infrastructure. Improving load forecasting accuracy over a short period is a challenging open problem due to the variety of factors that influence the load, and the volume of data that needs to be considered. This paper proposes a new approach for short term load forecasting using an effective new combination of clustering and deep learning methods, along with a new weighted aggregation mechanism. Our evaluation using smart meter data from a publicly available real-life dataset demonstrates the improved accuracy of our approach over existing methods.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Batch reinforcement learning is a subfield of dynamic programming-based reinforcement learning. Originally defined as the task of learning the best possible policy from a fixed set of a priori-known transition samples, the (batch) algorithms developed in this field can be easily adapted to the classical online case, where the agent interacts with the environment while learning. Due to the efficient use of collected data and the stability of the learning process, this research area has attracted a lot of attention recently. In this chapter, we introduce the basic principles and the theory behind batch reinforcement learning, describe the most important algorithms, exemplarily discuss ongoing research within this field, and briefly survey real-world applications of batch reinforcement learning.', 'positives': ['Technical process control is a highly interesting area of application serving a high practical impact. Since classical controller design is, in general, a demanding job, this area constitutes a highly attractive domain for the application of learning approaches—in particular, reinforcement learning (RL) methods. RL provides concepts for learning controllers that, by cleverly exploiting information from interactions with the process, can acquire high-quality control behaviour from scratch. This article focuses on the presentation of four typical benchmark problems whilst highlighting important and challenging aspects of technical process control: nonlinear dynamics; varying set-points; long-term dynamic effects; influence of external variables; and the primacy of precision. We propose performance measures for controller quality that apply both to classical control design and learning controllers, measuring precision, speed, and stability of the controller. A\\xa0second set of key-figures describes the performance from the perspective of a learning approach while providing information about the efficiency of the method with respect to the learning effort needed. For all four benchmark problems, extensive and detailed information is provided with which to carry out the evaluations outlined in this article. A close evaluation of our own RL learning scheme, NFQCA (Neural Fitted Q Iteration with Continuous Actions), in acordance with the proposed scheme on all four benchmarks, thereby provides performance figures on both control quality and learning behavior.'], 'negatives': ['As more and more people use computers for communicating, the behavioral and societal effects of computer-mediated communication are becoming critical research topics. This article describes some of the issues raised by electronic communication, illustrates one empirical approach for investigating its social psychological effects, and discusses why social psychological research might contribute to a deeper understanding of computer-mediated communication specifically and of computers and technological change in society more generally. One objective of our research is to explore how people participate in computer-mediated communication and how computerization affects group efforts to reach consensus. In experiments, we have shown differences in participation, decisions, and interaction among groups meeting face to face and in simultaneous computer-linked discourse and communication by electronic mail. We discuss these results and the design of subsequent research to highlight the many researchable social psychological issues raised by computing and technological change. Computer technologies are improving so swiftly these days that few of us comprehend even a small part of the change. Computers are transforming work and, in some cases, lives. Whether eager for this or resistant, many people believe the organizational, social, and personal effects of computers will be deeply felt (De Sola Poole, 1977; Hiltz & Turoff, 1978; Kling, 1980). Today, no one can predict in any detail the nature of the transformations that computers will bring, but one aspect of life that will certainly be affected is communication. The use of electronic mail and messages, long-distance blackboards, computer bulletin boards, instantaneously transferable data banks, and simultaneous computer conferences is reportedly advancing \"like an avalanche\" (Stockton, 1981; also see Kraemer, 1981). The U.S. federal judiciary, for example, is using electronic mail to speed the circulation of appellate opinion drafts among panels of judges (Weis, 1983). Computer conferences are being used for such legal proceedings as admission of evidence, trial scheduling, giving parties access to documents, and expert interrogation (Bentz & Potrykus, 1976; \"Party-Line Plea,\" 1981). Other government agencies, such as the Department of Defense, as well as private firms, such as Westinghouse Corporation and Xerox Corporation, and some universities, use computer-mediated communication extensively for both routine transfer of data and nonroutine interpersonal communication and project work (e.g., Licklider & Vezza, 1978; U.S. Department of Commerce, 1977; Wang Corporation, 1982). Computer-mediated communication was once confined to technical users and was considered somewhat arcane. This no longer holds true. Computer-mediated communication is a key component of the emerging technology of computer networks. In networks, people can exchange, store, edit, broadcast, and copy any written document. They can send data and messages instantaneously, easily, at low cost, and over long distances. Two or more people can look at a document and revise it together, consult with each other on critical matters without meeting together or setting up a telephone conference, or ask for and give assistance interactively (Hiltz & Turoff, 1978; Williams, 1977). Networks, and hence computer-mediated communications, are proliferating at a tremendous rate. In addition to the older long-distance networks that connect thousands of scientists, professionals, and managers (e.g., the Department of Defense\\'s ARPANET, GTE\\'s TELENET), there are more and more local-area networks that link up computers within a region, city, or organization (e.g., Nestar System\\'s CLUSTERBUS, Xerox\\'s ETHERNET, Ford Aerospace\\'s FLASHNET, and Wang Laboratories\\' WANGNET). Stimulating this growth are the decreasing costs and the advantages of networks over stand-alone systems, such as sharing high-speed printers and access to a common interface for otherwise incompatible equipment. The future of this technology cannot be foretold, but it is far from arcane. The functions and impact of computer-mediated communication are still poorly understood. Critical information (such as who uses it for what purposes) October 1984 • American Psychologist Copyright 1984 by the American Psychological Aisociation, Inc. Vol. 39, No. 10, 1123-1134 1123 is lacking, and the social psychological significance is controversial (see, e.g., Turoff, 1982). Computers could make communication easier, just as the canning of perishables and the development of can openers made food preparation easier, or they could have much more complex implications. For instance, access to electronic communication may change the flow of information within organizations, altering status relations and organizational hierarchy. When a manager can receive electronic mail from 10,000 employees, what happens to existing controls over participation and information? When people can publish and distribute their own electronic newspaper at no cost, does the distribution of power change too? When communication is rapid and purely textual, do working groups find it easier or harder to resolve conflict? These unanswered questions illustrate that, although the technology may be impressive, little systematic research exists on its psychological, social, and cultural significance. Given such conditions it seems sensible to try to understand the fundamental behavioral, social, and organizational processes that surround computer-mediated communication. We believe that ideas and approaches from social psychology and other areas of behavioral science can be applied to these questions. This article is meant to describe some of the issues raised by electronic communication; to illustrate, from our own work, one empirical approach for investigating them; and to show why social psychological research might contribute to a deeper understanding of electronic communication specifically and of computers and technological change in society more generally. We begin by citing some existing research on computer-mediated communication. Most of this research addresses the technical capabilities of the electronic technologies. Next, we consider the possible social psychological impact, and we discuss some hypotheses and some possible implications for the outcomes of communication. Finally, we describe some of our own experiments on social psychological aspects of computer-mediated communication, using these to indicate potential lines of future research.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Neural networks have shown promising results for relation extraction. State-ofthe-art models cast the task as an end-toend problem, solved incrementally using a local classifier. Yet previous work using statistical models have demonstrated that global optimization can achieve better performances compared to local classification. We build a globally optimized neural model for end-to-end relation extraction, proposing novel LSTM features in order to better learn context representations. In addition, we present a novel method to integrate syntactic information to facilitate global learning, yet requiring little background on syntactic grammars thus being easy to extend. Experimental results show that our proposed model is highly effective, achieving the best performances on two standard benchmarks.', 'positives': ['We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional treestructured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the stateof-the-art feature-based model on end-toend relation extraction, achieving 3.5% and 4.8% relative error reductions in F1score on ACE2004 and ACE2005, respectively. We also show a 2.5% relative error reduction in F1-score over the state-ofthe-art convolutional neural network based model on nominal relation classification (SemEval-2010 Task 8).'], 'negatives': ['The use of neuroleptics as psychotherapeutic agents has resulted in extrapyramidal syndromes including parkinsonism. This specific drug-induced parkinsonism (DIP) mimics idiopathic Parkinson’s disease with the typical parkinsonian triad but the symptomatology of this disorder is a rather akinetic rigid syndrome with lesser incidence of resting tremor. This disorder is usually dose-dependent and related to individual susceptibility to neuroleptics. Recent PET techniques with selective radioactive ligands enable us to study extrapyramidal side effects and dopamine D2 receptor occupancy. Now we know that more than 80% D2-receptor occupancy is consistent with the appearance of DIP, whereas a low occupancy between 40–70% induces no DIP. Conventional neuroleptics in regular doses usually cause more than 80% D2 occupancy with resultant parkinsonian symptoms, whereas regular doses of atypical neuroleptics cause only less than 40–70% D2 occupancy without parkinsonism. The other mechanism to explain the lower incidence of DIP in patients with atypical neuroleptics is the “fast-off” hypothesis. D2 receptor occupancy by atypical antipsychotic drugs is rather loose and transient, so they easily dissociate to allow normal dopamine transmission. Newer calcium entry blocking agents such as flunarizine and cinnarizine are known to cause similar DIP. The pathomechanism of this disorder was studied by SPECT and the dose dependent dopamine D2-receptor occupancy by these drugs was noted to explain DIP. The first management for this disorder is to withdraw the offending drugs if possible or switch from conventional neuroleptics to atypical agents. If it is impossible to change the drugs, it is better to add anticholinergics. For the elderly, it is recommended to use amantadine to prevent anticholinergic side effects.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': '& In this article, we present information-theoretic concepts for analyzing complex networks. We see that the application of information-theoretic concepts to networks leads to interesting tasks and gives a possibility for understanding information processing in networks. The main contribution of this article is a method for determining the structural information content of graphs that is based on a tree decomposition. It turns out that the computational complexity of the underlying algorithm is polynomial. Finally, we present some numerical results to study the influence of the used methods on the resulting information contents.', 'positives': ['Graphs are a powerful and versatile tool useful in various subfields of science and engineering. In many applications, for example, in pattern recognition and computer vision, it is required to measure the similarity of objects. When graphs are used for the representation of structured objects, then the problem of measuring object similarity turns into the problem of computing the similarity of graphs, which is also known as graph matching. In this paper, similarity measures on graphs and related algorithms will be reviewed. Applications of graph matching will be demonstrated giving examples from the fields of pattern recognition and computer vision. Also recent theoretical work showing various relations between different similarity measures will be discussed.'], 'negatives': ['An optimized algorithm and a corresponding reconfigurable architecture for computing Zadoff-Chu (ZC) complex sequence elements based on the CORDIC algorithm are proposed. The algorithm computes ZC-sequence elements both in time domain and frequency domain using a simple duality relationship. Algorithm transforms are employed to compute the elements recursively and eliminate multipliers with nonconstant terms. The algorithm is applied in a searcher block for detecting the physical random access channel (PRACH) in LTE PHY layer. The PRACH transmits a preamble constructed from ZC sequences to establish initial access along with uplink synchronization with the base station. A reconfigurable hardware architecture was implemented to generate these preambles on the fly with high accuracy based on the proposed algorithm, eliminating the need for storing a large number of long complex ZC sequence elements. Simulation results demonstrate that the proposed architecture is capable of achieving detection error rates for LTE PRACH that are close to ideal rates achieved using floating-point precision.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper planar circular Electromagnetic Band Gap (EBG) structures have been implemented in the Butler matrix fed antenna array system to improve the radiation performance of the system. Initially a conventional 4×4 Butler matrix fed antenna array system has been designed at 14.5 GHz. Asymmetricity in the gain values of major beams of the antenna array system has been observed both in simulation and measurement. Generally due to the design simplicity, light weight and compactness, the rectangular patch microstrip antenna has been used as the radiating element in the Butler matrix fed antenna array system. At higher frequencies microstrip antenna suffers from losses due to surface wave excitation. It degrades the radiation efficiency of the antenna array system and also increases the level of mutual coupling between the radiating elements in the antenna array. EBG (Electromagnetic Band Gap) units are used to improve the radiation performance of the system by the generation of stop band. The propagation of surface wave will be suppressed in this stop band region and may improve the performance of the system. To fulfill this requirement, 3 × 1 planar circular EBG unit has been designed. A stop band of 2.15 GHz with the centre frequency of 14.5 GHz has been obtained by the proposed EBG unit. The 3×1 planar circular EBG unit has been integrated between the radiating elements of the antenna array system. As a result the gain enhancement has been achieved for the 1R, 2L, 2R and 1L beams both in simulation and measurement at 14.5 GHz.', 'positives': ['This paper introduces a novel structure of 4×4 multiple beam forming antenna system using substrate integrated folded waveguide technology. For high speed wireless communication it is necessary to minimize the interferences and multipath fading. Multiple beam forming antenna system is a good solution to these problems. The substrate integrated folded waveguide (SIFW) technology reduces the width of substrate integrated waveguide (SIW) by half. All the basic building blocks required for the antenna array system are designed and simulated individually. They are then combined to form the butler matrix fed antenna array system. The SIFW technology reduces the total width of butler matrix. The radiation performance of the multiple beam forming antenna system is realized by integrating the H-plane SIFW horn antennas with the output ports of the butler matrix. The system is practically realized and good directive multiple beams with symmetric gain (5.8 dB, 5.63 dB, 5.31 dB and 5.9 dB for the beams 1R, 2L, 2R and 1L) have been achieved.'], 'negatives': ['Materials are said to show a shape-memory effect if they can be deformed and fixed into a temporary shape, and recover their original, permanent shape only on exposure to an external stimulus. Shape-memory polymers have received increasing attention because of their scientific and technological significance. In principle, a thermally induced shape-memory effect can be activated by an increase in temperature (also obtained by heating on exposure to an electrical current or light illumination). Several papers have described light-induced changes in the shape of polymers and gels, such as contraction, bending or volume changes. Here we report that polymers containing cinnamic groups can be deformed and fixed into pre-determined shapes—such as (but not exclusively) elongated films and tubes, arches or spirals—by ultraviolet light illumination. These new shapes are stable for long time periods, even when heated to 50\\u2009°C, and they can recover their original shape at ambient temperatures when exposed to ultraviolet light of a different wavelength. The ability of polymers to form different pre-determined temporary shapes and subsequently recover their original shape at ambient temperatures by remote light activation could lead to a variety of potential medical and other applications.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The conventional three-level inverter suffers the limitation of voltage buck operation. In order to give both voltage buck and boost operation capability, the quasi-Z-source three-level T-type inverter (3LT<inline-formula> <tex-math notation=\"LaTeX\">$^2$</tex-math></inline-formula>I) has been proposed. This paper further proposes a space vector modulation (SVM) scheme for the quasi-Z-source 3LT<inline-formula><tex-math notation=\"LaTeX\">$^2$</tex-math> </inline-formula>I to reduce the magnitude and slew rate of common-mode voltage (CMV). By properly selecting the shoot-through phase, the shoot-through states are inserted within zero vector in order not to affect the active states and output voltage. Doing so, the CMV generated by the quasi-Z-source 3LT<inline-formula><tex-math notation=\"LaTeX\"> $^2$</tex-math></inline-formula>I is restricted within one-sixth of dc-link voltage, and voltage boosting and CMV reduction can be simultaneously realized. In addition, high dc-link voltage utilization can be maintained. The proposed scheme has been verified in both simulations and experiments. Comparisons are conducted with the conventional SVM method and the phase-shifted sinusoidal PWM method.', 'positives': ['Three existing and one extended space vector modulations (SVMs) for the three-phase Z-source/quasi-Z-source inverter (ZSI/qZSI) are investigated. The different switching control patterns, the available maximum shoot-through duty ratio, the maximum voltage stress across the switch versus voltage gain, and efficiency are compared in detail. A total average switch device power taking into account the shoot-through current stress is proposed to evaluate the total stress of power switches. Simulation and experimental results of the prototyped qZSI verify the theoretical analysis. The six parts of shoot-through time intervals will reduce the inductor current ripples, and improve the qZSI efficiency. Also, the maximum voltage stress and total average switch power will benefit from the shoot-through division. However, the division method impacts these performances of qZSI.'], 'negatives': ['Millions of children are infected by enteroviruses each year, usually exhibiting only mild symptoms. Nevertheless, these viruses are also associated with severe and life-threatening infections, such as meningitis and encephalitis. We describe a 32-month-old patient with enteroviral encephalitis confirmed by polymerase chain reaction in cerebrospinal fluid, with unfavorable clinical course with marked developmental regression, autistic features, persistent stereotypes and aphasia. She experienced slow clinical improvement, with mild residual neurologic and developmental deficits at follow-up. Viral central nervous system infections in early childhood have been associated with autism spectrum disorders but the underlying mechanisms are still poorly understood. This case report is significant in presenting a case of developmental regression with autistic features and loss of language improving on follow-up. To our knowledge, this is the first published report of enterovirus encephalitis leading to an autism spectrum disorder.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Calibration between color camera and 3D Light Detection And Ranging (LIDAR) equipment is an essential process for data fusion. The goal of this paper is to improve the calibration accuracy between a camera and a 3D LIDAR. In particular, we are interested in calibrating a low resolution 3D LIDAR with a relatively small number of vertical sensors. Our goal is achieved by employing a new methodology for the calibration board, which exploits 2D-3D correspondences. The 3D corresponding points are estimated from the scanned laser points on the polygonal planar board with adjacent sides. Since the lengths of adjacent sides are known, we can estimate the vertices of the board as a meeting point of two projected sides of the polygonal board. The estimated vertices from the range data and those detected from the color image serve as the corresponding points for the calibration. Experiments using a low-resolution LIDAR with 32 sensors show robust results.', 'positives': ['The combined use of 3D scanning lasers with 2D cameras has become increasingly popular in mobile robotics, as the sparse depth measurements of the former augment the dense color information of the latter. Sensor fusion requires precise 6DOF transforms between the sensors, but hand-measuring these values is tedious and inaccurate. In addition, autonomous robots can be rendered inoperable if their sensors’ calibrations change over time. Yet previously published camera-laser calibration algorithms are offline only, requiring significant amounts of data and/or specific calibration targets; they are thus unable to correct calibration errors that occur during live operation. In this paper, we introduce two new real-time techniques that enable camera-laser calibration online, automatically, and in arbitrary environments. The first is a probabilistic monitoring algorithm that can detect a sudden miscalibration in a fraction of a second. The second is a continuous calibration optimizer that adjusts transform offsets in real time, tracking gradual sensor drift as it occurs. Although the calibration objective function is not globally convex and cannot be optimized in real time, in practice it is always locally convex around the global optimum, and almost everywhere else. Thus, the local shape of the objective function at the current parameters can be used to determine whether the sensors are calibrated, and allows the parameters to be adjusted gradually so as to maintain the global optimum. In several online experiments on thousands of frames in real markerless scenes, our method automatically detects miscalibrations within one second of the error exceeding .25 deg or 10cm, with an accuracy of 100%. In addition, rotational sensor drift can be tracked in real-time with a mean error of just .10 deg. Together, these techniques allow significantly greater flexibility and adaptability of robots in unknown and potentially harsh environments.'], 'negatives': ['Many online videogames make use of characters controlled by both humans (avatar) and computers (agent) to facilitate game play. However, the level of agency a teammate shows potentially produces differing levels of social presence during play, which in turn may impact on the player experience. To better understand these effects, two experimental studies were conducted utilising cooperative multiplayer games (Left 4 Dead 2 and Rocket League). In addition, the effect of familiarity between players was considered. The trend across the two studies show that playing with another human is more enjoyable, and facilitates greater connection, cooperation, presence and positive mood than play with a computer agent. The implications for multiplayer game design is discussed.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Closed Circuit Television (CCTV) is currently used in daily basis for a wide variety of purposes. The development of CCTV has transformed from a simple passive surveillance into an integrated intelligent control system. In this research, motion detection and facial recognition in CCTV video is used as the basis of decision making to produce automatic, effective and efficient integrated system. This CCTV video process provides three outputs, motion detection information, face detection information and face identification information. Accumulative Differences Images (ADI) method is used for motion detection, and Haar Classifiers Cascade method is used for face detection. Feature extraction is done with Speeded-Up Robust Features (SURF) and Principal Component Analysis (PCA). Then, these features are trained by Counter-Propagation Network (CPN). Offline tests are performed on 45 CCTV video. The result shows 92.655% success rate on motion detection,76% success rate on face detection, and 60% success rate on face detection. It shows that this faces detection and identification through CCTV video have not been able to obtain optimal results. The motion detection process is ideal to be applied in real-time conditions. Yet if it’s combined with face recognition process, it causes a significant time delay. Keywords— ADI, Haar Cascade Classifiers, SURF, PCA, CPN \\uf06e ISSN (print): 1978-1520, ISSN (online): 2460-7258 IJCCS Vol. 12, No. 2, July 2018 : 107 – 118 108', 'positives': ['Recently Viola et al. [5] have introduced a rapid object detection scheme based on a boosted cascade of simple features. In this paper we introduce a novel set of rotated haar-like features, which significantly enrich this basic set of simple haar-like features and which can also be calculated very efficiently. At a given hit rate our sample face detector shows off on average a 10% lower false alarm rate by means of using these additional rotated features. We also present a novel post optimization procedure for a given boosted cascade improving on average the false alarm rate further by 12.5%. Using both enhancements the number of false detections is only 24 at a hit rate of 82.3% on the CMU face set [7].'], 'negatives': [\"This study examines self-presentation in online dating profiles using a novel cross-validation technique for establishing accuracy. Eighty online daters rated the accuracy of their online self-presentation. Information about participants' physical attributes was then collected (height, weight, and age) and compared with their online profile, revealing that deviations tended to be ubiquitous but small in magnitude. Men lied more about their height, and women lied more about their weight, with participants farther from the mean lying more. Participants' self-ratings of accuracy were significantly correlated with observed accuracy, suggesting that inaccuracies were intentional rather than self-deceptive. Overall, participants reported being the least accurate about their photographs and the most accurate about their relationship information. Deception patterns suggest that participants strategically balanced the deceptive opportunities presented by online self-presentation (e.g., the editability of profiles) with the social constraints of establishing romantic relationships (e.g., the anticipation of future interaction).\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices, making medical diagnoses, and facial recognition. In a model inversion attack, recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al., adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs, however, is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings, and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and, in the other context, show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures, investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning, as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.\", 'positives': [\"We present a new class of statistical de- anonymization attacks against high-dimensional micro-data, such as individual preferences, recommendations, transaction records and so on. Our techniques are robust to perturbation in the data and tolerate some mistakes in the adversary's background knowledge. We apply our de-anonymization methodology to the Netflix Prize dataset, which contains anonymous movie ratings of 500,000 subscribers of Netflix, the world's largest online movie rental service. We demonstrate that an adversary who knows only a little bit about an individual subscriber can easily identify this subscriber's record in the dataset. Using the Internet Movie Database as the source of background knowledge, we successfully identified the Netflix records of known users, uncovering their apparent political preferences and other potentially sensitive information.\"], 'negatives': ['The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Applying parallelism to constraint solving seems a promising approach and it has been done with varying degrees of success. Early attempts to parallelize constraint propagation, which constitutes the core of traditional interleaved propagation and search constraint solving, were hindered by its essentially sequential nature. Recently, parallelization efforts have focussed mainly on the search part of constraint solving, as well as on local-search based solving. Lately, a particular source of parallelism has become pervasive, in the guise of GPUs, able to run thousands of parallel threads, and they have naturally drawn the attention of researchers in parallel constraint solving. In this paper, we address challenges faced when using multiple devices for constraint solving, especially GPUs, such as deciding on the appropriate level of parallelism to employ, load balancing and inter-device communication, and present our current solutions.', 'positives': ['This document describes the CRISP-DM process model, including an introduction to the CRISP-DM methodology, the CRISP-DM reference model, the CRISP-DM user guide and the CRISP-DM reports, as well as an appendix with additional useful and related information. This document and information herein, are the exclusive property of the partners of the CRISP-DM All trademarks and service marks mentioned in this document are marks of their respective owners and are as such acknowledged by the members of the CRISP-DM consortium. Foreword CRISP-DM was conceived in late 1996 by three \" veterans \" of the young and immature data mining market. DaimlerChrysler (then Daimler-Benz) was already experienced, ahead of most industrial and commercial organizations, in applying data mining in its business operations. SPSS (then ISL) had been providing services based on data mining since 1990 and had launched the first commercial data mining workbench – Clementine – in 1994. NCR, as part of its aim to deliver added value to its Teradata data warehouse customers, had established teams of data mining consultants and technology specialists to service its clients\\' requirements. At that time, early market interest in data mining was showing signs of exploding into widespread uptake. This was both exciting and terrifying. All of us had developed our approaches to data mining as we went along. Were we doing it right? Was every new adopter of data mining going to have to learn, as we had initially, by trial and error? And from a supplier\\'s perspective, how could we demonstrate to prospective customers that data mining was sufficiently mature to be adopted as a key part of their business processes? A standard process model, we reasoned, non-proprietary and freely available, would address these issues for us and for all practitioners. A year later we had formed a consortium, invented an acronym (CRoss-Industry Standard Process for Data Mining), obtained funding from the European Commission and begun to set out our initial ideas. As CRISP-DM was intended to be industry-, tool-and application-neutral, we knew we had to get input from as wide a range as possible of practitioners and others (such as data warehouse vendors and management consultancies) with a vested interest in data mining. We did this by creating the CRISP-DM Special Interest Group (\" The SIG \" , as it became known). We launched the SIG by broadcasting an invitation to interested parties to join us in Amsterdam for a day-long …'], 'negatives': ['A 1-Gb/s differential transimpedance amplifier (TIA) is realized in a 0.25-/spl mu/m standard CMOS technology, incorporating the regulated cascode input configuration. The TIA chip is then integrated with a p-i-n photodiode on an oxidized phosphorous-silicon (OPS) substrate by employing the multichip-on-oxide (MCO) technology. The MCO TIA demonstrates 80-dB/spl Omega/ transimpedance gain, 670-MHz bandwidth for 1-pF photodiode capacitance, 0.54-/spl mu/A average input noise current, -17-dBm sensitivity for 10/sup -12/ bit-error rate (BER), and 27-mW power dissipation from a single 2.5-V supply. It also shows negligible switching noise effect from an embedded VCO on the OPS substrate. Furthermore, a four-channel MCO TIA array is implemented for optical interconnects, resulting in less than -40-dB crosstalk between adjacent channels.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The concept of deliberate practice was introduced to explain exceptional performance in domains such as music and chess. We apply deliberate practice theory to intermediate-level performance in typing, an activity that many people pursue on a regular basis. Sixty university students with several years typing experience participated in laboratory sessions that involved the assessment of abilities, a semistructured interview on typing experience as well as various typing tasks. In line with traditional theories of skill acquisition, experience (amount of typing since introduction to the keyboard) was related to typing performance. A perceptual speed test (digit-symbol substitution) and a measure of motor abilities (tapping) were not significantly related to performance. In line with deliberate practice theory, the highest level of performance was reported among participants who had attended a typing class in the past and who reported to adopt the goal of typing quickly during everyday typing. Findings suggest that even after several years of experience engagement in an everyday activity can serve as an opportunity for further skill improvement if individuals are willing to push themselves.', 'positives': ['The superior skills of experts, such as accomplished musicians and chess masters, can be amazing to most spectators. For example, club-level chess players are often puzzled by the chess moves of grandmasters and world champions. Similarly, many recreational athletes find it inconceivable that most other adults – regardless of the amount or type of training – have the potential ever to reach the performance levels of international competitors. Especially puzzling to philosophers and scientists has been the question of the extent to which expertise requires innate gifts versus specialized acquired skills and abilities. One of the most widely used and simplest methods of gathering data on exceptional performance is to interview the experts themselves. But are experts always capable of describing their thoughts, their behaviors, and their strategies in a manner that would allow less-skilled individuals to understand how the experts do what they do, and perhaps also understand how they might reach expert level through appropriate training? To date, there has been considerable controversy over the extent to which experts are capable of explaining the nature and structure of their exceptional performance. Some pioneering scientists, such as Binet (1893 / 1966), questioned the validity of the experts’ descriptions when they found that some experts gave reports inconsistent with those of other experts. To make matters worse, in those rare cases that allowed verification of the strategy by observing the performance, discrepancies were found between the reported strategies and the observations (Watson, 1913). Some of these discrepancies were explained, in part, by the hypothesis that some processes were not normally mediated by awareness/attention and that the mere act of engaging in self-observation (introspection) during performance changed the content of ongoing thought processes. These problems led most psychologists in first half of the 20th century to reject all types of introspective verbal reports as valid scientific evidence, and they focused almost exclusively on observable behavior (Boring, 1950). In response to the problems with the careful introspective analysis of images and perceptions, investigators such as John B.'], 'negatives': ['With the worldwide third-generation mobile communication system gradually implemented, the future development of mobile communications has become a hot topic and evolution of the problem. This paper introduces the fourth generation mobile communication system and its performance and network structure and OFDM, software defined radio, smart antennas, IPv6 and other key technologies, and analyzes the relationship between 4G mobile communication system for mobile communications and 3G, and the evolution of communication systems do Prospect. Keywords-component; 4G, 3G, OFDM, IPv6, Mobile Data, Smart'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Apps on Google’s Android mobile device platform are written in Java, but are compiled to a special bytecode language called Dalvik. In this paper, we introduce SymDroid, a symbolic executor that operates directly on Dalvik bytecode. SymDroid begins by first translating Dalvik into μ-Dalvik, a simpler language that has only 16 instructions, in contrast to Dalvik’s more than 200 instructions. We present a formalism for SymDroid’s symbolic executor, which can be described with a small number of operational semantics rules; this semantics may be of independent interest. In addition to modeling bytecode instructions, SymDroid also contains models of some key portions of the Android platform, including libraries and the platform’s lifecycle control code. We evaluated SymDroid in two ways. First, we ran it on the Android Compatibility Test Suite, and found it passed all tests except ones that used library or system routines we have not yet implemented. On this test suite, SymDroid runs about twice as slow as the Dalvik VM, and about twice as fast as the Java VM. Second, we used SymDroid to discover the (path) conditions under which contacts may be accessed on an Android app, and found it was able to do so successfully. These results suggest that SymDroid, while still a prototype, is a promising first step in enabling direct, precise analysis of Android apps.', 'positives': ['STP is a decision procedure for the satisfiability of quantifier-free formulas in the theory of bit-vectors and arrays that has been optimized for large problems encountered in software analysis applications. The basic architecture of the procedure consists of word-level pre-processing algorithms followed by translation to SAT. The primary bottlenecks in software verification and bug finding applications are large arrays and linear bit-vector arithmetic. New algorithms based on the abstraction-refinement paradigm are presented for reasoning about large arrays. A solver for bit-vector linear arithmetic is presented that eliminates variables and parts of variables to enable other transformations, and reduce the size of the problem that is eventually received by the SAT solver. These and other algorithms have been implemented in STP, which has been heavily tested over thousands of examples obtained from several real-world applications. Experimental results indicate that the above mix of algorithms along with the overall architecture is far more effective, for a variety of applications, than a direct translation of the original formula to SAT or other comparable decision'], 'negatives': [\"Digital low dropout (LDO) voltage regulators have been widely used in the latest low-power circuits that involve fine-grain power management. Due to the mixture of discrete- and continuous-time operation as well as the nonlinear comparator gain, it is difficult to derive the closed-loop transfer function for a digital LDO. The use of its open-loop transfer function is also limited due to the non-constant feedback factor. Thus, it is not easy to predict digital LDO performance in the early design stage, which limits designer's capability to effectively explore the design space. This paper presents closed-form expressions for estimating critical performance parameters of digital LDO circuits, such as settling time and peak control error. The accuracy of the predictions is validated by comparing with circuit simulation results. The derived formulas can be used by designers or integrated into design automation tools.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The tilt tri-rotor UAV which combines the advantages of both rotary wing and fixed wing vehicle, offers the capability of hover, vertical take-off and landing and fast forward movement. Because of the complex structure and aerodynamics, the modeling and control of tilt tri-rotor UAV reamians a problem. In this paper, precise model of a tilt tri-rotor UAV is developed by combing system identification and physical measurement. An attitude controller is designed based on control allocation of attitude and throttle on the powerplant. The detailed mathematical model is obtained by the equations of Newton-Euler, which parameters are acquired from designed experiments. To improve the stability of helicopter fight, a new control allocation strategy is developed in the framework of PID control.', 'positives': [\"The experimental translational hovering control of a Tri-TiltRotor Unmanned Aerial Vehicle is the subject of this paper. This novel UAV is developed to possess the capability to perform autonomous conversion between the Vertical Take-Off and Landing, and the Fixed-Wing flight modes. Via this design's implemented features however, the capability for additional control authority on the UAV's longitudinal translational motion arises: The rotor-tilting servos are utilized in performing thrust vectoring of the main rotors, thus exploiting their fast response characteristics in directly providing translation-controlling forces. The system's hovering translation is handled by a Model Predictive Control scheme, following the aforementioned actuation principles. While performing experimental studies of the overall controlled system's efficiency, the advantageous effects of this novel control authority are clearly noted. Additionally, in this article the considerations and requirements for operational autonomy-related on-board-only state estimation are addressed.\"], 'negatives': ['We propose a robust classifier to predict buying intentions based on user behaviour within a large e-commerce website. In this work we compare traditional machine learning techniques with the most advanced deep learning approaches. We show that both Deep Belief Networks and Stacked Denoising auto-Encoders achieved a substantial improvement by extracting features from high dimensional data during the pre-train phase. They prove also to be more convenient to deal with severe class imbalance. Artificial Intelligence, Auto-encoders, Deep Belief Networks, Deep Learning, e-commerce, optimisation'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this letter, a new approach is presented for adaptive weight allocation-based subpixel rendering in organic light-emitting diode displays. Subpixel rendering is used to enhance the apparent resolution without changing a pixel structure. Existing methods have blurring and color fringing artifact after subpixel rendering. The proposed method, on the other hand, dynamically controls weights of current and neighboring pixels based on color difference. Thus, it preserves the image quality, while increasing the resolution. In experiments, the proposed subpixel rendering improved luminance sharpness by up to 0.043, when compared with the benchmark methods. For chrominance blending, the peak signal-to-noise ratio of the proposed method was up to 6.192 dB higher than those of benchmark methods.', 'positives': ['This paper surveys current technology and research in the area of digital color imaging. In order to establish the background and lay down terminology, fundamental concepts of color perception and measurement are first presented using vector-space notation and terminology. Present-day color recording and reproduction systems are reviewed along with the common mathematical models used for representing these devices. Algorithms for processing color images for display and communication are surveyed, and a forecast of research trends is attempted. An extensive bibliography is provided.'], 'negatives': ['The current commercial anti-virus software detects a virus only after the virus has appeared and caused damage. Motivated by the standard signature-based technique for detecting viruses, and a recent successful text classification method, we explore the idea of automatically detecting new malicious code using the collected dataset of the benign and malicious code. We obtained accuracy of 100% in the training data, and 98% in 3-fold cross-validation.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Leaf vein forms the basis of leaf characterization and classification. Different species have different leaf vein patterns. It is seen that leaf vein segmentation will help in maintaining a record of all the leaves according to their specific pattern of veins thus provide an effective way to retrieve and store information regarding various plant species in database as well as provide an effective means to characterize plants on the basis of leaf vein structure which is unique for every species. The algorithm proposes a new way of segmentation of leaf veins with the use of Odd Gabor filters and the use of morphological operations for producing a better output. The Odd Gabor filter gives an efficient output and is robust and scalable as compared with the existing techniques as it detects the fine fiber like veins present in leaves much more efficiently.', 'positives': ['A three-layered neural network is described for transforming two-dimensional discrete signals into generalized nonorthogonal 2-D “Gabor” representations for image analysis, segmentation, and compression. These transforms are conjoint spat iahpectral representations [lo], [15], which provide a complete image description in terms of locally windowed 2-D spectral coordinates embedded within global 2-D spatial coordinates. Because intrinsic redundancies within images a re extracted, the resulting image codes can be very compact. However, these conjoint transforms are inherently difficult to compute because t e elementary expansion functions a re not orthogonal. One o r t h o g o n k i n g approach developed for 1-D signals by Bastiaans [SI, based on biorthonormal expansions, is restricted by constraints on the conjoint sampling rates and invariance of the windowing function, as well as by the fact that the auxiliary orthogonalizing functions are nonlocal infinite series. In the present “neural network” approach, based upon interlaminar interactions involving two layers with fixed weights and one layer with adjustable weights, the network finds coefficients for complete conjoint 2-D Gabor transforms without these restrictive conditions. For arbitrary noncomplete transforms, in which the coefficients might be interpreted simply as signifying the presence of certain features in the image, the network finds optimal coefficients in the sense of minimal mean-squared-error in representing the image. I n one algebraically complete scheme permitting exact reconstruction, the network finds expansion coefficients that reduce entropy from 7.57 in the pixel representation to 2.55 in the complete 2-D Gabor transform. In “wavelet” expansions based on a biologically inspired log-polar ensemble of dilations, rotations, and translations of a single underlying 2-D Gabor wavelet template, image compression is illustrated with ratios up to 20: 1. Also demonstrated is image segmentation based on the clustering of coefficients in the complete 2-D Gabor transform. This coefficient-finding network for implementing useful nonorthogonal image transforms may also have neuroscientific relevance, because the network layers with fixed weights use empirical 2-D receptive field profiles obtained from orientation-selective neurons in cat visual cortex as the weighting functions, and the resulting transform mimics the biological visual strategy of embedding angular and spectral analysis within global spatial coordinates.'], 'negatives': ['This thesis consists of four parts: - An analysis of the core functions and the prerequisites for recommender systems in an industrial context: we identify four core functions for recommendation systems: Help do Decide, Help to Compare, Help to Explore, Help to Discover. The implementation of these functions has implications for the choices at the heart of algorithmic recommender systems. - A state of the art, which deals with the main techniques used in automated recommendation system: the two most commonly used algorithmic methods, the K-Nearest-Neighbor methods (KNN) and the fast factorization methods are detailed. The state of the art presents also purely content-based methods, hybridization techniques, and the classical performance metrics used to evaluate the recommender systems. This state of the art then gives an overview of several systems, both from academia and industry (Amazon, Google ...). - An analysis of the performances and implications of a recommendation system developed during this thesis: this system, Reperio, is a hybrid recommender engine using KNN methods. We study the performance of the KNN methods, including the impact of similarity functions used. Then we study the performance of the KNN method in critical uses cases in cold start situation. - A methodology for analyzing the performance of recommender systems in industrial context: this methodology assesses the added value of algorithmic strategies and recommendation systems according to its core functions.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Emotion recognition is the ability to identify what people would think someone is feeling from moment to moment and understand the connection between his/her feelings and expressions. In today’s world, human–computer interaction (HCI) interface undoubtedly plays an important role in our daily life. Toward harmonious HCI interface, automated analysis and recognition of human emotion has attracted increasing attention from the researchers in multidisciplinary research fields. In this paper, a survey on the theoretical and practical work offering new and broad views of the latest research in emotion recognition from bimodal information including facial and vocal expressions is provided. First, the currently available audiovisual emotion databases are described. Facial and vocal features and audiovisual bimodal data fusion methods for emotion recognition are then surveyed and discussed. Specifically, this survey also covers the recent emotion challenges in several conferences. Conclusions outline and address some of the existing emotion recognition issues.', 'positives': ['The current state of research on emotion effects on voice and speech is reviewed and issues for future research efforts are discussed. In particular, it is suggested to use the Brunswikian lens model as a base for research on the vocal communication of emotion. This approach allows one to model the complete process, including both encoding (expression), transmission, and decoding (impression) of vocal emotion communication. Special emphasis is placed on the conceptualization and operationalization of the major elements of the model (i.e., the speaker’s emotional state, the listener’s attribution, and the mediating acoustic cues). In addition, the advantages and disadvantages of research paradigms for the induction or observation of emotional expression in voice and speech and the experimental manipulation of vocal cues are discussed, using pertinent examples drawn from past and present research. SCHERER, Klaus R. Vocal communication of emotion: A review of research paradigms. Speech Communication, 2003, vol. 40, no. 1-2, p. 227-256 DOI : 10.1016/S0167-6393(02)00084-5'], 'negatives': [\"BACKGROUND\\nThe main purpose of this study was to explore the status of occupational stress among hospital nurses in Isfahan, Iran. It also aimed to examine the relationship between nurses' occupational stress and their intention to leave the hospital.\\n\\n\\nMETHODS\\nThe study employed a cross-sectional research design. A validated questionnaire was used to collect data from 296 nurses. Respondents were asked to rate the intensity of 30 common occupational stressors using a five-point scale.\\n\\n\\nRESULTS\\nA third of hospital nurses rated their occupational stress high. The major sources of stress were inadequate pay, inequality at work, too much work, staff shortage, lack of promotion, job insecurity and lack of management support. More than 35% of nurses stated that they are considering leaving the hospital, if they could find another job opportunity. Occupational stress was positively associated with nurses' turnover intentions.\\n\\n\\nCONCLUSION\\nHospital managers should develop and apply appropriate policies and strategies to reduce occupational stress and consequently nurses' turnover intention.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Information theoretic limits for random key generation in multiple-input multiple-output (MIMO) wireless systems exhibiting a reciprocal channel response are investigated experimentally with a new three-node MIMO measurement campaign. As background, simple expressions are presented for the number of available key bits, as well as the number of bits that are secure from a close eavesdropper. Two methods for generating secret keys are analyzed in the context of MIMO channels and their mismatch rate and efficiency are derived. A new wideband indoor MIMO measurement campaign in the 2.51- to 2.59-GHz band is presented, whose purpose is to study the number of available key bits in both line-of-sight and nonline-of-sight environments. Application of the key generation methods to measured propagation channels indicates key generation rates that can be obtained in practice for four-element arrays.', 'positives': ['There is growing interest in wireless security methods that provide strong or even perfect secrecy by taking advantage of features of the physical propagation channel. In advantage-based methods, high channel quality in an average or opportunistic sense is exploited between two legitimate nodes, such that nonzero secrecy capacity can be achieved. Since such methods require bounds on the quality of the eavesdropper channel, they are somewhat impractical. Secret key generation based on tracking channel evolution in time division duplex systems is a more attractive option, where two nodes generate secret key bits based on a mutually known random channel. Since the eavesdropper channel is typically independent of the legitimate channel, the key can only be broken by brute force attacks, which are difficult when new keys are continuously generated. In this paper, the information theoretic limits of key generation schemes are investigated, based on the level of estimation error, temporal correlation, and dependence of the eavesdropper and legitimate channels. Two practical candidate key generation schemes are also considered: channel quantization and channel quantization with guardband.'], 'negatives': ['This paper focuses on the novel task of automatic extraction of phrases related to causes of emotions. The analysis of emotional causes in sentences, where emotions are explicitly indicated through emotion keywords can provide the foundation for research on challenging task of recognition of implicit affect from text. We developed a corpus of emotion causes specific for 22 emotions. Based on the analysis of this corpus we introduce a method for the detection of the linguistic relations between an emotion and its cause and the extraction of the phrases describing the emotion causes. The method employs syntactic and dependency parser and rules for the analysis of eight types of the emotion-cause linguistic relations. The results of evaluation showed that our method performed with high level of accuracy (82%).'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Detecting and segmenting salient objects in natural scenes, often referred to as salient object detection, has attracted a lot of interest in computer vision. While many models have been proposed and several applications have emerged, yet a deep understanding of achievements and issues is lacking. We aim to provide a comprehensive review of the recent progress in salient object detection and situate this field among other closely related areas such as generic scene segmentation, object proposal generation, and saliency for fixation prediction. Covering 228 publications, we survey i) roots, key concepts, and tasks, ii) core techniques and main modeling trends, and iii) datasets and evaluation metrics in salient object detection. We also discuss open problems such as evaluation metrics and dataset bias in model performance and suggest future research directions.', 'positives': ['Despite significant recent progress, the best available visual saliency models still lag behind human performance in predicting eye fixations in free-viewing of natural scenes. Majority of models are based on low-level visual features and the importance of top-down factors has not yet been fully explored or modeled. Here, we combine low-level features such as orientation, color, intensity, saliency maps of previous best bottom-up models with top-down cognitive visual features (e.g., faces, humans, cars, etc.) and learn a direct mapping from those features to eye fixations using Regression, SVM, and AdaBoost classifiers. By extensive experimenting over three benchmark eye-tracking datasets using three popular evaluation scores, we show that our boosting model outperforms 27 state-of-the-art models and is so far the closest model to the accuracy of human model for fixation prediction. Furthermore, our model successfully detects the most salient object in a scene without sophisticated image processings such as region segmentation.'], 'negatives': ['In this paper, we propose a new theory of invariants to Gaussian blur. We introduce a notion of a primordial image as a canonical form of all Gaussian blur-equivalent images. The primordial image is defined in spectral domain by means of projection operators. We prove that the moments of the primordial image are invariant to Gaussian blur and we derive recursive formulas for their direct computation without actually constructing the primordial image itself. We show how to extend their invariance also to image rotation. The application of these invariants is in blur-invariant image comparison and recognition. In the experimental part, we perform an exhaustive comparison with two main competitors: 1) the Zhang distance and 2) the local phase quantization.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Creating a layout for an augmented reality (AR) application which embeds virtual objects in a physical environment is difficult as it must adapt to any physical space. We propose a rule-based framework for generating object layouts for AR applications. Under our framework, the developer of an AR application specifies a set of rules (constraints) which enforce self-consistency (rules regarding the inter-relationships of application components) and scene-consistency (application components are consistent with the physical environment they are placed in). When a user enters a new environment, we create, in real-time, a layout for the application, which is consistent with the defined constraints (as much as possible). We find the optimal configurations for each object by solving a constraint-satisfaction problem. Our stochastic move making algorithm is domain-aware, and allows us to efficiently converge to a solution for most rule-sets. In the paper we demonstrate several augmented reality applications that automatically adapt to different rooms and changing circumstances in each room.', 'positives': ['We present a novel Markov chain Monte Carlo (MCMC) algorithm that generates samples from transdimensional distributions encoding complex constraints. We use factor graphs, a type of graphical model, to encode constraints as factors. Our proposed MCMC method, called locally annealed reversible jump MCMC, exploits knowledge of how dimension changes affect the structure of the factor graph. We employ a sequence of annealed distributions during the sampling process, allowing us to explore the state space across different dimensionalities more freely. This approach is motivated by the application of layout synthesis where relationships between objects are characterized as constraints. In particular, our method addresses the challenge of synthesizing open world layouts where the number of objects are not fixed and optimal configurations for different numbers of objects may be drastically different. We demonstrate the applicability of our approach on two open world layout synthesis problems: coffee shops and golf courses.'], 'negatives': ['With a conventional lens sharpness of the image is always limited by the wavelength of light. An unconventional alternative to a lens, a slab of negative refractive index material, has the power to focus all Fourier components of a 2D image, even those that do not propagate in a radiative manner. Such \"superlenses\" can be realized in the microwave band with current technology. Our simulations show that a version of the lens operating at the frequency of visible light can be realized in the form of a thin slab of silver. This optical version resolves objects only a few nanometers across.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Modern machine learning-based approaches to computer vision require very large databases of hand labeled images. Some contemporary vision systems already require on the order of millions of images for training (e.g., Omron face detector [9]). New Internet-based services allow for a large number of labelers to collaborate around the world at very low cost. However, using these services brings interesting theoretical and practical challenges: (1) The labelers may have wide ranging levels of expertise which are unknown a priori, and in some cases may be adversarial; (2) images may vary in their level of difficulty; and (3) multiple labels for the same image must be combined to provide an estimate of the actual label of the image. Probabilistic approaches provide a principled way to approach these problems. In this paper we present a probabilistic model and use it to simultaneously infer the label of each image, the expertise of each labeler, and the difficulty of each image. On both simulated and real data, we demonstrate that the model outperforms the commonly used “Majority Vote” heuristic for inferring image labels, and is robust to both noisy and adversarial labelers.', 'positives': ['CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) are widespread security measures on the World Wide Web that prevent automated programs from abusing online services. They do so by asking humans to perform a task that computers cannot yet perform, such as deciphering distorted characters. Our research explored whether such human effort can be channeled into a useful purpose: helping to digitize old printed material by asking users to decipher scanned words from books that computerized optical character recognition failed to recognize. We showed that this method can transcribe text with a word accuracy exceeding 99%, matching the guarantee of professional human transcribers. Our apparatus is deployed in more than 40,000 Web sites and has transcribed over 440 million words.'], 'negatives': ['Recommender systems are becoming increasingly important to individual users and businesses for providing personalized recommendations. However, while the majority of algorithms proposed in recommender systems literature have focused on improving recommendation accuracy (as exemplified by the recent Netflix Prize competition), other important aspects of recommendation quality, such as the diversity of recommendations, have often been overlooked. In this paper, we introduce and explore a number of item ranking techniques that can generate substantially more diverse recommendations across all users while maintaining comparable levels of recommendation accuracy. Comprehensive empirical evaluation consistently shows the diversity gains of the proposed techniques using several real-world rating data sets and different rating prediction algorithms.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Steganography is a method of hiding any secret information like password, text, image and audio behind original cover file. In this paper we proposed the combination of image steganography and audio steganography with face recognition technology as a tool for authentication. Our aim is to hide the secret information behind audio and recipient’s face image behind the video. As video is a application of many still frames of images and audio, we select any frame of video to hide recipient’s face image and audio for hiding our secret data. Suitable algorithm such as improved LSB is used for image steganography and audio steganography, PCA algorithm is used for face recognition. Suitable parameter of security and authentication like PSNR, histogram are obtained at receiver and transmitter side which are exactly identical, hence the data security can be increased. Keywordsimproved LSB; Data Hiding; Steganography; face recognition; Histogram; PSNR; PCA; Authentication.', 'positives': [\"As the use of digital images has increased, so has the means and the incentive to create digital image forgeries. Accordingly, there is a great need for digital image forensic techniques capable of detecting image alterations and forged images. A number of image processing operations, such as histogram equalization or gamma correction, are equivalent to pixel value mappings. In this paper, we show that pixel value mappings leave behind statistical traces, which we shall refer to as a mapping's intrinsic fingerprint, in an image's pixel value histogram. We then propose forensic methods for detecting general forms globally and locally applied contrast enhancement as well as a method for identifying the use of histogram equalization by searching for the identifying features of each operation's intrinsic fingerprint. Additionally, we propose a method to detect the global addition of noise to a previously JPEG-compressed image by observing that the intrinsic fingerprint of a specific mapping will be altered if it is applied to an image's pixel values after the addition of noise. Through a number of simulations, we test the efficacy of each proposed forensic technique. Our simulation results show that aside from exceptional cases, all of our detection methods are able to correctly detect the use of their designated image processing operation with a probability of 99% given a false alarm probability of 7% or less.\"], 'negatives': ['A digitally altered photograph, often leaving no visual clues of having been tampered with, can be indistinguishable from an authentic photograph. As a result, photographs no longer hold the unique stature as a definitive recording of events. We describe several statistical techniques for detecting traces of digital tampering in the absence of any digital watermark or signature. In particular, we quantify statistical correlations that result from specific forms of digital tampering, and devise detection schemes to reveal these correlations.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Bankruptcy prediction and credit scoring have long been regarded as critical topics and have been studied extensively in the accounting and finance literature. Artificial intelligence and machine learning techniques have been used to solve these financial decision-making problems. The multilayer perceptron (MLP) network trained by the back-propagation learning algorithm is the mostly used technique for financial decision-making problems. In addition, it is usually superior to other traditional statistical models. Recent studies suggest combining multiple classifiers (or classifier ensembles) should be better than single classifiers. However, the performance of multiple classifiers in bankruptcy prediction and credit scoring is not fully understood. In this paper, we investigate the performance of a single classifier as the baseline classifier to compare with multiple classifiers and diversified multiple classifiers by using neural networks based on three datasets. By comparing with the single classifier as the benchmark in terms of average prediction accuracy, the multiple classifiers only perform better in one of the three datasets. The diversified multiple classifiers trained by not only different classifier parameters but also different sets of training data perform worse in all datasets. However, for the Type I and Type II errors, there is no exact winner. We suggest that it is better to consider these three classifier architectures to make the optimal financial decision. 2007 Elsevier Ltd. All rights reserved.', 'positives': ['El profesor Haykin ha escrito un libro muy interesante, que ya lleva su segunda edición, lo cual es extrafio dentro de la gran cantidad de libros que se producen en la actualidad. Es fácil encontrar en la literatura contemporánea la constante referencia que se hace a este libro; sin embargo, el libro no es lo que el título indica, ya que no es un libro ortodoxo de las teorías y técnicas que son conocidas como redes neuronales (también conocidas como sistemas conexionistas o sistemas neurocomputacionales), tampoco es un libro que presente los fundamentos o bases teóricas de las redes neuronales. neuronales, así como los grandes modelos de esta área de investigación, como son los perceptrones y las redes RBFN (Radial-Basis Function Networks). La presentación de estos cuatro capítulos es excelente.'], 'negatives': ['For many reasons, neural networks have become very popular AI machine learning models. Two of the most important aspects of machine learning models are how well the model generalizes to unseen data, and how well the model scales with problem complexity. Using a controlled task with known optimal training error, we investigate the convergence of the backpropagation (BP) algorithm. We find that the optimal solution is typically not found. Furthermo re, we observe that networks larger than might be expected can result in lower training and generalization error. This res ult is supported by another real world example. We further investigate the training behavior by analyzing the weights in trained networks (excess degrees of freedom are seen to do little harm and to aid convergence), and contrasting the int erpolation characteristics of multi-layer perceptron neura l networks (MLPs) and polynomial models (overfitting behavior is very different – the MLP is often biased towards smoother solutions). Finally, we analyze relevant theory outlining the reasons for significant practical differences. These resul ts bring into question common beliefs about neural network training regarding convergence and optimal network size, suggest alternate guidelines for practical use (lower fear of excess degrees of freedom), and help to direct future work (e.g. methods for creation of more parsimonious solutions, importance of the MLP/BP bias and possibly worse performance of “improved” training algorithms).'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Sign recognition is an integral part of autonomous cars. Any misclassification of traffic signs can potentially lead to a multitude of disastrous consequences, ranging from a life-threatening accident to even a large-scale interruption of transportation services relying on autonomous cars. In this paper, we propose and examine security attacks against sign recognition systems for Deceiving Autonomous caRs with Toxic Signs (we call the proposed attacks DARTS). In particular, we introduce two novel methods to create these toxic signs. First, we propose Out-of-Distribution attacks, which expand the scope of adversarial examples by enabling the adversary to generate these starting from an arbitrary point in the image space compared to prior attacks which are restricted to existing training/test data (In-Distribution). Second, we present the Lenticular Printing attack, which relies on an optical phenomenon to deceive the traffic sign recognition system. We extensively evaluate the effectiveness of the proposed attacks in both virtual and real-world settings and consider both white-box and black-box threat models. Our results demonstrate that the proposed attacks are successful under both settings and threat models. We further show that Out-of-Distribution attacks can outperform In-Distribution attacks on classifiers defended using the adversarial training defense, exposing a new attack vector for these defenses.', 'positives': ['Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.'], 'negatives': ['In the current standardization process of the scalable extension to High Efficiency Video Coding (SHVC) a high level syntax multi-loop approach is close to completion. On the one hand this multi-loop approach offers a reasonable rate-distortion performance while only minimal modifications to the encoder and decoder in both layers are required. On the other hand this approach requires full reconstruction of all pictures of all layers at the decoder side which, in the case of quality scalability with two layers, doubles the decoder complexity. In this paper high layer modifications to the prediction structure similar to the scalable extension of H.264 - AVC are implemented in SHVC and studied. These modifications allow for an enhancement layer decoder implementation to skip a significant amount of motion compensation and deblocking operations in the base layer. It is shown that the decoder complexity can hereby be reduced up to 55% for the random access configuration and up to 64% for the low delay configuration compared to SHVC. An overall coding performance increase of 1.2% when decoding the enhancement layer is reported while when only decoding the base layer a drift can be observed between -0.16 dB for random access and -0.39 dB for low delay.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this demo, we present Cleanix, a prototype system for cleaning relational Big Data. Cleanix takes data integrated from multiple data sources and cleans them on a shared-nothing machine cluster. The backend system is built on-top-of an extensible and flexible data-parallel substrate - the Hyracks framework. Cleanix supports various data cleaning tasks such as abnormal value detection and correction, incomplete data filling, de-duplication, and conflict resolution. We demonstrate that Cleanix is a practical tool that supports effective and efficient data cleaning at the large scale.', 'positives': [\"/ 0+120+354768491;:549<>=?49@BA CEDGFHCJIKFML'N OQP?0+3?N LRPS<UT VXW5<B4Y3?N 0 Z\\\\[^]_[^` acb deaf]_g afhji+aUkjlnm_`+hompacb qrh st4Y3?u20+1v4 W 1;LR<>0+@>N+P w <>L9x\\\\0+1yV5zG{|I }~aU`+m_[^]pa b \\x7fR]_\\x80Uho[^k\\x82\\x81^\\x83 ln\\x84+ho\\x80U\\x84\\x85[^]\\x86b \\x81y\\x80>\\x87 s 0+3?3?u2@M{':549@>:?4 \\x88 LRP?<>493\\x89TGCJ3?@fTBu\\x8aTBPST>09V5D\\x8c\\x8b8z V\\x8dzG{|I k\\x82g aUk\\x82g a>ln\\x81^k^b `\\x8f\\x8e+\\x83\\x90b [Ji+\\x83 \\x91 <Uu2N {|u2\\x92 LR3 CEDGFHCJI\\x93FHL'N OQP?0 3SN LRP?<fT VXW5<B493SN 0 \\x94Qhom_\\x81>b \\x95 m_\\x87 \\x80U`\\x85lnm_`+hompa b qrh \\x88 <Uu2@UT>uv493'\\x96JIGPS\\x97RP?@UT>u23\\x98{S4Yu;T\\x8f4 CEDGFHCJI\\x93FHL'N OQP?0 3SN LRP?<fT VXW5<B493SN 0 \\x99 hom_kv\\x9aompaU`+\\x9b;\\x9cX\\x83 \\x9d>\\x83+kv\\x9aom_`Yb \\x95+afm_\\x9aja>lnm_`+hompa b q\\x9eh\"], 'negatives': ['Wireless Sensor Networks (WSNs) consist of a network of wireless nodes that have the capability to sense a parameter of interest. Sensors of various types are deployed ubiquitously and pervasively in varied environments such as office buildings, wildlife reserves, battle fields, mobile networks, etc The sensed parameter is relayed to a base station through the network formed amongst these nodes. The devices used are typically characterized by low cost, low power and are rugged in operation. The node integrates programming, computation, communication, and sensing onto a single system and provides an easy user interface for operating and deploying it. The paper presents such a design which minimizes cost and power consumption, thus enhancing the life time of the node.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The rise of online social media has led to an explosion in user-generated content. However, user-generated content is difficult to analyze in isolation from its context. Accordingly, context detection and tracking its evolution is essential to understanding social media. This paper presents a statistical model that can detect interpretable topics along with their contexts. A topic is represented by a cluster of words that frequently occur together, and a context is represented by a cluster of hashtags that frequently occur with a topic. The model combines a context with a related topic by jointly modeling words with hashtags and time. Experiments on real datasets demonstrate that the proposed model successfully discovers both meaningful topics and contexts, and tracks their evolution.', 'positives': [\"This paper presents an LDA-style topic model that captures not only the low-dimensional structure of data, but also how the structure changes over time. Unlike other recent work that relies on Markov assumptions or discretization of time, here each topic is associated with a continuous distribution over timestamps, and for each generated document, the mixture distribution over topics is influenced by both word co-occurrences and the document's timestamp. Thus, the meaning of a particular topic can be relied upon as constant, but the topics' occurrence and correlations change significantly over time. We present results on nine months of personal email, 17 years of NIPS research papers and over 200 years of presidential state-of-the-union addresses, showing improved topics, better timestamp prediction, and interpretable trends.\"], 'negatives': ['OBJECTIVES\\nLoneliness is an important influence on quality of life in old age and has been conceptualised as consisting of two dimensions, social and emotional. This article describes analyses that sought to produce models of social and emotional loneliness in older people, using demographic, psychological and health, and social variables.\\n\\n\\nMETHOD\\nOlder people (aged 65+, n=1255) from the Barnsley metropolitan area of the United Kingdom were recruited randomly from within a stratified sampling frame and received a questionnaire-based interview (response rate: 68.1%). The questionnaire contained items and scales on demographic, psychological and health, and social characteristics, and a validated measure of loneliness that assesses both social and emotional loneliness.\\n\\n\\nRESULTS\\nOf the respondents, 7.7% were found to be severely or very severely lonely, while another 38.3% were moderately lonely. Social and emotional loneliness shared 19.36% variance. Being male, being widowed, low well-being, low self-esteem, low-income comfort, low contact with family, low contact with friends, low activity, low perceived community integration, and receipt of community care were significant predictors of social loneliness (R=0.50, R2=0.25, F(18, 979)=18.17, p<0.001). Being widowed, low well-being, low self-esteem, high activity restriction, low-income comfort, and non-receipt of informal care were significant predictors of emotional loneliness (R=0.55, R2=0.30, F (18, 973)=23.00, p<0.001).\\n\\n\\nCONCLUSION\\nThis study provides further empirical support for the conceptual separation of emotional and social loneliness. Consequently, policy on loneliness in older people should be directed to developing a range of divergent intervention strategies if both emotional and social loneliness are to be reduced.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In recent years, the Global Positioning System (GPS) explosive growth in outdoor location tracking. Other hand, another interest in developing indoor location tracking systems. Additionally in radio frequency identification (RFID) technology make it a precise technology for use in indoor location tracking systems. In this paper, we present an RFID-based location tracking system using the Received Signal Strength and Directional Antenna (RSS and DA) architecture, which can provide more flexibility for system implementation and cost-effectiveness for system maintenance.', 'positives': ['In the past, the selection of resources to execute various warehouse operation services was done solely by experts. In this paper, a RFIDbased Resource Management System (RFID-RMS) is designed to help users to select the most suitable resource usage packages for handling warehouse operation orders by retrieving and analysing useful knowledge from a case-based data warehouse for solutions in both time saving and cost effective manner. In addition, a pure integral-linear programming model using a branch and bound algorithm to define the optimum travel distance of forklifts is also developed and embedded in the proposed system. The proposed system, which is suitable for usage in a warehouse operation environment, enhances the effectiveness in formulating resource usage package and managing resource operation by integrating the Radio Frequency Identification (RFID), case-based reasoning (CBR) technologies and the programming model for forklift route optimization. Through applying RFID-RMS in the GENCO Distribution System, a multinational logistics company, the utilization of warehouse resources is expected to be maximized while work efficiency will be greatly enhanced. q 2005 Elsevier Ltd. All rights reserved.'], 'negatives': ['In this chapter, we introduce the readers to the field of big educational data and how big educational data can be analysed to provide insights into different stakeholders and thereby foster data driven actions concerning quality improvement in education. For the analysis and exploitation of big educational data, we present different techniques and popular applied scientific methods for data analysis and manipulation such as analyt‐ ics and different analytical approaches such as learning, academic and visual analytics, providing examples of how these techniques and methods could be used. The concept of quality improvement in education is presented in relation to two factors: (a) to improve‐ ment science and its impact on different processes in education such as the learning, educational and academic processes and (b) as a result of the practical application and realization of the presented analytical concepts. The context of health professions education is used to exemplify the different concepts.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"The task of protecting users' privacy is made more difficult by their attitudes towards information disclosure without full awareness and the economics of the tracking and advertising industry. Even after numerous press reports and widespread disclosure of leakages on the Web and on popular Online Social Networks, many users appear not be fully aware of the fact that their information may be collected, aggregated and linked with ambient information for a variety of purposes. Past attempts at alleviating this problem have addressed individual aspects of the user's data collection. In this paper we move towards a comprehensive and efficient client-side tool that maximizes users' awareness of the extent of their information leakage. We show that such a customizable tool can help users to make informed decisions on controlling their privacy footprint.\", 'positives': [\"Participation in social networking sites has dramatically increased in recent years. Services such as Friendster, Tribe, or the Facebook allow millions of individuals to create online profiles and share personal information with vast networks of friends - and, often, unknown numbers of strangers. In this paper we study patterns of information revelation in online social networks and their privacy implications. We analyze the online behavior of more than 4,000 Carnegie Mellon University students who have joined a popular social networking site catered to colleges. We evaluate the amount of information they disclose and study their usage of the site's privacy settings. We highlight potential attacks on various aspects of their privacy, and we show that only a minimal percentage of users changes the highly permeable privacy preferences.\"], 'negatives': ['Cloud Computing is a model of service delivery and access where dynamically scalable and virtualized resources are provided as a service over the Internet. This model creates a new horizon of opportunity for enterprises. It introduces new operating and business models that allow customers to pay for the resources they effectively use, instead of making heavy upfront investments. The biggest challenge in Cloud Computing is the lack of a de facto standard or single architectural method, which can meet the requirements of an enterprise cloud approach. In this paper, we explore the architectural features of Cloud Computing and classify them according to the requirements of end-users, enterprises that use the cloud as a platform, and cloud providers themselves. We show that several architectural features will play a major role in the adoption of the Cloud Computing paradigm as a mainstream commodity in the enterprise world. This paper also provides key guidelines to software architects and Cloud Computing application developers for creating future architectures.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Traffic sampling is viewed as a prominent strategy contributing to lightweight and scalable network measurements. Although multiple sampling techniques have been proposed and used to assist network engineering tasks, these techniques tend to address a single measurement purpose, without detailing the network overhead and computational costs involved. The lack of a modular approach when defining the components of traffic sampling techniques also makes difficult their analysis. Providing a modular view of sampling techniques and classifying their characteristics is, therefore, an important step to enlarge the sampling scope, improve the efficiency of measurement systems, and sustain forthcoming research in the area. Thus, this paper defines a taxonomy of traffic sampling techniques resorting to a comprehensive analysis of the inner components of existing proposals. After identifying granularity, selection scheme, and selection trigger as the main components differentiating sampling proposals, the study goes deeper on characterizing these components, including insights into their computational weight. Following this taxonomy, a general-purpose architecture is established to sustain the development of flexible sampling-based measurement systems. Traveling inside packet sampling techniques, this paper contributes to a clearer positioning and comparison of existing proposals, providing a road map to assist further research and deployments in the area. Copyright © 2016 John Wiley & Sons, Ltd.', 'positives': ['The use of packet sampling for traffic measurement has become mandatory for network operators to cope with the huge amount of data transmitted in nowadays net works, powered by increasingly faster transmission technologies. Therefore, many networking ta sks must already deal with such reduced data, more available but less rich in information. In this work we a ssess the impact of packet sampling on various network monitoring activities, with a particular f ocus on traffic characterization and classification. We process an extremely heterogeneous dataset composed of f our packet level traces (representative of different access technologies and operational environmen ts) with a traffic monitor able to apply different sampling policies and rates to the traffic and extract severa l features both in aggregated and per-flow fashion, providing empirical evidences of the impact of packet sampl ing on both traffic measurement and traffic classification. First, we analyze feature distortion, quan tified by means of two statistical metrics: most features appear already deteriorated under low sampling st ep, no matter the sampling policy, while only a few remain consistent under harsh sampling conditions, which m ay even cause some artifacts undermining the correctness of measurements. Second, we evaluate the perfo rmance of traffic classification under sampling. The information content of features, even though deteriora ted, still allows a good classification accuracy, provided that the classifier is trained with data obtained at the same sampling rate of the target data. The accuracy is also due to a thoughtful choice of a smart samplin g olicy which biases the sampling towards packets carrying the most useful information. Copyright c © 0000 John Wiley & Sons, Ltd.'], 'negatives': ['This paper presents a three degrees of freedom precision hybrid stage that can move and align an object on it for measurement of its three-dimensional image using the confocal scanning microscope. The hybrid stage consists of two individually operating x-y-thetas stages, called the coarse stage and the fine stage. The coarse stage is driven by the three linear motors and produces the initial movement of an object. On the other hand, the fine stage is driven by the four voice coil motors and provides the final alignment of it with sub-micron meter accuracy. For control of the hybrid stage, we propose a precision motion controller. The performances of the precision motion controller of the hybrid stage are evaluated by experiment with a hardware setup.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In real applications, the capacitive tactile sensor array usually needs to be mounted on curved surfaces. To study the effect of curved surfaces on the sensing performance of the sensor array, we have fabricated the sensor array with 4 × 4 sensor units. Four types of rigid and flexible curved surfaces are selected to mount the sensor array, with radius of curvature of +∞, 40 mm, 30 mm, and 20 mm. The initial capacitances of the sensor array increase as the radius of the surfaces decrease. By applying normal and shear forces to the sensor unit mounted on the curved surfaces, we have found that as the radius of the surface decrease, the capacitance increases faster when the sensor is mounted on 40 mm curved surfaces, and increases slower on 30 mm and 20 mm curved surfaces. The shear forces in the x- and y-axes cause symmetric and asymmetric capacitance changes to the sensor unit, respectively. The flexible curved surfaces can induce larger capacitance changes to the sensor unit, compared with the rigid ones.', 'positives': ['This paper presents a flexible capacitive tactile sensor array embedded with a truncated polydimethylsiloxane pyramid array as a dielectric layer. The proposed sensor array has been fabricated with 4 × 4 sensor units. The measurement ranges of forces in the x-axis, y-axis, and z-axis are 0-0.5, 0-0.5, and 0-4 N, respectively. In the range of 0-0.5 N, the sensitivities of the sensor unit are 58.3%/N, 57.4%/N, and 67.2%/N in the x-axis, y-axis, and z-axis, respectively. In the range of 0.5-4 N, the sensitivity in the z-axis is 7.7%/N. Three-axis force measurement has been conducted for all the sensor units. The average errors between the applied and calculated forces are 11.8% ± 6.4%. The sensor array has been mounted on a prosthetic hand. A paper cup and a cube are grasped by the prosthetic hand and the three-axis contact force is measured in real time by the sensor array. Results show that the sensor can capture the three-axis contact force image both in light and tight grasping. The proposed capacitive tactile sensor array can be utilized in robotics and prosthetic hand applications.'], 'negatives': ['Integrating easy-to-extract structured information such as medication and treatments into current natural language processing based systems can significantly boost coding performance; in this paper, we present a system that rigorously attempts to validate this intuitive idea. Based on recent i2b2 challenge winners, we derive a strong language model baseline that extracts patient outcomes from discharge summaries. Upon incorporating additional clinical cues into this language model, we see a significant boost in performance to F1 of 88.3 and a corresponding reduction in error of 23.52%.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Seeing the public of Bandung city as an active social media user, Bandung government provides channel in Twitter for citizen to report their complaints. In order to make the citizen complaint monitoring easier, there is a need to automatically detect the topics of complaint tweets (written in Indonesian language) in order to assist the government in managing the complaints reported. In this paper, a system to detect the topics of Indonesian complaint tweets automatically using supervised learning and unsupervised learning approaches is proposed. The supervised learning approach is implemented to classify complaint tweets topic, whereas the unsupervised learning approach is used to cluster complaint tweets based on the similarity of detail information contained in the complaints. Both the supervised learning and the unsupervised learning approaches are required to classify the topics of a tweet and to capture the detail information from each detected topic. The topics are classified using single label and multi label classification. The supervised learning approach is evaluated using accuracy, precision, recall, and F1 score. Three supervised machine learning algorithms are evaluated: Sequential Minimal Optimization, Naïve Bayes Multinomial, and Random Forests. The best algorithm for single label topic classification is SMO, with the accuracy average of 95%, whereas the best algorithm for multi-label topic classification is Random Forests, with 97.92% accuracy, 98.74% precision, 98.36% recall, and 98.44% F1 score. In the unsupervised learning approach, Clustering Index Value is used to evaluate the topic clusters detected. Two unsupervised learning algorithms are evaluated; Exemplar Based Topic Detection and Document Pivot Technique using TF-IDF. Exemplar Based Topic Detection has the best performance for detecting detail topic clusters with Clustering Index Value of 0.9653.', 'positives': [], 'negatives': ['Data stream processing is currently gaining importance due to the developments in novel application areas like escience, e-health, and e-business (considering RFID, for example). Focusing on e-science, it can be observed that scientific experiments and observations in many fields, e. g., in physics and astronomy, create huge volumes of data which have to be interchanged and processed. With experimental and observational data coming in particular from sensors, online simulations, etc., the data has an inherently streaming nature. Furthermore, continuing advances will result in even higher data volumes, rendering storing all of the delivered data prior to processing increasingly impractical. Hence, in such e-science scenarios, processing and sharing of data streams will play a decisive role. It will enable new possibilities for researchers, since they will be able to subscribe to interesting data streams of other scientists without having to set up their own devices or experiments. This results in much better utilization of expensive equipment such as telescopes, satellites, etc. Further, processing and sharing data streams on-the-fly in the network helps to reduce network traffic and to avoid network congestion. Thus, even huge streams of data can be handled efficiently by removing unnecessary parts early on, e. g., by early filtering and aggregation, and by sharing previously generated data streams and processing results. To enable these optimizations, we use Peer-to-Peer (P2P) networking techniques. P2P has gained a lot of attention in the context of exchanging persistent data—in particular for file sharing. In contrast to that, we apply P2P networks for the dissemination of individually subscribed and transformed data streams, allowing for data stream sharing. By using the computational capabilities of peers in the P2P network, we can push data stream transforming operators into the network, thus enabling efficient in-network'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This research studies on the e-learning services acceptance in higher education institutions in Brunei Darussalam. This research has seven hypotheses, relating to independent, intermediary, and dependent variables. The independent variables include lecturer’s characteristics, design of learning contents, teaching materials, and playfulness; while the intermediary variables are perceived benefits and perceived ease of use. On the other hand, the dependent variable in this research is the intention to use e-learning. Multiple regression analysis were conducted to test the hypotheses proposed. Data analysis from this research has confirmed that the lecturer’s characteristics, teaching materials, perceived ease of use and the intention to use e-learning corresponds to the perceived benefits. Meanwhile, the design of learning content and the intention to use e-learning are positively related to the perceived ease of use and lastly, the variable playfulness is positively related to the intention to use e-learning.', 'positives': ['Although the benefits of e-learning have been discussed in various previous studies; it is a critical issue of better understanding the reasons why some learners are dissatisfied with the e-learning experience. Therefore, this research investigates learners’ satisfaction, behavioral intentions, and the effectiveness of the Blackboard e-learning system. A total of 424 university students were surveyed using a standard questionnaire. The results showed that perceived self-efficacy is a critical factor that influences learners’ satisfaction with the Blackboard e-learning system. Perceived usefulness and perceived satisfaction both contribute to the learners’ behavioral intention to use the e-learning system. Furthermore, e-learning effectiveness can be influenced by multimedia instruction, interactive learning activities, and e-learning system quality. This research proposes a conceptual model for understanding learners’ satisfaction, behavioral intention, and effectiveness of using the e-learning system. 2007 Elsevier Ltd. All rights reserved.'], 'negatives': [\"To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Hematocolpos is rarely presented as a pelvic mass which mechanically compresses the bladder and the urethra thereby causing urinary retention. A 12-year-old girl referred with the history of lower abdominal pain and retention of urine for 24\\xa0h. The patient had not started her menses yet. Three weeks before she also complained of discomfort on passing urine, frequency and urgency and was taken to a local outpatient clinic where she was given antibiotics with the diagnosis of urinary tract infection, she had also the history of intermittent urinary catheterization (three times before) in an emergency department because of acute severe urinary retention. Transabdominal ultrasonography revealed a pelvic semi-solid mass suggestive of hematocolpos. Pelvic examination revealed a pale blue imperforate hymen bulging from the vaginal introitus outwards. A cruciate incision was made over the hymen. Postoperative period was uneventful. In case of acute severe urinary retention in an adolescent girl, the clinicians should keep in mind that imperforate hymen may be a causative factor and this condition may easily be treated surgically.', 'positives': ['Massive hematocolpos resulting from an imperforate hymen is quite a rare cause of acute urinary retention, in an adolescent girl admitted to the emergency department. A 12-year-old girl suffering from severe inguinal pain and dysuria together with difficulty in urination for about 1\\xa0month was admitted to the emergency department for acute urinary retention. On gynecological examination, imperforate hymen was observed to be the cause of the urinary difficulty. Pelvic magnetic resonance imaging revealed a dilated vagina exerting pressure on the bladder outlet suggestive of hematocolpos. Cruciate hymenotomy was performed. The postoperative period and three follow-up visits of the patient up to the 6th month were uneventful. The diagnosis of imperforate hymen can be missed if a genital examination is not performed in adolescent girls presenting to emergency departments with urinary difficulty. The purpose of this paper is to increase awareness among emergency physicians about the probability of imperforate hymen while examining adolescent girls with urinary retention and intermittent lower abdominal pain.'], 'negatives': ['BACKGROUND\\nTo assess the efficacy of quantitative analysis of the optic nerve head and peripapillary retinal nerve fiber layer (RNFL) with the spectral-domain optical coherence tomography (SD-OCT) in differentiating optic disc edema (ODE) from optic nerve head drusen (ONHD).\\n\\n\\nMETHODS\\nProspective clinical study. Twenty-five eyes of 25 ODE patients (group 1), 25 eyes of 25 ONHD patients (group 2), and 25 eyes of 25 healthy subjects were included. The thickness of the peripapillary RNFL, the thickness of the subretinal hyporeflective space (SHYPS), the area of the SHYPS, the horizontal length of the optic nerve head, and the angle between the temporal RNFL and the optic nerve head (α-angle) were evaluated with SD-OCT.\\n\\n\\nRESULTS\\nThe mean RNFL thickness was significantly greater in group 1 when compared with group 2 and control group (P < 0.001). The receiver operating characteristic curve areas for temporal and nasal RNFL thicknesses in differentiating group 1 and group 2 were 0.819 and 0.851, respectively (for temporal RNFL thickness >101.5 μm: sensitivity 92%, specificity 65%; for nasal RNFL thickness >74.5 μm: sensitivity 92%, specificity 47%). The mean SHYPS thickness, SHYPS area, and degree of the α-angle were greater in group 1 when compared with group 2 (P < 0.05). For the SHYPS thickness >464 μm: 85% sensitivity and 60% specificity; for the SHYPS area >811 μm: 85% sensitivity and 89% specificity; and for the α-angle >141°: 77% sensitivity and 95% specificity were obtained.\\n\\n\\nCONCLUSION\\nThe quantitative analysis of the optic nerve head and peripapillary RNFL with SD-OCT can provide useful data in differentiating ODE from ONHD.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We investigate from the competence standpoint two recent models of lexical semantics, algebraic conceptual representations and continuous vector models. Characterizing what it means for a speaker to be competent in lexical semantics remains perhaps the most significant stumbling block in reconciling the two main threads of semantics, Chomsky’s cognitivism and Montague’s formalism. As Partee (1979) already notes (see also Partee 2013), linguists assume that people know their language and that their brain is finite, while Montague assumed that words are characterized by intensions, formal objects that require an infinite amount of information to specify. In this paper we investigate two recent models of lexical semantics that rely exclusively on finite information objects: algebraic conceptual representations (ACR) (Wierzbicka, 1985; Kornai, 2010; Gordon et al., 2011), and continuous vector space (CVS) models which assign to each word a point in finitedimensional Euclidean space (Bengio et al., 2003; Turian et al., 2010; Pennington et al., 2014). After a brief introduction to the philosophical background of these and similar models, we address the hard questions of competence, starting with learnability in Section 2; the ability of finite networks or vectors to replicate traditional notions of lexical relatedness such as synonymy, antonymy, ambiguity, polysemy, etc. in Section 3; the interface to compositional semantics in Section 4; and language-specificity and universality in Section 5. Our survey of the literature is far from exhaustive: both ACR and CVS have deep roots, with significant precursors going back at least to Quillian (1968) and Osgood et al. (1975) respectively, but we put the emphasis on the computational experiments we ran (source code and lexica available at github.com/kornai/4lang).', 'positives': ['We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.'], 'negatives': ['0747-5632/$ see front matter Published by Elsevier doi:10.1016/j.chb.2011.08.016 ⇑ Corresponding author. Address: Department o Alabama, P.O. Box 870348, Tuscaloosa, AL 35487-034 758 2003; fax: +1 205 348 8648. E-mail address: nlmuscanell@crimson.ua.edu (N.L. The present study examined the influence of gender and personality on individuals’ use of online social networking websites such as Facebook and MySpace. Participants were 238 undergraduate students who reported being members of Facebook, MySpace, or both. Based on prior research examining online behavior, we expected that gender and scores on the Big Five personality scale would moderate online social networking behavior. The results supported our predictions. Specifically, men reported using social networking sites for forming new relationships while women reported using them more for relationship maintenance. Furthermore, women low in agreeableness reported using instant messaging features of social networking sites more often than women high in agreeableness, whereas men low in openness reported playing more games on social networking sites compared to men high in openness. Overall, these results indicate the importance of examining individual differences in online behavior. Published by Elsevier Ltd.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Exploiting variable impedance for dynamic tasks such as walking is both challenging and topical - research progress in this area impacts not only autonomous, bipedal mobility but also prosthetics and exoskeletons. In this work, we present the design, construction and preliminary testing of a planar bipedal robot with joints capable of physically varying both their stiffness and damping independently - the first of its kind. A wide variety of candidate variable stiffness and damping actuator designs are investigated. Informed by human biophysics and locomotion studies, we design an appropriate (heterogenous) impedance modulation mechanism that fits the necessary torque and stiffness range and rate requirements at each joint while ensuring the right form factor. In addition to hip, knee and ankle, the constructed robot is also equipped with a three part compliant foot modelled on human morphology. We describe in detail the hardware construction and the communication and control interfaces. We also present a full physics based dynamic simulation which matches the hardware closely. Finally, we test impedance modulation response characteristics and a basic walking gait realised through a simple movement controller, both in simulation and on the real hardware.', 'positives': [\"The Actuator with Adjustable Stiffness (AwAS) is an actuator which can independently control equilibrium position and stiffness by two motors. The first motor controls the equilibrium position while the second motor regulates the compliance. This paper describes the design and development of AwAS-II which is an improved version of the original realization. AwAS tuned the stiffness by controlling the location of the springs and adjusting its arm, length. Instead AwAS-II regulates the compliance by implementing a force amplifier based on a lever mechanism on which a pivot point can adjust the force amplification ratio from zero to infinitive. As in the first implementation, the actuator which is responsible for adjusting the stiffness in AwAS II is not working against the spring forces. Its displacement is perpendicular to the force generated by springs which makes changing the stiffness energetically efficient. As the force amplification ratio can theoretically change from zero to infinitive consequently the level of stiffness can tune from very soft to completely rigid. Because this range does not depends on the spring's rate and length of the lever, thus soft springs and small lever can be used which result in a lighter and more compact setup. Furthermore as the lever arm is shorter the time required for the stiffness regulation is smaller.\"], 'negatives': ['At present, several post-quantum cryptosystems have been proposed, and lattice-based cryptography is the main candidate. Especially in the direction of digital signatures, there are now many practical lattice-based signature schemes. However, there exist few lattice-based signatures with special property such as blind signature. Blind signature was introduced by Chaum for creating untraceable payment system. Then, it is widely used in e-cash and voting, especially in the revolutionary digital cash system based on blockchain. In our paper, we present a method to construct a post-quantum blind signature based on lattice assumptions, and we proved that any existential forger against the security of the resulting scheme can solve the <inline-formula> <tex-math notation=\"LaTeX\">${\\\\text {SIS}}_{q, n, m, \\\\beta }$ </tex-math></inline-formula> problem for <inline-formula> <tex-math notation=\"LaTeX\">$\\\\beta = \\\\widetilde {O}(dn)$ </tex-math></inline-formula>. Our main technique is the rejection sampling theory. The expected number of times needed to output a blind signature is at most <inline-formula> <tex-math notation=\"LaTeX\">$e^{2}$ </tex-math></inline-formula> under aborting, and our new scheme has much smaller signature size than those of all the previously proposed blind signature schemes over lattices.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'A center-fed, single-layer, planar antenna with unilateral radiation patterns is investigated. The antenna consists of a turnstile-shaped patch and a slotted ground plane, which function as a vertical magnetic dipole and a horizontal electric dipole, respectively. By combining the two orthogonal dipoles with the same radiation intensities and antiphases, unilateral patterns with wide beamwidth and high front-to-back (F/B) ratio are achieved. As the unilateral radiation pattern can be easily steered in the horizontal plane by changing the slot location, a pattern reconfigurable antenna is further designed by using p-i-n diodes to control the connection states of the radial slots on the ground plane. Four steerable beams are obtained, capable of covering the entire azimuthal plane. For demonstration, both the unilateral and pattern reconfigurable antennas operating at 2.4 GHz WLAN band (2.40–2.48 GHz) were fabricated and measured. The measured overlapping bandwidths, with  $\\\\vert S_{11}\\\\vert <-10$  dB and F/B ratio >15 dB, are given by 7.0% (2.33–2.5 GHz) and 6.3% (2.32–2.47 GHz), respectively.', 'positives': ['A wideband low-profile omnidirectional circularly polarized (CP) patch antenna is proposed and investigated in this communication. The design utilizes two monopolar modes of a circular patch which connects to a modified ground plane by a set of conductive vias, to achieve wide-band impedance matching. The curved branches introduced at the edge of circular ground plane excite a degenerate mode and create CP fields. To verify the design, a prototype operating at 2.4 GHz-WLAN band has been fabricated and measured. Measured reflection coefficient, axial ratio (AR), radiation pattern, and antenna gain agree well with simulation results. The proposed prototype has a low profile of 0.024 λ0, a 10-dB impedance bandwidth of 19.8% and a 3-dB AR bandwidth of 19.3%. To further characterize the design concept, a parametric study of the proposed antenna is carried out using HFSS, and general design guidelines are provided.'], 'negatives': ['The phrase \"Aesthetic Computing\" while taken literally applies the philosophical area of aesthetics to the field of computing and work in the area is broadly defined as such; however, in my operational definition for the work we do at the University of Florida, aesthetic computing is treated as embodied formal language. The purpose of aesthetic computing is to deliver knowledge and practice of formal languages using aesthetic products as a vehicle. Aesthetic Computing is founded on an increasing collection of literature on the role of the body in learning, specifically in mathematics. This foundation is then applied to the field of computing whose formal language elements are extensions of mathematics. There are two questions that this new area raises:'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We present a new method for semantic role labeling in which arguments and semantic roles are jointly embedded in a shared vector space for a given predicate. These embeddings belong to a neural network, whose output represents the potential functions of a graphical model designed for the SRL task. We consider both local and structured learning methods and obtain strong results on standard PropBank and FrameNet corpora with a straightforward product-of-experts model. We further show how the model can learn jointly from PropBank and FrameNet annotations to obtain additional improvements on the smaller FrameNet dataset.', 'positives': ['We propose a non-linear graphical model for structured prediction. It combines the power of deep neural networks to extract high level features with the graphical framework of Markov networks, yielding a powerful and scalable probabilistic model that we apply to signal labeling tasks.'], 'negatives': ['Due to global climate change as well as economic concern of network operators, energy consumption of the infrastructure of cellular networks, or “Green Cellular Networking,” has become a popular research topic. While energy saving can be achieved by adopting renewable energy resources or improving design of certain hardware (e.g., power amplifier) to make it more energy-efficient, the cost of purchasing, replacing, and installing new equipment (including manpower, transportation, disruption to normal operation, as well as associated energy and direct cost) is often prohibitive. By comparison, approaches that work on the operating protocols of the system do not require changes to current network architecture, making them far less costly and easier for testing and implementation. In this survey, we first present facts and figures that highlight the importance of green mobile networking and then review existing green cellular networking research with particular focus on techniques that incorporate the concept of the “sleep mode” in base stations. It takes advantage of changing traffic patterns on daily or weekly basis and selectively switches some lightly loaded base stations to low energy consumption modes. As base stations are responsible for the large amount of energy consumed in cellular networks, these approaches have the potential to save a significant amount of energy, as shown in various studies. However, it is noticed that certain simplifying assumptions made in the published papers introduce inaccuracies. This review will discuss these assumptions, particularly, an assumption that ignores the effect of traffic-load-dependent factors on energy consumption. We show here that considering this effect may lead to noticeably lower benefit than in models that ignore this effect. Finally, potential future research directions are discussed.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Recent research in sensor networks, wireless location systems, and power-saving in ad hoc networks suggests that some applications' wireless traffic be modeled as an event-driven workload: a workload where many nodes send traffic at the time of an event, not all reports of the event are needed by higher level protocols and applications, and events occur infrequently relative to the time needed to deliver all required event reports. We identify several applications that motivate the event-driven workload and propose a protocol that is optimal for this workload. Our proposed protocol, named CSMA/p/sup */, is nonpersistent carrier sense multiple access (CSMA) with a carefully chosen nonuniform probability distribution p/sup */ that nodes use to randomly select contention slots. We show that CSMA/p/sup */ is optimal in the sense that p/sup */ is the unique probability distribution that minimizes collisions between contending stations. CSMA/p/sup */ has knowledge of N. We conclude with an exploration of how p/sup */ could be used to build a more practical medium access control protocol via a probability distribution with no knowledge of N that approximates p/sup */.\", 'positives': ['This paper presents Span, a power saving technique for multi-hop ad hoc wireless networks that reduces energy consumption without significantly diminishing the capacity or connectivity of the network. Span builds on the observation that when a region of a shared-channel wireless network bag a sufficient density of nodes, only a small number of them need be on at any time to forward traffic for active connections.\\nSpan is a distributed, randomized algorithm where nodes make local decisions on whether to sleep, or to join a forwarding backbone as a coordinator. Each node bases its decision on an estimate of how many of its neighbors will benefit from it being awake, and the amount of energy available to it. We give a randomized algorithm where coordinators rotate with time, demonstrating how localized node decisions lead to a connected, capacity-preserving global topology.\\nImprovement in system lifetime due to Span increases as the ratio of idle-to-sleep energy consumption increases, and increases as the density of the network increases. For example, our simulations show that with a practical energy model, system lifetime of an 802.11 network in power saving mode with Span is a factor of two better than without. Span integrates nicely with 802.11—when run in conjunction with the 802.11 power saving mode, Span improves communication latency, capacity, and system lifetime.'], 'negatives': ['The IEC 61499 standard provides means to specify distributed control systems in terms of function blocks. The execution model is event driven (asynchronous), where triggering events may be associated with data (and seen as a message). In this paper we propose a low complexity implementation technique allowing to assess end-to-end response time of event chains spanning over a set of networked devices. In this paper we develop a method to provide safe end-to-end response time taking both intra- and inter-device delivery delays into account. As a use case we study the implementation onto (single-core) ARM-cortex based devices communicating over a switched Ethernet network. For the analysis we define a generic switch model and an experimental setup allowing us to study the impact of network topology as well as 802.1Q quality of service in a mixed critical setting. Our results indicate that safe sub millisecond end-to-end response times can be obtained using the proposed approach.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The rapid growth of the Internet has brought with it an exponential increase in the type and frequency of cyber attacks. Many well-known cybersecurity solutions are in place to counteract these attacks. However, the generation of Big Data over computer networks is rapidly rendering these traditional solutions obsolete. To cater for this problem, corporate research is now focusing on Security Analytics, i.e., the application of Big Data Analytics techniques to cybersecurity. Analytics can assist network managers particularly in the monitoring and surveillance of real-time network streams and real-time detection of both malicious and suspicious (outlying) patterns. Such a behavior is envisioned to encompass and enhance all traditional security techniques. This paper presents a comprehensive survey on the state of the art of Security Analytics, i.e., its description, technology, trends, and tools. It hence aims to convince the reader of the imminent application of analytics as an unparalleled cybersecurity solution in the near future.', 'positives': ['Global Internet threats have undergone a profound transformation from attacks designed solely to disable infrastructure to those that also target people and organizations. At the center of many of these attacks are collections of compromised computers, or Botnets, remotely controlled by the attackers, and whose members are located in homes, schools, businesses, and governments around the world [6]. In this survey paper we provide a brief look at how existing botnet research, the evolution and future of botnets, as well as the goals and visibility of today’s networks intersect to inform the field of botnet technology and defense.'], 'negatives': ['A \"discount\" version of Q-methodology for HCI, called \"HCI-Q\", can be used in iterative design cycles to explore, from the point of view of users and other stakeholders, what makes technologies personally significant. Initially, designers critically reflect on their own assumptions about how a design may affect social and individual behavior. Then, designers use these assumptions as stimuli to elicit other people\\'s points of view. This process of critical self-reflection and evaluation helps the designer to assess the fit between a design and its intended social context of use. To demonstrate the utility of HCI-Q for research and design, we use HCI-Q to explore stakeholders\\' responses to a prototype Alternative and Augmentative Communication (AAC) application called Vid2Speech. We show that our adaptation of Q-methodology is useful for revealing the structure of consensus and conflict among stakeholder perspectives, helping to situate design within the context of relevant value tensions and norms.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In a large sample (N = 234), we tested effects of 24-hr of sleep deprivation on error rates in a procedural task that requires memory maintenance of task-relevant information. In the evening, participants completed the task under double-blind conditions and then either stayed awake in the lab overnight or slept at home. In the morning, participants completed the task again. Sleep-deprived participants were more likely to suffer a general breakdown in ability (or willingness) to meet a modest accuracy criterion they had met the night before. Among sleep-deprived participants who could still perform the task, error rates were elevated, and errors reflecting memory failures increased with time-on-task. The results suggest that sleep-deprived individuals should not perform procedural tasks associated with interruptions and costly errors-or, if they must, they should perform such tasks only for short periods. (PsycINFO Database Record (c) 2018 APA, all rights reserved).', 'positives': ['Sleep deprivation severely compromises the ability of human beings to respond to stimuli in a timely fashion. These deficits have been attributed in large part to failures of vigilant attention, which many theorists believe forms the bedrock of the other more complex components of cognition. One of the leading paradigms used as an assay of vigilant attention is the psychomotor vigilance test (PVT), a high signal-load reaction-time test that is extremely sensitive to sleep deprivation. Over the last twenty years, four dominant findings have emerged from the use of this paradigm. First, sleep deprivation results in an overall slowing of responses. Second, sleep deprivation increases the propensity of individuals to lapse for lengthy periods (>500 ms), as well as make errors of commission. Third, sleep deprivation enhances the time-on-task effect within each test bout. Finally, PVT results during extended periods of wakefulness reveal the presence of interacting circadian and homeostatic sleep drives. A theme that links these findings is the interplay of \"top-down\" and \"bottom-up\" attention in producing the unstable and unpredictable patterns of behavior that are the hallmark of the sleep-deprived state.'], 'negatives': [\"In tasks requiring sustained attention, human alertness varies on a minute time scale. This can have serious consequences in occupations ranging from air traffic control to monitoring of nuclear power plants. Changes in the electroencephalographic (EEG) power spectrum accompany these fluctuations in the level of alertness, as assessed by measuring simultaneous changes in EEG and performance on an auditory monitoring task. By combining power spectrum estimation, principal component analysis and artificial neural networks, the authors show that continuous, accurate, noninvasive, and near real-time estimation of an operator's global level of alertness is feasible using EEC; measures recorded from as few as two central scalp sites. This demonstration could lead to a practical system for noninvasive monitoring of the cognitive state of human operators in attention-critical settings.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"In this paper, we analyze the Internet traffic from a different point of view based on Benford's law, an empirical law describing the distribution of leading digits in a collection of numbers met in naturally occurring phenomena. We claim that Benford's law holds for the inter-arrival times of TCP flows in case of normal traffic. Consequently, any type of anomalies affecting TCP flows, including intentional intrusions or unintended faults and network failures in general, can be detected by investigating the first digit distributions of the inter-arrival times of TCP SYN packets. In this paper we apply our findings to the detection of intentional attacks, whereas other types of anomalies can be studied in future works. We support our claim with the related researches that indicate the TCP flow inter-arrival times can be modeled by Weibull distribution with shape parameter less than one, and show the relation between Weibull distributed data and Benford’s law. Finally, we validate our findings on real traffic and achieve encouraging results.\", 'positives': ['One way to describe anomalies is by saying that anomalies are not concentrated. This leads to the problem of finding level sets for the data generating density. We interpret this learning problem as a binary classification problem and compare the corresponding classification risk with the standard performance measure for the density level problem. In particular it turns out that the empirical classification risk can serve as an empirical performance measure for the anomaly detection problem. This allows us to compare different anomaly detection algorithms empirically, i.e. with the help of a test set. Based on the above interpretation we then propose a support vector machine (SVM) for anomaly detection. Finally, we establish universal consistency for this SVM and report some experiments which compare our SVM to other commonly used methods including the standard one-class SVM.'], 'negatives': [\"The purpose of this study is to estimate the national prevalence of parent-reported attention deficit/hyperactivity disorder (ADHD) diagnosis and treatment among U.S. children 2-17\\xa0years of age using the 2016 National Survey of Children's Health (NSCH). The NSCH is a nationally representative, cross-sectional survey of parents regarding their children's health that underwent a redesign before the 2016 data collection. It included indicators of lifetime receipt of an ADHD diagnosis by a health care provider, whether the child currently had ADHD, and receipt of medication and behavioral treatment for ADHD. Weighted prevalence estimates were calculated overall and by demographic and clinical subgroups (n\\xa0=\\xa045,736). In 2016, an estimated 6.1 million U.S. children 2-17\\xa0years of age (9.4%) had ever received an ADHD diagnosis. Of these, 5.4 million currently had ADHD, which was 89.4% of children ever diagnosed with ADHD and 8.4% of all U.S. children 2-17\\xa0years of age. Of children with current ADHD, almost two thirds (62.0%) were taking medication and slightly less than half (46.7%) had received behavioral treatment for ADHD in the past year; nearly one fourth (23.0%) had received neither treatment. Similar to estimates from previous surveys, there is a large population of U.S. children and adolescents who have been diagnosed with ADHD by a health care provider. Many, but not all, of these children received treatment that appears to be consistent with professional guidelines, though the survey questions are limited in detail about specific treatment types received. The redesigned NSCH can be used to annually monitor diagnosis and treatment patterns for this highly prevalent and high-impact neurodevelopmental disorder.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Food is an inseparable part of people's lives. Food image recognition has been attracting increasing attention due to the advances of Internet, imaging techniques and social media. Approaches for food image recognition are mainly focused on two main directions: low-level approaches and mid-level approaches. Low-level approaches extract low-level local features, such as SIFT or SURF, following feature encoding techniques. Mid-level approaches extract higher-level image parts and have shown promising results in many recognition problems. Compared with other image recognition problems, food images are highly deformable with large intra-class variance and small between-class variance. In this paper, considering that mid-level approaches' superior performance and superpixels segmentation methods' ability to successfully segment food parts, we propose a superpixel-based food image recognition framework to mine mid-level superpixel food parts-to-class similarity. We evaluate the proposed framework on UEC Food dataset, and show promising results when compared with existing state-of-the-art methods.\", 'positives': ['In this paper, we report the feature obtained from the Deep Convolutional Neural Network boosts food recognition accuracy greatly by integrating it with conventional hand-crafted image features, Fisher Vectors with HoG and Color patches. In the experiments, we have achieved 72.26% as the top-1 accuracy and 92.00% as the top-5 accuracy for the 100-class food dataset, UEC-FOOD100, which outperforms the best classification accuracy of this dataset reported so far, 59.6%, greatly.'], 'negatives': ['We present a fully automatic method for design-preserving transfer of garments between characters with different body shapes. For real-life garments, such transfer is performed through a knowledge intensive and time consuming process, known as pattern grading. Our first contribution is to reformulate the criteria used in professional pattern-grading as a set of geometric requirements, respectively expressing shape or design preservation, proportionality, and fit. We then propose a fully automatic garment transfer algorithm which satisfies all of these criteria while ensuring the physical plausibility of the result. Specifically, we formulate garment transfer as a constrained optimization problem and solve it efficiently through iterative quadratic minimization. As demonstrated by our results, our method is able to automatically generate design-preserving versions of existing garments for target characters whose proportions and body shape significantly differ from those of the source. The method correctly handles the transfer of multiple layers of garment. Lastly, when source 2D patterns are available, we output graded patterns suitable for manufacturing the transferred garments. Our fully automatic design-preserving transfer method leads to significant time savings for both computer artists and fashion designers.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"UNLABELLED\\nAnnotating genetic variants, especially non-coding variants, for the purpose of identifying pathogenic variants remains a challenge. Combined annotation-dependent depletion (CADD) is an algorithm designed to annotate both coding and non-coding variants, and has been shown to outperform other annotation algorithms. CADD trains a linear kernel support vector machine (SVM) to differentiate evolutionarily derived, likely benign, alleles from simulated, likely deleterious, variants. However, SVMs cannot capture non-linear relationships among the features, which can limit performance. To address this issue, we have developed DANN. DANN uses the same feature set and training data as CADD to train a deep neural network (DNN). DNNs can capture non-linear relationships among features and are better suited than SVMs for problems with a large number of samples and features. We exploit Compute Unified Device Architecture-compatible graphics processing units and deep learning techniques such as dropout and momentum training to accelerate the DNN training. DANN achieves about a 19% relative reduction in the error rate and about a 14% relative increase in the area under the curve (AUC) metric over CADD's SVM methodology.\\n\\n\\nAVAILABILITY AND IMPLEMENTATION\\nAll data and source code are available at https://cbcl.ics.uci.edu/public_data/DANN/.\", 'positives': ['Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.'], 'negatives': ['Different from the traditional using method of one-input-one-output in planetary gear reducer, a concept of one-input-two-output is proposed to drive an underactuated finger. A finger consisting of three degrees of freedom, is driven by two actuators. MP joint is driven by one actuator while PIP and DIP joints are driven by another actuator with power distribution by a planetary gear reducer. When grasping the object, the finger may adapt to its shape automatically through self-motion tuning of the differentially underactuated mechanism. Additionally, when collision between the finger and external objects occurs in the gripping process, the mechanism can absorb the impact energy so as to protect the actuator. Kinematics and statics are analyzed to figure out the related motion relationship among each joint for the underactuated finger. Experiments are conducted to verify the desired characteristics of the finger and the related analysis.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We study the problem of decoding secret messages encrypted by the German Army with the M3 Enigma machine after September 15, 1938. We focused our attention on the algorithmization and programming of this problem. A completion and optimization of Zygalski’s sheets method were presented previously. We describe below the missing algorithm solving the problem of the plugboard settings with an algebraic justification. This method is the original idea of the authors, and we can use it for cryptanalysis together with both Zygalski’s sheets method and Rejewski’s bomb method. Next, we present a reconstruction of the cryptologic bomb. We enclose an implementation of both algorithms in Cpp language.', 'positives': ['Want to get experience? Want to get any ideas to create new things in your life? Read cryptography an introduction to computer security now! By reading this book as soon as possible, you can renew the situation to get the inspirations. Yeah, this way will lead you to always think more and more. In this case, this book will be always right for you. When you can observe more about the book, you will know why you need this.'], 'negatives': ['Training robust deep video representations has proven to be much more challenging than learning deep image representations. This is in part due to the enormous size of raw video streams and the high temporal redundancy; the true and interesting signal is often drowned in too much irrelevant data. Motivated by that the superfluous information can be reduced by up to two orders of magnitude by video compression (using H.264, HEVC, etc.), we propose to train a deep network directly on the compressed video. This representation has a higher information density, and we found the training to be easier. In addition, the signals in a compressed video provide free, albeit noisy, motion information. We propose novel techniques to use them effectively. Our approach is about 4.6 times faster than Res3D and 2.7 times faster than ResNet-152. On the task of action recognition, our approach outperforms all the other methods on the UCF-101, HMDB-51, and Charades dataset.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Explosive oral cavity injuries make restoring optimal oral function a challenge. An explosion in the oral cavity can cause burns and concomitant smoke inhalation injury to the upper airway.We present the case of a patient in whom the middle and lower thirds of the face were destroyed when a firecracker exploded in his oral cavity. Gunpowder tattooing caused by the explosion was present on the retropharyngeal space. He had an open fracture of the mandibular symphysis and inhalation burns of the upper airway were suspected. Tracheostomy was performed because we could not rule out inhalation burns of the upper airway. After close observation, his cardiopulmonary function and vital signs were stable, and we prepared him for reconstructive surgery.', 'positives': ['Firecracker display is used worldwide for celebrating religious festivities, New Year celebrations and various other occasions. Explosion during the manufacture of firecrackers can result in serious injuries. We, herein, report a case, where a person succumbed to injuries sustained in an explosion in a firecracker factory. Superficial to deep burns, traumatic amputation of right upper limb, and multiple abrasions and lacerations were present on various parts of the body with contusion of internal thoracic and abdominal organs. Also, multiple punctured circumscribed wounds with burnt floor and margins were present over the body.'], 'negatives': ['Fireworks are used worldwide to celebrate popular events (e.g. festivals, official celebrations, weddings). The festival of lights (Diwali) is celebrated with fireworks in India. During this period, many patients from all age groups present to hospital with injuries due to fireworks. Prevalence, period of occurrence, sex and age variation, adult supervision, causative fireworks, mode of lighting, age groups prone to injury, patterns of injury caused by individual fireworks, and the body parts injured were studied. One hundred and fifty-seven cases (92 retrospective, 65 prospective) with injury due to fireworks presenting to the Department of Plastic Surgery at KEM Hospital between 1997 and 2006 were studied. The prevalence of injuries has decreased steadily over the last 10 years (41 cases in 1997, 3 cases in 2006). The maximum number of injuries (35%) was seen in the age group 5-14 years; 92% of these children were unsupervised. The commonest cause of injury was firework misuse (41% of cases), followed by device failure (35%). Device failure was commonest with flares/fountains (ground firework emitting sparks upwards) and aerial devices. Flare/fountains caused most injury (39%), sparklers the least (0.6%). Flare/fountains, ground spinners, sparklers, and gunpowder (explosive material from cracker, obtained by tearing paper wrapper and obtaining chemicals) caused only soft tissue burns; stringbombs (high-intensity fire cracker made by wrapping chemicals with jute strings/coir in layers) and rockets (aerial device that zooms upwards and bursts) caused blast injuries, leading to soft tissue disruption and bony injuries. Emergency surgery was done if indicated: tendon and/or neurovascular repair, fracture fixation, flap cover or amputation. Superficial burns were treated with dressings. Certain wounds needed only thorough cleansing of the wound and primary suturing. We concluded that, over a 10-year period, the prevalence of firework injury decreased due to increased awareness in the community. Aggressive awareness campaigns by government and non-government organisations was the cause. We can minimise the number and severity of accidents by raising awareness regarding safety precautions, encouraging professional displays and motivating manufacturers to adhere to strict quality control.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'For the “take baking pan\" action our model give more weight to the static back camera when the subject walks to the cabinet. After opening the cabinet door, egocentric camera becomes more important, followed by putting more weights on the side camera, when the subject is about to put the pan on the counter top. Approach Avg. Acc. Avg. per Class Acc. Our Method 54.62 45.95 No Viterbi Smoothing (*) 41.80 44.05 Binary α 52.00 41.55 No Cam Combination 47.93 42.45 Binary α, No Cam Combination 44.58 35.01 Per Action α 48.83 45.89 No α 43.55 39.81 Equal α 48.75 45.66 Latent Dynamic CRF 41.55 33.57 Hidden Unit CRF 24.13 26.22 Feature Level Merge 35.04 36.97 Egocentric Camera 37.92 32.93 Static Back Camera 22.07 31.46 Static Side Camera 21.26 24.43 Static Top Camera 20.86 21.84', 'positives': ['This paper presents a method for the detection and recognition of social interactions in a day-long first-person video of u social event, like a trip to an amusement park. The location and orientation of faces are estimated and used to compute the line of sight for each face. The context provided by all the faces in a frame is used to convert the lines of sight into locations in space to which individuals attend. Further, individuals are assigned roles based on their patterns of attention. The rotes and locations of individuals are analyzed over time to detect and recognize the types of social interactions. In addition to patterns of face locations and attention, the head movements of the first-person can provide additional useful cues as to their attentional focus. We demonstrate encouraging results on detection and recognition of social interactions in first-person videos captured from multiple days of experience in amusement parks.'], 'negatives': ['Detecting objects in cluttered scenes and estimating articulated human body parts are two challenging problems in computer vision. The difficulty is particularly pronounced in activities involving human-object interactions (e.g. playing tennis), where the relevant object tends to be small or only partially visible, and the human body parts are often self-occluded. We observe, however, that objects and human poses can serve as mutual context to each other – recognizing one facilitates the recognition of the other. In this paper we propose a new random field model to encode the mutual context of objects and human poses in human-object interaction activities. We then cast the model learning task as a structure learning problem, of which the structural connectivity between the object, the overall human pose, and different body parts are estimated through a structure search approach, and the parameters of the model are estimated by a new max-margin algorithm. On a sports data set of six classes of human-object interactions [12], we show that our mutual context model significantly outperforms state-of-the-art in detecting very difficult objects and human poses.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Significant events are characterized by interactions between entities (such as countries, organizations, or individuals) that deviate from typical interaction patterns. Analysts, including historians, political scientists, and journalists, commonly read large quantities of text to construct an accurate picture of when and where an event happened, who was involved, and in what ways. In this paper, we present the Capsule model for analyzing documents to detect and characterize events of potential significance. Specifically, we develop a model based on topic modeling that distinguishes between topics that describe “business as usual” and topics that deviate from these patterns. To demonstrate this model, we analyze a corpus of over two million U.S. State Department cables from the 1970s. We provide an open-source implementation of an inference algorithm for the model and a pipeline for exploring its results.', 'positives': [\"We propose a generative model for text and other collections of discrete data that generalizes or improves on several previous models including naive Bayes/unigram, mixture of unigrams [6], and Hofmann's aspect model , also known as probabilistic latent semantic indexing (pLSI) [3]. In the context of text modeling, our model posits that each document is generated as a mixture of topics, where the continuous-valued mixture proportions are distributed as a latent Dirichlet random variable. Inference and learning are carried out efficiently via variational algorithms. We present empirical results on applications of this model to problems in text modeling, collaborative filtering, and text classification.\"], 'negatives': ['In this paper we have focused on the carbon nano tube field effect transistor technology. The advantages of CNTFET over MOS technology are also discussed. The structure and types of CNTFET are given in detail along with the variation of threshold voltage with respect to the alteration in CNT diameter. The characteristics curve between gate to source current and drain to source voltage is plotted. Various fixed and variable parameters of CNT are also focused.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper presents a systematic and optimal design of hybrid cascode compensation method which is used in fully differential two-stage CMOS operational transconductance amplifiers (OTAs). The closed loop analysis results are given to obtain a design procedure. A simple design procedure for the minimum settling time of the hybrid cascode compensation technique for a two-stage class A/AB amplifier is proposed. Optimal design issues of power dissipation are considered to achieve the lowest power consumption for the required settling time. Finally, a design example is presented to show both the usefulness of the hybrid cascode compensation and the proposed design procedure. The proposed design technique can help circuit designers as well as it can be used in computer aided circuit design tools', 'positives': ['This paper presents the analysis of hybrid cascode compensation scheme, merged Ahuja and improved Ahuja style compensation methods, which is used in two-stage CMOS operational transconductance amplifiers (OTAs). The open loop signal transfer function is derived to allow the accurate estimation of the poles and zeros. This analytical approach shows that the non-dominant poles and zeros of the hybrid cascode compensation are about 40 percent greater than those of the conventional cascode compensation. Circuit level simulation results are provided to show the accuracy of the calculated expressions and also the usefulness of the proposed cascode compensation technique. key words: operational transconductance amplifiers, cascode compensation, switched-capacitor circuits'], 'negatives': ['ile acids (BAs) are amphipathic cholesterol derivaBtives that are produced in the liver and stored in the gallbladder. Because of their physical detergent properties, BAs facilitate postprandial emulsification and absorption of lipids in the intestine. A fine tuning of the BA pool size is essential because cholestasis, or excessive BAs in plasma and liver, is toxic for the organism. Homeostasis of the BA pool, or the so-called entero-hepatic cycle of BAs is maintained by the balance of hepatic BA synthesis, controlled by the rate-limiting enzyme CYP7A1/Cyp7a1, and ileal BA reabsorption, mediated by the apical sodiumdependent BA transporter ASBT/Slc10a2 (Figure 1). More recently, BAs were found to act as endogenous receptor ligands, exerting not only a negative feedback control on their own synthesis, but also controlling energy and metabolic homeostasis through activation of the nuclear receptor (NR) FXR/Nr1h4 and the membrane G-protein–coupled receptor TGR5. FXR is pivotal in control of the enterohepatic cycle under physiologic conditions, because it represses hepatic BA synthesis, stimulates BA export into the gallbladder, and represses ileal Slc10a2 expression. In addition to FXR, multiple other transcription factors participate directly or indirectly in BA homeostasis, including several NRs (REV-ERBa, VDR, PXR, CAR, HNF4) and HNF3b/ FOXA2 in the liver or GATA4 in the intestine. Importantly, the homeodomain transcription factor HNF1a induces Nr1h4 expression in the liver and is a critical regulator of liver BA homeostasis. These intestinal and hepatic transcriptional networks function in a concerted manner, because ileal FXR controls the expression of circulating FGF15/19, which in turn represses hepatic Cyp7a1 expression in a FGFR4dependent manner. Accordingly, intestinal FXR-deficiency in the mouse increases the BA pool size, although this phenotypic feature is observed only during the active dark phase owing to the circadian regulation of Cyp7a1 by the intestinal FXR-FGF15 axis. In contrast, constitutive activation of intestinal FXR results in a reduction of the BA pool size. Transcriptional co-modulators also play significant roles in BA homeostasis. Kazgan et al now add an important and novel component in the control of this complex and intertwined hepatic and intestinal transcriptional network by showing that the class III histone/protein deacetylase SIRT1 plays a critical role in regulating intestinal HNF1a and FXR activity. Activated by a low cellular energy status characterized by increased NADþ concentrations, SIRT1 induces catabolic reactions to maintain cellular energy homeostasis and plays a global protective role against metabolic insults. Acting on a broad array of substrates (>80), SIRT1 may impact hepatic BA metabolism through several mechanisms whose relative contributions are not fully characterized. SIRT1 has been shown to (a) favor a repressive effect of SHP on LRH1 activation of Cyp7a1 expression, (b) regulate liver FXR acetylation levels, thereby inhibiting its transcriptional activity, (c) regulate histone acetylation levels of hepatic FXR target genes, thereby activating their expression, and (d) enhance HNF1a-mediated expression of liver FXR. Furthermore, hepatic FXR may itself positively affect liver SIRT1 levels by down-regulating levels of the inhibitory mir34a. In contrast, until now nothing was known about the role of intestinal SIRT1 in metabolic control. Using intestinal epithelial cell-specific SIRT1-deficient (iSirt1 KO) mice, Kazgan et al investigated the role of this protein deacetylase in intestinal physiology. Intestinal SIRT1 deficiency did not result in measurable alterations of intestinal morphology or permeability in mice fed a regular chow diet. However, plasma and hepatic BA concentrations dropped significantly in iSirt1 KO mice, and fecal BA excretion increased. Assessment of BA absorption using the everted gut sac model showed that intestinal apical BA uptake and basolateral export were compromised. Expression of FXR and its target genes, including Osta/Ostb and to a lesser nonsignificant extent Shp, Fgf15, Ibabp, and Slc10a2 were all decreased. Ex vivo chromatin immunoprecipitation analysis pointed to a decreased binding of HNF1a to the HNF1a-regulated Nr1h4 and Slc10a2 promoters, leading to a diminished occupancy of FXR gene response elements by FXR in the intestine. These results indicate the existence of a SIRT1-HNF1a-FXR gene expression cascade in intestinal epithelial cells, which controls systemic BA metabolism. HNF1a is involved in hepatic transcriptional networks regulating liver organogenesis and is sufficient, together with the forkhead transcription factor FOXA2, to promote mouse embryonic fibroblast differentiation into hepatic stem cells. HNF1a is also important for differentiation of pancreatic islet b-cells and mutations of HNF1a cause MODY3. HNF1a functions as a heterotetramer together with the bifunctional protein pterin 4a carbinolamine dehydratase 2, also known as dimerization cofactor of HNF1a (DCoH). The saddle-shaped DCoH dimerizes with the helical N-terminal dimerization domain of HNF1a. However, very little is known about the specific roles of HNF1a in the intestine, although whole-body Hnf1a deficiency results in intestinal epithelial disorders affecting enterocyte barrier functions, such as glucose transport, crypt cell proliferation, and disturbance of intestinal epithelial cell lineage functions during adult life. The study by Kazgan et al thus provides an unprecedented insight concerning the functions of SIRT1 in intestinal metabolism by showing that SIRT1 controls HNF1a DNA binding activity through deacetylation of DCoH2. Moreover, the acetylation status of DCoH2 was reversibly controlled by SIRT1 and the'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, we introduce McTorch, a manifold optimization library for deep learning that extends PyTorch. It aims to lower the barrier for users wishing to use manifold constraints in deep learning applications, i.e., when the parameters are constrained to lie on a manifold. Such constraints include the popular orthogonality and rank constraints, and have been recently used in a number of applications in deep learning. McTorch follows PyTorch’s architecture and decouples manifold definitions and optimizers, i.e., once a new manifold is added it can be used with any existing optimizer and vice-versa. McTorch is available at https://github.com/mctorch.', 'positives': ['We propose a novel geometric approach for learning bilingual mappings given monolingual embeddings and a bilingual dictionary. Our approach decouples the source-to-target language transformation into (a) languagespecific rotations on the original embeddings to align them in a common, latent space, and (b) a language-independent similarity metric in this common space to better model the similarity between the embeddings. Overall, we pose the bilingual mapping problem as a classification problem on smooth Riemannian manifolds. Empirically, our approach outperforms previous approaches on the bilingual lexicon induction and cross-lingual word similarity tasks. We next generalize our framework to represent multiple languages in a common latent space. Language-specific rotations for all the languages and a common similarity metric in the latent space are learned jointly from bilingual dictionaries for multiple language pairs. We illustrate the effectiveness of joint learning for multiple languages in an indirect word translation setting.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In psychological measurements, two levels should be distinguished: the individual level, relative to the different participants in a given cognitive situation, and the collective level, relative to the overall statistics of their outcomes, which we propose to associate with a notion of collective participant. When the distinction between these two levels is properly formalized, it reveals why the modeling of the collective participant generally requires beyond-quantum – non-Bornian – probabilistic models, when sequential measurements at the individual level are considered, and this though a pure quantum description remains valid for single measurement situations.', 'positives': ['We elaborate a theory for the modeling of concepts using the mathematical structure of quantum mechanics. Items and concepts are represented by vectors in the complex Hilbert space of quantum mechanics and membership weights of items are modeled by quantum weights calculated following the quantum rules. We apply this theory to model the disjunction of concepts and show that the predictions of our theory for the membership weights of items with respect to the disjunction of concepts match with great accuracy the results of an experiment conducted by Hampton (1988b). It is the quantum effects of interference and superposition that are at the origin of the effects of overextension and underextension observed by Hampton as deviations from a classical use of the disjunction. We show that the complex numbers of the Hilbert space are essential to obtaining the experimental predictions, i.e. vector space models over real numbers do not provide predictions matching the experimental data. We put forward an explanation of the effects of overextension and underextension by interpreting the quantum model applied to the modeling of the disjunction of concepts.'], 'negatives': ['Recurrent Neural Networks (RNNs) with attention mechanisms have obtained state-of-the-art results for many sequence processing tasks. Most of these models use a simple form of encoder with attention that looks over the entire sequence and assigns a weight to each token independently. We present a mechanism for focusing RNN encoders for sequence modelling tasks which allows them to attend to key parts of the input as needed. We formulate this using a multilayer conditional sequence encoder that reads in one token at a time and makes a discrete decision on whether the token is relevant to the context or question being asked. The discrete gating mechanism takes in the context embedding and the current hidden state as inputs and controls information flow into the layer above. We train it using policy gradient methods. We evaluate this method on several types of tasks with different attributes. First, we evaluate the method on synthetic tasks which allow us to evaluate the model for its generalization ability and probe the behavior of the gates in more controlled settings. We then evaluate this approach on large scale Question Answering tasks including the challenging MS MARCO and SearchQA tasks. Our models shows consistent improvements for both tasks over prior work and our baselines. It has also shown to generalize significantly better on synthetic tasks as compared to the baselines. Montreal Institute for Learning Algorithms, Montreal, Canada Polytechnique Montreal Microsoft Research, Montreal Jagiellonian University, Cracow, Poland AdeptMind Scholar University of Montreal Senior Cifar Member McGill University Facebook AI Research, Montreal HEC Montreal. Correspondence to: Nan Rosemary Ke <rosemary.nan.ke@gmail.com>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Binary Neural Networks (BNNs), whose weights and activations can be represented by a single bit, are gaining more and more attention. Because their inference speed and memory consumption are far superior to full-precision neural networks. However, the previous work on BNNs often leads to severe accuracy degradation. To address this issue, we propose a novel BNN model named Binary Densely Connected Network (BDCN), which connects each mlpconv (a multilayer perceptron to extract better features) layer to all preceding mlpconv layers. Such enhanced dense connection can strengthen the representation capabilities of BNN, which is beneficial to improve the accuracy of the network. This work further narrows the accuracy gap between BNNs and their full-precision counterpart. We evaluate our BDCN on a range of visual datasets (MNIST, CIFAR-10 and ImageNet) and find that our method outperforms other state-of-art binary networks whilst keeping the model size acceptable.', 'positives': ['The problem of arbitrary object tracking has traditionally been tackled by learning a model of the object’s appearance exclusively online, using as sole training data the video itself. Despite the success of these methods, their online-only approach inherently limits the richness of the model they can learn. Recently, several attempts have been made to exploit the expressive power of deep convolutional networks. However, when the object to track is not known beforehand, it is necessary to perform Stochastic Gradient Descent online to adapt the weights of the network, severely compromising the speed of the system. In this paper we equip a basic tracking algorithm with a novel fully-convolutional Siamese network trained end-to-end on the ILSVRC15 dataset for object detection in video. Our tracker operates at frame-rates beyond real-time and, despite its extreme simplicity, achieves state-of-the-art performance in multiple benchmarks.'], 'negatives': ['In order to foster sustainable management of food waste, innovations in food waste valorization technologies are crucial. Black soldier fly (BSF) bioconversion is an emerging technology that can turn food waste into high-protein fish feed through the use of BSF larvae. The conventional method of BSF bioconversion is to feed BSF larvae with food waste directly without any moisture adjustment. However, it was reported that difficulty has been experienced in the separation of the residue (larval excreta and undigested material) from the insect biomass due to excessive moisture. In addition to the residue separation problem, the moisture content of the food waste may also affect the growth and survival aspects of BSF larvae. This study aims to determine the most suitable moisture content of food waste that can improve residue separation as well as evaluate the effects of the moisture content of food waste on larval growth and survival. In this study, pre-consumer and post-consumer food waste with different moisture content (70%, 75% and 80%) was fed to BSF larvae in a temperature-controlled rotary drum reactor. The results show that the residue can be effectively separated from the insect biomass by sieving using a 2.36mm sieve, for both types of food waste at 70% and 75% moisture content. However, sieving of the residue was not feasible for food waste at 80% moisture content. On the other hand, reduced moisture content of food waste was found to slow down larval growth. Hence, there is a trade-off between the sieving efficiency of the residue and the larval growth rate. Furthermore, the larval survival rate was not affected by the moisture content of food waste. A high larval survival rate of at least 95% was achieved using a temperature-controlled rotary drum reactor for all treatment groups. The study provides valuable insights for the waste management industry on understanding the effects of moisture content when employing BSF bioconversion for food waste recycling.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'With the rapid growth of internet finance, the credit assessing is becoming more and more important. An effective classification model will help financial institutions gain more profits and reduce the loss of bad debts. In this paper, we propose a new Support Vector Machine (SVM) based ensemble model (SVM-BRS) to address the issue of credit analysis. The model combines random subspace strategy and boosting strategy, which encourages diversity. SVM is considered as a state-of-art model to solve classification problem. Therefore, the proposed model has the potential to generate more accuracy classification. Accordingly, this study compares the ANN, LR, SVM, Bagging SVM, Boosting SVM techniques and experience shows that the new SVM based ensemble model can be used as an alternative method for credit assessing.', 'positives': ['Credit scoring models have been widely studied in the areas of statistics, machine learning, and artificial intelligence (AI). Many novel approaches such as artificial neural networks (ANNs), rough sets, or decision trees have been proposed to increase the accuracy of credit scoring models. Since an improvement in accuracy of a fraction of a percent might translate into significant savings, a more sophisticated model should be proposed to significantly improving the accuracy of the credit scoring mode. In this paper, genetic programming (GP) is used to build credit scoring models. Two numerical examples will be employed here to compare the error rate to other credit scoring models including the ANN, decision trees, rough sets, and logistic regression. On the basis of the results, we can conclude that GP can provide better performance than other models. q 2005 Elsevier Ltd. All rights reserved.'], 'negatives': ['INTRODUCTION Myasthenia Gravis (MG), a slowly progressive neuromuscular disorder, can be classified as either ocular or generalised. MG affects between 5 – 12 people per 100,000 (Muscular Dystrophy Association, 2004).Ocular involvement is often the fi rst sign of MG with patients complaining of ptosis and diplopia. Seventy-fi ve to ninety percent of patients with ocular involvement then progress to having generalised MG (Kernich and Kaminski 1995; Evoli et al., 1996). Muscle weakness and fatigue are signifi cant problems for patients, with proximal muscles frequently more affected than distal muscles (Walton, 1989). The specifi c role of exercise prescription in the management of MG has not yet been established; however some research has been conducted into the effects of exercise prescription in other slowly progressive neuromuscular disorders (NMD) having similar symptomatology. These conditions include myotonic muscular dystrophy, limb-girdle syndrome and fascioscapulohumeral dystrophy, and other conditions where fatigue is an important or primary symptom, such as multiple sclerosis and chronic fatigue syndrome (Aitkens et al., 1993; Petajan et al., 1996; Wright et al., 1996; Fulcher and White, 1997; Whiting et al., 2001). This case report discusses exercise prescription for people with MG and the implementation and outcome of a specifi c exercise programme prescribed to a patient with MG. Leona Davidson*, BPhty, MCSP Leigh Hale, PhD, MSc (Physiotherapy), BSc (Physiotherapy), Lecturer, School of Physiotherapy, University of Otago'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': '................................................................................................................................................. 4 Introduction ............................................................................................................................................ 5 Objective and research questions .................................................................................................. 5 Theory and definitions .......................................................................................................................... 6 Physical environment ....................................................................................................................... 6 Teaching, learning, and education ................................................................................................. 6 Methodology .......................................................................................................................................... 7 Data collection ................................................................................................................................... 7 Data analysis ..................................................................................................................................... 8 Ethical considerations .................................................................................................................... 10 Results .................................................................................................................................................. 10 The roles of the physical environment ......................................................................................... 10 Teachers’ conceptions of the physical environment ................................................................. 11 Teachers’ stated preferences for the physical environment .................................................... 12 Summary .......................................................................................................................................... 12 Discussion ............................................................................................................................................ 13 The proposed methodology .......................................................................................................... 13 Implications ...................................................................................................................................... 14 Limitations ........................................................................................................................................ 14 References .......................................................................................................................................... 15', 'positives': ['Gewährt wird ein nicht exklusives, nicht übertragbares, persönliches und beschränktes Recht auf Nutzung dieses Dokuments. Dieses Dokument ist ausschließlich für den persönlichen, nicht-kommerziellen Gebrauch bestimmt. Die Nutzung stellt keine Übertragung des Eigentumsrechts an diesem Dokument dar und gilt vorbehaltlich der folgenden Einschränkungen: Auf sämtlichen Kopien dieses Dokuments müssen alle Urheberrechtshinweise und sonstigen Hinweise auf gesetzlichen Schutz beibehalten werden. Sie dürfen dieses Dokument nicht in irgendeiner Weise abändern, noch dürfen Sie dieses Dokument für öffentliche oder kommerzielle Zwecke vervielfältigen, öffentlich ausstellen, aufführen, vertreiben oder anderweitig nutzen.'], 'negatives': [\"AIMS\\nTo investigate the presence of methicillin-resistant Staphylococcus aureus (MRSA) in untreated hospital wastewaters (UHWW), their transmission into the receiving sewage treatment plant (STP) and survival through the STP treatment.\\n\\n\\nMETHODS AND RESULTS\\nOver eight consecutive weeks of sampling, we isolated 224 Staph. aureus strains from UHWW-1, UHWW-2 and its receiving STP inlet (SI) and post-treatment outlet (SO). These strains were typed using the PhP typing method and RAPD-PCR and tested for their antibiotic resistance patterns. Resistance to cefoxitin and the presence of mecA gene identified MRSA isolates. In all, 11 common (C) and 156 single (S) PhP-RAPD types were found among isolates, with two multidrug resistant (MDR) C-types found in H2, SI and SO. These C-type strains also showed resistance to cefoxitin and vancomycin. The mean number of antibiotics to which the strains from UHWW were resistant (5.14 ± 2) was significantly higher than the STP isolates (2.9 ± 1.9) (P < 0.0001). Among the 131 (68%) MRSA strains, 24 were also vancomycin resistant. MDR strains (including MRSA) were more prevalent in hospital wastewaters than in the STP.\\n\\n\\nCONCLUSION\\nThis study provides evidence of the survival of MRSA strains in UHWWs and their transit to the STP and then through to the final treated effluent and chlorination stage.\\n\\n\\nSIGNIFICANCE AND IMPACT OF THE STUDY\\nThis preliminary study identifies the need to further investigate the load of MRSA in hospitals' wastewaters and possible their survival in STPs. From a public health point of view, this potential route of hospital MRSA dissemination is of great importance.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Tables are an easy way to represent information in a structural form. Table recognition is important for the extraction of such information from document images. Usually, modern OCR systems provide textual information coming from tables without recognizing actual table structure. However, recognition of table structure is important to get the contextual meaning of the contents. Table structure recognition in heterogeneous documents is challenging due to a variety of table layouts. It becomes harder where no physical rulings are present in a table. This work proposes a novel learning based methodology for the recognition of table contents in heterogeneous document images. Textual contents of documents are classified as table or non-table elements using a pre-trained neural network model. The output of the neural network is further enhanced by applying a contextual post processing on each element to correct the classifications errors if any. The system is trained using a subset of UNLV and UW3 document images and depicted more than 97% accuracy on a test set in detection of table and non-table elements.', 'positives': ['Detecting tables in document images is important since not only do tables contain important information, but also most of the layout analysis methods fail in the presence of tables in the document image. Existing approaches for table detection mainly focus on detecting tables in single columns of text and do not work reliably on documents with varying layouts. This paper presents a practical algorithm for table detection that works with a high accuracy on documents with varying layouts (company reports, newspaper articles, magazine pages, ...). An open source implementation of the algorithm is provided as part of the Tesseract OCR engine. Evaluation of the algorithm on document images from publicly available UNLV dataset shows competitive performance in comparison to the table detection module of a commercial OCR system.'], 'negatives': ['This paper presents an efficient approach to identify tabular structures within either electronic or paper documents. The resulting T—Recs system takes word bounding box information as input, and outputs the corresponding logical text block units (e.g. the cells within a table environment). Starting with an arbitrary word as block seed the algorithm recursively expands this block to all words that interleave with their vertical (north and south) neighbors. Since even smallest gaps of table columns prevent their words from mutual interleaving, this initial segmentation is able to identify and isolate such columns. In order to deal with some inherent segmentation errors caused by isolated lines (e.g. headers), overhanging words, or cells spawning more than one column, a series of postprocessing steps is added. These steps benefit from a very simple distinction between type 1 and type 2 blocks: type 1 blocks are those of at most one word per line, all others are of type 2. This distinction allows the selective application of heuristics to each group of blocks. The conjoint decomposition of column blocks into subsets of table cells leads to the final block segmentation of a homogeneous abstraction level. These segments serve the final layout analysis which identifies table environments and cells that are stretching over several rows and/or columns.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Exposure bracketing for high dynamic range (HDR) imaging involves capturing several images of the scene at different exposures. If either the camera or the scene moves during capture, the captured images must be registered. Large exposure differences between bracketed images lead to inaccurate registration, resulting in artifacts such as ghosting (multiple copies of scene objects) and blur. We present two techniques, one for image capture (Fibonacci exposure bracketing) and one for image registration (generalized registration), to prevent such motion-related artifacts. Fibonacci bracketing involves capturing a sequence of images such that each exposure time is the sum of the previous N(N > 1) exposures. Generalized registration involves estimating motion between sums of contiguous sets of frames, instead of between individual frames. Together, the two techniques ensure that motion is always estimated between frames of the same total exposure time. This results in HDR images and videos which have both a large dynamic range and minimal motion-related artifacts. We show, by results for several real-world indoor and outdoor scenes, that the proposed approach significantly outperforms several existing bracketing schemes.', 'positives': ['While real scenes produce a wide range of brightness variations, vision systems use low dynamic range image detectors that typically provide 8 bits of brightness data at each pixel. The resulting low quality images greatly limit what vision can accomplish today. This paper proposes a very simple method for significantly enhancing the dynamic range of virtually any imaging system. The basic principle is to simultaneously sample the spatial and exposure dimensions of image irradiance. One of several ways to achieve this is by placing an optical mask adjacent to a conventional image detector array. The mask has a pattern with spatially varying transmittance, thereby giving adjacent pixels on the detector different exposures to the scene. The captured image is mapped to a high dynamic range image using an efficient image reconstruction algorithm. The end result is an imaging system that can measure a very wide range of scene radiances and produce a substantially larger number of brightness levels, with a slight reduction in spatial resolution. We conclude with several examples of high dynamic range images computed using spatially varying pixel exposures. 1 High Dynamic Range Imaging Any real-world scene has a significant amount of brightness variation within it. The human eye has a remarkable dynamic range that enables it to detect subtle contrast variations and interpret scenes under a large variety of illumination conditions [Blackwell, 1946]. In contrast, a typical video camera, or a digital still camera, provides only about 8 bits (256 levels) of brightness information at each pixel. As a result, virtually any image captured by a conventional imaging system ends up being too dark in some areas and possibly saturated in others. In computational vision, it is such low quality images that we are left with the task of interpreting. Clearly, the low dynamic range of existing image detectors poses a severe limitation on what computational vision can accomplish. This paper presents a very simple modification that can be made to any conventional imaging system to dramatically increases its dynamic range. The availability of extra bits of data at each image pixel is expected to enhance the robustness of vision algorithms. This work was supported in part by an ONR/DARPA MURI grant under ONR contract No. N00014-97-1-0553 and in part by a David and Lucile Packard Fellowship. Tomoo Mitsunaga is supported by the Sony Corporation. 2 Existing Approaches First, we begin with a brief summary of existing techniques for capturing a high dynamic range image with a low dynamic range image detector. 2.1 Sequential Exposure Change The most obvious approach is to sequentially capture multiple images of the same scene using different exposures. The exposure for each image is controlled by either varying the F-number of the imaging optics or the exposure time of the image detector. Clearly, a high exposure image will be saturated in the bright scene areas but capture the dark regions well. In contrast, a low exposure image will have less saturation in bright regions but end up being too dark and noisy in the dark areas. The complementary nature of these images allows one to combine them into a single high dynamic range image. Such an approach has been employed in [Azuma and Morimura, 1996], [Saito, 1995], [Konishi et al., 1995], [Morimura, 1993], [Ikeda, 1998], [Takahashi et al., 1997], [Burt and Kolczynski, 1993], [Madden, 1993] [Tsai, 1994]. In [Mann and Picard, 1995], [Debevec and Malik, 1997] and [Mitsunaga and Nayar, 1999] this approach has been taken one step further by using the acquired images to compute the radiometric response function of the imaging system. The above methods are of course suited only to static scenes; the imaging system, the scene objects and their radiances must remain constant during the sequential capture of images under different exposures. 2.2 Multiple Image Detectors The stationary scene restriction faced by sequential capture is remedied by using multiple imaging systems. This approach has been taken by several investigators [Doi et al., 1986], [Saito, 1995], [Saito, 1996], [Kimura, 1998], [Ikeda, 1998]. Beam splitters are used to generate multiple copies of the optical image of the scene. Each copy is detected by an image detector whose exposure is preset by using an optical attenuator or by changing the exposure time of the detector. This approach has the advantage of producing high dynamic range images in real time. Hence, the scene objects and the imaging system are free to move during the capture process. The disadvantage of course is that this approach is expensive as it requires multiple image detectors, precision optics for the alignment of all the acquired images and additional hardware for the capture and processing of multiple images. 1063-6919/00 $10.0'], 'negatives': ['Player goal recognition in digital games offers the promise of enabling games to dynamically customize player experience. Goal recognition aims to recognize players’ high-level intentions using a computational model trained on a player behavior corpus. A significant challenge is posed by devising reliable goal recognition models with a behavior corpus characterized by highly idiosyncratic player actions. In this paper, we introduce deep LSTM-based goal recognition models that handle the inherent uncertainty stemming from noisy, non-optimal player behaviors. Empirical evaluation indicates that deep LSTMs outperform competitive baselines including singlelayer LSTMs, n-gram encoded feedforward neural networks, and Markov logic networks for a goal recognition corpus collected from an open-world educational game. In addition to metric-based goal recognition model evaluation, we investigate a visualization technique to show a dynamic goal recognition model’s performance over the course of a player’s goalseeking behavior. Deep LSTMs, which are capable of both sequentially and hierarchically extracting salient features of player behaviors, show significant promise as a goal recognition approach for open-world digital games.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'According to politeness theory (P. Brown & S. Levinson, 1987), politeness serves to both reflect and regulate social distance. On the basis of this notion and on construal level theory (N. Liberman & Y. Trope, 2008; N. Liberman, Y. Trope, & E. Stephan, 2007), it was predicted that politeness would be related to abstract construal, temporal distance, and spatial distance. Eight studies supported this prediction. Politeness increased when the addressees were construed abstractly (Study 1), were temporally distant (Studies 2, 3), and were spatially distant (Study 4). It was also found that increasing politeness produced abstract construals (Study 5), greater temporal distance (Study 6), and greater spatial distance (Study 7, 8). These findings shed light on the way politeness operates in different cultures and is conveyed in different languages, and they support the idea that dimensions of psychological distance are interrelated.', 'positives': ['The authors propose that self-control involves making decisions and behaving in a manner consistent with high-level versus low-level construals of a situation. Activation of high-level construals (which capture global, superordinate, primary features of an event) should lead to greater self-control than activation of low-level construals (which capture local, subordinate, secondary features). In 6 experiments using 3 different techniques, the authors manipulated construal levels and assessed their effects on self-control and underlying psychological processes. High-level construals led to decreased preferences for immediate over delayed outcomes, greater physical endurance, stronger intentions to exert self-control, and less positive evaluations of temptations that undermine self-control. These results support a construal-level analysis of self-control.'], 'negatives': ['We characterize Participatory Design (PD) as a maturing area of research and as an evolving practice among design professionals. Although PD has been applied outside of technology design, here we focus on PD in relation to the introduction of computer-based systems at work. We discuss three main issues addressed by PD researchers; the politics of design; the nature of participation; and method, tools and techniques for participation. We also report on the conditions for the transfer of “PD results” to workers, user groups, and design professionals that have characterized PD over time and across geopolitical terrains. The topic of the sustainability of PD within an organizational context is also considered. The article concludes with a discussion of common issues explored within PD and CSCW and frames directions for a continuing dialogue between researchers and practitioners from the two fields. The article draws on a review of PD and CSCW literatures as well as on our own research and practical experiences.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Approximate computing explores opportunities that emerge when applications can tolerate error or inexactness. These applications, which range from multimedia processing to machine learning, operate on inherently noisy and imprecise data. We can trade-off some loss in output value integrity for improved processor performance and energy-efficiency. As memory accesses consume substantial latency and energy, we explore load value approximation, a micro architectural technique to learn value patterns and generate approximations for the data. The processor uses these approximate data values to continue executing without incurring the high cost of accessing memory, removing load instructions from the critical path. Load value approximation can also inhibit approximated loads from accessing memory, resulting in energy savings. On a range of PARSEC workloads, we observe up to 28.6% speedup (8.5% on average) and 44.1% energy savings (12.6% on average), while maintaining low output error. By exploiting the approximate nature of applications, we draw closer to the ideal latency and energy of accessing memory.', 'positives': [\"Traditional Network-on-Chips (NoCs) employ simple arbitration strategies, such as round-robin or oldest-first, to decide which packets should be prioritized in the network. This is counter-intuitive since different packets can have very different effects on system performance due to, e.g., different level of memory-level parallelism (MLP) of applications. Certain packets may be performance-critical because they cause the processor to stall, whereas others may be delayed for a number of cycles with no effect on application-level performance as their latencies are hidden by other outstanding packets'latencies. In this paper, we define slack as a key measure that characterizes the relative importance of a packet. Specifically, the slack of a packet is the number of cycles the packet can be delayed in the network with no effect on execution time. This paper proposes new router prioritization policies that exploit the available slack of interfering packets in order to accelerate performance-critical packets and thus improve overall system performance. When two packets interfere with each other in a router, the packet with the lower slack value is prioritized. We describe mechanisms to estimate slack, prevent starvation, and combine slack-based prioritization with other recently proposed application-aware prioritization mechanisms.\\n We evaluate slack-based prioritization policies on a 64-core CMP with an 8x8 mesh NoC using a suite of 35 diverse applications. For a representative set of case studies, our proposed policy increases average system throughput by 21.0% over the commonlyused round-robin policy. Averaged over 56 randomly-generated multiprogrammed workload mixes, the proposed policy improves system throughput by 10.3%, while also reducing application-level unfairness by 30.8%.\"], 'negatives': [\"SDN networks rely mainly on a set of software defined modules, running on generic hardware platforms, and managed by a central SDN controller. The tight coupling and lack of isolation between the controller and the underlying host limit the controller resilience against host-based attacks and failures. That controller is a single point of failure and a target for attackers. “Linux-containers” is a successful thin virtualization technique that enables encapsulated, host-isolated execution-environments for running applications. In this paper we present PAFR, a controller sandboxing mechanism based on Linux-containers. PAFR enables controller/host isolation, plug-and-play operation, failure-and-attack-resilient execution, and fast recovery. PAFR employs and manages live remote checkpointing and migration between different hosts to evade failures and attacks. Experiments and simulations show that the frequent employment of PAFR's live-migration minimizes the chance of successful attack/failure with limited to no impact on network performance.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We present a deep learning framework for probabilistic pixel-wise semantic segmentation, which we term Bayesian SegNet. Semantic segmentation is an important tool for visual scene understanding and a meaningful measure of uncertainty is essential for decision making. Our contribution is a practical system which is able to predict pixelwise class labels with a measure of model uncertainty using Bayesian deep learning. We achieve this by Monte Carlo sampling with dropout at test time to generate a posterior distribution of pixel class labels. In addition, we show that modelling uncertainty improves segmentation performance by 2-3% across a number of datasets and architectures such as SegNet, FCN, Dilation Network and DenseNet.', 'positives': ['We present an approach to interpret the major surfaces, objects, and support relations of an indoor scene from an RGBD image. Most existing work ignores physical interactions or is applied only to tidy rooms and hallways. Our goal is to parse typical, often messy, indoor scenes into floor, walls, supporting surfaces, and object regions, and to recover support relationships. One of our main interests is to better understand how 3D cues can best inform a structured 3D interpretation. We also contribute a novel integer programming formulation to infer physical support relations. We offer a new dataset of 1449 RGBD images, capturing 464 diverse indoor scenes, with detailed annotations. Our experiments demonstrate our ability to infer support relations in complex scenes and verify that our 3D scene cues and inferred support lead to better object segmentation.'], 'negatives': [\"We propose a “smart parking” system for an urban environment based on a dynamic resource allocation approach. The system assigns and reserves an optimal resource (parking space) for a user (driver) based on the user's objective function that combines proximity to destination with parking cost, while also ensuring that the overall parking capacity is efficiently utilized. Our approach solves a Mixed Integer Linear Program (MILP) problem at each decision point in a time-driven sequence. The solution of each MILP is an optimal allocation based on current state information and subject to random events such as new user requests or parking spaces becoming available. The allocation is updated at the next decision point ensuring that there is no resource reservation conflict, that no user is ever assigned a resource with higher than the current cost function value, and that a set of fairness constraints is satisfied. We add an event-driven mechanism to compensate for users with no assignment that are close to their destinations. Simulation results show that using this “smart parking” approach can achieve near-optimal resource utilization and significant improvement over uncontrolled parking processes or state-of-the-art guidance-based systems.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Software systems are often built upon third party libraries. Developers may replace an old library with a new library, for the consideration of functionality, performance, security, and so on. It is tedious to learn the often complex APIs in the new library from the scratch. Instead, developers may identify the suitable APIs in the old library, and then find counterparts of these APIs in the new library. However, there is typically no such cross-references for APIs in different libraries. Previous work on automatic API recommendation often recommends related APIs in the same library. In this paper, we propose to mine search results of Web search engines to recommend related APIs of different libraries. In particular, we use Web search engines to collect relevant Web search results of a given API in the old library, and then recommend API candidates in the new library that are frequently appeared in the Web search results. Preliminary results of generating related C# APIs for the APIs in JDK show the feasibility of our approach.', 'positives': ['Programmers commonly reuse existing frameworks or libraries to reduce software development efforts. One common problem in reusing the existing frameworks or libraries is that the programmers know what type of object that they need, but do not know how to get that object with a specific method sequence. To help programmers to address this issue, we have developed an approach that takes queries of the form \"Source object type → Destination object type\" as input, and suggests relevant method-invocation sequences that can serve as solutions that yield the destination object from the source object given in the query. Our approach interacts with a code search engine (CSE) to gather relevant code samples and performs static analysis over the gathered samples to extract required sequences. As code samples are collected on demand through CSE, our approach is not limited to queries of any specific set of frameworks or libraries. We have implemented our approach with a tool called PARSEWeb, and conducted four different evaluations to show that our approach is effective in addressing programmer\\'s queries. We also show that PARSEWeb performs better than existing related tools: Prospector and Strathcona'], 'negatives': ['Geographic information is defined as information li king locations on or near the Earth’s surface to p roperties of those locations. The technologies for handling such information include GPS, remote sensing, and geogr aphic information systems. Behind the technologies are a s t of fundamental, researchable issues whose study has been termed geographic information science. I review the se technologies under four headings: positioning, d ata acquisition, data dissemination, and analysis. Rece nt research has led to substantial advances in spec ific areas of GIScience. I outline five future scenarios that are ll technically feasible given current technology, and discuss the research advances that will be needed to make them a reality. In the conclusion I comment on the chang ing needs of education in geographic information systems and sci ence.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, we introduce a novel stylus capable of displaying two haptic effects to the user. The first effect is a tactile flow effect up and down along the pen, and the other is a rotation effect about the long axis of the pen. The flow effect is based on the haptic illusion of “apparent tactile motion”, while the rotation effect comes from the reaction torque created by an electric motor placed along the stylus shaft. The stylus is embedded with two vibration actuators at the ends, and a DC motor with a rotating balanced mass in the middle. We show that, it is possible to create flow and rotation effects on the stylus by driving the actuators on the stylus. Furthermore, we show that the timing and the actuation patterns of the vibration actuators and DC motor on the stylus significantly affect the discernibility of the synthesized perceptions; hence these parameters should be selected carefully. Two psychophysical experiments, each performed with 10 subjects, shed light on the discernability of the two haptic effects as a function of various actuation parameters. Our results show that, with carefully selected parameters, the subjects can successfully identify the flow of motion and the direction of rotation with high accuracies.', 'positives': [\"This article explores direct touch and manipulation techniques for surface computing environments using a specialized haptic force feedback stylus, called ImpAct, which can dynamically change its effective length and equipped with sensors to calculate its orientation in world coordinates. When a user pushes it against a touch screen, the physical stylus shrinks and a rendered projection of the stylus is drawn inside the screen, giving the illusion that it is submerged in the display device. Once the users can see the stylus immersed in the digital world below the screen, he or she can manipulate and interact with the virtual objects with active haptic sensations. In this article, ImpAct's functionality, design, and prototype applications are described in detail with relevance to the concept of direct touch, giving special attention to novel interaction scenarios and design challenges. Furthermore, a technical evaluation was done to study ImpAct's accuracy and controlability and the results presented. This article concludes by discussing ImpAct's current limitations and future perspectives as a direct touch and manipulation tool.\"], 'negatives': ['Human trafficking (HT) victims may present to emergency departments (ED) as patients, but are infrequently identified. To address this issue, we developed and piloted a training intervention for emergency providers on HT and how to identify and treat these patients. Included in the intervention participants were emergency medicine residents, ED attendings, ED nurses, and hospital social workers. Prior to the intervention, 4.8% felt some degree of confidence in their ability to identify and 7.7% to treat a trafficked patient. After the 20-minute intervention, 53.8% felt some degree of confidence in their ability to identify and 56.7% care for this patient population. Because this problem is global, we created a Website that includes an instructive toolkit and an interactive course for self-learning and/or assessment. This intervention will give ED providers the tools they need to assess and treat a patient who might be a victim of human trafficking.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Mobile cloud computing is a key enabling technology in the era of the Internet of Things. Geo-distributed mobile cloud computing (GMCC) is a new scenario that adds geography consideration in mobile cloud computing. In GMCC, users are able to access cloud resources that are geographically close to their mobile devices. This is expected to reduce the communication delay and the service providers’ cost compared with the traditional centralized approach. In this paper, we focus on resource sharing through the cooperation among the service providers in geo-distributed mobile cloud computing. Then, we propose two different strategies for efficient resource cooperation in geographically distributed data centers. Furthermore, we present a coalition game theoretical approach to deal with the competition and the cooperation among the service providers. Utility functions have been specifically considered to incorporate the cost related to virtual machine migration and resource utilization. Illustrative results indicate that our proposed schemes are able to efficiently utilize limited resources with quality-of-service consideration.', 'positives': ['The rapid growth in demand for computational power driven by modern service applications combined with the shift to the Cloud computing model have led to the establishment of large-scale virtualized data centers. Such data centers consume enormous amounts of electrical energy resulting in high operating costs and carbon dioxide emissions. Dynamic consolidation of virtual machines (VMs) using live migration and switching idle nodes to the sleep mode allow Cloud providers to optimize resource usage and reduce energy consumption. However, the obligation of providing high quality of service to customers leads to the necessity in dealing with the energy-performance trade-off, as aggressive consolidation may lead to performance degradation. Due to the variability of workloads experienced by modern applications, the VM placement should be optimized continuously in an online manner. To understand the implications of the online nature of the problem, we conduct competitive analysis and prove competitive ratios of optimal online deterministic algorithms for the single VM migration and dynamic VM consolidation problems. Furthermore, we propose novel adaptive heuristics for dynamic consolidation of VMs based on an analysis of historical data from the resource usage by VMs. The proposed algorithms significantly reduce energy consumption, while ensuring a high level of adherence to the Service Level Agreements (SLA). We validate the high efficiency of the proposed algorithms by extensive simulations using real-world workload traces from more than a thousand PlanetLab VMs. Copyright c © 2012 John Wiley & Sons, Ltd.'], 'negatives': ['The increase in speed and accuracy of computation methods and the advancement in sensor technologies has shifted the focus towards health monitoring systems of vehicles. Li-ion batteries which are used in electric vehicles, tend to get damaged and pose potential safety threats when ill-used. An adaptive control system called battery management system is needed to ensure the safety and life optimization of batteries in electric vehicles. This system takes care of both diagnosis and prognosis, giving the user an idea of current status as well as remaining lifetime of the battery. A novel algorithm based on dynamic resistance mapping is used to develop a data driven computational model for estimating the state of health of battery. A model with a correlation co-efficient of 99.45% is developed for state of health estimation to find the health of the battery during run time.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'A generative model with a disentangled representation allows for control over independent aspects of the output. Learning disentangled representations has been a recent topic of great interest, but it remains poorly understood. We show that even for GANs that do not possess disentangled representations, one can find curved trajectories in latent space over which local disentanglement occurs. These trajectories are found by iteratively following the leading right-singular vectors of the Jacobian of the generator with respect to its input. Based on this insight, we describe an efficient regularizer that aligns these vectors with the coordinate axes, and show that it can be used to induce disentangled representations in GANs, in a completely unsupervised manner.', 'positives': ['In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsuper-vised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolu-tional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks-demonstrating their applicability as general image representations .'], 'negatives': ['This paper reports a methodology of combining differential-phase-shift-injection-locking (DPSIL) with mode-coupled-delay-feedback (MCDF) techniques to shave the size, cost, and phase noise from Crystal oscillator circuits. An example of 100 MHz, 125 MHz and 155 MHz ovenized crystal oscillator (OCXO) is demonstrated for the validation of the novel approach, which holds good for both fundamental and higher order overtone mode high frequency crystal oscillator circuits.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, we develop a centralized spectrum sensing and Dynamic Spectrum Access (DSA) scheme for secondary users (SUs) in a Cognitive Radio (CR) network. Assuming that the primary channel occupancy follows a Markovian evolution, the channel sensing problem is modeled as a Partially Observable Markov Decision Process (POMDP). We assume that each SU can sense only one channel at a time by using energy detection, and the sensing outcomes are then reported to a central unit, called the secondary system decision center (SSDC), that determines the channel sensing/accessing policies. We derive both the optimal channel assignment policy for secondary users to sense the primary channels, and the optimal channel access rule. Our proposed optimal sensing and accessing policies alleviate many shortcomings and limitations of existing proposals: (a) ours allows fully utilizing all available primary spectrum white spaces, (b) our model, and thus the proposed solution, exploits the temporal and spatial diversity across different primary channels, and (c) is based on realistic local sensing decisions rather than complete knowledge of primary signalling structure. As an alternative to the high complexity of the optimal channel sensing policy, a suboptimal sensing policy is obtained by using the Hungarian algorithm iteratively, which reduces the complexity of the channel assignment from an exponential to a polynomial order. We also propose a heuristic algorithm that reduces the complexity of the sensing policy further to a linear order. The simulation results show that the proposed algorithms achieve a near-optimal performance with a significant reduction in computational time.', 'positives': [], 'negatives': ['A 2/spl times/40W (into 4/spl Omega/ with a 20V supply) integrated stereo /spl Delta//spl Sigma/ class D amplifier with 100dB SNR is realized in a 0.6 /spl mu/m CMOS process with DMOS transistors and buried Zener diodes. Feedback from power stage outputs gives 0.001% THD and 65dB PSRR. The modulator clock rate is 6MHz, but dynamically adjusted quantizer hysteresis reduces the output data rate to 450kHz, helping achieve 88% efficiency.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'ÐStochastic discrimination is a general methodology for constructing classifiers appropriate for pattern recognition. It is based on combining arbitrary numbers of very weak components, which are usually generated by some pseudorandom process, and it has the property that the very complex and accurate classifiers produced in this way retain the ability, characteristic of their weak component pieces, to generalize to new data. In fact, it is often observed, in practice, that classifier performance on test sets continues to rise as more weak components are added, even after performance on training sets seems to have reached a maximum. This is predicted by the underlying theory, for even though the formal error rate on the training set may have reached a minimum, more sophisticated measures intrinsic to this method indicate that classifier performance on both training and test sets continues to improve as complexity increases. In this paper, we begin with a review of the method of stochastic discrimination as applied to pattern recognition. Through a progression of examples keyed to various theoretical issues, we discuss considerations involved with its algorithmic implementation. We then take such an algorithmic implementation and compare its performance, on a large set of standardized pattern recognition problems from the University of California Irvine, and Statlog collections, to many other techniques reported on in the literature, including boosting and bagging. In doing these studies, we compare our results to those reported in the literature by the various authors for the other methods, using the same data and study paradigms used by them. Included in this paper is an outline of the underlying mathematical theory of stochastic discrimination and a remark concerning boosting, which provides a theoretical justification for properties of that method observed in practice, including its ability to generalize. Index TermsÐPattern recognition, classification algorithms, stochastic discrimination, SD.', 'positives': [], 'negatives': ['In deep learning, performance is strongly affected by the choice of architecture and hyperparameters. While there has been extensive work on automatic hyperparameter optimization for simple spaces, complex spaces such as the space of deep architectures remain largely unexplored. As a result, the choice of architecture is done manually by the human expert through a slow trial and error process guided mainly by intuition. In this paper we describe a framework for automatically designing and training deep models. We propose an extensible and modular language that allows the human expert to compactly represent complex search spaces over architectures and their hyperparameters. The resulting search spaces are tree-structured and therefore easy to traverse. Models can be automatically compiled to computational graphs once values for all hyperparameters have been chosen. We can leverage the structure of the search space to introduce different model search algorithms, such as random search, Monte Carlo tree search (MCTS), and sequential model-based optimization (SMBO). We present experiments comparing the different algorithms on CIFAR-10 and show that MCTS and SMBO outperform random search. In addition, these experiments show that our framework can be used effectively for model discovery, as it is possible to describe expressive search spaces and discover competitive models without much effort from the human expert. Code for our framework and experiments has been made publicly available.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Touchless interaction with medical images lets surgeons maintain sterility during surgical procedures.', 'positives': [\"Body posture and finger pointing are a natural modality for human-machine interaction, but first the system must know what it's seeing.\"], 'negatives': ['We performed a study to determine the influence that site quality has on repurchase intention of Internet shopping through customer satisfaction, customer trust, and customer commitment. Appropriate measures were developed and tested on 230 university students of Gyeongnam province in South Korea with a cross-sectional questionnaire survey. The results of the empirical analysis confirmed that site quality can be conceptualized as a composite of six dimensions of shopping convenience, site design, information usefulness, transaction security, payment system, and customer communication. Second, site quality positively affected customer satisfaction and customer trust, but did not affect customer commitment and repurchase intention. Third, site quality can affect repurchase intention by enhancing or attenuating customer satisfaction, customer trust, and customer commitment in online transaction situation. The mediating effect of customer satisfaction, customer trust, and customer commitment between site quality and repurchase intention is identified. Fourth, site quality indirectly affected customer commitment through customer satisfaction. Customer satisfaction indirectly affected repurchase intention through customer trust and customer commitment. Thus, it is found that site quality can be a very important factor to enhance repurchase intention in the customer perspective. © 2013 Elsevier Ltd. All rights reserved.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We introduce a robust moving least-squares technique for reconstructing a piecewise smooth surface from a potentially noisy point cloud. We use techniques from robust statistics to guide the creation of the neighborhoods used by the moving least squares (MLS) computation. This leads to a conceptually simple approach that provides a unified framework for not only dealing with noise, but also for enabling the modeling of surfaces with sharp features.Our technique is based on a new robust statistics method for outlier detection: the forward-search paradigm. Using this powerful technique, we locally classify regions of a point-set to multiple outlier-free smooth regions. This classification allows us to project points on a locally smooth region rather than a surface that is smooth everywhere, thus defining a piecewise smooth surface and increasing the numerical stability of the projection operator. Furthermore, by treating the points across the discontinuities as outliers, we are able to define sharp features. One of the nice features of our approach is that it automatically disregards outliers during the surface-fitting phase.', 'positives': ['Estimation techniques in computer vision applications must estimate accurate model parameters despite small-scale noise in the data, occasional large-scale measurement errors (outliers), and measurements from multiple populations in the same data set. Increasingly, robust estimation techniques, some borrowed from the statistics literature and others described in the computer vision literature, have been used in solving these parameter estimation problems. Ideally, these techniques should effectively ignore the outliers and measurements from other populations, treating them as outliers, when estimating the parameters of a single population. Two frequently used techniques are least-median of squares (LMS) [P. J. Rousseeuw, J. Amer. Statist. Assoc., 79 (1984), pp. 871–880] and M-estimators [Robust Statistics: The Approach Based on Influence Functions, F. R. Hampel et al., John Wiley, 1986; Robust Statistics, P. J. Huber, John Wiley, 1981]. LMS handles large fractions of outliers, up to the theoretical limit of 50% for estimators invariant to affine changes to the data, but has low statistical efficiency. M-estimators have higher statistical efficiency but tolerate much lower percentages of outliers unless properly initialized. While robust estimators have been used in a variety of computer vision applications, three are considered here. In analysis of range images—images containing depth or X, Y , Z measurements at each pixel instead of intensity measurements—robust estimators have been used successfully to estimate surface model parameters in small image regions. In stereo and motion analysis, they have been used to estimate parameters of what is called the “fundamental matrix,” which characterizes the relative imaging geometry of two cameras imaging the same scene. Recently, robust estimators have been applied to estimating a quadratic image-to-image transformation model necessary to create a composite, “mosaic image” from a series of images of the human retina. In each case, a straightforward application of standard robust estimators is insufficient, and carefully developed extensions are used to solve the problem.'], 'negatives': ['Brazilian Portuguese needs a Wordnet that is open access, downloadable and changeable, so that it can be improved by the community interested in using it for knowledge representation and automated deduction. This kind of resource is also very valuable to linguists and computer scientists interested in extracting and representing knowledge obtained from texts. We discuss briefly the reasons for a Brazilian Portuguese Wordnet and the process we used to get a preliminary version of such a resource. Then we discuss possible steps to improving our preliminary version.1'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper presents the packaging technology and the integrated antenna design for a miniaturized 122-GHz radar sensor. The package layout and the assembly process are shortly explained. Measurements of the antenna including the flip chip interconnect are presented that have been achieved by replacing the IC with a dummy chip that only contains a through-line. Afterwards, radiation pattern measurements are shown that were recorded using the radar sensor as transmitter. Finally, details of the fully integrated radar sensor are given, together with results of the first Doppler measurements.', 'positives': ['A low-cost, fully-integrated antenna-in-package solution for 60-GHz phased-array system is demonstrated. Sixteen patch antennas are integrated into a 28 mm × 28 mm ball grid array together with a flip-chip attached phased-array transmitter or receiver chip. The packages have first been fabricated using low temperature co-fired ceramic technology, and then built using conventional printed circuit board processes for lower manufacturing cost. Antenna chamber measurement has shown ∼5 dBi unit antenna gain across the 60-GHz frequency band covering all four IEEE 802.15.3c channels. The packaged transmitter and receiver chipsets, each mounted on an evaluation board, have demonstrated beam-steered, non-line-of-sight links with data rates up to 5.3 Gb/s.'], 'negatives': ['Integration of mm-wave multiple-antenna systems on silicon-based processes enables complex, low-cost systems for high-frequency communication and sensing applications. In this paper, the transmitter and LO-path phase-shifting sections of the first fully integrated 77-GHz phased-array transceiver are presented. The SiGe transceiver utilizes a local LO-path phase-shifting architecture to achieve beam steering and includes four transmit and receive elements, along with the LO frequency generation and distribution circuitry. The local LO-path phase-shifting scheme enables a robust distribution network that scales well with increasing frequency and/or number of elements while providing high-resolution phase shifts. Each element of the heterodyne transmitter generates +12.5 dBm of output power at 77 GHz with a bandwidth of 2.5 GHz leading to a 4-element effective isotropic radiated power (EIRP) of 24.5 dBm. Each on-chip PA has a maximum saturated power of +17.5 dBm at 77 GHz. The phased-array performance is measured using an internal test option and achieves 12-dB peak-to-null ratio with two transmit and receive elements active'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'RF front end modules (FEMs) are currently realized using a variety of technologies. However, since integration drives wireless business in order to achieve the appropriate cost and form factor, CMOS Silicon-on-insulator (SOI) has emerged over the past few years as the dominant technology for RF switches in RF FEMs for cell phones and WiFi [1]. While current performances available on RF SOI technology are already exceeding what was feasible using GaAs one, new cellular system such as carrier aggregation require even more stringent performances (linearity, power handling, insertion loss, isolation). To address those new requirements, RF SOI technology has to be improved. In this paper, the performances results of the latest generations of RF SOI switch technologies from STMicroelectronics are reviewed and technology elements that contribute to improved performance are discussed. Future improvements are also proposed, paving the way for RF SOI technology able to address 5G RF switches challenges.', 'positives': ['This paper presents high-Q and high current on-chip inductors integrated in a six copper metal level radio frequency (RF) back end of line (BEOL), including two 3 mum thick top metallizations, in an advanced high resistivity (HR) SOI CMOS technology. Inductors achieved on HR SOI CMOS technology using this optimized RF BEOL are reported, compared with standard BEOL, and firstly benchmarked with current ones fabricated in dedicated passive component technologies (integrated passive device (IPD) on glass or RF substrates). According to measurement results, reported SOI inductors offer quality factor Q greater than 30 and current capability up to 57 mA/mum @ 125 degC, performances largely comparable to those obtained in IPD technologies, and required for RF front-end module design.'], 'negatives': ['This paper presents the design of a single pole 6 throw antenna switch able to manage all the four GSM standards, i.e. 850-900-1800-1900 MHz. The switch has been integrated in a 0.13mum CMOS SOI process with high resistivity substrate and a thick oxide (50Aring) option. The use of high resistivity substrate allows a good loss (IL)-isolation trade-off: IL is kept in the range of 0.55-0.8 dB for the RXs and at 0.7 dB for the TXs, while isolation varies from 40 dB at 900 MHz to 30 dB at 1900 MHz. Power handling capability is well compatible with GSM standards since an ICP0.1dB of 36 dBm has been measured and harmonics distortion is below -39 dBm for an input power of 34 dBm. Robustness to antenna mismatching condition has been successfully demonstrated up to a VSWR of 10:1. The chip size is of 1.23 mm2  and the power consumption is below 10muA and 0.5 mA respectively in stand by mode and during switching, under 2.5 voltage supply'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The use of Cloud Computing for computation offloading in the robotics area has become a field of interest today. The aim of this work is to demonstrate the viability of cloud offloading in a low level and intensive computing task: a vision-based navigation assistance of a service mobile robot. In order to do so, a prototype, running over a ROS-based mobile robot (Erratic by Videre Design LLC) is presented. The information extracted from on-board stereo cameras will be used by a private cloud platform consisting of five bare-metal nodes with AMD Phenom 965 × 4 CPU, with the cloud middleware Openstack Havana. The actual task is the shared control of the robot teleoperation, that is, the smooth filtering of the teleoperated commands with the detected obstacles to prevent collisions. All the possible offloading models for this case are presented and analyzed. Several performance results using different communication technologies and offloading models are explained as well. In addition to this, a real navigation case in a domestic circuit was done. The tests demonstrate that offloading computation to the Cloud improves the performance and navigation results with respect to the case where all processing is done by the robot.', 'positives': [\"We propose DAvinCi, a software framework that provides the scalability and parallelism advantages of cloud computing for service robots in large environments. We have implemented such a system around the Hadoop cluster with ROS (Robotic Operating system) as the messaging framework for our robotic ecosystem. We explore the possibilities of parallelizing some of the robotics algorithms as Map/Reduce tasks in Hadoop. We implemented the FastSLAM algorithm in Map/Reduce and show how significant performance gains in execution times to build a map of a large area can be achieved with even a very small eight-node Hadoop cluster. The global map can later be shared with other robots introduced in the environment via a Software as a Service (SaaS) Model. This reduces the burden of exploration and map building for the new robot and minimizes it's need for additional sensors. Our primary goal is to develop a cloud computing environment which provides a compute cluster built with commodity hardware exposing a suite of robotic algorithms as a SaaS and share data co-operatively across the robotic ecosystem.\"], 'negatives': ['This paper introduces a new parametric <i>n</i>-ary Gray code, the (<i>n</i>, <i>k</i>, <i>p</i>)-Gray code, which includes several commonly used codes such as the binary-reflected, ternary, and (<i>n</i>, <i>k</i>)-Gray codes. The new (<i>n</i>, <i>k</i>, <i>p</i>)-Gray code has potential applications in digital communications and signal/image processing systems. This paper focuses on three illustrative applications of the (<i>n</i>, <i>k</i>, <i>p</i>)-Gray code, namely, image bit-plane decomposition, image denoising, and encryption. The computer simulations demonstrate that the (<i>n</i>, <i>k</i>, <i>p</i>)-Gray code shows better performance than other traditional Gray codes for these applications in image systems.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In a weakly-supervised scenario object detectors need to be trained using image-level annotation alone. Since bounding-box-level ground truth is not available, most of the solutions proposed so far are based on an iterative, Multiple Instance Learning framework in which the current classifier is used to select the highest-confidence boxes in each image, which are treated as pseudo-ground truth in the next training iteration. However, the errors of an immature classifier can make the process drift, usually introducing many of false positives in the training dataset. To alleviate this problem, we propose in this paper a training protocol based on the self-paced learning paradigm. The main idea is to iteratively select a subset of images and boxes that are the most reliable, and use them for training. While in the past few years similar strategies have been adopted for SVMs and other classifiers, we are the first showing that a self-paced approach can be used with deep-network-based classifiers in an end-to-end training pipeline. The method we propose is built on the fully-supervised Fast-RCNN architecture and can be applied to similar architectures which represent the input image as a bag of boxes. We show state-of-the-art results on Pascal VOC 2007, Pascal VOC 2010 and ILSVRC 2013. On ILSVRC 2013 our results based on a low-capacity AlexNet network outperform even those weakly-supervised approaches which are based on much higher-capacity networks.', 'positives': ['Objects vary in their visual complexity, yet existing discovery methods perform “batch” clustering, paying equal attention to all instances simultaneously — regardless of the strength of their appearance or context cues. We propose a self-paced approach that instead focuses on the easiest instances first, and progressively expands its repertoire to include more complex objects. Easier regions are defined as those with both high likelihood of generic objectness and high familiarity of surrounding objects. At each cycle of the discovery process, we re-estimate the easiness of each subwindow in the pool of unlabeled images, and then retrieve a single prominent cluster from among the easiest instances. Critically, as the system gradually accumulates models, each new (more difficult) discovery benefits from the context provided by earlier discoveries. Our experiments demonstrate the clear advantages of self-paced discovery relative to conventional batch approaches, including both more accurate summarization as well as stronger predictive models for novel data.'], 'negatives': ['• Lighting. When an object is in bright light, it looks brighter than when it’s in shadow, so a program can’t just look at image intensity values. • Within-class variation. Different instances of the same kind of object can look quite different to one another. For example, a green station wagon and a red convertible are both cars, so a program can’t simply compare a picture to one example. • Aspect. The same object can look very different when viewed at from different directions—pick up a book and compare its cover and its spine to see this effect. Again, this means that a program might need to have many examples of each type of object. • Deformation. Many objects can change their appearance significantly without their identity changing. For example, you can move your limbs around, change clothes, paint your face, or have your hair cut. You will look very different indeed, but you will still be a person.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Databases contain most valuable personal, economic, and government information. They are most desirable to the malicious adversaries and therefore, it is very critical to protect against all possible adversarial behavior. With the recent rapid growth in the availability and popularity of cloud services, many personal and business and government information are now moving to the Cloud. Therefore, databases are more difficult to protect because of new security and privacy issues. Various techniques have been proposed to solve the outsourcing database scenarios which preserve a certain degree of confidentiality while still allowing to execute some SQL queries efficiently. CryptDB is a new database management system for protecting data confidentiality while preserving confidentiality and performing a standard set of SQL queries in an efficient way. CryptDB seems to be practical compared to other attempts at solving the problem of computing with encrypted data and the database can be fully moved to the Cloud with no security concern because all the data are already encrypted and never revealed to the database administrator. In this paper, CryptDB is revisited from cryptographic point of view. First of all, CryptDB is described in more details for ease of understanding and then the drawbacks of CryptDB are highlighted from security and efficiency points of view. Keywords—Secure Database, Encrypted Search, Cryptographic Protocol, Proxy Server', 'positives': ['MONOMI is a system for securely executing analytical workloads over sensitive data on an untrusted database server. MONOMI works by encrypting the entire database and running queries over the encrypted data. MONOMI introduces split client/server query execution, which can execute arbitrarily complex queries over encrypted data, as well as several techniques that improve performance for such workloads, including per-row precomputation, space-efficient encryption, grouped homomorphic addition, and pre-filtering. Since these optimizations are good for some queries but not others, MONOMI introduces a designer for choosing an efficient physical design at the server for a given workload, and a planner to choose an efficient execution plan for a given query at runtime. A prototype of MONOMI running on top of Postgres can execute most of the queries from the TPC-H benchmark with a median overhead of only 1.24× (ranging from 1.03× to 2.33×) compared to an un-encrypted Postgres database where a compromised server would reveal all data.'], 'negatives': ['Research on next generation agricultural systems models shows that the most important current limitation is data, both for on-farm decision support and for research investment and policy decision making. One of the greatest data challenges is to obtain reliable data on farm management decision making, both for current conditions and under scenarios of changed bio-physical and socio-economic conditions. This paper presents a framework for the use of farm-level and landscape-scale models and data to provide analysis that could be used in NextGen knowledge products, such as mobile applications or personal computer data analysis and visualization software. We describe two analytical tools - AgBiz Logic and TOA-MD - that demonstrate the current capability of farmlevel and landscape-scale models. The use of these tools is explored with a case study of an oilseed crop, Camelina sativa, which could be used to produce jet aviation fuel. We conclude with a discussion of innovations needed to facilitate the use of farm and policy-level models to generate data and analysis for improved knowledge products.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Adequate representation of natural language semantics requires access to vast amounts of common sense and domain-specific world knowledge. Prior work in the field was based on purely statistical techniques that did not make use of background knowledge, on limited lexicographic knowledge bases such as WordNet, or on huge manual efforts such as the CYC project. Here we propose a novel method, called Explicit Semantic Analysis (ESA), for fine-grained semantic interpretation of unrestricted natural language texts. Our method represents meaning in a high-dimensional space of concepts derived from Wikipedia, the largest encyclopedia in existence. We explicitly represent the meaning of any text in terms of Wikipedia-based concepts. We evaluate the effectiveness of our method on text categorization and on computing the degree of semantic relatedness between fragments of natural language text. Using ESA results in significant improvements over the previous state of the art in both tasks. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users.', 'positives': ['Most research in text classification to date has used a “bag of words” representation in which each feature corresponds to a single word. This paper examines some alternative ways to represent text based on syntactic and semantic relationships between words (phrases, synonyms and hypernyms). We describe the new representations and try to justify our hypothesis that they could improve the performance of a rule-based learner. The representations are evaluated using the RIPPER learning algorithm on the Reuters-21578 and DigiTrad test corpora. On their own the new representations are not found to produce significant performance improvements. We also try combining classifiers based on different representations using a majority voting technique, and this improves performance on both test collections. In our opinion, more sophisticated Natural Language Processing techniques need to be developed before better text representations can be produced for classification.'], 'negatives': ['Botulinum toxin injections are an effective treatment option for several laryngeal disorders. This article reviews the indications, procedural techniques, potential complications, and outcomes of Botox injections for laryngeal disorders.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': '1. Department of Molecular, Cellular and Developmental Biology, Yale University, New Haven, CT 06511 2. Department of Molecular and Cellular Physiology, Stanford University School of Medicine, Stanford, CA 94305 3. Department of Chemical and Systems Biology, Stanford University School of Medicine, Stanford, CA 94305 4. Department of Genetics, Stanford University School of Medicine, Stanford, CA 94305 5. Department of Developmental Biology, Stanford University School of Medicine, Stanford, CA 94305 6. Co-first author', 'positives': ['The ability to perturb genes in human cells is crucial for elucidating gene function and holds great potential for finding therapeutic targets for diseases such as cancer. To extend the catalog of human core and context-dependent fitness genes, we have developed a high-complexity second-generation genome-scale CRISPR-Cas9 gRNA library and applied it to fitness screens in five human cell lines. Using an improved Bayesian analytical approach, we consistently discover 5-fold more fitness genes than were previously observed. We present a list of 1,580 human core fitness genes and describe their general properties. Moreover, we demonstrate that context-dependent fitness genes accurately recapitulate pathway-specific genetic vulnerabilities induced by known oncogenes and reveal cell-type-specific dependencies for specific receptor tyrosine kinases, even in oncogenic KRAS backgrounds. Thus, rigorous identification of human cell line fitness genes using a high-complexity CRISPR-Cas9 library affords a high-resolution view of the genetic vulnerabilities of a cell.'], 'negatives': ['BACKGROUND\\nThe efficacy of low-dose oral isotretinoin in the treatment of seborrhea and seborrheic dermatitis has been poorly investigated in randomized studies.\\n\\n\\nOBJECTIVES\\nThis study was designed to determine the efficacy and safety of low-dose oral isotretinoin in the treatment of moderate to severe seborrhea and seborrheic dermatitis on the scalp and/or face.\\n\\n\\nMETHODS\\nA randomized, comparative clinical trial, using two groups, was conducted over 6 months. Patients in Group ISO were treated with isotretinoin 10 mg every other day. In Group X, patients received antiseborrheic topical treatment. Patient opinion, investigator assessment, scalp pruritus, sebum production, and quality of life (QoL) comprised the efficacy outcomes.\\n\\n\\nRESULTS\\nThe intention-to-treat population comprised a total of 45 patients with mean ± standard deviation ages of 28.7 ± 5.8 years in Group ISO and 29.8 ± 6.5 years in Group X. The rate of sebum production significantly decreased in Group ISO. Patient opinion, investigator, and QoL assessments improved in both groups.\\n\\n\\nCONCLUSIONS\\nLow-dose oral isotretinoin can be a therapeutic modality for moderate to severe seborrhea and seborrheic dermatitis.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The growing interest in Structured Equation Modeling (SEM) techniques and recognition of their importance in IS research suggests the need to compare and contrast different types of SEM techniques so that research designs can be selected appropriately. After assessing the extent to which these techniques are currently being used in IS research, the article presents a running example which analyzes the same dataset via three very different statistical techniques. It then compares two classes of SEM: covariance-based SEM and partial-least-squaresbased SEM. Finally, the article discusses linear regression models and offers guidelines as to when SEM techniques and when regression techniques should be used. The article concludes with heuristics and rule of thumb thresholds to guide practice, and a discussion of the extent to which practice is in accord with these guidelines.', 'positives': ['The technology acceptance model (Davis 1989) is one of the most widely used models of IT adoption. According to TAM, IT adoption is influenced by two perceptions: usefulness and ease-of-use. Research has shown that perceived usefulness (PU) affects intended adoption of IT, but has mostly failed to do so regarding perceived ease of use (PEOU). The basic proposition of this study is that this varying importance of PEOU may be related to the nature of the task. PEOU relates to assessments of the intrinsic characteristics of IT, such as the ease of use, ease of learning, flexibility, and clarity of its interface. PU, on the other hand, is a response to user assessment of its extrinsic, i.e., task-oriented, outcomes: how IT'], 'negatives': ['Lattice problems are an attractive basis for cryptographic systems because they seem to offer better security than discrete logarithm and factoring based problems. Efficient lattice-based constructions are known for signature and encryption schemes. However, the constructions known for more sophisticated schemes such as group signatures are still far from being practical. In this paper we make a number of steps towards efficient lattice-based constructions of more complex cryptographic protocols. First, we provide a more efficient way to prove knowledge of plaintexts for lattice-based encryption schemes. We then show how our new protocol can be combined with a proof of knowledge for Pedersen commitments in order to prove that the committed value is the same as the encrypted one. Finally, we make use of this to construct a new group signature scheme that is a “hybrid” in the sense that privacy holds under a lattice-based assumption while security is discrete-logarithm-based.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"We develop a multilayer overlapped self-organizing maps (SOM's) with limited structure adaptation capabilities, and associated learning scheme for labeled pattern classification applications. The learning algorithm consists of the standard unsupervised SOM learning of synaptic weights as well as the supervised learning vector quantization (LVQ) 2 learning. As higher layer SOM's overlap, the final classification is made by fusing the classifications of top-level overlapped SOM's. We obtained the best results ever reported for any SOM-based numerals classification system.\", 'positives': ['Alrstract-We present a new self-organizing neural network model that has two variants. The first variant performs unsupervised learning and can be used for data visualization, clustering, and vector quantization. The main advantage over existing approaches ( e.g., the Kohonen feature map) is the ability o f the model to automatically find a suitable network structure and size. This is achieved through a controlled growth process that also includes occasional removal o f units. The second variant of the model is a supervised learning method that results from the combination of the above-mentioned self-organizing network with the radial basis function (RBF) approach. In this model it is possible--in contrast to earlier approaches--to perform the positioning of the RBF units and the supervised training of the weights in parallel. Therefore, the current classification error can be used to determine where to insert new RBF units. This leads to small networks that generalize very well. Results on the two-spirals benchmark and a vowel classification problem are presented that are better than any results previously published.'], 'negatives': ['In order to solve the leak problem from water pipeline, the principle of water pipeline leak detection using acoustic theory is elaborated and the location algorithm is given. A leak detection technique combines wavelet transform and cross-correlation technique is the focus in this paper. The leak location algorithm using wavelet transform for noise reduction before using cross-correlation technique to calculate the time arrival difference between the two vibration sensors. After wavelet transform denoising, by introducing the optimal maximum likelihood based on cross-correlation technique, the time delay estimate between the two sensors is precisely calculated and obtained. Then a compare between this method and basic cross-correlation method is conducted. Simulation results verifies the validity of the new measuring method.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The volume of data in healthcare repositories is growing exponentially, giving increased concerns on its organizational implications. The quality of data and information represents a considerable risk for organizations, particularly in healthcare, where consequences of poor quality may be fatal for patients. This research seeks to investigate the role of information quality in organizations, by reviewing multi-disciplinary research literature and provide a framework of the relations between IQ and its organizational implications. Findings suggest that research on information quality has focused on different aspects of organizational impact: organizational performance, process performance, process improvement, and decision-making. However, since the research is fragmented and scarce, this paper suggests a shift in research focus from defining, measuring and improving information quality, to understanding the implications and applications of information quality towards better and safer health services.', 'positives': ['Ten years ago, we presented the DeLone and McLean Information Systems (IS) Success Model as a framework and model for measuring the complexdependent variable in IS research. In this paper, we discuss many of the important IS success research contributions of the last decade, focusing especially on research efforts that apply, validate, challenge, and propose enhancements to our original model. Based on our evaluation of those contributions, we propose minor refinements to the model and propose an updated DeLone and McLean IS Success Model. We discuss the utility of the updated model for measuring e-commerce system success. Finally, we make a series of recommendations regarding current and future measurement of IS success. 10 DELONE AND MCLEAN'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Mobile apps continue to consume increasing amounts of sensitive data, such as banking credentials and classified documents. At the same time, the number of smartphone thefts is increasing at a rapid speed. As a result, there is an imperative need to protect sensitive data on lost or stolen mobile devices. In this work, we develop a practical solution to protect sensitive data on mobile devices. Our solution enables adaptive protection by pro-actively stepping up or stepping down data security based on perceived contextual risk of the device. We realize our solution for the Android platform in the form of a system called AppShell. AppShell does not require root privilege, nor need any modification to the underlying framework, and hence is a ready-to-deploy solution. It supports both in-memory and on-disk data protection by transparently encrypting the data, and discarding the encryption key, when required, for enhanced protection. We implement a working prototype of AppShell and evaluate it against several popular Android apps. Our results show that AppShell can successfully protect sensitive data in the lost devices with a reasonable performance overhead.', 'positives': ['Commodity operating systems entrusted with securing sensitive data are remarkably large and complex, and consequently, frequently prone to compromise. To address this limitation, we introduce a virtual-machine-based system called Overshadow that protects the privacy and integrity of application data, even in the event of a total OScompromise. Overshadow presents an application with a normal view of its resources, but the OS with an encrypted view. This allows the operating system to carry out the complex task of managing an application\\'s resources, without allowing it to read or modify them. Thus, Overshadow offers a last line of defense for application data.\\n Overshadow builds on multi-shadowing, a novel mechanism that presents different views of \"physical\" memory, depending on the context performing the access. This primitive offers an additional dimension of protection beyond the hierarchical protection domains implemented by traditional operating systems and processor architectures.\\n We present the design and implementation of Overshadow and show how its new protection semantics can be integrated with existing systems. Our design has been fully implemented and used to protect a wide range of unmodified legacy applications running on an unmodified Linux operating system. We evaluate the performance of our implementation, demonstrating that this approach is practical.'], 'negatives': ['Increased personal control and comfort needs of employees triggered the concern among organizations to provide them with an environment and office design, which fulfills the employees’ needs and helps to boost their productivity. The main objective of this study is to find out the relationship between office design and productivity. For this purpose, 31 bank branches of 13 banks were contacted and studied. The findings of this study show that office design is very vital in terms of increasing employees’ productivity. Comfortable and ergonomic office design motivates the employees and increases their performance substantially.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Reciprocal Rank Fusion (RRF), a simple method for combining the document rankings from multiple IR systems, consistently yields better results than any individual system, and better results than the standard method Condorcet Fuse. This result is demonstrated by using RRF to combine the results of several TREC experiments, and to build a meta-learner that ranks the LETOR 3 dataset better than any previously reported method', 'positives': ['This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples.'], 'negatives': ['A series of information retrieval experiments was earned out with a computer installed in a medical practice setting for relatively inexperienced physician end-users. Using a commercial MEDLINE product based on the vector space model, these physicians searched just as effectively as more experienced searchers using Boolean searching. The results of this experiment were subsequently used to create anew large medical test collection, which was used in experiments with the SMART ~trieval system to obtain baseline performance data as well as compare SMART with the other searchers.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Disruption of function of left, but not right, lateral prefrontal cortex (LPFC) with low-frequency repetitive transcranial magnetic stimulation (rTMS) increased choices of immediate rewards over larger delayed rewards. rTMS did not change choices involving only delayed rewards or valuation judgments of immediate and delayed rewards, providing causal evidence for a neural lateral-prefrontal cortex–based self-control mechanism in intertemporal choice.', 'positives': ['The authors investigated risk taking and underlying information use in 13- to 16- and 17- to 19-year-old adolescents and in adults in 4 experiments, using a novel dynamic risk-taking task, the Columbia Card Task (CCT). The authors investigated risk taking under differential involvement of affective versus deliberative processes with 2 versions of the CCT, constituting the most direct test of a dual-system explanation of adolescent risk taking in the literature so far. The \"hot\" CCT was designed to trigger more affective decision making, whereas the \"cold\" CCT was designed to trigger more deliberative decision making. Differential involvement of affective versus deliberative processes in the 2 CCT versions was established by self-reports and assessment of electrodermal activity. Increased adolescent risk taking, coupled with simplified information use, was found in the hot but not the cold condition. Need-for-arousal predicted risk taking only in the hot condition, whereas executive functions predicted information use in the cold condition. Results are consistent with recent dual-system explanations of risk taking as the result of competition between affective processes and deliberative cognitive-control processes, with adolescents\\' affective system tending to override the deliberative system in states of heightened emotional arousal.'], 'negatives': ['Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Haptic feedback on touch-sensitive displays provides significant benefits in terms of reducing error rates, increasing interaction speed and minimizing visual distraction. This particularly holds true for multitasking situations such as the interaction with mobile devices or touch-based in-vehicle systems. In this paper, we explore how the interaction with tactile touchscreens can be modeled and enriched using a 2+1 state transition model. The model expands an approach presented by Buxton. We present HapTouch -- a force-sensitive touchscreen device with haptic feedback that allows the user to explore and manipulate interactive elements using the sense of touch. We describe the results of a preliminary quantitative study to investigate the effects of tactile feedback on the driver's visual attention, driving performance and operating error rate. In particular, we focus on how active tactile feedback allows the accurate interaction with small on-screen elements during driving. Our results show significantly reduced error rates and input time when haptic feedback is given.\", 'positives': ['When on the move, cognitive resources are reserved partly for passively monitoring and reacting to contexts and events, and partly for actively constructing them. The Re-source Competition Framework (RCF), building on the Multiple Resources Theory, explains how psychosocial tasks typical of mobile situations compete for cognitive resources and then suggests that this leads to the depletion of resources for task interaction and eventually results in the breakdown of fluent interaction. RCF predictions were tested in a semi-naturalistic field study measuring attention during the performance of assigned Web search tasks on mobile phone while moving through nine varied but typical urban situations. Notably, we discovered up to eight-fold differentials between micro-level measurements of atten-tional resource fragmentation, for example from spans of over 16 seconds in a laboratory condition dropping to bursts of just a few seconds in difficult mobile situations. By cali-brating perceptual sampling, reducing resources from tasks of secondary importance, and resisting the impulse to switch tasks before finalization, participants compensated for the resource depletion. The findings are compared to previous studies in office contexts. The work is valuable in many areas of HCI dealing with mobility.'], 'negatives': ['Make more knowledge even in less time every day. You may not always spend your time and money to go abroad and get the experience and knowledge by yourself. Reading is a good alternative to do in getting this desirable knowledge and experience. You may gain many things from experiencing directly, but of course it will spend much money. So here, by reading psychology of human computer interaction, you can take more advantages with limited budget.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'The zebrafish has become a popular experimental model organism for biomedical research. In this paper, a unique framework is proposed for automatically detecting Tyrosine Hydroxylase-containing (TH-labeled) cells in larval zebrafish brain z-stack images recorded through the wide-field microscope. In this framework, a supervised max-pooling Convolutional Neural Network (CNN) is trained to detect cell pixels in regions that are preselected by a Support Vector Machine (SVM) classifier. The results show that the proposed deep-learned method outperforms hand-crafted techniques and demonstrate its potential for automatic cell detection in wide-field microscopy z-stack zebrafish images.', 'positives': ['Over the last few years, with the immense popularity of the Kinect, there has been renewed interest in developing methods for human gesture and action recognition from 3D skeletal data. A number of approaches have been proposed to extract representative features from 3D skeletal data, most commonly hard wired geometric or bio-inspired shape context features. We propose a hierarchial dynamic framework that first extracts high level skeletal joints features and then uses the learned representation for estimating emission probability to infer action sequences. Currently gaussian mixture models are the dominant technique for modeling the emission distribution of hidden Markov models. We show that better action recognition using skeletal features can be achieved by replacing gaussian mixture models by deep neural networks that contain many layers of features to predict probability distributions over states of hidden Markov models. The framework can be easily extended to include a ergodic state to segment and recognize actions simultaneously.'], 'negatives': [\"The Arab Muslim population is one of the dramatically increasing minorities in the United States. In addition to other factors, religion and cultural background influence individuals' beliefs, behaviors, and attitudes toward health and illness. The author describes health beliefs and practices of the Arab Muslim population in the United States. That population is at an increased risk for several diseases and faces many barriers to accessing the American health care system. Some barriers, such as modesty, gender preference in healthcare providers, and illness causation misconceptions, arise out of their cultural beliefs and practices. Other barriers are related to the complexity of the health care system and the lack of culturally competent services within it. Nurses need to be aware of these religious and cultural factors to provide culturally competent health promotion services for this population. Nurses also need to integrate Islamic teachings into their interventions to provide appropriate care and to motivate healthy behaviors.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, we propose two approaches to improve deep neural network (DNN) acoustic models for speech recognition in reverberant environments. Both methods utilize auxiliary information in training the DNN but differ in the type of information and the manner in which it is used. The first method uses parallel training data for multi-task learning, in which the network is trained to perform both a primary senone classification task and a secondary feature enhancement task using a shared representation. The second method uses a parameterization of the reverberant environment extracted from the observed signal to train a room-aware DNN. Experiments were performed on the single microphone task of the REVERB Challenge corpus. The proposed approach obtained a word error rate of 7.8% on the SimData test set, which is lower than all reported systems using the same training data and evaluation conditions, and 27.5% on the mismatched RealData test set, which is lower than all but two systems.', 'positives': ['Recently, substantial progress has been made in the field of reverberant speech signal processing, including both single- and multichannel dereverberation techniques, and automatic speech recognition (ASR) techniques robust to reverberation. To evaluate state-of-the-art algorithms and obtain new insights regarding potential future research directions, we propose a common evaluation framework including datasets, tasks, and evaluation metrics for both speech enhancement and ASR techniques. The proposed framework will be used as a common basis for the REVERB (REverberant Voice Enhancement and Recognition Benchmark) challenge. This paper describes the rationale behind the challenge, and provides a detailed description of the evaluation framework and benchmark results.'], 'negatives': ['BACKGROUND\\nMillions of people worldwide are exposed to arsenic in drinking water, and many are likely coexposed to other agents that could substantially increase their risks of arsenic-related cancer.\\n\\n\\nMETHODS\\nWe performed a case-control study of multiple chemical exposures in 538 lung and bladder cancer cases and 640 controls in northern Chile, an area with formerly high drinking water arsenic concentrations. Detailed information was collected on lifetime arsenic exposure, smoking, secondhand smoke, and other known or suspected carcinogens, including asbestos, silica, and wood dust.\\n\\n\\nRESULTS\\nVery high lung and bladder cancer odds ratios (ORs), and evidence of greater than additive effects, were seen in people exposed to arsenic concentrations >335 µg/L and who were tobacco smokers (OR = 16, 95% confidence interval = 6.5-40 for lung cancer; and OR = 23 [8.2-66] for bladder cancer; Rothman Synergy Indices = 4.0 [1.7-9.4] and 2.0 [0.92-4.5], respectively). Evidence of greater than additive effects were also seen in people coexposed to arsenic and secondhand tobacco smoke and several other known or suspected carcinogens, including asbestos, silica, and wood dust.\\n\\n\\nCONCLUSIONS\\nThese findings suggest that people coexposed to arsenic and other known or suspected carcinogens have very high risks of lung or bladder cancer.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Brushless DC (BLDC) motors have been widely used in many field of drives for their high power/weight, high torque, high efficiency, long operating life, noiseless operation, high speed ranges and ease of control. In this paper, a Neuro-Fuzzy Controller (NFC) based on supervisory learning is presented for the speed and torque control of BLDC motors to enhance high control performance of the drive under transient and steady state conditions. This designed controller is combination of Neural Networks (NNs) and Fuzzy Logic (FL), therefore has parallel processing and learning abilities of NNs and inference capacity of FL. For improvement the performance of leaning algorithm and thereupon increase efficiency of drive, instead of usual Error Back Propagation (EBP) learning technique, a fuzzy based supervisory learning algorithm is employed. The proposed controller has simple structure and also due to its modest fuzzy rule in rule-base is relatively easy for implementation. This controller has high accuracy, suitable performance, high robustness and high tracking efficiency. In order to demonstrate the NFC ability to tracking reference speed and torque and also test of robustness and rejection ability of controller against undesired disturbances or suddenly changes in speed and torque, these designs are simulated with MATLAB/SIMULINK. In some cases, results are compared with that of a conventional PID controller and other designs. Streszczenie. W artykule zaprezentowane układ sterowania bezszczotkowym silnikiem DC z wykorzystaniem sterownika Neuro-Fuzzy. Dla poprawienia efektywności uczenia sieci zamiast wstecznej propagacji błędu zaproponowano algorytm wykorzystujący logikę rozmytą. Sterownik okazał się być dokładny, odporny i o dużej efektywności śledzenia zmian. Porównano możliwości kontrolera z konwencjonalnym sterownikiem PID. (Projekt skutecznego sterownika silnika bezszczotkowego DC z wykorzystaniem sieci neuronowych i logiki rozmytej)', 'positives': ['– The techniques of artificial intelligence based in fuzzy logic and neural networks are frequently applied together. The reasons to combine these two paradigms come out of the difficulties and inherent limitations of each isolated paradigm. Generically, when they are used in a combined way, they are called Neuro-Fuzzy Systems. This term, however, is often used to assign a specific type of system that integrates both techniques. This type of system is characterised by a fuzzy system where fuzzy sets and fuzzy rules are adjusted using input output patterns. There are several different implementations of neuro-fuzzy systems, where each author defined its own model. This article summarizes a general vision of the area describing the most known hybrid neuro-fuzzy techniques, its advantages and disadvantages.'], 'negatives': ['The practical deployment of massive multiple-input multiple-output (MIMO) in the future fifth generation (5G) wireless communication systems is challenging due to its high-hardware cost and power consumption. One promising solution to address this challenge is to adopt the low-resolution analog-to-digital converter (ADC) architecture. However, the practical implementation of such architecture is challenging due to the required complex signal processing to compensate the coarse quantization caused by low-resolution ADCs. Therefore, few high-resolution ADCs are reserved in the recently proposed mixed-ADC architecture to enable low-complexity transceiver algorithms. In contrast to previous works over Rayleigh fading channels, we investigate the performance of mixed-ADC massive MIMO systems over the Rician fading channel, which is more general for the 5G scenarios like Internet of Things. Specially, novel closed-form approximate expressions for the uplink achievable rate are derived for both cases of perfect and imperfect channel state information (CSI). With the increasing Rician  $K$ -factor, the derived results show that the achievable rate will converge to a fixed value. We also obtain the power-scaling law that the transmit power of each user can be scaled down proportionally to the inverse of the number of base station (BS) antennas for both perfect and imperfect CSI. Moreover, we reveal the tradeoff between the achievable rate and the energy efficiency with respect to key system parameters, including the quantization bits, number of BS antennas, Rician  $K$ -factor, user transmit power, and CSI quality. Finally, numerical results are provided to show that the mixed-ADC architecture can achieve a better energy-rate tradeoff compared with the ideal infinite-resolution and low-resolution ADC architectures.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper presents the Emotional-Belief-DesireIntention architecture which reflects humans’ practical reasoning by adding the influence of primary and secondary emotions into the decision making process of a traditional BDI architecture. Our architecture handles bounded resources by using primary emotions as the first filter for adjusting the priority of beliefs, thereby allowing the agents to speed up decision making. Secondary emotions are used to refine the decision when time permits. We present a sample EBDI agent for the Tileworld domain in order to show our architecture might be used.', 'positives': ['Most theories of choice assume that decisions derive from an assessment of the future outcomes of various options and alternatives through some type of cost-benefit analyses. The influence of emotions on decision-making is largely ignored. The studies of decision-making in neurological patients who can no longer process emotional information normally suggest that people make judgments not only by evaluating the consequences and their probability of occurring, but also and even sometimes primarily at a gut or emotional level. Lesions of the ventromedial (which includes the orbitofrontal) sector of the prefrontal cortex interfere with the normal processing of \"somatic\" or emotional signals, while sparing most basic cognitive functions. Such damage leads to impairments in the decision-making process, which seriously compromise the quality of decisions in daily life. The aim of this paper is to review evidence in support of \"The Somatic Marker Hypothesis,\" which provides a systems-level neuroanatomical and cognitive framework for decision-making and suggests that the process of decision-making depends in many important ways on neural substrates that regulate homeostasis, emotion, and feeling. The implications of this theoretical framework for the normal and abnormal development of the orbitofrontal cortex are also discussed.'], 'negatives': ['Neuromodulators associated with arousal modulate learning and memory, but most of these substances do not freely enter the brain from the periphery. In rodents, these neuromodulators act in part by initiating neural messages that travel via the vagus nerve to the brain, and electrical stimulation of the vagus enhances memory. We now extend that finding to human verbal learning. We examined word-recognition memory in patients enrolled in a clinical study evaluating the capacity of vagus nerve stimulation to control epilepsy. Stimulation administered after learning significantly enhanced retention. These findings confirm in humans the hypothesis that vagus nerve activation modulates memory formation similarly to arousal.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Perspective distortion occurs due to the perspective projection of 3D scene on a 2D surface. Correcting the distortion of a single image without losing any desired information is one of the challenging task in the field of Computer Vision. We consider the problem of estimating perspective distortion from a single still image of an unstructured environment and to make perspective correction which is both quantitatively accurate as well as visually pleasing. Corners are detected based on the orientation of the image. A method based on plane homography and transformation is used to make perspective correction. The algorithm infers frontier information directly from the images, without any reference objects or prior knowledge of the camera parameters. The frontiers are detected using geometric context based segmentation. The goal of this paper is to present a framework providing fully automatic and fast perspective correction.', 'positives': ['Compared to typical scanners, handheld cameras offer convenient, flexible, portable, and noncontact image capture, which enables many new applications and breathes new life into existing ones. However, camera-captured documents may suffer from distortions caused by a nonplanar document shape and perspective projection, which lead to the failure of current optical character recognition (OCR) technologies. We present a geometric rectification framework for restoring the frontal-flat view of a document from a single camera-captured image. Our approach estimates the 3D document shape from texture flow information obtained directly from the image without requiring additional 3D/metric data or prior camera calibration. Our framework provides a unified solution for both planar and curved documents and can be applied in many, especially mobile, camera-based document analysis applications. Experiments show that our method produces results that are significantly more OCR compatible than the original images.'], 'negatives': [\"Child neglect results from either acts of omission or of commission. Fatalities from neglect account for 30% to 40% of deaths caused by child maltreatment. Deaths may occur from failure to provide the basic needs of infancy such as food or medical care. Medical care may also be withheld because of parental religious beliefs. Inadequate supervision may contribute to a child's injury or death through adverse events involving drowning, fires, and firearms. Recognizing the factors contributing to a child's death is facilitated by the action of multidisciplinary child death review teams. As with other forms of child maltreatment, prevention and early intervention strategies are needed to minimize the risk of injury and death to children.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'By arranging multiple existing web services into workflows to create value-added services, automatic web service composition has received much attention in service-oriented computing. A large number of methods have been proposed for it although most of them are merely based on the matching of input-output parameters of services. Besides these parameters, some other elements can affect the execution of services and their composition, such as the preconditions and service execution results. In particular, the execution effects of some services are often uncertain because of the complex and dynamically changing application environments in the real world, and this can cause the emergence of nondeterministic choices in the workflows of composite services. However, the previous methods for automatic service composition mainly rely on sequential structures, which make them difficult to take into account uncertain effects during service composition. In this paper, Graphplan is employed and extended to tackle this problem. In order to model services with uncertain effects, we first extend the original form of Graphplan. Then, we propose a novel approach that can introduce branch structures into composite solutions to cope with such uncertainty in the service composition process. Extensive experiments are performed to evaluate and analyze the proposed methodology.', 'positives': ['The Internet is going through several major changes. It has become a vehicle of Web services rather than just a repository of information. Many organizations are putting their core business competencies on the Internet as a collection of Web services. An important challenge is to integrate them to create new value-added Web services in ways that could never be foreseen forming what is known as Business-to-Business (B2B) services. Therefore, there is a need for modeling techniques and tools for reliable Web service composition. In this paper, we propose a Petri net-based algebra, used to model control flows, as a necessary constituent of reliable Web service composition process. This algebra is expressive enough to capture the semantics of complex Web service combinations.'], 'negatives': [\"Today's business enterprises must deal with global competition, reduce the cost of doing business, and rapidly develop new services and products. To address these requirements enterprises must constantly reconsider and optimize the way they do business and change their information systems and applications to support evolving business processes. Workflow technology facilitates these by providing methodologies and software to support (i) business process modeling to capture business processes as workflow specifications, (ii) business process reengineering to optimize specified processes, and (iii) workflow automation to generate workflow implementations from workflow specifications. This paper provides a high-level overview of the current workflow management methodologies and software products. In addition, we discuss the infrastructure technologies that can address the limitations of current commercial workflow technology and extend the scope and mission of workflow management systems to support increased workflow automation in complex real-world environments involving heterogeneous, autonomous, and distributed information systems. In particular, we discuss how distributed object management and customized transaction management can support further advances in the commercial state of the art in this area.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Calculating differences between models is an important and challenging task in Model Driven Engineering. Model differencing involves a number of steps starting with identifying matching model elements, calculating and representing their differences, and finally visualizing them in an appropriate way. In this paper, we provide an overview of the fundamental steps involved in the model differencing process and summarize the advantages and shortcomings of existing approaches for identifying matching model elements. To assist potential users in selecting one of the existing methods for the problem at stake, we investigate the trade-offs these methods impose in terms of accuracy and effort required to implement each one of them.', 'positives': ['Model differentiation techniques, which provide the capability to identify mappings and differences between models, are essential to many model development and management practices. There has been initial research toward model differentiation applied to UML diagrams, but differentiation of domain-specific models has not been explored deeply in the modeling community. Traditional modeling practice using the UML relies on a single fixed generalpurpose language (i.e., all UML diagrams conform to a single metamodel). In contrast, DomainSpecific Modeling (DSM) is an emerging model-driven paradigm in which multiple metamodels are used to define various modeling languages that represent the key concepts and abstractions for particular domains. Therefore, domain-specific models may conform to various metamodels, which requires model differentiation algorithms be metamodel-independent and able to apply to multiple domain-specific modeling languages. This paper presents metamodel-independent algorithms and associated tools for detecting mappings and differences between domain-specific models, with facilities for graphical visualization of the detected differences. INTRODUCTION Model-Driven Engineering (MDE) is emerging as a software development paradigm that promotes models as first-class artifacts to specify properties of software systems at a higher level of abstraction. The capability to identify mappings and differences between models, which is called model differentiation or model comparison, is essential to many model development and management practices [Cicchetti et al., 2007]. For example, model differentiation is needed in a model versioning system to trace the changes between different model versions to understand the evolution history of the models. Model comparison techniques and tools may help maintain consistency between different views of a modeled system. Furthermore, model differentiation can also be applied to assist in testing the correctness of model transformations by comparing the expected model and the resulting model after applying a transformation ruleset. Although there exist many techniques available for differentiating text files (e.g., source code and documentation) and for structured data (e.g., XML documents), such tools either operate under a linear file-based paradigm that is purely textual (e.g., the Unix diff tool [Hunt and McIlroy, 75]) or perform comparison on a tree structure (e.g., the XMLDiff tool [Wang et al., 03]). However, models are structurally represented as graphs and are often rendered in a graphical notation. Thus, there is a structural mismatch between currently available text-based differentiation tools and the graphical nature of models. Furthermore, from our experience, large models can contain several thousand modeling elements, which makes a manual approach to model differentiation infeasible. To address these problems, more research is needed to explore automated differentiation algorithms and supporting tools that may be applied to models with graphical structures. Theoretically, generic model comparison is similar to the graph isomorphism problem that can be defined as finding the correspondence between two given graphs, which is known to be NP-hard [Khuller and Raghavachari, 96]. Some research efforts aim to provide generic model comparison algorithms, such as the Bayesian approach, which initially provides diagram matching solutions to architectural models and data models [Mandelin et al., 06]. However, the computational complexity of general graph matching algorithms is the major hindrance to applying them to practical applications in modeling. Thus, it is necessary to loosen the constraints on graph matching to find solutions for model comparison. A typical solution is to provide differentiation techniques that are specific to a particular modeling language, where the syntax and semantics of this language help handle conflicts during model matching. Currently, there exist many types of modeling languages. Particularly, the Unified Modeling Language (UML) is a popular object-oriented modeling language. The majority of investigations into model differentiation focus on UML diagrams [Ohst et al., 03], [Xing and Stroulia, 05]. Alternatively, Domain-Specific Modeling (DSM) [Gray et al., 07] is an emerging MDE methodology that generates customized modeling languages and environments from metamodels that define a narrow domain of interest. DSM has been adopted frequently in the development of computer-based systems, especially in the domain of embedded control software (e.g., avionics and automotive control). Distinguished from UML, which is a general-purpose modeling language, Domain-Specific Modeling Languages (DSMLs) aim to specify the solution directly using rules and concepts familiar to end-users of a particular application domain. There are two main differences between domain-specific models and UML diagrams: 1) UML diagrams have a single definition for syntax and static semantics (i.e., a single metamodel); however, domain-specific models vary significantly in their structures and properties when their syntax and static semantics are defined in different metamodels, which correspond to different DSMLs tailored for specific end-users; 2) domain-specific models are usually considered as instance-based models (e.g., large domainspecific system models often have repetitive and nested hierarchical structures and may contain large quantities of objects of the same type), but traditional UML diagrams are primarily classbased models. Thus, domain-specific models and UML diagrams differ in structure, syntax and semantics. New approaches are therefore required to analyze differences among domain-specific models. However, there has been little work reported in the literature on computing differences between domain-specific models that are visualized in a graphical concrete syntax. The main goal of this paper is to present our algorithms that are metamodel-independent and have been implemented in a tool called DSMDiff, which addresses the problem of computing the differences between domain-specific models by exploring the following issues: Q1. What are the essential characteristics of domain-specific models and how are they defined? Q2. What information within domain-specific models needs to be compared and what information is needed to support metamodel-independent model comparison? Q3. How is this information formalized within the model representation in a particular DSML? Q4. How are model mappings and differences defined to enable model comparison? Q5. What algorithms can be used to discover the mappings and differences between models? Q6. How to visualize the result of model comparison to assist in comprehending the mappings and differences between two models? The next section (Metamodeling and Domain-Specific Models) provides a foundation for discussing the key entities of domain-specific modeling that contribute to model comparison (i.e., questions Q1 through Q3). The section entitled Model Differences and Mappings offers a context for Q4, which addresses the mapping and difference sets used in model comparison. The core of the paper makes a contribution to model differentiation (see the section on Model Differentiation Algorithms, which addresses Q5) by describing the algorithms that we have developed and implemented for a model differentiation tool. This section also motivates the importance of visualizing the model differences in a manner that can be comprehended by a model engineer, which is the essence of Q6. The paper presents an evaluation of the algorithms (Evaluation and Discussion) and concludes with an overview of related work and a summary conclusion. METAMODELING AND DOMAIN-SPECIFIC MODELS To develop algorithms for model differentiation, one of the critical questions is whether to determine if the two models are syntactically equivalent or to determine if they are semantically equivalent. Because the semantics of most modeling languages are not formally defined, the algorithms presented in this paper only determine whether the two models are syntactically equivalent. To achieve this, a model comparison algorithm must be informed by the syntax of a specific DSML. Thus, this section discusses how the syntax of a DSML is defined and what essential information is embodied in the syntax. Metamodeling is a common technique for conceptualizing a domain by defining the abstract syntax and static semantics of a DSML. A metamodel defines a set of modeling elements and their valid relationships that represent certain properties for a specific domain. The Generic Modeling Environment (GME) [Lédeczi et al., 01] is a meta-configurable tool that allows a DSML to be defined from a metamodel. Domain-specific models can be created using this DSML and may be translated into source code, or synthesized into data to be sent to a simulation tool. The work described in this paper was performed within the context of the GME, but we believe the algorithms that are described can solve broader model comparison problems in other metamodeling tools that represent models as hierarchical graphs, such as the ATLAS Model Management Architecture (AMMA) [Kurtev et al., 06], Microsoft’s DSL tools [Microsoft, 05], MetaEdit+ [MetaCase, 07], and the Eclipse Modeling Framework (EMF) [Budinsky et al., 04]. There are three basic types of entities used to define a DSML in GME: atom, model and connection. An atom is the most basic type of entity that cannot have any internal structures. A model is another type of entity that can contain other modeling entities such as child models and atoms. A connection represents the relationship between two entities. Generally, the constructs of a DSML defined in a metamodel consist of a set of model entities, a set of atom entities and a set 1 Please note that this is not a serious limitation when compared to other differentiation methods. The large majo'], 'negatives': ['We propose and experimentally demonstrate a series of <inline-formula> <tex-math notation=\"TeX\">$L_{n}$</tex-math></inline-formula> slot photonic crystal (PhC) microcavities, which operate as refractive index (RI) gas sensors. The cavities are simply composed of a silicon slab triangular photonic crystal with <inline-formula> <tex-math notation=\"TeX\">$n$</tex-math></inline-formula> holes replaced by a slot, which do not require sophisticated design or high fabrication resolution. With the increase in <inline-formula> <tex-math notation=\"TeX\">$n$</tex-math></inline-formula>, the quality factor of the cavity exponentially increases, which is explained by the envelope of electric field approaching a Gaussian profile. An <inline-formula> <tex-math notation=\"TeX\">$L_{9}$</tex-math></inline-formula> slot PhC microcavity with a quality factor exceeding 30\\xa0000, sensitivity of 421 nm per RI unit (RIU), and detection limit down to <inline-formula> <tex-math notation=\"TeX\">$1\\\\times 10^{-5}$</tex-math></inline-formula> RIU was experimentally demonstrated. The performance of the device is comparable with other fine-tuned PhC microcavity structures. Due to its simple structure and high fabrication tolerance, it could have wide applications in optical sensors.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Harvard Business School Working Paper Number 05-016. Working papers are distributed in draft form for purposes of comment and discussion only. They may not be reproduced without permission of the copyright holder. Copies of working papers are available from the author(s). Abstract Much recent research has pointed to the critical role of architecture in the development of a firm\\'s products, services and technical capabilities. A common theme in these studies is the notion that specific characteristics of a product\\'s design – for example, the degree of modularity it exhibits – can have a profound effect on among other things, its performance, the flexibility of the process used to produce it, the value captured by its producer, and the potential for value creation at the industry level. Unfortunately, this stream of work has been limited by the lack of appropriate tools, metrics and terminology for characterizing key attributes of a product\\'s architecture in a robust fashion. As a result, there is little empirical evidence that the constructs emerging in the literature have power in predicting the phenomena with which they are associated. This paper reports data from a research project which seeks to characterize the differences in design structure between complex software products. In particular, we adopt a technique based upon Design Structure Matrices (DSMs) to map the dependencies between different elements of a design then develop metrics that allow us to compare the structures of these different DSMs. We demonstrate the power of this approach in two ways: First, we compare the design structures of two complex software products – the Linux operating system and the Mozilla web browser – that were developed via contrasting modes of organization: specifically, open source versus proprietary development. We find significant differences in their designs, consistent with an interpretation that Linux possesses a more \" modular \" architecture. We then track the evolution of Mozilla, paying particular attention to a major \" redesign \" effort that took place several months after its release as an open source product. We show that this effort resulted in a design structure that was significantly more modular than its predecessor, and indeed, more modular than that of a comparable version of Linux. Our findings demonstrate that it is possible to characterize the structure of complex product designs and draw meaningful conclusions about the precise ways in which they differ. We provide a description of a set of tools …', 'positives': ['Currently two models of innovation are prevalent in organization science. The \"private investment\" model assumes returns to the innovator results from private goods and efficient regimes of intellectual property protection. The \"collective action\" model assumes that under conditions of market failure, innovators collaborate in order to produce a public good. The phenomenon of open source software development shows that users program to solve their own as well as shared technical problems, and freely reveal their innovations without appropriating private returns from selling the software. In this paper we propose that open source software development is an exemplar of a compound model of innovation that contains elements of both the private investment and the collective action models. We describe a new set of research questions this model raises for scholars in organization science. We offer some details regarding the types of data available for open source projects in order to ease access for researchers who are unfamiliar with these, and also offer some advice on conducting empirical studies on open source software development processes.'], 'negatives': ['English. The present research deals with the automatic annotation and classification of vulgar ad offensive speech on social media. In this paper we will test the effectiveness of the computational treatment of the taboo contents shared on the web, the output is a corpus of 31,749 Facebook comments which has been automatically annotated through a lexicon-based method for the automatic identification and classification of taboo expressions. Italiano. La presente ricerca affronta il tema dell’annotazione e della classificazione automatica dei contenuti volgari e offensivi espressi nei social media. Lo scopo del nostro lavoro consiste nel testare l’efficacia del trattamento computazionale dei contenuti tabù condivisi in rete. L’output che forniamo un corpus di 31,749 commenti generati dagli utenti di Facebook e annotato automaticamente attraverso un metodo basato sul lessico per l’identificazione e la classificazione delle'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In industry, reviews and inspections are the primary methods to identify ambiguities, inconsistencies, and under specifications in natural language (NL) software requirements specifications (SRSs). However, humans have difficulties identifying ambiguities and tend to overlook inconsistencies in a large NL SRS. This paper presents a three-step, semi-automatic method, supported by a prototype tool, for identifying inconsistencies and ambiguities in NL SRSs. The method combines the strengths of automation and human reasoning to overcome difficulties with reviews and inspections. First, the tool parses a NL SRS according to a constraining grammar. Second, from relationships exposed in the parse, the tool creates the classes, methods, variables, and associations of an object-oriented analysis model of the specified system. Third, the model is diagrammed so that a human reviewer can use the model to detect ambiguities and inconsistencies. Since a human finds the problems, the tool has to have neither perfect recall nor perfect precision. The effectiveness of the approach is demonstrated by applying it and the tool to a widely published example NL SRS. A separate study evaluates the tool’s domain-specific term detection.', 'positives': ['This volume takes a broad view of information extraction as any method for ltering information from large volumes of text. This includes the retrieval of documents from collections and the tagging of particular terms in text. In this paper we shall use a narrower de nition: the identi cation of instances of a particular class of events or relationships in a natural language text, and the extraction of the relevant arguments of the event or relationship. Information extraction therefore involves the creation of a structured representation (such as a data base) of selected information drawn from the text. The idea of reducing the information in a document to a tabular structure is not new. Its feasibility for sublanguage texts was suggested by Zellig Harris in the 1950\\'s, and an early implementation for medical texts was done at New York University by Naomi Sager[20]. However, the speci c notion of information extraction described here has received wide currency over the last decade through the series of Message Understanding Conferences [1, 2, 3, 4, 14]. We shall discuss these Conferences in more detail a bit later, and shall use simpli ed versions of extraction tasks from these Conferences as examples throughout this paper. Figure 1 shows a simpli ed example from one of the earlier MUC\\'s, involving terrorist events (MUC-3) [1]. For each terrorist event, the system had to determine the type of attack (bombing, arson, etc.), the date, location, perpetrator (if stated), targets, and e ects on targets. Other examples of extraction tasks are international joint ventures (where the arguments included the partners, the new venture, its product or service, etc.) and executive succession (indicating who was hired or red by which company for which position). Information extraction is a more limited task than \\\\full text understanding\". In full text understanding, we aspire to represent in a explicit fashion all the information in a text. In contrast, in information extraction we delimit in advance, as part of the speci cation of the task, the semantic range of the output: the relations we will represent, and the allowable llers in each slot of a relation.'], 'negatives': ['This paper will look at the various predictions that have been made about AI and propose decomposition schemas for analyzing them. It will propose a variety of theoretical tools for analyzing, judging, and improving these predictions. Focusing specifically on timeline predictions (dates given by which we should expect the creation of AI), it will show that there are strong theoretical grounds to expect predictions to be quite poor in this area. Using a database of 95 AI timeline predictions, it will show that these expectations are born out in practice: expert predictions contradict each other considerably, and are indistinguishable from non-expert predictions and past failed predictions. Predictions that AI lie 15 to 25 years in the future are the most common, from experts and non-experts alike. Armstrong, Stuart, and Kaj Sotala. 2012. “How We’re Predicting AI—or Failing To.” In Beyond AI: Artificial Dreams, edited by Jan Romportl, Pavel Ircing, Eva Zackova, Michal Polak, and Radek Schuster, 52–75. Pilsen: University of West Bohemia. This version contains minor changes. Stuart Armstrong, Kaj Sotala'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"This review provides an overview of recent studies that have examined how music influences the judgment of emotional stimuli, including affective pictures and film clips. The relevant findings are incorporated within a broader theory of music and emotion, and suggestions for future research are offered. Music is important in our daily lives, and one of its primary uses by listeners is the active regulation of one's mood. Despite this widespread use as a regulator of mood and its general pervasiveness in our society, the number of studies investigating the issue of whether, and how, music affects mood and emotional behaviour is limited however. Experiments investigating the effects of music have generally focused on how the emotional valence of background music impacts how affective pictures and/or film clips are evaluated. These studies have demonstrated strong effects of music on the emotional judgment of such stimuli. Most studies have reported concurrent background music to enhance the emotional valence when music and pictures are emotionally congruent. On the other hand, when music and pictures are emotionally incongruent, the ratings of the affect of the pictures will inor decrease depending on the emotional valence of the background music. These results appear to be consistent in studies investigating the effects of (background) music.\", 'positives': ['BACKGROUND\\nThe powerful emotion inducing properties of music are well-known, yet music may convey differing emotional responses depending on environmental factors. We hypothesized that neural mechanisms involved in listening to music may differ when presented together with visual stimuli that conveyed the same emotion as the music when compared to visual stimuli with incongruent emotional content.\\n\\n\\nMETHODS\\nWe designed this study to determine the effect of auditory (happy and sad instrumental music) and visual stimuli (happy and sad faces) congruent or incongruent for emotional content on audiovisual processing using fMRI blood oxygenation level-dependent (BOLD) signal contrast. The experiment was conducted in the context of a conventional block-design experiment. A block consisted of three emotional ON periods, music alone (happy or sad music), face alone (happy or sad faces), and music combined with faces where the music excerpt was played while presenting either congruent emotional faces or incongruent emotional faces.\\n\\n\\nRESULTS\\nWe found activity in the superior temporal gyrus (STG) and fusiform gyrus (FG) to be differentially modulated by music and faces depending on the congruence of emotional content. There was a greater BOLD response in STG when the emotion signaled by the music and faces was congruent. Furthermore, the magnitude of these changes differed for happy congruence and sad congruence, i.e., the activation of STG when happy music was presented with happy faces was greater than the activation seen when sad music was presented with sad faces. In contrast, incongruent stimuli diminished the BOLD response in STG and elicited greater signal change in bilateral FG. Behavioral testing supplemented these findings by showing that subject ratings of emotion in faces were influenced by emotion in music. When presented with happy music, happy faces were rated as more happy (p=0.051) and sad faces were rated as less sad (p=0.030). When presented with sad music, happy faces were rated as less happy (p=0.008) and sad faces were rated as sadder (p=0.002).\\n\\n\\nINTERPRETATION\\nHappy-sad congruence across modalities may enhance activity in auditory regions while incongruence appears to impact the perception of visual affect, leading to increased activation in face processing regions such as the FG. We suggest that greater understanding of the neural bases of happy-sad congruence across modalities can shed light on basic mechanisms of affective perception and experience and may lead to novel insights in the study of emotion regulation and therapeutic use of music.'], 'negatives': ['Over the past decade, vision-based vehicle detection techniques for road safety improvement have gained an increasing amount of attention. Unfortunately, the techniques suffer from robustness due to huge variability in vehicle shape (particularly for motorcycles), cluttered environment, various illumination conditions, and driving behavior. In this paper, we provide a comprehensive survey in a systematic approach about the state-of-the-art on-road vision-based vehicle detection and tracking systems for collision avoidance systems (CASs). This paper is structured based on a vehicle detection processes starting from sensor selection to vehicle detection and tracking. Techniques in each process/step are reviewed and analyzed individually. Two main contributions in this paper are the following: survey on motorcycle detection techniques and the sensor comparison in terms of cost and range parameters. Finally, the survey provides an optimal choice with a low cost and reliable CAS design in vehicle industries.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'A consensual, componential model of emotions conceptualises them as experiential, physiological, and behavioural responses to personally meaningful stimuli. The present review examines this model in terms of whether different types of emotion-evocative stimuli are associated with discrete and invariant patterns of responding in each response system, how such responses are structured, and if such responses converge across different response systems. Across response systems, the bulk of the available evidence favours the idea that measures of emotional responding reflect dimensions rather than discrete states. In addition, experiential, physiological, and behavioural response systems are associated with unique sources of variance, which in turn limits the magnitude of convergence across measures. Accordingly, the authors suggest that there is no \"gold standard\" measure of emotional responding. Rather, experiential, physiological, and behavioural measures are all relevant to understanding emotion and cannot be assumed to be interchangeable.', 'positives': ['This theoretical model of emotion is based on research using the startle-probe methodology. It explains inconsistencies in probe studies of attention and fear conditioning and provides a new approach to emotional perception, imagery, and memory. Emotions are organized biphasically, as appetitive or aversive (defensive). Reflexes with the same valence as an ongoing emotional state are augmented; mismatched reflexes are inhibited. Thus, the startle response (an aversive reflex) is enhanced during a fear state and is diminished in a pleasant emotional context. This affect-startle effect is not determined by general arousal, simple attention, or probe modality. The effect is found when affects are prompted by pictures or memory images, changes appropriately with aversive conditioning, and may be dependent on right-hemisphere processing. Implications for clinical, neurophysiological, and basic research in emotion are outlined.'], 'negatives': ['Five experiments are presented which explore the relation of masking to consciousness and visual word processing. In Experiment 1 a single word or blank field was followed by a pattern mask. Subjects had to make one of three decisions: Did anything precede the mask? To which of two probe words was what preceded the mask more similar graphically? To which of two probe words was it more similar semantically? As word-mask stimulus onset asynchrony (SOA) was reduced, subjects reached chance performance on the detection, graphic, and semantic decisions in that order. In Experiment 2, subjects again had to choose which of two words was more similar either graphically or semantically to a nondetectable masked word, but the forced-choice stimuli now covaried negatively on graphic and semantic similarity. Subjects were now unable to choose selectively on each dimension, suggesting that their ability to choose in Experiment 1 was passively rather than intentionally mediated. In Experiment 3 subjects had to make manual identification responses to color patches which were either accompanied or preceded by words masked to prevent awareness. Color-congruent words facilitated reaction time (RT), color-incongruent words delayed RT. Experiment 4 used a lexical decision task where a trial consisted of the critical letter string following another not requiring a response. When both were words they were either semantically associated or not. The first letter string was either left unmasked, energy masked monoptically, or pattern masked dichoptically to prevent awareness. The effect of association was equal in the unmasked and pattern masked cases, but absent with energy masking. In Experiment 5 repeating a word-plus-mask (where the SOA precluded detection) from 1 to 20 times (a) increased the association effect on a subsequent lexical decision, but had no effect on (b) detectability or(c) the semantic relatedness of forced guesses of the masked word. It is proposed that central pattern masking has little effect on visual processing itself (while peripheral energy masking does), but affects availability of records of the results of those processes to consciousness. Perceptual processing itself is unconscious and automatically proceeds to all levels of analysis and redescription available to the perceiver. The general importance of these findings is to cast doubt on the paradigm assumption that representations yielded by perceptual analysis are identical to and directly reflected by phenomenal percepts.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper describes a high-efficiency, high-output-power GaN power amplifier for S-band radar applications. The amplifier uses an inverse class-F configuration for high efficiency. The matching circuit includes a 2nd harmonic resonant circuit to compensate for GaN FET parasitics. The developed GaN single-chip power amplifier delivers output power of 95 W with power added efficiency (PAE) of 72% and high linear gain of 19.8 dB at 2.6 GHz. To the best of our knowledge, this is the highest efficiency for S-band power amplifiers ever reported with nearly 100-W output power.', 'positives': ['A wide variety of semiconductor devices are used in wireless power amplifiers. The RF performance and other attributes of cellphone RF power amplifiers using Si and GaAs based technologies are reviewed and compared.'], 'negatives': ['In this study, Scenedesmus obliquus SJTU-3 and Chlorella pyrenoidosa SJTU-2 were cultivated with 0.03%, 5%, 10%, 20%, 30%, 50% CO(2). The two microalgae could grow at 50% CO(2) (>0.69 g L(-1)) and grew well (>1.22 g L(-1)) under CO(2) concentrations ranging from 5% to 20%. Both of the two examined microalgae showed best growth potential at 10% CO(2). The maximum biomass concentration and CO(2) biofixation rate were 1.84 g L(-1) and 0.288 g L(-1) d(-1) for S. obliquus SJTU-3 and 1.55 g L(-1) and 0.260 g L(-1) d(-1) for C. pyrenoidosa SJTU-2, respectively. The main fatty acid compositions of the two examined microalgae were fatty acids with C(16)-C(18) (>94%) under different CO(2) levels. High CO(2) levels (30-50%) were favorable for the accumulation of total lipids and polyunsaturated fatty acids. The present results suggested that the two microalgae be appropriate for mitigating CO(2) in the flue gases and biodiesel production.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper presents a novel compact low-temperature cofired ceramic (LTCC) bandpass filter (BPF) with wide stopband and high selectivity. The proposed circuit consists of two coupled λ<sub>g</sub>/4 transmission-line resonators. A special coupling region is selected to realize a novel discriminating coupling scheme for generating a transmission zero (TZ) at the third harmonic frequency. The mechanism is analyzed and the design guideline is described. The source-load coupling is introduced to generate two TZs near the passband and one in the stopband. Thus, wide stopband can be obtained without extra circuits. Due to the LTCC multilayer structures, the filter size is 0.058 λ<sub>g</sub>×0.058 λ<sub>g</sub>×0.011 λ<sub>g</sub>, or 2.63 mm × 2.61 mm × 0.5 mm. The simulated and measured results of the demonstrated LTCC BPF are presented to validate the proposed design.', 'positives': ['Time-Domain Computer Analysis of Nonlinear Hybrid Systems by Wenquan Sui My first thought upon picking up Time-Domain Computer Analysis of Nonlinear Hybrid Systems by Wenquan Sui was wondering just what kind of hybrid he was going to discuss. Dr. Sui’s hybrid world consists of bringing together finite difference time domain (FDTD) electromagnetic simulators with circuit level nonlinear device simulators. In spite of the fact that analyzing even a fraction of a printed circuit board can bring an electromagnetic simulator to its knees, there is a continuing drive to create simulators that will reduce more and more of our problems to a number. The bottom line is that we live in an age where we can join the circuit laws of Kirchoff to the electromagnetic formulations of Maxwell and the nonlinear physics of semiconductors and solve the lot on a desktop computer. Dr. Sui’s book takes on the formidable task of joining FDTD electromagnetic analysis with nonlinear circuit analysis. His treatment is application oriented rather than theoretical or historical. Working at Bell Labs, IBM Microelectronics, and Conexant has obviously motivated Dr. Sui toward the practical side of computer-aided design (CAD). This book appears targeted at the professional who uses CAD or develops CAD programs. Each topic is handled in depth, and the book covers a wide range of subjects quickly. This book is not oriented toward classroom'], 'negatives': ['Image registration is the process of matching, aligning and overlaying two or more images of a scene, which are captured from different viewpoints. It is extensively used in numerous vision based applications. Image registration has five main stages: Feature Detection and Description; Feature Matching; Outlier Rejection; Derivation of Transformation Function; and Image Reconstruction. Timing and accuracy of feature-based Image Registration mainly depend on computational efficiency and robustness of the selected feature-detector-descriptor, respectively. Therefore, choice of feature-detector-descriptor is a critical decision in feature-matching applications. This article presents a comprehensive comparison of SIFT, SURF, KAZE, AKAZE, ORB, and BRISK algorithms. It also elucidates a critical dilemma: Which algorithm is more invariant to scale, rotation and viewpoint changes? To investigate this problem, image matching has been performed with these features to match the scaled versions (5% to 500%), rotated versions (0° to 360°), and perspective-transformed versions of standard images with the original ones. Experiments have been conducted on diverse images taken from benchmark datasets: University of OXFORD, MATLAB, VLFeat, and OpenCV. Nearest-Neighbor-Distance-Ratio has been used as the feature-matching strategy while RANSAC has been applied for rejecting outliers and fitting the transformation models. Results are presented in terms of quantitative comparison, feature-detection-description time, feature-matching time, time of outlier-rejection and model fitting, repeatability, and error in recovered results as compared to the ground-truths. SIFT and BRISK are found to be the most accurate algorithms while ORB and BRISK are most efficient. The article comprises rich information that will be very useful for making important decisions in vision based applications and main aim of this work is to set a benchmark for researchers, regardless of any particular area.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We analyze the design space for implementing the Constrained Application Protocol (CoAP) within Content-Centric Networks (CCN), identifying several CoAP specific scenarios and seeing how they map to CCNs. We present an evaluation, recommendations for implementations and extensions, and directions for future work. Our key result is that while several protocol features and flows map naturally, some communication patterns are more difficult to capture without modifications or additions to the CCN model. In addition to many conceptual and also non-performance related advantages, our experimental evaluation demonstrates that it is feasible and useful to implement CoAP over CCN, with the performance similar to that of CoAP over UDP over IP, and in several cases outperforming it significantly.', 'positives': [\"The Named Data Networking (NDN) project is emerging as one of the most promising information-centric future Internet architectures. Besides NDN recognized potential as a content retrieval solution in wired and wireless domains, its innovative concepts, such as named content, name-based routing and in-network caching, particularly suit the requirements of Internet of Things (IoT) interconnecting billions of heterogeneous objects. IoT highly differs from today's Internet due to resource-constrained devices, massive volumes of small exchanged data, and traffic type diversity. The study in this paper addresses the design of a high-level NDN architecture, whose main components are overhauled to specifically meet the IoT challenges.\"], 'negatives': ['In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Algorithm selection and configuration is a challenging problem in the continuous optimization domain. An approach to tackle this problem is to develop a model that links landscape analysis measures and algorithm parameters to performance. This model can be then used to predict algorithm performance when a new optimization problem is presented. In this paper, we investigate the use of a machine learning framework to build such a model. We demonstrate the effectiveness of our technique using CMA-ES as a representative algorithm and a feed-forward backpropagation neural network as the learning strategy. Our experimental results show that we can build sufficiently accurate predictions of an algorithm’s expected performance. This information is used to rank the algorithm parameter settings based on the current problem instance, hence increasing the probability of selecting the best configuration for a new problem.', 'positives': ['A major unsolved problem in the field of optimisation and computational intelligence is how to determine which algorithms are best suited to solving which problems. This research aims to analytically characterise individual problems as a first step towards attempting to link problem types with the algorithms best suited to solving them. In particular, an information theoretic technique for analysing the ruggedness of a fitness landscape with respect to neutrality was adapted to work in continuous landscapes and to output a single measure of ruggedness. Experiments run on test functions with increasing ruggedness show that the proposed measure of ruggedness produced relative values consistent with a visual inspection of the problem landscapes. Combined with other measures of complexity, the proposed ruggedness measure could be used to more broadly characterise the complexity of fitness landscapes in continuous domains.'], 'negatives': ['Various techniques for statistical analysis of the structure of fitness landscapes have been proposed. An important feature of these techniques is that they study the ruggedness of landscapes by measuring their correlation characteristics. This paper proposes a new information analysis of fitness landscapes. The underlying idea is to consider a fitness landscape as an ensemble of objects that are related to the fitness of neighboring points. Three information characteristics of the ensemble are defined and studied. They are termed: information content, partial information content, and information stability. The information characteristics of a range of landscapes with known correlation features are analyzed in an attempt to reveal the advantages of the information analysis. We show that the proposed analysis is an appropriate tool for investigating the structure of fitness landscapes.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Security has been one of the major concerns for the computer network community due to resource abuse and malicious flows intrusion. Before a network or a system is attacked, a port scan is typically performed to discover vulnerabilities, like open ports, which may be used to access and control them. Several studies have addressed Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS) methods for detecting malicious activities, based on received flows or packet data analysis. However, those methods lead to an increase in switching latency, due to the need to analyze flows or packets before routing them. This may also increase network overhead when flows or packets are duplicated to be parsed by an external IDS. On the one hand, an IDS/IPS may be a bottleneck on the network and may not be useful. On the other hand, the new paradigm called Software Defined Networking (SDN) and the OpenFlow protocol provide some statistical information about the network that may be used for detecting malicious activities. Hence, this work presents a new port scan IPS for SDN based on the OpenFlow switch counters data. A non-intrusive and lightweight method was developed and implemented, with low network overhead, and low memory and processing power consumption. The results showed that our method is effective on detecting and preventing port scan attacks.', 'positives': ['Cyber attack is a sensitive issue in the world of Internet security. Governments and business organisations around the world are providing enormous effort to secure their data. They are using various types of tools and techniques to keep the business running, while adversaries are trying to breach security and send malicious software such as botnets, viruses, trojans etc., to access valuable data. Everyday the situation is getting worse because of new types of malware emerging to attack networks. It is important to understand those attacks both before and after they happen in order to provide better security to our systems. Understanding attack models provide more insight into network vulnerability, which in turn can be used to protect the network from future attacks. In the cyber security world, it is difficult to predict a potential attack without understanding the vulnerability of the network. So, it is important to analyse the network to identify top possible vulnerability list, which will give an intuitive idea to protect the network. Also, handling an ongoing attack poses significant risk on the network and valuable data, where prompt action is necessary. Proper utilisation of attack modelling techniques provide advance planning, which can be implemented rapidly during an ongoing attack event. This paper aims to analyse various types of existing attack modelling techniques to understand the vulnerability of the network, and the behaviour and goals of the adversary. The ultimate goal is to handle cyber attack in efficient manner using attack modelling techniques.'], 'negatives': ['iii'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Part detection is an important aspect of object recognition. Most approaches apply object proposals to generate hundreds of possible part bounding box candidates which are then evaluated by part classifiers. Recently several methods have investigated directly regressing to a limited set of bounding boxes from deep neural network representation. However, for object parts such methods may be unfeasible due to their relatively small size with respect to the image. We propose a hierarchical method for object and part detection. In a single network we first detect the object and then regress to part location proposals based only on the feature representation inside the object. Experiments show that our hierarchical approach outperforms a network which directly regresses the part locations. We also show that our approach obtains part detection accuracy comparable or better than state-of-the-art on the CUB-200 bird and Fashionista clothing item datasets with only a fraction of the number of part proposals.', 'positives': ['The use of object proposals is an effective recent approach for increasing the computational efficiency of object detection. We propose a novel method for generating object bounding box proposals using edges. Edges provide a sparse yet informative representation of an image. Our main observation is that the number of contours that are wholly contained in a bounding box is indicative of the likelihood of the box containing an object. We propose a simple box objectness score that measures the number of edges that exist in the box minus those that are members of contours that overlap the box’s boundary. Using efficient data structures, millions of candidate boxes can be evaluated in a fraction of a second, returning a ranked set of a few thousand top-scoring proposals. Using standard metrics, we show results that are significantly more accurate than the current state-of-the-art while being faster to compute. In particular, given just 1000 proposals we achieve over 96% object recall at overlap threshold of 0.5 and over 75% recall at the more challenging overlap of 0.7. Our approach runs in 0.25 seconds and we additionally demonstrate a near real-time variant with only minor loss in accuracy.'], 'negatives': ['This study was conducted to examine different factors influencing the academic performance of secondary school students in a metropolitan city of Pakistan. The respondents for this study were 10th grade students (300 male & 300 female). A survey was conducted by using a questionnaire for information gathering about different factors relating to academic performance of students. The academic performance was gauged by the result of their 9th grade annual examination. Standard t-test and ANOVA were applied to investigate the effect of different factors on students’ achievement. The results of the study revealed that socioeconomic status (SES) and parents’ education have a significant effect on students’ overall academic achievement as well as achievement in the subjects of Mathematics and English. The high and average socio-economic level affects the performance more than the lower level. It is very interesting that parents’ education means more than their occupation in relation to their children’s academic performance at school. It was found that girls perform better than the male students.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Emerging high-performance storage devices have attractive features such as low latency and high throughput. This leads to a rapid increase in the demand for fast storage devices in cloud platforms, social network services, etc. However, there are few block-based file systems that are capable of utilizing superior characteristics of fast storage devices. In this paper, we find that the I/O strategy of modern operating systems prevents file systems from exploiting fast storage devices. To address this problem, we propose several optimization techniques for block-based file systems. Then, we apply our techniques to two well-known file systems and evaluate them with multiple benchmarks. The experimental results show that our optimized file systems achieve 32% on average and up to 54% better performance than existing file systems.', 'positives': ['Persistent, user-defined objects present an attractive abstraction for working with non-volatile program state. However, the slow speed of persistent storage (i.e., disk) has restricted their design and limited their performance. Fast, byte-addressable, non-volatile technologies, such as phase change memory, will remove this constraint and allow programmers to build high-performance, persistent data structures in non-volatile storage that is almost as fast as DRAM. Creating these data structures requires a system that is lightweight enough to expose the performance of the underlying memories but also ensures safety in the presence of application and system failures by avoiding familiar bugs such as dangling pointers, multiple free()s, and locking errors. In addition, the system must prevent new types of hard-to-find pointer safety bugs that only arise with persistent objects. These bugs are especially dangerous since any corruption they cause will be permanent.\\n We have implemented a lightweight, high-performance persistent object system called NV-heaps that provides transactional semantics while preventing these errors and providing a model for persistence that is easy to use and reason about. We implement search trees, hash tables, sparse graphs, and arrays using NV-heaps, BerkeleyDB, and Stasis. Our results show that NV-heap performance scales with thread count and that data structures implemented using NV-heaps out-perform BerkeleyDB and Stasis implementations by 32x and 244x, respectively, by avoiding the operating system and minimizing other software overheads. We also quantify the cost of enforcing the safety guarantees that NV-heaps provide and measure the costs of NV-heap primitive operations.'], 'negatives': [\"PURPOSE\\nStudies of penile length in children have been rarely conducted. In Korea, great improvements in height and weight have been observed because of economic development over the past 25 years. We investigated the current status of penile length in Korean children and compared the results with those of a previous Korean study conducted in 1987.\\n\\n\\nMATERIALS AND METHODS\\nThe subjects in this study were 233 boys aged 1 to 158 months, each of whom had been brought to outpatient clinics between April and October 2011. Penile length was measured according to the stretched penile length (SPL) technique; testicular size was measured (in ml) by using orchidometry. A comparison of penile lengths between the current study and the 1987 study was made by using Student's t-test.\\n\\n\\nRESULTS\\nSPL increased significantly by 0.7 to 1.1 cm in most age groups (p<0.05). Current anthropometric measures of Korean children such as height, body weight, and testicular size have increased compared with those from 1987.\\n\\n\\nCONCLUSIONS\\nPenile length has increased significantly over the last quarter century. Therefore, it is suggested that novel reference values for penile length in prepubertal Korean children be determined in studies with a larger community-based population in order to diagnose and treat size-related penile disorders.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Because main memory is vulnerable to errors and failures, large-scale systems and critical servers utilize error checking and correcting (ECC) mechanisms to meet their reliability requirements. We propose a novel mechanism, Frugal ECC (FECC), that combines ECC with fine-grained compression to provide versatile protection that can be both stronger and lower overhead than current schemes, without sacrificing performance. FECC compresses main memory at cache-block granularity, using any left over space to store ECC information. Compressed data and its ECC information are then frequently read with a single access even without redundant memory chips; insufficiently compressed blocks require additional storage and accesses. As examples, we present chipkill-correct ECCs on a non-ECC DIMM with x4 chips and the first true chipkill-correct ECC for x8 devices using an ECC DIMM. FECC relies on a new Coverage-oriented-Compression that we developed specifically for the modest compression needs of ECC and for floating-point data.', 'positives': [\"Several recent publications have shown that hardware faults in the memory subsystem are commonplace. These faults are predicted to become more frequent in future systems that contain orders of magnitude more DRAM and SRAM than found in current memory subsystems. These memory subsystems will need to provide resilience techniques to tolerate these faults when deployed in high-performance computing systems and data centers containing tens of thousands of nodes. Therefore, it is critical to understand the efficacy of current hardware resilience techniques to determine whether they will be suitable for future systems. In this paper, we present a study of DRAM and SRAM faults and errors from the field. We use data from two leadership-class high-performance computer systems to analyze the reliability impact of hardware resilience schemes that are deployed in current systems. Our study has several key findings about the efficacy of many currently deployed reliability techniques such as DRAM ECC, DDR address/command parity, and SRAM ECC and parity. We also perform a methodological study, and find that counting errors instead of faults, a common practice among researchers and data center operators, can lead to incorrect conclusions about system reliability. Finally, we use our data to project the needs of future large-scale systems. We find that SRAM faults are unlikely to pose a significantly larger reliability threat in the future, while DRAM faults will be a major concern and stronger DRAM resilience schemes will be needed to maintain acceptable failure rates similar to those found on today's systems.\"], 'negatives': ['This letter proposes an asymmetrical hybrid optical orthogonal frequency division multiplexing (AHO-OFDM) scheme for dimmable visible light communication systems. In the proposed scheme, either asymmetrically clipped optical OFDM (ACO-OFDM) or pulse-amplitude-modulated discrete multitone (PAM-DMT) signal is inverted and then both the signals are combined for transmission, where pulsewidth modulation is no longer required for dimming control. The power of ACO-OFDM and PAM-DMT signals is adjusted so that the amplitude of the combined AHO-OFDM signal is asymmetrical, which could utilize all the available subcarriers as well as the entire dynamic range of light-emitting diodes with various dimming levels. Simulation results show that the proposed scheme could achieve a wide dimming range with a small throughput fluctuation.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, we propose a deep learning framework for malware classification. There has been a huge increase in the volume of malware in recent years which poses a serious security threat to financial institutions, businesses and individuals. In order to combat the proliferation of malware, new strategies are essential to quickly identify and classify malware samples so that their behavior can be analyzed. Machine learning approaches are becoming popular for classifying malware, however, most of the existing machine learning methods for malware classification use shallow learning algorithms (e.g. SVM). Recently, Convolutional Neural Networks (CNN), a deep learning approach, have shown superior performance compared to traditional learning algorithms, especially in tasks such as image classification. Motivated by this success, we propose a CNN-based architecture to classify malware samples. We convert malware binaries to grayscale images and subsequently train a CNN for classification. Experiments on two challenging malware classification datasets, Malimg and Microsoft malware, demonstrate that our method achieves better than the state-of-the-art performance. The proposed method achieves 98.52% and 99.97% accuracy on the Malimg and Microsoft datasets respectively.', 'positives': ['In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category.'], 'negatives': ['Platelet rich plasma (PRP) has been utilized in regenerative dentistry as a supra-physiological concentrate of autologous growth factors capable of stimulating tissue regeneration. Despite this, concerns have been expressed regarding the use of anti-coagulants, agents known to inhibit wound healing. In this study, a liquid formulation of platelet rich fibrin (PRF) termed injectable-PRF (i-PRF) without the use of anti-coagulants was investigated. Standard PRP and i-PRF (centrifuged at 700\\xa0rpm (60G) for 3\\xa0min) were compared for growth factor release up to 10\\xa0days (8 donor samples). Furthermore, fibroblast biocompatibility at 24\\xa0h (live/dead assay); migration at 24\\xa0h; proliferation at 1, 3, and 5\\xa0days, and expression of PDGF, TGF-β, and collagen1 at 3 and 7\\xa0days were investigated. Growth factor release demonstrated that in general PRP had higher early release of growth factors whereas i-PRF showed significantly higher levels of total long-term release of PDGF-AA, PDGF-AB, EGF, and IGF-1 after 10\\xa0days. PRP showed higher levels of TGF-β1 and VEGF at 10\\xa0days. While both formulations exhibited high biocompatibility and higher fibroblast migration and proliferation when compared to control tissue-culture plastic, i-PRF induced significantly highest migration whereas PRP demonstrated significantly highest cellular proliferation. Furthermore, i-PRF showed significantly highest mRNA levels of TGF-β at 7\\xa0days, PDGF at 3\\xa0days, and collagen1 expression at both 3 and 7\\xa0days when compared to PRP. i-PRF demonstrated the ability to release higher concentrations of various growth factors and induced higher fibroblast migration and expression of PDGF, TGF-β, and collagen1. Future animal research is now necessary to further validate the use of i-PRF as a bioactive agent capable of stimulating tissue regeneration. The findings from the present study demonstrate that a potent formulation of liquid platelet concentrates could be obtained without use of anti-coagulants.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Simulated binary crossover (SBX) is a real-parameter recombinationoperator which is commonly used in the evolutionary algorithm (EA) literature. The operatorinvolves a parameter which dictates the spread of offspring solutionsvis-a-vis that of the parent solutions. In all applications of SBX sofar, researchers have kept a fixed value throughout a simulation run. In this paper, we suggest a self-adaptive procedure of updating theparameter so as to allow a smooth navigation over the functionlandscape with iteration. Some basic principles of classicaloptimization literature are utilized for this purpose. The resultingEAs are found to produce remarkable and much better results comparedto the original operator having a fixed value of the parameter. Studieson both single and multiple objective optimization problems are madewith success.', 'positives': ['Multiobjective evolutionary algorithms (EAs) that use nondominated sorting and sharing have been criticized mainly for their: 1) ( ) computational complexity (where is the number of objectives and is the population size); 2) nonelitism approach; and 3) the need for specifying a sharing parameter. In this paper, we suggest a nondominated sorting-based multiobjective EA (MOEA), called nondominated sorting genetic algorithm II (NSGA-II), which alleviates all the above three difficulties. Specifically, a fast nondominated sorting approach with ( ) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best (with respect to fitness and spread) solutions. Simulation results on difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to Pareto-archived evolution strategy and strength-Pareto EA—two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multiobjective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective seven-constraint nonlinear problem, are compared with another constrained multiobjective optimizer and much better performance of NSGA-II is observed.'], 'negatives': ['The autonomic nervous system (ANS) plays a critical role in emotion, providing metabolic support for adaptive action, generating appearance changes with high signal value for conspecifics, and producing visceral sensations that shape subjective emotional experience. In this chapter, I consider several of the most important ways that the ANS is involved in emotion, including: (a) peripheral activation of emotion; (b) autonomic influences on emotional language and the labeling of subjective emotional experience; (c) positive emotion and autonomic soothing; (d) expressive signs of autonomic origin; (e) autonomic substrates of emotional contagion and empathy; and (f) autonomic consequences of emotion regulation. For each, I describe relevant research from our laboratory and discuss implications for an evolutionary account of emotion. In these and many other ways the autonomic architecture of human emotion has evolved not only to move blood and tears in the service of fears, but also to provide us with a rich set of tools that help us communicate and signal the nature of our internal emotional experiences, understand the emotions of others, calm ourselves and others, and give us some modicum of control over harmful and unproductive emotions.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Priya Bijlani MDS prosthodontics Associate professor, Department of Dentistry, K J Somaiya Medical College and Research Centre, Mumbai Planning of the prosthetic design in implant supported rehabilitations is based on the anatomical situation, patient’s esthetic and functional requirements and economics. The goal of treatment must be to offer an optimum restorative solution with minimum surgical morbidity. This article presents numeric guidelines aimed at helping the clinician for making a prudent choice of restorative material and design in implant prosthodontics.', 'positives': ['The predictability of successful osseointegrated implant rehabilitation of the edentulous jaw as described by Branemark et al., introduced a new era of management for the edentulous predicament. Implant rehabilitation of the edentulous maxilla remains one of the most complex restorative challenges because of the number of variables that affect both the aesthetic and functional aspect of the prosthesis. Among the prosthesis designs used to treat the edentulous maxilla are fixed or removable implant-supported restorations. Since the aesthetic requirements and preoperative situation of each patient varies, considerable time must be spent on accurate diagnosis to ensure patient desires are satisfied and predictable outcomes are achieved. The purpose of this article is to compare the treatment options and prosthesis designs for the edentulous maxilla. Emphasis will be placed on diagnosis and treatment planning. Criteria will be given to guide the practitioner in deciding whether a fixed or removable restoration should be placed. This objective will be accomplished through the review of cases with regard to varying design considerations and factors that influence the decision-making process.'], 'negatives': ['Since the development of fast imaging sequences, MR has proved to be a helpful tool in the evaluation of fetal pathology. Because of the high water content of fetal tissues and pathology, hydrography imaging (MR fetography) can provide additional diagnostic information. To demonstrate the benefit of MR fetography in fetal imaging. From 2004 to 2005, 126 fetal MR examinations were performed for evaluation of an abnormality depicted on an antenatal sonogram. Single-shot fast spin-echo MR imaging and MR fetography were performed through the area of fetal pathology. The two studies were retrospectively compared. The primary diagnosis was not changed with the addition of MR fetography. New findings, particularly in the kidneys and spine, were identified in 9% of the patients. When fetal pathology was of high water content (80% patients), the MR fetography imaging increased diagnostic confidence. In 11% of the patients, those with cardiovascular or low water pathology, the MR fetography was not beneficial. The mainstay of fetal imaging is currently the HASTE and SSFSE sequences. However, MR fetography is an excellent adjunct that highlights fetal pathology by reinforcing the diagnosis, identifying additional findings, and providing high-contrast high-resolution images that are helpful when counseling clinicians and patients.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.', 'positives': ['Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD) is a technique for calculating derivatives of numeric functions expressed as computer programs efficiently and accurately, used in fields such as computational fluid dynamics, nuclear engineering, and atmospheric sciences. Despite its advantages and use in other fields, machine learning practitioners have been little influenced by AD and make scant use of available tools. We survey the intersection of AD and machine learning, cover applications where AD has the potential to make a big impact, and report on some recent developments in the adoption of this technique. We aim to dispel some misconceptions that we contend have impeded the use of AD within the machine learning community.'], 'negatives': ['We use a stochastic approach in order to investigate the production and evolution of aerosols in Titan’s atmosphere. The simulation initiates from the benzene molecules observed in the thermosphere and follows their evolution to larger aromatic structures through reaction with gas phase radical species. Aromatics are allowed to collide and provide the first primary particles, which further grow to aggregates through coagulation. We also consider for the first time the contribution of heterogenous processes at the surface of the particles, which are described by the deposition of the formed aromatic structures on the surface of the particles, and also through the chemical reaction with radical species. Our results demonstrate that the evolution of aerosols in terms of size, shape, and density is a result of competing processes between surface growth, coagulation and sedimentation. Furthermore, our simulations clearly demonstrate the presence of a spherical growth region in the upper atmosphere followed by a transition to an aggregate growth region below. The transition altitude ranges between 500 and 600 km based on the parameters of the simulation.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Applications are increasingly expected to make smart decisions based on what humans consider basic commonsense. An often overlooked but essential form of commonsense involves comparisons, e.g. the fact that bears are typically more dangerous than dogs, that tables are heavier than chairs, or that ice is colder than water. In this paper, we first rely on open information extraction methods to obtain large amounts of comparisons from the Web. We then develop a joint optimization model for cleaning and disambiguating this knowledge with respect to WordNet. This model relies on integer linear programming and semantic coherence scores. Experiments show that our model outperforms strong baselines and allows us to obtain a large knowledge base of disambiguated commonsense assertions.', 'positives': ['Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.'], 'negatives': ['Many corpus-based natural language processing systems rely on text corpora that have been manually annotated with syntactic or semantic tags. In particular, all previous dictionary construction systems for information extraction have used an annotated training corpus or some form of annotated input. We have developed a system called AutoSlog-TS that creates dictionaries of extraction patterns using only untagged text. AutoSlog-TS is based on the AutoSlog system, which generated extraction patterns using annotated text and a set of heuristic rules. By adapting AutoSlog and combining it with statistical techniques, we eliminated its dependency on tagged text. In experiments with the MUG-4 terrorism domain, AutoSlogTS created a dictionary of extraction patterns that performed comparably to a dictionary created by AutoSlog, using only preclassified texts as input.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Direct visual odometry and Simultaneous Localization and Mapping (SLAM) methods determine camera poses by means of direct image alignment. This optimizes a photometric cost term based on the Lucas-Kanade method. Many recent works use the brightness constancy assumption in the alignment cost formulation and therefore cannot cope with significant illumination changes. Such changes are especially likely to occur for loop closures in SLAM. Alternatives exist which attempt to match images more robustly. In our paper, we perform a systematic evaluation of real-time capable methods. We determine their accuracy and robustness in the context of odometry and of loop closures, both on real images as well as synthetic datasets with simulated lighting changes. We find that for real images, a Census-based method outperforms the others. We make our new datasets available online3.', 'positives': ['In this paper, we present a novel benchmark for the evaluation of RGB-D SLAM systems. We recorded a large set of image sequences from a Microsoft Kinect with highly accurate and time-synchronized ground truth camera poses from a motion capture system. The sequences contain both the color and depth images in full sensor resolution (640 × 480) at video frame rate (30 Hz). The ground-truth trajectory was obtained from a motion-capture system with eight high-speed tracking cameras (100 Hz). The dataset consists of 39 sequences that were recorded in an office environment and an industrial hall. The dataset covers a large variety of scenes and camera motions. We provide sequences for debugging with slow motions as well as longer trajectories with and without loop closures. Most sequences were recorded from a handheld Kinect with unconstrained 6-DOF motions but we also provide sequences from a Kinect mounted on a Pioneer 3 robot that was manually navigated through a cluttered indoor environment. To stimulate the comparison of different approaches, we provide automatic evaluation tools both for the evaluation of drift of visual odometry systems and the global pose error of SLAM systems. The benchmark website [1] contains all data, detailed descriptions of the scenes, specifications of the data formats, sample code, and evaluation tools.'], 'negatives': ['While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called \"perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'While many active learning papers assume that the learner can simply ask for a label and receive it, real annotation often presents a mismatch between the form of a label (say, one among many classes), and the form of an annotation (typically yes/no binary feedback). To annotate examples corpora for multiclass classification, we might need to ask multiple yes/no questions, exploiting a label hierarchy if one is available. To address this more realistic setting, we propose active learning with partial feedback (ALPF), where the learner must actively choose both which example to label and which binary question to ask. At each step, the learner selects an example, asking if it belongs to a chosen (possibly composite) class. Each answer eliminates some classes, leaving the learner with a partial label. The learner may then either ask more questions about the same example (until an exact label is uncovered) or move on immediately, leaving the first example partially labeled. Active learning with partial labels requires (i) a sampling strategy to choose (example, class) pairs, and (ii) learning from partial labels between rounds. Experiments on Tiny ImageNet demonstrate that our most effective method improves 26% (relative) in top-1 classification accuracy compared to i.i.d. baselines and standard active learners given 30% of the annotation budget that would be required (naively) to annotate the dataset. Moreover, ALPF-learners fully annotate TinyImageNet at 42% lower cost. Surprisingly, we observe that accounting for per-example annotation costs can alter the conventional wisdom that active learners should solicit labels for hard examples.', 'positives': ['We demonstrate that cons&g optimal binary de&ion trees ia an NP=compkt.e probtem, where an op timal tree is one which minin&s the expected number c: teats required to identuy the unknown object. Precise defu\\\\ltons of NP-compkte problems are given in refs. f 1.2.41. while the proof to be given is relatively simple, the importance of this result can be measured in terms of the Jarge amount of effort that has been put into fmding efftient aJgorJthms for constructing optimal binary decision trees (see (3,5,6) and their references). Thus at present we may conjecture that no such efficient dgodhm exists (cm the supposition tit P# NP), thereby suppIying motivation for finding efficient hetitics for constructing nearsptimal decision trees.'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Rehabilitation for stroke afflicted patients, through exercises tailored for individual needs, aims at relearning basic motor skills, especially in the extremities. Rehabilitation through Augmented Reality (AR) based games engage and motivate patients to perform exercises which, otherwise, maybe boring and monotonic. Also, mirror therapy allows users to observe one's own movements in the game providing them with good visual feedback. This paper presents an augmented reality based system for rehabilitation by playing four interactive, cognitive and fun Exergames (exercise and gaming).\\n The system uses low-cost RGB-D cameras such as Microsoft Kinect V2 to capture and generate 3D model of the person by extracting him/her from the entire captured data and immersing it in different interactive virtual environments. Animation based limb movement enhancement along with cognitive aspects incorporated in the game can help in positive reinforcement, progressive challenges and motion improvement. Recording module of the toolkit allows future reference and facilitates feedback from the physician. 10 able-bodied users, 2 psychological experts and 2 Physical Medicine and Rehabilitation physicians evaluated the user experience and usability aspects of the exergames. Results obtained shows the games to be fun and realistic, and at the same time engaging and motivating for performing exercises.\", 'positives': [\"This paper presents a novel system architecture and evaluation metrics for an Adaptive Mixed Reality Rehabilitation (AMRR) system for stroke patient. This system provides a purposeful, engaging, hybrid (visual, auditory and physical) scene that encourages patients to improve their performance of a reaching and grasping task and promotes learning of generalizable movement strategies. This system is adaptive in that it provides assistive adaptation tools to help the rehabilitation team customize the training strategy. Our key insight is to combine the patients, rehabilitation team, multimodal hybrid environments and adaptation tools together as an adaptive experiential mixed reality system.\\n There are three major contributions in this paper: (a) developing a computational deficit index for evaluating the patient's kinematic performance and a deficit-training-improvement (DTI) correlation for evaluating adaptive training strategy, (b) integrating assistive adaptation tools that help the rehabilitation team understand the relationship between the patient's performance and training and customize the training strategy, and (c) combining the interactive multimedia environment and physical environment together to encourage patients to transfer movement knowledge from media space to physical space. Our system has been used by two stroke patients for one-month mediated therapy. They have significant improvement in their reaching and grasping performance (+48.84% and +39.29%) compared to other two stroke patients who experienced traditional therapy (-18.31% and -8.06%).\"], 'negatives': ['Data mining techniques are becoming indispensable as the amount and complexity of available data is rapidly growing. Visual data mining techniques attempt to include a human observer in the loop and leverage human perception for knowledge extraction. This is commonly allowed by performing a dimensionality reduction into a visually easy-to-perceive 2D space, which might result in significant loss of important spatial and topological information. To address this issue, this paper presents the design and implementation of a unique 3D visual data mining framework - CAVE-SOM. The CAVE-SOM system couples the Self-Organizing Map (SOM) algorithm with the immersive Cave Automated Virtual Environment (CAVE). The main advantages of the CAVE-SOM system are: i) utilizing a 3D SOM to perform dimensionality reduction of large multi-dimensional datasets, ii) immersive visualization of the trained 3D SOM, iii) ability to explore and interact with the multi-dimensional data in an intuitive and natural way. The CAVE-SOM system uses multiple visualization modes to guide the visual data mining process, for instance the data histograms, U-matrix, connections, separations, uniqueness and the input space view. The implemented CAVE-SOM framework was validated on several benchmark problems and then successfully applied to analysis of wind-power generation data. The knowledge extracted using the CAVE-SOM system can be used for further informed decision making and machine learning.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In recent years there has been explosive growth in the number of neuroimaging studies performed using functional Magnetic Resonance Imaging (fMRI). The field that has grown around the acquisition and analysis of fMRI data is intrinsically interdisciplinary in nature and involves contributions from researchers in neuroscience, psychology, physics and statistics, among others. A standard fMRI study gives rise to massive amounts of noisy data with a complicated spatio-temporal correlation structure. Statistics plays a crucial role in understanding the nature of the data and obtaining relevant results that can be used and interpreted by neuroscientists. In this paper we discuss the analysis of fMRI data, from the initial acquisition of the raw data to its use in locating brain activity, making inference about brain connectivity and predictions about psychological or disease states. Along the way, we illustrate interesting and important issues where statistics already plays a crucial role. We also seek to illustrate areas where statistics has perhaps been underutilized and will have an increased role in the future.', 'positives': ['This article discusses general modeling of multisubject and/or multisession FMRI data. In particular, we show that a two-level mixed-effects model (where parameters of interest at the group level are estimated from parameter and variance estimates from the single-session level) can be made equivalent to a single complete mixed-effects model (where parameters of interest at the group level are estimated directly from all of the original single sessions\\' time series data) if the (co-)variance at the second level is set equal to the sum of the (co-)variances in the single-level form, using the BLUE with known covariances. This result has significant implications for group studies in FMRI, since it shows that the group analysis requires only values of the parameter estimates and their (co-)variance from the first level, generalizing the well-established \"summary statistics\" approach in FMRI. The simple and generalized framework allows different prewhitening and different first-level regressors to be used for each subject. The framework incorporates multiple levels and cases such as repeated measures, paired or unpaired t tests and F tests at the group level; explicit examples of such models are given in the article. Using numerical simulations based on typical first-level covariance structures from real FMRI data we demonstrate that by taking into account lower-level covariances and heterogeneity a substantial increase in higher-level Z score is possible.'], 'negatives': ['Friston et al. (1995, NeuroImage 2:45-53) presented a method for detecting activations in fMRI time-series based on the general linear model and a heuristic analysis of the effective degrees of freedom. In this communication we present corrected results that replace those of the previous paper and solve the same problem without recourse to heuristic arguments. Specifically we introduce a proper and unbiased estimator for the error terms and provide a more generally correct expression for the effective degrees of freedom. The previous estimates of error variance were biased and, in some instances, could have led to a 10-20% overestimate of Z values. Although the previous results are almost correct for the random regressors chosen for validation, the present theoretical results are exact for any covariate or waveform. We comment on some aspects of experimental design and data analysis, in the light of the theoretical framework discussed here.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'This paper describes the first demonstration of a 76 GHz gallium nitride (GaN) power amplifier (PA) on a silicon substrate. The PA microwave monolithic IC (MMIC) was fabricated by using AlGaN/GaN FET with a maximum oscillation frequency of 160GHz and a breakdown voltage of over 50 V. For reducing transmission loss, we used a CPW line on the silicon substrate with low transmission loss of 0.5 dB/mm at 76 GHz. For precise design of the PA, a large signal model of the FET was developed. The developed CPW 3-stage PA exhibited an output of over 12 dBm with over 5 dB gain at 75–81 GHz.', 'positives': ['We present the performance of a 77 GHz power amplifier for potential applications directed towards automotive radar systems. The circuit was fabricated in a SiGe bipolar preproduction technology. A balanced two-stage common emitter circuit topology was used to achieve 6.1 dB of power gain at 77 GHz and 11.6 dBm output power at 1dB compression. The power amplifier uses a single 2.5 V supply and was fully integrated (including matching elements) to demonstrate its low-cost potential. First experimental results show its broadband characteristic from 40 GHz to 80 GHz and its temperature dependence up to 130/spl deg/C.'], 'negatives': ['This paper surveys the available system architectures for cyber-physical systems. Several candidate architectures are examined using a series of essential qualities for cyber-physical systems for healthcare. Next, diagrams detailing the expected functionality of infusion pumps in two of the architectures are analyzed. The STRIDE Threat Model is then used to decompose each to determine possible security issues and how they can be addressed. Finally, a comparison of the major security issues in each architecture is presented to help determine which is most adaptable to meet the security needs of cyber-physical systems in healthcare.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'In this paper, we study the problem of mining temporally anomalous sub-trajectory patterns from an input trajectory in a scalable manner. Given the prevailing road conditions, a sub-trajectory is temporally anomalous if its travel time deviates significantly from the expected time. Mining these patterns requires us to delve into the sub-trajectory space, which is not scalable for real-time analytics. To overcome this scalability challenge, we design a technique called MANTRA. We study the properties unique to anomalous sub-trajectories and utilize them in MANTRA to iteratively refine the search space into a disjoint set of sub-trajectory islands. The expensive enumeration of all possible sub-trajectories is performed only on the islands to compute the answer set of maximal anomalous sub-trajectories. Extensive experiments on both real and synthetic datasets establish MANTRA as more than 3 orders of magnitude faster than baseline techniques. Moreover, through trajectory classification and segmentation, we demonstrate that the proposed model conforms to human intuition.', 'positives': ['An automatic stock market categorization system would be invaluable to individual investors and financial experts, providing them with the opportunity to predict the stock price changes of a company with respect to other companies. In recent years, clustering all companies in the stock markets based on their similarities in the shape of the stock market has increasingly become a common scheme. However, existing approaches are impractical because the stock price data are high-dimensional data and the changes in the stock price usually occur with shift, which makes the categorization more complex. Moreover, no stock market categorization method that can cluster companies down to the sub-cluster level, which are very meaningful to end users, has been developed. Therefore, in this paper, a novel three-phase clustering model is proposed to categorize companies based on the similarity in the shape of their stock markets. First, low-resolution time series data are used to approximately categorize companies. Then, in the second phase, pre-clustered companies are split into some pure sub-clusters. Finally, sub-clusters are merged in the third phase. The accuracy of the proposed method is evaluated using various published data sets in different domains. We show that this approach has good performance in efficiency and effectiveness compared to existing conventional clustering algorithms. There are many works related to stock market analysis includ-Clustering is a data mining technique in which similar data are automatically placed into related groups without advanced knowledge of the group definitions. Clustering of companies in the stock market is very useful for managers, investors, and policy makers. It can be performed based on several factors, such as the size of the companies, their annual profit, and the industry category. For example, Nanda et al. (2010) used the returns of the stock for variable time intervals along with the validation ratios to cluster the companies listed in Bombay Stock Exchange (BSE). However, these features usually change over time; thus, they are improper for categorization purposes. Industry-based categorization is also not preferable due to evidence that financial analysts are biased by industry categorization (Krüger et al., 2012). Conversely, the closing prices of stocks related to each company are stored as time series data. Companies can be categorized by the clustering of their stock price time series. Clustering companies based on the time series of their stock price is particularly advantageous in co-movement assessment. Identifying homogeneous groups of stocks where the movement in one market …'], 'negatives': ['We present an efficient indexing method to locate 1-dimensional subsequences within a collection of sequences, such that the subsequences match a given (query) pattern within a specified tolerance. The idea is to map each data sequences into a small set of multidimensional rectangles in feature space. Then, these rectangles can be readily indexed using traditional spatial access methods, like the R*-tree [9]. In more detail, we use a sliding window over the data sequence and extract its features; the result is a trail in feature space. We propose an efficient and effective algorithm to divide such trails into sub-trails, which are subsequently represented by their Minimum Bounding Rectangles (MBRs). We also examine queries of varying lengths, and we show how to handle each case efficiently. We implemented our method and carried out experiments on synthetic and real data (stock price movements). We compared the method to sequential scanning, which is the only obvious competitor. The results were excellent: our method accelerated the search time from 3 times up to 100 times.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"A guidewire is a medical device inserted into vessels during image guided interventions for balloon inflation. During interventions, the guidewire undergoes non-rigid deformation due to patients' breathing and cardiac motions, and such 3D motions are complicated when being projected onto the 2D fluoroscopy. Furthermore, in fluoroscopy there exist severe image artifacts and other wire-like structures. All these make robust guidewire tracking challenging. To address these challenges, this paper presents a probabilistic framework for robust guidewire tracking. We first introduce a semantic guidewire model that contains three parts, including a catheter tip, a guidewire tip and a guidewire body. Measurements of different parts are integrated into a Bayesian framework as measurements of a whole guidewire for robust guidewire tracking. Moreover, for each part, two types of measurements, one from learning-based detectors and the other from online appearance models, are applied and combined. A hierarchical and multi-resolution tracking scheme is then developed based on kernel-based measurement smoothing to track guidewires effectively and efficiently in a coarse-to-fine manner. The presented framework has been validated on a test set of 47 sequences, and achieves a mean tracking error of less than 2 pixels. This demonstrates the great potential of our method for clinical applications.\", 'positives': ['Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications.'], 'negatives': ['The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection.'], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': 'Real-time information from microblogs like Twitter is useful for different applications such as market research, opinion mining, and crisis management. For many of those messages, location information is required to derive useful insights. Today, however, only around 1% of all tweets are explicitly geotagged. We propose the first multi-indicator method for determining (1) the location where a tweet was created as well as (2) the location of the user’s residence. Our method is based on various weighted indicators, including the names of places that appear in the text message, dedicated location entries, and additional information from the user profile. An evaluation shows that our method is capable of locating 92% of all tweets with a median accuracy of below 30km, as well as predicting the user’s residence with a median accuracy of below 5.1km. With that level of accuracy, our approach significantly outperforms existing work.', 'positives': ['Widespread use of social media during crises has become commonplace, as shown by the volume of messages during the Haiti earthquake of 2010 and Japan tsunami of 2011. Location mentions are particularly important in disaster messages as they can show emergency responders where problems have occurred. This article explores the sorts of locations that occur in disaster-related social messages, how well off-theshelf software identifies those locations, and what is needed to improve automated location identification, called geo-parsing. To do this, we have sampled Twitter messages from the February 2011 earthquake in Christchurch, Canterbury, New Zealand. We annotated locations in messages manually to make a gold standard by which to measure locations identified by a Named Entity Recognition software. The Stanford NER software found some locations that were proper nouns, but did not identify locations that were not capitalized, local streets and buildings, or nonstandard place abbreviations and mis-spellings that are plentiful in microtext. We review how these problems might be solved in software research, and model a readable crisis map that shows crisis location clusters via enlarged place labels.'], 'negatives': [\"BACKGROUND\\nRhamnolipids are potent biosurfactants with high potential for industrial applications. However, rhamnolipids are currently produced with the opportunistic pathogen Pseudomonas aeruginosa during growth on hydrophobic substrates such as plant oils. The heterologous production of rhamnolipids entails two essential advantages: Disconnecting the rhamnolipid biosynthesis from the complex quorum sensing regulation and the opportunity of avoiding pathogenic production strains, in particular P. aeruginosa. In addition, separation of rhamnolipids from fatty acids is difficult and hence costly.\\n\\n\\nRESULTS\\nHere, the metabolic engineering of a rhamnolipid producing Pseudomonas putida KT2440, a strain certified as safety strain using glucose as carbon source to avoid cumbersome product purification, is reported. Notably, P. putida KT2440 features almost no changes in growth rate and lag-phase in the presence of high concentrations of rhamnolipids (> 90 g/L) in contrast to the industrially important bacteria Bacillus subtilis, Corynebacterium glutamicum, and Escherichia coli. P. putida KT2440 expressing the rhlAB-genes from P. aeruginosa PAO1 produces mono-rhamnolipids of P. aeruginosa PAO1 type (mainly C(10):C(10)). The metabolic network was optimized in silico for rhamnolipid synthesis from glucose. In addition, a first genetic optimization, the removal of polyhydroxyalkanoate formation as competing pathway, was implemented. The final strain had production rates in the range of P. aeruginosa PAO1 at yields of about 0.15 g/g(glucose) corresponding to 32% of the theoretical optimum. What's more, rhamnolipid production was independent from biomass formation, a trait that can be exploited for high rhamnolipid production without high biomass formation.\\n\\n\\nCONCLUSIONS\\nA functional alternative to the pathogenic rhamnolipid producer P. aeruginosa was constructed and characterized. P. putida KT24C1 pVLT31_rhlAB featured the highest yield and titer reported from heterologous rhamnolipid producers with glucose as carbon source. Notably, rhamnolipid production was uncoupled from biomass formation, which allows optimal distribution of resources towards rhamnolipid synthesis. The results are discussed in the context of rational strain engineering by using the concepts of synthetic biology like chassis cells and orthogonality, thereby avoiding the complex regulatory programs of rhamnolipid production existing in the natural producer P. aeruginosa.\"], 'type': 'sts_triplet', 'source_id': 6}\n",
            "{'query': \"Insurance Policy Transfer Act - Requires an insurer to notify a policyholder before the insurer enters into a transfer agreement or transfers the policyholder's insurance contract to another insurer, provided that such requirement shall not apply to: (1) a transfer agreement or transaction in which the transferring insurer continues to remain directly liable for its insurance obligations, risks, or both, under the insurance contracts subject to the transfer agreement; (2) the substitution of one insurer for another upon the expiration of insurance coverage pursuant to statutory or contractual requirements and the issuance of a new insurance contract by another insurer; (3) the transfer of insurance contracts pursuant to mergers or consolidations of two or more insurers to the extent that those transactions are regulated by the laws of the affected State or States; and (4) an insurer subject to a judicial order of liquidation or rehabilitation. Sets forth provisions regarding the form and content of such notice. Requires the written consent of the policyholder or a beneficiary before an insurer can enter into a transfer agreement or transfer an insurance contract pursuant to a transfer agreement unless: (1) the transferring insurer and the assuming insurer are rated by the same three insurance company rating organizations for each of the three years immediately preceding the transfer; (2) such rating is the highest possible rating or is a higher rating than the transferring insurer; and (3) the policyholder or beneficiary has been provided with the required notice between February 28 and May 1 of each of the three years immediately preceding the transfer and has not responded to the notice with an objection to the transfer or transaction within 90 days after the third notice is sent. Allows the policyholder or the Attorney General to bring an action for relief in the appropriate United States district court if an insurer violates this Act. Empowers the district court to grant such relief as is necessary or appropriate to redress a violation of this Act, including permanent or temporary injunctive relief, compensatory damages, punitive damages, and costs, including reasonable attorney's fees.\", 'positives': [\"It is the purpose of this Act to prohibit the transfer and novation of a contract of insurance without the prior informed written consent of the policyholder. SEC. 3. DEFINITIONS. As used in this Act: (1) Assuming insurer.--The term ``assuming insurer'' means an insurer that assumes an insurance obligation or risk, or both, from a transferring insurer pursuant to a transfer agreement. (2) Transferring insurer.--The term ``transferring insurer'' means an insurer that transfers insurance obligations or risks, or both, of existing or in-force contracts of insurance to an assuming insurer pursuant to a transfer agreement. (3) Transfer agreement.--The term ``transfer agreement'' means a contract that-- (A) transfers insurance obligations or risks, or both, of existing or in-force contracts of insurance from a transferring insurer to an assuming insurer; and (B) is intended to effect a novation of the transferred contract of insurance with the result that-- (i) the assuming insurer becomes directly liable to the policyholders of the transferring insurer; and (ii) the insurance obligations or risks, or both, of the transferring insurer under the contract are extinguished. (4) Contract of insurance.--The term ``contract of insurance'' means a written agreement between an insurer and a policyholder pursuant to which the insurer, in exchange for a premium or other consideration, agrees to assume an obligation or risk, or both, of the policyholder, or to make payments on behalf of, or to, the policyholder or his or her beneficiaries. The term includes all property, casualty, life, health, accident, surety, title, and annuity business authorized to be written pursuant to the laws of any State. SEC. 4. NOTICE. (a) Requirement.--Except as provided in section 6, no insurer shall enter into a transfer agreement or transfer a contract of insurance pursuant to a transfer agreement unless the transferring insurer has first provided or caused to be provided to each policyholder of the insurer affected by the agreement a notice of the intent of the insurer to transfer the contract of insurance held by such policyholder in accordance with this section. (b) Form of Notice.--The notice shall be sent by first-class mail, addressed to the last known address of the policyholder or to the address to which premium notices or other policy documents are sent or, with respect to home service business, by personal delivery with acknowledged receipt. A notice of intent to transfer shall also be sent to the transferring insurer's agent or broker of record on the affected policy. (c) Content of Notice.--The notice required by subsection (a) shall state or provide-- (1) the date the intended transfer and novation of the contract of insurance of the policyholder is proposed to take place and become effective; (2) the name, address, and telephone number of the transferring insurer and the assuming insurer under the proposed transfer agreement; (3) that the transfer and novation of the insurance contract of the policyholder cannot take effect without the written consent of the policyholder, except as provided in section 5 of this Act; (4) the procedures and any time limitation for consenting to the transfer and novation; (5) a summary informing the policyholder regarding any adverse effect that the policyholder might experience as a result of consenting to the transfer and novation; (6) a statement that, without the written consent of the policyholder, the transferring insurer will remain as the insurance company of the policyholder or beneficiary, except as provided in section 5 of this Act; (7) a statement that the assuming insurer is licensed to write the type of business being transferred in the State where the policyholder resides, or is otherwise authorized, under applicable law, to assume such business; (8) the name, address, and telephone number of the person designated by t\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Safe and Secure Federal Websites Act of 2014 - (Sec. 2) Prohibits a federal agency from deploying or making available to the public a new federal personally identifiable information website (new Federal PII Website) until the chief information officer of the agency submits a certification to Congress that the website is fully functional and secure, as those terms are defined by this Act. Defines \"new Federal PII website\" as a website that: (1) is operated by (or under contract with) an agency; (2) elicits, collects, stores, or maintains personally identifiable information (i.e., information that can be used to identify an individual, such as a social security number, a date and place of birth, a mother\\'s maiden name, biometric records, or other information linked to an individual); and (3) is first made accessible to the public and collects or stores personally identifiable information on or after October 1, 2012. Exempts beta websites designed for testing and development if users execute an agreement acknowledging the risks involved. (Sec. 3) Directs the Director of the Office of Management and Budget (OMB) to establish and oversee policies and procedures for federal agencies to follow in the event of a breach of information security involving the disclosure of personally identifiable information, including: (1) notice, not later than 72 hours after discovery of a breach or possible breach, to individuals whose personally identifiable information could be compromised as a result of such breach; (2) timely reporting to a federal cyber security center designated by this Act; and (3) any additional actions that the Director finds necessary and appropriate. Requires: (1) agency heads to ensure that agency actions taken in response to a breach comply with OMB policies and procedures established by this Act; and (2) the OMB Director to report to Congress, not later than March 1 of each year, on agency compliance with such policies and procedures.', 'positives': [\"(a) Certification Requirement.-- (1) In general.--Except as otherwise provided under this subsection, an agency may not deploy or make available to the public a new Federal PII website until the date on which the chief information officer of the agency submits a certification to Congress that the website is fully functional and secure. (2) Transition.--In the case of a new Federal PII website that is operational on the date of the enactment of this Act, paragraph (1) shall not apply until the end of the 90-day period beginning on such date of enactment. If the certification required under paragraph (1) for such website has not been submitted to Congress before the end of such period, the head of the responsible agency shall render the website inaccessible to the public until such certification is submitted to Congress. (3) Exception for beta website with explicit permission.-- Paragraph (1) shall not apply to a website (or portion thereof) that is in a development or testing phase, if the following conditions are met: (A) A member of the public may access PII-related portions of the website only after executing an agreement that acknowledges the risks involved. (B) No agency compelled, enjoined, or otherwise provided incentives for such a member to access the website for such purposes. (4) Construction.--Nothing in this section shall be construed as applying to a website that is operated entirely by an entity (such as a State or locality) that is independent of the Federal Government, regardless of the receipt of funding in support of such website from the Federal Government. (b) Definitions.--In this section: (1) Agency.--The term ``agency'' has the meaning given that term under section 551 of title 5, United States Code. (2) Fully functional.--The term ``fully functional'' means, with respect to a new Federal PII website, that the website can fully support the activities for which it is designed or intended with regard to the eliciting, collection, storage, or maintenance of personally identifiable information, including handling a volume of queries relating to such information commensurate with the purpose for which the website is designed. (3) New federal personally identifiable information website (new federal pii website).--The terms ``new Federal personally identifiable information website'' and ``new Federal PII website'' mean a website that-- (A) is operated by (or under a contract with) an agency; (B) elicits, collects, stores, or maintains personally identifiable information of individuals and is accessible to the public; and (C) is first made accessible to the public and collects or stores personally identifiable information of individuals, on or after October 1, 2012. (4) Operational.--The term ``operational'' means, with respect to a website, that such website elicits, collects, stores, or maintains personally identifiable information of members of the public and is accessible to the public. (5) Personally identifiable information (pii).--The terms ``personally identifiable information'' and ``PII'' mean any information about an individual elicited, collected, stored, or maintained by an agency, including-- (A) any information that can be used to distinguish or trace the identity of an individual, such as a name, a social security number, a date and place of birth, a mother's maiden name, or biometric records; and (B) any other information that is linked or linkable to an individual, such as medical, educational, financial, and employment information. (6) Responsible agency.--The term ``responsible agency'' means, with respect to a new Federal PII website, the agency that is responsible for the operation (whether directly or through contracts with other entities) of the website. (7) Secure.--The term ``secure'' mean\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Protecting America's Children Against Terrorism Act - Amends the Public Health Service Act to direct the Secretary of Health and Human Services to: (1) establish a Task Force on Children and Bioterrorism; (2) establish a Children and Terrorism Information Network; (3) provide for the inclusion of supplies, equipment, and instructions as are appropriate for use with respect to children in push packs and Vendor Management Inventories under the National Pharmaceutical Stockpile Program; (4) award grants concerning the implementation, development, expansion or increase in the capacity of 2-1-1 call centers, or other universal hotlines; (5) develop and maintain a secure and confidential list of drugs and biologics that may be used to prevent and treat illnesses and injury caused by biological or chemical agents; (6) award contracts for the conduct of pediatric clinical trials and studies concerning drugs and biologics that are used to prevent and treat illnesses and injuries caused by biological or chemical agents; and (7) award grants concerning training for pediatric issues surrounding biological and chemical agents used in warfare and terrorism.Amends the Elementary and Secondary Education Act of 1965 with respect to: (1) school evacuations, safe places and parental notifications; and (2) mental health services for children.Amends the Robert T. Stafford Disaster Relief and Emergency Assistance Act with respect to assisting children who have lost parents in a disaster.\", 'positives': [\"(a) Public Health Measures To Protect Against Terrorism.--Part B of title III of the Public Health Service Act (42 U.S.C. 243 et seq.) is amended by inserting after section 319G, the following: ``SEC. 319H. PUBLIC HEALTH MEASURES TO PROTECT AGAINST TERRORISM. ``(a) National Task Force on Children and Bioterrorism.-- ``(1) Establishment.--The Secretary shall establish a National Task Force on Children and Bioterrorism (referred to in this subsection as the `Task Force'). ``(2) Membership.--The Task Force shall be composed of-- ``(A) the Secretary and other officials of the Department determined appropriate by the Secretary; ``(B) the Director of the Federal Emergency Management Agency; ``(C) the Administrator of the Environmental Protection Agency; ``(D) the Secretary of Education; ``(E) child health experts on infectious disease, environmental health, and toxicology, who shall be appointed by the Secretary; ``(F) representatives of national children's health organizations, including the American Academy of Pediatrics and the National Association of Children's Hospitals, who shall be appointed by the Secretary; and ``(G) representatives of other relevant organizations determined appropriate by the Secretary. ``(3) Recommendations.--Not later than 60 days after the date of enactment of this section, the Task Force shall make recommendations to the Secretary concerning-- ``(A) an assessment of the preparedness of the health care system of the United States to respond to bioterrorism aimed at children and youth, including the readiness of public health institutions, providers of health care, and other emergency service personnel to detect, diagnose and respond to bioterrorist attacks affecting large numbers of children and youth; ``(B) needed changes to the health care and emergency medical services systems, including recommendations on research, training of health personnel, and changes to the National Pharmaceutical Stockpile Program to include the medical needs of children; and ``(C) national, regional, and local health care and emergency medical services protocols for dealing with mass casualties of children and youth resulting from bioterrorism. ``(b) Children and Terrorism Information Network.-- ``(1) Establishment.--The Secretary, acting through the Centers for Disease Control and Prevention, shall establish a Children and Terrorism Information Network to collect and disseminate to health providers (including children's hospitals and pediatric units of hospitals), community centers (including poison control centers), and schools (including school-based health clinics) up-to-date information on how to prepare for a biological or chemical terrorist attack and the steps that should be taken to ensure that children get the health care they need in the event of such an attack. ``(2) Authorization of appropriations.--There is authorized to be appropriated to carry out this subsection, $10,000,000 for fiscal year 2002, and such sums as may be necessary for each subsequent fiscal year. Amounts appropriated under the preceding sentence shall remain available to carry out this section until expended. ``(c) National Pharmaceutical Stockpile Program.-- ``(1) In general.--The Secretary, acting through the Centers for Disease Control and Prevention, shall provide for the inclusion of supplies, equipment, and instructions as are appropriate for use with respect to children in push packs and Vendor Management Inventories under the National Pharmaceutical Stockpile Program. ``(2) Authorization of appropriations.--There is authorized to be appropriated to carry out this subsection, $50,000,000 for fiscal year 2002, and such sums as may be necessary for each subsequent fiscal year. Amounts appropriated under the preceding sentence shall remain available to carry out this section until expended. ``(d) Se\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Farm and Ranch Risk Management Act - Amends the Internal Revenue Code to allow an individual engaged in an eligible farming or commercial fishing business a deduction for any taxable year of up to 20 percent of taxable income attributable to the eligible farming or commercial fishing business which was paid in cash by the taxpayer to a Farm and Ranch Risk Management Account (FARRM Account).Includes distributions from a FARRM account in the taxpayer's gross income, and subjects to a special ten percent surtax any distributions not made within five years of contribution. Establishes a tax on excess contributions, but exempts the taxpayer from the tax on certain prohibited transactions.\", 'positives': [\"(a) In General.--Subpart C of part II of subchapter E of chapter 1 of the Internal Revenue Code of 1986 (relating to taxable year for which deductions taken) is amended by inserting after section 468B the following: ``SEC. 468C. FARM AND RANCH RISK MANAGEMENT ACCOUNTS. ``(a) Deduction Allowed.--In the case of an individual engaged in an eligible farming business or commercial fishing, there shall be allowed as a deduction for any taxable year the amount paid in cash by the taxpayer during the taxable year to a Farm and Ranch Risk Management Account (hereinafter referred to as the `FARRM Account'). ``(b) Limitation.-- ``(1) Contributions.--The amount which a taxpayer may pay into the FARRM Account for any taxable year shall not exceed 20 percent of so much of the taxable income of the taxpayer (determined without regard to this section) which is attributable (determined in the manner applicable under section 1301) to any eligible farming business or commercial fishing. ``(2) Distributions.--Distributions from a FARRM Account may not be used to purchase, lease, or finance any new fishing vessel, add capacity to any fishery, or otherwise contribute to the overcapitalization of any fishery. The Secretary of Commerce shall implement regulations to enforce this paragraph. ``(c) Eligible Businesses.--For purposes of this section-- ``(1) Eligible farming business.--The term `eligible farming business' means any farming business (as defined in section 263A(e)(4)) which is not a passive activity (within the meaning of section 469(c)) of the taxpayer. ``(2) Commercial fishing.--The term `commercial fishing' has the meaning given such term by section (3) of the Magnuson- Stevens Fishery Conservation and Management Act (16 U.S.C. 1802) but only if such fishing is not a passive activity (within the meaning of section 469(c)) of the taxpayer. ``(d) FARRM Account.--For purposes of this section-- ``(1) In general.--The term `FARRM Account' means a trust created or organized in the United States for the exclusive benefit of the taxpayer, but only if the written governing instrument creating the trust meets the following requirements: ``(A) No contribution will be accepted for any taxable year in excess of the amount allowed as a deduction under subsection (a) for such year. ``(B) The trustee is a bank (as defined in section 408(n)) or another person who demonstrates to the satisfaction of the Secretary that the manner in which such person will administer the trust will be consistent with the requirements of this section. ``(C) The assets of the trust consist entirely of cash or of obligations which have adequate stated interest (as defined in section 1274(c)(2)) and which pay such interest not less often than annually. ``(D) All income of the trust is distributed currently to the grantor. ``(E) The assets of the trust will not be commingled with other property except in a common trust fund or common investment fund. ``(2) Account taxed as grantor trust.--The grantor of a FARRM Account shall be treated for purposes of this title as the owner of such Account and shall be subject to tax thereon in accordance with subpart E of part I of subchapter J of this chapter (relating to grantors and others treated as substantial owners). ``(e) Inclusion of Amounts Distributed.-- ``(1) In general.--Except as provided in paragraph (2), there shall be includible in the gross income of the taxpayer for any taxable year-- ``(A) any amount distributed from a FARRM Account of the taxpayer during such taxable year, and ``(B) any deemed distribution under-- ``(i) subsection (f)(1) (relating to deposits not distributed within 5 years), ``(ii) subsection (f)(2) (relating to cessation in eligible farming business), and ``(iii) subparagraph (A) or (B) of subsection (f)(3) (relating to prohibited transactions and pledging account as security). ``(2) E\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Establishes the World War I Centennial Commission to: (1) plan, develop, and execute programs, projects, and activities to commemorate the centennial of World War I; (2) encourage private organizations and state and local governments to organize and participate in such activities; (3) facilitate and coordinate such activities throughout the United States; and (4) serve as a clearinghouse for the collection and dissemination of information about centennial events and plans; and (5) develop commemoration recommendations for Congress and the President.', 'positives': [\"The purpose of this Act is to establish a commission, in Kansas City, Missouri, on the centennial of World War I to ensure a suitable observance of such centennial that promotes the values of honor, courage, patriotism, and sacrifice, in keeping with the representation of these values through the four Guardian Spirits sculpted on the Liberty Memorial Monument at America's National World War I Museum. SEC. 3. ESTABLISHMENT OF COMMISSION. (a) Establishment.--There is established a commission to be known as the ``World War I Centennial Commission'' (referred to in this Act as the ``Commission''). (b) Membership.-- (1) Composition.--The Commission shall be composed of 24 members as follows: (A) Four members who shall be appointed by the Speaker of the House of Representatives. (B) Three members who shall be appointed by the minority leader of the House of Representatives. (C) Four members who shall be appointed by the majority leader of the Senate. (D) Three members who shall be appointed by the minority leader of the Senate. (E) Seven members who shall be appointed by the President from among persons who are broadly representative of the people of the United States (including members of the Armed Forces, veterans, and representatives of veterans service organizations). (F) One member who shall be appointed by the executive director of the Veterans of Foreign Wars of the United States. (G) One member who shall be appointed by the executive director of the American Legion. (H) One member who shall be appointed by the president of the Liberty Memorial Association. (2) Period of appointment.--Each member shall be appointed for the life of the Commission. (3) Vacancies.--A vacancy in the Commission shall be filled in the manner in which the original appointment was made. (4) Initial meeting.-- (A) In general.--Not later than 30 days after the date on which all members of the Commission have been appointed, the Commission shall hold its first meeting. (B) Location.--The location for the meeting held under subparagraph (A) shall be America's National World War I Museum. (5) Meetings.-- (A) In general.--The Commission\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': '. Targeting Rogue and Opaque Letters Act of 2015 (Sec. 2) This bill directs the Federal Trade Commission (FTC), and authorizes state attorneys general, to enforce against written communications (commonly referred to as demand letters) that represent in bad faith that the recipient bears liability or owes compensation for infringing an asserted patent. The pattern or practice of sending such bad faith demand letters shall be treated as an unfair or deceptive act or practice in violation of the Federal Trade Commission Act. The bill sets forth the types of bad faith representations, assertions of legal action, claims of a sender holding an exclusive license, compensation requests, or omissions that are considered to be unfair or deceptive. The bill provides an affirmative defense if the sender can show that statements, representations, or omissions were mistakes made in good faith, which may be demonstrated by a preponderance of evidence that the violation was not intentional and resulted from a bona fide error notwithstanding the maintenance of procedures reasonably adapted to avoid any such error. (Sec. 3) The bill provides the FTC with authority to enforce against violations. (Sec. 4) The bill preempts state or local laws expressly relating to the transmission or contents of communications regarding the assertion of patent rights. But the bill shall not be contrued to limit any other state laws, including those relating to consumer protection, fraud, deception, trespass, contracts, or torts. State attorneys general may bring civil actions in federal court to enjoin violations or obtain civil penalties for violations of this bill. The maximum civil penalty for which a person may be liable for a series of related violations is $5 million.', 'positives': [\"(a) In General.--It shall be an unfair or deceptive act or practice within the meaning of section 5(a)(1) of the Federal Trade Commission Act (15 U.S.C. 45(a)(1)) for a person, in connection with the assertion of a United States patent, to engage in a pattern or practice of sending written communications that state or represent that the recipients are or may be infringing, or have or may have infringed, the patent and bear liability or owe compensation to another, if-- (1) the sender of the communications, in bad faith, states or represents in the communications that-- (A) the sender is a person with the right to license or enforce the patent at the time the communications are sent, and the sender is not a person with such a right; (B) a civil action asserting a claim of infringement of the patent has been filed against the recipient; (C) a civil action asserting a claim of infringement of the patent has been filed against other persons; (D) legal action for infringement of the patent will be taken against the recipient; (E) the sender is the exclusive licensee of the patent asserted in the communications; (F) persons other than the recipient purchased a license for the patent asserted in the communications; (G) persons other than the recipient purchased a license, and the sender does not disclose that such license is unrelated to the alleged infringement or the patent asserted in the communications; (H) an investigation of the recipient's alleged infringement occurred; or (I) the sender or an affiliate of the sender previously filed a civil action asserting a claim of infringement of the patent based on the activity that is the subject of the written communication when the sender knew such activity was held, in a final determination, not to infringe the patent; (2) the sender of the communications, in bad faith, seeks compensation for-- (A) a patent claim that has been held to be unenforceable due to inequitable conduct, invalid, or otherwise unenforceable against the recipient, in a final determination; (B) activities undertaken by the recipient after expiration of the patent asserted in the communications; or (C) activity of the recipient that the sender knew was authorized, with respect to the patent claim or claims that are the subject of the communications, by a person with the right to license the patent; or (3) the sender of the communications, in bad faith, fails to include-- (A) the identity of the person asserting a right to license the patent to, or enforce the patent against, the recipient, including the identity of any parent entity and the ultimate parent entity of such person, unless such person is a public company and the name of the public company is identified; (B) an identification of at least one patent issued by the United States Patent and Trademark Office alleged to have been infringed; (C) an identification, to the extent reasonable under the circumstances, of at least one product, service, or other activity of the recipient that is alleged to infringe the identified patent; (D) a description, to the extent reasonable under the circumstances, of how the product, service, or other activity of the recipient infringes an identified patent and patent claim; or (E) a name and contact information for a person the recipient may contact about the assertions or claims relating to the patent contained in the communications. (b) Affirmative Defense.--With respect to subsection (a), there shall be an affirmative defense that statements, representations, or omissions were not made in bad faith (as defined in subparagraphs (B) and (C) of section 5(1)) if the sender can demonstrate that such statements, representations, or omissions were mistakes made in good faith, which may be demonstrated by a preponderance of evidence that th\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Pipeline Modernization and Consumer Protection Act Requires each operator of a gas pipeline facility, in accordance with an integrity management program, if applicable, to accelerate the repair, rehabilitation, and replacement of gas piping or equipment that is leaking or may pose high risk of leaking. Requires each state regulatory authority and each nonregulated gas utility, in complying with such requirements, to: develop prioritized timelines to repair or replace all leaking or high-risk piping or equipment, and require use of best available technology to detect gas leaks. Directs the Administrator of the Pipeline and Hazardous Materials Safety Administration to issue non-binding best practices guidelines for identifying and classifying high-risk pipeline infrastructure and leaks for repair or replacement. Directs the Administrator and the heads of other applicable federal agencies to work jointly to establish and publish forms that adopt a standard definition and methodology for calculating and reporting information on the causes of unaccounted-for gas.', 'positives': [\"(a) Findings.--Congress finds that-- (1) Federal requirements related to repairing pipeline leaks are limited to ``hazardous'' leaks, which are leaks that represent an existing or probable hazard to persons or property and require immediate repair; (2) there are no Federal requirements to address slower or less hazardous leaks, which can allow the leaks to persist unrepaired indefinitely; (3) in States without a standard definition and methodology for calculating unaccounted-for gas (the difference between the amount of gas purchased by a utility and the amount used or sold to customers), data inconsistencies may be pervasive and these inconsistencies hinder the ability of regulators to monitor gas system and utility performance; (4) the cost of leaked or otherwise unaccounted-for natural gas in the distribution system is typically passed on to ratepayers without limitation as an accepted cost of service, which removes financial incentive for utilities to minimize the leaks; (5) methane, the primary constituent of natural gas, is a greenhouse gas at least 20 times more potent than carbon dioxide; (6) according to the Pipeline and Hazardous Materials Safety Administration, the United States natural gas distribution system still includes 61,000 miles of bare steel pipe without adequate corrosion protection and 32,000 miles of cast iron pipe, which was installed beginning in the 1830s and can be prone to failure; (7) major recent pipeline explosions that led to human fatalities, including those in Austin, Texas, Philadelphia, Pennsylvania, and Allentown, Pennsylvania, have been traced to aging, leaking, and high-risk pipeline infrastructure; (8) natural gas distribution utilities may be discouraged from making capital expenditures for the replacement of leaking and failure-prone pipelines because traditional ratemaking structures may not allow for cost recovery on a timely basis; and (9) according to the Pipeline and Hazardous Materials Safety Administration, the natural gas pipeline replacement programs established as part of the ratemaking process in 27 States and the District of Columbia have played a vital role in enhancing public safety by better ensuring the prompt rehabilitation, repair, or replacement of high-risk natural gas distribution infrastructure. (b) Natural Gas Distribution Companies.-- (1) In general.--Chapter 601 of title 49, United States Code, is amended by inserting after section 60112 the following: ``Sec. 60112A. Replacement programs for high-risk natural gas pipelines ``(a) Definition of Gas Pipeline Facility.--In this section, the term `gas pipeline facility' includes-- ``(1) a distribution facility; and ``(2) a gas utility. ``(b) In General.--Each operator of a gas pipeline facility shall, in accordance with an integrity management program required under section 60109 of this title, if applicable, accelerate the repair, rehabilitation, and replacement of gas piping or equipment that-- ``(1) is leaking; or ``(2) may pose high risks of leaking, or may no longer be fit for service, because of-- ``(A) inferior materials; ``(B) poor construction practices; ``(C) lack of maintenance; or ``(D) age. ``(c) Policy Options.-- ``(1) In general.--In complying with subsection (b), each State regulatory authority and each nonregulated gas utility shall consider-- ``(A) developing prioritized timelines to repair all leaks based on the severity of the leak, including non-hazardous leaks, or replace identified leaking or high-risk piping or equipment, including leaks identified as part of an integrity management plan developed under section 192.1007 of title 49, Code of Federal Regulations, if applicable; ``(B) adopting a cost-recovery program that includes-- ``(i) replacement plans with targets and benchmarks for leaking or high-risk infrastructure replacement; ``(ii)\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Requires the President, before issuing an order, to: (1) cite all constitutional and statutory provisions that authorize the order; (2) conduct and publish in the Federal Register a cost benefit analysis of the order; and (3) provide no less than 30 days after publication for public comment before the order takes effect. Sets forth special requirements respecting orders that include classified information. States that any order that is not compliance with this Act shall have no force and effect. Provides that an order in effect before this Act's effective date shall have no force or effect one year after such effective date unless the President reissues such order in compliance with the requirements of this Act. Sets forth provisions governing civil actions challenging an order not in compliance with this Act and judicial review thereof.\", 'positives': [\"SECTION 1. REQUIREMENTS BEFORE THE PRESIDENT MAY ISSUE AN ORDER. (a) Definitions.--In this Act, the term-- (1) ``benefit'' means the reasonably identifiable significant favorable effects, quantifiable and nonquantifiable, including social, health, safety, environmental, economic, and distributional effects, that are expected to result from implementation of, or compliance with, an order; (2) ``cost'' means the reasonably identifiable significant adverse effects, quantifiable and nonquantifiable, including social, health, safety, environmental, economic, and distributional effects, that are expected to result from implementation of, or compliance with, an order; (3) ``cost benefit analysis'' means an evaluation of the costs and benefits of an order, quantified to the extent feasible and appropriate and otherwise qualitatively described, that is prepared at the level of detail appropriate and practicable for reasoned decisionmaking on the matter involved, taking into consideration uncertainties, the significance and complexity of the decision, and the need to adequately inform the public; and (4) ``order'' means any Executive order, proclamation, or other written directive that-- (A) is issued by the President; and (B) subject to subsection (b)(1)-- (i) is not based solely on an authority under article II of the United States Constitution; and (ii) is based on a statutory authority. (b) Authority for Orders.-- (1) Orders.--Subsection (a)(4)(B) shall not apply with respect to the term ``order'' as used in this subsection. (2) Authority.--The President may only issue an order if such order is authorized under a provision of the United States Constitution or expressly authorized by statute. (c) Requirements.--Subject to subsection (d), before issuing an order, the President shall-- (1) cite in the order all constitutional and statutory provisions that authorize the order; (2) conduct a cost benefit analysis of the order; (3) publish the order and the cost benefit analysis of the order in the Federal Register; and (4) provide for a period of no less than 30 days after the publication under paragraph (3), for public comment before the order takes effect. (d) Orders With Classified Information.-- (1) Inapplicability.--Subsection (c) (3) and (4) shall not apply to an order that includes classified information. (2) Requirement.--Before issuing an order that includes classified information, the President shall submit a copy of the order to the President pro tempore of the Senate and the Speaker of the House of Representatives no less than 30 days before the order takes effect. (e) Effect of Noncompliance.--Any order that is not in compliance with this section shall have no force and effect. (f) Application to Prior Orders.--An order in effect before the effective date of this Act shall have no force and effect on and after the date that occurs 1 year after such effective date, unless the President reissues such order in compliance with subsections (c) and (d). (g) Judicial Review.-- (1) Jurisdiction of district courts.--The district courts of the United States shall have jurisdiction of any civil action arising under this Act. (2) Standing.--The following persons may bring a civil action in an appropriate district court of the United States to challenge an order that is not in compliance with this Act: (A) Congress and members of congress.--The Senate, the House of Representatives, any Senator, and any Representative to the House of Representatives. (B) State and local governments.--The highest governmental official of any State, commonwealth, district, territory, or possession of the United States, or any political subdivision thereof, or the designee of such person. (C) Aggrieved persons.--Any person aggrieved in a liberty or property interest adversely affected directly by an order that is not in compliance with this Act. (3) Appeal and expedited review.-- (A) Appeal to supreme court.--An appeal may be taken directly to the Supreme Court of the United St\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Access to Frontline Health Care Act of 2015 This bill amends the Public Health Service Act to direct the Department of Health and Human Services (HHS) to establish and carry out a Frontline Providers Loan Repayment Program under which HHS makes student loan repayments in exchange for a health professional providing frontline care services for two years in a frontline care scarcity area. Frontline care services include surgery, optometry, physical therapy, pharmacies, public health, dietetics, occupational therapy, pediatrics, and medical technology. Frontline care scarcity areas are federal health professional shortage areas and areas, populations, or facilities designated by a state as having a shortage of frontline care services.', 'positives': [\"Part D of title III of the Public Health Service Act (42 U.S.C. 254b et seq.) is amended-- (1) by redesignating the second subpart XI (as added by section 10333 of Public Law 111-148) as subpart XII; (2) by redesignating the second section 340H (as added by such section 10333) as section 340I; and (3) by adding at the end the following: ``Subpart XIII--Frontline Health Care Services ``SEC. 340J. FRONTLINE PROVIDERS LOAN REPAYMENT PROGRAM. ``(a) In General.--The Secretary shall establish and carry out a Frontline Providers Loan Repayment Program (in this section referred to as the `Loan Repayment Program') under which, pursuant to contracts in accordance with this section-- ``(1) the Secretary agrees to make student loan repayments; and ``(2) the individual agrees to serve as a health professional for a period of full-time service of not less than 2 years at a health care facility serving a frontline care scarcity area. ``(b) Eligibility.--To be eligible to participate in the Loan Repayment Program, an individual must-- ``(1) submit an application to participate in the Loan Repayment Program in such form and manner and at such time as specified by the Secretary; and ``(2) sign and submit to the Secretary, at the time of submittal of such application, a written contract (described in subsection (d)). ``(c) Participation in Program.-- ``(1) In general.--An individual becomes a participant in the Loan Repayment Program only upon the approval of the Secretary of the individual's application submitted under subsection (b)(1) and the Secretary's acceptance of the contract submitted by the individual under subsection (b)(2). ``(2) Preference.--In awarding contracts under this section, the Secretary shall give preference to applicants who have undertaken training or coursework in interdisciplinary studies. ``(3) Recruitment for interdisciplinary programs.--The Secretary shall-- ``(A) determine the frontline care scarcity areas in which to place contract recipients under this section; and ``(B) in making such determination, give preference to areas with a demonstrated program of interdisciplinary health care, or with demonstrated plans to initiate interdisciplinary approaches to community health care. ``(4) Notice.--The Secretary shall provide written notice to an individual promptly upon the Secretary's approving, under paragraph (1), of the individual's participation in the Loan Repayment Program. ``(d) Contract.--The contract described in this subsection is a written contract between the Secretary and an individual that contains-- ``(1) an agreement that-- ``(A) the Secretary agrees to provide the individual with student loan repayment (described in subsection (e)) for a period of time as determined by the Secretary, to pay off debts incurred during the course of the study or program described in subsection (g)(2)(B); and ``(B) the individual agrees-- ``(i) to accept provision of such a student loan repayment to the individual; and ``(ii) to provide frontline care services for a period of full-time service of not less than 2 years at a health care facility serving a frontline care scarcity area; ``(2) a provision that any financial obligation of the United States arising out of a contract entered into under this section and any obligation of the individual which is conditioned thereon, is contingent upon funds being appropriated for student loan repayment under this section; ``(3) a statement of the damages to which the United States is entitled, under subsection (f), for the individual's breach of the contract; and ``(4) such other statements as the Secretary deems appropriate of the rights and liabilities of the Secretary and of the individual, not inconsistent with the provisions of this section. ``(e) Student Loan Repayment.-- ``(1) Amount.--The amount of an annual student loan repayment under this\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Financial Security in Retirement Act of 2008 - Suspends, for calendar 2008 and 2009, minimum distribution requirements for up to $300,000 of an individual's interest in all eligible defined contribution plans as of December 31, 2008.\", 'positives': [\"(a) In General.--In the case of an eligible defined contribution plan of an individual, sections 401(a)(9), 404(a)(2), 403(b)(10), 408(a)(6), 408(b)(3), and 457(d)(2) of the Internal Revenue Code of 1986 shall not apply with respect to such individual for any year during the suspension period to the extent such individual's interest in all such plans as of December 31, 2008, is not greater than $300,000. (b) Suspension Period.--For purposes of this section, the term ``suspension period'' means the period beginning on January 1, 2008, and ending on December 31, 2009. (c) Eligible Defined Contribution Plan.--For purposes of this section, the term ``eligible defined contribution plan'' means-- (1) a defined contribution plan (within the meaning of section 414(i) of such Code) which is-- (A) an employee's trust described in section 401(a) of such Code which is exempt from tax under section 501(a) of such Code, (B) an annuity plan described in section 403(a) of such Code, (C) an annuity contract described in section 403(b) of such Code, and (D) an eligible deferred compensation plan described in section 457(b) of such Code which is maintained by an eligible employer described in section 457(e)(1)(A) of such Code, and (2) an individual retirement plan (as defined in section 7701(a)(37) of such Code). (d) Special Rules.-- (1) Exception for 5-year rule.--In the case of a distribution required under section 401(a)(9)(B)(ii) of such Code, subsection (a) shall not apply. (2) Delay in required minimum distribution for 2008.--The required minimum distribution for 2008 (if any) with respect to any eligible defined contribution plan of an individual-- (A) shall be determined on the basis of the individual's interest in such plan determined as of December 31, 2008, and (B) shall be treated as timely made if such distribution is made before April 1, 2009. (3) Aggregation of employer plans.-- (A) In general.--A plan shall not be treated as disqualified merely because the plan treats the aggregate interest of the individual in all plans maintained by the employer (and any member of any controlled group which includes the employer) as such individual's interest in all eligible defined contribution plans. (B) Controlled group.--For purposes of subparagraph (A), the term ``controlled group'' means any group treated as a single employer under subsection (b), (c), (m), or (o) of section 414 of such Code. (4) Exemption of distributions during suspension period from trustee transfer and withholding rules.--For purposes of sections 401(a)(31), 402(f), and 3405 of such Code, any distribution during the suspension period which, but for subsection (a), would have been a required distribution under section 401(a)(9) of such Code shall not be treated as an eligible rollover distribution. (e) Regulations.--The Secretary of the Treasury shall prescribe such regulations as may be necessary to carry out the purposes of this section, including rules providing for the allocation of the $300,000 amount described in subsection (a) in the case of an individual with an interest in more than 1 defined contribution plan. (f) Provisions Relating to Plan Amendments.-- (1) In general.--If this subsection applies to any plan or annuity contract, such plan or contract shall be treated as being operated in accordance with the terms of the plan during the period described in paragraph (2)(B)(i). (2) Amendments to which subsection applies.-- (A) In general.--This subsection shall apply to any amendment to any plan or annuity contract which is made-- (i) pursuant to this section or pursuant to any regulation issued by the Secretary of the Treasury to carry out this section, and (ii) on or before the last day of the first plan year beginning on or after January 1, 2009. (B) Conditions.--This subsection\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Fire-Safe Communities Act of 2009 - Authorizes the Under Secretary for Federal Emergency Management of the Department of Homeland Security (DHS) to reduce the amount of the share of nonfederal funds required by the Fire Management Assistance Grant Program to 10% of the grant amount for a municipality at risk if such municipality has adopted: (1) a national wildland fire code, standard, or ordinance; or (2) a local ordinance, standard, or code that requires the retrofit of existing construction that provides for increased protection for the municipality from the threat of wildfire, such as a requirement to replace combustible roofing material used in existing structures. Directs the Under Secretary to award grants to municipalities at risk to: (1) encourage responsible development in such municipalities; (2) mitigate the catastrophic effects of fires; and (3) encourage the retrofit of existing wildfire-prone structures. Limits grant awards to $1 million. Directs the Under Secretary to require that a person awarded a grant provide nonfederal funds equal to 25% of the grant amount for the purpose of the award. Amends the Cooperative Forestry Assistance Act of 1978 to: (1) include as a purpose of the Community and Private Land Fire Assistance Program to enhance the capacity of local governments to integrate fire-resistant community and home design into local planning, zoning, building codes, property maintenance codes, and brush clearing ordinances; and (2) authorize a pilot program to assess the feasibility and advisability of awarding grants to fire-safe communities located near federal land to assist in federal efforts to prevent and manage fires.', 'positives': [\"In this Act: (1) Fire hazard area.--The term ``fire hazard area'' means an area at significant risk from wildland fire as determined by-- (A) the applicable State forestry agency or equivalent State agency; or (B) the Under Secretary. (2) Fire safe community.--The term ``fire safe community'' means-- (A) a subdivision of a State that has adopted a national wildland fire code, standard, or ordinance; or (B) a municipality at risk that has adopted local ordinances that-- (i) are consistent with more than one of the elements set out in paragraph (4)(C)(ii); and (ii) the Under Secretary determines provide generally accepted levels of fire protection. (3) Municipality at risk.--The term ``municipality at risk'' means a subdivision of a State that is located in, or contains, a fire hazard area. (4) National wildland fire code, standard, or ordinance.-- The term ``national wildland fire code, standard, or ordinance'' means-- (A) the most recent publication of National Fire Protection Association code number 1141, 1142, or 1144; (B) the most recent publication of the International Wildland-Urban Interface Code of the International Code Council; or (C) any other code which-- (i) the Under Secretary determines provides the same, or better, standards for protection against wildland fire as a code described in subparagraph (A) or (B); and (ii) may include-- (I) specifications for construction materials and techniques for use in municipalities at risk; (II) guidelines for the placement of utilities, defensible space, and vegetation management; (III) enforcement mechanisms for compliance with defensible space requirements; (IV) zoning and site design standards for new residential construction, including the width and placement of surrounding fuel breaks and description of unsafe areas to locate new homes, such as the top of highly dangerous canyons that funnel wildfire heat; (V) specifications for water supplies for firefighting; (VI) requirements for adequate firefighting protection, including requirements for fire stations and equipment; (VII) guidelines for the participation of fire professionals in the development of local fire protection models; (VIII) standards for the protection of roads and bridges; (IX) standards for the egress capacities of roads and bridges; (X) guidelines for the marking of buildings and homes; and (XI) requirements for the replacement of combustible roofing material on existing homes. (5) Under secretary.--The term ``Under Secretary'' means the Under Secretary for Federal Emergency Management of the Department of Homeland Security. SEC. 3. ADDITIONAL FIRE MANAGEMENT ASSISTANCE GRANTS FOR FIRE SAFE COMMUNITIES. (a) In General.--The Under Secretary may reduce the amount of the share of non-Federal funds required by the Fire Management Assistance Grant Program to 10 percent of the grant amount for a municipality at risk if such municipality has adopted a-- (1) national wildland fire code, standard, or ordinance; or (2) local ordinance, standard, or code that requires the retrofit of existing construction that provides for increased protection for the municipality from the threat of wildfire, such as a requirement to replace combustible roofing material used in existing structures. (b) Rulemaking.--Not later than 1 year after the date of the enactment of this Act, the Under Secretary shall publish in the Federal Register a final rule that includes a definition of the term ``local ordinance, standard, or code that requires the retrofit of existing construction that provides for increased protection for the municipality from the threat of wildfire'' as used in subsection (a)(2). (c) Fire Management Assistance Grant Program Defined.--In this section, the term ``Fire Management Assistance Grant Program'' means the fire management assistance grant program carried out pursuant to section 420 of the Robert T. Stafford Disaster Rel\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Accountability and Flexibility Associated With Spending on Transportation Act of 2005 - Amends the Safe, Accountable, Flexible, Efficient Transportation Equity Act: A Legacy for Users (SAFETEA-LU) to allow a state to use its specified transportation improvement program (TIP) project allocation for any other eligible transportation project the state may designate. Expresses the sense of Congress that state departments of transportation should take project descriptions in certain set-aside bridge program projects and specified TIP projects under SAFETEA-LU into consideration if such projects involve improving transportation safety. Rescinds for FY2006 a specified amount of state unobligated balances of funds for the Interstate maintenance, national highway system, bridge, congestion mitigation and air quality improvement, surface transportation (other than the STP set-aside programs), metropolitan planning, minimum guarantee, Appalachian development highway system, recreational trails, safe routes to school, freight intermodal connectors, coordinated border infrastructure, high risk rural road, high priority projects, and TIPs and each of the STP set-aside programs. Rescinds 10% of amounts appropriated for FY2007-FY2009 by SAFETEA-LU (including the equity bonus program), but excluding amounts appropriated for the highway safety improvement program.', 'positives': [\"(a) Highway Bridge Program.--Section 144(g)(1) of title 23, United States Code, is amended by adding at the end the following: ``(D) Funding Flexibility.--If a State is provided funds under subparagraph (A) for a project described in subparagraph (A), the State may use all or any portion of such funds to carry out such project or any other project eligible for assistance under this section that the State designates.''. (b) Projects of National and Regional Significance.--Section 1301 of the Safe, Accountable, Flexible, Efficient Transportation Equity Act: A Legacy for Users (Public Law 109-59) is amended by adding at the end the following: ``(n) Funding Flexibility.--If a State is provided funds under this section for a project described in the table contained in subsection (m), the State may use all or any portion of such funds to carry out such project or any other project eligible for assistance under this section that the State designates.''. (c) National Corridor Infrastructure Improvement Program.--Section 1302 such Act is amended by adding at the end the following: ``(f) Funding Flexibility.--If a State is provided funds under this section for a project described in the table contained in subsection (e), the State may use all or any portion of such funds to carry out such project or any other project eligible for assistance under this section that the State designates.''. (d) High Priority Projects Program.--Section 117 of title 23, United States Code, is amended by adding at the end the following: ``(i) Funding Flexibility.--If a State is provided funds under this section for a project described in the table contained in section 1702 of the Safe, Accountable, Flexible, Efficient Transportation Equity Act: A Legacy for Users (Public Law 109-59), the State may use all or any portion of such funds to carry out such project or any other project eligible for assistance under the surface transportation program in section 133 that the State designates.''. (e) Transportation Improvements.--Section 1934 of such Act is amended by adding at the end the following: ``(d) Funding Flexibility.--If a State is provided funds under this section for a project described in the table contained in subsection (c), the State may use all or any portion of such funds to carry out such project or any other project eligible for assistance under the surface transportation program in section 133 of title 23, United States Code, that the State designates.''. (f) Projects for Bus and Bus-Related Facilities and Clean Funds Grant Program.--Section 3044 of such Act is amended by adding at the end the following: ``(d) Funding Flexibility.--If a recipient is provided funds under this section or section 5308 of title 49, United States Code, or both, for a project described in the table contained in subsection (a), the recipient may use all or any portion of such funds to carry out such project or any other project eligible for assistance under this section or section 5308 of such title, other than a project to fund any operations of buses or bus-related facilities.''. SEC. 3. SENSE OF CONGRESS. It is the sense of Congress that State departments of transportation should take project descriptions in section 144(g)(1)(A) of title 23, United States Code, and in the tables contained in sections 1301, 1302, 1702, 1934, and 3044 of the Safe, Accountable, Flexible, Efficient Transportation Equity Act: A Legacy for Users (Public Law 109-59) into consideration if such projects involve improving transportation safety. SEC. 4. ACROSS-THE-BOARD RESCISSIONS. (a) Fiscal Year 2006.-- (1) In general.--On September 30, 2006, there is rescinded $4,718,047,269 of the unobligated balances of funds apportioned before such date to the States for the Interstate maintenance, national highway system, bridge, congesti\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Science Prize Competitions Act Amends the Stevenson-Wydler Technology Innovation Act of 1980 regarding prize competitions, allowing an agency to waive liability insurance requirements for participants. Allows an agency to enter into a grant, contract, cooperative agreement, or other agreement with a private sector for-profit as well as a nonprofit entity (as under current law) to administer a prize competition. Permits the use of funds from private sector for-profit entities to support a prize competition. Prohibits an agency from giving special consideration to any private sector for-profit entity in return for a donation. Limits the use of federal funds to those made available by appropriations Acts.', 'positives': [\"Section 24 of the Stevenson-Wydler Technology Innovation Act of 1980 (15 U.S.C. 3719) is amended-- (1) in subsection (c)-- (A) by inserting ``competition'' after ``section, a prize''; (B) by inserting ``types'' after ``following''; and (C) in paragraph (4), by striking ``prizes'' and inserting ``prize competitions''; (2) in subsection (f)-- (A) by striking ``in the Federal Register'' and inserting ``on a publicly accessible Government website, such as www.challenge.gov,''; and (B) in paragraph (4), by striking ``prize'' and inserting ``cash prize purse''; (3) in subsection (g), by striking ``prize'' and inserting ``cash prize purse''; (4) in subsection (h), by inserting ``prize'' before ``competition'' both places it appears; (5) in subsection (i)-- (A) in paragraph (1)(B), by inserting ``prize'' before ``competition''; (B) in paragraph (2)(A), by inserting ``prize'' before ``competition'' both places it appears; (C) by redesignating paragraph (3) as paragraph (4); and (D) by inserting after paragraph (2) the following new paragraph: ``(3) Waiver.--An agency may waive the requirement under paragraph (2). The annual report under subsection (p) shall include a list of such waivers granted during the preceding fiscal year, along with a detailed explanation of the reasons for granting the waivers.''; (6) in subsection (k)-- (A) in paragraph (2)(A), by inserting ``prize'' before ``competition''; and (B) in paragraph (3), by inserting ``prize'' before ``competitions'' both places it appears; (7) in subsection (l), by striking all after ``may enter into'' and inserting ``a grant, contract, cooperative agreement, or other agreement with a private sector for-profit or nonprofit entity to administer the prize competition, subject to the provisions of this section.''; (8) in subsection (m)-- (A) by amending paragraph (1) to read as follows: ``(1) In general.--Support for a prize competition under this section, including financial support for the design and administration of a prize competition or funds for a cash prize purse, may consist of Federal appropriated funds and funds provided by private sector for-profit and nonprofit entities. The head of an agency may accept funds from other Federal agencies, private sector for-profit entities, and nonprofit entities, to be available to the extent provided by appropriations Acts, to support such prize competitions. The head of an agency may not give any special consideration to any private sector for-profit or nonprofit entity in return for a donation.''; (B) in paragraph (2), by striking ``prize awards'' and inserting ``cash prize purses''; (C) in paragraph (3)(A)-- (i) by striking ``No prize'' and inserting ``No prize competition''; and (ii) by striking ``the prize'' and inserting ``the cash prize purse''; (D) in paragraph (3)(B), by striking ``a prize'' and inserting ``a cash prize purse''; (E) in paragraph (3)(B)(i), by inserting ``competition'' after ``prize''; (F) in paragraph (4)(A), by striking ``a prize'' and inserting ``a cash prize purse''; and (G) in paragraph (4)(B), by striking ``cash prizes'' and inserting ``cash prize purses''; (9) in subsection (n), by inserting ``for both for-profit and nonprofit entities,'' after ``contract vehicle''; (10) in subsection (o)(1), by striking ``or providing a prize'' and insert ``a prize competition or providing a cash prize purse''; and (11) in subsection (p)(2)-- (A) in subparagraph (C), by striking ``cash prizes'' both places it occurs and inserting ``cash prize purses''; and (B) by adding at the end the following new subparagraph: ``(G) Plan.--A description of crosscutting topical areas and agency-specific mission needs that may be the strongest opportunities for prize competitions during the upcoming 2 fiscal years.''. Passed the House of Representatives May 19, 2015. Attest: KAREN L. HAAS, Clerk.\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Veterans Business Center Act of 2009 - Amends the Small Business Act to direct the Administrator of the Small Business Administration (SBA) to establish within the SBA a Veterans Business Center program (program), headed by a Director, to provide entrepreneurial training and counseling to veterans. Requires the Director to establish a program of grants to centers that will develop specialized programs to assist veteran-owned small businesses in securing capital and repairing damaged credit, counsel on how to improve financial presentations, facilitate access to financing, and assist unemployed veterans become entrepreneurs. Requires the Director to establish a program of grants to centers to: (1) assist veteran-owned small businesses to identify contracts that are suitable to such businesses; (2) prepare veteran-owned small businesses to be ready as subcontractors and prime contractors for contracts made available through the American Recovery and Reinvestment Act of 2009, particularly with respect to the construction trades; and (3) provide veteran-owned small businesses technical assistance with respect to the federal procurement process. Requires the Director to establish a program of grants to centers to develop outreach programs for service-disabled veterans to promote self-employment opportunities and to train and assist such veterans with respect to developing business plans and securing business opportunities. Authorizes the Director to carry out a veterans entrepreneurial development summit. Requires an annual report from the Administrator to Congress on appointments made to, and activities of, the interagency task force on veteran-owned small businesses. Directs the Comptroller General to carry out a study of the effects of this Act on small businesses owned and controlled by veterans.', 'positives': [\"Section 32 of the Small Business Act (15 U.S.C. 657b) is amended-- (1) in subsection (f), by inserting ``(other than subsections (g), (h), and (i))'' after ``this section''; and (2) by adding at the end the following: ``(g) Veterans Business Center Program.-- ``(1) In general.--The Administrator shall establish a Veterans Business Center program within the Administration to provide entrepreneurial training and counseling to veterans in accordance with this subsection. ``(2) Director.--The Administrator shall appoint a Director of the Veterans Business Center program, who shall implement and oversee such program and who shall report directly to the Associate Administrator for Veterans Business Development. ``(3) Designation of veterans business centers.--The Director shall establish by regulation an application, review, and notification process to designate entities as veterans business centers for purposes of this section. The Director shall make publicly known the designation of an entity as a veterans business center and the award of a grant to such center under this subsection. ``(4) Funding for veterans business centers.-- ``(A) Initial grants.--The Director is authorized to make a grant (hereinafter in this subsection referred to as an `initial grant') to each veterans business center each year for not more than 5 years in the amount of $200,000. ``(B) Growth funding grants.--After a veterans business center has received 5 years of initial grants under subparagraph (A), the Director is authorized to make a grant (hereinafter in this subsection referred to as a `growth funding grant') to such center each year for not more than 3 years in the amount of $150,000. After such center has received 3 years of growth funding grants, the Director shall require such center to meet performance benchmarks established by the Director to be eligible for growth funding grants in subsequent years. ``(5) Center responsibilities.--Each veterans business center receiving a grant under this subsection shall use the funds primarily on veteran entrepreneurial development, counseling of veteran-owned small businesses through one-on-one instruction and classes, and providing government procurement assistance to veterans. ``(6) Matching funds.--Each veterans business center receiving a grant under this subsection shall be required to provide a non-Federal match of 50 percent of the Federal funds such center receives under this subsection. The Director may issue to a veterans business center, upon request, a waiver from all or a portion of such matching requirement upon a determination of hardship. The Director may waive the matching funds requirement under this paragraph with respect to veterans business centers that serve communities with a per capita income less than 75 percent of the national per capita income and an unemployment rate at least 150 percent higher than the national average. ``(7) Targeted areas.--The Director shall give priority to applications for designations and grants under this subsection that will establish a veterans business center in a geographic area, as determined by the Director, that is not currently served by a veterans business center and in which-- ``(A) the population of veterans exceeds the national median of such measure; or ``(B) the population of veterans of Operation Iraqi Freedom or Operation Enduring Freedom exceeds the national median of such measure. ``(8) Training program.--The Director shall develop and implement, directly or by contract, an annual training program for the staff and personnel of designated veterans business centers to provide education, support, and information on best practices with respect to the establishment and operation of such centers. The Director shall develop such training program in consultation with veterans business centers, the interagency task force establ\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'James Monroe Commemorative Coin Act - Directs the Secretary of the Treasury to mint and issue $50 gold coins, $1 silver coins, and half-dollar clad coins in commemoration of the bicentennial of the election of President James Monroe, the fifth President of the United States. Authorizes the issuance of such coins only during the one-year period beginning on January 1, 2016. Requires all sales of coins minted under this Act to include specified surcharges and requires such surcharges to be promptly paid to the James Monroe Memorial Foundation.', 'positives': [\"The Congress hereby finds as follows: (1) James Monroe was the only United States President besides George Washington to have actively served in the regular military during the Revolutionary War. (2) James Monroe-- (A) participated in the Battles of Harlem Heights and White Plains; (B) crossed the Delaware River in advance of George Washington; (C) was seriously wounded at the Battle of Trenton and cited for conspicuous gallantry; (D) wintered with the Continental Army at Valley Forge; and (E) subsequently participated in the Battles of Brandywine, Germantown and Monmouth. (3) James Monroe served at the State level in the Virginia House of Delegates and served 4 times as the Governor of Virginia. (4) James Monroe served at the national level as a member of the Continental Congress, United States Senator, Minister to France (negotiating the Louisiana Purchase), Minister to Spain, Minister to England, Secretary of War, and Secretary of State (he was the only person to ever hold those 2 posts simultaneously, defending the Nation during the War of 1812), and finally as President of the United States from 1817-1825. (5) James Monroe's accomplishments as President included the purchase of Florida, limiting the expansion of slavery, the admission of Maine and Missouri as States, and the promulgation of principles that became known as the ``Monroe Doctrine'' on December 2, 1823, expanding the concept of hemispheric independence beyond the United States--truly making him one of the most important figures in our Nation's history. (6) The bicentennial of the election of James Monroe as President will occur in 2016, an election which ushered in what has been known since as the ``Era of Good Feelings''. SEC. 3. COIN SPECIFICATIONS. (a) Denominations.--In commemoration of the bicentennial of the election of James Monroe to the first of 2 terms as President of the United States of America, the Secretary of the Treasury (hereafter in this Act referred to as the ``Secretary'') shall mint and issue the following coins: (1) $50 gold coins.--Not more than 20,000 $50 gold coins which shall-- (A) weigh 33.931 grams; (B) have a diameter of 32.7 millimeters; and (C) contain 1 troy ounce of fine gold. (2) $1 silver coins.--Not more than 275,000 $1 coins which shall-- (A) weigh 26.73 grams; (B) have a diameter of 1.500 inches; and (C) contain 90 percent silver and 10 percent copper. (3) Half dollar clad coins.--Not more than 500,000 half dollar coins, which shall-- (A) weigh 11.34 grams; (B) have a diameter of 1.205 inches; and (C) be minted to the specifications for half dollar coins, contained in section 5112(b) of title 31, United States Code. (b) Legal Tender.--The coins minted under this Act shall be legal tender, as provided in section 5103 of title 31, United States Code. (c) Numismatic Items.--For purposes of section 5134 of title 31, United States Code, all coins minted under this Act shall be considered to be numismatic items. SEC. 4. DESIGN OF COINS. (a) Design Requirements.-- (1) In general.--The design of the coins minted under this Act shall be emblematic of President James Monroe and his immeasurable contributions to the United States. (2) Obverse.--The obverse of the coins minted under this Act shall bear the side profile image of President James Monroe based upon Rembrandt Peale's 1830 portrait which the James Monroe Memorial Foundation donated to The Commonwealth of Virginia in 1964. (3) Reverse.--The reverse of the coins minted under this Act shall bear the image of the Monroe birthplace as drawn by the Colonial Williamsburg Foundation based on the 1830 drawing published as an etching. (4) Designations and inscriptions.--On each coin minted under this Act, there shall be-- (A) a designation of the value of the coin; (B) an inscription of the year ``2016''; and (C) inscriptions of the words ``Liberty'', ``In God We Trust'', ``United States of A\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"African Higher Education Expansion and Improvement Act of 2009 - Expresses the sense of Congress regarding the importance to the development of sub-Saharan Africa of support for the improvement of primary, secondary, and higher education in that region. States that it is this country's policy to provide Africa with long-term assistance to improve the capacity of its institutions of higher education (IHEs) through partnerships with our IHEs. Amends the Foreign Assistance Act of 1961 to authorize the President to provide long-term assistance to sub-Saharan Africa that improves higher education by: (1) building the capacity of IHEs in sub-Saharan Africa; (2) building linkages and partnerships between sub-Saharan IHEs and our IHEs; (3) assisting efforts to recruit and retain women as students, faculty, and administrators; and (4) establishing an American University in West Africa. Requires the Administrator of the U.S. Agency for International Development (USAID) to designate a Director of Assistance to Support and Promote Higher Education in Sub-Saharan Africa, who is to carry out such activities. Establishes a Sub-Saharan African Higher Education Advisory Board within USAID, which is appointed by the Administrator and composed of individuals from the private sector who have the requisite experience with Africa and higher education to assist the Director. Urges the Director and the Board to make every effort to leverage resources from the private sector in carrying out their responsibilities.\", 'positives': [\"Congress finds the following: (1) The demand for higher education in Africa has been increasing at very high rates and is rapidly overtaking the capacity of current infrastructure and staffing capability. (2) Africa's challenges in higher education are substantial and have important social, economic, and stability dimensions. (3) Despite increasing enrollments, sub-Saharan Africa's gross enrollment ration is just 5 percent as compared to 11 percent in India, 20 percent in China, and 70 percent in high income countries. (4) On average, institutions of higher education in Africa have only about 70 percent of the staff required by their programs; staff development, nurturing and retention are important elements of higher education programming. (5) In 2005, only 28 percent of African University graduates completed their degrees in science and technology (STEM) fields--agriculture, engineering, health sciences, general sciences. (6) African higher education institutions have addressed many critical development challenges in collaboration with regional and international counterparts, such as the United Nations, the International Agricultural Research Centres, and bilateral and regional assistance agencies. (7) Higher education has expanded to provide more opportunities for advanced education to graduates of the secondary school systems and it has sought new ways to achieve university collaboration across national and regional boundaries. (8) Africa has made important strides as public universities have doubled from roughly 100 to 200 from 1990 to 2007 and private tertiary institutions have increased from around 24 to an estimated 468 during this same period. (9) Historically, sub-Saharan Africa was marked by several centers of excellence in higher education. Linked to former European sponsors, institutions such as Makerere University in Uganda, Kenyatta University in Kenya, Cheik Anta Diop University, Senegal, and the University of Ibadan in Nigeria graduated scholars and professionals that were highly prized around the globe and that served the interests of their respective nations well. (10) These universities serve as ``centres of excellence'' that also have major positive impacts on other universities in their respective regions, and are currently making substantial progress in regaining their national and international prominence. (11) Increasing rates of higher education in developing countries is a critical component to long-term economic growth and stability and poverty reduction. (12) Estimates indicate that a 1-year increase in tertiary education stock would raise steady-state levels of African Gross Domestic Product per capita by 12.2 percent due to factor inputs, potentially boosting incomes by 3 percent after 5 years. (13) Studies of 17 countries found that individuals with higher education levels were more likely to engage in entrepreneurial activity, and more educated entrepreneurs created larger numbers of jobs than less educated entrepreneurs. (14) Research has found a positive and statistically significant correlation between higher education enrollment rates and governance indicators, including absence of corruption, higher stands of rule of law, absence of ethnic tensions, increased bureaucratic quality, low risk of repudiation of contracts by governments, and low risk of appropriation abuse. (15) A cadre of skilled, educated Africans is a necessary component to addressing every sector of development, whether it be poverty alleviation and economic growth, combating disease, improving governance, or rule of law and human rights, but such a cadre does not currently exist in large enough numbers to truly effect a sea-change in these areas in most of the countries in the region. (16) Exchange programs which bring Africans to developed countries for training, while an essential component of building i\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Oversight Commission on Presidential Capacity Act This bill establishes in the legislative branch an Oversight Commission on Presidential Capacity to determine whether the President is mentally or physically unable to discharge the powers and duties of office. The commission: (1) within 72 hours after Congress adopts a concurrent resolution directing it to do so, shall conduct a medical examination to determine if the President is temporarily or permanently impaired by physical illness or disability, mental illness, mental deficiency, or alcohol or drug use to the extent that he or she lacks sufficient understanding or capacity to execute the powers and duties of the office of President; and (2) within 72 hours after completing the examination, shall report its findings and conclusions to the Speaker of the House of Representatives and the President pro tempore of the Senate. Any refusal by the President to undergo such examination shall be taken into consideration by the commission in reaching a conclusion.', 'positives': [\"There is established a commission in the legislative branch to be known as the ``Oversight Commission on Presidential Capacity'' (in this Act referred to as the ``Commission''). The Commission shall serve as the body provided by law by Congress to carry out section 4 of the 25th Amendment to the Constitution of the United States. SEC. 3. DUTY OF COMMISSION. (a) In General.--If directed by Congress pursuant to section 5, the Commission shall carry out a medical examination of the President to determine whether the President is mentally or physically unable to discharge the powers and duties of the office, as described under subsection (b). (b) Determination.--The determination under subsection (a) shall be made if the Commission finds that the President is temporarily or permanently impaired by physical illness or disability, mental illness, mental deficiency, or alcohol or drug use to the extent that the person lacks sufficient understanding or capacity to execute the powers and duties of the office of President. SEC. 4. MEMBERSHIP. (a) Number and Appointment.--The Commission shall be composed of 11 members, appointed as follows: (1) Two members appointed by the majority leader of the Senate. (2) Two members appointed by the minority leader of the Senate. (3) Two members appointed by the Speaker of the House of Representatives. (4) Two members appointed by the minority leader of the House of Representatives. (5) Two members-- (A) one of whom is appointed jointly by the two appointing individuals under paragraphs (1) through (4) who are members of, or caucus with, the Democratic party; (B) one of whom is appointed jointly by the two appointing individuals under paragraphs (1) through (4) who are members of, or caucus with, the Republican party; and (C) each of whom has served as President, Vice President, Secretary of State, Attorney General, Secretary of the Treasury, Secretary of Defense, or Surgeon General. (6) One member, to serve as Chair of the Commission, appointed by simple majority vote of the 10 members appointed under paragraphs (1) through (5). (b) Criteria for Appointment.-- (1) In general.--Each member appointed to the Commission under paragraphs (1) through (4) of subsection (a) shall be a physician. Of the two members appointed by each individual under such paragraphs, one shall be a physician with a specialty in psychiatry. The Chair shall be either a physician or an individual appointed under paragraph (5) of subsection (a), or both. (2) Limitations.--A member appointed under subsection (a) may not, at the time the member is appointed or serving as a member on the Commission, be-- (A) an elected official to any Federal, State, or local office; (B) an employee (as that term is defined in section 2105 of title 5, United States Code, including any employee of the United States Postal Service or the Postal Regulatory Commission); or (C) a member of the Armed Forces, including reserve components thereof. (3) Physician defined.--In this subsection, the term ``physician'' means a doctor of medicine licensed to practice medicine, surgery, or osteopathy in a State. (c) Travel Expenses.--Each member shall receive travel expenses, including per diem in lieu of subsistence, in accordance with applicable provisions under subchapter I of chapter 57 of title 5, United States Code. (d) Terms.-- (1) In general.--Each member shall be appointed for a term of 4 years. A member may serve after the expiration of that member's term until a successor has taken office. (2) Appointment.--Each member shall be appointed during the period beginning on the date that a Presidential election is held and ending on the date that is 30 days after such election date. (3) Vacancies.--A vacancy in the Commission shall be filled in the manner in which the original appointment was made, not later than 30 days after the vacancy occurs. Any m\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Student Testing Flexibility Act of 2002 - Amends the Elementary and Secondary Education Act of 1965 (ESEA) to direct the Secretary of Education to grant waivers of certain annual testing and assessment requirements to States and local educational agencies (LEAs) if they demonstrate that they have: (1) significantly closed the achievement gap between certain groups of students; or (2) exceeded their adequate yearly progress for two or more consecutive years.Requires States and LEAs receiving such waivers to use ESEA annual assessment funds for educational activities which they determine will improve the academic achievement of students attending public elementary schools and secondary schools that fail to make adequate yearly progress. Prohibits such States and LEAs from using such funds to pay a student's private school costs.\", 'positives': [\"Congress finds that-- (1) State and local governments bear the majority of the cost and responsibility of educating public elementary school and secondary school students; (2) State and local governments often struggle to find adequate funding to provide basic educational services; (3) the Federal Government has not provided its share of funding for numerous federally mandated elementary and secondary education programs; (4) underfunded Federal education mandates increase existing financial pressures on States and local educational agencies; (5) the cost to States and local educational agencies to implement the annual student academic assessments required under section 1111(b)(3)(C)(vii) of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 6311(b)(3)(C)(vii)) remains uncertain; (6) public elementary school and secondary school students take numerous tests each year, from classroom quizzes and exams to standardized and other tests required by the Federal Government, State educational agencies, or local educational agencies; (7) multiple measures of student academic achievement provide a more accurate picture of a student's strengths and weaknesses than does a single score on a high-stakes test; and (8) the frequency of the use of high quality assessments as a tool to measure and increase student achievement should be decided by State educational agencies and local educational agencies. SEC. 3. WAIVER AUTHORITY. Section 1111(b)(3) of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 6311(b)(3)) is amended by adding at the end the following: ``(E) Waiver authority.-- ``(i) States.--Upon application by a State educational agency, the Secretary shall waive the requirements of subparagraph (C)(vii) for a State if the State educational agency demonstrates that the State-- ``(I) significantly closed the achievement gap between the groups of students described in paragraph (2); or ``(II) exceeded the State's adequate yearly progress, consistent with paragraph (2), for 2 or more consecutive years. ``(ii) Local educational agencies.--Upon application of a local educational agency located in a State that does not receive a waiver under clause (i), the Secretary shall waive the application of the requirements of subparagraph (C)(vii) for the local educational agency if the local educational agency demonstrates that the local educational agency-- ``(I) significantly closed the achievement gap between the groups of students described in paragraph (2); or ``(II) exceeded the local educational agency's adequate yearly progress, consistent with paragraph (2), for 2 or more consecutive years. ``(iii) Period of waiver.--A waiver under clause (i) or (ii) shall be for a period of 3 years and may be renewed for subsequent 3-year periods. ``(iv) Utilization of certain federal funds.-- ``(I) Permissive uses.--Subject to subclause (II), a State or local educational agency granted a waiver under clause (i) or (ii) shall use funds, that are awarded to the State or local educational agency, respectively, under this Act for the development and implementation of annual assessments under subparagraph (C)(vii), to carry out educational activities that the State educational agency or local educational agency, respectively, determines will improve the academic achievement of students attending public elementary schools and secondary schools in the State or local educational agency, respectively, that fail to make adequate yearly progress (as defined in paragraph (2)(C)). ``(II) Nonpermissive use of funds.--A State or local educational agency granted a waiver under clause (i) or (ii) shall not use funds, that are awarded to the State or local educational agency, respectively, under this Act for the development and implementation of annual assessments under subparagraph (C)(vii), to pay a student's cost of tuition, room, board, or fees at a priv\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Preventing Our Kids From Inhaling Deadly Smoke (PRO-KIDS) Act of 1993 - Directs the Administrator of the Environmental Protection Agency to issue guidelines for enforcing a nonsmoking policy at indoor facilities where children's services are provided. Requires such policy, at a minimum, to prohibit smoking in each portion of such a facility that is not ventilated separately. Directs the Administrator and the Secretary of Health and Human Services to provide technical assistance to persons who provide children's services and other persons who request it. Authorizes persons who make a good-faith effort to enforce a nonsmoking policy that meets requirements to petition their funding Federal agency for a waiver from the general requirements. Sets forth conditions for granting waivers, including that the person requesting the waiver will make a good-faith effort to enforce an alternative nonsmoking policy to protect children. Provides for special waivers for persons who provide children's services pursuant to certain collective bargaining agreements. Prescribes civil penalties for violations of this Act. Exempts from this Act's requirements registered persons providing children's services in a private residence to grandchildren, nieces, or nephews. Directs the Administrator to report to the Congress on information concerning compliance with this Act and an assessment of the legal status of smoking in public places.\", 'positives': [\"Congress finds that-- (1) environmental tobacco smoke comes from secondhand smoke exhaled by smokers and sidestream smoke emitted from the burning of cigarettes, cigars, and pipes; (2) since citizens of the United States spend up to 90 percent of a day indoors, there is a significant potential for exposure to environmental tobacco smoke from indoor air; (3) exposure to environmental tobacco smoke occurs in schools, public buildings, and other indoor facilities; (4) recent scientific studies have concluded that exposure to environmental tobacco smoke is a cause of lung cancer in healthy nonsmokers and is responsible for acute and chronic respiratory problems and other health impacts in sensitive populations (including children); (5) the health risks posed by environmental tobacco smoke exceed the risks posed by many environmental pollutants regulated by the Environmental Protection Agency; and (6) according to information released by the Environmental Protection Agency, environmental tobacco smoke results in a loss to the economy of over $3,000,000,000 per year. SEC. 3. DEFINITIONS. As used in this Act: (1) Administrator.--The term ``Administrator'' means the Administrator of the Environmental Protection Agency. (2) Children.--The term ``children'' means individuals who have not attained the age of 18. (3) Children's services.--The term ``children's services'' means-- (A)(i) direct health services routinely provided to children; or (ii) any other direct services routinely provided primarily to children, including educational services; and (B) that are funded (in whole or in part) by Federal funds. (4) Secretary.--The term ``Secretary'' means the Secretary of Health and Human Services. SEC. 4. NONSMOKING POLICY FOR CHILDREN'S SERVICES. (a) Issuance of Guidelines.--Not later than 180 days after the date of enactment of this Act, the Administrator shall issue guidelines for instituting and enforcing a nonsmoking policy at each indoor facility where children's services are provided. (b) Contents of Guidelines.--A nonsmoking policy that meets the requirements of the guidelines shall, at a minimum, prohibit smoking in each portion of an indoor facility where children's services are provided that is not ventilated separately (as defined by the Administrator) from other portions of the facility. SEC. 5. TECHNICAL ASSISTANCE AND OUTREACH ACTIVITIES. (a) Technical Assistance.--The Administrator and the Secretary shall provide technical assistance to persons who provide children's services and other persons who request technical assistance. The technical assistance shall include information-- (1) on smoking cessation programs for employees; and (2) to assist in compliance with the requirements of this Act. SEC. 6. FEDERALLY FUNDED PROGRAMS. (a) In General.--Notwithstanding any other provision of law, each person who provides children's services shall establish and make a good-faith effort to enforce a nonsmoking policy that meets or exceeds the requirements of subsection (b). (b) Nonsmoking Policy.-- (1) General requirements.--A nonsmoking policy meets the requirements of this subsection if the policy-- (A) is consistent with the guidelines issued under section 4(a); (B) prohibits smoking in each portion of an indoor facility used in connection with the provision of services directly to children; and (C) where appropriate, requires that signs stating that smoking is not permitted be posted in each indoor facility to communicate the policy. (2) Permissible features.--A nonsmoking policy that meets the requirements of this subsection may allow smoking in those portions of the facility-- (A) in which services are not normally provided directly to children; and (B) that are ventilated separately from those portions of the facility in which services are normally provided directly to children. (c) Waiver.-- (1) In genera\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Directs the court, upon application made by an attorney for the Government or by a State investigative or law enforcement officer, to enter an ex parte order authorizing the installation and use of such a device if it finds that such attorney or officer has certified that the information likely to be obtained is relevant to an ongoing criminal investigation. Requires the order to specify a description of the communications to which the order applies, including the number or other identifier and, if known, the location of the telephone line or other facility to which the device is to be attached or applied, and, in with respect to States, the geographic limits of the order. Provides for emergency installation of such a device in situations involving: (1) an immediate threat to U.S. national security interests or to public health or safety; or (2) an attack on the integrity or availability of a protected computer if such attack would be a Federal computer fraud offense. Modifies the definitions of: (1) \"court of competent jurisdiction\" to mean any U.S. district court or any U.S. Court of Appeals having jurisdiction over the offense being investigated; and (2) \"pen register\" and \"trap and trace device\" to cover processes (as well as devices) and dialing, routing, addressing, or signaling information with respect to a wire or electronic communication. (Sec. 2) Revises Federal criminal code (the code) provisions regarding penalties for fraud and related activity in connection with computers to cover certain attempts to commit punishable offenses and to provide penalties for offenses (or attempts) regarding: (1) loss to one or more persons during any one-year period aggregating at least $5,000 in value; (2) the modification or impairment, or potential modification or impairment, of the medical examination, diagnosis, treatment, or care of one or more individuals; (3) physical injury to any person; (4) a threat to public health or safety; or (5) damage affecting a computer system used by or for a government entity in furtherance of the administration of justice, national defense, or national security. Repeals a limitation on damages in civil actions to economic damages if any of subparagraphs (2) through (5) apply. Directs the court, in imposing sentence on any person convicted of a violation, to order, in addition to any other sentence imposed and irrespective of any State law provision, that such person forfeit to the United States: (1) any property that was used to commit or to facilitate such violation; and (2) any property constituting or derived from any proceeds that such person obtained as a result of such violation. Makes specified Controlled Substances Act provisions regarding the criminal forfeiture, seizure, and disposition of property applicable to this section. Sets forth similar provisions with respect to civil forfeiture. (Sec. 3) Amends provisions of the code regarding juvenile delinquency proceedings in district courts, and transfer for criminal prosecution, to cover situations involving fraud and related activity in connection with computers. (Sec. 4) Modifies provisions of the Antiterrorism and Effective Death Penalty Act of 1996 to direct the United States Sentencing Commission to amend the sentencing guidelines to ensure that any individual convicted of a felony violation of the prohibition against knowingly causing the transmission of a program, information, code, or command and thereby intentionally causing damage, without authorization, to a protected computer is imprisoned for not less than six months. (Sec. 5) Authorizes the Secretary of Defense to make grants to, or enter into contracts with, a qualified entity or organization to: (1) conduct research for the prevention of cyberterrorism or to develop technology products or services designed for use in its prevention; and (2) make improvements to the critical information protection architecture of such entity or organization or to refinance improvements previously made to such architecture. Sets forth reporting requirements. Authorizes appropriations.', 'positives': [\"SECTION 1. MODIFICATION OF AUTHORITIES RELATING TO USE OF PEN REGISTERS AND TRAP AND TRACE DEVICES. (a) General Limitation on Use by Governmental Agencies.--Section 3121(c) of title 18, United States Code, is amended-- (1) by inserting ``or trap and trace device'' after ``pen register''; (2) by inserting ``, routing, addressing,'' after ``dialing''; and (3) by striking ``call processing'' and inserting ``the processing and transmitting of wire and electronic communications''. (b) Issuance of Orders.-- (1) In general.--Subsection (a) of section 3123 of that title is amended to read as follows: ``(a) In General.--(1) Upon an application made under section 3122(a)(1) of this title, the court shall enter an ex parte order authorizing the installation and use of a pen register or trap and trace device if the court finds that the attorney for the Government has certified to the court that the information likely to be obtained by such installation and use is relevant to an ongoing criminal investigation. The order shall, upon service of the order, apply to any entity providing wire or electronic communication service in the United States whose assistance is required to effectuate the order. ``(2) Upon an application made under section 3122(a)(2) of this title, the court shall enter an ex parte order authorizing the installation and use of a pen register or trap and trace device within the jurisdiction of the court if the court finds that the State law enforcement or investigative officer has certified to the court that the information likely to be obtained by such installation and use is relevant to an ongoing criminal investigation.''. (2) Contents of order.--Subsection (b)(1) of that section is amended-- (A) in subparagraph (A)-- (i) by inserting ``or other facility'' after ``telephone line''; and (ii) by inserting before the semicolon at the end ``or applied''; and (B) by striking subparagraph (C) and inserting the following new subparagraph (C): ``(C) a description of the communications to which the order applies, including the number or other identifier and, if known, the location of the telephone line or other facility to which the pen register or trap and trace device is to be attached or applied, and, in the case of an order authorizing installation and use of a trap and trace device under subsection (a)(2), the geographic limits of the order; and''. (3) Nondisclosure requirements.--Subsection (d)(2) of that section is amended-- (A) by inserting ``or other facility'' after ``the line''; and (B) by striking ``or who has been ordered by the court'' and inserting ``or applied or who is obligated by the order''. (c) Emergency Installation.--Section 3125(a)(1) of that title is amended-- (1) in subparagraph (A), by striking ``or'' at the end; (2) in subparagraph (B), by striking the comma at the end and inserting a semicolon; and (3) by inserting after subparagraph (B) the following new subparagraphs: ``(C) immediate threat to the national security interests of the United States; ``(D) immediate threat to public health or safety; or ``(E) an attack on the integrity or availability of a protected computer which attack would be an offense punishable under section 1030(c)(2)(C) of this title,''. (d) Definitions.-- (1) Court of competent jurisdiction.--Paragraph (2) of section 3127 of that title is amended by striking subparagraph (A) and inserting the following new subparagraph (A): ``(A) any district court of the United States (including a magistrate judge of such a court) or any United States Court of Appeals having jurisdiction over the offense being investigated; or''. (2) Pen register.--Paragraph (3) of that section is amended-- (A) by striking ``electronic or other impulses'' and all that follows through ``is attached'' and inserting ``dialing, routing, addressing, or signalling information transmitted by an instrument or facility from which a wire or electronic communication is transmitted''; and (B) by inserting ``or process'' after ``device'' ea\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Building Opportunities Bonus Act - Amends part A (Temporary Assistance for Needy Families) (TANF) of title IV of the Social Security Act to establish a building opportunities bonus program under provisions regarding State family assistance grants in order to reward high performance States under TANF. Authorizes appropriations.', 'positives': [\"Section 403(a) of the Social Security Act (42 U.S.C. 603(a)) is amended by adding at the end the following: ``(6) Building opportunities bonus.-- ``(A) In general.--The Secretary shall make a grant pursuant to this paragraph to each State for each bonus year for which the State is a high performing State. ``(B) Amount of grant.-- ``(i) In general.--Subject to clause (ii), the Secretary shall determine the amount of the grant payable under this paragraph to a high performing State for a bonus year, which shall be based on the score assigned to the State under subparagraph (D)(i) for the fiscal year that immediately precedes the bonus year. ``(ii) Limitation.--The amount payable to a State under this paragraph for a bonus year shall not exceed 5 percent of the State family assistance grant and shall be used to address the matters set forth in subparagraph (C). ``(C) Criteria for measuring state performance.-- Not later than 1 year after the date of the enactment of this paragraph, the Secretary, in consultation with the National Governor's Association and the Institute for Women's Policy Research, shall develop criteria for measuring State performance in operating the State program funded under this part to address the following matters as they relate to the ability of recipients of assistance under the State program to become economically self-sufficient: ``(i) Child care.--Whether States are-- ``(I) ensuring an adequate supply of safe, accessible, appropriate, and quality child care slots; ``(II) helping women identify and place children in safe, accessible, appropriate, and quality child care; ``(III) ensuring that available child care slots are filled; ``(IV) improving the quality of child care by ensuring that child care providers are adequately paid and trained; ``(V) increasing access to safe, accessible, appropriate, and quality child care by making child care subsidies available to recipients of assistance under the State program funded under this part and families that earn up to 85 percent of the State's median income; ``(VI) collaborating with State child care resource and referral agencies and child care development experts in developing and implementing child care programs and policies; and ``(VII) collaborating with State domestic violence coalitions to address the child care needs of families affected by domestic violence. ``(ii) Employment.--Whether States are-- ``(I) providing education and training for recipients of assistance under the State program under this part for employment that pays a sustainable wage, such as apprenticeable, technical, and professional occupations, and nontraditional employment; ``(II) placing such recipients in such employment; ``(III) retaining such recipients in such employment; ``(IV) providing career development assistance including job readiness training, reliable, up-to-date career counseling services, and employability assessments on available employment that pays a sustainable wage, such as nontraditional training and education options and employment opportunities to all women entering welfare-to-work programs; and ``(V) utilizing resources available under title I of the Workforce Investment Act of 1998, including section 134(a)(3)(A)(vi)(II) of such Act, to support State efforts on education, training, placement, retention, and career development assistance, as described in subclauses (I) through (IV). ``(iii) Domestic violence.--Whether States are-- ``(I) collaborating with State domestic violence coalitions in implementing substantive programs addressing domestic violence as an impediment to women's work and education (such as through demonstration and model projects), programs placing domestic violence advocates in welfare offices, and programs providing employment and support services for victims of domestic violence that will reach a substa\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Small Business Emergency Fuel Assistance Act of 2007 - Establishes within the Economic Development Administration of the Department of Commerce an emergency assistance program for small businesses and small farms dependent on fuel. Authorizes the President to declare a federal energy emergency if the health, safety, welfare, or economic well-being of U.S. citizens is at risk because of an imminent or actual shortage of adequate supplies of crude oil, gasoline or petroleum distillates owing to: (1) a disruption in the national distribution system for such distillates (including a shortage related to a major disaster); or (2) significant pricing anomalies in national energy markets for them. Authorizes the Secretary of Commerce to award grants to states under a presidential declaration of fuel supply interruption.', 'positives': ['There is established within the Economic Development Administration of the Department of Commerce, an emergency assistance program for small businesses and small farms dependent on fuel. SEC. 3. PRESIDENTIAL DECLARATION OF ENERGY EMERGENCY. (a) In General.--If the President determines that the health, safety, welfare, or economic well-being of the citizens of the United States is at risk because of a shortage or imminent shortage of adequate supplies of crude oil, gasoline or petroleum distillates due to a disruption in the national distribution system for crude oil, gasoline or petroleum distillates (including such a shortage related to a major disaster (as defined in section 102(2) of the Robert T. Stafford Disaster Relief and Emergency Assistance Act (42 U.S.C. 5122(2)))), or significant pricing anomalies in national energy markets for crude oil, gasoline, or petroleum distillates, the President may declare that a Federal energy emergency exists. (b) Scope and Duration.--The emergency declaration declared pursuant to subsection (a) shall specify-- (1) the period, not to exceed 30 days, for which the declaration applies; (2) the circumstance or condition necessitating the declaration; (3) the area or region to which it applies which may not be limited to a single State; and (4) the product or products to which it applies. (c) Extensions.--The President may-- (1) extend a declaration under subsection (a) for a period of not more than 30 days; (2) extend such a declaration more than once; and (3) discontinue such a declaration before its expiration. SEC. 4. AUTHORIZATION OF GRANTS. (a) In General.--During any energy emergency declared by the President under section 3, the Secretary of Commerce is authorized to award grants to States under a declaration of fuel supply interruption in accordance with this Act. (b) Allocation Formula.--Subject to subsection (c), the Secretary shall award grants to States, in accordance with an allocation formula established by the Secretary, that is based on the pro rata share of each State of the total need among all States, as applicable, for emergency assistance for fuel interruption, as determined on the basis of-- (1) the number and percentage of qualifying small businesses and small farms operating within a State; (2) the increase in price of fuel in a State; and (3) such other factors as the Secretary determines to be appropriate. (c) State Allocation Plan.--Each State shall establish, after giving notice to the public, an opportunity for public comment, and consideration of public comments received, an allocation plan for the distribution of financial assistance under this section, which shall be submitted to the Secretary and shall be made available to the public by the State, and shall include-- (1) application requirements for qualifying small businesses and small farms seeking to receive financial assistance under this section, including a requirement that each application include-- (A) demonstration of need for assistance under this section; (B) a plan to decrease the total commercial energy usage of the small business through energy efficiency measures, such as those promoted through the Energy Star Program; and (C) if a small business or small farm has previously received assistance under this section, evidence that the small business or small farm has implemented the plan previously documented under subparagraph (B); and (2) factors for selecting among small businesses and small farms that meet the application requirements, with preference given to small businesses and small farms based on the percentage of operating costs expended on fuel. SEC. 5. ELIGIBILITY. A small business or small farm is eligible for a grant under this Act if-- (a) the average gross receipts of the small business or small farm for the 3 preceding taxable years does not exceed'], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"TABLE OF CONTENTS: Title I: Mission Assignment Title II: Governance Department of Energy Laboratory Missions Act - Title I: Mission Assignment - Authorizes the Department of Energy (DOE) to maintain departmental laboratories to advance and implement research and development (R&D) activities essential to the following core missions: (1) maintain national security; (2) ensure domestic energy supply and reduce reliance on imported energy sources; (3) conduct basic research in energy-related science and technology, in the fundamental understanding of matter, and in emerging scientific fields; (4) carry out R&D to minimize environmental impacts of the production and use of energy, nuclear weapons, and materials, including the development of technologies for safe hazardous and radioactive waste disposal and cleanup; and (5) implement such additional missions as are assigned by the President. (Sec. 103) Instructs the Secretary of Energy to transmit to certain congressional committees the criteria to be used in making proposals for mission assignments and the streamlining of departmental laboratories. Requires the Comptroller General to report a detailed analysis of the Secretary's proposals and procedures to certain congressional committees. (Sec. 104) Directs the Secretary to: (1) complete the mission assignments and streamlining of all laboratories as outlined in the proposals by a specified deadline; and (2) transmit a status report to certain congressional committees as part of the annual budget request. Title II: Governance - Declares that DOE shall implement, but not be the agency of enforcement of, Federal, State, and local environmental, safety, and health promulgations at departmental laboratories unless the Secretary certifies that a particular action is unique to departmental activities and necessary for human health and safety.\", 'positives': [\"For purposes of this Act-- (1) the term ``departmental laboratory'' means a Federal laboratory, or any other laboratory or facility designated by the Secretary, operated by or on behalf of the Department of Energy; (2) the term ``Federal laboratory'' has the meaning given the term ``laboratory'' in section 12(d)(2) of the Stevenson- Wydler Technology Innovation Act of 1980 (15 U.S.C. 3710a(d)(2)); (3) the term ``relevant congressional committees'' means the Committee on Armed Services of the Senate, the Committee on National Security of the House of Representatives, the Committee on Science of the House of Representatives, and the Committee on Energy and Natural Resources of the Senate; and (4) the term ``Secretary'' means the Secretary of Energy. TITLE I--MISSION ASSIGNMENT SEC. 101. FINDINGS. The Congress finds that-- (1) through their unique historical missions, the departmental laboratories have developed core competencies and technical capabilities that strategically position them to contribute to the scientific and technological wellbeing of the Nation; (2) the departmental laboratories have contributed and continue to contribute technology to ensure the maintenance of the nuclear deterrent and other elements of the national security; (3) through their contributions to the national security in the production of nuclear and conventional weapons, the departmental laboratories have helped deter the repetition of the global conflicts of the past, and have helped maintain the relative peace which the United States enjoys; (4) the departmental laboratories collectively represent an extensive science and technology resource of people, facilities, and equipment that contribute to the achievement of national technology goals; (5) in carrying out their Department of Energy mission responsibilities, the departmental laboratories have established successful collaborative relationships with other Federal agencies, universities, and other federally funded laboratories that allow each of the partners to share and leverage their unique capabilities; (6) collaboration in partnerships among the departmental laboratories, other Federal agencies, universities, and private industry, especially through cooperative research and development agreements, should be encouraged to enable the departmental laboratories to ensure the maximum return on the taxpayer's investment; and (7) the departmental laboratories need well defined and assigned missions to continue to successfully contribute to the scientific, technological, and national security interests of the United States. SEC. 102. MISSIONS. The Department of Energy may maintain departmental laboratories for the purpose of advancing, and shall carry out research and development activities which are essential to support and perform, the following core missions: (1) To maintain national security, as follows: (A) To provide for the Nation's nuclear weapons requirements, to be stewards of the Nation's nuclear weapons stockpile, and to meet other national security requirements as determined by the President. (B) To reduce the threat of nuclear war, by assisting with the dismantlement of nuclear weapons, working to curb the proliferation of weapons of mass destruction, including nuclear, chemical, and biological weapons, supporting efforts to counter the proliferation of weapons of mass destruction, including nuclear, chemical, and biological weapons, and their delivery systems, and conducting research on and the development of technologies needed for the effective verification of international arms control agreements, including prospective international arms control agreements, which may include the production and dissemination of foreign intelligence pertinent to the Department's missions. (C) To provide for the advancement of science and technology in the development of nuclear and conventional w\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"United States-Israel Alzheimer's Disease Cooperation Act - Directs the Secretary of Health and Human Services (HHS) to establish a program of grants to support research on the development and commercialization of tools, treatments, and cures for Alzheimer's disease and other dementias. Requires eligible projects to be joint ventures between U.S. and Israeli non-governmental entities or the U.S. and Israeli governments. Establishes an advisory board to monitor the method by which grants are awarded and to provide performance reviews of actions taken to carry out this Act.\", 'positives': [\"The Congress finds the following: (1) It is in the highest national interests of the United States to further research into Alzheimer's disease. (2) The State of Israel is a steadfast ally of the United States. (3) The special relationship between the United States and Israel is manifested in a variety of cooperative scientific research and development programs, such as-- (A) the United States-Israel Binational Science Foundation; (B) the United States-Israel Binational Industrial Research and Development Foundation; and (C) the United States-Israel Energy Cooperation Act. (4) Those programs have made possible many scientific, technological, and commercial breakthroughs in fields including the life sciences, medicine, bioengineering, agriculture, biotechnology, communications, and energy development. (5) Israeli scientists are at the forefront of research and development in the field of Alzheimer's disease. (6) Enhanced cooperation between the United States and Israel for the purpose of research in Alzheimer's disease would be in the national interests of both countries. SEC. 3. GRANTS FOR ALZHEIMER'S DISEASE RESEARCH. (a) Grant Program.-- (1) Establishment.--The Secretary of Health and Human Services (in this section referred to as the ``Secretary'') shall establish a program of awarding grants to support research on the development and commercialization of applicable tools, treatments, and cures for Alzheimer's disease and other dementias. (2) Eligible projects.--To be eligible for funding under this section, a project shall-- (A) be designed to further research described in paragraph (1); and (B) be a joint venture between-- (i)(I) a for-profit business entity, academic institution, National Laboratory (as defined in section 2 of the Energy Policy Act of 2005 (42 U.S.C. 15801)), or nonprofit entity in the United States; and (II) a for-profit business entity, academic institution, or nonprofit entity in Israel; or (ii)(I) the Federal Government; and (II) the Government of Israel. (3) Applications.--To seek a grant under this section, an applicant shall submit to the Secretary an application in accordance with procedures established by the Secretary, in consultation with the advisory board established under paragraph (4). (4) Advisory board.-- (A) Establishment.--The Secretary shall establish an advisory board-- (i) to monitor the method by which grants are awarded under this section; and (ii) to provide to the Secretary periodic performance reviews of actions taken to carry out this section. (B) Composition.--The advisory board established under subparagraph (A) shall be composed of 3 members, to be appointed by the Secretary, of whom-- (i) 1 shall be a representative of the Federal Government; (ii) 1 shall be selected from a list of nominees provided by the United States-Israel Binational Science Foundation; and (iii) 1 shall be selected from a list of nominees provided by the United States-Israel Binational Industrial Research and Development Foundation. (5) Contributed funds.--Notwithstanding section 3302 of title 31, United States Code, the Secretary may accept, retain, and use funds contributed by any person, government entity, or organization for purposes of carrying out this section-- (A) without further appropriation; and (B) without fiscal year limitation. (6) Report.--Not later than 180 days after the date of completion of a project for which a grant is provided under this section, the grant recipient shall submit to the Secretary a report that contains-- (A) a description of the method by which the recipient used the grant funds; and (B) an evaluation of the level of success of each project funded by the grant. (7) Classification.--Grants shall be awarded under this section only for projects that are considered to be unclassified by both the United States and Israel. (b) Termination.--The grant program\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Amends the Internal Revenue Code to allow a first-time homebuyer who purchases a principal residence a tax credit of ten percent of the purchase price of such residence. Limits the credit to $6,500. Requires married individuals filing jointly to both be first-time homebuyers. Makes this credit applicable to a principal residence only if the taxpayer enters into, on or after June 1, 2001, and before June 1, 2002, a binding contract to purchase the residence, and purchases and occupies the residence before January 1, 2003.', 'positives': [\"SECTION 1. CREDIT FOR FIRST-TIME HOMEBUYERS. (a) In General.--Subpart A of part IV of subchapter A of chapter 1 of the Internal Revenue Code of 1986 (relating to nonrefundable personal credits) is amended by inserting after section 25A the following new section: ``SEC. 25B. PURCHASE OF PRINCIPAL RESIDENCE BY FIRST-TIME HOMEBUYER. ``(a) Allowance of Credit.--In the case of an individual who is a first-time homebuyer of a principal residence in the United States during any taxable year, there shall be allowed as a credit against the tax imposed by this chapter for the taxable year an amount equal to 10 percent of the purchase price of the residence. ``(b) Limitations.-- ``(1) Maximum credit.--The credit allowed under subsection (a) shall not exceed $6,500. ``(2) Limitation to one residence.--The credit under this section shall be allowed with respect to only one residence of the taxpayer. ``(3) Married individuals filing jointly.--In the case of a husband and wife who file a joint return, the credit under this section is allowable only if both the husband and wife are first-time homebuyers, and the amount specified under paragraph (1) shall apply to the joint return. ``(4) Married individuals filing separately.--In the case of a married individual filing a separate return, the credit under this section is allowable only if the individual is a first-time homebuyer, and subsection (a) shall be applied by substituting `$3,250' for `$6,500'. ``(5) Other taxpayers.--If 2 or more individuals who are not married purchase a principal residence, the amount of the credit allowed under subsection (a) shall be allocated among such individuals in such manner as the Secretary may prescribe, except that the total amount of the credits allowed to all such individuals shall not exceed $6,500. ``(c) Definitions.--For purposes of this section-- ``(1) First-time homebuyer.-- ``(A) In general.--The term `first-time homebuyer' means any individual is such individual (and if married, such individual's spouse) had no present ownership interest in a principal residence in the United States during the 3-year period ending on the date of the purchase of the principal residence to which this section applies. ``(B) One-time only.--If an individual is treated as a first-time homebuyer with respect to any principal residence, such individual may not be treated as a first-time homebuyer with respect to any other principal residence. ``(2) Principal residence.--The term `principal residence' has the same meaning as when used in section 121. ``(3) Purchase and purchase price.--The terms `purchase' and `purchase price' have the meanings provided by section 1400C(e). ``(d) Carryforward of Unused Credit.--If the credit allowable under subsection (a) for any taxable year exceeds the limitation imposed by section 26(a) for such taxable year reduced by the sum of the credits allowable under this subpart (other than this section), such excess shall be carried to the succeeding taxable year and added to the credit allowable under subsection (a) for such taxable year. ``(e) Reporting.--If the Secretary requires information reporting under section 6045 by a person described in subsection (e)(2) thereof to verify the eligibility of taxpayers for the credit allowable by this section, the exception provided by section 6045(e)(5) shall not apply. ``(f) Denial of Double Benefit.--No credit shall be allowed under subsection (a) if the credit under section 1400C is allowed. ``(g) Basis Adjustment.--For purposes of this subtitle, if a credit is allowed under this section with respect to the purchase of any residence, the basis of such residence shall be reduced by the amount of the credit so allowed. ``(h) Property to Which Section Applies.--The provisions of this section apply to a principal residence if the taxpayer enters into, on or after June 1, 2001, and before June 1, 2002, a binding contract to purchase the residence, and purchases and occupies the residence before January 1, 2003.''. (b) Co\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Servicemember Assistance for Lawful Understanding, Treatment, and Education Act or the SALUTE Act - Amends the Omnibus Crime Control and Safe Streets Act of 1968 to authorize the Attorney General to award grants for developing, implementing, or enhancing veterans' treatment courts or expanding operational mental health or drug courts to serve veterans to ensure that such courts effectively integrate substance abuse treatment, mental health treatment, sanctions and incentives, and transitional services, in a judicially supervised court setting with jurisdiction over offenders who are veterans. Authorizes the Attorney General to award such grants to states, state courts, local courts, local governments, and Indian tribal governments for court programs that involve: (1) continuing judicial supervision over offenders who are veterans with substance abuse or mental health problems; (2) coordination with appropriate federal, state, or local prosecutors; (3) coordination with the Veterans Health Administration; and (4) the integrated administration of other sanctions and services, including substance abuse and mental health treatment, supervised release involving the possibility of prosecution, confinement, or incarceration based on non-compliance with program requirements or failure to show satisfactory progress, and offender management. Prohibits the use of grant funds to provide judicial supervision over, treatment of, or other services to violent offenders. Sets forth application and reporting requirements. Directs the Comptroller General to conduct a study to assess the effectiveness and impact of such grant program.\", 'positives': [\"Title I of the Omnibus Crime Control and Safe Streets Act of 1968 (42 U.S.C. 3711 et seq.) is amended-- (1) by redesignating part JJ, as added by section 952 of Public Law 110-315 (relating to Loan Repayment for Prosecutors and Public Defenders), as part LL, and moving such part so that such part follows part KK; (2) in part LL, as so redesignated and moved by paragraph (1), by redesignating section 3001 as section 3021; and (3) by adding at the end the following new part: ``PART MM--VETERANS' TREATMENT COURTS ``SEC. 3031. GRANT AUTHORITY. ``(a) In General.--The Attorney General is authorized to award grants for developing, implementing, or enhancing veterans' treatment courts or expanding operational mental health or drug courts to serve veterans to ensure that such courts effectively integrate substance abuse treatment, mental health treatment, sanctions and incentives, and transitional services, in a judicially supervised court setting with jurisdiction over offenders who are veterans. The Attorney General may award such grants to States, State courts, local courts, units of local government, and Indian tribal governments, acting directly or through agreements with other public or private entities, for court programs that involve-- ``(1) continuing judicial supervision over offenders who are veterans with substance abuse or mental health problems; ``(2) coordination with appropriate Federal, State, or local prosecutors; ``(3) coordination with the Veterans Health Administration; and ``(4) the integrated administration of other sanctions and services, which shall include-- ``(A) substance abuse and mental health treatment (such as treatment for depression, traumatic brain injury, and post-traumatic stress disorder) for each participant who requires such treatment; ``(B) diversion, probation, or other supervised release involving the possibility of prosecution, confinement, or incarceration based on non-compliance with program requirements or failure to show satisfactory progress; and ``(C) offender management, which may include aftercare services such as relapse prevention, health care, education, vocational training, job placement, housing placement, and child care or other family support services for each participant who requires such services. ``(b) Limitation on Use of Funds.--Grant funds made available under this part may not be used to provide judicial supervision over, treatment of, or other services to violent offenders. A State, State court, local court, unit of local government, or Indian tribal government that receives a grant under this part may provide such supervision, treatment, or services to violent offenders who are otherwise eligible for veterans' treatment court participation only if such supervision, treatment, or services are funded exclusively with non-Federal funds. ``SEC. 3032. ADMINISTRATION. ``(a) Consultation.--In awarding grants under this part, the Attorney General shall consult with the Secretary of Veterans Affairs and any other appropriate officials. ``(b) Regulatory Authority.--The Attorney General may, in consultation with the Secretary of Veterans Affairs, issue regulations and guidelines necessary to carry out this part. ``(c) Applications.--In addition to any other requirements that may be specified by the Attorney General, in consultation with the Secretary of Veterans Affairs, an application for a grant under this part shall-- ``(1) include a long-term strategy and implementation plan that shall provide for the consultation and coordination with appropriate Federal, State and local prosecutors, particularly when veterans' treatment court participants fail to comply with program requirements; ``(2) explain the applicant's inability to fund the veterans' treatment court adequately without Federal assistance; ``(3)\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': \"Children's Online Privacy Protection Act of 1998 - Directs the Federal Trade Commission (FTC) to prescribe regulations requiring commercial website operators to follow fair information practices in connection with the collection and use of personal information from children under age 16, including by obtaining verifiable parental consent for the collection, use, or disclosure of personal information from children under the age of 13. Directs the FTC to provide incentives for efforts of self-regulation by operators to implement appropriate protections for such information. Authorizes the States to enforce such regulations by bringing actions on behalf of residents, requiring the appropriate attorney general to first notify the FTC of such action. Authorizes the FTC to intervene in any such action. Provides for enforcement of this Act through the Federal Trade Commission Act. Directs the FTC to review and report to the Congress on the implementation of this Act.\", 'positives': [\"In this Act: (1) Child.--The term ``child'' means an individual under the age of 16. (2) Children.--The term ``children'' means more than 1 child. (3) Commercial website operator.--The term ``commercial website operator'' means any person operating a website on the World Wide Webs for commercial purposes, including any person offering products or services for sale though that website, involving commerce-- (A) among the several States or with 1 or more foreign nations; (B) in any territory of the United States or in the District of Columbia, or between any such territory-- (i) and another such territory; or (ii) and any State or foreign nation; or (C) between the District of Columbia and any State, territory, or foreign nation. (4) Commission.--The term ``Commission'' means the Federal Trade Commission. (5) Disclosure.--The term ``disclosure'' means, with respect to personal information-- (A) the release of information in identifiable form by a person to any other person for any purpose; or (B) making publicly available information in identifiable form by any means including by a public posting, through the use of a computer on or through-- (i) a home page of a website; (ii) a pen pal service; (iii) an electronic mail service; (iv) a message board; or (v) a chat room. (6) Federal agency.--The term ``Federal agency'' means an agency, as that term is defined in section 551(1) of title 5, United States Code. (7) Internet.--The term ``Internet'' means the international computer network of both Federal and non-Federal interoperable packet switched data networks. (8) Parent.--The term ``parent'' means a legal guardian, including a biological or adoptive parent. (9) Personal information.--The term ``personal information'' means individually, identifiable information about an individual, including-- (A) a first and last name; (B) a home or other physical address; (C) an e-mail address; (D) a telephone number; (E) a Social Security number; or (F) any other information that would facilitate or enable the physical or online locating and contacting of a specific individual, including information that is associated with an identifier described in this paragraph in such manner as to become identifiable to a specific individual. (10) Verifiable parental consent.--The term ``verifiable parental consent'' means any reasonable effort (taking into consideration available technology) to ensure that a parent of a child authorizes the disclosure of personal information and subsequent use of that information before that information is collected from that child. (11) Website directed to children.--The term ``website directed to children''-- (A) means a commercial website that is-- (i) targeted to children; (ii) directed to children by reason of the subject matter, visual content, age of models, language, characters, tone, message, or any other similar characteristic of the website; or (iii) used by a commercial website operator to knowingly collect information from children; and (B) includes any commercial website any portion of which is directed to children, as specified in subparagraph (A). (12) Person.--The term ``person'' means any individual, partnership, corporation, trust, estate, cooperative, association, or other entity. SEC. 3. REGULATION OF UNFAIR AND DECEPTIVE ACTS AND PRACTICES IN CONNECTION WITH THE COLLECTION AND USE OF PERSONAL INFORMATION FROM AND ABOUT CHILDREN ON THE INTERNET. (a) Regulations.-- (1) In general.--Not later than 1 year after the date of enactment of this Act, the Commission shall, in a manner consistent with section 553 of title 5, United States Code, prescribe regulations requiring commercial website operators to follow fair information practices in connection with the collection and use of personal information from children. (2) Contents.--The regulations issued under this subsection shall-- (A) require that a\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}\n",
            "{'query': 'Amends the Solid Waste Disposal Act to authorize the Administrator of the Environmental Protection Agency to: (1) treat Indian tribes as States under such Act; (2) delegate primary enforcement authority for programs under such Act to Indian tribes; and (3) provide grant and contract assistance to tribes to carry out such Act. Sets forth conditions under which Indian tribes may be treated as States. Directs the Administrator to report to the Congress on: (1) recommendations for addressing hazardous and solid wastes and underground storage tanks within Indian country; (2) methods to maximize Indian participation in, and administration of, programs under such Act; and (3) the amount of assistance required and how the Administrator intends to provide such assistance to Indian tribes for the administration of such programs. Requires the Administrator to establish an inventory of: (1) sites within Indian country at which hazardous waste has been stored or disposed; and (2) open dumps within Indian country at which solid waste has been disposed. Directs the Administrator to assist Indian tribes in upgrading open dumps to comply with applicable requirements.', 'positives': [\"SECTION 1. AUTHORITY TO GRANT STATE STATUS TO INDIAN TRIBES FOR ENFORCEMENT OF SOLID WASTE DISPOSAL ACT. (a) Definitions.--(1) Section 1004 of the Solid Waste Disposal Act (42 U.S.C. 6903) is amended by adding at the end the following new paragraphs: ``(42) The term `Indian country' means-- ``(A) all land within the limits of any Indian reservation under the jurisdiction of the United States Government, notwithstanding the issuance of any patent, and including rights-of-way running through the reservation; ``(B) all dependent Indian communities within the borders of the United States whether within the original or subsequently acquired territory thereof, and whether within or without the limits of a State; and ``(C) all Indian allotments, the Indian titles to which have not been extinguished, including rights-of-way running through the same. ``(43) The term `Indian tribe' means any Indian tribe, band, group, or community, including any Alaska Native village, organization, or regional corporation as defined in or established pursuant to the Alaska Native Claims Settlement Act, recognized by the Secretary of the Interior and exercising governmental authority within Indian country.''. (2) Paragraph (13) of such section is amended by striking out ``or authorized tribal organization or Alaska Native village or organization,'' and inserting in lieu thereof ``not treated as a State under section 1009,''. (3) Paragraph (15) of such section is amended by inserting after ``State,'' the following: ``Indian tribe,''. (b) Treatment of Indian Tribes as States.--Subtitle A of the Solid Waste Disposal Act is amended by adding at the end the following new section: ``SEC. 1009. INDIAN TRIBES. ``(a) In General.--Subject to the provisions of subsection (b), the Administrator-- ``(1) is authorized to treat Indian tribes as States under this Act; ``(2) may delegate to such tribes primary enforcement responsibility for programs and projects under this Act; and ``(3) may provide such tribes grant and contract assistance to carry out functions provided by this Act. ``(b) EPA Regulations.-- ``(1) The Administrator shall, not later than 18 months after the date of the enactment of this section, promulgate final regulations that specify how Indian tribes shall be treated as States for the purposes of this Act. Such treatment shall be authorized only if-- ``(A) the Indian tribe has a governing body carrying out substantial governmental duties and powers; ``(B) the functions to be exercised by the Indian tribe pertain to land and resources which are held by the Indian tribe, held by the United States in trust for the Indian tribe, held by a member of the Indian tribe if such property interest is subject to a trust restriction on alienation, or are otherwise within Indian country; and ``(C) the Indian tribe is reasonably expected to be capable, in the Administrator's judgment, of carrying out the functions to be exercised in a manner consistent with the terms and purposes of this Act and of all applicable regulations. ``(2) For any provision of this Act where treatment of Indian tribes identically to States is inappropriate, administratively infeasible, or otherwise inconsistent with the purposes of this Act, the Administrator may include in the regulations promulgated under this section means for the direct implementation of such provision by the Environmental Protection Agency in a manner that will achieve the purpose of the provision. Nothing in this section shall be construed to allow Indian tribes to assume or maintain primary enforcement responsibility for programs under this Act in a manner less protective of human health and the environment than such responsibility may be assumed or maintained by a State. An Indian tribe shall not be required to exercise criminal jurisdiction for purposes of complying with the preceding sentence. ``(c) Cooperative Agreements.--In order to ensure the consistent implementation of the requirements of this Act, an Indian tribe and the Stat\"], 'negatives': [], 'type': 'sts_triplet', 'source_id': 7}"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': '7.9.2005 EN Official Journal of the European Union L 230/7\\nCOMMISSION REGULATION (EC) No 1450/2005\\nof 5 September 2005\\namending Annex V to Council Regulation (EC) No 1210/2003 concerning restrictions on economic and financial relations with Iraq\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1210/2003 of 7 July 2003 concerning certain specific restrictions on economic and financial relations with Iraq\\xa0(1), and in particular Article 11(c) thereof,\\nWhereas:\\n(1) Annex V to Regulation (EC) No 1210/2003 lists the competent authorities to which specific functions related to the implementation of that Regulation are attributed.\\n(2) Belgium, Germany, Lithuania and the Netherlands have requested that the address details concerning their competent authorities be amended.\\n(3) Annex V to Regulation (EC) No 1210/2003 should therefore be amended accordingly,\\nAnnex V to Regulation (EC) No 1210/2003 is hereby amended as set out in the Annex to this Regulation.\\nThis Regulation shall enter into force on the day following its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1318', '1448', '1500', '2286', '3483', '4040', '4839', '5709', '614'], 'source_id': 9}\n",
            "{'query': \"Council Decision\\nof 22 December 2003\\nappointing a Finnish member of the European Economic and Social Committee\\n(2004/62/EC, Euratom)\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Treaty establishing the European Community, and in particular Article 259 thereof,\\nHaving regard to the Treaty establishing the European Atomic Energy Community, and in particular Article 167 thereof,\\nHaving regard to Council Decision 2002/758/EC, Euratom of 17 September 2002 appointing the members of the Economic and Social Committee for the period from 21 September 2002 to 20 September 2006(1),\\nWhereas a member's seat on that Committee has fallen vacant following the resignation of Mr Martti REUNA, of which the Council was informed on 14 April 2003;\\nHaving regard to the nominations submitted by the Finnish Government,\\nHaving obtained the opinion of the Commission of the European Union,\\nMs Leila KURKI is hereby appointed a member of the European Economic and Social Committee in place of Mr Martti REUNA for the remainder of the latter's term of office, which runs until 20 September 2006.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1019', '3559', '6054'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION (EEC) No 554/92  of 2 March 1992  amending the list annexed to Regulation (EEC) No 3715/91 establishing, for 1992, the list of vessels exceeding eight metres length overall permitted to fish for sole within certain areas of  the Community using beam trawls whose aggregate length exceeds nine metres\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 3094/86 of 7 October 1986 laying down certain technical measures for the conservation of fishery resources (1), as last amended by Regulation (EEC) No 3500/91 (2),\\nHaving regard to Commission Regulation (EEC) No 3554/90 of 10 December 1990 adopting provisions for the establishment of the list of vessels exceeding eight metres length overall which are permitted to fish for sole within certain areas of the Community  using beam trawls of an aggregate length exceeding nine metres (3), and in particular Article 2 thereof;\\nWhereas Commission Regulation (EEC) No 3715/91 (4) establishes for 1992 the list of vessels exceeding eight metres length overall permitted to fish for sole within certain areas of the Community using beam trawls of aggregate length exceeding nine  metres;\\nWhereas the German and Belgian authorities have requested withdrawal from the list annexed to Regulation (EEC) No 3715/91 of 18 vessels that no longer meet the requirements laid down in Article 1 (2) of Regulation (EEC) No 3554/90; whereas the national  authorities have provided all the information in support of the request required pursuant to Article 2 of Regulation (EEC) No 3554/90; whereas scrutiny of this information shows that the requirements of the Regulation are met; whereas the vessels in  question should be withdrawn from the list,\\nThe Annex to Regulation (EEC) No 3715/91 is amended as indicated in the Annex to this Regulation.\\nThis Regulation shall enter into force on the day following its publication in the Official Journal of the European Communities. This Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['3001', '4829', '997'], 'source_id': 9}\n",
            "{'query': 'COMMISSION  REGULATION (EEC) No 2164/87\\nof 22 July 1987\\nfixing for the 1987/88 marketing year the production aid for tinned pineapple and the minimum price to be paid to pineapple producers\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 525/77 of 14 March 1977 establishing a system of production aid for tinned pineapple (1), as last amended by Regulation (EEC) No 1699/85 (2), and in particular Article 8 thereof,\\nWhereas, under Article 4 of Regulation (EEC) No 525/77, the minimum price to be paid to producers is to be determined on the basis of: the minimum price applicable during the preceding marketing year, and the trend of production costs in the fruit and vegetable sector;\\nWhereas Article 5 of the said Regulation lays down the criteria for fixing the amount of production aid; whereas account must, in particular, be taken of the aid fixed for the previous marketing year adjusted to take account of changes in the minimum price to be paid to producers, the non-member country price and, if necessary, the pattern of processing cost assessed on a flat-rate basis;\\nWhereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Products Processed from Fruit and Vegetalbes,\\nFor the 1987/88 marketing year:\\n(a) the minimum price referred to in Article 4 of Regulation (EEC) No 525/77 to be paid to producers for pineapples;\\n(b) the production aid referred to in Article 5 of the said Regulation for tinned pineapples\\nshall be as set out in the Annex.\\nThis Regulation shall enter into force on the day of its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1120', '4083', '797', '870'], 'source_id': 9}\n",
            "{'query': 'COMMISSION DECISION  of 16 December 1991  approving the plan concerning infectious haemopoietic necrosis and viral haemorrhagic septicaemia presented by Portugal  (Only the Portuguese text is authentic)  (92/45/EEC)\\nTHE COMMISSION OF THE  EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Decision 90/495/EEC of 24 September 1990 introducing a Community financial measure with a view to the eradication of infectious haemopoietic necrosis of salmonids in the Community (1), and in particular Article 4 thereof,\\nWhereas, in accordance with Article 1 of Decision 90/495/EEC, Member States must submit a plan for assessing the rate of infection of infectious haemopoietic necrosis (IHN) and viral haemorrhagic septicaemia (VHS) in their territory;\\nWhereas by letter dated 28 December 1990, Portugal has notified the Commission of its plan; whereas this plan has been replaced by the plan presented on 19 July 1991;\\nWhereas, after examination, the plan was found to comply with Decision 90/495/EEC, and in particular with Article 3 thereof;\\nWhereas the conditions for financial participation by the Community as foreseen in Article 7 of Decision 90/495/EEC, are therefore met;\\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Veterinary Committee,\\nThe plan for assessing the rate of infection of IHN and VHS within its territory, presented by Portugal, is hereby approved.\\nPortugal shall bring into force by 1 November 1991 the laws, regulations and administrative provisions for implementing the plan referred to in Article 1.\\nThe financial participation of the Community for Portugal is fixed at 50 % of the expenditure incurred pursuant to points 4 and 5 of Article 3 of Decision 90/495/EEC.\\nThe Community financial participation is granted upon presentation of the supporting documents.\\nThis Decision is addressed to Portugal.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1005', '1755', '2384', '2563'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 573/2004\\nof 26 March 2004\\nfixing the refunds applicable to cereal and rice sector products supplied as Community and national food aid\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 1766/92 of 30 June 1992 on the common organisation of the market in cereals(1), and in particular the third subparagraph of Article 13(2) thereof,\\nHaving regard to Council Regulation (EC) No 3072/95 of 22 December 1995 on the common organisation of the market in rice(2), and in particular Article 13(3) thereof,\\nWhereas:\\n(1) Article 2 of Council Regulation (EEC) No 2681/74 of 21 October 1974 on Community financing of expenditure incurred in respect of the supply of agricultural products as food aid(3) lays down that the portion of the expenditure corresponding to the export refunds on the products in question fixed under Community rules is to be charged to the European Agricultural Guidance and Guarantee Fund, Guarantee Section.\\n(2) In order to make it easier to draw up and manage the budget for Community food aid actions and to enable the Member States to know the extent of Community participation in the financing of national food aid actions, the level of the refunds granted for these actions should be determined.\\n(3) The general and implementing rules provided for in Article 13 of Regulation (EEC) No 1766/92 and in Article 13 of Regulation (EC) No 3072/95 on export refunds are applicable mutatis mutandis to the abovementioned operations.\\n(4) The specific criteria to be used for calculating the export refund on rice are set out in Article 13 of Regulation (EC) No 3072/95.\\n(5) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Cereals,\\nFor Community and national food aid operations under international agreements or other supplementary programmes, and other Community free supply measures, the refunds applicable to cereals and rice sector products shall be as set out in the Annex.\\nThis Regulation shall enter into force on 1 April 2004.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['3568', '3732', '5360', '807', '862', '889'], 'source_id': 9}\n",
            "{'query': 'COMMISSION  DECISION\\nof 31 July 1987\\nauthorizing the United Kingdom to restrict the marketing of seed of a variety of an agricultural plant species\\n(Only the English text is authentic)\\n(87/448/EEC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Directive 70/457/EEC of 29 September 1970 on the common catalogue of varieties of agricultural plant species (1), as last amended by Directive 86/155/EEC (2), and in particular Article 15 (2) and (3) thereof,\\nHaving regard to the application lodged by the United Kingdom,\\nWhereas, under Article 15 (1) of the said Directive, seed and propagating material of varieties of agricultural plant species which have been officially accepted during 1984 in at least one of the Member States and which also meet the conditions laid down in the said Directive are, after 31 December 1986, no longer subject to any marketing restrictions relating to variety in the Community;\\nWhereas, however, Article 15 (2) of the said Directive provides that a Member State may be authorized upon application to prohibit the marketing of seed and propagating material of certain varieties;\\nWhereas the United Kingdom applied for such authorization for a certain number of varieties of different species;\\nWhereas Commission Decision 87/111/EEC (3) extended for the United Kingdom the period provided for in the said Article 15 (1) beyond 31 December 1986 until 30 June 1987 in respect of the variety Barra (oats);\\nWhereas the Commission has meanwhile completed its examination of the United Kingdom application in respect of that variety;\\nWhereas the results of that examination show that in the United Kingdom, in the light of the national rules governing the acceptance of varieties there which apply within the framework of current Community provisions, the variety is not clearly distinguishable from another variety accepted there in respect of the characteristics which were to be examined in this case, or is not sufficiently uniform in respect of certain aspects of the relevant characteristic (Article 15 (3) (a), first case, of the said Directive);\\nWhereas the United Kingdom application should therefore be granted in full in respect of that variety;\\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Seeds and Propagating Material for Agriculture, Horticulture and Forestry,\\nThe United Kingdom is hereby authorized to prohibit the marketing in its territory of seed of the following variety listed in the 1987 common catalogue of varieties of agricultural plant species:\\nBarra (Avena sativa L.).\\nThe authorization given in Article 1 shall be withdrawn as soon as it is established that the conditions thereof are no longer satisfied.\\nThe United Kingdom shall notify the Commission of the date from which and the methods by which it makes use of the authorization under Article 1. The Commission shall inform the other Member States thereof.\\nThis Decision is addressed to the United Kingdom.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1662', '3774', '4081'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION (EEC) No 332/80  of 13 February 1980  amending for the eighth time Regulation (EEC) No 1528/78 laying down detailed rules for the application of the system of aid for dried fodder\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 1117/78 of 22 May 1978 on the common organization of the market in dried fodder (1), as amended by Regulation (EEC) No 2285/79 (2), and in particular Article 6 (3) thereof,\\nWhereas Commission Regulation (EEC) No 1528/78 (3), as last amended by Regulation (EEC) No 2329/79 (4), laid down detailed rules for paying the aid in respect of dried fodder;\\nWhereas, in order to facilitate the application of these systems of aid, provision should be made for the aid in question to be advanced, subject to the lodging of a security to be released once entitlement to the aid has been recognized ; whereas, however, in order to permit the functioning of the measure to be assessed, its period of application should be limited;\\nWhereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Dried Fodder,\\nArticle 13 of Regulation (EEC) No 1528/78 is replaced by the following text:\\n\"Article 13\\n1. The Member State shall pay the amount of the aid within 150 days of the date on which the relevant application was submitted.\\n2. However, the amount of the aid shall be advanced as soon as the interested party submits an application for aid accompanied by a certificate showing that a security equal to the amount of the aid has been lodged.\\n3. The security shall be lodged in the form of a guarantee given by an establishment meeting the criteria laid down by the Member State to which the application for aid is submitted.\\n4. The security shall be released as soon as the competent authority of the Member State has recognized entitlement to the aid in respect of the quantities shown in the application.\\nWhere entitlement to the aid is not recognized in respect of all or part of the quantities stated in the application, the security shall be forfeit in proportion to the quantities in respect of which the conditions giving entitlement to the aid have not been fulfilled\".\\nThis Regulation shall enter into force on 1 March 1980.\\nThe provisions of Article 1, which refer to Article 13 (2) (3) and (4) of Regulation (EEC) No 1528/78, shall apply only to applications for aid submitted up to and including 28 February 1981.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1129', '2668', '3576', '4854', '870'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 718/2003\\nof 24 April 2003\\nfixing the rates of the refunds applicable to certain cereal and rice-products exported in the form of goods not covered by Annex I to the Treaty\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 1766/92 of 30 June 1992 on the common organisation of the market in cereals(1), as last amended by Regulation (EC) No 1666/2000(2), and in particular Article 13(3) thereof,\\nHaving regard to Council Regulation (EC) No 3072/95 of 22 December 1995 on the common organisation of the market in rice(3), as last amended by Commission Regulation (EC) No 411/2002(4), and in particular Article 13(3) thereof,\\nWhereas:\\n(1) Article 13(1) of Regulation (EEC) No 1766/92 and Article 13(1) of Regulation (EC) No 3072/95 provide that the difference between quotations of prices on the world market for the products listed in Article 1 of each of those Regulations and the prices within the Community may be covered by an export refund.\\n(2) Commission Regulation (EC) No 1520/2000 of 13 July 2000 laying down common implementing rules for granting export refunds on certain agricultural products exported in the form of goods not covered by Annex I to the Treaty, and the criteria for fixing the amount of such refunds(5), as last amended by Regulation (EC) No 1052/2002(6), specifies the products for which a rate of refund should be fixed, to be applied where these products are exported in the form of goods listed in Annex B to Regulation (EEC) No 1766/92 or in Annex B to Regulation (EC) No 3072/95 as appropriate.\\n(3) In accordance with the first subparagraph of Article 4(1) of Regulation (EC) No 1520/2000, the rate of the refund per 100 kilograms for each of the basic products in question must be fixed for each month.\\n(4) The commitments entered into with regard to refunds which may be granted for the export of agricultural products contained in goods not covered by Annex I to the Treaty may be jeopardised by the fixing in advance of high refund rates. It is therefore necessary to take precautionary measures in such situations without, however, preventing the conclusion of long-term contracts. The fixing of a specific refund rate for the advance fixing of refunds is a measure which enables these various objectives to be met.\\n(5) Now that a settlement has been reached between the European Community and the United States of America on Community exports of pasta products to the United States and has been approved by Council Decision 87/482/EEC(7), it is necessary to differentiate the refund on goods falling within CN codes 1902 11 00 and 1902 19 according to their destination.\\n(6) Pursuant to Article 4(3) and (5) of Regulation (EC) No 1520/2000 provides that a reduced rate of export refund has to be fixed, taking account of the amount of the production refund applicable, pursuant to Council Regulation (EEC) No 1722/93(8), as last amended by Commission Regulation (EC) No 1786/2001(9), for the basic product in question, used during the assumed period of manufacture of the goods.\\n(7) Spirituous beverages are considered less sensitive to the price of the cereals used in their manufacture. However, Protocol 19 of the Act of Accession of the United Kingdom, Ireland and Denmark stipulates that the necessary measures must be decided to facilitate the use of Community cereals in the manufacture of spirituous beverages obtained from cereals. Accordingly, it is necessary to adapt the refund rate applying to cereals exported in the form of spirituous beverages.\\n(8) It is necessary to ensure continuity of strict management taking account of expenditure forecasts and funds available in the budget.\\n(9) The Management Committee for Cereals has not delivered an opinion within the time limit set by its chairman,\\nThe rates of the refunds applicable to the basic products appearing in Annex A to Regulation (EC) No 1520/2000 and listed either in Article 1 of Regulation (EEC) No 1766/92 or in Article 1(1) of Regulation (EC) No 3072/95, exported in the form of goods listed in Annex B to Regulation (EEC) No 1766/92 or in Annex B to amended Regulation (EC) No 3072/95 respectively, are hereby fixed as shown in the Annex to this Regulation.\\nThis Regulation shall enter into force on 25 April 2003.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1258', '3568', '3732', '5360'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 180/2002\\nof 31 January 2002\\nestablishing the standard import values for determining the entry price of certain fruit and vegetables\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Commission Regulation (EC) No 3223/94 of 21 December 1994 on detailed rules for the application of the import arrangements for fruit and vegetables(1), as last amended by Regulation (EC) No 1498/98(2), and in particular Article 4(1) thereof,\\nWhereas:\\n(1) Regulation (EC) No 3223/94 lays down, pursuant to the outcome of the Uruguay Round multilateral trade negotiations, the criteria whereby the Commission fixes the standard values for imports from third countries, in respect of the products and periods stipulated in the Annex thereto.\\n(2) In compliance with the above criteria, the standard import values must be fixed at the levels set out in the Annex to this Regulation,\\nThe standard import values referred to in Article 4 of Regulation (EC) No 3223/94 shall be fixed as indicated in the Annex hereto.\\nThis Regulation shall enter into force on 1 February 2002.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '1605', '2511', '2635', '693'], 'source_id': 9}\n",
            "{'query': '11.11.2009 EN Official Journal of the European Union L 294/16\\nCOMMISSION DECISION\\nof 3 November 2009\\nrelating to the draft Regional Legislative Decree declaring the Autonomous Region of Madeira to be an Area Free of Genetically Modified Organisms, notified by the Republic of Portugal pursuant to Article 95(5) of the EC Treaty\\n(notified under document C(2009) 8438)\\n(Only the Portuguese text is authentic)\\n(Text with EEA relevance)\\n(2009/828/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community, and in particular Article 95(6) thereof,\\nWhereas:\\n(1) In a letter dated 5 May 2009, the Portuguese Permanent Representation to the European Union notified the Commission, in accordance with Article 95(5) of the EC Treaty, a draft Regional Legislative Decree (hereinafter: ‘the draft decree’) declaring the Autonomous Region of Madeira to be an Area Free of Genetically Modified Organisms (GMOs). The draft decree was accompanied by an explanatory statement and a document setting out the arguments reasoning and justifying the declaration of the Autonomous Region of Madeira as an Area Free from GMOs.\\n(2) By a letter of 26 June 2009, the Commission informed the Portuguese authorities that it had received the notification under Article 95(5) of the EC Treaty and that the six-month period for its examination pursuant to Article 95(6) had begun following this notification. The Portuguese notification contained no scientific literature, studies, or any other scientific information that would support the respective argumentation. Therefore the Commission asked Portugal by that letter to complement its notification with more concrete information in the form of relevant scientific literature which would indicate the evidence relating to the protection of the environment or the working environment on grounds of a problem specific to the region of Madeiras. Portugal submitted complementary information on 31 July 2009.\\n(3) The Commission published a notice regarding the request in the Official Journal of the European Union\\n\\xa0(1) to inform the other parties concerned of the draft national measure that Portugal intended to adopt. Bulgaria, Czech Republic, Denmark, France, Latvia, Malta and Romania submitted their comments.\\n(4) Article 95(5) and (6) of the Treaty provides:\\n(5) In accordance with Article 1 of the draft decree, the Autonomous Region of Madeira is declared to be an area free of the cultivation of varieties of genetically modified organisms (GMOs). In accordance with Article 2, the introduction of plant or seed propagating material containing GMOs into the territory of the Autonomous Region of Madeira and also its use in agriculture would be prohibited. Article 3 would define the infringement of the provisions of the above article as administrative offence and Article 4 would lay down additional penalties. Article 5 would establish provisions for the investigation, prosecution and decision of the administrative offenses and Article 6 would stipulate the use of the proceeds from fines.\\n(6) The scope of the latter draft provisions, in conjunction with the explanation of the explanatory note, implies that it will primarily impact on:\\n— the cultivation of genetically modified seed varieties authorised under the provisions of part C (Articles 12 – 24) of Directive 2001/18/EC of the European Parliament and of the Coincil of 12 March 2001 on the deliberate release into the environment of genetically modified organisms and repealing Council Directive 90/220/EEC\\xa0(2) (hereinafter ‘Directive 2001/18/EC’),\\n— the cultivation of genetically modified seed varieties already approved under the provisions of Council Directive 90/220/EEC of 23 April 1990 on the deliberate release into the environment of genetically modified organisms\\xa0(3) and now notified as existing products under Articles 8 and 20 of Regulation (EC) No 1829/2003 of the European Parliament and of the Council of 22 September 2003 on genetically modified food and feed\\xa0(4) (hereinafter ‘Regulation (EC) No 1829/2003’),\\n— the cultivation of genetically modified seed varieties authorised under the provisions of Regulation (EC) No 1829/2003.\\n(7) Directive 2001/18/EC is based on Article 95 of the EC Treaty. It aims at approximating legislation and procedures in Member States for the authorisation of GMOs intended for deliberate release into the environment. In accordance with its Article 34, Member States were required to transpose it into national law by 17 October 2002.\\n(8) According to its Article 1, Regulation (EC) No 1829/2003 aims at (a) providing the basis for ensuring a high level of protection of human life and health, animal health and welfare, environment and consumer interests in relation to genetically food and feed, whilst ensuring the effecting functioning of the internal market; (b) in laying down Community procedures for the authorization and supervision of genetically modified food and feed and (c) in laying down provisions for the labeling of genetically modified food and feed.\\n(9) Information for the draft Act, offering interpretation about the Act’s impact on and conformity with Community legislation, is provided in:\\n— The document submitted together with the notification of 5 May 2009 and titled ‘Establishment of the Autonomous Region of Madeira (RAM) as an “Area Free of Genetically Modified Organisms (GMOs)” — Arguments’,\\n— The additional information submitted on 31 July 2009 titled ‘Establishment of the Autonomous Region of Madeira as an Area Free of Genetically Modified Organisms (GMOs) — Additional information’.\\n(10) In its justification, Portugal points to agricultural and natural reasons.\\n(11) The agricultural reasons refer to the impossibility of co-existence between GM crops and conventional and/or organic crops in the Autonomous Area of Madeira. They particularly invoke aspects such as the distance between fields, border strips, sowing of varieties with different growth cycles, refuge areas, installation of pollen traps or barriers to prevent pollen dispersion, crops rotation systems, crop production cycles, reduction of the size of the seed banks through adequate soil tillage, management of populations in field borders, choosing of optimal sowing dates, handling of seeds to avoid mixing or the prevention of seed spillage when travelling to and from the field and on field boundaries.\\n(12) The natural reasons claim that the effects of introducing GMOs into nature (in the case of the RAM, the natural Madeiran forest) have not been adequately studied, although many articles have been published in which concerns are raised with regard to the consequences of deliberately releasing GMOs into nature and to the resulting environmental effects which might be expected. However there may be other potential risks which are not covered by these scientific studies.\\n(13) The natural reasons further refer to:\\n(a) preliminary tests carried out using GM varieties;\\n(b) model showing the invasive capacity of GM varieties;\\n(c) interaction of the model to the use of plants containing GMOs;\\n(d) capacity of transgenic plants to cross-pollinate;\\n(e) parallel effects with other species;\\n(f) production of toxins;\\n(g) collateral interactions;\\n(h) effects connected with genetic alterations;\\n(i) implications in poor agricultural practices;\\n(j) gene transfer;\\n(k) effects on the food chain.\\n(14) Portugal concludes that on the basis of the above, the introduction of genetically modified material into the RAM could have extremely dangerous consequences for the Madeiran environment in general (it would be pointless to distinguish between agricultural and forest areas). Although there are no solid theories on the matter, research and experiments, as well as all the theoretical parallels, suggest that the risk to nature presented by the deliberate release of GMOs is so dangerous and poses such a threat to the environmental and ecological health of Madeira, that it is not worthwhile risking their use, either directly in the agricultural sector or even on an experimental basis.\\n(15) Article 95(5) of the EC Treaty applies to new national measures on the basis of the protection of the environment or the working environment, on grounds of a problem specific to that Member State arising after the adoption of the harmonisation measure, and which are justified by new scientific evidence.\\n(16) Under Article 95(6) of the EC Treaty, the Commission is either to approve or reject the draft national provisions in question after verifying whether or not they are a means of arbitrary discrimination or a disguised restriction on trade between Member States, and whether or not they shall constitute an obstacle to the functioning of the internal market.\\n(17) Nevertheless, under the same provision, when justified by the complexity of the matter and in the absence of danger for human health, the Commission may notify the Member State concerned that the period referred to in this paragraph may be extended for a further period of up to six months.\\n(18) The notification submitted by the Portuguese authorities on 5 May 2009 is intended to obtain approval for the introduction of the draft decree.\\n(19) Portugal did not specify the European Community act which the draft decree derogates from. Cultivation of GMOs is to a large extent regulated by Directive 2001/18/EC, and Regulation (EC) No 1829/2003.\\n(20) Article 95(5) of the Treaty requires that when a Member State deems it necessary to introduce national provisions derogating from a harmonisation measure, those provisions could be justified on the following cumulative conditions\\xa0(5):\\n— new scientific evidence,\\n— relating to the protection of the environment or the working environment,\\n— on grounds of a problem specific to that Member State,\\n— arising after the adoption of the harmonisation measure.\\n(21) The justifications put forward by Portugal make extensive reference to the potential effects of the cultivation of GM varieties on the environment. The notification contains an analysis of extended and complicated issues such as preliminary tests carried out using GM varieties, model showing the invasive capacity of GM varieties, interaction of the model to the use of plants containing GMOs, capacity of transgenic plants to cross-pollinate, parallel effects with other species, production of toxins, collateral interactions, effects connected with genetic alterations, implications in poor agricultural practices, gene transfer and effects on the food chain.\\n(22) It results from these justifications that a thorough scientific risk assessment is necessary to indicate whether the submitted scientific evidence relates to the protection of the environment or the working environment on grounds of a problem specific to the Autonomous Region of Madeira arising after the adoption of Directive 2001/18/EC and Regulation (EC) No 1829/2003 or other relevant EC provisions. This assessment should be carried out by the European Food Safety Authority (EFSA) which, in accordance with Article 22(2) of Regulation (EC) No 178/2002 of the European Parliament and of the Council of 28 January 2002 laying down the general principles and requirements of food law, establishing the European Food Safety Authority and laying down procedures in matters of food safety\\xa0(6), is competent to provide scientific advice and scientific and technical support for the Community’s legislation and policies in all fields which have a direct or indirect impact on food and feed safety, and shall provide independent information on all matters within these fields and communicate on risks. Moreover, in accordance with Article 29 of that Regulation, EFSA shall issue a scientific opinion at the request of the Commission, in respect of any matter within its mission, and in all cases where Community legislation makes provision for the Authority to be consulted.\\n(23) For this reason the Commission sent on 23 September 2009 a mandate to the European Food Safety Authority (EFSA) asking it to assess, on the basis of the new evidence provided by Portugal and in the light of the requirements of Article 95(5) of EC Treaty, whether the particular evidence relates to the protection of the environment on grounds of a problem specific to the concerned area, namely the Autonomous Region of Madeira.\\n(24) Under those circumstances, the adoption of the EFSA Opinion is necessary before the adoption of a decision on the Portuguese notification. In view of the extended scope of the potential adverse environmental effects indicated by the Portuguese notification and the complexity of the scientific aspects related to the cultivation of GMOs in the Autonomous Region of Madeira, it is necessary that EFSA is granted a reasonable period of time before adopting its Opinion. For this reason, the Commission asked EFSA to deliver its Opinion by 31 January 2010.\\n(25) The justifications put forward by Portugal make no specific reference to danger for human health, which would be caused by the cultivation of GMOs in the Autonomous Region of Madeira. While they specifically refer to risks for the environment and ‘ecological health’, no evidence has been presented with regards to identified or potential effects on human health. All scientific arguments have focused solely on agricultural aspects and the protection of biodiversity in Madeira.\\n(26) In view of the above, the adoption of a decision within the deadline of six months, namely by 4 November 2009, which is laid down by Article 95(6)(1) of EC Treaty, would lack the essential scientific support on such a complex matter. Therefore, taking into consideration the complexity of the matter and the absence of danger for human health, the Commission, in accordance with Article 95(6)(3) of EC Treaty, should extend the period to decide on the Portuguese notification to another six months, namely until 4 May 2010,\\nThe period to approve or reject the draft Regional Legislative Decree declaring the Autonomous Region of Madeira to be an Area Free of Genetically Modified Organisms, notified by the Republic of Portugal pursuant to Article 95(5) of the EC Treaty, is extended to 4 May 2010.\\nThis Decision is addressed to the Republic of Portugal.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1730', '2825', '3409', '5768', '863'], 'source_id': 9}\n",
            "{'query': \"19.5.2006 EN Official Journal of the European Union L 132/37\\nCOMMISSION DECISION\\nof 16 May 2006\\nsetting up an expert group on customer mobility in relation to bank accounts\\n(2006/355/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nWhereas:\\n(1) Article 3 of the Treaty establishing the European Community assigned the European Community the task of ensuring the creation of an internal market characterised by the abolition, as between Member States, of obstacles to the free movement of goods, persons, services and capital.\\n(2) The Commission wishes to identify any legal, regulatory, administrative and other obstacles to customer mobility in relation to bank accounts, and to be advised on how to address these obstacles.\\n(3) The White Paper on the Financial Services Policy 2005-2010\\xa0(1) provides for the setting up of an expert group on customer mobility in relation to bank accounts.\\n(4) The group must be made up of individuals having expertise in the area of customer mobility in relation to bank accounts.\\n(5) The expert group on customer mobility in relation to bank accounts therefore has to be set up and its terms of reference and structures detailed,\\nThe expert group on customer\\xa0(2) mobility in relation to bank accounts hereinafter referred to as ‘the group’ is hereby set up by the Commission.\\nTask\\nThe group's task is to:\\n— Identify any legal, regulatory, administrative and other obstacles to customer mobility in relation to bank accounts. In particular, the group should identify any obstacles to open a bank account cross-border as well as to switch banks both at domestic and cross-border level (e.g. cost of opening, maintaining and closing a bank account, direct switching costs etc.).\\n— Provide advice to the Commission on how the identified obstacles should be addressed.\\n— Consider the merits of designing an EU optional standard bank account.\\n— Issue a report containing its findings and advice.\\nComposition — Appointment\\n1.\\xa0\\xa0\\xa0The members of the group shall be appointed by the Commission from experts with competence in the area covered by the mandate of the group, on the basis of:\\n— proposals from European or national associations, representing customer and financial services industry interests, which have responded to a call for expression of interest;\\n— responses to a call for expression of interest by individuals with academic background.\\n2.\\xa0\\xa0\\xa0The group shall be composed of a maximum of 20 members.\\n3.\\xa0\\xa0\\xa0The following provisions shall apply:\\n— members proposed by European or national associations, representing customer and financial services industry interests, are appointed as representatives of interested parties;\\n— members with academic background are appointed in a personal capacity;\\n— the mandate of the members of the group shall start with the first meeting of the group and end with the issuance of the report, no later than 1 May 2007. They shall remain in office until such time as they are replaced or their mandate ends;\\n— members who are no longer able to contribute effectively to the group’s deliberations, who resign or who do not respect the conditions set out in the first, second or third dash of this paragraph or Article 287 of the Treaty establishing the European Community may be replaced for the remaining period of their mandate;\\n— the names of the members will be published on the Internet site of the DG Internal Market and Services. The names of members are collected, processed and published in accordance with the provisions of Regulation (EC) No 45/2001 on the protection of individuals with regards to the processing of personal data.\\n— Members appointed in a personal capacity shall each year sign an undertaking to act in the public interest and a declaration indicating the absence or existence of any interest which may undermine their objectivity.\\nOperation\\n1.\\xa0\\xa0\\xa0The group is chaired by the Commission.\\n2.\\xa0\\xa0\\xa0In agreement with the Commission, sub-groups may be set up to examine specific questions under terms of reference established by the group; they shall be disbanded as soon as these have been fulfilled.\\n3.\\xa0\\xa0\\xa0Observers with specific competence on a subject on the agenda may be invited by the Chairman to participate in the group's or sub-group's deliberations if this is useful and/or necessary.\\n4.\\xa0\\xa0\\xa0Information obtained by participating in the group's or sub-group's deliberations may not be divulged if the Commission says that this relates to confidential matters.\\n5.\\xa0\\xa0\\xa0The group and its sub-groups normally meet on Commission premises in accordance with the procedures and schedule established by it. The Commission provides secretarial services. Commission officials with an interest in the proceedings may attend meetings of the group and its sub-groups.\\n6.\\xa0\\xa0\\xa0The group shall adopt its rules of procedure on the basis of the standard rules of procedure adopted by the Commission\\xa0(3)\\n7.\\xa0\\xa0\\xa0The Commission may publish on the Internet site of DG Internal Market and Services, in the original language of the document concerned, any summary, conclusion, or partial conclusion or working document of the group.\\nMeeting expenses\\n1.\\xa0\\xa0\\xa0The Commission shall reimburse travel and subsistence expenses for members and observers in connection with the group's activities in accordance with the provisions in force at the Commission. The members shall not be remunerated for the services they render.\\n2.\\xa0\\xa0\\xa0Meeting expenses are reimbursed within the limits of the appropriations allocated to the department concerned under the annual procedure for allocating resources.\\nEntry into force\\nThe decision shall enter into force on the day of its adoption by the Commission. It shall be published in the Official Journal of the European Union.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1630', '2836', '408', '5640', '6050'], 'source_id': 9}\n",
            "{'query': '20.11.2008 EN Official Journal of the European Union L 309/3\\nCOMMISSION REGULATION (EC) No 1149/2008\\nof 19 November 2008\\namending the representative prices and additional import duties for certain products in the sugar sector fixed by Regulation (EC) No 945/2008 for the 2008/2009 marketing year\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1234/2007 of 22 October 2007 establishing a common organisation of agricultural markets and on specific provisions for certain agricultural products (single CMO Regulation)\\xa0(1),\\nHaving regard to Commission Regulation (EC) No 951/2006 of 30 June 2006 laying down detailed rules for the implementation of Council Regulation (EC) No 318/2006 as regards trade with third countries in the sugar sector\\xa0(2), and in particular Article 36(2), second subparagraph, second sentence thereof,\\nWhereas:\\n(1) The representative prices and additional duties applicable to imports of white sugar, raw sugar and certain syrups for the 2008/2009 marketing year are fixed by Commission Regulation (EC) No 945/2008\\xa0(3). These prices and duties have been last amended by Commission Regulation (EC) No 1133/2008\\xa0(4).\\n(2) The data currently available to the Commission indicate that those amounts should be amended in accordance with the rules and procedures laid down in Regulation (EC) No 951/2006,\\nThe representative prices and additional duties applicable to imports of the products referred to in Article 36 of Regulation (EC) No 951/2006, as fixed by Regulation (EC) No 945/2008 for the 2008/2009, marketing year, are hereby amended as set out in the Annex hereto.\\nThis Regulation shall enter into force on 20 November 2008.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2687', '2733', '4080', '4315', '4316'], 'source_id': 9}\n",
            "{'query': \"14.12.2013 EN Official Journal of the European Union L 335/46\\nCOUNCIL DECISION\\nof 10 December 2013\\nestablishing that no effective action has been taken by Poland in response to the Council Recommendation of 21 June 2013\\n(2013/758/EU)\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 126(8) thereof,\\nHaving regard to the recommendation from the European Commission,\\nWhereas:\\n(1) According to Article 126 of the Treaty on the Functioning of the European Union (TFEU) Member States are to avoid excessive government deficits;\\n(2) The Stability and Growth Pact is based on the objective of sound government finances as a means of strengthening the conditions for price stability and for strong sustainable growth conducive to employment creation.\\n(3) On 7 July 2009, the Council decided, in accordance with Article 104(6) of the Treaty establishing the European Community (TEC), that an excessive deficit existed in Poland and issued a recommendation to correct the excessive deficit by 2012, in accordance with Article 104(7) TEC and Article 3 of Council Regulation (EC) No 1467/97\\xa0(1). In order to bring the general government deficit at or below 3\\xa0% of GDP in a credible and sustainable manner, the Polish authorities were recommended to implement the fiscal stimulus measures in 2009 as planned, ensure an average annual structural budgetary adjustment of at least 1¼\\xa0% of GDP starting in 2010, provide detailed measures to bring the deficit below the reference value by 2012, and introduce reforms to contain primary current expenditure over the following years. The Council established a deadline of 7 January 2010 for effective action to be taken.\\n(4) On 3 February 2010, the Commission concluded that, based on the Commission 2009 autumn forecast, Poland had taken necessary action to comply with the Council recommendation of 7 July 2009 to bring its government deficit within the Treaty reference value and considered that no additional step in the excessive deficit procedure was therefore necessary. However, on the basis of its 2011 autumn forecast, the Commission considered that Poland was not on track and asked for additional measures, which Poland adopted and publicly announced up to 10 January 2012. Thus, on 11 January 2012 the Commission confirmed that the Polish authorities had taken effective action towards a timely and sustainable correction of the excessive deficit and no further steps in the excessive deficit procedure of Poland were needed at the time.\\n(5) On 21 June 2013, the Council concluded that Poland had taken effective action but adverse economic events with major implications on public finances had occurred, and issued revised recommendations\\xa0(2). Thus, Poland fulfilled the conditions for the extension of the deadline for correcting the excessive general government deficit as laid down in Article 3(5) of Regulation (EC) No 1467/97. The Council recommended that Poland put an end to the excessive deficit situation by 2014. It also recommended that Poland reach a headline general government deficit target of 3,6\\xa0% of GDP in 2013 and 3,0\\xa0% of GDP in 2014, which is consistent with an annual improvement of the structural budget balance of at least 0,8\\xa0% of GDP and 1,3\\xa0% of GDP in 2013 and 2014, respectively, based on the Commission updated 2013 spring forecast. It recommended that Poland rigorously implement the measures already adopted, while complementing them with additional measures sufficient to achieve a correction of the excessive deficit by 2014. In addition, it recommended that Poland use all windfall gains for deficit reduction. The Council established the deadline of 1 October 2013 for Poland to take effective action and, in accordance with Article 3(4a) of Regulation (EC) No 1467/97, to report in detail the consolidation strategy that is envisaged to achieve the targets.\\n(6) On 2 October 2013, Poland submitted a report on effective action. The macroeconomic scenario underpinning the report is similar to the one used for the Convergence Programme 2013. After recording an average real GDP growth of 4\\xa0% per year over 2001-2011, the pace of economic activity slowed down in 2012 to 1,9\\xa0%. The macroeconomic scenario underpinning the report on effective action projects real GDP growth to slow down further in 2013 to 1,5\\xa0% before rebounding in 2014 and 2015 with real GDP expanding by 2,5\\xa0% and 3,8\\xa0%, respectively. According to the Commission 2013 autumn forecast, real GDP is set to grow at 1,3\\xa0% in 2013 and accelerate to 2,5\\xa0% in 2014 and 2,9\\xa0% in 2015. Compared to the Polish authorities, the Commission has a less optimistic view on domestic demand growth over the forecast horizon, private consumption and private investment in particular.\\n(7) The Polish authorities foresee a general government deficit of 4,8\\xa0% of GDP in 2013, up from 3,9\\xa0% of GDP in 2012. This is worse than 3,5\\xa0% of GDP provided in the 2013 update of the Convergence Programme and is due to a significant revenue shortfall of 1,2\\xa0% of GDP and an expenditure slippage of 0,1\\xa0% of GDP. For 2014, the Polish Ministry of Finance has projected a surplus of 4,5\\xa0% of GDP on the back of the planned pension reform, which in particular results in a one-off transfer of assets worth 8,5\\xa0% of GDP. In 2015, the general government balance is expected to become a deficit of 3\\xa0% of GDP.\\n(8) For 2013 and 2014, the Commission forecast is similar to the one of the Polish authorities. It also projects a deficit of 4,8\\xa0% of GDP in 2013. The deterioration compared to the 3,9\\xa0% of GDP in the EDP baseline scenario is mainly due to revenue shortfalls. In 2014, the general government balance is projected to be in surplus (+\\xa04,6\\xa0% of GDP) as a consequence of the planned pension reform. For 2015, the Commission is less optimistic than the Polish authorities and expects a general government deficit of 3,3\\xa0% of GDP. The 0,3 percentage points of GDP difference is mainly due to lower current revenues based on a lower projection of nominal GDP growth as well as higher government expenditure on intermediate consumption. The deficit targets are subject to implementation risks.\\n(9) Both the Polish authorities and the Commission project the general government gross debt to remain below the 60\\xa0% threshold over the entire period under consideration. According to the Commission 2013 autumn forecast, the debt-to-GDP ratio is forecast to fall from 55,6\\xa0% in 2012 to 51\\xa0% in 2014, mainly as an effect of the announced transfer of pension funds' assets of 8,5\\xa0% of GDP, before edging up to 52,5\\xa0% in 2015.\\n(10) Since, according to the Commission 2013 autumn forecast, the general government deficit in 2013 is projected to reach 4,8\\xa0% of GDP, Poland is set to miss the headline deficit target of 3,6\\xa0% of GDP recommended by the Council. Also the annual adjusted structural effort in 2013 (0,3\\xa0% of GDP) is well below the recommended annual fiscal effort (0,8\\xa0% of GDP). The bottom-up analysis of new discretionary measures complemented by an assessment of expenditure developments, corrected for expenditure over- and under-execution which is outside the control of the government, shows an overall fiscal effort of 0,2\\xa0% of GDP. This falls short of the required additional measures of 0,4\\xa0% of GDP underlying the fiscal effort set in the Council Recommendation and confirms that Poland has not implemented the fiscal effort in 2013 as recommended by the Council.\\n(11) In 2014, the Commission expect a general government surplus of 4,6\\xa0% of GDP. Thus, the headline deficit target is set to be fulfilled only due to the one-off transfer of pension funds' assets. The expected annual adjusted structural effort is with 1,4\\xa0% of GDP in 2014 above the recommended annual fiscal effort of 1,3\\xa0% of GDP.\\n(12) Overall, Poland has not complied with fiscal targets recommended for 2013, while for 2014 the targets specified in the Council recommendation of 21 June 2013 are forecast to be met. However, the Commission projection for 2015 expect the correction of the excessive deficit in 2014 not to be sustainable as the deficit is set to reach 3,3\\xa0% of GDP,\\nPoland has not taken effective action in 2013 in response to the Council Recommendation of 21 June 2013.\\nThis Decision is addressed to the Republic of Poland.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2543', '2761', '368', '6212', '843'], 'source_id': 9}\n",
            "{'query': '10.3.2005 EN Official Journal of the European Union C 60/1\\nCOUNCIL DECISION\\nof 24 February 2005\\nre-appointing a Deputy Director of Europol\\n(2005/C 60/01)\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Convention on the establishment of a European Police Office (Europol\\xa0Convention)\\xa0(1), and in particular Article 29(2) thereof,\\nActing as the authority vested with the power to appoint the Director and Deputy Directors of Europol,\\nHaving regard to the opinion of the Management Board,\\nWhereas:\\n(1) The term of office of a deputy Director of Europol appointed by Council Decision of 17 December 2001\\xa0(2), is due to expire by 31 December 2005.\\n(2) The Staff Regulations applicable to Europol employees\\xa0(3), and in particular their Appendix 8, establish special provisions on the procedure for the re-appointment of the Director or a Deputy Director of Europol.\\n(3) The Management Board presented the Council with an opinion proposing that the present Deputy Director of Europol, Mr Mariano Germán SIMANCAS CARRIÓN be re-appointed.\\n(4) On the basis of the opinion provided by the Management Board, the Council wishes to re-appoint Mr Mariano Germán SIMANCAS CARRIÓN as Deputy Director,\\nMr Mariano Germán SIMANCAS CARRIÓN is hereby re-appointed as Deputy Director of Europol from 1 January 2006 to 31 December 2009.\\nThis Decision shall take effect on the day of its adoption.\\nIt shall be published in the Official Journal of the European Union.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['3559', '5630'], 'source_id': 9}\n",
            "{'query': '22.12.2006 EN Official Journal of the European Union L 367/59\\nCOMMISSION REGULATION (EC) No 1956/2006\\nof 21 December 2006\\nfixing the rates of refunds applicable to certain products from the sugar sector exported in the form of goods not covered by Annex I to the Treaty\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 318/2006 of 20 February 2006 on the common organisation of the market in the sugar sector\\xa0(1), and in particular Article 33(2)(a) and (4) thereof,\\nWhereas:\\n(1) Article 32(1) and (2) of Regulation (EC) No 318/2006 provides that the differences between the prices in international trade for the products listed in Article 1(1)(b), (c), (d) and (g) of that Regulation and prices within the Community may be covered by an export refund where these products are exported in the form of goods listed in Annex VII to that Regulation.\\n(2) Commission Regulation (EC) No 1043/2005 of 30 June 2005 implementing Council Regulation (EC) No\\xa03448/93 as regards the system of granting export refunds on certain agricultural products exported in the form of goods not covered by Annex I to the Treaty, and the criteria for fixing the amount of such refunds, and the criteria for fixing the amount of such refunds\\xa0(2), specifies the products for which a rate of refund is to be fixed, to be applied where these products are exported in the form of goods listed in Annex VII to Regulation (EC) No 318/2006.\\n(3) In accordance with the first paragraph of Article 14 of Regulation (EC) No 1043/2005, the rate of the refund per 100 kilograms for each of the basic products in question is to be fixed each month.\\n(4) Article 32(4) of Regulation (EC) No 318/2006 lays down that the export refund for a product contained in goods may not exceed the refund applicable to that product when exported without further processing.\\n(5) The refunds fixed under this Regulation may be fixed in advance as the market situation over the next few months cannot be established at the moment.\\n(6) The commitments entered into with regard to refunds which may be granted for the export of agricultural products contained in goods not covered by Annex I to the Treaty may be jeopardised by the fixing in advance of high refund rates. It is therefore necessary to take precautionary measures in such situations without, however, preventing the conclusion of long-term contracts. The fixing of a specific refund rate for the advance fixing of refunds is a measure which enables these various objectives to be met.\\n(7) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Sugar,\\nThe rates of the refunds applicable to the basic products listed in Annex I to Regulation (EC) No\\xa01043/2005 and in Article 1(1) and in point (1) of Article 2 of Regulation (EC) No\\xa0318/2006, and exported in the form of goods listed in Annex VII to Regulation (EC) No\\xa0318/2006, shall be fixed as set out in the Annex to this Regulation.\\nThis Regulation shall enter into force on 22 December 2006.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['3568', '4315'], 'source_id': 9}\n",
            "{'query': \"COMMISSION  DECISION\\nof 29 June 1990\\non a specific programme on the provision of facilities for fishing ports in Madeira presented by Portugal pursuant to Council Regulation (EEC) No 4028/86\\n(Only the Portuguese text is authentic)\\n(90/372/EEC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 4028/86 of 18 December 1986 on Community measures to improve and adapt structures in the fisheries and aquaculture sectors (1), and in particular Article 27 thereof,\\nWhereas the Government of Portugal transmitted to the Commission on 30 October 1989 a specific programme for the provision of facilities at fishing ports, hereinafter referred to as 'the programme';\\nWhereas the programme was introduced by the national authorities during the period of validity of Council Regulation (EEC) No 355/77 of 15 February 1977 on common measures to improve the conditions under which agricultural and fishery products are processed and marketed (2), as last amended by Regulation (EEC) No 1760/87 (3);\\nWhereas the programme is consistent with the specific programmes concerning the processing and marketing of fish and fish products in Portugal adopted under Commission Decision 87/397/EEC (4);\\nWhereas the programme contributes to the attainment of the objectives of the common fisheries policy;\\nWhereas the programme complies with Article 2 of Regulation (EEC) No 355/77 and contains the details specified in Article 3 of that Regulation relating to facilities at fishing ports;\\nWhereas sectorial plans which have to be presented by the Member States under Council Regulation (EEC) No 4042/89 of 19 December 1989 on the improvement of conditions of processing and marketing of fishery and aquaculture products (5), may include the provision of facilities at fishing ports;\\nWhereas Article 21 (2) of Regulation (EEC) No 4042/89 provides that until 30 June 1991 projects presented under Regulation (EEC) No 355/77 which do not form part of a sectorial plan will be considered for the purpose of financial assistance under that Regulation;\\nWhereas Article 21 (3) of Regulation (EEC) No 4042/89 provides that specific programmes approved by the Commission under Regulation (EEC) No 355/77 will be extended until 30 June 1991;\\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Committee for the Fishing Industry,\\nThe specific programme for the provision of facilities at fishing ports in Madeira (1989 to 1993) submitted by Portugal on 30 October 1989, the main features of which are set out in Annex I, is hereby approved subject to the requirements in Annex II.\\nThis Decision is without prejudice to the granting of Community financial aid to individual investment projects.\\nThis Decision is addressed to the Portuguese Republic.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1730', '2561', '850'], 'source_id': 9}\n",
            "{'query': '20.5.2011 EN Official Journal of the European Union L 133/4\\nCOMMISSION IMPLEMENTING REGULATION (EU) No 484/2011\\nof 18 May 2011\\nentering a name in the register of protected designations of origin and protected geographical indications [Gönci kajszibarack (PGI)]\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Council Regulation (EC) No 510/2006 of 20 March 2006 on the protection of geographical indications and designations of origin for agricultural products and foodstuffs\\xa0(1), and in particular the first subparagraph of Article 7(4) thereof,\\nWhereas:\\n(1) Pursuant to the first subparagraph of Article 6(2) and in accordance with Article 17(2) of Regulation (EC) No 510/2006, Hungary’s application to register the name ‘Gönci kajszibarack’ was published in the Official Journal of the European Union\\n\\xa0(2).\\n(2) As no statement of objection under Article 7 of Regulation (EC) No 510/2006 has been received by the Commission, that name should therefore be entered in the register,\\nThe name contained in the Annex to this Regulation is hereby entered in the register.\\nThis Regulation shall enter into force on the 20th day following its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1255', '3173', '5360', '5573', '893'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 89/2004\\nof 20 January 2004\\nestablishing the standard import values for determining the entry price of certain fruit and vegetables\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Commission Regulation (EC) No 3223/94 of 21 December 1994 on detailed rules for the application of the import arrangements for fruit and vegetables(1), as last amended by Regulation (EC) No 1947/2002(2), and in particular Article 4(1) thereof,\\nWhereas:\\n(1) Regulation (EC) No 3223/94 lays down, pursuant to the outcome of the Uruguay Round multilateral trade negotiations, the criteria whereby the Commission fixes the standard values for imports from third countries, in respect of the products and periods stipulated in the Annex thereto.\\n(2) In compliance with the above criteria, the standard import values must be fixed at the levels set out in the Annex to this Regulation,\\nThe standard import values referred to in Article 4 of Regulation (EC) No 3223/94 shall be fixed as indicated in the Annex hereto.\\nThis Regulation shall enter into force on 21 January 2004.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1117', '1118', '1605', '2635', '5231', '693'], 'source_id': 9}\n",
            "{'query': \"COUNCIL REGULATION (EC) No 408/97 of 24 February 1997 on the conclusion of an Agreement on cooperation in the sea fisheries sector between the European Community and the Islamic Republic of Mauritania and laying down provisions for its implementation\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Treaty establishing the European Community, and in particular Article 43, in conjunction with Article 228 (2) and the first subparagraph of Article 228 (3) thereof,\\nHaving regard to the proposal from the Commission,\\nHaving regard to the opinion of the European Parliament (1),\\nWhereas, on 20 June 1996, the Community and the Islamic Republic of Mauritania initialled an Agreement on cooperation in the sea fisheries sector which provides fishing opportunities for Community fishermen in waters over which Mauritania has sovereignty or jurisdiction;\\nWhereas it is in the Community's interest to approve this Agreement;\\nWhereas, in order to manage them efficiently, the fishing opportunities available to the Community in Mauritania's fishing zone should be allocated between the Member States;\\nWhereas the fishing activities covered by this Regulation are subject to the controls provided for in Council Regulation (EEC) No 2847/93 of 12 October 1993 establishing a control system applicable to the common fisheries policy (2);\\nWhereas, to ensure implementation of the said Agreement, it is necessary for the Member States to ensure that shipowners comply with their obligations and provide the Commission with all relevant information;\\nWhereas in accordance with Regulation (EC) No 3317/94 (3) and with the arrangements agreed in the aforementioned Agreement, the flag Member State and the Commission have to ensure that applications for fishing licences comply with those arrangements and the Community rules applicable,\\nThe Agreement on cooperation in the sea fisheries sector between the European Community and the Islamic Republic of Mauritania, hereinafter referred to as 'the Agreement`, is hereby approved on behalf of the Community.\\nThe text of the Agreement is attached to this Regulation (4).\\nThe fishing opportunities arising from the provisional application of the Agreement shall be allocated according to the table in the Annex to this Regulation. As far as cephalopods are concerned, the annual allocation of the opportunities between Member States as from 1 August 1997 will be decided upon by 30 June each year according to the procedure provided for in Article 18 of Regulation (EEC) No 3760/92 (5).\\nWhere, in a fishing category, a Member State draws up licence applications for less than its allocated tonnage, the Commission shall offer shipowners from the other Member States the opportunity to submit applications.\\n1. The Member States shall:\\n(a) check that the data given on the licence application forms provided for in Appendix 1 to Annex I to the Agreement match those in the Community register of fishing vessels established by Commission Regulation (EC) No 109/94 (6), and report to the Commission any changes in those data at the time of subsequent applications.\\nThey shall likewise verify the assurance of the other data necessary for the drawing-up of licences;\\n(b) submit licence applications to the Commission in accordance with Article 3 (1) of Regulation (EC) No 3317/94, no later than two working days before the deadline laid down in point 2.1 of Chapter II of Annex I to the Agreement;\\n(c) provide the Commission each month with a list of vessels whose licences have been suspended with, by port, the date on which a licence was handed over and the date on which it was restored;\\n(d) transmit to the Commission the summaries of the inspection reports referred to in point 2 of Chapter IV of Annex II to the Agreement. The summaries shall describe the inspections carried out, the results obtained and the action taken;\\n(e) transmit to the Commission each month a copy of the scientific observers' reports provided for in point 14 of Chapter V of Annex II to the Agreement;\\nThey shall notify the Commission immediately of any infringements revealed by the information contained in these reports and the action taken;\\nThey shall enter the scientific data contained in these reports in an electronic database. The Commission shall have access to these databases;\\n(f) transmit to the Commission, and at the same time to Mauritania's competent authorities, a copy of the notice of the inspection missions planned under point 4 of Chapter VI of Annex II to the Agreement and, where relevant, of the notification that an observer will be taking part;\\nThey shall transmit to the Commission a copy of the reports of the observers appointed by their supervisory authorities pursuant to point 3 of Chapter VI of Annex II to the Agreement;\\n(g) adopt the provisions needed to take appropriate action and initiate administrative proceedings, as provided for in point 15 of Chapter V of Annex II to the Agreement.\\nThe President of the Council shall, on behalf of the Community, give the notification provided for in Article 16 of the Agreement (7).\\nThis Regulation shall enter into force on the seventh day following that of its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1035', '1842', '2556', '3001', '5228', '5404'], 'source_id': 9}\n",
            "{'query': '21.4.2005 EN Official Journal of the European Union L 101/10\\nCOMMISSION REGULATION (EC) No 611/2005\\nof 20 April 2005\\namending Regulation (EC) No 823/2000 on the application of Article 81(3) of the Treaty to certain categories of agreements, decisions and concerted practices between liner shipping companies (consortia)\\n(Text with EEA relevance)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 479/92 of 25 February 1992 on the application of Article 85(3) of the Treaty to certain categories of agreements, decisions and concerted practices between liner shipping companies (consortia)\\xa0(1), and in particular Article 1 thereof,\\nHaving published a draft of this Regulation\\xa0(2),\\nAfter consulting the Advisory Committee on Restrictive Practices and Dominant Positions,\\nWhereas:\\n(1) Commission Regulation (EC) No 823/2000\\xa0(3) grants a general exemption to liner shipping consortia from the prohibition contained in Article 81(1) of the Treaty, subject to certain conditions.\\n(2) Regulation (EC) No 823/2000 will expire on 25 April 2005. On the basis of the Commission’s experience in applying that Regulation, it appears that the justifications for a block exemption for consortia are still valid. The application of Regulation (EC) No 823/2000 should therefore be extended for a further five years.\\n(3) However, in some respects the provisions of Regulation (EC) No 823/2000 are not sufficiently attuned to current practice applied in the industry. It is therefore appropriate to introduce some minor amendments in order to make Regulation (EC) No 823/2000 more suitable for its purpose, pending the outcome of the review of Council Regulation (EEC) No 4056/86 of 22 December 1986 laying down detailed rules for the application of Articles 85 and 86 of the Treaty to maritime transport\\xa0(4), following which more substantial amendments may prove necessary.\\n(4) In particular, Regulation (EC) No 823/2000 provides that consortium agreements must give member companies the right to withdraw from the consortium without financial or other penalty, subject to certain conditions concerning the period of notice to be given. Practice has shown that it is unclear how this provision is to be interpreted in the event that the date of entry into force of the consortium agreement is earlier than the date the service actually starts, for example, when vessels are unavailable, or still under construction. Specific provision should therefore be made for that situation.\\n(5) It is justifiable for consortia to seek security for new investments committed to an existing service. Therefore, the possibility for the parties to a consortium agreement to enter into a ‘non-withdrawal’ clause should also apply where the parties to an existing consortium agreement have agreed to make substantial new investments and the costs of such new investments justify a new ‘non-withdrawal’ clause.\\n(6) Regulation (EC) No 823/2000 provides that the exemption is subject to compliance with certain conditions, including the existence of effective price competition between the members of the conference within which the consortium operates due to the fact that the members are expressly authorised by the conference agreement to apply independent rate action to any freight rate provided for in the conference tariff. It has been brought to the Commission’s attention that independent rate action can no longer be considered as a common general market practice. Instead, individual confidential contracts are now more important on various trades. Such confidential contracts may also bring about effective competition between liner conference members. The existence of individual confidential contracts should therefore also be regarded as an indicator of effective price competition between the members of the conference.\\n(7) Regulation (EC) No 823/2000 should therefore be amended accordingly,\\nRegulation (EC) No 823/2000 is amended as follows:\\n1. In Article 2 the following points 6 and 7 are added:\\n‘6. “commencement of the service” means the date on which the first vessel sails on the service or, when there has been substantial new investment, the date on which the first vessel sails under the conditions directly arising from that substantial new investment;\\n7. “substantial new investment” means investment which results in the building, purchase or long-term charter of vessels, which are specifically designed, required and substantial for the operation of the service and which constitutes at least half of the total investment made by the consortium members in relation to the maritime transport service offered by the consortium.’;\\n2. In Article 5 point (a) is replaced by the following:\\n‘(a) there is effective price competition between the members of the conference within which the consortium operates, due to the fact that the members are expressly authorised by the conference agreement, whether by virtue of a statutory obligation or otherwise, to apply independent rate action to any freight rate provided for in the conference tariff and/or to enter into individual confidential contracts; or’;\\n3. In Article 8 point (b) is replaced by the following:\\n‘(b) the consortium agreement must give member companies the right to withdraw from the consortium without financial or other penalty such as, in particular, an obligation to cease all transport activity in the trade or trades in question, whether or not coupled with the condition that such activity may be resumed only after a certain period has elapsed. This right shall be subject to a maximum notice period of six months which may be given after an initial period of 18 months starting from the date of entry into force of the consortium agreement or the agreement to make a substantial new investment in the joint maritime service. If the date of entry into force of the agreement is earlier than the date of commencement of the service, the initial period shall not be more than 24 months starting from the date of entry into force of the consortium agreement or the date of entry into force of the agreement to make a substantial new investment in the joint maritime service.\\n4. In the second paragraph of Article 14, the date ‘25 April 2005’ is replaced by ‘25 April 2010’.\\nThis Regulation shall enter into force on 26 April 2005.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2463', '3060', '4522', '539', '818'], 'source_id': 9}\n",
            "{'query': '11.1.2014 EN Official Journal of the European Union L 8/24\\nCOMMISSION IMPLEMENTING REGULATION (EU) No 22/2014\\nof 10 January 2014\\nestablishing the standard import values for determining the entry price of certain fruit and vegetables\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Council Regulation (EC) No 1234/2007 of 22 October 2007 establishing a common organisation of agricultural markets and on specific provisions for certain agricultural products (Single CMO Regulation)\\xa0(1),\\nHaving regard to Commission Implementing Regulation (EU) No 543/2011 of 7 June 2011 laying down detailed rules for the application of Council Regulation (EC) No 1234/2007 in respect of the fruit and vegetables and processed fruit and vegetables sectors\\xa0(2), and in particular Article 136(1) thereof,\\nWhereas:\\n(1) Implementing Regulation (EU) No 543/2011 lays down, pursuant to the outcome of the Uruguay Round multilateral trade negotiations, the criteria whereby the Commission fixes the standard values for imports from third countries, in respect of the products and periods stipulated in Annex XVI, Part A thereto.\\n(2) The standard import value is calculated each working day, in accordance with Article 136(1) of Implementing Regulation (EU) No 543/2011, taking into account variable daily data. Therefore this Regulation should enter into force on the day of its publication in the Official Journal of the European Union,\\nThe standard import values referred to in Article 136 of Implementing Regulation (EU) No 543/2011 are fixed in the Annex to this Regulation.\\nThis Regulation shall enter into force on the day of its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '1605', '2173', '2635', '3191', '693'], 'source_id': 9}\n",
            "{'query': \"COMMISSION  DECISION\\nof 13 July 1982\\nestablishing that the apparatus described as 'Nicolet - Digital Oscilloscope, model Explorer III' may not be imported free of Common Customs Tariff duties\\n(82/514/EEC)\\nTHE COMMISSION OF THE EUROPEAN\\nCOMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 1798/75 of 10 July 1975 on the importation free of Common Customs Tariff duties of educational, scientific and cultural materials (1), as amended by Regulation (EEC) No 1027/79 (2),\\nHaving regard to Commission Regulation (EEC) No 2784/79 of 12 December 1979 laying down provisions for the implementation of Regulation (EEC) No 1798/75 (3), and in particular Article 7 thereof,\\nWhereas, by letter dated 7 January 1982, Germany has requested the Commission to invoke the procedure provided for in Article 7 of Regulation (EEC) No 2784/79 in order to determine whether or not the apparatus described as 'Nicolet - Digital Oscilloscope model Explorer III', ordered on 4 November 1980 and to be used for the recording of mechanograms of muscule fibres for determination of the kinetics of muscule building blocks, should be considered as a scientific apparatus and, where the reply is in the affirmative, whether apparatus of equivalent scientific value is currently being manufactured in the Community;\\nWhereas, in accordance with the provisions of Article 7 (5) of Regulation (EEC) No 2784/79, a group of experts composed of representatives of all the Member States met on 14 May 1982 within the framework of the Committee on Duty-Free Arrangements to examine the matter;\\nWhereas this examination showed that the apparatus in question is an oscilloscope; whereas it does not have the requisite objective characteristics making it specifically suited to scientific research; whereas, moreover, apparatus of the same kind are principally used for non-scientific activities; whereas its use in the case in question could not alone confer upon it the character of a scientific apparatus; whereas it therefore cannot be regarded as a scientific apparatus; whereas the duty-free admission of the apparatus in question is therefore not justified,\\nThe apparatus described as 'Nicolet - Digital Oscilloscope, model Explorer III', which is the subject of an application by Germany of 7 January 1982, may not be imported free of Common Customs Tariff duties.\\nThis Decision is addressed to the Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1091', '3842', '4381', '4921'], 'source_id': 9}\n",
            "{'query': \"COUNCIL  REGULATION (EEC) No 636/93 of 15 March 1993 opening and providing for the administration of a  Community preferential ceiling for certain petroleum products refined in Turkey and establishing  Community surveillance for imports thereof (1993)\\nTHE COUNCIL OF THE EUROPEAN  COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article  113 thereof,\\nHaving regard to the proposal from the Commission,\\nWhereas Article 7 of the Supplementary Protocol to the Association Agreement between the European  Economic Community and Turkey consequent on the accession of new Member States to the Community   (1), which was signed in Ankara on 30 June 1973 and entered into force on 1 March 1986  (2),  provides for the total suspension of customs duties applicable in certain petroleum products  refined in Turkey falling within Chapter 27 of the Common Customs Tariff within the limits of an  annual Community tariff quota of 340  000 tonnes; whereas, for the products concerned, a  provisional adjustment should be made to those tariff preferences, consisting essentially of  substituting for the Community tariff quota a Community ceiling amounting, after successive  increases, to 740  250 tonnes, above which the customs duties applicable to third countries may be  re-established;\\nWhereas the Council adopted Regulation (EEC) No 1059/88 laying down the arrangements applicable to  Greece's trade with Turkey  (3); whereas, the Council also adopted Regulation (EEC) No 2573/87  laying down the arrangements for trade between Spain and Portugal, on the one hand, and Algeria,  Egypt, Jordan, Lebanon, Tunisia and Turkey, on the other  (4); whereas the tariff quota in question  applies therefore to the current Community;\\nWhereas the application of ceilings requires the Community to be regularly informed of the trend of  imports of the relevant products originating in Turkey; whereas imports should, therefore, be made  subject to a system of surveillance;\\nWhereas the decision for the opening of Community tariff ceilings in the execution of its  international obligations should be taken by the Community; whereas to ensure the efficiency of a  common administration of these ceilings, the Member States might well have recourse to the means of  an administrative procedure based on offsetting imports of the products in question against the  ceiling at Community level as and when these products are entered with the customs authorities for  free circulation; whereas this administrative procedure must make provision for the possible  re-establishment of customs tariff duties as soon as the ceiling is reached at Community level;\\nWhereas this administrative procedure requires close and particularly swift cooperation between the  Member States and the Commission; whereas the latter must, in particular, be able to follow the  progress of quantities charged against the ceiling and keep the Member States informed; whereas  this cooperation has to be particularly close since the Commission must be able to take the  appropriate measures to re-establish customs tariff duties if the ceiling is reached,\\n1.  From 1 January to 31 December 1993 the duties applicable to  imports into the Community of the petroleum products refined in Turkey and indicated in paragraph 2  shall be suspended in full within the limits of a Community ceiling of 740  250 tonnes.\\n2.  The petroleum products to which paragraph 1 applies shall be the following:\\n>TABLE>\\n3.  Imports of the petroleum products referred to in paragraph 1 shall be subject  to Community surveillance.\\n4.  Quantities shall be charged against the ceiling as and when products are entered with the  customs authorities for free circulation.\\n5.  The extent to which that ceiling is used up shall be determined at Community level on the basis  of the imports charged against it, in the manner specified in paragraph 4.\\n6.  Member States shall inform the Commission, at the intervals and within the time limits  specified in Article 3, of imports effected in accordance with the rules referred to in this  Article.\\nAs soon as the ceiling referred to in Article 1 (1) has been reached at Community  level, the Commission may adopt a regulation re-establishing, until the end of the calendar year,  the collection of the duties normally applicable.\\nMember States shall send the Commission statements of the quantities charged for the  preceding month no later than the 15th day of each month. At the Commission's request, they shall  send statements of the quantities charged for periods of 10 days, to be forwarded within five clear  days of the end of each 10-day period.\\nThe Commission shall take all appropriate measures, in close cooperation with the  Member States, to ensure the implementation of this Regulation.\\nThis Regulation shall enter into force on 1 January 1993.\\nThis Regulation shall be binding in its entirety and directly applicable in all  Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['161', '2772', '4347', '4580'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION (EC) No 1305/1999\\nof 21 June 1999\\nfixing for the 1999/2000 marketing year the minimum price to be paid to producers for Williams and Rocha pears and the amount of production aid for Williams and Rocha pears in syrup and/or natural fruit juice\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 2201/96 of 28 October 1996 on the common organisation of the market in products processed from fruit and vegetables(1), as last amended by Regulation (EC) No 2199/97(2), and in particular Articles 3(3) and 4(9) thereof,\\n(1) Whereas the minimum price and the amount of the production aid should be set for the 1999/2000 marketing year for Williams and Rocha pears in syrup and/or natural fruit juice on the basis of the criteria laid down in Articles 3 and 4 of Regulation (EC) No 2201/96 respectively, taking account of the guarantee threshold beyond which the aid is reduced introduced by Article 5 of that Regulation;\\n(2) Whereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Products Processed from Fruit and Vegetables,\\nFor the 1999/2000 marketing year:\\n(a) the minimum price referred to in Article 3 of Regulation (EC) No 2201/96 shall be EUR 35,552 per 100 kg net from the producer for Williams and Rocha pears intended for the production of pears in syrup and/or natural fruit juice;\\n(b) the production aid referred to in Article 4 of that Regulation shall be EUR 11,886 per 100 kg net for Williams and Rocha pears in syrup and/or natural fruit juice.\\nThis Regulation shall enter into force on the third day following its publication in the Official Journal of the European Communities.\\nIt shall apply from 15 July 1999.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '2638', '2681', '4083', '797'], 'source_id': 9}\n",
            "{'query': \"14.8.2004 EN Official Journal of the European Union L 267/54\\nCOMMISSION DECISION\\nof 13 August 2004\\non a financial contribution from the Community towards the eradication of classical swine fever in Luxembourg in 2003\\n(notified under document number C(2004) 3084)\\n(Only the French text is authentic)\\n(2004/598/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Decision 90/424/EEC of 26 June 1990 on expenditure in the veterinary field\\xa0(1), and in particular Article 3(3) and Article 5(3) thereof,\\nWhereas:\\n(1) An outbreak of classical swine fever occurred in Luxembourg in 2003. The emergence of this disease represents a serious risk to the Community's livestock population.\\n(2) With a view to helping to eradicate the disease as rapidly as possible, the Community may contribute financially to eligible costs incurred by the Member State, as provided for in Decision 90/424/EEC.\\n(3) Pursuant to Article 3(2) of Council Regulation (EC) No 1258/1999 of 17 May 1999 on the financing of the common agricultural policy\\xa0(2), veterinary and plant health measures undertaken in accordance with Community rules shall be financed under the Guarantee section of the European Agricultural Guidance and Guarantee Fund. The auditing of these measures comes under Articles 8 and 9 of the said Regulation.\\n(4) The payment of the Community financial contribution must be subject to the condition that the planned activities were actually implemented and the authorities provide all the necessary information within certain deadlines.\\n(5) On 12 March 2004, Luxembourg submitted an official request for reimbursement for all the expenditure incurred on its territory. According to this request 1\\xa0351 animals were culled.\\n(6) The terms ‘swift and adequate compensation of the livestock farmers’ used in Article 3 of Decision 90/424/EEC, ‘reasonable payments’ and ‘justified payments’ and the categories of eligible expenditure under ‘other costs’ associated with the compulsory culling should all be defined.\\n(7) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,\\nGranting of a financial contribution from the Community to Luxembourg\\nIn order to eradicate classical swine fever in 2003, Luxembourg may benefit from a Community financial contribution for 50\\xa0% of the expenditure incurred for:\\n(a) the swift and adequate compensation of farmers forced to cull their animals as part of the measures to eradicate the outbreaks of classical swine fever in 2003, pursuant to the provisions of the first and seventh indents of Article 3(2) of Decision 90/424/EEC and in accordance with this Decision;\\n(b) the operational expenditure associated with the culling of the animals, the destruction of carcasses and products, the cleaning and disinfecting of premises and the cleaning and disinfecting, or destruction if necessary, of contaminated equipment, pursuant to the provisions of the first, the second and third indents of Article 3(2) of Decision 90/424/EEC and in accordance with this Decision.\\nDefinitions\\nIn this Decision, the following definitions shall apply:\\n(a) ‘swift and adequate compensation’ means payment, within 90 days of the culling of the animals, for compensation corresponding to the market value as defined in Article 3(1);\\n(b) ‘reasonable payments’ means payments for the purchase of materials or services at proportionate prices compared to the market prices before the outbreak of the classical swine fever;\\n(c) ‘justified payments’ means payments for the purchase of materials or services of which the nature and the direct link with the compulsory culling of animals, as referred to in Article 1(a) is demonstrated.\\nThe eligible expenditure covered by the financial contribution from the Community\\n1.\\xa0\\xa0\\xa0The maximum amount per animal of the compensation to the owners of the animals shall be based on the market value the animals had before their contamination or culling.\\n2.\\xa0\\xa0\\xa0When the compensation payments made by Luxembourg pursuant to Article 1(a) are effected after the 90 days deadline laid down in Article 2(a), the eligible amounts shall be reduced for expenditure effected after the deadline as follows:\\n— 25\\xa0% for payments made between 91 and 105 days after the culling of the animals,\\n— 50\\xa0% for payments made between 106 and 120 days after the culling of the animals,\\n— 75\\xa0% for payments made between 121 and 135 days after the culling of the animals,\\n— 100\\xa0% for payments beyond 135 days after the culling of the animals.\\nHowever, the Commission will apply a different time-scale and/or lower reductions or none at all, if exceptional management conditions are encountered for certain measures, or if other well-founded justifications are introduced by Luxembourg.\\n3.\\xa0\\xa0\\xa0The costs referred to in Article 1(b) eligible for a financial contribution shall only be those set out in Annex III.\\n4.\\xa0\\xa0\\xa0The calculation of the financial contribution from the Community shall exclude:\\n(a) value added tax;\\n(b) salaries of civil servants;\\n(c) use of public material other than consumables.\\nConditions for payment and supporting documentation\\n1.\\xa0\\xa0\\xa0The financial contribution from the Community shall be fixed in accordance with the procedure laid down in Article 41 of Council Decision 90/424/EEC on the basis of:\\n(a) a claim submitted in accordance with Annexes I and II within the time-limit provided for in paragraph 2;\\n(b) detailed documents confirming the figures in the claim referred to in point (a);\\n(c) the results of the on-the-spot checks, if any, by the Commission as referred to in Article 5.\\nThe documents referred to in point (b) as well as relevant commercial information shall be made available for on-the-spot checks by the Commission.\\n2.\\xa0\\xa0\\xa0The claim referred to in paragraph 1(a) shall be provided in computerised form in accordance with Annex I and Annex II within 60 calendar days after the notification of the present Decision.\\nWhen this deadline is not observed, the financial contribution from the Community shall be reduced by 25\\xa0% for each month of delay.\\nOn-the-spot checks by the Commission\\nThe Commission may make on-the-spot checks, with the co-operation of the competent national authorities, on the implementation of the classical swine fever eradication measures and the related costs incurred.\\nRecipients\\nThis Decision is addressed to the Grand Duchy of Luxembourg.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1712', '1857', '2356', '2560', '2965', '862'], 'source_id': 9}\n",
            "{'query': '30.3.2011 EN Official Journal of the European Union L 82/7\\nEUROPEAN COUNCIL DECISION\\nof 25 March 2011\\nappointing a member of the Executive Board of the European Central Bank\\n(2011/195/EU)\\nTHE EUROPEAN COUNCIL\\n,\\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 283(2) thereof,\\nHaving regard to the Protocol on the Statute of the European System of Central Banks and of the European Central Bank, and in particular Article 11.2 thereof,\\nHaving regard to the recommendation of the Council of the European Union\\xa0(1),\\nHaving regard to the opinion of the European Parliament\\xa0(2),\\nHaving regard to the opinion of the Governing Council of the European Central Bank\\xa0(3),\\nMr Peter PRAET is hereby appointed member of the Executive Board of the European Central Bank for a term of office of 8 years, as from 1 June 2011.\\nThis Decision shall be published in the Official Journal of the European Union.\\nThis Decision shall enter into force on the date of its adoption.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['3559', '5455', '5762'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 2412/2001\\nof 10 December 2001\\nre-establishing the preferential customs duty on imports of multiflorous (spray) carnations originating in Israel\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 4088/87 of 21 December 1987 fixing conditions for the application of preferential customs duties on imports of certain flowers originating in Cyprus, Israel, Jordan and Morocco and the West Bank and the Gaza Strip(1), as last amended by Regulation (EC) No 1300/97(2), and in particular Article 5(2)(b) thereof,\\nWhereas:\\n(1) Regulation (EEC) No 4088/87 fixes conditions for the application of a preferential customs duty on large-flowered roses, small-flowered roses, uniflorous (bloom) carnations and multiflorous (spray) carnations within the limit of tariff quotas opened annually for imports of fresh cut flowers into the Community.\\n(2) Council Regulation (EC) No 747/2001(3) opens and provides for the administration of Community tariff quotas for certain products originating in Cyprus, Egypt, Israel, Malta, Morocco, the West Bank and the Gaza Strip, Tunisia and Turkey, and providing detailed rules for extending and adapting these tariff quotas.\\n(3) Commission Regulation (EC) No 2410/2001(4) fixed Community producer and import prices for carnations and roses for application of the arrangements for importation from the countries in question.\\n(4) Commission Regulation (EEC) No 700/88(5), as last amended by Regulation (EC) No 2062/97(6), laid down detailed rules for the application of these arrangements.\\n(5) The preferential customs duty fixed for multiflorous (spray) carnations originating in Israel by Regulation (EC) No 747/2001 was suspended by Commission Regulation (EC) No 753/2001(7).\\n(6) On the basis of price recordings made as specified in Regulations (EEC) No 4088/87 and (EEC) No 700/88 it must be concluded that the requirement for reintroduction of the preferential customs duty laid down in Article 2(4) of Regulation (EEC) No 4088/87 is met for multiflorous (spray) carnations originating in Israel. The preferential customs duty should be reintroduced.\\n(7) In between meetings of the Management Committee for Live Plants and Floriculture Products, the Commission must adopt such measures,\\n1. For imports of multiflorous (spray) carnations (CN code ex 0603 10 20 ) originating in Israel the preferential customs duty set by Regulation (EC) No 747/2001 is reintroduced.\\n2. Regulation (EC) No 753/2001 is hereby repealed.\\nThis Regulation shall enter into force on 12 December 2001.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1031', '1309', '1518', '3611', '4385'], 'source_id': 9}\n",
            "{'query': '22.11.2005 EN Official Journal of the European Union L 303/28\\nCOMMISSION REGULATION (EC) No 1903/2005\\nof 21 November 2005\\nestablishing a prohibition of fishing for mackerel in ICES zone IIa (non-EC waters), Vb (EC waters), VI, VII, VIIIa, b, d, e, XII, XIV by vessels flying the flag of France\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 2371/2002 of 20 December 2002 on the conservation and sustainable exploitation of fisheries resources under the common fisheries policy\\xa0(1), and in particular Article 26(4) thereof,\\nHaving regard to Council Regulation (EEC) No 2847/93 of 12 October 1993 establishing a control system applicable to the common fisheries policy\\xa0(2), and in particular Article 21(3) thereof,\\nWhereas:\\n(1) Council Regulation (EC) No 27/2005 of 22 December 2004 fixing for 2005 the fishing opportunities and associated conditions for certain fish stocks and groups of fish stocks, applicable in Community waters and, for Community vessels, in waters where catch limitations are required\\xa0(3), lays down quotas for 2005.\\n(2) According to the information received by the Commission, catches of the stock referred to in the Annex to this Regulation by vessels flying the flag of or registered in the Member State referred to therein have exhausted the quota allocated for 2005.\\n(3) It is therefore necessary to prohibit fishing for that stock and its retention on board, transhipment and landing,\\nQuota exhaustion\\nThe fishing quota allocated to the Member State referred to in the Annex to this Regulation for the stock referred to therein for 2005 shall be deemed to be exhausted from the date set out in that Annex.\\nProhibitions\\nFishing for the stock referred to in the Annex to this Regulation by vessels flying the flag of or registered in the Member State referred to therein shall be prohibited from the date set out in that Annex. It shall be prohibited to retain on board, tranship or land such stock caught by those vessels after that date.\\nEntry into force\\nThis Regulation shall enter into force on the day following its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1085', '2282', '2437', '2879', '4790', '5228', '544'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 585/2001\\nof 26 March 2001\\nproviding for compensation to producer organisations for tuna delivered to the processing industry between 1 January and 31 March 2000\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 104/2000 of 17 December 1999 on the common organisation of the market in fishery and aquaculture products(1), and in particular Article 27(6) thereof,\\nWhereas:\\n(1) Until 31 December 2000, Article 18 of Council Regulation (EEC) No 3759/92 of 17 December 1992 on the common organisation of the market in fishery and aquaculture products(2), which was repealed by Regulation (EC) No 104/2000, provided for a compensatory allowance to be granted under certain conditions to Community tuna producer organisations for quantities of tuna delivered to the processing industry during the calendar quarter for which prices had been recorded, where both the average quarterly selling price recorded on the Community market and the free-at-frontier price plus any applicable countervailing charge were lower than 91 % of the Community producer price for the product concerned.\\n(2) An examination of the situation on the Community market in the year 2000 has shown that between 1 January and 31 March of that year both the average quarterly selling price and the free-at-frontier price as referred to in Article 18 of Regulation (EEC) No 3759/92 for yellowfin tuna (Thunnus albacares) weighing more than 10 kg each, yellowfin tuna (Thunnus albacares) weighing not more than 10 kg each, bigeye tuna (Thunnus obesus) and skipjack or stripe-bellied bonito (Euthynnus (Katsuwonus) pelamis) were lower than 91 % of the Community producer price in force, as laid down in Council Regulation (EC) No 2748/1999(3).\\n(3) The conditions laid down by Regulation (EEC) No 3759/92 should be retained in order to take a decision on granting the compensatory allowance on the products in question for the period from 1 January to 31 March 2000.\\n(4) Entitlement to the compensatory allowance should be determined on the basis of sales covered by invoices bearing a date falling within the quarter concerned and which have been used to calculate the average monthly selling price referred to in Article 7(1)(b) of Commission Regulation (EEC) No 2210/93(4), which was repealed with effect from 1 January 2001 by Commission Regulation (EC) No 80/2001(5).\\n(5) The level of the compensation provided for in Article 18(2) of Regulation (EEC) No 3759/92 may not in any case exceed either the difference between the triggering threshold and the average selling price of the product in question on the Community market or a flat-rate amount equivalent to 12 % of that threshold.\\n(6) The quantities on which compensation as provided for in Article 18(1) of Regulation (EEC) No 3759/92 is payable may under no circumstances exceed the limits laid down in paragraph 3 of that Article for the quarter concerned.\\n(7) The quantities of yellowfin tuna (Thunnus albacares) weighing more than 10 kg each, yellowfin tuna (Thunnus albacares) weighing not more than 10 kg each, bigeye tuna (Thunnus obesus) and skipjack or stripe-bellied bonito (Euthynnus (Katsuwonus) pelamis) sold and delivered to the processing industry established in the customs territory of the Community were higher during the quarter concerned than the quantities sold and delivered during the same quarter of the three previous fishing years. Since those quantities exceed the limit set in Article 18(3) of Regulation (EEC) No 3759/92, the total quantities of those products on which compensation is payable should therefore be limited.\\n(8) In accordance with the ceilings laid down in Article 18(4) of Regulation (EEC) No 3759/92 for the purpose of calculating the allowance to be granted to each producer organisation, the quantities on which the allowance is payable should be allocated among the producer organisations concerned in proportion to the quantities produced by them in the same quarter of the 1997, 1998 and 1999 fishing years.\\n(9) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Fishery Products,\\nThe compensatory allowance to producer organisations for tuna delivered to the processing industry shall be granted for the period from 1 January to 31 March 2000 in respect of the following products:\\n>TABLE>\\n1. The total quantities on which the allowance for these species is payable shall be:\\n>TABLE>.\\n2. The allocation of the total quantity among the producer organisations concerned shall be as set out in the Annex hereto.\\nThis Regulation shall enter into force on the seventh day following its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1201', '1377', '1486', '2320', '2437'], 'source_id': 9}\n",
            "{'query': 'COUNCIL REGULATION (EEC) No 391/86 of 17 February 1986 on the  application of EEC-Sweden Joint Committee Decision No 2/85 supplementing Annexes II and III to  Protocol 3 concerning the definition of the concept of originating products and methods of  administrative cooperation by the addition of alternative percentage rules for the products of  Chapters 84 to 92 of the Customs Cooperation Council Nomenclature\\nTHE COUNCIL OF  THE EUROPEAN COMMUNITIES\\n, Having regard to the Treaty establishing the European Economic Community,  and in particular Article 113 thereof, Having regard to the proposal from the Commission, Whereas  an Agreement between the European Economic Community and the Kingdom of Sweden (1) was signed on 22  July 1972 and entered into force on 1 January 1973; Whereas, by virtue of Article 28 of Protocol 3  concerning the definition of the concept of originating products and methods of administrative  cooperation, which forms an integral part of the above Agreement, the Joint Committee has, because  of the interdependence of the industrial sectors of the European Economic Community and Sweden, and  the reciprocal nature and mutual importance of the preferential trade concerned, adopted Decision  No 2/85 supplementing Annexes II and III to that Protocol by the addition of alternative percentage  rules for the products of Chapters 84 to 92 of the Customs Cooperation Council Nomenclature;  Whereas it is necessary to apply this Decision in the Community,\\nFor the application of the Agreement between the European  Economic Community and the Kingdom of Sweden, EEC-Sweden Joint Committee Decision No 2/85 shall be  applied in the Community. The text of the Decision is attached to this Regulation.\\nThis  Regulation shall enter into force on the third day following that of its publication in the  Official Journal of the European Communities.\\nThis Regulation shall be binding in  its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['206', '2765', '2771', '2850', '4320'], 'source_id': 9}\n",
            "{'query': '27.2.2014 EN Official Journal of the European Union L 57/27\\nCOMMISSION IMPLEMENTING REGULATION (EU) No 188/2014\\nof 26 February 2014\\nestablishing the standard import values for determining the entry price of certain fruit and vegetables\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Council Regulation (EC) No 1234/2007 of 22 October 2007 establishing a common organisation of agricultural markets and on specific provisions for certain agricultural products (Single CMO Regulation)\\xa0(1),\\nHaving regard to Commission Implementing Regulation (EU) No 543/2011 of 7 June 2011 laying down detailed rules for the application of Council Regulation (EC) No 1234/2007 in respect of the fruit and vegetables and processed fruit and vegetables sectors\\xa0(2), and in particular Article 136(1) thereof,\\nWhereas:\\n(1) Implementing Regulation (EU) No 543/2011 lays down, pursuant to the outcome of the Uruguay Round multilateral trade negotiations, the criteria whereby the Commission fixes the standard values for imports from third countries, in respect of the products and periods stipulated in Annex XVI, Part A thereto.\\n(2) The standard import value is calculated each working day, in accordance with Article 136(1) of Implementing Regulation (EU) No 543/2011, taking into account variable daily data. Therefore this Regulation should enter into force on the day of its publication in the Official Journal of the European Union,\\nThe standard import values referred to in Article 136 of Implementing Regulation (EU) No 543/2011 are fixed in the Annex to this Regulation.\\nThis Regulation shall enter into force on the day of its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '1605', '2173', '2635', '3191', '5231', '693'], 'source_id': 9}\n",
            "{'query': \"COUNCIL REGULATION (EEC) No 2139/92  of 23 July 1992  on urgent action for the supply of agricultural products to the victims of the conflict in what was formerly Yugoslavia\\nTHE COUNCIL OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 2727/75 of 29 October 1975 on the common organization of the market in cereals (1), and in particular Article 7 (5) and (8) thereof,\\nHaving regard to Council Regulation (EEC) No 804/68 of 27 June 1968 on the common organization of the market in milk and milk products (2), and in particular Articles 6 (6) and 7 (4) thereof,\\nHaving regard to Council Regulation (EEC) No 805/68 of 27 June 1968 on the common organization of the market in beef and veal (3), and in particular Articles 6 (5) and 7 (2) thereof,\\nHaving regard to Council Regulation (EEC) No 1035/72 of 18 May 1972 on the common organization of the market in fruit and vegetables (4), and in particular Article 35 thereof,\\nHaving regard to Council Regulation (EEC) No 426/86 of 24 February 1986 on the common organization of the market in products processed from fruit and vegetables (5), and in particular Article 8 (3) and (6) thereof,\\nHaving regard to Council Regulation (EEC) No 1418/76 of 21 June 1976 on the common organization of the market in rice (6), and in particular Article 5 thereof,\\nHaving regard to Council Regulation No 136/66/EEC of 22 September 1966 on the establishment of a common organization of the market in oils and fats (7), and in particular Article 12 (2a) and (3) thereof,\\nHaving regard to the proposal from the Commission,\\nWhereas the market for certain agricultural products may feature production situations which make it possible to dispose of such products on special terms;\\nWhereas in application of the European Council's conclusions of 26 and 27 June 1992 regarding the supply of substantial additional aid to victims of the conflict in what was formerly Yugoslavia, provision should be made for making agricultural products  available in order to improve conditions of supply to these people; whereas, in the case of some of these products, the necessary measures could be adopted by the Commission, pursuant to the rules in force;\\nWhereas it is for the Commission to lay down the detailed rules enabling the measure provided for by this Regulation to be executed,\\nAn emergency measure is hereby adopted, under the conditions laid down in this Regulation, for free supply to the victims of the conflict in what was formerly Yugoslavia of certain foodstuffs to be determined, available as a result of  intervention measures.\\nThe expense of the measure shall be limited to ECU 35 million, entered in the general budget of the European Communities.\\n1. The products may be supplied unprocessed or in processed form.\\n2. The measure may also relate to foodstuffs obtained through a commercial exchange of products from intervention storage against foodstuffs belonging to the same group of products.\\n3. The supply costs, including transport and, where applicable, processing, shall be determined by invitation to tender or, on account of the urgency of the situation, by direct agreement procedure.\\n4. The costs shall be reimbursed to the operators concerned in respect of the supply of products for which proof is provided that the products have reached the delivery stage laid down.\\n5. Distribution costs shall be covered according to the usual emergency aid procedures.\\n6. Products consigned pursuant to this Regulation shall not qualify for export refunds and shall not be subject to the arrangements concerning monetary compensatory amounts.\\n1. The Commission shall be responsible for executing the measure.\\n2. The detailed rules for the application of this Regulation shall be adopted in accordance with the procedure laid down in Article 26 of Regulation (EEC) No 2727/75 or, as the case may be, in the corresponding Articles in Regulations (EEC) No 804/68,  (EEC) No 805/68, (EEC) No 1035/72, (EEC) No 426/86, (EEC) No 1418/76 and (EEC) No 136/66/EEC.\\nThe Commission shall be responsible for supervising the delivery operations.\\nThis Regulation shall enter into force on the day of its publication in the Official Journal of the European Communities. This Regulation shall be binding in its entirety and directly applicable in all Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1211', '2734', '4696', '4778', '807', '881'], 'source_id': 9}\n",
            "{'query': 'COUNCIL REGULATION (EEC) No 151/91  of 21 January 1991  amending the list of least-developed countries contained in Annex II to Regulation (EEC) No 429/87\\nTHE COUNCIL OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 428/87 of 9 February 1987 setting up a system of compensation for loss of export earnings for least-developed countries not signatory to the Third ACP-EEC Convention (1), and in particular Article 9 thereof,\\nHaving regard to the proposal from the Commission,\\nWhereas the Republic of Haiti has recently signed the fourth ACP-EEC Convention and will therefore be covered by the Stabex system set up by that Convention from the 1990 year of application onwards;\\nWhereas that country should therefore be withdrawn from the list of countries contained in Annex II to Council Regulation (EEC) No 429/87 of 9 February 1987 laying down detailed rules for the implementation of Regulation (EEC) No 428/87 (2),\\n    Article 1\\nThe Republic of Haiti is hereby withdrawn from the list of countries contained in Annex II to Regulation (EEC) No 429/87.  Article 2\\nThis Regulation shall enter into force on the third day following its publication in the Official Journal of the European Communities.\\nIt shall apply from 1 January 1990.   This Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2299', '2355', '3472', '946'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 348/2003\\nof 25 February 2003\\nestablishing the standard import values for determining the entry price of certain fruit and vegetables\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Commission Regulation (EC) No 3223/94 of 21 December 1994 on detailed rules for the application of the import arrangements for fruit and vegetables(1), as last amended by Regulation (EC) No 1947/2002(2), and in particular Article 4(1) thereof,\\nWhereas:\\n(1) Regulation (EC) No 3223/94 lays down, pursuant to the outcome of the Uruguay Round multilateral trade negotiations, the criteria whereby the Commission fixes the standard values for imports from third countries, in respect of the products and periods stipulated in the Annex thereto.\\n(2) In compliance with the above criteria, the standard import values must be fixed at the levels set out in the Annex to this Regulation,\\nThe standard import values referred to in Article 4 of Regulation (EC) No 3223/94 shall be fixed as indicated in the Annex hereto.\\nThis Regulation shall enter into force on 26 February 2003.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '1605', '2511', '2635', '5231', '693'], 'source_id': 9}\n",
            "{'query': \"6.7.2007 EN Official Journal of the European Union L 176/25\\nCOMMISSION DECISION\\nof 28 June 2007\\nsetting up the Expert Group on Radio Frequency Identification\\n(2007/467/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nWhereas:\\n(1) Article 153 of the Treaty assigned the European Community the task of ensuring a high level of protection for consumers, by promoting their right to information and to organising themselves in order to safeguard their interests. Article 163 provides that the Community shall encourage industry to become more competitive at international level and encourage undertakings to exploit the internal market potential to the full, including through the definition of common standards. Article 157 provides that the Community and Member States shall encourage an environment favourable to initiative and shall foster better exploitation of the industrial potential of policies.\\n(2) The Commission Communication entitled ‘Radio Frequency Identification (RFID) in Europe: steps towards a policy framework’\\xa0(1) (hereinafter ‘the Communication’) announced the creation of the expert group on Radio Frequency Identification (hereinafter ‘RFID’) which should allow a dialogue between stakeholders, in order to fully understand and advise on action which should be taken in relation to the concerns raised in the Communication.\\n(3) It is therefore necessary to set up a group of experts in the field of RFID and to define its tasks and its structure.\\n(4) The group should help to develop a dialogue between consumer organisations, market actors, and national and European authorities, including data protection authorities.\\n(5) Personal data relating to members of the group should be processed in accordance with Regulation (EC) No 45/2001 of the European Parliament and of the Council of 18 December 2000 on the protection of individuals with regard to the processing of personal data by the Community institutions and bodies and on the free movement of such data\\xa0(2).\\n(6) It is appropriate to fix a period for the application of this Decision. The Commission will in due time consider the advisability of an extension,\\nThe Expert Group on Radio Frequency Identification\\nThe ‘Expert Group on Radio Frequency Identification’ group of experts, hereinafter referred to as ‘the group’ is hereby set up with effect from 1.7.2007.\\nTask\\nThe group's tasks shall be to:\\n(a) To provide advice to the Commission on the content of a Recommendation which shall set out the principles that public authorities and other stakeholders should apply in respect of RFID usage and on the content of other Commission initiatives related to this field;\\n(b) To develop guidelines on how RFID applications should operate taking into account the views of stakeholders and issues relating to long-term users as well as economic and societal aspects of RFID technologies;\\n(c) To support the Commission in its efforts to promote awareness campaigns at Member States and citizen level about the opportunities and challenges of RFID.\\n(d) To provide objective information and facilitate the exchange of experience and good practices in respect of the opportunities and challenges of RFID technology, including applications for Europe's economy and society; to provide objective information on the Community and national regulatory frameworks as regards data protection and privacy, and on other policy concerns.\\nConsultation\\nThe Commission may consult the group on any matter relating to the implementation in Europe of a safe, secure, privacy-friendly and effective approach to RFID.\\nMembership — Appointment\\n1.\\xa0\\xa0\\xa0The group shall be composed of up to 35 members.\\n2.\\xa0\\xa0\\xa0The Director-General of DG ‘Information Society and Media’ or his/her representative shall appoint the members and observers of the group from specialists with competence in the areas referred to in Articles 2 and 3.1 and on the proposal of organisations that have been invited to recommend experts. Alternate members for the members of the group shall be appointed in equal numbers and on the same conditions as the members. An alternate member shall automatically replace the member who is absent or indisposed.\\n3.\\xa0\\xa0\\xa0Members shall be appointed to ensure a balanced representation of the various stakeholders and, more specifically, will include representatives from the following areas:\\n(a) Civil society:\\n(i) the end-user communities that are subjected to RFID systems (citizens, consumers, patients, employees);\\n(ii) privacy organisations.\\n(b) Interested parties:\\n(i) users from different application sectors (for example, logistics, automotive, aerospace, health, retail, pharmaceuticals);\\n(ii) parties that are actively involved in setting up RFID systems (such as RFID chip producers, designers and manufacturers of packaged tags and readers, software and systems integrators, service providers, and privacy and security solution providers);\\n(iii) standardisation bodies.\\n4.\\xa0\\xa0\\xa0The following public authorities shall be invited to participate in the group's deliberations as observers:\\n(a) Representatives of the Member States assuming Presidency of the EU over the course of the Expert Group term of office;\\n(b) Representatives of data protection authorities.\\n5.\\xa0\\xa0\\xa0The following experts shall be invited to participate in the group's deliberations as observers:\\n(a) Academic researchers and practitioners;\\n(b) Technology experts, in particular with regard to the next generation of networked RFIDs (‘Internet of Things’);\\n(c) Legal experts who shall provide advice on existing legislation.\\n6.\\xa0\\xa0\\xa0Members of the group are appointed for a two-year renewable term of office. They shall remain in office until such time as they are replaced or their term of office ends.\\n7.\\xa0\\xa0\\xa0Members who are no longer able to contribute effectively to the group's deliberations, who resign or who do not respect the conditions set out in paragraphs three to five of this Article or Article 287 of the Treaty may be replaced for the remaining period of their term of office.\\n8.\\xa0\\xa0\\xa0The names of the organisations mentioned in paragraph 2 of this article are published on the Internet site of the DG ‘Information Society and Media’. Data on members are collected, processed and published in accordance with the provisions of Regulation (EC) No 45/2001.\\nOperation\\n1.\\xa0\\xa0\\xa0The group shall be chaired by a representative of the Commission.\\n2.\\xa0\\xa0\\xa0In agreement with the Commission, sub-groups may be set up to examine specific questions under the terms of reference established by the group. Such groups shall be dissolved as soon as their mandates are fulfilled.\\n3.\\xa0\\xa0\\xa0The Commission's representative may ask experts or observers with specific competence on a subject on the agenda to participate in the group's or sub-group's deliberations if this is useful and/or necessary.\\n4.\\xa0\\xa0\\xa0Information obtained by participating in the deliberation of a group or sub-group may not be divulged if, in the opinion of the Commission, that information relates to confidential matters.\\n5.\\xa0\\xa0\\xa0The group and its sub-groups shall normally meet on Commission premises in accordance with the procedures and schedule established by it. The Commission shall provide secretarial services. Other Commission officials with an interest in the proceedings may attend meetings of the group and its sub-groups.\\n6.\\xa0\\xa0\\xa0The group shall adopt its rules of procedure on the basis of the standard rules of procedure adopted by the Commission.\\n7.\\xa0\\xa0\\xa0The Commission may publish, in the original language of the document concerned, any summary, conclusion, or partial conclusion or working document of the group.\\nMeeting expenses\\nThe Commission shall reimburse travel and, where appropriate, subsistence expenses for members, experts and observers in connection with the group's activities in accordance with the Commission's rules on the compensation of external experts.\\nThe members shall not be paid for the services they render.\\nMeeting expenses shall be reimbursed within the limits of the annual budget allocated to the group by the responsible Commission services.\\nApplicability\\nThe decision shall apply until 31 March 2009.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['3017', '3545', '5181', '5320', '5532'], 'source_id': 9}\n",
            "{'query': '23.2.2007 EN Official Journal of the European Union L 55/13\\nCOMMISSION REGULATION (EC) No 176/2007\\nof 22 February 2007\\nfixing the maximum export refund for white sugar in the framework of the standing invitation to tender provided for in Regulation (EC) No 958/2006\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 318/2006 of 20 February 2006 on the common organisation of the markets in the sugar sector\\xa0(1), and in particular the second subparagraph and point (b) of the third subparagraph of Article 33(2) thereof,\\nWhereas:\\n(1) Commission Regulation (EC) No 958/2006 of 28 June 2006 on a standing invitation to tender to determine refunds on exports of white sugar for the 2006/2007 marketing year\\xa0(2) requires the issuing of partial invitations to tender.\\n(2) Pursuant to Article 8(1) of Regulation (EC) No 958/2006 and following an examination of the tenders submitted in response to the partial invitation to tender ending on 22 February 2007, it is appropriate to fix a maximum export refund for that partial invitation to tender.\\n(3) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Sugar,\\nFor the partial invitation to tender ending on 22 February 2007, the maximum export refund for the product referred to in Article 1(1) of Regulation (EC) No 958/2006 shall be 28,125 EUR/100\\xa0kg.\\nThis Regulation shall enter into force on 23 February 2007.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['20', '3568', '4315'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION (EEC) No 762/80  of 28 March 1980  amending for the second time Regulation (EEC) No 1250/79 fixing coutervailing charges on seeds\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 2358/71 of 26 October 1971 on the common organization of the market in seeds (1), as last amended by Regulation (EEC) No 2878/79 (2), and in particular Article 6 (5) thereof,\\nWhereas Commission Regulation (EEC) No 1250/79 (3), as amended by Regulation (EEC) No 335/80 (4), fixed countervailing charges on seeds in respect of a certain type of hybrid maize for sowing;\\nWhereas, since that time, a significant variation has been recorded in the free-at-frontier offer prices which, under the terms of Article 4 (2) of Commission Regulation (EEC) No 1665/72 (5), requires that these charges be amended;\\nWhereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Seeds,\\nThe Annex to Regulation (EEC) No 1250/79 is replaced by the Annex to this Regulation.\\nThis Regulation shall enter into force on the third day following its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1744', '3409', '4402'], 'source_id': 9}\n",
            "{'query': '17.10.2009 EN Official Journal of the European Union L 273/1\\nCOMMISSION REGULATION (EC) No 969/2009\\nof 16 October 2009\\nestablishing the standard import values for determining the entry price of certain fruit and vegetables\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1234/2007 of 22 October 2007 establishing a common organisation of agricultural markets and on specific provisions for certain agricultural products (Single CMO Regulation)\\xa0(1),\\nHaving regard to Commission Regulation (EC) No 1580/2007 of 21 December 2007 laying down implementing rules for Council Regulations (EC) No 2200/96, (EC) No 2201/96 and (EC) No 1182/2007 in the fruit and vegetable sector\\xa0(2), and in particular Article 138(1) thereof,\\nWhereas:\\nRegulation (EC) No 1580/2007 lays down, pursuant to the outcome of the Uruguay Round multilateral trade negotiations, the criteria whereby the Commission fixes the standard values for imports from third countries, in respect of the products and periods stipulated in Annex XV, Part A thereto,\\nThe standard import values referred to in Article 138 of Regulation (EC) No 1580/2007 are fixed in the Annex hereto.\\nThis Regulation shall enter into force on 17 October 2009.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '1605', '2511', '2635', '2888', '693'], 'source_id': 9}\n",
            "{'query': '1.2.2012 EN Official Journal of the European Union L 29/36\\nCOMMISSION IMPLEMENTING REGULATION (EU) No 81/2012\\nof 31 January 2012\\nconcerning the denial of authorisation of Lactobacillus pentosus (DSM 14025) as a feed additive\\n(Text with EEA relevance)\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Regulation (EC) No 1831/2003 of the European Parliament and of the Council of 22 September 2003 on additives for use in animal nutrition\\xa0(1), and in particular Article 9(2) thereof,\\nWhereas:\\n(1) Regulation (EC) No 1831/2003 provides for the authorisation of additives for use in animal nutrition and for the grounds and procedures for granting or denying such authorisation. Article 10(7) of Regulation (EC) No 1831/2003 provides for the evaluation of substances, micro-organisms and preparations used in the Union as silage additives at the date that Regulation became applicable. Silage additives were not subject to evaluation or authorisation under previous Union legislation.\\n(2) In accordance with Article 10(1)(b) and Article 10(7) of Regulation (EC) No 1831/2003, the preparation Lactobacillus pentosus (DSM 14025) was entered in the Register of feed additives as a silage additive for all animal species.\\n(3) In accordance with Article 10(2) in conjunction with Article 7 of Regulation (EC) No 1831/2003, an application was submitted for the authorisation of Lactobacillus pentosus (DSM 14025) as a feed additive for all animal species, with the request to classify it in the category ‘technological additives’ and in the functional group ‘silage additives’. That application was accompanied by the particulars and documents required under Article 7(3) of Regulation (EC) No 1831/2003.\\n(4) The European Food Safety Authority (the Authority) concluded in its opinion of 16 November 2011\\xa0(2) that Lactobacillus pentosus (DSM 14025) is resistant to three antibiotics used in human and veterinary medicine.\\n(5) The information available does not permit the risk to be excluded that Lactobacillus pentosus (DSM 14025) may spread resistance to those antibiotics to micro-organisms. Consequently, it has not been established that Lactobacillus pentosus (DSM 14025) does not have an adverse effect on animal health, human health and the environment, when used under the proposed conditions.\\n(6) The conditions for authorisation, as provided for in Article 5 of Regulation (EC) No 1831/2003, are therefore not satisfied. Accordingly, the authorisation of Lactobacillus pentosus (DSM 14025) as a feed additive should be denied.\\n(7) Since further use of Lactobacillus pentosus (DSM 14025) as a feed additive may cause a risk to human and animal health, respective products should be withdrawn from the market as soon as possible.\\n(8) The measures provided for in this Regulation are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,\\nAuthorisation of Lactobacillus pentosus (DSM 14025) as an additive in animal nutrition is denied.\\nExisting stocks of Lactobacillus pentosus (DSM 14025) and premixtures containing it shall be withdrawn from the market as soon as possible and at the latest by 22 April 2012. Silage produced with Lactobacillus pentosus (DSM 14025) before the date of entry into force of this Regulation may be used up until stocks are exhausted.\\nThis Regulation shall enter into force on the 20th day following its publication in the Official Journal of the European Union.\\nThis Regulation is binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1224', '1442', '192', '3618', '5451', '6052'], 'source_id': 9}\n",
            "{'query': \"REGULATION (EEC) No 990/69 OF THE COMMISSION  of 28 May 1969  on the non-fixing of an additional amount for Austrian egg products\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community;\\nHaving regard to Council Regulation No 122/67/EEC (1) of 13 June 1967 on the common organisation of the market in eggs, as amended by Regulation (EEC) No 830/68, (2) and in particular Article 8 (4) thereof;\\nHaving regard to Council Regulation No 170/67/EEC (3) of 27 June on the common system of trade for ovalbumin and lactalbumin and repealing Regulation No 48/67/EEC, and in particular Article 5 (5) thereof;\\nWhereas, where the free-at-frontier offer price for a product falls below the sluice-gate price, the levy or the duty on imports of that product must be increased by an additional amount equal to the difference between the sluice-gate price and that offer price;\\nWhereas the levy is not, however, increased by this additional amount as regards third countries which are prepared and in a position to guarantee that the price for imports into the Community of products originating in and coming from their territory will not be lower than the sluice-gate price and that any deflection of trade will be avoided;\\nWhereas, by letter dated 28 May 1969, the Government of the Republic of Austria stated that it was prepared to give such guarantee for exports to the Community of products falling within sub-headings Nos 04.05 B I and 35.02 A II (a) of the Common Customs Tariff ; whereas, in order to ensure the effectiveness of the proposed measures, that guarantee is to cover all the products listed in Article 1 (1) (b) of Regulation No 122/67/EEC and in Article 1 of Regulation No 170/67/EEC;\\nWhereas the Government of the Republic of Austria will ensure that such exports are made only by the undertaking Biomerx, which is a member of the Ă\\x96sterreichischer Molkerei- und KĂ¤serei-Verband and which is under permanent State supervision ; whereas it will ensure also that the undertaking Biomerx so fixes the prices at which such exports are effected that deliveries are not made at prices lower than the sluice-gate prices fixed by the Community for those products which are valid on the day of customs clearance;\\nWhereas the Government of the Republic of Austria has, furthermore, stated that it is prepared: - to communicate to the Commission information including the nature and the physical state of the product ; the species of animal from which the product is derived, the quantities, prices, delivery dates and countries of destination within the Community;\\n- to enable the Commission to exercise continuous supervision of the effectiveness of the measures it has taken;\\nWhereas questions affecting observance of the guarantee given have been discussed in detail with representatives of the Republic of Austria ; whereas, following these discussions, it may be assumed that the Republic of Austria is in a position to abide by its guarantee;\\nWhereas, consequently, there is no need to levy an additional amount on imports of egg products and of ovalbumin and lactalbumin originating in and coming from the Republic of Austria;\\nWhereas the Management Committee for Poultrymeat and Eggs has not delivered an Opinion within the time limit set by its Chairman;  (1) OJ No 117, 19.6.1967, p. 2293/67. (2) OJ No L 151, 30.6.1968, p. 23. (3) OJ No 130, 28.6.1967, p. 2596/67.\\nThe levies fixed in accordance with Article 5 of Regulation No 122/67/EEC shall not be increased by an additional amount in respect of imports of products falling within the following heading Nos of the Common Customs Tariff, originating in and coming from the Republic of Austria:\\n04.05 Birds' eggs and egg yolks, fresh, dried or otherwise preserved, sweetened or not:\\nB. Eggs, not in shell ; egg yolks:    I. Suitable for human consumption:    (a) Eggs, not in shell:    1. Dried\\n2. Other\\n(b) Egg yolks:    1. Liquid\\n2. Frozen\\n3. Dried.\\nThe import duties fixed in accordance with Article 2 of Regulation No 170/67/EEC shall not be increased by an additional amount in respect of products falling within the following heading Nos of the Common Customs Tariff, originating in and coming from the Republic of Austria:\\n35.02 Albumins, albuminates and other albumin derivatives:\\nA. Albumins:    II. Other (than unfit, or rendered unfit, for human consumption):    (a) Ovalbumin and lactalbumin:    1. Dried (for example, in sheets, scales, flakes, powder)   2. Other\\nThis Regulation shall enter into force on the third day following its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2121', '2591', '2845', '3191', '4353', '4400'], 'source_id': 9}\n",
            "{'query': \"27.6.2013 EN Official Journal of the European Union L 175/43\\nCOMMISSION IMPLEMENTING REGULATION (EU) No 619/2013\\nof 26 June 2013\\nprohibiting fishing activities for purse seiners flying the flag of or registered in France, Greece, Italy, Malta and Spain fishing for bluefin tuna in the Atlantic Ocean, east of longitude 45°\\xa0W, and in the Mediterranean Sea\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Council Regulation (EC) No 1224/2009 of 20 November 2009 establishing a Community control system for ensuring compliance with the rules on the common fisheries policy,\\xa0(1) and in particular Article 36, paragraph 2 thereof,\\nWhereas:\\n(1) Council Regulation (EU) No 40/2013 of 21 January 2013 fixing for 2013 the fishing opportunities available in EU waters and, to EU vessels, in certain non-EU waters for certain fish stocks and groups of fish stocks which are subject to international negotiations or agreements\\xa0(2) fixes the amount of bluefin tuna which may be fished in 2013 in the Atlantic Ocean, east of longitude 45° W, and the Mediterranean Sea by European Union fishing vessels and traps.\\n(2) Council Regulation (EC) No 302/2009 of 6 April 2009 concerning a multiannual recovery plan for bluefin tuna in the Eastern Atlantic and Mediterranean, amending Regulation (EC) No 43/2009 and repealing Regulation (EC) No 1559/2007,\\xa0(3) requires Member States to inform the Commission of the individual quota allocated to their vessels over 24 metres. For catching vessels less than 24 metres and for traps, Member States need to inform the Commission at least of the quota allocated to producer organisations or groups of vessels fishing with similar gear.\\n(3) The Common Fisheries Policy is designed to ensure the long-term viability of the fisheries sector through sustainable exploitation of living aquatic resources based on the precautionary approach.\\n(4) In accordance with Article 36, paragraph 2 of Council Regulation (EC) No 1224/2009, where the Commission finds that, on the basis of information provided by Member States and of other information in its possession, fishing opportunities available to the European Union, a Member State or group of Member States are deemed to have been exhausted for one or more gears or fleets, the Commission shall inform the Member State(s) concerned thereof and shall prohibit fishing activities for the respective area, gear, stock, group of stocks or fleet involved in those specific fishing activities.\\n(5) The information in the Commission's possession indicates that the fishing opportunities for bluefin tuna in the Atlantic Ocean, east of longitude 45° W, and the Mediterranean Sea allocated to purse seiners flying the flag of or registered in France, Greece, Italy, Malta and Spain have been exhausted.\\n(6) On the 3, 5, 8 and 17 June, France informed the Commission of the fact that it had imposed a stop on the fishing activities of its 17 purse seine vessels active in the 2013 bluefin tuna fishery with effect from 3 June for 10 vessels, with effect from 5 June for four vessels, with effect from 8 June for two vessels, and with effect from 17 June for the remaining vessel resulting in the prohibition of all the activities as of 17 June 2013 at 17:22.\\n(7) On the 3 June, Greece informed the Commission of the fact that it had imposed a stop on the fishing activities of its purse seine vessel active in the 2013 bluefin tuna fishery with effect from 3 June 2013 at 8:00.\\n(8) On the 13 June, Italy informed the Commission of the fact that it had imposed a stop on the fishing activities of its 12 purse seine vessels active in the 2013 bluefin tuna fishery with effect from 5 June for four vessels, with effect from 6 June for four vessels, with effect from 9 June for three vessels, and with effect from 13 June for the remaining vessel resulting in the prohibition of all the activities as of 13 June 2013 at 15:27.\\n(9) On the 8 June, Malta informed the Commission of the fact that it had imposed a stop on the fishing activities of its purse seine vessel active in the 2013 bluefin tuna fishery with effect from 8 June 2013 at 21:56.\\n(10) On the 3 and 17 June, Spain informed the Commission of the fact that it had imposed a stop on the fishing activities of its six purse seine vessels active in the 2013 bluefin tuna fishery with effect from 3 June for five vessels and with effect from 17 June for the remaining vessel resulting in the prohibition of all the activities as of 17 June 2013 at 00:00.\\n(11) Without prejudice to the actions by France, Greece, Italy, Malta and Spain mentioned above, it is necessary that the Commission confirms the prohibition of fishing for bluefin tuna in the Atlantic Ocean, east of longitude 45° W and the Mediterranean Sea by purse seiners flying the flag of or registered in the EU Member States concerned with effect from 17 June 2013 at 17:22 at the latest for France, with effect from 3 June 2013 at 8:00 for Greece, with effect from 13 June 2013 at 15:27 at the lastest for Italy, with effect from 8 June 2013 at 21:56 for Malta and with effect from 17 June 2013 at 00:00 at the latest for Spain.\\nFishing for bluefin tuna in the Atlantic Ocean, east of longitude 45° W, and the Mediterranean Sea by purse seiners flying the flag of or registered in France shall be prohibited as from 17 June 2013 at 17:22 at the latest.\\nBluefin tuna caught by those vessels as from that date shall not be retained on board, placed in cages for fattening or farming, transhipped, transferred or landed.\\nFishing for bluefin tuna in the Atlantic Ocean, east of longitude 45° W, and the Mediterranean Sea by purse seiners flying the flag of or registered in Greece shall be prohibited as from 3 June 2013 at 08:00.\\nBluefin tuna caught by those vessels as from that date shall not be retained on board, placed in cages for fattening or farming, transhipped, transferred or landed.\\nFishing for bluefin tuna in the Atlantic Ocean, east of longitude 45° W, and the Mediterranean Sea by purse seiners flying the flag of or registered in Italy shall be prohibited as from 13 June 2013 at 15:27 at the latest.\\nBluefin tuna caught by those vessels as from that date shall not be retained on board, placed in cages for fattening or farming, transhipped, transferred or landed.\\nFishing for bluefin tuna in the Atlantic Ocean, east of longitude 45° W, and the Mediterranean Sea by purse seiners flying the flag of or registered in Malta shall be prohibited as from 8 June 2013 at 21:56.\\nBluefin tuna caught by those vessels as from that date shall not be retained on board, placed in cages for fattening or farming, transhipped, transferred or landed.\\nFishing for bluefin tuna in the Atlantic Ocean, east of longitude 45° W, and the Mediterranean Sea by purse seiners flying the flag of or registered in Spain shall be prohibited as from 17 June 2013 at 00:00 at the latest.\\nBluefin tuna caught by those vessels as from that date shall not be retained on board, placed in cages for fattening or farming, transhipped, transferred or landed.\\nThis Regulation shall enter into force on the day of its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1085', '1182', '1519', '1774', '1879', '2110', '2282', '2437', '2879', '4829', '544', '863', '997'], 'source_id': 9}\n",
            "{'query': '25.6.2013 EN Official Journal of the European Union L 172/31\\nCOUNCIL DECISION 2013/308/CFSP\\nof 24 June 2013\\namending Decision 2012/642/CFSP concerning restrictive measures against Belarus\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Treaty on European Union and in particular Article 29 thereof,\\nWhereas:\\n(1) On 15 October 2012, the Council adopted Decision 2012/642/CFSP\\xa0(1) concerning restrictive measures against Belarus.\\n(2) The Council considers that to facilitate political dialogue, the travel ban imposed on Mr. Uladzimir Uladzimiravich Makei under Article 3(1) of Decision 2012/642/CFSP should be suspended while he holds the position of Minister for Foreign Affairs of the Republic of Belarus. The suspension should be subject to the review referred to in Article 8(2) of Decision 2012/642/CFSP.\\n(3) Decision 2012/642/CFSP should therefore be amended accordingly,\\nArticle 8 of Decision 2012/642/CFSP is replaced by the following:\\n\"Article 8\\n1.\\xa0\\xa0\\xa0The measures referred to in Article 3(1), in so far as they apply to Mr. Uladzimir Uladzimiravich Makei, shall be suspended while he holds the position of Minister for Foreign Affairs of the Republic of Belarus.\\n2.\\xa0\\xa0\\xa0This Decision shall apply until 31 October 2013. It shall be kept under constant review. It may be renewed or amended, as appropriate, if the Council deems that its objectives have not been met.\"\\nThis Decision shall enter into force on the day of its publication in the Official Journal of the European Union.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['3483', '5458', '950'], 'source_id': 9}\n",
            "{'query': '21.10.2006 EN Official Journal of the European Union L 291/38\\nCOMMISSION DECISION\\nof 20 October 2006\\napproving the plan for preventive vaccination against avian influenza of subtype H5 in certain holdings in North Rhine-Westphalia submitted by Germany under Council Directive 2005/94/EC\\n(notified under document number C(2006) 4906)\\n(Only the German text is authentic)\\n(2006/705/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Directive 2005/94/EC of 20 December 2005 on Community measures for the control of avian influenza and repealing Directive 92/40/EEC\\xa0(1), and in particular, Article 57(2) thereof,\\nWhereas:\\n(1) Germany has recently experienced a high number of positive findings of highly pathogenic avian influenza A virus of subtype H5N1 in wild birds. Outbreaks of the disease have also occurred in a poultry holding and in a zoo.\\n(2) Vaccination against avian influenza of subtypes H5 and H7 may be a valuable tool for disease prevention and control. However, it has not yet been applied on poultry holdings in Germany.\\n(3) Germany wishes to gather further data on the use of vaccination by means of a large-scale field study.\\n(4) On 24 August 2006 Germany has submitted for approval a preventive vaccination plan to be carried out in three commercial holdings located in North Rhine-Westphalia in the framework of a study aimed at assessing the protective efficacy of an avian influenza vaccine of subtype H5 by applying vaccination to poultry kept under normal field conditions.\\n(5) The preventive vaccination plan submitted contains the information required by Article 56(2) of Directive 2005/94/EC and is in accordance with a Differentiating Infected from Vaccinated Animal (DIVA) strategy. In the light of an assessment of the plan and discussions with Germany it appears appropriate to approve the plan.\\n(6) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,\\nPreventive vaccination plan\\n1.\\xa0\\xa0\\xa0The plan for preventive vaccination against highly pathogenic avian influenza of subtype H5 to be applied until 30 September 2008, submitted by Germany on 24 August 2006 is approved.\\nThe preventive vaccination shall be carried out with an inactivated vaccine of avian influenza of the subtype H5N2 in three selected poultry holdings in North Rhine-Westphalia in Germany in accordance with that plan.\\n2.\\xa0\\xa0\\xa0Official surveillance accompanied by appropriate biosecurity measures, as set out in the preventive vaccination plan, shall be carried out in the poultry holdings referred to in paragraph 1.\\n3.\\xa0\\xa0\\xa0The preventive vaccination plan shall be implemented efficiently.\\n4.\\xa0\\xa0\\xa0The Commission shall publish the preventive vaccination plan.\\nMeasures restricting movements\\n1.\\xa0\\xa0\\xa0The competent authority shall ensure that:\\n(a) poultry, eggs, poultry carcasses and fresh poultry meat from poultry kept on the holdings referred to in Article 1(1) (‘poultry and other commodities’) are not moved from those holdings;\\n(b) poultry and other captive birds are not introduced into the holdings referred to in Article 1(1) during the implementation of the preventive vaccination plan.\\n2.\\xa0\\xa0\\xa0The competent authority may, by way of derogation from paragraph 1(a) and in accordance with the preventive vaccination plan, authorise the following movements of poultry and other commodities:\\n(a) movement to the national reference laboratory for avian influenza in Germany;\\n(b) transport for immediate disposal within Germany following the collection of appropriate samples to be dispatched to that laboratory.\\nCleansing and disinfection of holdings and means of transport\\n1.\\xa0\\xa0\\xa0The competent authority shall ensure that the poultry holdings referred to in Article 1(1) are cleansed and disinfected in accordance with the instructions of the competent authority following the removal of all poultry from the holdings.\\n2.\\xa0\\xa0\\xa0The competent authority shall ensure that all means of transport used for movements of poultry and other commodities are cleansed and disinfected following each transport with disinfectants and methods of use approved by the competent authority.\\nReports\\nGermany shall submit a report to the Commission on the implementation of the preventive vaccination plan within one month from the date of application of this Decision.\\nIt shall present quarterly reports at the Standing Committee on the Food Chain and Animal Health as from 3 October 2006.\\nAddresses\\nThis Decision is addressed to the Federal Republic of Germany.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1445', '1755', '1854', '192', '3711', '4427', '4636'], 'source_id': 9}\n",
            "{'query': 'COMMISSION DECISION  of 22 July 1980  relating to a proceeding under Article 85 of the EEC Treaty (IV/26.528 - The Distillers Co. Ltd - Victuallers)  (Only the English text is authentic)  (80/789/EEC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 85 thereof,\\nHaving regard to Regulation No 17 of 6 February 1962 (1), and in particular Articles 2 and 4 thereof,\\nHaving regard to the notification of a standard agreement by the Distillers Company Ltd made on 4 September 1967 on behalf of 41 of its subsidiaries (listed in the Annex hereto),\\nHaving regard to the publication in OJ No C 9 of 2 February 1971 and No C 65 of 15 March 1980 of the essential content of the notification as required by Article 19 (3) of Regulation No 17,\\nHaving regard to the opinion of the Advisory Committee on Restrictive Practices and Dominant Positions obtained pursuant to Article 10 (3) of Regulation No 17 on 16 July 1975 and on 20 May 1980,\\nI. The facts\\nThe facts are as follows:    1. This Decision concerns the standard agreement on the basis of which subsidiaries of The Distillers Company Ltd supply victuallers in all common market countries with Scotch whisky intended exclusively for resale for tax and duty-free consumption.\\n2. The relevant subsidiaries of the Distillers Company Ltd produce Scotch whisky which they sell under their own brands. They all have their registered offices in the United Kingdom.\\nThey have made agreements of this kind with about 500 victuallers in various common market countries.\\nWorld-wide sales by The Distillers Company Ltd group of Scotch whisky amounted to ÂŁ 497 72 million (including duties and taxes) in the financial year 1978/79. In 1978/79 its world-wide sales of Scotch whisky for tax and duty-free consumption represented 11 73 % of its total sales world-wide, and its tax and duty-free sales in the common market amounted to 2 76 % of its total sales.\\n3. Firms which receive supplies on the basis of the agreement notified are termed \"victuallers\". This word originally meant firms established in ports which supplied ships with on-board provisions of all kinds. Victuallers supply ships serving international routes with products like Scotch whisky, which, if they are consumed on board ship, are not subject to payment of duties and taxes in the normal way. As aviation developed, the term \"victualler\" was also applied to firms supplying aircraft with products to be consumed on board for tax and duty-free consumption.\\nApart from international ship and aircraft operators, victuallers also supply other customers who are entitled to consume products such as Scotch whisky free of duty and taxes, particularly embassies, armed forces outside their own country and certain international organizations. To sum up, victuallers supply the duty-free trade.\\n4. The terms on which duty-free concessions are granted are laid down by legal provisions and international conventions. The concessions are available to persons consuming the products on board a ship or aircraft serving an international route and to embassies, foreign armed forces and certain international organizations. The concessions apply to consumable products and for limited quantities only. Lastly, those eligible for the concessions are not allowed to transfer the duty-free products to other persons.\\n5. Scotch whisky supplied to the victuallers on the basis of the relevant agreement is often labelled in such a way as to indicate its duty-free destination, typical words being \"for duty-free only\".  (1)OJ No 13, 21.2.1962, p. 204/62.\\n6. For many years the subsidiaries of The Distillers Company Ltd have imposed on victuallers uniform obligations which are contained in the standard agreement notified. Under the terms of this standard agreement, the victuallers undertake:      (a) not to resell the products supplied except for the purpose of tax and duty-free consumption (in embassies or in aircraft or as ships\\' stores), and to resell them only to persons or firms which there is no reasonable cause to believe will resell or use such products otherwise than for duty-free consumption;\\n(b) to impose an obligation similar in terms to (a) above on the resale of the products supplied and to use their best endeavours to ensure that the same obligation is accepted by all subsequent purchasers of the products supplied.\\nThese agreements impose no sales restrictions other than those stated in (a) and (b).\\n7. Observations addressed to the Commission after the first publication of the essential content of the standard agreement on 2 February 1971 in the Official Journal (1), pursuant to Article 19 (3) of Regulation No 17, demonstrated that dealers selling branded whiskies to ordinary customers have in some cases been supplied by victuallers in breach of their abovementioned obligations. No further observations were made to the Commission following the second publication, on 15 March 1980 (2), the main purpose of that new publication being to enable interested third parties in the new Member States (Denmark, Ireland and the United Kingdom) to present any observations they may have had.\\nII. Applicability of Article 85 (1) of the EEC Treaty\\n8. Negative clearance may be given under Article 2 of Regulation 17 if the Commission finds that on the basis of the facts in its possession there are no grounds for action under Article 85 (1) of the Treaty in respect of the agreement notified.\\n9. Article 85 (1) prohibits all agreements between undertakings, decisions by associations of undertakings and concerted practices which may affect trade between the Member States and which have as their object or effect the prevention, restriction or distortion of competition within the common market.\\n10. The standard agreement notified is an agreement between undertakings which imposes certain obligations on victuallers as regards the resale of the whiskies supplied.\\n11. Under the agreement the victualler may supply customers only if he knows or may reasonably suppose that they will use the products concerned for the purpose of duty-free consumption. He is also obliged to impose on his customers a similar obligation on the resale of the products supplied and to obtain an undertaking that the same conditions will be imposed on any subsequent purchasers.\\n12. The effect of the agreement is to prevent victuallers in one Member State from reselling products supplied under the agreement to customers in other Member States for \"ordinary\" consumption, which is to say, to customers who sell or consume products on which duties and taxes must be paid. The wholesale and retail trades, large shops, supermarkets and the ordinary final consumer cannot obtain supplies from victuallers of products supplied under the agreement. However, these are customers who would not normally be supplied by the victualler or his customers.\\n13. The victuallers mainly supply international ship and aircraft operators, embassies, foreign armed forces and international organisations with duty-free products in quantities limited by law. These customers pass these products on to consumers who are authorized by law to consume them without paying duties and taxes. The victuallers\\' business therefore consists of selling duty-free products, such as Scotch whisky, generally identified by words such as \"for duty-free only\", that is to say supplying the very category of customer to which the agreement in question obliges them to confine themselves. The victuallers\\' business is not oriented towards trade in products for ordinary consumption or towards supplying customers whom, as a result of the obligation at issue, they cannot supply. Moreover, the Commission\\'s information is that, in practice, only in exceptional cases have victuallers supplied customers other than those entitled to make duty-free purchases and, duty having been paid, made deliveries to retailers who supply for ordinary consumption.  (1)OJ No C 9, 2.2.1971, p. 3. (2)OJ No C 65, 15.3.1980, p. 4.\\n14. Lastly, if the victuallers wish to set up in business for ordinary consumption and supply other sellers or final consumers, they are free to ask the producer, wholesalers or sole distributors to supply them with products for ordinary consumption, that is to say products not bearing special labels and on which tax and duty has been paid.\\n15. Consequently it may be concluded that, although in theory the standard agreement notified appears to restrict the victualler\\'s freedom to choose his customers and the terms of the sales agreements to be made with them, it does not in practice result in any real restriction on the victualler\\'s freedom of action. It follows that the obligation imposed on victuallers does not have the effect of appreciably restricting competition in the common market. Moreover, the agreement notified restricts them in no other way, for it leaves the victuallers free to sell in all countries of the common market - and indeed in the world - without restrictions ; it does not prevent them from selling other brands of Scotch whisky which are not covered by the agreement, nor does it affect their freedom to determine their resale prices.\\n16. Furthermore, the fact that the victuallers\\' successive customers are prohibited from reselling the products for ordinary consumption is likewise not such as to appreciably restrict competition. In fact, the victuallers sell only to other victuallers or to international operators of ships and aircraft, embassies, foreign armed forces and international organizations, for the account of persons who qualify for duty-free concessions. In so far as the obligation at issue relates to other victuallers, its effect is not appreciably to restrict competition, for the reasons already advanced. Moreover, the second category of customer is supplied by the victuallers only in limited quantities and provided that the products are not for ordinary consumption but for duty-free consumption. Moreover, if these customers, whose normal activity is not reselling Scotch whisky, were to sell any whisky duty-paid, they could in any case do so only very occasionally and in very limited quantities. Lastly, the current legal provisions prohibit final consumers qualifying for duty-free concessions from passing the goods on to other persons. Consequently the obligation imposed on successive customers does not have the effect of appreciably restricting competition on the common market.\\n17. Consequently, on the basis of the information at its disposal, the Commission has no cause to find that the standard agreement notified by The Distillers Company Ltd has the object or effect of preventing, restricting or distorting competition to an appreciable extent within the common market. Since this condition for the application of Article 85 (1) of the Treaty is not present, negative clearance may be granted.\\nOn the basis of the facts in its possession, the Commission has no grounds for action under Article 85 (1) of the Treaty establishing the European Economic Community in respect of the standard agreement between the subsidiaries of The Distillers Company Limited and victuallers in the common market, which agreement relates to supplies of Scotch whisky for resale for consumption free of duties and taxes.\\nThis Decision is addressed to The Distillers Company Ltd, 21 St James\\'s Square, London SW1, which shall notify it to its 41 subsidiaries listed in the Annex hereto.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['164', '2292', '5647', '601', '663', '998'], 'source_id': 9}\n",
            "{'query': \"COMMISSION DECISION of 8  September 1995 on the Community's financial contribution to a programme for the control of  organisms harmful to plants and plant products in the Azores for 1995 (Only the Portuguese text is  authentic) (95/384/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 1600/92 of 15 June 1992 introducing specific measures  in respect of certain agricultural products for the benefit of the Azores and Madeira  (1), as last  amended by the Commission Regulation (EEC) No 1974/93  (2), and in particular Article 33 (3)  thereof,\\nWhereas Commission Decision 93/522/EEC  (3) defines what measures are eligible for Community  financing as regards programmes for the control of organisms harmful to plants and plant products  in the French overseas departments, the Azores and Madeira;\\nWhereas agricultural production conditions in the Azores call for particular attention, and action  must be taken or reinforced as regards crop production, in particular the phytosanitary aspects for  this region;\\nWhereas action to be taken or reinforced on the phytosanitary side is particularly costly;\\nWhereas the programme of action has been presented to the Commission by the relevant Portuguese  authorities; whereas this programme specifies the objectives to be achieved, the measures to be  carried out, their duration and their cost so that the Community may contribute to financing them;\\nWhereas the Community's financial contribution may cover up to 75  % of eligible expenditure,  protective measures for bananas excluded;\\nWhereas the technical information provided by Portugal has enabled the Standing Committee on Plant  Health to analyse the situation accurately and comprehensively;\\nWhereas the measures provided for in this Decision are in accordance with the opinion of the  Standing Committee on Plant Health,\\nThe Community's financial contribution to the official programme for  the control of organisms harmful to plants and plant products on the Azores presented for 1995 by  the relevant Portuguese authorities is hereby approved.\\nThe official programme shall relate to the control of Popillia Japonica New on the  island of Terceira in order to avoid its spread to other parts of the Community and to  progressively tend to its total eradication on this island.\\nThe Community contribution to financing the programme is limited to 75  % maximum  expenditure on eligible measures as defined by Decision 93/522/EEC, and is set for 1995 at ECU 650   000 out of total expenditure of ECU 866  667 (VAT excluded).\\nThe schedule of programme costs and their financing is set out as Annex I to this Decision. If the  total eligible expenditure for 1995 presented by Portugal was less than the forecast amount of ECU  866  667, the Community's contribution would be reduced in proportion.\\nThe Community will reimburse up to the amount specified in the first paragraph, at the financial  rate of the ecu on 1 June 1995, i.e. ECU 1 = Esc 196,159.\\nAn advance of ECU 120  000 shall be paid to Portugal.\\nThe Community assistance shall relate to the eligible measures associated with the  operations covered by the programme set up in Portugal by provisions for which the necessary  financial resources have been committed between 1 August and 31 December 1995. The final date for  payments in connection with the operations shall be 31 July 1996, and non-compliance without  justification of delay shall entail loss of entitlement to Community financing.\\nSpecific provisions relating to the financing of the programme, provisions on  compliance with Community policies and the information to be provided by Portugal shall be set out  in Annex II.\\nPublic contracts in connection with investments covered by this Decision must be  awarded in compliance with Community law, in particular the Directives coordinating procedures for  awarding public works and supply contracts, and Articles 30, 52 and 59 of the EC Treaty.\\nThis Decision is addressed to the Portuguese Republic.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2232', '2723', '2792', '4490', '5076', '862'], 'source_id': 9}\n",
            "{'query': '19.12.2009 EN Official Journal of the European Union L 338/92\\nPOLITICAL AND SECURITY COMMITTEE DECISION EUJUST LEX/2/2009\\nof 15 December 2009\\nconcerning the appointment of the Head of Mission for the European Union Integrated Rule of Law Mission for Iraq, EUJUST LEX\\n(2009/982/CFSP)\\nTHE POLITICAL AND SECURITY COMMITTEE\\n,\\nHaving regard to the Treaty on European Union, and in particular the third paragraph of Article 38 thereof,\\nHaving regard to Council Joint Action 2009/475/CFSP of 11 June 2009 on the European Union Integrated Rule of Law Mission for Iraq, EUJUST LEX, and in particular Article 9(2) thereof,\\nWhereas:\\n(1) On 11 June 2009, the Council adopted Joint Action 2009/475/CFSP on the European Union Integrated Rule of Law Mission for Iraq, EUJUST LEX. That Joint Action expires on 30 June 2010.\\n(2) Article 9(2) of Joint Action 2009/475/CFSP authorises the Political and Security Committee to take decisions regarding the appointment of the Head of Mission.\\n(3) The High Representative of the Union for Foreign Affairs and Security Policy has proposed that Mr Francisco DÍAZ ALCANTUD be appointed as Head of Mission of EUJUST LEX until 30 June 2010.\\nMr Francisco DÍAZ ALCANTUD is hereby appointed as Head of Mission of the European Union Integrated Rule of Law Mission for Iraq, EUJUST LEX, for the period from 1 January 2010 until 30 June 2010.\\nThis Decision shall be notified to Mr Francisco DÍAZ ALCANTUD.\\nIt shall take effect on the day of its notification.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1500', '3559', '5622', '5744', '5873'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 2017/2002\\nof 14 November 2002\\nfixing the representative prices and the additional import duties for molasses in the sugar sector\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1260/2001 of 19 June 2001 on the common organisation of the market in sugar(1), as amended by Commission Regulation (EC) No 680/2002(2),\\nHaving regard to Commission Regulation (EC) No 1422/95 of 23 June 1995 laying down detailed rules of application for imports of molasses in the sugar sector and amending Regulation (EEC) No 785/68(3), and in particular Article 1(2) and Article 3(1) thereof,\\nWhereas:\\n(1) Regulation (EC) No 1422/95 stipulates that the cif import price for molasses, hereinafter referred to as the \"representative price\", should be set in accordance with Commission Regulation (EEC) No 785/68(4). That price should be fixed for the standard quality defined in Article 1 of the above Regulation.\\n(2) The representative price for molasses is calculated at the frontier crossing point into the Community, in this case Amsterdam; that price must be based on the most favourable purchasing opportunities on the world market established on the basis of the quotations or prices on that market adjusted for any deviations from the standard quality. The standard quality for molasses is defined in Regulation (EEC) No 785/68.\\n(3) When the most favourable purchasing opportunities on the world market are being established, account must be taken of all available information on offers on the world market, on the prices recorded on important third-country markets and on sales concluded in international trade of which the Commission is aware, either directly or through the Member States. Under Article 7 of Regulation (EEC) No 785/68, the Commission may for this purpose take an average of several prices as a basis, provided that this average is representative of actual market trends.\\n(4) The information must be disregarded if the goods concerned are not of sound and fair marketable quality or if the price quoted in the offer relates only to a small quantity that is not representative of the market. Offer prices which can be regarded as not representative of actual market trends must also be disregarded.\\n(5) If information on molasses of the standard quality is to be comparable, prices must, depending on the quality of the molasses offered, be increased or reduced in the light of the results achieved by applying Article 6 of Regulation (EEC) No 785/68.\\n(6) A representative price may be left unchanged by way of exception for a limited period if the offer price which served as a basis for the previous calculation of the representative price is not available to the Commission and if the offer prices which are available and which appear not to be sufficiently representative of actual market trends would entail sudden and considerable changes in the representative price.\\n(7) Where there is a difference between the trigger price for the product in question and the representative price, additional import duties should be fixed under the conditions set out in Article 3 of Regulation (EC) No 1422/95. Should the import duties be suspended pursuant to Article 5 of Regulation (EC) No 1422/95, specific amounts for these duties should be fixed.\\n(8) Application of these provisions will have the effect of fixing the representative prices and the additional import duties for the products in question as set out in the Annex to this Regulation.\\n(9) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Sugar,\\nThe representative prices and the additional duties applying to imports of the products referred to in Article 1 of Regulation (EC) No 1422/95 are fixed in the Annex hereto.\\nThis Regulation shall enter into force on 15 November 2002.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1309', '1863', '2687', '4080', '4314'], 'source_id': 9}\n",
            "{'query': \"COMMISSION  DECISION\\nof 5 February 1982\\nestablishing that the equipment described as 'Matec - pulse modulator and receiver, model 6600; - R. F. plug-in, model 765 V, model 760 VRF, model 770; - automatic attenuation recorder, model 2470 A; - decade dividers and dual delay generator, model 122 B; - high resolution frequency source, model 110' may be imported free of Common Customs Tariff duties\\n(82/144/EEC)\\nTHE COMMISSION OF THE EUROPEAN\\nCOMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 1798/75 of 10 July 1975 on the importation free of Common Customs Tariff duties of educational, scientific and cultural materials (1), as amended by Regulation (EEC) No 1027/79 (2),\\nHaving regard to Commission Regulation (EEC) No 2784/79 of 12 December 1979 laying down provisions for the implementation of Regulation (EEC) No 1798/75 (3), and in particular Article 7 thereof,\\nWhereas, by letter dated 21 July 1981, the United Kingdom has requested the Commission to invoke the procedure provided for in Article 7 of Regulation (EEC) No 2784/79 in order to determine whether or not the equipment described as 'Matec - pulse modulator and receiver, model 6600; - R. F. plug-in, model 765 V, model 760 VRF, model 770; - automatic attenuation recorder, model 2470 A; - decade dividers and dual delay generator, model 122 B; - high resolution frequency source, model 110', to be used for research into atomic tunnelling in solids at low temperatures and in particular for the measurement of ultrasonic attenuation and sound velocity in the frequency range between 10 and 700 MhZ, should be considered to be a scientific equipment and, where the reply is in the affirmative, whether equipment of equivalent scientific value is currently being manufactured in the Community;\\nWhereas, in accordance with the provisions of Article 7 (5) of Regulation (EEC) No 2784/79, a group of experts composed of representatives of all the Member States met on 12 January 1982 within the framework of the Committee on Duty-Free Arrangements to examine the matter;\\nWhereas this examination showed that the equipment in question is a ultrasonic radiation system;\\nWhereas its objective technical characteristics such as the great sensitivity at the attenuation measurement and the use to which it is put make it specially suited to scientific research; whereas, moreover, equipment of the same kind is principally used for scientific activities; whereas it must therefore be considered to be scientific equipment;\\nWhereas, on the basis of information received from Member States, equipment of equivalent scientific value capable of use for the same purpose is not currently manufactured in the Community; whereas, therefore, duty-free admission of this equipment is justified,\\nThe equipment described as 'Matec - pulse modulator and receiver, model 6600; - R. F. plug-in, model 765 V, model 760 VRF, model 770; - automatic attenuation recorder, model 2470 A; - decade dividers and dual delay generator, model 122 B; - high resolution frequency source, model 110', which is the subject of an application by the United Kingdom of 21 July 1981, may be imported free of Common Customs Tariff duties.\\nThis Decision is addressed to the Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1091', '3291', '3842', '4381'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION (EC) No 1755/1999\\nof 6 August 1999\\non the sale, at prices fixed in advance, of beef held by certain intervention agencies, with a view to its processing in the Community, and repealing Regulation (EC) No 1151/1999\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 805/68 of 27 June 1968 on the common organisation of the market in beef and veal(1), as last amended by Regulation (EC) No 1633/98(2), and in particular Article 7(3) thereof,\\n(1) Whereas the introduction of intervention in beef has resulted in a build-up of stocks in several Member States; whereas, in order to prevent storage being prolonged excessively, part of these stocks should be sold for processing in the Community;\\n(2) Whereas this sale should be subject to the rules laid down in Commission Regulations (EEC) No 2173/79(3), as last amended by Regulation (EC) No 2417/95(4), (EEC) No 3002/92(5), as last amended by Regulation (EC) No 770/96(6), and (EEC) No 2182/77(7), as last amended by Regulation (EC) No 2417/95, subject to certain special exceptions on account of the particular use to which the products in question are to be put;\\n(3) Whereas, in order to ensure regular and continuous sales, Title I of Regulation (EEC) No 2173/79, in particular, should be applied;\\n(4) Whereas, to ensure economic management of stocks, the intervention agencies should give priority to selling the meat which has been stored the longest;\\n(5) Whereas provision should be made for derogations from the second subparagraph of Article 2(2) of Regulation (EEC) No 2173/79 in view of the administrative difficulties which the application of this rule is creating in certain Member States;\\n(6) Whereas, to ensure optimum monitoring of the destination of beef from intervention stocks, control measures should be taken, in addition to the measures provided for in Regulation (EEC) No 3002/92, based on physical inspection of quantities and qualities;\\n(7) Whereas Commission Regulation (EC) No 1151/1999(8), as last amended by Regulations (EC) No 1450/1999(9), should be repealed;\\n(8) Whereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Beef and Veal,\\n1. The sale shall take place, for processing in the Community, of products bought into intervention under Article 6 of Regulation (EEC) No 805/68 amounting to approximately:\\n- 200 tonnes of bone-in beef held by the Dutch intervention agency,\\n- 3500 tonnes of bone-in beef held by the German intervention agency,\\n- 480 tonnes of bone-in beef held by the Danish intervention agency,\\n- 3000 tonnes of bone-in beef held by the French intervention agency,\\n- 1500 tonnes of bone-in beef held by the Spanish intervention agency,\\n- 3000 tonnes of deboned beef held by the Irish intervention agency,\\n- 200 tonnes of deboned beef held by the French intervention agency,\\n- 8310 tonnes of deboned beef held by the United Kingdom intervention agency.\\nDetailed information concerning the products and their selling prices is given in Annex I.\\n2. Subject to the provisions of this Regulation the products referred to in paragraph 1 shall be sold in accordance with Regulations (EEC) No 2173/79, and in particular Titles I and III thereof, (EEC) No 2182/77 and (EEC) No 3002/92.\\n3. Particulars of the quantities and the places where the products are stored may be obtained by interested parties at the addresses given in Annex II hereto.\\n4. For each product listed in Annex I hereto, the intervention agencies shall sell first the meat which has been stored the longest.\\n5. Notwithstanding the second subparagraph of Article 2(2) of Regulation (EEC) No 2173/79, purchase applications shall not indicate in which store or stores the meat is held.\\n1. Purchase applications shall be valid only if presented by or on behalf of a natural or legal person who, for the 12 months prior to the entry into force of this Regulation, has been engaged in the processing of products containing beef and who is entered in a national VAT register. In addition, applications must be presented by or on behalf of a processing establishment approved in accordance with Article 8 of Council Directive 77/99/EEC(10).\\n2. Notwithstanding Article 3(1) and (2) of Regulation (EEC) No 2182/77, applications shall be accompanied by:\\n- an indication of the product covered, as referred to in either Article 3(2) or (3),\\n- a written undertaking by the purchaser to process the meat into the product as specified above within the period referred to in Article 5(1) of Regulation (EEC) No 2182/77,\\n- precise details of the establishment or establishments where the meat purchased is to be processed.\\n3. The purchasers referred to in paragraph 1 may instruct an agent in writing to take delivery, on their behalf, of the products which they purchase. In this case agents shall submit the purchase application of the purchaser whom they represent together with the written instruction referred to above.\\n4. Notwithstanding Article 18(1) of Regulation (EEC) No 2173/79, taking over must be completed within two months.\\n5. The purchasers and agents referred to in the preceding paragraphs shall maintain and keep up to date an accounting system which permits the destination and use of the products to be ascertained with a view in particular to ensuring that the quantities of products purchased and processed tally with each other.\\n1. Meat purchased in accordance with this Regulation shall be processed into products which comply with the definitions for A products and B products set out in paragraphs 2 and 3 below.\\n2. An \"A\" product means a processed product falling within CN code 1602 10 00, 1602 50 31, 1602 50 39 or 1602 50 80, not containing meat other than that of animals of the bovine species, with a collagen/protein ratio of no more than 0,45 %(11) and containing by weight at least 20 %(12) of lean meat excluding offal(13) and fat, with meat and jelly accounting for at least 85 % of the total net weight.\\nThe product must be subjected to a heat treatment sufficient to ensure the coagulation of meat proteins in the whole of the product, which may not show any traces of a pinkish liquid on the cut surface when the product is cut along a line passing through its thickest part.\\n3. A \"B\" product means a processed product containing beef, other than:\\n- one specified in Article 1(1)(a) of Regulation (EEC) No 805/68, or\\n- one referred to in paragraph 2.\\nHowever, a processed product falling within CN code 0210 20 90 which has been dried or smoked so that the colour and consistency of the fresh meat has totally disappeared and with a water/protein ratio not exceeding 3,2 shall be considered to be a B product.\\n1. Member States shall set up a system of physical and documentary supervision to ensure that all meat is processed in accordance with Articles 2 and 3.\\nThe system must include physical checks of quantity and quality at the start of the processing, during the processing and after the processing operation is completed. To this end, processors must at any time be able to demonstrate the identity and use of the meat through appropriate production records.\\nTechnical verification of the production method by the competent authority may, to the extent necessary, make allowance for drip losses and trimmings.\\nIn order to verify the quality of the finished product and establish its conformity with the processor\\'s recipe, Member States shall undertake representative sampling and analysis of the product. The costs of such operations shall be borne by the processor concerned.\\n2. Member States may, at the request of the processor, authorise the deboning of bone-in quarters in an establishment other than that provided for in respect of processing provided the relevant operations take place in the same Member State under appropriate supervision.\\n3. Article 1 of Regulation (EEC) No 2182/77 shall not apply. However, the processing of hindquarters may be undertaken after the removal of fillet and striploin.\\n1. The security provided for in Article 15(1) of Regulation (EEC) No 2173/79 shall be EUR 12 per 100 kilograms.\\n2. The security provided for in Article 4(1) of Regulation (EEC) No 2182/77 shall be per tonne:\\n- EUR 1000 for bone-in hindquarters processed into A products,\\n- EUR 900 for bone-in hindquarters processed into B products or a mixture of A and B products,\\n- EUR 700 for bone-in forequarters processed into A products,\\n- EUR 600 for bone-in forequarters processed into B products or a mixture of A and B products,\\n- EUR 1800 for deboned beef processed into A products,\\n- EUR 1700 for deboned beef processed into B products or a mixture of A and B products.\\n3. Notwithstanding Article 5(3) of Regulation (EEC) No 2182/77, the processing of all beef purchased into finished products as indicated in the purchase application shall constitute a principal requirement.\\nNotwithstanding Article 9 of Regulation (EEC) No 2182/77, in addition to the entries provided for in Regulation (EEC) No 3002/92:\\n- Section 104 of T5 control copies must be completed with one or more of the following:\\n- Para transformación [Reglamentos (CEE) n° 2182/77 y (CE) n° 1755/1999]\\n- Til forarbejdning (forordning (EØF) nr. 2182/77 og (EF) nr. 1755/1999)\\n- Zur Verarbeitung bestimmt (Verordnungen (EWG) Nr. 2182/77 und (EG) Nr. 1755/1999)\\n- Για μεταποίηση [κανονισμοί (ΕΟΚ) αριθ. 2182/77 και (ΕΚ) αριθ. 1755/1999]\\n- For processing (Regulations (EEC) No 2182/77 and (EC) No 1755/1999)\\n- Destinés à la transformation [règlements (CEE) n° 2182/77 et (CE) n° 1755/1999]\\n- Destinate alla trasformazione [regolamenti (CEE) n. 2182/77 e (CE) n. 1755/1999]\\n- Bestemd om te worden verwerkt (Verordeningen (EEG) nr. 2182/77 en (EG) nr. 1755/1999)\\n- Para transformação [Regulamentos (CEE) n.o 2182/77 e (CE) n.o 1755/1999]\\n- Jalostettavaksi (Asetukset (ETY) N:o 2182/77 ja (EY) N:o 1755/1999)\\n- För bearbetning (Förordningarna (EEG) nr 2182/77 och (EG) nr 1755/1999).\\n- Section 106 of T5 control copies must be completed with the date of conclusion of the contract of sale.\\nRegulation (EC) No 1151/1999 is hereby repealed.\\nThis Regulation shall enter into force on the third day following its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2670', '2743', '4284', '4498', '4663', '4682'], 'source_id': 9}\n",
            "{'query': 'COMMISSION DECISION of 14 July 1997 concerning the placing on the market of T102-test (Streptococcus thermophilus T102) pursuant to Council Directive 90/220/EEC (Text with EEA relevance) (97/549/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Directive 90/220/EEC of 23 April 1990 on the deliberate release into the environment of genetically modified organisms (1), as last amended by Commission Directive 97/35/EC (2), and in particular Article 13 thereof,\\nWhereas Articles 10 to 18 of Directive 90/220/EEC lay down a Community procedure enabling the competent authority of a Member State to give consent to the placing on the market of products containing, or consisting of, genetically modified organisms;\\nWhereas a notification concerning the placing on the market of such a product has been submitted to the competent authority of Finland;\\nWhereas the competent authority of Finland has subsequently forwarded the dossier thereon to the Commission with a favourable opinion;\\nWhereas the competent authority of a Member State has raised an objection to the said dossier;\\nWhereas, therefore, in accordance with Article 13 (3) of Directive 90/220/EEC, the Commission is required to take a decision in accordance with the procedure laid down in Article 21 of that Directive;\\nWhereas the Commission, having examined the objection raised in the light of the scope of Directive 90/220/EEC and the information submitted in the dossier, has reached the conclusion that there is no reason to believe that there will be any adverse effects on human health or the environment from the introduction into Streptococcus thermophilus T102 of the gene coding for chloramphenicol-acetyl-transferase on the plasmid pMJ 763;\\nWhereas Articles 11 (6) and 16 (1) of Directive 90/220/EEC provide additional safeguards if new information on risks of the product becomes available;\\nWhereas the measures provided for in this Decision are in accordance with the opinion of the committee established under Article 21 of Directive 90/220/EEC,\\nWithout prejudice to other Community legislation, consent shall be given by the competent authority of Finland to the placing on the market of the following product, notified by Valio Oy (ref. C/FI/96-1NA):\\nvials containing a freezedried preparation of Streptococcus thermophilus T102 which has been transformed with the plasmid pMJ 763 containing synthetic luxA, luxB genes derived from Xenorhabdus luminescens, the chloramphenicol-acetyl-transferase gene from plasmid pVS2 under the regulation of a P45 Lactococcal promotor and a transcriptional terminator from Escherichia coli rrnB.\\nThis Decision is addressed to the Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2081', '2825', '5383', '5768', '616', '87'], 'source_id': 9}\n",
            "{'query': 'Commission Regulation (EC) No 2042/2001\\nof 18 October 2001\\namending Regulation (EEC) No 2568/91 on the characteristics of olive oil and olive-residue oil and on the relevant methods of analysis and the Additional Note in Annex I to Council Regulation (EEC) No 2658/87 on the tariff and statistical nomenclature and on the Common Customs Tariff\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation No 136/66/EEC of 22 September 1966 on the establishment of a common organisation of the market in oils and fats(1), as last amended by Regulation (EC) No 1513/2001(2), and in particular Article 35(a) thereof,\\nHaving regard to Council Regulation (EEC) No 2658/87 of 23 July 1987 on the tariff and statistical nomenclature and on the Common Customs Tariff(3), as last amended by Commission Regulation (EC) No 1783/2001(4), and in particular Article 9 thereof,\\nWhereas:\\n(1) Commission Regulation (EEC) No 2568/91 of 11 July 1991 on the characteristics of olive oils and olive-residue oils and on the relevant methods of analysis(5), as last amended by Regulation (EC) No 455/2001(6), defines the physical, chemical and organoleptic characteristics of olive oils and olive-residue oils and the methods for evaluating these characteristics.\\n(2) The olive varieties and conditions under which they are harvested in Morocco may produce virgin olive oils with a linolenic acid content above the 0,9 % limit laid down in Community legislation.\\n(3) Article 1(8) of Regulation (EC) No 2568/91 and Table I in Additional Note 2 in Chapter 15 of the Combined Nomenclature contained in Annex I to Regulation (EEC) No 2658/87 provide for a maximum linolenic acid content of 1,0 % in the case of virgin oils from Morocco falling within subheadings 1509 10 10 and 1509 10 90 for the 1998/1999 to 2000/2001 marketing years.\\n(4) Pending a review of the characteristics and methods of analysis that must be conducted in order to apply the new names and definitions provided for in Regulation (EEC) No 136/66/CEE and applicable from 1 November 2003, the existing arrangements should be extended by amending Regulations (EEC) Nos 2568/91 and 2658/87.\\n(5) The Management Committee for Oils and Fats has not delivered an opinion within the time limit set by its chairman,\\nIn Article 1(8) of Regulation (EEC) No 2568/91 the words \"1998/1999 to 2000/01 marketing years\" are replaced by \"1998/1999 to 2002/03 marketing years\".\\nThe date \"31 October 2001\" in Table 1 in Additional Note 2 to Chapter 15 of the Combined Nomenclature contained in Annex I to Regulation (EEC) No 2658/87 is replaced by \"31 October 2003\".\\nThis Regulation shall enter into force on 1 November 2001.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1264', '2066', '2069', '4381', '5751'], 'source_id': 9}\n",
            "{'query': '25.3.2014 EN Official Journal of the European Union L 89/6\\nCOUNCIL DECISION\\nof 18 November 2013\\non the conclusion of a Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, on a Framework Agreement between the European Union and the Hashemite Kingdom of Jordan on the general principles for the participation of the Hashemite Kingdom of Jordan in Union programmes\\n(2014/163/EU)\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union, and in particular Article 217, in conjunction with Article 218(6)(a) and the first subparagraph of Article 218(8) thereof,\\nHaving regard to the proposal from the European Commission,\\nHaving regard to the consent of the European Parliament,\\nWhereas:\\n(1) The Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, on a Framework Agreement between the European Union and the Hashemite Kingdom of Jordan on the general principles for the participation of the Hashemite Kingdom of Jordan in Union programmes (‘the Protocol’) was signed on behalf of the Union on 19 December 2012.\\n(2) The Protocol should be approved,\\nThe Protocol to the Euro-Mediterranean Agreement establishing an Association between the European Communities and their Member States, of the one part, and the Hashemite Kingdom of Jordan, of the other part, on a Framework Agreement between the European Union and the Hashemite Kingdom of Jordan on the general principles for the participation of the Hashemite Kingdom of Jordan in Union programmes (‘the Protocol’) is hereby approved on behalf of the Union\\xa0(1).\\nThe President of the Council shall, on behalf of the Union, give the notification provided for in Article 10 of the Protocol\\xa0(2).\\nThis Decision shall enter into force on the day of its adoption.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1532', '2850', '4048', '5315', '6373', '7932'], 'source_id': 9}\n",
            "{'query': '12.2.2005 EN Official Journal of the European Union L 42/11\\nCOMMISSION REGULATION (EC) No 241/2005\\nof 11 February 2005\\namending Council Regulation (EC) No 747/2001 as regards Community tariff quotas for certain products originating in Israel\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 747/2001 of 9 April 2001 providing for the management of Community tariff quotas and of reference quantities for products eligible for preferences by virtue of agreements with certain Mediterranean countries and repealing Regulations (EC) No 1981/94 and (EC) No 934/95\\xa0(1), and in particular Article 5(1)(b) thereof,\\nWhereas:\\n(1) By its Decision of 31 January 2005\\xa0(2), the Council has given authorisation for the signing and has provided for the provisional application from 1 May 2004 of a Protocol to the Euro-Mediterranean Agreement between the European Communities and their Member States, of the one part, and the State of Israel, of the other part, to take account of the accession of the Czech Republic, the Republic of Estonia, the Republic of Cyprus, the Republic of Hungary, the Republic of Latvia, the Republic of Lithuania, the Republic of Malta, the Republic of Poland, the Republic of Slovenia, and the Slovak Republic to the European Union.\\n(2) This Protocol provides for new tariff quotas and for changes to the existing tariff quotas laid down in Regulation (EC) No 747/2001.\\n(3) To implement the new tariff quotas and the changes to the existing tariff quotas, it is necessary to amend Regulation (EC) No 747/2001.\\n(4) For the year 2004 the volumes of the new tariff quotas and the increases of the volumes of existing tariff quotas should be calculated as a pro rata of the basic volumes specified in the Protocol, taking into account the part of the period elapsed before 1 May 2004.\\n(5) In order to facilitate the management of certain existing tariff quotas provided for in Regulation (EC) No 747/2001, the quantities imported within the framework of those quotas should be taken into account for charging on the tariff quotas opened in accordance with Regulation (EC) No 747/2001, as amended by this Regulation.\\n(6) Since the Protocol to the EU-Israel Euro-Mediterranean Agreement applies on a provisional basis from 1 May 2004, this Regulation should apply from the same date and should enter into force as soon as possible.\\n(7) The measures provided for in this Regulation are in accordance with the opinion of the Customs Code Committee,\\nAnnex VII to Regulation (EC) No 747/2001 is amended as set out in the Annex to this Regulation.\\nThe quantities which, pursuant to Annex VII to Regulation (EC) No 747/2001, have been put into free circulation in the Community within the tariff quotas with order numbers 09.1303, 09.1306, 09.1310, 09.1318, 09.1329, 09.1352 and 09.1360, shall be charged against the respective tariff quotas opened pursuant to Annex VII to Regulation (EC) No 747/2001, as amended by this Regulation.\\nThis Regulation shall enter into force on the day of its publication in the Official Journal of the European Union.\\nIt shall apply from 1 May 2004.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1518', '161', '2520', '5842'], 'source_id': 9}\n",
            "{'query': \"COMMISSION  REGULATION (EEC) No 2468/82\\nof 10 September 1982\\namending Regulation (EEC) No 368/77 on the sale by tender of skimmed-milk powder for use in feed for pigs and poultry\\nTHE COMMISSION OF THE EUROPEAN\\nCOMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 804/68 of 27 June 1968 on the common organization of the market in milk and milk products (1), as last amended by Regulation (EEC) No 1183/82 (2), and in particular Article 7 (5) thereof,\\nWhereas Article 9 (2) of Commission Regulation (EEC) No 368/77 (3), as last amended by Regulation (EEC) No 1753/82 (4), states that the tenderer must indicate the price offered per tonne of product; whereas the minimum sale price fixed for the invitation to tender is expressed in ECU per 100 kilograms; whereas it is appropriate for this reason to provide that the price indicated in the tender should be expressed in the same unit;\\nWhereas point 1 in the Annex to Regulation (EEC) No 368/77 provides for different formulae for denaturing; whereas in Commission Regulation (EEC) No 1726/79 (5) formulae I A and I B were supplemented by provision for the addition of 1 000 grams of starch; whereas therefore point 3 of the Annex should be supplemented as regards the prescriptions concerning denaturing;\\nWhereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Milk and Milk Products,\\nRegulation (EEC) No 368/77 is hereby amended as follows:\\n1. Article 9 (2) (c) is replaced by the following:\\n'(c) the price offered per 100 kilograms, exclusive of internal taxes, ex store and delivered as provided in Article 15 (2), expressed in the currency of the Member State in which the tender is held;'.\\n2. The following subparagraph is added to Article 13 (1):\\n'The intervention agency may make use of telex provided that the message is accompanied by an acknowledgement of receipt.'\\n3. In point 3B of the Annex, the third subparagraph is replaced by the following:\\n'Starch and carboxymethylcellulose, referred to in formulae I A, I B, I D 1 and D 2, I E and I F, must have at least 50 % of particles less than 80 microns in size.'\\n4. In the English version of the last subparagraph of point 3B of the Annex, 'anti-skating' is replaced by 'anti-caking'.\\nThis Regulation shall enter into force on the third day following its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1277', '20', '2958', '4668'], 'source_id': 9}\n",
            "{'query': '8.12.2006 EN Official Journal of the European Union L 343/81\\nCOMMISSION REGULATION (EC) No 1813/2006\\nof 7 December 2006\\nconcerning tenders notified in response to the invitation to tender for the export of common wheat issued in Regulation (EC) No 936/2006\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1784/2003 of 29 September 2003 on the common organisation of the market in cereals\\xa0(1), and in particular Article 13(3) thereof,\\nWhereas:\\n(1) An invitation to tender for the refund for the export of common wheat to certain third countries was opened pursuant to Commission Regulation (EC) No 936/2006\\xa0(2).\\n(2) Article 7 of Commission Regulation (EC) No 1501/95 of 29 June 1995 laying down certain detailed rules for the application of Council Regulation (EEC) No 1766/92 on the granting of export refunds on cereals and the measures to be taken in the event of disturbance on the market for cereals\\xa0(3), and in particular Article 13(3) thereof,\\n(3) On the basis of the criteria laid down in Article 1 of Regulation (EC) No 1501/95, a maximum refund should not be fixed.\\n(4) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Cereals,\\nNo action shall be taken on the tenders notified from 1 to 7 December 2006 in response to the invitation to tender for the refund for the export of common wheat issued in Regulation (EC) No 936/2006.\\nThis Regulation shall enter into force on 8 December 2006.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['20', '2300', '3568', '5010'], 'source_id': 9}\n",
            "{'query': \"COMMISSION  REGULATION (EEC) No 2316/85\\nof 12 August 1985\\namending Regulation (EEC) No 1368/85 as regards the beef products which may be taken into intervention in certain Member States\\nTHE COMMISSION OF THE EUROPEAN\\nCOMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 805/68 of 27 June 1968 on the common organization of the market in beef and veal (1), as last amended by the Act of Accession of Greece, and in particular Article 6 (5) (c) thereof,\\nHaving regard to Council Regulation (EEC) No 1308/85 of 23 May 1985 fixing for the 1985/1986 marketing year the guide price and intervention price for adult bovine animals (2), and in particular Article 3 (5) thereof,\\nWhereas, by Regulation (EEC) No 869/84 (3), the Council decided, by way of an experiment, to implement for a period of three years the Community scale for the classification of carcases of adult bovine animals established under Regulation (EEC) No 1208/81 (4) in connection with intervention measures; whereas the categories and qualities of products which may be bought in by the intervention agencies must therefore be defined on the basis of the said scale;\\nWhereas, in accordance with Council Regulation (EEC) No 1302/73 (5), as last amended by Regulation (EEC) No 427/77 (6), the qualities and cuts of the products to be bought in by the intervention agencies must be determined taking into account, on the one hand, the need to give effective support to the market and to maintain the balance between the market concerned and that in competing animal products and, on the other hand, the financial burden on the Community; whereas application of these criteria in the present situation on the beef market at the start of the period for the marketing of grass feed cattle indicates that category C should be included temporarily in the list of products which may be taken into intervention in the Federal Republic of Germany in order to cope with the substantial seasonal supplies of this category of animal;\\nWhereas Commission Regulation (EEC) No 1368/85 fixing the buying-in prices for forequarters in the beef and veal sector valid with effect from 27 May 1985 and repealing Regulation (EEC) No 1177/85 (7) should therefore be amended;\\nWhereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Beef and Veal,\\nThe part 'Deutschland' in the Annex to Regulation (EEC) No 1368/85 shall be replaced by the Annex to this Regulation.\\nThis Regulation shall enter into force on 19 August 1985.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['4682', '5025', '5034', '5263'], 'source_id': 9}\n",
            "{'query': \"COUNCIL  REGULATION (EEC) No 726/90\\nof 22 March 1990\\nopening and providing for the administration of a Community tariff quota for apricot pulp originating in Turkey (1990/91)\\nTHE COUNCIL OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community, and in particular Article 113 thereof,\\nHaving regard to the proposal from the Commission,\\nWhereas the Annex to Council Regulation (EEC) No 4115/86 of 22 December 1986 on import into the Community of agricultural products in Turkey (1), provides for the opening by the Community of an annual Community tariff quota of 90 tonnes at zero duty for apricot pulp originating in Turkey; whereas such a quota has been opened for the period up to 30 June 1990 by Regulation (EEC) No 1711/89 (2); whereas the tariff quota in question should therefore be opened for the abovementioned volume for the period 1 July 1990 to 30 June 1991;\\nWhereas the Council has adopted Regulation (EEC) No 1059/88 of 28 March 1988 laying down the arrangements applicable to Greece's trade with Turkey (3); whereas the Council has also adopted Regulation (EEC) No 2573/87 of 11 August 1987 laying down the arrangements for trade between Spain and Portugal on the one hand and Algeria, Egypt, Jordan, Lebanon, Tunisia and Turkey on the other (4), as last amended by Regulation (EEC) No 4162/87 (5);\\nWhereas equal and continuous access to the quota should be ensured for all Community importers and the rates laid down for the quota should be applied consistently to all imports of the product in question into all the Member States until the quota is exhausted; whereas it is appropriate to take the necessary measures to ensure efficient Community administration of this tariff quota while offering the Member States the opportunity to draw fromn the quota volume the necessary quantities corresponding to actual imports; whereas this method of administration requires close cooperation between the Member States and the Commission, and the latter must in particular monitor the rate at which the quota volume is used up and keep the Member States informed;\\nWhereas, since the Kingdom of Belgium, the Kingdom of the Netherlands and the Grand Duchy of Luxembourg are united within and jointly represented by the Benelux Economic Union, any operation concerning the administration of the quota may be carried out by any one of its members,\\n1. From 1 July 1990 to 30 June 1991 the customs duty applicable to the following product, originating in Turkey, shall be suspended in the Community at the level and within the limit of the Commission tariff quota as shown herewith:\\n1.2.3.4.5 //  //  //  //  //  // Order No  // CN code (1)  // Description  // Amount of quota (in tonnes)   // Quota duty (%)   //    //   //   //   //   //   //   //   //   //  // 09.0203   // ex 2008 50 91   // Apricot pulp neither containing added spirit nor added sugar in immediate packings of a net content of 4,5 kg or more   // 90   // 0   //    //  //   //   //\\n(1) Taric code 2008 50 91*20\\n2. Within the framework of this tariff quota, the Kingdom of Spain and the Portuguese Republic shall apply a customs duty calculated in accordance with the relevant provisions of the Act of Accession and Regulation (EEC) No 2573/87.\\nThe tariff quota referred to in Article 1 shall be administered by the Commission, which may take any appropriate measure with a view to ensuring the efficient administration thereof.\\nIf an importer presents, in a Member State, a declaration of entry into free circulation including a request for preferential benefit for a product covered by this Regulation, and if this declaration is accepted by the customs authorities, the Member State concerned shall draw, from the tariff quota, by means of notification to the Commission, a quantity corresponding to these needs.\\nThe requests for drawing, with the indication of the date of acceptance of the said declaration, must be communicated to the Commission without delay.\\nThe drawings are granted by the Commission on the basis of the date of acceptance of the declaration of entry into free circulation by the customs authorities of the Member State concerned, to the extent that the available balance so permits.\\nIf a Member State does not use the quantities drawn, it shall return them as soon as possible to the tariff quota.\\nIf the quantities requested are greater than the available balance of the tariff quota, allocation shall be made on a pro rata basis with respect to the requests. Member States shall be informed by the Commission of the drawings made.\\nEach Member State shall ensure that importers of the product concerned have equal and continuous access to the quota for such time as the residual balance of the quota volume so permits.\\nThe Member States and the Commission shall cooperate closely to ensure that this Regulation is complied with.\\nThis Regulation shall enter into force on 1 July 1990.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1117', '161', '4580'], 'source_id': 9}\n",
            "{'query': \"COMMISSION DECISION of 20 December 1993 amending Decision 93/447/EEC authorizing the Member States to provide for derogations from certain provisions of Council Directive 77/93/EEC, in respect of growing medium originating in third countries  (94/9/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Directive 77/93/EEC of 21 December 1976 on protective measures against the introduction into the Community of organisms harmful to plants or plant products and against their spread within the Community (1), as last amended by  Commission Directive 93/110/EC (2), and in particular Article 14 (3) thereof,\\nHaving regard to the requests made by the Member States,\\nWhereas, under the provisions of Directive 77/93/EEC, soil and growing medium as such, as defined in Annex III, part A, item 14 thereof, may not in principle be introduced into the Community, because of the risk of introducing harmful soil-borne  organisms, if they originate in Turkey, Belarus, Estonia, Latvia, Lithuania, Moldova, Russia, Ukraine or third countries outside the European continent other than Cyprus, Egypt, Israel, Libya, Malta, Morocco and Tunisia;\\nWhereas by Decision 93/447/EEC (3) the Commission authorized the Member States to provide for derogations in respect of the introduction of growing medium, for the purpose of scientific work and under specified conditions;\\nWhereas the conditions justifying the authorization for growing medium should be extended to soil;\\nWhereas the measures provided for in this Decision are in accordance with the opinion of the Standing Committee on Plant Health,\\nDecision 93/447/EEC is hereby amended as follows:\\n1. The title is replaced by the following:\\n'Commission Decision 93/447/EEC of 9 July 1993 authorizing the Member States to provide for derogations from certain provisions of Council Directive 77/93/EEC, in respect of soil and growing medium originating in third countries.'\\n2. Article 1 is amended as follows:\\n(a) In paragraph 1, 'growing medium' is replaced by 'soil and growing medium'.\\n(b) In paragraph 2, indents (a), (b) and (c) are replaced by the following:\\n'(a) the nature and objectives of the scientific work for which the soil or the growing medium is to be imported shall have been examined and approved;\\n(b) the quantity of soil or growing medium shall be limited to an amount which is adequate for the approved scientific work;\\n(c) the premises and facilities of the establishment at which the scientific work is to be undertaken shall have been inspected and approved to ensure that no harmful organism imported with the soil or the growing medium can escape and'.\\n(c) In paragraph 3, indent (a) is replaced by the following:\\n'(a) the imported soil or growing medium, and any plants, plant products, soil, growing medium and other material which has been in contact with it shall be destroyed, sterilized or otherwise treated in a manner to be specified by the said official  bodies\\nand'.\\nThis Decision is addressed to the Member States.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1595', '191', '2300', '2723', '2827', '2924'], 'source_id': 9}\n",
            "{'query': '12.7.2007 EN Official Journal of the European Union L 182/34\\nCOMMISSION DECISION\\nof 11 July 2007\\ngranting exemptions to Italy under Council Directive 92/119/EEC for the transport of pigs for slaughter on public and private roads to a slaughterhouse within protection zones in Cremona\\n(notified under document number C(2007) 3314)\\n(Only the Italian text is authentic)\\n(2007/488/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Directive 92/119/EEC of 17 December 1992 introducing general Community measures for the control of certain animal diseases and specific measures relating to swine vesicular disease\\xa0(1) and in particular point 7(2)(d) of Annex II thereof,\\nWhereas:\\n(1) On 7 and 15 May 2007 protection zones were established by the competent authority in Italy around outbreaks of swine vesicular disease in the municipalities of Salvirola and Fiesco, Province of Cremona, in accordance with Article 10 of Directive 92/119/EEC. On 14 June 2007 a protection zone was established around an outbreak in the municipality of Offanengo, Province of Cremona. The protection zones are partially overlapping.\\n(2) Accordingly, the movement and transport of pigs on public and private roads within those protection zones have been prohibited.\\n(3) However, Italy has submitted two requests for an exemption from that prohibition for the transport of pigs for slaughter coming from outside those protection zones, on public and private roads within the protection zones, in order to transport them to slaughterhouses situated in the protection zones.\\n(4) It is appropriate to provide for those two exemptions, subject to the condition that Italy takes strict control and precaution measures that guarantee that there is no risk of the spread of the disease.\\n(5) Commission Decision 2007/123/EC of 20 February 2007 was adopted to grant a similar exemption for a slaughterhouse in the protection zone around an outbreak of swine vesicular disease in the municipality of Romano di Lombardia, Province of Bergamo, Italy. The measures provided for in that protection zone are no longer applied. Accordingly, Decision 2007/123/EC should be repealed.\\n(6) The measures provided for in this Decision are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health,\\nItaly may authorise the transport of pigs for slaughter coming from outside the protection zones established on 7 and 15 May 2007 around the outbreaks of swine vesicular disease that occurred in the municipalities of Salvirola and Fiesco and the protection zone established on 14 June 2007 around the outbreak that occurred in the municipality of Offanengo, (the pigs), on public and private roads within those protection zones, to slaughterhouses ‘2037 M/S’ and ‘523M’ (the slaughterhouse), subject to the conditions set out in Article 2.\\nThe conditions applying to the exemptions provided for in Article 1 are as follows:\\n(a) the dispatch of the pigs must be notified at least 24 hours in advance by the official veterinarian for the holding of origin to the official veterinarian for the slaughterhouse;\\n(b) the transport of the pigs to the slaughterhouse must be via a corridor; details of that corridor must be laid down in advance by Italy;\\n(c) vehicles carrying the pigs must be sealed by the competent authority before or on entry to the corridor; at the time of sealing, the competent authority must record the registration number of the vehicle and the number of pigs transported therein;\\n(d) on arrival at the slaughterhouse, the competent authority shall:\\n(i) inspect and remove the seal on the vehicle;\\n(ii) be present at the unloading of the pigs;\\n(iii) record the registration number of the vehicle and the number of pigs therein;\\n(e) any vehicle carrying pigs to the slaughterhouse shall undergo, immediately following unloading, cleaning and disinfection under official control and in accordance with the instructions of the competent authority, before the vehicle leaves the slaughterhouse.\\nDecision 2007/123/EC is repealed.\\nThis Decision is addressed to the Italian Republic.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1445', '1519', '1701', '1755', '192', '2560', '4152', '5581'], 'source_id': 9}\n",
            "{'query': '22.10.2009 EN Official Journal of the European Union L 277/17\\nCOMMISSION REGULATION (EC) No 986/2009\\nof 21 October 2009\\nentering a name in the register of protected designations of origin and protected geographical indications (Traditional Grimsby Smoked Fish (PGI))\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 510/2006 of 20 March 2006 on the protection of geographical indications and designations of origin for agricultural products and foodstuffs\\xa0(1), and in particular the first subparagraph of Article 7(4) thereof,\\nWhereas:\\n(1) Pursuant to the first subparagraph of Article 6(2) and to Article 17(2) of Regulation (EC) No 510/2006, the United Kingdom’s application to register the name ‘Traditional Grimsby Smoked Fish’ was published in the Official Journal of the European Union\\n\\xa0(2).\\n(2) As no statement of objection under Article 7 of Regulation (EC) No 510/2006 has been received by the Commission, that name should therefore be entered in the register,\\nThe name contained in the Annex to this Regulation is hereby entered in the register.\\nThis Regulation shall enter into force on the 20th day following its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1686', '1961', '2435', '313', '3173', '3774', '5573'], 'source_id': 9}\n",
            "{'query': '27.2.2007 EN Official Journal of the European Union L 59/69\\nCOMMISSION REGULATION (EC) No 199/2007\\nof 26 February 2007\\nfixing the corrective amount applicable to the refund on malt\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1784/2003 of 29 September 2003 on the common organization of the market in cereals\\xa0(1), and in particular Article 15(2),\\nWhereas:\\n(1) Article 14(2) of Regulation (EC) No 1784/2003 provides that the export refund applicable to cereals on the day on which application for an export licence is made must be applied on request to exports to be effected during the period of validity of the export licence. In this case, a corrective amount may be applied to the refund.\\n(2) Commission Regulation (EC) No 1501/95 of 29 June 1995 laying down certain detailed rules under Council Regulation (EEC) No 1766/92 on the granting of export refunds on cereals and the measures to be taken in the event of disturbance on the market for cereals\\xa0(2) allows for the fixing of a corrective amount for the malt referred to in Article 1(1)(c) of Regulation (EC) No 1784/2003. That corrective amount must be calculated taking account of the factors referred to in Article 1 of Regulation (EC) No 1501/95.\\n(3) It follows from applying the provisions set out above that the corrective amount must be as set out in the Annex hereto.\\n(4) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Cereals,\\nThe corrective amount referred to in Article 15(3) of Regulation (EC) No 1784/2003 which is applicable to export refunds fixed in advance in respect of malt shall be as set out in the Annex hereto.\\nThis Regulation shall enter into force on 1 March 2007.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1772', '3568'], 'source_id': 9}\n",
            "{'query': '6.7.2012 EN Official Journal of the European Union L 176/43\\nCOMMISSION REGULATION (EU) No 594/2012\\nof 5 July 2012\\namending Regulation (EC) 1881/2006 as regards the maximum levels of the contaminants ochratoxin A, non dioxin-like PCBs and melamine in foodstuffs\\n(Text with EEA relevance)\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Council Regulation (EEC) No\\xa0315/93 of 8\\xa0February 1993 laying down Community procedures for contaminants in food\\xa0(1), and in particular Article\\xa02(3) thereof,\\nWhereas:\\n(1) Commission Regulation (EC) No\\xa01881/2006\\xa0(2) sets maximum levels for certain contaminants in foodstuffs.\\n(2) Commission Regulation (EU) No 1259/2011\\xa0(3), amending Regulation (EC) No\\xa01881/2006, established new maximum levels for non dioxin-like PCBs applicable as from 1 January 2012. It is appropriate to provide that those maximum levels are not applicable to foodstuffs which were lawfully placed on the market before that date.\\n(3) Commission Regulation (EU) No 105/2010\\xa0(4), amending Regulation (EC) No\\xa01881/2006, established a final lower maximum level for Ochratoxin A in spices, which is supposed to be achievable by applying good practices. To enable the spices producing countries to put prevention measures in place and in order to avoid disruptions of trade to an unacceptable extent, that Regulation furthermore provided for a higher maximum level to be applied for a limited period of time. The Regulation furthermore provided that an assessment should be performed of the achievability of the lower levels for ochratoxin A by applying good practices in the different producing regions in the world. This assessment had to be done before the lower maximum level of Ochratoxin A would become applicable. Although a significant improvement in the application of good practices in the different producing regions in the world has been noticed, the projected lower maximum level for Ochratoxin A is not yet achieavable in Capsicum species on a consistent basis. It is therefore appropriate to postpone the application of the lower maximum level for Capsicum spp.\\n(4) Wheat gluten is produced as a co-product of the starch production. Evidence has been provided that the current maximum level of Ochratoxin A in wheat gluten is no longer achievable, in particular at the end of the storage season, even with the strict application of good practices as regards storage, possibly due to the changing climate conditions. It is therefore appropriate to modify the current maximum level to a level which is achievable by applying good practices and which still provides a high level of human health protection.\\n(5) The Scientific Panel on Contaminants in the Food Chain of the European Food Safety Authority (EFSA) has, on a request from the Commission, adopted on 4 April 2006 an updated scientific opinion relating to ochratoxin A in food\\xa0(5), taking into account new scientific information and derived a tolerable weekly intake (TWI) of 120 ng/kg b.w. In accordance with the conclusions of the opinion adopted by EFSA, the envisaged changes as regards Ochratoxin A in this Regulation continue to provide a high level of human health protection.\\n(6) The EFSA has, on a request from the Commission, on 18 March 2010, adopted a scientific opinion related to the melamine in feed and food\\xa0(6). Its findings show that exposure to melamine can result in the formation of crystals in the urinary tract. Those crystals cause proximal tubular damage and have been observed in animals and children as a result of incidents involving adulteration of feed and infant formula with melamine, leading to fatalities in some instances. The Codex Alimentarius Commission has established maximum levels for melamine in feed and food\\xa0(7). It is appropriate to include those maximum levels in Regulation (EC) No 1881/2006 to protect public health as those levels are in accordance with the conclusions of the EFSA\\'s opinion.\\n(7) Therefore, Regulation (EC) No 1881/2006 should be amended accordingly.\\n(8) The measures provided for in this Regulation are in accordance with the opinion of the Standing Committee on the Food Chain and Animal Health and neither the European Parliament nor the Council have opposed them,\\nAmending provisions\\nRegulation (EC) No 1881/2006 is amended as follows:\\n(1) In Article 11, the first paragraph is amended as follows:\\n(a) the introductory sentence is replaced by the following:\\n(b) the following points (e) and (f) are added:\\n\"(e) 01 January 2012 as regards the maximum levels for non dioxin-like PCBs laid down in section 5 of the Annex;\\n(f) 01 January 2015 as regards the maximum level for Ochratoxin A in Capsicum spp. laid down in point 2.2.11. of the Annex.\"\\n(2) The Annex is amended in accordance with the Annex to this Regulation.\\nEntry into force\\nThis Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union.\\nIt shall apply from the date of entry into force with the exception of the provisions laid down in point 2.2.11 of the Annex which shall apply from 1 July 2012.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['192', '2531', '2735', '3135', '6569'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION 3809/90\\nof 19 December  1990\\nlaying down general rules for stocks of maize in Portugal on 1 January 1991\\nTHE COMMISSION OF THE EUROPEAN\\nCOMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) 3653/90 of on transitional measures on the common  organization of the markets in cereals and rice in Portugal  (1), and in particular Article 10  thereof,\\nWhereas, from 1 January 1991, the market price for maize in Portugal will be aligned to the market  price of this cereal in the Community; whereas the latter price may be considerably lower than that  applicable in Portugal under the national organization of the market during the first stage of  accession; whereas, in order to ensure a harmonious transition from the national scheme to the  Community scheme, provision should be made for compensation of the fall in price of the quantities  of maize originating from the national harvest still in stock on 1 January 1991;\\nWhereas the level of this compensation must reflect the difference between the market price in the  most representative Portuguese regions for marketing maize and the Portuguese guide price;\\nWhereas the proper functioning of the scheme makes it necessary for Portugal to carry out  administrative checks, ensuring that aid is granted in accordance with the prescribed conditions;  whereas aid applications must include a minimum amount of information for the purposes of the  checks to be carried out by Portugal;\\nWhereas, in the interests of efficiency, provision should be made for random on-the-spot checks of  the accuracy of applications submitted; whereas these checks must be made on a sufficiently  representative number of aid applications;\\nWhereas provision should be made for the recovery of aid in cases of undue payment as well as  appropriate penalties for false declarations;\\nWhereas the Management Committee for Cereals has not issued an opinion within the time limit set  by its chairman,\\nAid may be granted to traders and  industrial processors located in Portugal for stocks of maize harvested in Portugal and belonging  to them on 1 January 1991.\\nThe minimum required quantity on 1 January 1991 enabling  stocks to qualify for the aid referred to in Article 1 shall be 20 tonnes.\\n1.    To  qualify for the aid referred to in Article 1, applicants must have lodged an application with INGA  by registered mail or by any other form of written telecommunication by 7 January 1991 at the  latest.\\n2.    Applications must include the following information at least:\\n-  name and address of applicant,\\n-quantity,\\n-place of storage,\\n-a declaration certifying that the maize was harvested in Portugal,\\n-a undertaking by the applicant to submit to any checks made to verify the accuracy of the  application.\\n1.    The Portuguese authorities shall institute an administrative control  scheme ensuring that the conditions for the grant of aid are satisfied. They shall make on-the-spot  checks on the accuracy of all applications presented.\\n2.    A report must be made out on each on-the-spot check.\\nFor the purposes of  entitlement to the aid the operative event as referred to in Article 6 of Council Regulation (EEC)  No 1676/85  (2) shall be deemed to have occurred on 1 January 1991.\\n1.    If control reveals a discrepancy in aid applications of up to 10  % or 10  tonnes at a maximum between the quantity applied for and that measured, the aid shall be calculated  on the basis of the quantity measured less the excess found.\\n2.    If the said excess is greater than the limits laid down in paragraph 1, the application  shall be rejected.\\n3.    In the event of undue payment of aid, the amount concerned shall be recovered plus interest  of 15  % calculated on the basis of the time elapsing between payment of the aid and its  reimbursement by the beneficiary. Amounts recovered shall be paid to the disbursing agency and  shall be deducted from the expenditure financed by the Guarantee Section of the EAGGF.\\nThe aid indicated in Article 1 shall, if it is required, be fixed using the procedure  set out in Article 26 of Council Regulation (EEC) No 2727/75  (1).\\nIt shall amount to the difference between the guide price applicable for maize in Portugal on 31  December 1990 and the market price recorded in Portugal in the most representative regions for the  marketing of maize. It may not however exceed the difference between the abovementioned guide price  and the intervention purchase price.\\nThis Regulation shall enter into force on the day  of its publication in the Official Journal of the European Communities.\\nIt shall apply from 1 January 1991.\\nThis Regulation shall be binding in its  entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1744', '2563', '2656', '2965', '4289', '80'], 'source_id': 9}\n",
            "{'query': '9.5.2006 EN Official Journal of the European Union L 122/3\\nCOUNCIL REGULATION (EC) No 701/2006\\nof 25 April 2006\\nlaying down detailed rules for the implementation of Regulation (EC) No 2494/95 as regards the temporal coverage of price collection in the harmonised index of consumer prices\\n(Text with EEA relevance)\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 2494/95 of 23 October 1995 concerning harmonised indices of consumer prices\\xa0(1), and in particular the third subparagraph of Article 4 and Article 5(3) thereof,\\nHaving regard to the opinion of the European Central Bank\\xa0(2), as required under Article 5(3) of Regulation (EC) No 2494/95,\\nWhereas:\\n(1) Harmonised indices of consumer prices (HICPs) are harmonised inflation figures required by the Commission and the European Central Bank for the performance of their functions under Article 121 of the Treaty. HICPs are designed to facilitate international comparisons of consumer price inflation. They serve as important indicators for the management of monetary policy.\\n(2) Pursuant to Article 5(1)(b) of Regulation (EC) No 2494/95, each Member State is required, as part of the implementation of that Regulation, to produce an HICP starting with the index for January 1997.\\n(3) Article 3 of Regulation (EC) No 2494/95 requires that the HICP should be based on the prices of goods and services available for purchase in the economic territory of the Member State for the purposes of directly satisfying consumer needs.\\n(4) Commission Regulation (EC) No 1749/96 of 9 September 1996 on initial implementing measures for Council Regulation (EC) No 2494/95 concerning harmonised indices of consumer prices\\xa0(3) defined the coverage of the HICP as those goods and services which are included in household final monetary consumption expenditure which is incurred, inter alia, on the economic territory of the Member State in one or both of the time periods being compared.\\n(5) Article 8 of Regulation (EC) No 1749/96 requires the HICP to be constructed from target samples which have sufficient prices within each elementary aggregate to take account of the variation of price movements in the population.\\n(6) Differences in price collection periods may lead to significant differences in the estimated price change for the time periods being compared.\\n(7) A harmonised approach with respect to the temporal coverage of the HICPs is necessary in order to ensure that the resulting HICPs meet the requirements as to comparability, reliability, and relevance according to the third subparagraph of Article 4 and pursuant to Article 5(3) of Regulation (EC) No 2494/95.\\n(8) The compilation of the Monetary Union index of consumer prices (MUICP) and the European index of consumer prices (EICP) requires a harmonised concept for the temporal coverage of the HICPs. This should not, however, preclude the release of provisional HICPs or HICP flash estimates of the average price change based on a part of the price information observed in the month to which the current index refers.\\n(9) Commission Regulation (EC) No 1921/2001 of 28 September 2001 laying down detailed rules for the implementation of Council Regulation (EC) No 2494/95 as regards minimum standards for revisions of the harmonised index of consumer prices and amending Regulation (EC) No 2602/2000\\xa0(4) stipulates that changes in the system of harmonised rules should not require revisions, but that, where necessary, estimates of the impact on the annual rates of change of the HICP should be made.\\n(10) The Statistical Programme Committee has been consulted in accordance with Article 3 of Council Decision 89/382/EEC, Euratom of 19 June 1989 establishing a Committee on the Statistical Programmes of the European Communities\\xa0(5),\\nAim\\nThe aim of this Regulation is to establish minimum standards for price collection periods in order to improve the comparability, reliability and relevance of HICPs.\\nRepresentation\\nThe HICP is a sample statistic which shall represent the average change in prices between the calendar month of the current index and the period to which it is compared.\\nMinimum standards for price collection\\n1.\\xa0\\xa0\\xa0Price collection shall take place across at least a one working week period at, or near, the middle of the calendar month to which the index pertains.\\n2.\\xa0\\xa0\\xa0Where products are known to typically show sharp and irregular price changes within the same month, price collection shall take place over a period of more than one working week.\\nThis rule shall apply in particular to the following products:\\n(a) energy products; and\\n(b) fresh food, such as fruit and vegetables.\\nImplementation\\nThe provisions of this Regulation shall be implemented in December 2007 at the latest and take effect with the index for January 2008.\\nEntry into force\\nThis Regulation shall enter into force on the 20th day following its publication in the Official Journal of the European Union.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1354', '2636', '5155', '6030'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION (EEC) No 1861/93 of 12 July 1993 amending Regulation (EEC) No 2167/83 laying down detailed rules for the supply of milk and certain milk products to schoolchildren\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to Council Regulation (EEC) No 804/68 of 27 June 1968 on the common organization of the market in milk and milk products (1), as last amended by Regulation (EEC) No 2071/92 (2), and in particular Article 26 (4) thereof,\\nWhereas Article 1 (3) of Council Regulation (EEC) No 1842/83 of 30 June 1983 laying down general rules for the supply of milk and certain milk products at reduced prices to schoolchildren (3), as last amended by Regulation (EEC) No 222/88 (4), provides  that the Community aid is to be established in line with the target price for milk applicable for the milk year concerned;\\nWhereas, following the change in the target price for the 1993/94 milk year, the aid provided for in Article 4 (1) of Commission Regulation (EEC) No 2167/83 (5), as last amended by Regulation (EEC) No 706/92 (6), should be adapted;\\nWhereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Milk and Milk Products,\\nArticle 4 (1) (a), (b) and (c) of Regulation (EEC) No 2167/83 is hereby replaced by the following:\\n\\'(a) ECU 32,57 per 100 kilograms for category I \"whole milk\" products;\\n(b) ECU 20,56 per 100 kilograms for category II \"semi-skimmed milk\" products;\\n(c) ECU 10,20 per 100 kilograms for category III \"buttermilk\" products;\\'.\\nThis Regulation shall enter into force on the day of its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1565', '1684', '2763', '862', '873'], 'source_id': 9}\n",
            "{'query': 'COMMISSION REGULATION (EC) No 2570/97 of 19 December 1997 concerning the stopping of fishing for mackerel by vessels flying the flag of Denmark\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 2847/93 of 12 October 1993 establishing a control system applicable to the common fisheries policy (1), as last amended by Regulation (EC) No 2205/97 (2), and in particular Article 21 (3) thereof,\\nWhereas Council Regulation (EC) No 392/97 of 20 December 1996 allocating, for 1997, certain catch quotas between Member States for vessels fishing in the Norwegian exclusive economic zone and the fishing zone around Jan Mayen (3), provides for mackerel quotas for 1997;\\nWhereas, in order to ensure compliance with the provisions relating to the quantitative limitations on catches of stocks subject to quotas, it is necessary for the Commission to fix the date by which catches made by vessels flying the flag of a Member State are deemed to have exhausted the quota allocated;\\nWhereas, according to the information communicated to the Commission, catches of mackerel in the waters of ICES division IIa (Norwegian waters north of 62 °N) by vessels flying the flag of Denmark or registered in Denmark have reached the quota allocated for 1997; whereas Denmark has prohibited fishing for this stock as from 23 November 1997; whereas it is therefore necessary to abide by that date,\\nCatches of mackerel in the waters of ICES division IIa (Norwegian waters north of 62 °N) by vessels flying the flag of Denmark or registered in Denmark are deemed to have exhausted the quota allocated to Denmark for 1997.\\nFishing for mackerel in the waters of ICES division IIa (Norwegian waters north of 62 °N) by vessels flying the flag of Denmark or registered in Denmark is prohibited, as well as the retention on board, the transhipment and the landing of such stock captured by the abovementioned vessels after the date of application of this Regulation.\\nThis Regulation shall enter into force on the day following its publication in the Official Journal of the European Communities.\\nIt shall apply with effect from 23 November 1997.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1159', '2282', '2437', '2879', '336', '544'], 'source_id': 9}\n",
            "{'query': '19.5.2005 EN Official Journal of the European Union L 126/32\\nCOMMISSION REGULATION (EC) No 754/2005\\nof 18 May 2005\\nfixing the export refunds on eggs applicable from 19 May 2005\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EEC) No 2771/75 of 29 October 1975 on the common organisation of the market in eggs\\xa0(1), and in particular the third subparagraph of Article 8(3) thereof,\\nWhereas:\\n(1) Article 8 of Regulation (EEC) No 2771/75 provides that the difference between prices on the world market for the products listed in Article 1(1) of that regulation and prices for those products on the Community market may be covered by an export refund.\\n(2) It follows from applying these rules and criteria to the present situation on the market in eggs that the refund should be fixed at an amount which would permit Community participation in world trade and would also take account of the nature of these exports and their importance at the present time.\\n(3) The present market situation in certain third countries and that regarding competition makes it necessary to fix a refund differentiated by destination for certain products in the egg sector.\\n(4) Article 21 of Commission Regulation (EC) No 800/1999 of 15 April 1999 laying down detailed rules for the application of the system of export refunds on agricultural products\\xa0(2), stipulates that no refund is granted if the products are not of sound and fair marketable quality on the date on which the export declaration is accepted. In order to ensure uniform application of the rules in force, it should be stated that, in order to qualify for the refund, the egg products listed in Article 1 of Regulation (EEC) No 2771/75 must bear the health mark laid down in Council Directive 89/437/EEC of 20 June 1989 on hygiene and health problems affecting the production and the placing on the market of egg products\\xa0(3).\\n(5) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Poultrymeat and Eggs,\\nThe codes of products for which, when they are exported, the export refund referred to in Article 8 of Regulation (EEC) No 2771/75 is granted and the amount of that refund shall be as shown in the Annex hereto.\\nHowever, in order to qualify for the refund, products falling within the scope of Chapter XI of the Annex to Directive 89/437/EEC must also satisfy the health marking conditions laid down in that Directive.\\nThis Regulation shall enter into force on 19 May 2005.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2121', '2212', '3568'], 'source_id': 9}\n",
            "{'query': \"19.7.2014 EN Official Journal of the European Union L 214/29\\nCOMMISSION IMPLEMENTING DECISION\\nof 17 July 2014\\nauthorising methods for grading pig carcases in Sweden and repealing Decision 97/370/EC\\n(notified under document C(2014) 4946)\\n(Only the Swedish text is authentic)\\n(2014/476/EU)\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Regulation (EU) No 1308/2013 of the European Parliament and of the Council of 17 December 2013 establishing a common organisation of the markets in agricultural products and repealing Council Regulations (EEC) No\\xa0922/72, (EEC) No 234/79, (EC) No 1037/2001 and (EC) No 1234/2007\\xa0(1), and in particular Article 20 (p) thereof,\\nWhereas:\\n(1) Point 1 of Section B.IV of Annex IV to Regulation (EU) No 1308/2013 provides that, for the classification of pig carcasses, the lean-meat content has to be assessed by means of grading methods authorised by the Commission, and only statistically proven assessment methods based on the physical measurement of one or more anatomical parts of the pig carcass may be authorised. The authorisation of grading methods should be subject to compliance with a maximum tolerance for statistical error in assessment. That tolerance is defined in Article 23(3) of Commission Regulation (EC) No 1249/2008\\xa0(2).\\n(2) By Commission Decision 97/370/EC\\xa0(3), the use of three methods for grading pig carcasses in Sweden was authorised.\\n(3) As the authorised grading methods need technical adaptation, Sweden has requested the Commission to authorise the replacement of the formula used in the ‘Intra-scope (Optical Probe)’, ‘Hennessy Grading Probe (HGP II)’ and AutoFom methods, as well as to authorise two new methods ‘Fat-O-Meat'er II (FOM II)’ and ‘Hennessy Grading Probe 7 (HGP 7)’ for grading pig carcasses on its territory. Sweden has presented a detailed description of the dissection trial, indicating the principles on which the new formula are based, the result of its dissection trial and the equations used for assessing the percentage of lean meat in the protocol provided for in Article 23(4) of Regulation (EC) No 1249/2008.\\n(4) Examination of that request has revealed that the conditions for authorising those new formula and methods are fulfilled. Those formula and methods should therefore be authorised in Sweden.\\n(5) Modifications of the apparatuses or grading methods should not be allowed, unless they are explicitly authorised by Commission Implementing Decision.\\n(6) For reasons of clarity and legal certainty, a new decision should be adopted. Decision 97/370/EC should therefore be repealed.\\n(7) The measures provided for in this Decision are in accordance with the opinion of the Committee for the Common Organisation of the Agricultural Markets,\\nThe use of the following methods is authorised for grading pig carcasses pursuant to point 1 of Section B.IV of Annex\\xa0IV to Regulation (EU) No 1308/2013 in Sweden:\\n(a) the ‘Intra-scope (Optical Probe)’ apparatus and the assessment methods related thereto, details of which are given in Part I of the Annex;\\n(b) the ‘Hennessy Grading Probe 2 (HGP 2)’ apparatus and the assessment methods related thereto, details of which are given in Part II of the Annex;\\n(c) the ‘AutoFom III’ apparatus and the assessment methods related thereto, details of which are given in Part III of the Annex;\\n(d) the ‘Fat-O-Meat'er II (FOM II)’ apparatus and the assessment methods related thereto, details of which are given in Part IV of the Annex;\\n(e) the ‘Hennessy Grading Probe 7 (HGP 7)’ apparatus and the assessment methods related thereto, details of which are given in Part V of the Annex.\\nModifications of the authorised apparatus or grading methods shall not be allowed, unless those modifications are explicitly authorised by Commission Implementing Decision.\\nDecision 97/370/EC is repealed.\\nThis Decision shall apply from 1 July 2014.\\nThis Decision is addressed to the Kingdom of Sweden.\", 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1374', '4320', '4692', '5263', '6004', '6263'], 'source_id': 9}\n",
            "{'query': '27.4.2010 EN Official Journal of the European Union L 105/15\\nCOMMISSION REGULATION (EU) No 359/2010\\nof 26 April 2010\\nestablishing the standard import values for determining the entry price of certain fruit and vegetables\\nTHE EUROPEAN COMMISSION\\n,\\nHaving regard to the Treaty on the Functioning of the European Union,\\nHaving regard to Council Regulation (EC) No 1234/2007 of 22 October 2007 establishing a common organisation of agricultural markets and on specific provisions for certain agricultural products (Single CMO Regulation)\\xa0(1),\\nHaving regard to Commission Regulation (EC) No 1580/2007 of 21 December 2007 laying down implementing rules for Council Regulations (EC) No 2200/96, (EC) No 2201/96 and (EC) No 1182/2007 in the fruit and vegetable sector\\xa0(2), and in particular Article 138(1) thereof,\\nWhereas:\\nRegulation (EC) No 1580/2007 lays down, pursuant to the outcome of the Uruguay Round multilateral trade negotiations, the criteria whereby the Commission fixes the standard values for imports from third countries, in respect of the products and periods stipulated in Annex XV, Part A thereto,\\nThe standard import values referred to in Article 138 of Regulation (EC) No 1580/2007 are fixed in the Annex hereto.\\nThis Regulation shall enter into force on 27 April 2010.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '1605', '2511', '2635', '693'], 'source_id': 9}\n",
            "{'query': '12.11.2005 EN Official Journal of the European Union L 296/6\\nCOMMISSION REGULATION (EC) No 1846/2005\\nof 11 November 2005\\nfixing the minimum selling prices for butter for the 174th individual invitation to tender under the standing invitation to tender provided for in Regulation (EC) No 2571/97\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1255/1999 of 17 May 1999 on the common organisation of the market in milk and milk products\\xa0(1), and in particular Article 10 thereof,\\nWhereas:\\n(1) The intervention agencies are, pursuant to Commission Regulation (EC) No 2571/97 of 15 December 1997 on the sale of butter at reduced prices and the granting of aid for cream, butter and concentrated butter for use in the manufacture of pastry products, ice-cream and other foodstuffs\\xa0(2), to sell by invitation to tender certain quantities of butter from intervention stocks that they hold and to grant aid for cream, butter and concentrated butter. Article 18 of that Regulation stipulates that in the light of the tenders received in response to each individual invitation to tender a minimum selling price shall be fixed for butter and maximum aid shall be fixed for cream, butter and concentrated butter. It is further stipulated that the price or aid may vary according to the intended use of the butter, its fat content and the incorporation procedure, and that a decision may also be taken to make no award in response to the tenders submitted. The amount(s) of the processing securities must be fixed accordingly.\\n(2) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Milk and Milk Products,\\nThe minimum selling prices of butter from intervention stocks and processing securities applying for the 174th individual invitation to tender, under the standing invitation to tender provided for in Regulation (EC) No 2571/97, shall be fixed as indicated in the Annex hereto.\\nThis Regulation shall enter into force on 12 November 2005.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['20', '2644', '2681', '4860'], 'source_id': 9}\n",
            "{'query': 'COMMISSION  REGULATION (EEC) No 2343/86\\nof 25 July 1986\\nfixing for the 1986/87 marketing year the minimum price to be paid to producers for Williams pears and the amount of production aid for Williams pears in syrup\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Economic Community,\\nHaving regard to the Act of Accession of Spain and Portugal,\\nHaving regard to Council Regulation (EEC) No 426/86 of 24 February 1986 on the common organization of the market in products processed from fruit and vegetables (1), as amended by Regulation (EEC) No 1838/86 (2), and in particular Articles 4 (4) and 5 (5) thereof,\\nWhereas Council Regulation (EEC) No 1277/84 of 8 May 1984 laying down general rules for the system of production aid for processed fruit and vegetables (3) contains provisions as to the methods for determining the production aid;\\nWhereas, under Article 4 (1) of Regulation (EEC) No 426/86, the minimum price to be paid to producers is to be determined on the basis of, firstly, the minimum price applying during the previous marketing year, secondly, the movement of basic prices in the fruit and vegetable sector, and thirdly, the need to ensure the normal marketing of fresh products for the various uses;\\nWhereas the minimum price to be paid to producers in Spain and Portugal and the production aid for the products obtained are to be determined as provided for in Articles 118 and 304 of the Act of Accession; whereas the representative period for determining the minimum price is laid down in Council Regulation (EEC) No 461/86 of 25 February 1986 laying down, on account of the accession of Spain and Portugal, rules on the production aid system in respect of processed fruit and vegetables (4);\\nWhereas Article 5 of the said Regulation lays down the criteria for fixing the amount of production aid; whereas account must, in particular, be taken of the aid fixed for the previous marketing year adjusted to take account of changes in the minimum price to be paid to producers, the non-member country price and, where appropriate the pattern of processing cost assessed on a flat-rate basis;\\nWhereas the measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Products Processed from Fruit and Vegetables,\\nFor the marketing year 1986/87:\\n(a) the minimum price referred to in Article 4 of Regulation (EEC) No 426/86 to be paid to producers for Williams pears, and\\n(b) the production aid referred to in Article 5 of the same Regulation for Williams pears in syrup\\nshall be as set out in the Annex.\\nWhere processing takes place outside the Member State in which the produce was grown, such Member State shall furnish proof to the Member State paying the production aid that the minimum price payable to the producer has been paid.\\nThis Regulation shall neter into force on the day following its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['1118', '4170', '797', '870'], 'source_id': 9}\n",
            "{'query': '24.1.2009 EN Official Journal of the European Union L 21/77\\nDECISION OF THE EUROPEAN CENTRAL BANK\\nof 12 December 2008\\nlaying down the measures necessary for the contribution to the European Central Bank’s accumulated equity value and for adjusting the national central banks’ claims equivalent to the transferred foreign reserve assets\\n(ECB/2008/27)\\n(2009/57/EC)\\nTHE GOVERNING COUNCIL OF THE EUROPEAN CENTRAL BANK\\n,\\nHaving regard to the Statute of the European System of Central Banks and of the European Central Bank (hereinafter the ESCB Statute) and in particular Article 30 thereof,\\nWhereas:\\n(1) Decision ECB/2008/23 of 12 December 2008 on the national central banks’ percentage shares in the key for subscription to the European Central Bank’s capital\\xa0(1) provides for the adjustment of the key for subscription to the capital of the European Central Bank (ECB) (hereinafter capital key) in accordance with Article 29.3 of the ESCB Statute and establishes, with effect from 1 January 2009, the new weightings assigned to each national central bank (NCB) in the adjusted capital key (hereinafter the capital key weightings).\\n(2) The adjustments to the capital key weightings and the resulting changes in the NCBs’ shares in the ECB’s subscribed capital make it necessary to adjust the claims which the ECB has credited under Article 30.3 of the ESCB Statute to the NCBs of the Member States that have adopted the euro (hereinafter the participating NCBs) and which are equivalent to the participating NCBs’ contributions of foreign reserve assets to the ECB (hereinafter the claims).\\n(3) Those participating NCBs whose percentage shares in the adjusted capital key increase due to the adjustment should therefore effect a compensatory transfer to the ECB, while the ECB should effect a compensatory transfer to those participating NCBs whose percentage shares in the adjusted capital key decrease.\\n(4) In accordance with the general principles of fairness, equal treatment and the protection of legitimate expectations underlying the ESCB Statute, those participating NCBs whose relative share in the ECB’s accumulated equity value increases due to the abovementioned adjustments should also effect a compensatory transfer to those participating NCBs whose relative shares decrease.\\n(5) The respective capital key weightings of each participating NCB until 31 December 2008 and with effect from 1 January 2009 should be expressed as a percentage of the ECB’s total capital as subscribed to by all participating NCBs for the purpose of calculating the adjustment of the value of each participating NCB’s share in the ECB’s accumulated equity value.\\n(6) Accordingly, the adoption of a new ECB decision is required that repeals Decision ECB/2006/24 of 15 December 2006 laying down the measures necessary for the contribution to the European Central Bank’s accumulated equity value and for adjusting the national central banks’ claims equivalent to the transferred foreign reserve assets\\xa0(2).\\n(7) Pursuant to Article 1 of Council Decision 2008/608/EC of 8 July 2008 in accordance with Article 122(2) of the Treaty on the adoption by Slovakia of the single currency on 1 January 2009\\xa0(3), the derogation in favour of Slovakia referred to in Article 4 of the 2003 Act of Accession\\xa0(4) is abrogated with effect from 1 January 2009,\\nDefinitions\\nFor the purposes of this Decision:\\n(a) ‘accumulated equity value’ means the total of the ECB’s reserves, revaluation accounts and provisions equivalent to reserves as calculated by the ECB as at 31 December 2008. The ECB’s reserves and those provisions equivalent to reserves shall include, without limitation to the generality of the ‘accumulated equity value’, the general reserve fund and the provision equivalent to reserves for foreign exchange rate, interest rate and gold price risks;\\n(b) ‘transfer date’ means the second business day following the Governing Council’s approval of the ECB’s financial accounts for the financial year 2008.\\nContribution to the ECB’s reserves and provisions\\n1.\\xa0\\xa0\\xa0If a participating NCB’s share in the accumulated equity value increases due to the increase in its capital key weighting with effect from 1 January 2009, that participating NCB shall transfer the amount determined pursuant to paragraph 3 to the ECB on the transfer date.\\n2.\\xa0\\xa0\\xa0If a participating NCB’s share in the accumulated equity value decreases due to the decrease in its capital key weighting with effect from 1 January 2009, that participating NCB shall receive the amount determined pursuant to paragraph 3 from the ECB on the transfer date.\\n3.\\xa0\\xa0\\xa0The ECB shall, on or before the day the Governing Council approves the ECB’s financial accounts for the financial year 2008, calculate and confirm to each participating NCB either the amount to be transferred by that participating NCB to the ECB where paragraph 1 applies, or the amount which that participating NCB shall receive from the ECB where paragraph 2 applies. Subject to rounding, each amount to be transferred or received shall be calculated by multiplying the accumulated equity value by the absolute difference between each participating NCB’s capital key weighting on 31 December 2008 and its capital key weighting with effect from 1 January 2009 and dividing the result by 100.\\n4.\\xa0\\xa0\\xa0Each amount described in paragraph 3 shall be due in euro on 1 January 2009 but shall be effectively transferred on the transfer date.\\n5.\\xa0\\xa0\\xa0On the transfer date, a participating NCB or the ECB having to transfer an amount under paragraph 1 or paragraph 2 shall also separately transfer any interest accruing over the period from 1 January 2009 until the transfer date on each of the respective amounts due from such participating NCB and the ECB. The transferors and recipients of this interest shall be the same as the transferors and recipients of the amounts on which the interest accrues.\\n6.\\xa0\\xa0\\xa0If the accumulated equity value is less than zero, the amounts that have to be transferred or received under paragraph 3 and paragraph 5 shall be settled in the opposite directions to those specified in paragraph 3 and paragraph 5.\\nAdjustment of the claims equivalent to the transferred foreign reserve assets\\n1.\\xa0\\xa0\\xa0Given that the adjustment of the claims equivalent to the transferred foreign reserve assets for Národná banka Slovenska will be regulated by Decision ECB/2008/33 of 31 December 2008 on the paying-up of capital, transfer of foreign reserve assets and contributions by Národná banka Slovenska to the European Central Bank’s reserves and provisions\\xa0(5), this Article shall regulate the adjustment of the claims equivalent to the foreign reserve assets transferred by the other participating NCBs.\\n2.\\xa0\\xa0\\xa0The participating NCBs’ claims shall be adjusted with effect from 1 January 2009 in accordance with their adjusted capital key weightings. The value of the participating NCBs’ claims with effect from 1 January 2009 is shown in the third column of the table in the Annex to this Decision.\\n3.\\xa0\\xa0\\xa0Each participating NCB shall, by virtue of this provision and without any further formality or act being required, be considered to have either transferred or received on 1 January 2009 the absolute value of the claim (in euro) shown next to its name in the fourth column of the table in the Annex to this Decision, whereby ‘–’ shall refer to a claim that the participating NCB shall transfer to the ECB and ‘+’ to a claim that the ECB shall transfer to the participating NCB.\\n4.\\xa0\\xa0\\xa0On the first operating day of the Trans-European Automated Real-time Gross settlement Express Transfer system (TARGET2) following 1 January 2009, each participating NCB shall either transfer or receive the absolute value of the amount (in euro) shown next to its name in the fourth column of the table in the Annex to this Decision, whereby ‘+’ shall refer to an amount that the participating NCB shall transfer to the ECB and ‘–’ to an amount that the ECB shall transfer to the participating NCB.\\n5.\\xa0\\xa0\\xa0On the first TARGET2 operating day following 1 January 2009, the ECB and the participating NCBs that are under an obligation to transfer amounts under paragraph 4 shall also separately transfer any interest accruing over the period from 1 January 2009 until the date of this transfer on the respective amounts due from the ECB and such participating NCBs. The transferors and recipients of this interest shall be the same as the transferors and recipients of the amounts on which the interest accrues.\\nGeneral provisions\\n1.\\xa0\\xa0\\xa0The interest accruing under Article 2(5) and Article 3(5) shall be calculated on a daily basis, using the actual over-360-day method of calculation, at a rate equal to the marginal interest rate used by the Eurosystem in its most recent main refinancing operation.\\n2.\\xa0\\xa0\\xa0Each transfer pursuant to Article 2(1), (2) and (5) and Article 3(4) and (5) shall take place separately through TARGET2.\\n3.\\xa0\\xa0\\xa0The ECB and the participating NCBs that are under an obligation to effect any of the transfers referred to in paragraph 2 shall, in due course, give the necessary instructions for duly executing such transfers on time.\\nFinal provisions\\n1.\\xa0\\xa0\\xa0This Decision shall enter into force on 1 January 2009.\\n2.\\xa0\\xa0\\xa0Decision ECB/2006/24 is hereby repealed with effect from 1 January 2009.\\n3.\\xa0\\xa0\\xa0References to Decision ECB/2006/24 shall be construed as references to this Decision.', 'negatives': [], 'positives': [], 'type': 'sts_by_textlabel', 'label': ['2149', '2447', '3449', '4763', '5455', '5883'], 'source_id': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from multiprocessing import Pool\n",
        "# Download stopwords and lemmatization resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "#lemmatizer = WordNetLemmatizer()\n",
        "#stemmer = PorterStemmer()\n",
        "#stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p9YPJwhkt3h",
        "outputId": "8eddb3bd-3bfc-489d-8408-e5b9f27f4936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LabelProcesser:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pos_thres = 0.97,\n",
        "        neg_thres = 0.9,\n",
        "        min_similarity_matrix_pos =0.34,\n",
        "        max_similarity_matrix_pos = 0.30,\n",
        "        examples=None, seed=42, textname='text',labelname='label'\n",
        "    ):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this\n",
        "        #self.lemmatizer = WordNetLemmatizer()\n",
        "        #self.stemmer = PorterStemmer()\n",
        "        #self.stop_words = set(stopwords.words('english'))\n",
        "        #self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def jaccard_similarity(tokens1, tokens2):\n",
        "        set1 = set(tokens1)\n",
        "        set2 = set(tokens2)\n",
        "        intersection = set1.intersection(set2)\n",
        "        union = set1.union(set2)\n",
        "        similarity_score = len(intersection) / len(union)\n",
        "        return similarity_score\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _compute_similarity_for_processor_func(self, pair):\n",
        "        \"\"\"to be used internally with Pool map similarity functions\"\"\"\n",
        "        idx, j, tokens1, tokens2 = pair\n",
        "        return idx, j, self.jaccard_similarity(tokens1, tokens2)\n",
        "\n",
        "    def compute_similarity_matrix(self, corpus):\n",
        "        \"\"\"Csompute similarity using calculate_similarity\"\"\"\n",
        "        corpus_size = len(corpus)\n",
        "\n",
        "        # Create an empty similarity matrix\n",
        "        similarity_matrix = np.zeros((corpus_size, corpus_size))\n",
        "\n",
        "        # Generate all pairwise combinations of indices and texts\n",
        "        pairs = [(i, j, corpus[i], corpus[j]) for i in range(corpus_size) for j in range(i + 1, corpus_size)]\n",
        "\n",
        "        # Use parallel processing to compute similarities efficiently\n",
        "        with Pool() as pool:\n",
        "            results = pool.map(self._compute_similarity_for_processor_func, pairs)\n",
        "\n",
        "        # Fill in the similarity matrix\n",
        "        for i,j, similarity in results:\n",
        "            #i, j = divmod(idx, corpus_size)\n",
        "            similarity_matrix[i, j] = similarity\n",
        "            similarity_matrix[j, i] = similarity\n",
        "\n",
        "        # threshold the similarity matrx -- no, because that will creat positives in the negatives\n",
        "        return similarity_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def is_in(tuple1, tuple2):\n",
        "        \"\"\"is a in b or b in a\"\"\"\n",
        "        s1=set(tuple1); s2 = set(tuple2)\n",
        "        if not bool(s1.difference(s2)):\n",
        "            return True\n",
        "        return not bool(s2.difference(s1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _quick_text_hash(text):\n",
        "        return re.sub(\"\\W+\",\"\",text.lower())\n",
        "\n",
        "    def find_positive(\n",
        "        self,\n",
        "        query_text, # text of anchor/query (used to ensure not too similar, like an exact match)\n",
        "        query_labelstem, # processed label (often a multi-label)\n",
        "        corpus_keys, # corpus keys of other labels to find matches\n",
        "        max_candidates=15\n",
        "    ):\n",
        "        \"\"\"find positive match, based on best overlap of multi-label\"\"\"\n",
        "        # first, check if there are other text with same label\n",
        "        query_label_hash = self._quick_text_hash(query_text)\n",
        "\n",
        "        # get all text with same label\n",
        "        best_candidates_text = [\n",
        "            s for s in self.label_corpus[query_labelstem] if self._quick_text_hash(s)!=query_label_hash\n",
        "        ]\n",
        "        if len(best_candidates_text)==0:\n",
        "            # no similar text: need to find text with overlapping labelss\n",
        "            kidx = corpus_keys.index(query_labelstem)\n",
        "            # get similarities with other keys\n",
        "            k_similarities = self.SimMat[kidx]\n",
        "            if k_similarities.max()==0:\n",
        "                #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                return []\n",
        "            else:\n",
        "                idx_bests = np.argsort(-1*k_similarities)[:max_candidates]\n",
        "                # get most similar labels\n",
        "                label_candidates = [\n",
        "                    corpus_keys[j] for j in idx_bests if k_similarities[j]>= self.min_similarity_matrix\n",
        "                ]\n",
        "                # assert that the labels are AT LEAST inside of each other -- otherwise, no match\n",
        "                label_candidates = [\n",
        "                    lab for lab in label_candidates if self.is_in(lab, query_labelstem)\n",
        "                ]\n",
        "                if len(label_candidates)==0:\n",
        "                    #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                    return []\n",
        "\n",
        "                # get the text of the top candidate text\n",
        "                best_candidates_text = [subs for s in [\n",
        "                    self.label_corpus[lab] for lab in label_candidates\n",
        "                ] for subs in s][:100]\n",
        "\n",
        "                # ensure candidate texts are not the same\n",
        "                best_candidates_text = [\n",
        "                  s for s in self.label_corpus[query_labelstem] if self._quick_text_hash(s)!=query_label_hash\n",
        "                ]\n",
        "                if len(best_candidates_text)==0:\n",
        "                    #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "                    return []\n",
        "\n",
        "        # grab first candidate text htat is NOT a high jaccard similarity\n",
        "        best_candidates_text = best_candidates_text[::-1]\n",
        "        top_match = None\n",
        "        query_text_tokenized = [w for w in query_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "        while top_match is None and len(best_candidates_text)>0:\n",
        "            candidate_text = best_candidates_text.pop()\n",
        "            # check that they aren't too similar in text\n",
        "            candidate_text_tokenized = [w for w in candidate_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "            candidate_sim_score = self.jaccard_similarity(query_text_tokenized, candidate_text_tokenized)\n",
        "            if candidate_sim_score < self.pos_thres:\n",
        "                top_match = candidate_text\n",
        "                return [top_match]\n",
        "        #print(\"%s has no matches:\" % '-'.join(query_labelstem))\n",
        "        #print('Its candidate pool was:')\n",
        "        #print(best_candidates_text[:4])\n",
        "        return []\n",
        "\n",
        "    def find_positives(self, examples):\n",
        "        if True:\n",
        "            # find positives\n",
        "            for idx, example in enumerate(examples):\n",
        "                pos = self.find_positive(\n",
        "                    query_text=example[self.textname],\n",
        "                    query_labelstem=self.label2stem[tuple(example[self.labelname])],\n",
        "                    corpus_keys = list(self.label_corpus.keys()),\n",
        "                )\n",
        "                example.update({'positives':pos})\n",
        "                examples[idx] = example\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def find_negative(self, query_text, query_labelstem, corpus_keys, max_candidates=15, n_negatives=1):\n",
        "        # first, check if there are other text with same label\n",
        "        query_label_hash = self._quick_text_hash(query_text)\n",
        "        # get similarities with other keys\n",
        "        kidx = corpus_keys.index(query_labelstem)\n",
        "        k_similarities = self.SimMat[kidx]\n",
        "        if k_similarities.max()==0:\n",
        "            best_candidate_label = query_labelstem\n",
        "            while best_candidate_label == query_labelstem:\n",
        "                best_candidate_label = self.random.choice(corpus_keys)\n",
        "        else:\n",
        "            idx_bests = np.argsort(-1*k_similarities)[:max_candidates]\n",
        "            # get most similar labels\n",
        "            label_candidates = [\n",
        "                corpus_keys[j] for j in idx_bests if (k_similarities[j]!=0 and k_similarities[j] <= self.max_similarity_matrix)\n",
        "            ]\n",
        "            # assert that the labels have some disjoint labels\n",
        "            label_candidates = [\n",
        "                lab for lab in label_candidates if not self.is_in(lab, query_labelstem)\n",
        "            ] # disjoint entirely\n",
        "            # sample randomly from candidate labels\n",
        "            if len(label_candidates)>0:\n",
        "                best_candidate_label_idx = self.random.choice(np.arange(len(label_candidates)))\n",
        "                best_candidate_label = label_candidates[best_candidate_label_idx]\n",
        "            # sample randomly from entire corpus\n",
        "            elif len(label_candidates)==0:\n",
        "                # pick random\n",
        "                best_candidate_label = query_labelstem\n",
        "                while best_candidate_label == query_labelstem:\n",
        "                    best_candidate_label_idx = self.random.choice(np.arange(len(corpus_keys)))\n",
        "                    best_candidate_label = corpus_keys[best_candidate_label_idx]\n",
        "\n",
        "        # grab best text\n",
        "        best_candidates_text = self.label_corpus[best_candidate_label]\n",
        "        if len(best_candidates_text)==0:\n",
        "            return []\n",
        "\n",
        "        # ensure texts and query are not the same\n",
        "        best_candidates_text = [\n",
        "            s for s in best_candidates_text if self._quick_text_hash(s)!=query_label_hash\n",
        "        ]\n",
        "        if len(best_candidates_text)==0:\n",
        "            return []\n",
        "\n",
        "        # ensure texts are not very similar\n",
        "        top_matches = []\n",
        "        query_text_tokenized = [w for w in query_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "        while len(top_matches) < n_negatives and len(best_candidates_text)>0:\n",
        "            candidate_text = best_candidates_text.pop()\n",
        "            # check that they aren't too similar in text\n",
        "            candidate_text_tokenized = [w for w in candidate_text.split(\" \") if bool(re.search(\"\\w+\",w))]\n",
        "            candidate_sim_score = self.jaccard_similarity(query_text_tokenized, candidate_text_tokenized)\n",
        "            if candidate_sim_score < self.neg_thres:\n",
        "                top_matches.append(candidate_text)\n",
        "                if len(top_matches)==n_negatives:\n",
        "                    return top_matches\n",
        "        # no matches\n",
        "        return []\n",
        "\n",
        "    def find_negatives(self, examples, n_negatives=1):\n",
        "        if True:\n",
        "            # find negatives\n",
        "            for idx, example in enumerate(examples):\n",
        "                neg = self.find_negative(\n",
        "                    query_text=example[self.textname],\n",
        "                    query_labelstem=self.label2stem[tuple(example[self.labelname])],\n",
        "                    corpus_keys = list(self.label_corpus.keys()),\n",
        "                    n_negatives=1\n",
        "                )\n",
        "                example.update({'negatives':neg})\n",
        "                examples[idx] = example\n",
        "\n",
        "        return examples\n",
        "\n",
        "\n",
        "class LabelProcesserLedgar(LabelProcesser):\n",
        "    \"\"\"Preprocesses labels of LEDGAR for semantic similarity, as well as functionality for finding positive and negative pairs\"\"\"\n",
        "\n",
        "    def __init__(self, pos_thres = 0.97, neg_thres = 0.9, min_similarity_matrix =0.33, max_similarity_matrix_neg=0.3, examples=None, seed=42, textname='text',labelname='label'):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this, else 0\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "        #print(self.preprocess_label(\"The Borrowers’ obligation\"))\n",
        "        #print(self.preprocess_label(\"The Borrower's obligations\"))\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        if isinstance(text,str):\n",
        "            tokens = word_tokenize(text.lower())\n",
        "            # Remove stop words\n",
        "            filtered_tokens = [token for token in tokens if token not in self.stop_words]\n",
        "            # Perform lemmatization and stemming\n",
        "            processed_tokens = [self.lemmatizer.lemmatize(self.stemmer.stem(token)) for token in filtered_tokens]\n",
        "            processed_tokens = [w for w in processed_tokens if w not in [\"'\", \"’\", \"’s\", \"'s\", \"(\",\")\", \",\", \".\"]]\n",
        "            # Return the lemmatized and stop word-free tokens as a string\n",
        "            return sorted(processed_tokens)\n",
        "\n",
        "        elif isinstance(text,list):\n",
        "            if len(text)==1:\n",
        "                return self.preprocess_label(text[0])\n",
        "            all_labels = [self.preprocess_label(l) for l in text]\n",
        "            return sorted([subl for l in all_labels for subl in l])\n",
        "        else:\n",
        "            raise NotImplementedError(text)\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        label_corpus = {}\n",
        "        label2lem = {}\n",
        "        for example in list_of_dict_with_labels_and_text:\n",
        "            label = example[self.labelname]\n",
        "            s = example[self.textname]\n",
        "            if tuple(label) not in label2lem:\n",
        "                labelstemmed = tuple(self.preprocess_label(label))\n",
        "                label2lem[tuple(label)] = labelstemmed\n",
        "            else:\n",
        "                labelstemmed = label2lem[tuple(label)]\n",
        "            if labelstemmed not in label_corpus.keys():\n",
        "                label_corpus[labelstemmed] = []\n",
        "            if s not in label_corpus[labelstemmed]:\n",
        "                label_corpus[labelstemmed].append(s)\n",
        "\n",
        "        # next, calculate the similarities between all pairs of keys\n",
        "        return label_corpus, label2lem\n",
        "\n",
        "\n",
        "class DatasetTripletsSimilarityByCoLabel(DatasetTriplets):\n",
        "\n",
        "    def process(self, list_of_data):\n",
        "        \"\"\"Makes (query,pos,neg)-triplets, converts samples to dataframe for pytorch iteration\"\"\"\n",
        "\n",
        "        # initialize the LabelProcessor\n",
        "        label_processor = self.label_processor_class(\n",
        "            examples = list_of_data,\n",
        "            textname = self.focal_text_name\n",
        "        )\n",
        "\n",
        "        # find positives\n",
        "        list_of_data = label_processor.find_positives(list_of_data)\n",
        "\n",
        "        # only do ones with positives (otherwise no point)\n",
        "        #list_of_data = [example for example in list_of_data if len(example['positives'])>0]\n",
        "        #print(len(list_of_data))\n",
        "\n",
        "        # find negatives\n",
        "        list_of_data = label_processor.find_negatives(list_of_data, n_negatives=self.n_negatives)\n",
        "        print(len(list_of_data))\n",
        "\n",
        "        # loop through the data and add each triplets\n",
        "        self._loop_through_list_of_data_and_add_to_selfdata(list_of_data = list_of_data)\n",
        "\n",
        "        # harden the dataset to pandas dataframe\n",
        "        df = self.sample_data_and_make_static_dataframe(self.data)\n",
        "        return df #pd.DataFrame({})\n",
        "\n",
        "    def _build_corpus_of_potential_negatives(self):\n",
        "        pass\n",
        "\n",
        "    def _find_negative(self):\n",
        "        pass\n",
        "\n",
        "    def _find_positives_and_add_to_data(self):\n",
        "        \"\"\"For data that has a label, this can be used to artifically find and create synthetic positives\"\"\"\n",
        "        pass\n",
        "\n",
        "    def _find_negatives_and_add_to_data(self):\n",
        "       pass\n"
      ],
      "metadata": {
        "id": "6LLn5zFf0i2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sts_statics_datsets['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rw5n61iayhm",
        "outputId": "e8398d7a-5062-4042-9208-38b311ba8632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"COMMISSION DECISION of 10 February 1999 amending the Decision on the Liaison Group on the Elderly (notified under document number C(1999) 211) (1999/141/EC)\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nWhereas, in the light of developments at Community level, it is necessary to adjust the membership of the Group set up by Commission Decision 91/544/EEC (1), as amended by Decision 93/417/EEC (2); whereas at the same time, in the interests of administrative efficiency, the terms of office of the Chairman and of the Members of the Group should be reduced,\\nDecision 91/544/EEC is amended as follows:\\n1. in Article 3(2), '25 members` is replaced by '24 members`;\\n2. Article 4(3) is amended as follows:\\n(a) in each case, 'five seats` is replaced by 'four seats`;\\n(b) the following indent is added:\\n'- ESCU-European Senior Citizens Union: four seats`;\\n3. in Article 5(1), '18 months` is replaced by '12 months`;\\n4. in Article 7(1), '18 months` is replaced by '12 months`;\\n5. in the Annex, the following indent is added:\\n'- ESCU-European Senior Citizens Union`.\",\n",
              " 'negatives': [\"23.12.1994 EN Official Journal of the European Communities L 335/5\\nCOUNCIL REGULATION (ECSC, EC, EURATOM) No 3162/94\\nof 19 December 1994\\namending Regulation (EEC, Euratom, ECSC) No 260/68 laying down the conditions and procedure for applying the tax for the benefit of the European Communities\\nTHE COUNCIL OF THE EUROPEAN UNION\\n,\\nHaving regard to the Treaty establishing a Single Council and a Single Commission of the European Communities, and in particular the first paragraph of Article 28 thereof,\\nHaving regard to the Protocol on the Privileges and Immunities of the European Communities, and in particular Article 13 thereof,\\nHaving regard to the proposal from the Commission\\xa0(1),\\nHaving regard to the opinion of the European Parliament\\xa0(2),\\nWhereas it is a appropriate to extend the application of the tax for the benefit of the European Communities, on the terms and in accordance with the procedure laid down in Regulation (EEC, Euratom, ECSC) No 260/68\\xa0(3), to the salaries, wages and emoluments of the members of the organs of the European Investment Fund in the performance of their duties as such and the staff of the Fund,\\nThe following Article is hereby inserted in Regulation (EEC, Euratom, ECSC) No 260/68:\\n‘Article 12b\\nThis Regulation shall apply to the members of the organs of the European Investment Fund in the performance of their duties as such, to members of its staff and to recipients of the pensions paid by the Fund who are included in the categories determined by the Council pursuant to the first paragraph of Article 16 of the Protocol on Privileges and Immunities, with regard to salaries, wages and emoluments and to disability, retirement and survivor's pensions paid by the Fund.’\\nThis Regulation shall enter into force on the day following its publication in the Official Journal of the European Communities.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\"],\n",
              " 'positives': [],\n",
              " 'type': 'sts_by_textlabel',\n",
              " 'label': ['2333', '3324', '3346', '3751'],\n",
              " 'source_id': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelProcesserEurlex(LabelProcesser):\n",
        "    \"\"\"Preprocesses labels of EURLEX for semantic similarity, as well as functionality for finding positive and negative pairs\"\"\"\n",
        "\n",
        "    def __init__(self, pos_thres = 0.97, neg_thres = 0.9, min_similarity_matrix_pos =0.33, max_similarity_matrix_neg =0.30,  examples=None, seed=42, textname='text',labelname='label'):\n",
        "        self.pos_thres = pos_thres # jaccard similarity index max\n",
        "        self.neg_thres = neg_thres # jaccard similarity index max\n",
        "        self.min_similarity_matrix = min_similarity_matrix_pos # threshold the similarity matrix by this, else 0\n",
        "        self.max_similarity_matrix = max_similarity_matrix_neg # threshold the similarity matrix by this, else 0\n",
        "        self.random = np.random.RandomState(seed)\n",
        "        self.label_corpus =None\n",
        "        self.label2stem =None\n",
        "        self.textname=textname\n",
        "        self.labelname=labelname\n",
        "        #print(self.preprocess_label(\"The Borrowers’ obligation\"))\n",
        "        #print(self.preprocess_label(\"The Borrower's obligations\"))\n",
        "\n",
        "        if examples is not None and len(examples)>0:\n",
        "\n",
        "            # build corpus from examples\n",
        "            label_corpus, label2stem = self.build_corpus_by_labels(examples)\n",
        "            self.label_corpus = label_corpus\n",
        "            self.label2stem = label2stem\n",
        "\n",
        "            # build label-similarity matrix\n",
        "            self.SimMat = self.compute_similarity_matrix(list(self.label_corpus.keys()))\n",
        "\n",
        "    def preprocess_label(self, text):\n",
        "        # eurlex labels are already \"tokenized\" into integers of concepts\n",
        "        if isinstance(text,str):\n",
        "            return text\n",
        "        elif isinstance(text,list):\n",
        "            if len(text)==1:\n",
        "                return text\n",
        "            return sorted(list(set(text)))\n",
        "        else:\n",
        "            raise NotImplementedError(text)\n",
        "\n",
        "    def build_corpus_by_labels(self, list_of_dict_with_labels_and_text):\n",
        "        \"\"\"Makes a dictionary of (tokenized/stemmed) labels:List[str] as the corpus by labels\"\"\"\n",
        "        label_corpus = {}\n",
        "        label2lem = {}\n",
        "        for example in list_of_dict_with_labels_and_text:\n",
        "            label = example[self.labelname]\n",
        "            s = example[self.textname]\n",
        "            if tuple(label) not in label2lem:\n",
        "                labelstemmed = tuple(self.preprocess_label(label))\n",
        "                label2lem[tuple(label)] = labelstemmed\n",
        "            else:\n",
        "                labelstemmed = label2lem[tuple(label)]\n",
        "            if labelstemmed not in label_corpus.keys():\n",
        "                label_corpus[labelstemmed] = []\n",
        "            if s not in label_corpus[labelstemmed]:\n",
        "                label_corpus[labelstemmed].append(s)\n",
        "\n",
        "        # next, calculate the similarities between all pairs of keys\n",
        "        return label_corpus, label2lem"
      ],
      "metadata": {
        "id": "RhnPR4rraJV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sts_statics_datsets['train'][0]\n",
        "\n",
        "label_processer_eurlex = LabelProcesserEurlex(\n",
        "    pos_thres = 0.97,\n",
        "    neg_thres = 0.9,\n",
        "    min_similarity_matrix_pos =0.33,\n",
        "    examples=sts_statics_datsets['train'],\n",
        "    seed=42,\n",
        "    textname='query',\n",
        "    labelname='label'\n",
        ")"
      ],
      "metadata": {
        "id": "YuLbI2CLakZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sts_statics_datsets['train'] = label_processer_eurlex.find_positives(sts_statics_datsets['train'])\n",
        "\n",
        "sts_statics_datsets['train'] = label_processer_eurlex.find_negatives(sts_statics_datsets['train'], n_negatives=3)\n",
        "#print(len(list_of_data))"
      ],
      "metadata": {
        "id": "owGqWwzDW0q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foo = [e for e in sts_statics_datsets['train'] if bool(e['positives'])]"
      ],
      "metadata": {
        "id": "XWrPGhgneRiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sts_torchdataset_train_eurlex = DatasetTripletsSimilarityByCoLabel(\n",
        "    list_of_data=[\n",
        "        example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    seed = 42,\n",
        "    label_processor_class = LabelProcesserEurlex\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q9NBIBYey4K",
        "outputId": "e2ac2f95-a0e9-4dee-fcb0-2244f94bb38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sts_torchdataset_train_ledgar = DatasetTripletsSimilarityByCoLabel(\n",
        "    list_of_data=[\n",
        "        example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        "    seed = 42,\n",
        "    label_processor_class = LabelProcesserLedgar\n",
        ")"
      ],
      "metadata": {
        "id": "ZNoFf6aTUiuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73366776-5504-43dd-e67c-6912c0ec50a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-160d85949eb4>:204: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sts_torchdataset_train_eurolex[270]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z6vZNuhaWyf",
        "outputId": "e8a6ab95-ab92-4f2b-9358-d0fdbdbd2ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '15.6.2007 EN Official Journal of the European Union L 155/31\\nCOMMISSION REGULATION (EC) No 662/2007\\nof 14 June 2007\\nfixing the export refunds on white and raw sugar exported without further processing\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 318/2006 of 20\\xa0February 2006 on the common organisation of the market in the sugar sector\\xa0(1), and in particular the second subparagraph of Article 33(2) thereof,\\nWhereas:\\n(1) Article 32 of Regulation (EC) No 318/2006 provides that the difference between prices on the world market for the products listed in Article 1(1)(b) of that Regulation and prices for those products on the Community market may be covered by an export refund.\\n(2) Given the present situation on the sugar market, export refunds should therefore be fixed in accordance with the rules and certain criteria provided for in Articles 32 and 33 of Regulation (EC) No 318/2006.\\n(3) The first subparagraph of Article 33(2) of Regulation (EC) No 318/2006 provides that the world market situation or the specific requirements of certain markets may make it necessary to vary the refund according to destination.\\n(4) Refunds should be granted only on products that are allowed to move freely in the Community and that comply with the requirements of Regulation (EC) No 318/2006.\\n(5) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Sugar,\\nExport refunds as provided for in Article 32 of Regulation (EC) No 318/2006 shall be granted on the products and for the amounts set out in the Annex to this Regulation.\\nThis Regulation shall enter into force on 15 June 2007.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.',\n",
              " 'pos': '2.7.2004 EN Official Journal of the European Union L 233/9\\nCOMMISSION REGULATION (EC) No 1226/2004\\nof 1 July 2004\\nfixing the export refunds on white sugar and raw sugar exported in its unaltered state\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 1260/2001 of 19 June 2001 on the common organisation of the markets in the sugar sector\\xa0(1), and in particular the second subparagraph of Article 27(5) thereof,\\nWhereas:\\n(1) Article 27 of Regulation (EC) No 1260/2001 provides that the difference between quotations or prices on the world market for the products listed in Article 1(1)(a) of that Regulation and prices for those products within the Community may be covered by an export refund.\\n(2) Regulation (EC) No 1260/2001 provides that when refunds on white and raw sugar, undenatured and exported in its unaltered state, are being fixed account must be taken of the situation on the Community and world markets in sugar and in particular of the price and cost factors set out in Article 28 of that Regulation. The same Article provides that the economic aspect of the proposed exports should also be taken into account.\\n(3) The refund on raw sugar must be fixed in respect of the standard quality. The latter is defined in Annex I, point II, to Regulation (EC) No 1260/2001. Furthermore, this refund should be fixed in accordance with Article 28(4) of that Regulation. Candy sugar is defined in Commission Regulation (EC) No 2135/95 of 7 September 1995 laying down detailed rules of application for the grant of export refunds in the sugar sector\\xa0(2). The refund thus calculated for sugar containing added flavouring or colouring matter must apply to their sucrose content and, accordingly, be fixed per 1\\xa0% of the said content.\\n(4) In special cases, the amount of the refund may be fixed by other legal instruments.\\n(5) The refund must be fixed every two weeks. It may be altered in the intervening period.\\n(6) The first subparagraph of Article 27(5) of Regulation (EC) No 1260/2001 provides that refunds on the products referred to in Article 1 of that Regulation may vary according to destination, where the world market situation or the specific requirements of certain markets make this necessary.\\n(7) The significant and rapid increase in preferential imports of sugar from the western Balkan countries since the start of 2001 and in exports of sugar to those countries from the Community seems to be highly artificial.\\n(8) To prevent any abuse through the re-import into the Community of sugar products in receipt of an export refund, no refund should be set for all the countries of the western Balkans for the products covered by this Regulation.\\n(9) In view of the above and of the present situation on the market in sugar, and in particular of the quotations or prices for sugar within the Community and on the world market, refunds should be set at the appropriate amounts.\\n(10) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Sugar,\\nThe export refunds on the products listed in Article 1(1)(a) of Regulation (EC) No 1260/2001, undenatured and exported in the natural state, are hereby fixed to the amounts shown in the Annex hereto.\\nThis Regulation shall enter into force on 2 July 2004.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.',\n",
              " 'neg': '25.5.2007 EN Official Journal of the European Union L 133/21\\nCOMMISSION REGULATION (EC) No 571/2007\\nof 24 May 2007\\nfixing the rates of refunds applicable to certain products from the sugar sector exported in the form of goods not covered by Annex I to the Treaty\\nTHE COMMISSION OF THE EUROPEAN COMMUNITIES\\n,\\nHaving regard to the Treaty establishing the European Community,\\nHaving regard to Council Regulation (EC) No 318/2006 of 20 February 2006 on the common organisation of the market in the sugar sector\\xa0(1), and in particular Article 33(2)(a) and (4) thereof,\\nWhereas:\\n(1) Article 32(1) and (2) of Regulation (EC) No 318/2006 provides that the differences between the prices in international trade for the products listed in Article 1(1)(b), (c), (d) and (g) of that Regulation and prices within the Community may be covered by an export refund where these products are exported in the form of goods listed in Annex VII to that Regulation.\\n(2) Commission Regulation (EC) No 1043/2005 of 30 June 2005 implementing Council Regulation (EC) No\\xa03448/93 as regards the system of granting export refunds on certain agricultural products exported in the form of goods not covered by Annex I to the Treaty, and the criteria for fixing the amount of such refunds\\xa0(2), specifies the products for which a rate of refund is to be fixed, to be applied where these products are exported in the form of goods listed in Annex VII to Regulation (EC) No 318/2006.\\n(3) In accordance with the first paragraph of Article 14 of Regulation (EC) No 1043/2005, the rate of the refund per 100 kilograms for each of the basic products in question is to be fixed each month.\\n(4) Article 32(4) of Regulation (EC) No 318/2006 lays down that the export refund for a product contained in goods may not exceed the refund applicable to that product when exported without further processing.\\n(5) The refunds fixed under this Regulation may be fixed in advance as the market situation over the next few months cannot be established at the moment.\\n(6) The commitments entered into with regard to refunds which may be granted for the export of agricultural products contained in goods not covered by Annex I to the Treaty may be jeopardised by the fixing in advance of high refund rates. It is therefore necessary to take precautionary measures in such situations without, however, preventing the conclusion of long-term contracts. The fixing of a specific refund rate for the advance fixing of refunds is a measure which enables these various objectives to be met.\\n(7) The measures provided for in this Regulation are in accordance with the opinion of the Management Committee for Sugar,\\nThe rates of the refunds applicable to the basic products listed in Annex I to Regulation (EC) No\\xa01043/2005 and in Article 1(1) and in point (1) of Article 2 of Regulation (EC) No\\xa0318/2006, and exported in the form of goods listed in Annex VII to Regulation (EC) No\\xa0318/2006, shall be fixed as set out in the Annex to this Regulation.\\nThis Regulation shall enter into force on 25 May 2007.\\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.'}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example in sts_statics_datsets['train']:\n",
        "    if example['type']=='sts_by_textlabel':\n",
        "        assert 'label' in example.keys()\n"
      ],
      "metadata": {
        "id": "15D5Lf1Xp7tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelprocessor = LabelProcesserLedgar(examples = [\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "foopos = labelprocessor.find_positives([\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "print(sum([bool(d['positives']) for d in foopos])/len(foopos))\n",
        "\n",
        "fooneg = labelprocessor.find_negatives([\n",
        "  example for example in sts_statics_datsets['train'] if example['type']=='sts_by_textlabel'\n",
        "])\n",
        "\n",
        "print(sum([bool(d['negatives']) for d in fooneg])/len(fooneg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA27NcTqDNvL",
        "outputId": "efedfd24-fb0a-4959-ece3-c8c98b8d9f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['borrow', 'oblig']\n",
            "['borrow', 'oblig']\n",
            "0.4376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-94-1451465b933c>:204: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  best_candidate_label = self.random.choice(corpus_keys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# convert to torch dataset (val)\n",
        "sts_torchdataset_val = DatasetTriplets(\n",
        "    list_of_data = [\n",
        "       x for x in sts_statics_datsets['val'] if x.get('type','na') == 'sts_triplet'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        ")\n",
        "# convert to torch dataset (train)\n",
        "print('STS DatasetTriplet')\n",
        "sts_torchdataset_train = DatasetTriplets(\n",
        "    list_of_data = [\n",
        "       x for x in sts_statics_datsets['train'] if x.get('type','na')== 'sts_triplet'\n",
        "    ],\n",
        "    n_negatives= 3,\n",
        "    focal_text_name ='query',\n",
        "    positives_text_name ='positives',\n",
        "    negativess_text_name ='negatives',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAP4wenTovCw",
        "outputId": "fd715e12-eb7d-4d73-a057-0df5e8c76c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done finding negatives\n",
            "STS DatasetTriplet\n",
            "done finding negatives\n",
            "{'positives': [], 'negatives': ['We present a novel method for approximately equilibrating a matrix using only multiplication by the matrix and its transpose. Our method is based on convex optimization and projected stochastic gradient descent, using an unbiased estimate of a gradient obtained by a randomized method. Our method provably converges in expectation and empirically gets good results with a small number of iterations. We show how the method can be applied as a preconditioner for matrix-free iterative algorithms, substantially reducing the iterations required to reach a given level of precision. We also derive a novel connection between equilibration and condition number, showing that equilibrationminimizes an upper bound on the condition number over all choices of row and column scalings.']}\n",
            "this is missing a positive example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sts_torchdataset_train[95]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISaK7WFF8rTM",
        "outputId": "d96fc24d-dbfc-4e5d-e1eb-0e454f0f8f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'After two summers , Scout and Jem find small presents in a tree outside the Radley place .',\n",
              " 'pos': 'Following two summers of friendship with Dill , Scout and Jem find that someone is leaving them small gifts in a tree outside the Radley place .',\n",
              " 'neg': 'It is of critical relevance that designers are able to comprehend the various kinds of design-level modifications that a system undergoes throughout its entire lifecycle. In this respect, an interesting and useful operation between subsequent system versions is the model difference calculation and representation. In this paper, a metamodel independent approach to the representation of model differences which is agnostic of the calculation method is presented. Given two models which conform to a metamodel, their difference is conforming to another metamodel derived from the former by an automated transformation. Difference models are first-class entities which induce transformations able to apply the modifications they specify. Finally, difference models can be composed sequentially and in parallel giving place to more complex modifications.'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHjGUXzXIDuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifications Datasets\n",
        "\n",
        "- SNLI - no, that will be its own task\n",
        "- ag_news classification - (a couple of labels) https://huggingface.co/datasets/ag_news/viewer/default/train?row=100039\n",
        "- dbpedia_14 - news classification or topic ? https://huggingface.co/datasets/dbpedia_14 (~14 labels corresponding to art or building types)\n",
        "- sentiment analysis -- ?\n",
        "- ccdv/patent-classification - 25k (abstract)\n",
        "- fkdosilovic/docee-event-classification (21.9k) - 59 event types (fire, diaster)\n",
        "- scholarly360/contracts-classification-instruction-llm-experiments - 6.05k (clauses) -- no, I think these are just the auto-labels from LEDGAR\n",
        "- 'rcds/swiss_judgment_prediction','mt_en', (59703 examples) (NO, it is autotranslated)\n",
        "- 'tum-nlp/cannot-dataset' - like entailment, but contains paraphrases & negations\n",
        "- samchain/BIS_Speeches_97_23 - next sentence prediction\n",
        "- I could synthetically make another next-sentence-prediction using wikipedia?\n",
        "\n",
        "I could combine all into a multilabel exercise"
      ],
      "metadata": {
        "id": "XYbqWcsOtc5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "jUjM10o64Jl6",
        "outputId": "98d355a0-59c2-4fc5-b206-0b237cb772b6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-27beb5425bc6>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# streaming datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdatasets_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_streaming_mlm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_streaming_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-27beb5425bc6>\u001b[0m in \u001b[0;36mprocess_streaming_mlm_data\u001b[0;34m(data_config)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_streaming_mlm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdataset_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'dataset_probabilities'"
          ]
        }
      ],
      "source": [
        "\n",
        "## Need a function to randomly\n",
        "# ... function takes the first 5000 entries as the dev set\n",
        "# ... then skips 5000 to make the starting position for the train set\n",
        "# ... then randomly takes another start position to cycle trhough all the data\n",
        "# ... then what? Hardens it and converts it into 512 chunks? filters out small segments (<200)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nwords(sentence):\n",
        "    return len([w for w in sentence.split(' ') if len(w)>0])\n",
        "\n",
        "def process_streaming_mlm_data(data_config):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "    if data_config['dataset_probabilities'] is not None:\n",
        "        dataset_probabilities = [a/sum(data_config['dataset_probabilities']) for a in data_config['dataset_probabilities']]\n",
        "    else:\n",
        "        dataset_probabilities = [1.0/len(data_config['files']) for _ in range(len(data_config['files']))]\n",
        "\n",
        "    # concatenate list of streaming datasets\n",
        "    datasets_to_stream = []\n",
        "    for file_to_stream in data_config['files']:\n",
        "        dataset_to_stream = load_dataset(\"json\", data_files=file_to_stream, split=\"train\", streaming=True)\n",
        "        datasets_to_stream.append(dataset_to_stream.remove_columns(\"meta\"))\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy ='all_exhausted',\n",
        "        probabilities = dataset_probabilities\n",
        "    )\n",
        "    return datasets_combined\n",
        "\n",
        "# streaming datasets\n",
        "datasets_combined = process_streaming_mlm_data(data_streaming_config)\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MLMDataset(Dataset):\n",
        "    \"\"\"Do I want to pre-tokenize? If so, then the Collator will call .pad\"\"\"\n",
        "    def __init__(self, input_text, tokenizer, max_seq_length=512, min_seq_length=200):\n",
        "        self.data = []\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        for text in input_text:\n",
        "            word_count = nwords(text)\n",
        "            if word_count <= self.max_seq_length and word_count >= self.min_seq_length:\n",
        "                self.data.append(text)\n",
        "            elif word_count > self.max_seq_length:\n",
        "                text_split = text.split(\" \")\n",
        "                chunks = [\n",
        "                    text_split[i:i+self.max_seq_length] for i in range(0, word_count, 512)\n",
        "                ]\n",
        "                chunks = [\" \".join(s) for s in chunks if len(s)>=self.min_seq_length]\n",
        "                self.texts.extend(chunks)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MNnOqVW4ng5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wai8-2BMVp7Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset1 = load_dataset(\"json\", data_files=data_files[0], split=\"train\", streaming=True)\n",
        "print(next(iter(dataset1)))\n",
        "\n",
        "dataset2 = load_dataset(\"json\", data_files=data_files[1], split=\"train\", streaming=True)\n",
        "dataset3 = load_dataset(\"json\", data_files=data_files[2], split=\"train\",streaming=True)\n",
        "\n",
        "# streaming datasets\n",
        "streaming_datasets = [\n",
        "    dataset1.remove_columns(\"meta\"),\n",
        "    dataset2.remove_columns(\"meta\"),\n",
        "    dataset3.remove_columns([\"label\",\"source\"]).rename_column('provision','text') # ledgar\n",
        "]\n",
        "\n",
        "combined_dataset = interleave_datasets(streaming_datasets)\n",
        "combined_dataset = combined_dataset.skip(10001)\n",
        "next(iter(combined_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEObDHvhkHSZ",
        "outputId": "7b632de6-7471-458e-c70e-c3856cef5728"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n"
          ]
        }
      ],
      "source": [
        "dataset4 = load_dataset(\"pile-of-law/pile-of-law\",'euro_parl',split='train',streaming=True)\n",
        "dataset4 = dataset4.skip(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5zaHGuuQwt6",
        "outputId": "d14ac12b-5b66-4eff-eb9f-287b7e343795"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.builder:Using custom data configuration default-de993bbf5aabe685\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        }
      ],
      "source": [
        "# can I load ledgar\n",
        "dataset3 = load_dataset(\"json\", data_files=data_files[2], split=\"train\",streaming=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512,
          "referenced_widgets": [
            "90cd613da6d54fa881f325d531f371c6",
            "8f8f8bd06e8b4ce7bb74b30a5a2e68b4",
            "0491c321ae9344ff98592968423dccd3",
            "84949f4ae0b6402aaca1326d124436b3",
            "8e856b6e5ce74a4fa9b35ae801df4d31",
            "af00aa1a3bd64be9ad8f4df3e3c5f942",
            "11a1247638b6426c961fa4705dc85fee",
            "b6f9c6c1ac8a4eec97466e0f2108ce39",
            "ea3b3bc369804d85b562e7b83bc34804",
            "3650364038714617bd315e4fcd23d3bd",
            "f6823010dba245d1843a2f324e00c382",
            "ad8df595bb704a599d9abd994aa65691",
            "516b1796b208442ca32a48c8611b35fe",
            "e8db7bdb8bf04011874e6bb31570d763",
            "6679251fa0b64c59ab34bf7a811e0ae0",
            "c03bf64ecd204abab3d1b97eb32e0fdf",
            "5cd0803047b8426eb76e8412d6cf976a",
            "6b6b3265e630457aac2433dea92348e9",
            "a31311fbeb1d49c1a34ce41c4b01c22f",
            "3ba6ff0046c843679c0581a44ec69e1c",
            "6fdb79deb808435caba9e231f98118f0",
            "7bac298bf1954016a76ce82ab5842870",
            "a03e87f36c0240e0afd87ff4ebc334a2",
            "cfa3fef5ad8743228d10e60238d91449",
            "fd04d23b69a545d4acab01dd3046b44a",
            "f6eac59aef894d88bcae4654df6ef1b2",
            "ea4024140d39477884175e9aa9c2f796",
            "5d276b68035e42d79ec3d6c3600cd125",
            "dbe7e052a2994aadac7b883a020cd42f",
            "01bc3f5cd2ec4435b5a97c1dbbe7a86e",
            "5ef185dc852646fbb92d1eb31981bed0",
            "08187ae67b63489bba4a7b9c10d4d719",
            "379f64826a714ae89a85c265b4937902",
            "bf4d157f4fc041fca5718cdd41e73c10",
            "ab4bf3b1267743a8960deeeafcd0fcee",
            "ecaeab95cff44076a0a84cca103b6b60",
            "3cfadb1af62b45e1b6cf9f3243a281d5",
            "b5641641fc6e4f72b58c505565e16367",
            "f216f345dde54c35abaff30dac041c89",
            "e7cd7488f7264496be788107804bc9e8",
            "5dc68509c6494c6ebdd22c30ea632bfb",
            "7ad09b3ac2d5406caa626954d7dc4b92",
            "a51c61ff30d4474080167a38356ca402",
            "a6f38b1623f14bc9bea9b812f9102fce",
            "98371c9b595a4354a51020081c8adaa6",
            "d25f24f6c4464900af0369a1d34197af",
            "cf24681dbccd42f59ffda006ca4cdac6",
            "afbc002e8eed45b78884f7c4ccd6f37f",
            "12371b67bb334b2786c3809702b7bac7",
            "e3b7f6b62b45464db85df430da2ab97f",
            "dda17487487843c7a86152cde6220a6b",
            "f48649787c3d4f0f8de5d5eb8fdfc31b",
            "ca59bd8ff338413c8514ab0eee2d8ec3",
            "e779447c8d8e4578bd3a7747941bfbeb",
            "928685f89f3e40ddbf9b97a5281bb86f",
            "499cfcd99b96406383ff92126cab7c5d",
            "0787d9b7b9c649c9a8a70dd37d645a11",
            "a18b3a57972c42e1b061e2ada2c7858e",
            "f5a25f48fd7045d092d4b4b1a66f296c",
            "dbbeb2e4f0ca4e3b831fc5f58b883cf7",
            "e2dfbd412e2c4420931223730a476148",
            "9977be2298704813a37ed7c23e31d840",
            "610680918453400fba82622926af1b56",
            "933e94b11adf415abb0b16cad1201e93",
            "de941ef06f9a4974ba4e4075d96d5637",
            "4b242512f1ca473793bf144e5d062a9b"
          ]
        },
        "id": "ocINPgQyb84H",
        "outputId": "f9fd5a2b-b1a8-4540-8374-7fef089314fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.info:Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/pile-of-law--pile-of-law/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60\n",
            "INFO:datasets.builder:Generating dataset pile-of-law (/root/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60)\n",
            "INFO:datasets.builder:Dataset not on Hf google storage. Downloading and preparing it from source\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset pile-of-law/r_legaladvice to /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90cd613da6d54fa881f325d531f371c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.r_legaldvice.jsonl.xz not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/3401aa15961b3081a5a04646851c71451f98bc46a642f049a73b5bf2e7ce9876.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad8df595bb704a599d9abd994aa65691",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/61.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/train.r_legaldvice.jsonl.xz in cache at /root/.cache/huggingface/datasets/downloads/3401aa15961b3081a5a04646851c71451f98bc46a642f049a73b5bf2e7ce9876\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/3401aa15961b3081a5a04646851c71451f98bc46a642f049a73b5bf2e7ce9876\n",
            "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
            "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a03e87f36c0240e0afd87ff4ebc334a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/validation.r_legaldvice.jsonl.xz not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8.incomplete\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf4d157f4fc041fca5718cdd41e73c10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.file_utils:storing https://huggingface.co/datasets/pile-of-law/pile-of-law/resolve/main/data/validation.r_legaldvice.jsonl.xz in cache at /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8\n",
            "INFO:datasets.utils.file_utils:creating metadata file for /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8\n",
            "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
            "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
            "INFO:datasets.builder:Generating train split\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98371c9b595a4354a51020081c8adaa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.builder:Generating validation split\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "499cfcd99b96406383ff92126cab7c5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error reading file: /root/.cache/huggingface/datasets/downloads/a1ef937f954b208b1e34406796793ca2d775f7d96ade8fbb7fef66979430b6a8\n",
            "Dataset pile-of-law downloaded and prepared to /root/.cache/huggingface/datasets/pile-of-law___pile-of-law/r_legaladvice/0.0.0/c1090502f95031ebfad49ede680394da5532909fa46b7a0452be8cddecc9fa60. Subsequent calls will reuse this data.\n",
            "{'text': 'Title: Landlord broke lease agreement, what are my rights? (Chicago, IL)\\nQuestion:Our landlord has been promising us a washer/dryer unit since we moved in (July 2015). When we resigned the lease August 2016, we wrote into the lease that an in-unit washer and dryer would be installed by September 30th 2016.\\n\\nSince September 30th, there have been continuous delays in getting the W/D installed. Since it has now been almost a month past the date the W/D was supposed to be installed, I am wondering what types of rights as a tenant I have? \\n\\nThanks ahead of time for any and all advice given.\\nAnswer #1: You can let your landlord know in writing that he is in default under the current lease agreement and give him a reasonable timeframe to cure his default.  \\n\\nIf he fails to correct the default, you can likely end your lease and move.', 'created_timestamp': '10-25-2016', 'downloaded_timestamp': '11-09-2021', 'url': 'https://www.reddit.com/r/legaladvice/comments/59cv5x/landlord_broke_lease_agreement_what_are_my_rights/'}\n"
          ]
        }
      ],
      "source": [
        "# these pile datasets cannot be streamed, but then can be loaded individually\n",
        "all_pile_datasets = ['r_legaladvice', 'courtlistener_docket_entry_documents', 'atticus_contracts', 'courtlistener_opinions', 'federal_register',\n",
        "           'bva_opinions', 'us_bills', 'cc_casebooks', 'tos', 'euro_parl', 'nlrb_decisions', 'scotus_oral_arguments', 'cfr', 'state_codes',\n",
        "           'scotus_filings', 'exam_outlines', 'edgar', 'cfpb_creditcard_contracts', 'constitutions', 'congressional_hearings', 'oig',\n",
        "           'olc_memos', 'uscode', 'founding_docs', 'ftc_advisory_opinions', 'echr', 'eurlex', 'tax_rulings', 'un_debates', 'fre', 'frcp',\n",
        "           'canadian_decisions', 'eoir', 'dol_ecab', 'icj-pcij', 'uspto_office_actions', 'ed_policy_guidance', 'acus_reports', 'hhs_alj_opinions',\n",
        "           'sec_administrative_proceedings', 'fmshrc_bluebooks', 'resource_contracts', 'medicaid_policy_guidance', 'irs_legal_advice_memos', 'doj_guidance_documents'\n",
        "    ]\n",
        "\n",
        "dataset3 = load_dataset('pile-of-law/pile-of-law',all_pile_datasets[0],split='train')\n",
        "\n",
        "print(next(iter(dataset3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDdE_WK7_hlH",
        "outputId": "f883cb06-2457-46f6-918d-ace90091e8e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': '543 U.S. 1079\\nBARNESv.UNITED STATES.\\nNo. 04-7550.\\nSupreme Court of United States.\\nJanuary 10, 2005.\\n\\n1\\nC. A. 8th Cir. Certiorari denied. Reported below: 374 F. 3d 601.\\n\\n'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(streaming_datasets[1])) # works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BOAAaYO9F4p"
      },
      "outputs": [],
      "source": [
        "#dataset_head = pubmed_dataset_streamed.skip(10000) # skipping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZLuqQNU_PMO",
        "outputId": "2d82aadf-52d6-4cec-feb1-4f314538d1da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': '\\n517 U.S. 706 (1996)\\nQUACKENBUSH, CALIFORNIA INSURANCE COMMISSIONER\\nv.\\nALLSTATE INSURANCE CO.\\nNo. 95-244.\\nUnited States Supreme Court.\\nArgued February 20, 1996.\\nDecided June 3, 1996.\\nCERTIORARI TO THE UNITED STATES COURT OF APPEALS FOR THE NINTH CIRCUIT\\n*708 *708 O\\'Connor, J., delivered the opinion for a unanimous Court. Scalia, J., post, p. 731, and Kennedy, J., post, p. 733, filed concurring opinions.\\nKarl L. Rubinstein argued the cause for petitioner. With him on the briefs were Dana Carli Brooks, Melissa S. Kooistra, William W. Palmer, and David L. Shapiro. \\nDonald Francis Donovan argued the cause for respondent. With him on the brief were Carl Micarelli, Joseph D. Lee, and James G. Sporleder.[*]\\n*709 Justice O\\'Connor, delivered the opinion of the Court.\\nIn this case, we consider whether an abstention-based remand order is appealable as a final order under 28 U. S. C. § 1291, and whether the abstention doctrine first recognized in Burford v. Sun Oil Co., 319 U. S. 315 (1943), can be applied in a common-law suit for damages.\\n\\nI\\nPetitioner, the Insurance Commissioner for the State of California, was appointed trustee over the assets of the Mission Insurance Company and its affiliates (Mission companies) in 1987, after those companies were ordered into liquidation by a California court. In an effort to gather the assets of the defunct Mission companies, the Commissioner filed the instant action against respondent Allstate Insurance Company in state court, seeking contract and tort damages for Allstate\\'s alleged breach of certain reinsurance agreements, as well as a general declaration of Allstate\\'s obligations under those agreements.\\nAllstate removed the action to federal court on diversity grounds and filed a motion to compel arbitration under the Federal Arbitration Act, 9 U. S. C. § 1 et seq. (1988 ed. and Supp. V). The Commissioner sought remand to state court, arguing that the District Court should abstain from hearing the case under Burford, supra, because its resolution might interfere with California\\'s regulation of the Mission insolvency. Specifically, the Commissioner indicated that Allstate would be asserting its right to set off its own contract claims against the Commissioner\\'s recovery under the contract, that the viability of these setoff claims was a hotly disputed question of state law, and that this question was currently pending before the state courts in another case arising out of the Mission insolvency.\\nThe District Court observed that \"California has an overriding interest in regulating insurance insolvencies and liquidations in a uniform and orderly manner,\" and that in this *710 case \"this important state interest could be undermined by inconsistent rulings from the federal and state courts.\" App. to Pet. for Cert. 34a. Based on these observations, and its determination that the setoff question should be resolved in state court, the District Court concluded this case was an appropriate one for the exercise of Burford abstention. The District Court did not stay its hand pending the California courts\\' resolution of the setoff issue, but instead remanded the entire case to state court. The District Court entered this remand order without ruling on Allstate\\'s motion to compel arbitration.\\nAfter determining that appellate review of the District Court\\'s remand order was not barred by 28 U. S. C. § 1447(d), see Garamendi v. Allstate Ins. Co., 47 F. 3d 350, 352 (CA9 1995) (citing Thermtron Products, Inc. v. Hermansdorfer,  423 U. S. 336 (1976)), and that the remand order was appealable under 28 U. S. C. § 1291 as a final collateral order, see 47 F. 3d, at 353-354 (citing Moses H. Cone Memorial Hospital  v. Mercury Constr. Corp., 460 U. S. 1 (1983)), the Court of Appeals for the Ninth Circuit vacated the District Court\\'s decision and ordered the case sent to arbitration. The Ninth Circuit concluded that federal courts can abstain from hearing a case under Burford only when the relief being sought is equitable in nature, and therefore held that abstention was inappropriate in this case because the Commissioner purported to be seeking only legal relief. 47 F. 3d, at 354-356; App. to Pet. for Cert. 35a\\x9737a (order denying petition for rehearing because Commissioner had waived any argument that this case involved a request for equitable relief).\\nThe Ninth Circuit\\'s holding that abstention-based remand orders are appealable conflicts with the decisions of other Courts of Appeals, see Doughty v. Underwriters at Lloyd\\'s, London, 6 F. 3d 856, 865 (CA1 1993) (order not appealable); Corcoran v. Ardra Insurance Co., Ltd., 842 F. 2d 31, 34 (CA2 1988) (same); In re Burns & Wilcox, Ltd., 54 F. 3d 475, 477, *711 n. 7 (CA8 1995) (same); but see Minot v. Eckardt-Minot, 13 F. 3d 590, 593 (CA2 1994) (order appealable under collateral order doctrine), as does its determination that Burford abstention can only be exercised in cases in which equitable relief is sought, see Lac D\\'Amiante du Quebec, Ltee v. American Home Assurance Co., 864 F. 2d 1033, 1045 (CA3 1988) (Burford abstention appropriate in case seeking declaratory relief); Brandenburg v. Seidel, 859 F. 2d 1179, 1192, n. 17 (CA4 1988) (Burford abstention appropriate in action for damages); Wolfson v. Mutual Benefit Life Ins. Co., 51 F. 3d 141, 147 (CA8 1995) (same); but see Fragoso v. Lopez, 991 F. 2d 878, 882 (CA1 1993) (federal court can abstain under Burford only if it is \"sitting in equity\"); University of Maryland v. Peat Marwick Main & Co., 923 F. 2d 265, 272 (CA3 1991) (same); Baltimore Bank for Cooperatives v. Farmer\\'s Cheese Cooperative, 583 F. 2d 104, 111 (CA3 1978) (same). We granted certiorari to resolve these conflicts, 516 U. S. 929 (1995), and now affirm on grounds different from those provided by the Ninth Circuit.\\n\\nII\\nWe first consider whether the Court of Appeals had jurisdiction to hear Allstate\\'s appeal under 28 U. S. C. § 1291, which confers jurisdiction over appeals from \"final decisions\" of the district courts, and 28 U. S. C. § 1447(d), which provides that \"[a]n order remanding a case to the State court from which it was removed is not reviewable on appeal or otherwise.\"\\nWe agree with the Ninth Circuit and the parties that § 1447(d) interposes no bar to appellate review of the remand order at issue in this case. See 47 F. 3d, at 352; Brief for Petitioner 29-30; Brief for Respondent 13-14, n. 12. As we held in Thermtron Products, Inc. v. Hermansdorfer, supra, at 345-346, and reiterated this Term in Things Remembered, Inc. v. Petrarca, 516 U. S. 124, 127 (1995), \"§ 1447(d) must be read in pari materia with § 1447(c), so *712 that only remands based on grounds specified in § 1447(c) are immune from review under § 1447(d).\" This gloss renders § 1447(d) inapplicable here: The District Court\\'s abstentionbased remand order does not fall into either category of remand order described in § 1447(c), as it is not based on lack of subject matter jurisdiction or defects in removal procedure.\\nFinding no affirmative bar to appellate review of the District Court\\'s remand order, we must determine whether that review may be obtained by appeal under § 1291. The general rule is that \"a party is entitled to a single appeal, to be deferred until final judgment has been entered, in which claims of district court error at any stage of the litigation may be ventilated.\" Digital Equipment Corp. v. Desktop Direct, Inc., 511 U. S. 863, 868 (1994) (citations omitted). Accordingly, we have held that a decision is ordinarily considered final and appealable under § 1291 only if it \"ends the litigation on the merits and leaves nothing for the court to do but execute the judgment.\" Catlin v. United States, 324 U. S. 229, 233 (1945); see also Digital, supra, at 867 (quoting this standard). We have also recognized, however, a narrow class of collateral orders which do not meet this definition of finality, but which are nevertheless immediately appealable under § 1291 because they \"`conclusively determine [a] disputed question\\' \" that is \"`completely separate from the merits of the action,\\' \" \"`effectively unreviewable on appeal from a final judgment,\\' \" Richardson-Merrell Inc. v. Koller, 472 U. S. 424, 431 (1985) (quoting Coopers & Lybrand v. Livesay,  437 U. S. 463, 468 (1978)), and \"too important to be denied review,\" Cohen v. Beneficial Industrial Loan Corp., 337 U. S. 541, 546 (1949).\\nThe application of these principles to the appealability of the remand order before us is controlled by our decision in Moses H. Cone Memorial Hospital v. Mercury Constr. Corp., supra. The District Court in that case entered an order under Colorado River Water Conservation Dist. v. United States, 424 U. S. 800 (1976), staying a federal diversity suit *713 pending the completion of a declaratory judgment action that had been filed in state court. The Court of Appeals held that this stay order was appealable under § 1291, and we affirmed that determination on two independent grounds.\\nWe first concluded that the abstention-based stay order was appealable as a \"final decision\" under § 1291 because it put the litigants \"`effectively out of court,\\' \" 460 U. S., at 11, n. 11 (quoting Idlewild Bon Voyage Liquor Corp. v. Epstein,  370 U. S. 713, 715, n. 2 (1962) (per curiam) ), and because its effect was \"precisely to surrender jurisdiction of a federal suit to a state court,\" 460 U. S., at 11, n. 11. These standards do not reflect our oft-repeated definition of finality, see supra, at 712 (citing Catlin, supra, at 233); see, e. g., Digital, supra, at 867 (citing the Catlin definition); Lauro Lines s.r.l.  v. Chasser, 490 U. S. 495, 497 (1989) (same); Van Cauwenberghe v. Biard, 486 U. S. 517, 521-522 (1988) (same), but in Moses H. Cone we found their application to be compelled by precedent, see 460 U. S., at 11, n. 11 (\"Idlewild `s reasoning is limited to cases where (under Colorado River, abstention, or a closely similar doctrine) the object of the stay is to require all or an essential part of the federal suit to be litigated in a state forum\").\\nAs an alternative to this reliance on Idlewild, we also held that the stay order at issue in Moses H. Cone was appealable under the collateral order doctrine. 460 U. S., at 11. We determined that a stay order based on the Colorado River  doctrine \"presents an important issue separate from the merits\" because it \"amounts to a refusal to adjudicate\" the case in federal court; that such orders could not be reviewed on appeal from a final judgment in the federal action because the district court would be bound, as a matter of res judicata, to honor the state court\\'s judgment; and that unlike other stay orders, which might readily be reconsidered by the district court, abstention-based stay orders of this ilk are \"conclusive\" because they are the practical equivalent of an order dismissing the case. 460 U. S., at 12.\\n*714 The District Court\\'s order remanding on grounds of Burford abstention is in all relevant respects indistinguishable from the stay order we found to be appealable in Moses H. Cone. No less than an order staying a federal court action pending adjudication of the dispute in state court, it puts the litigants in this case \"`effectively out of court,\\' \" Moses H. Cone, supra, at 11, n. 11 (quoting Idlewild Bon Voyage Liquor Corp. v. Epstein, supra, at 715, n. 2), and its effect is \"precisely to surrender jurisdiction of a federal suit to a state court,\" 460 U. S., at 11, n. 11. Indeed, the remand order is clearly more \"final\" than a stay order in this sense. When a district court remands a case to a state court, the district court disassociates itself from the case entirely, retaining nothing of the matter on the federal court\\'s docket.\\nThe District Court\\'s order is also indistinguishable from the stay order we considered in Moses H. Cone in that it conclusively determines an issue that is separate from the merits, namely, the question whether the federal court should decline to exercise its jurisdiction in the interest of comity and federalism. See infra, at 716-717, 727-728. In addition, the rights asserted on appeal from the District Court\\'s abstention decision are, in our view, sufficiently important to warrant an immediate appeal. See infra, at 716, 723-728 (describing interests weighed in decision to abstain under Burford ); cf.Digital, 511 U. S., at 878 (review under collateral order doctrine limited to those issues \"`too important to be denied review\\' \") (quoting Cohen, supra, at 546). And, like the stay order we found appealable in Moses H. Cone, the District Court\\'s remand order in this case will not be subsumed in any other appealable order entered by the District Court.\\nWe have previously stated that \"an order remanding a removed action does not represent a final judgment reviewable by appeal.\" Thermtron Products, Inc. v. Hermansdorfer,  423 U. S., at 352-353. Petitioner asks that we adhere to that statement and hold that appellate review of the District *715 Court\\'s remand order can only be obtained through a petition for writ of mandamus. To the extent Thermtron would require us to ignore the implications of our later holding in Moses H. Cone, however, we disavow it. Thermtron `s determination that remand orders are not reviewable \"final judgments\" doubtless was necessary to the resolution of that case, see 423 U. S., at 352 (posing the question whether mandamus was the appropriate vehicle), but our principal concern in Thermtron was the interpretation of the bar to appellate review embodied in 28 U. S. C. § 1447(d), see supra,  at 711-712, and our statement concerning the appropriate procedural vehicle for reviewing a district court\\'s remand order was peripheral to that concern. Moreover, the parties in Thermtron did not brief the question, our opinion does not refer to Catlin or its definition of \"final decisions,\" and our opinion nowhere addresses whether any class of remand order might be appealable under the collateral order doctrine. Indeed, the only support Thermtron cites for the proposition that remand orders are reviewable only by mandamus, not by appeal, is Railroad Co. v. Wiswall, 23 Wall. 507 (1875), the superannuated reasoning of which is of little vitality today, compare id., at 508 (deeming a \"writ of error to review what has been done\" an inappropriate vehicle for reviewing a court of appeals\\' \"refusal to hear and decide\"), with Moses H. Cone, 460 U. S., at 10-11, n. 11 (holding that a stay order is appealable because it amounts to a refusal to hear and decide a case).\\nAdmittedly, remand orders like the one entered in this case do not meet the traditional definition of finality\\x97they do not \"en[d] the litigation on the merits and leav[e] nothing for the court to do but execute the judgment,\" Catlin, 324 U. S., at 233. But because the District Court\\'s remand order is functionally indistinguishable from the stay order we found appealable in Moses H. Cone, see supra, at 714, we conclude that it is appealable, and turn to the merits of the Ninth Circuit\\'s decision respecting Burford abstention.\\n\\n\\n*716 III\\n\\nA\\nWe have often acknowledged that federal courts have a strict duty to exercise the jurisdiction that is conferred upon them by Congress. See, e. g., Colorado River, 424 U. S., at 821 (\"[F]ederal courts have a `virtually unflagging obligation. . . to exercise the jurisdiction given them\\' \"); England v. Louisiana Bd. of Medical Examiners, 375 U. S. 411, 415 (1964) (\"`When a federal court is properly appealed to in a case over which it has by law jurisdiction, it is its duty to take such jurisdiction\\' \") (quoting Willcox v. Consolidated Gas Co., 212 U. S. 19, 40 (1909)); Cohens v. Virginia, 6 Wheat. 264, 404 (1821) (federal courts \"have no more right to decline the exercise of jurisdiction which is given, than to usurp that which is not\"). This duty is not, however, absolute. See Canada Malting Co. v. Paterson S. S., Ltd., 285 U. S. 413, 422 (1932) (\"[T]he proposition that a court having jurisdiction must exercise it, is not universally true\"). Indeed, we have held that federal courts may decline to exercise their jurisdiction, in otherwise \"`exceptional circumstances,\\' \" where denying a federal forum would clearly serve an important countervailing interest, Colorado River, supra, at 813 (quoting County of Allegheny v. Frank Mashuda Co., 360 U. S. 185, 189 (1959)), for example, where abstention is warranted by considerations of \"proper constitutional adjudication,\" \"regard for federal-state relations,\" or \"wise judicial administration,\" Colorado River, supra, at 817 (internal quotation marks omitted).\\nWe have thus held that federal courts have the power to refrain from hearing cases that would interfere with a pending state criminal proceeding, see Younger v. Harris, 401 U. S. 37 (1971), or with certain types of state civil proceedings, see Huffman v. Pursue, Ltd., 420 U. S. 592 (1975); Juidice v. Vail, 430 U. S. 327 (1977); cases in which the resolution of a federal constitutional question might be obviated *717 if the state courts were given the opportunity to interpret ambiguous state law, see Railroad Comm\\'n of Tex. v. Pullman Co., 312 U. S. 496 (1941); cases raising issues \"intimately involved with [the States\\'] sovereign prerogative,\" the proper adjudication of which might be impaired by unsettled questions of state law, see Louisiana Power & Light Co. v. City of Thibodaux, 360 U. S. 25, 28 (1959); id., at 31 (Stewart, J., concurring); cases whose resolution by a federal court might unnecessarily interfere with a state system for the collection of taxes, see Great Lakes Dredge & Dock Co. v. Huffman, 319 U. S. 293 (1943); and cases which are duplicative of a pending state proceeding, see Colorado River Water Conservation Dist. v. United States, 424 U. S. 800 (1976); Pennsylvania v. Williams, 294 U. S. 176 (1935).\\nOur longstanding application of these doctrines reflects \"the common-law background against which the statutes conferring jurisdiction were enacted,\" New Orleans Public Service, Inc. v. Council of City of New Orleans, 491 U. S. 350, 359 (1989) (NOPSI) (citing Shapiro, Jurisdiction and Discretion, 60 N. Y. U. L. Rev. 543, 570-577 (1985)). And, as the Ninth Circuit correctly indicated, 47 F. 3d, at 354, it has long been established that a federal court has the authority to decline to exercise its jurisdiction when it \"is asked to employ its historic powers as a court of equity,\" Fair Assessment in Real Estate Assn., Inc. v. McNary, 454 U. S. 100, 120 (1981) (Brennan, J., concurring). This tradition informs our understanding of the jurisdiction Congress has conferred upon the federal courts, and explains the development of our abstention doctrines. In Pullman, for example, we explained the principle underlying our abstention doctrines as follows:\\n\". . . The history of equity jurisdiction is the history of regard for public consequences in employing the extraordinary remedy of the injunction. . . . Few public interests have a higher claim upon the discretion of a federal chancellor than the avoidance of needless friction *718 with state policies, whether the policy relates to the enforcement of the criminal law, or the administration of a specialized scheme for liquidating embarrassed business enterprises, or the final authority of a state court to interpret doubtful regulatory laws of the state. These cases reflect a doctrine of abstention appropriate to our federal system, whereby the federal courts, `exercising a wise discretion,\\' restrain their authority because of `scrupulous regard for the rightful independence of the state governments\\' and for the smooth working of the federal judiciary. This use of equitable powers is a contribution of the courts in furthering the harmonious relation between state and federal authority without the need of rigorous congressional restriction of those powers.\" 312 U. S., at 500-501 (citations omitted).\\nThough we have thus located the power to abstain in the historic discretion exercised by federal courts \"sitting in equity,\" we have not treated abstention as a \"technical rule of equity procedure.\" Thibodaux, supra, at 28. Rather, we have recognized that the authority of a federal court to abstain from exercising its jurisdiction extends to all cases in which the court has discretion to grant or deny relief. See NOPSI, supra, at 359 (mandate of federal jurisdiction \"does not eliminate . . . the federal courts\\' discretion in determining whether to grant certain types of relief\"). Accordingly, we have not limited the application of the abstention doctrines to suits for injunctive relief, but have also required federal courts to decline to exercise jurisdiction over certain classes of declaratory judgments, see, e. g., Huffman, 319 U. S., at 297 (federal court must abstain from hearing declaratory judgment action challenging constitutionality of a state tax); Samuels v. Mackell, 401 U. S. 66, 69-70, 72-73 (1971) (extending Younger abstention to declaratory judgment actions), the granting of which is generally committed to the courts\\' discretion, see Wilton v. Seven Falls Co.,  515 U. S. 277, 282 (1995) (federal courts have \"discretion in *719 determining whether and when to entertain an action under the Declaratory Judgment Act, even when the suit otherwise satisfies subject matter jurisdictional prerequisites\").\\nNevertheless, we have not previously addressed whether the principles underlying our abstention cases would support the remand or dismissal of a common-law action for damages. Cf. Deakins v. Monaghan, 484 U. S. 193, 202, and n. 6 (1988) (reserving the question whether Younger requires abstention in an action for damages); Ankenbrandt v. Richards, 504 U. S. 689 (1992) (discussing, without applying, Burford abstention in damages action). To be sure, we held in Fair Assessment in Real Estate Assn., Inc. v.McNary, supra,  that a federal court should not entertain a 42 U. S. C. § 1983 suit for damages based on the enforcement of a state tax scheme, see 454 U. S., at 115, but we have subsequently indicated that Fair Assessment was a case about the scope of the § 1983 cause of action, see National Private Truck Council, Inc. v. Oklahoma Tax Comm\\'n, 515 U. S. 582, 589-590 (1995), not the abstention doctrines. To the extent Fair Assessment does apply abstention principles, its holding is very limited. The damages action in that case was based on the unconstitutional application of a state tax law, and the award of damages turned first on a declaration that the state tax was in fact unconstitutional. We therefore drew an analogy to Huffman and other cases in which we had approved the application of abstention principles in declaratory judgment actions, and held that the federal court should decline to hear the action because \"[t]he recovery of damages under the Civil Rights Act first requires a `declaration\\' or determination of the unconstitutionality of a state tax scheme that would halt its operation.\" Fair Assessment, supra, at 115.\\nOtherwise, we have applied abstention principles to actions \"at law\" only to permit a federal court to enter a stay order that postpones adjudication of the dispute, not to dismiss the federal suit altogether. See, e. g., Thibodaux, supra, at 28-30 (approving stay order); Fornaris v. Ridge *720 Tool Co., 400 U. S. 41, 44 (1970) (per curiam) (directing District Court to \"hold its hand until the Puerto Rican Supreme Court has authoritatively ruled on the local law question in light of the federal claims\" (footnote omitted)) (emphasis added); United Gas Pipe Line Co. v. Ideal Cement Co., 369 U. S. 134, 135-136 (1962) (per curiam) (\"Wise judicial administration in this case counsels that decision of the federal question be deferred until the potentially controlling statelaw issue is authoritatively put to rest\"); Clay v. Sun Ins. Office Ltd., 363 U. S. 207, 212 (1960) (approving \"postponement of decision\" in damages suit).\\nOur decisions in Thibodaux and County of Allegheny v. Frank Mashuda Co., 360 U. S. 185 (1959), illustrate the distinction we have drawn between abstention-based remand orders or dismissals and abstention-based decisions merely to stay adjudication of a federal suit. In Thibodaux, a city in Louisiana brought an eminent domain proceeding in state court, seeking to condemn for public use certain property owned by a Florida corporation. After the corporation removed the action to federal court on diversity grounds, the Federal District Court decided on its own motion to stay the case, pending a state court\\'s determination whether the city could exercise the power of eminent domain under state law. The case did not arise within the \"equity\" jurisdiction of the federal courts, 360 U. S., at 28, because the suit sought compensation for a taking, and the District Court lacked discretion to deny relief on the corporation\\'s claim. Nonetheless, the issues in the suit were \"intimately involved with [the State\\'s] sovereign prerogative.\" Ibid. We concluded that \"[t]he considerations that prevailed in conventional equity suits for avoiding the hazards of serious disruption by federal courts of state government or needless friction between state and federal authorities are similarly appropriate in a state eminent domain proceeding brought in, or removed to, a federal court.\" Ibid. And based on that conclusion, we affirmed the District Court\\'s order staying the case.\\n*721 County of Allegheny was decided the same day as Thibodaux, and like Thibodaux it involved review of a District Court order abstaining from the exercise of diversity jurisdiction over a state law eminent domain action. Unlike in Thibodaux, however, the District Court in County of Allegheny had not merely stayed adjudication of the federal action pending the resolution of an issue in state court, but rather had dismissed the federal action altogether. Based in large measure on this distinction, we reversed the District Court\\'s order. See 360 U. S., at 190; Thibodaux, 360 U. S., at 31 (Stewart, J., concurring) (\"In Mashuda, the Court holds that it was error for the District Court to dismiss the complaint\" (emphasis added)).\\nWe were careful to note in Thibodaux that the District Court had only stayed the federal suit pending adjudication of the dispute in state court. Unlike the outright dismissal or remand of a federal suit, we held, an order merely staying the action \"does not constitute abnegation of judicial duty. On the contrary, it is a wise and productive discharge of it. There is only postponement of decision for its best fruition.\" Id., at 29. We have thus held that in cases where the relief being sought is equitable in nature or otherwise discretionary, federal courts not only have the power to stay the action based on abstention principles, but can also, in otherwise appropriate circumstances, decline to exercise jurisdiction altogether by either dismissing the suit or remanding it to state court. By contrast, while we have held that federal courts may stay actions for damages based on abstention principles, we have not held that those principles support the outright dismissal or remand of damages actions.\\nOne final line of cases bears mentioning. Though we deal here with our abstention doctrines, we have recognized that federal courts have discretion to dismiss damages actions, in certain narrow circumstances, under the common-law doctrine of forum non conveniens. The seminal case recognizing this authority is Gulf Oil Corp. v. Gilbert, 330 U. S. 501 *722 (1947), in which we considered whether a Federal District Court sitting in diversity in New York could dismiss a tort action for damages on the grounds that Virginia provided a more appropriate locale for adjudicating the dispute. Id., at 503. We conceded that the application of this doctrine should be \"rare,\" id., at 509, but also held that the exercise of forum non conveniens is not limited to actions in equity:\\n\"This Court[,] in recognizing and approving it by name has never indicated that it was rejecting application of the doctrine to law actions which had been an integral and necessary part of [the] evolution of the doctrine. Wherever it is applied in courts in other jurisdictions, its application does not depend on whether the action is at law or in equity.\" Id., at 505, n. 4 (citations omitted).\\nThe dispute in Gulf Oil was over venue, not jurisdiction, and the expectation was that after dismissal of the suit in New York the parties would refile in federal court, not the state courts of Virginia. This transfer of venue function of the forum non conveniens doctrine has been superseded by statute, see 28 U. S. C. § 1404(a); Piper Aircraft Co. v. Reyno,  454 U. S. 235, 253 (1981), and to the extent we have continued to recognize that federal courts have the power to dismiss damages actions under the common-law forum non conveniens doctrine, we have done so only in \"cases where the alternative forum is abroad.\" American Dredging Co. v. Miller, 510 U. S. 443, 449, n. 2 (1994); see, e. g., Piper, supra,  at 265-269 (dismissal of wrongful death action).\\nThe fact that we have applied the forum non conveniens  doctrine in this manner does not change our analysis in this case, where we deal with the scope of the Burford abstention doctrine. To be sure, the abstention doctrines and the doctrine of forum non conveniens proceed from a similar premise: In rare circumstances, federal courts can relinquish their jurisdiction in favor of another forum. But our abstention doctrine is of a distinct historical pedigree, and the traditional *723 considerations behind dismissal for forum non conveniens differ markedly from those informing the decision to abstain. Compare American Dredging, supra, at 448-449 (describing \"multifarious factors,\" including both public and private interests, which might allow a district court to dismiss a case under doctrine of forum non conveniens ), with Burford, 319 U. S., at 332-333 (describing \"federal-state conflict\" that requires a federal court to yield jurisdiction in favor of a state forum). Federal courts abstain out of deference to the paramount interests of another sovereign, and the concern is with principles of comity and federalism. See, e. g., ibid.; Younger, 401 U. S., at 44-45. Dismissal for forum non conveniens, by contrast, has historically reflected a far broader range of considerations, see Piper, supra, at 241, 257-262 (describing the interests which bear on forum non conveniens decision); Gulf Oil, supra, at 508-509 (same), most notably the convenience to the parties and the practical difficulties that can attend the adjudication of a dispute in a certain locality, see Piper, supra, at 257-259 (evidentiary problems, unavailability of witnesses, difficulty of coordinating multiple suits); Gulf Oil, supra, at 511 (availability of witnesses, need to interplead Virginia corporation, location of evidence).\\n\\nB\\nWith these background principles in mind, we consider the contours of the Burford doctrine. The principal issue presented in Burford was the \"reasonableness\" of an order issued by the Texas Railroad Commission, which granted \"a permit to drill four oil wells on a small plot of land in the East Texas oil field.\" 319 U. S., at 317. Due to the potentially overlapping claims of the many parties who might have an interest in a common pool of oil and the need for uniform regulation of the oil industry, Texas endowed the Railroad Commission with exclusive regulatory authority in the area. Texas also placed the authority to review the Commission\\'s *724 orders in a single set of state courts, \"[t]o prevent the confusion of multiple review,\" id., at 326, and to permit an experienced cadre of state judges to obtain \"specialized knowledge\" in the field, id., at 327. Though Texas had thus demonstrated its interest in maintaining uniform review of the Commission\\'s orders, the federal courts had, in the years preceding Burford, become increasingly involved in reviewing the reasonableness of the Commission\\'s orders, both under a constitutional standard imposed under the Due Process Clause, see, e. g., Railroad Comm\\'n of Tex. v. Rowan & Nichols Oil Co., 310 U. S. 573, 577 (1940), and under state law, which established a similar standard, see Burford, 319 U. S., at 317, 326.\\nViewing the case as \"a simple proceeding in equity to enjoin the enforcement of the Commissioner\\'s order,\" id., at 317, we framed the question presented in terms of the power of a federal court of equity to abstain from exercising its jurisdiction:\\n\"Although a federal equity court does have jurisdiction of a particular proceeding, it may, in its sound discretion, whether its jurisdiction is invoked on the ground of diversity of citizenship or otherwise, `refuse to enforce or protect legal rights, the exercise of which may be prejudicial to the public interest,\\' for it `is in the public interest that federal courts of equity should exercise their discretionary power with proper regard for the rightful independence of state governments in carrying out their domestic policy.\\' While many other questions are argued, we find it necessary to decide only one: Assuming that the federal district court had jurisdiction, should it, as a matter of sound equitable discretion, have declined to exercise that jurisdiction here?\" Id., at 317\\x97 318 (footnote omitted) (quoting United States ex rel. Greathouse v. Dern, 289 U. S. 352, 360 (1933), and Penn- sylvania v. Williams, 294 U. S., at 185).\\n*725 Having thus posed the question in terms of the District Court\\'s discretion, as a court sitting \"in equity,\" to decline jurisdiction, we approved the District Court\\'s dismissal of the complaint on a number of grounds that were unique to that case. We noted, for instance, the difficulty of the regulatory issues presented, stating that the \"order under consideration is part of the general regulatory system devised for the conservation of oil and gas in Texas, an aspect of `as thorny a problem as has challenged the ingenuity and wisdom of legislatures.\\' \" 319 U. S., at 318 (quoting Rowan, supra, at 579). We also stressed the demonstrated need for uniform regulation in the area, 319 U. S., at 318-319, citing the unified procedures Texas had established to \"prevent the confusion of multiple review,\" id., at 325-326, and the important state interests this uniform system of review was designed to serve, id., at 319-320. Most importantly, we also described the detrimental impact of ongoing federal court review of the Commission\\'s orders, which review had already led to contradictory adjudications by the state and federal courts. Id., at 327-328, 331-332.\\nWe ultimately concluded in Burford that dismissal was appropriate because the availability of an alternative, federal forum threatened to frustrate the purpose of the complex administrative system that Texas had established. See id.,  at 332 (\"The whole cycle of federal-state conflict cannot be permitted to begin again\"). We have since provided more generalized descriptions of the Burford doctrine, see, e. g., County of Allegheny, 360 U. S., at 189 (\"abstention on grounds of comity with the States where the exercise of jurisdiction by the federal court would disrupt a state administrative process\"); Colorado River, 424 U. S., at 814-816 (abstention where \"exercise of federal review of the question in a case and in similar cases would be disruptive of state efforts to establish a coherent policy with respect to a matter of substantial public concern\"), but with the exception of cases that rest only loosely on the Burford rationale, e. g., *726 Louisiana Power & Light Co. v. City of Thibodaux, 360 U. S. 25 (1959), we have revisited the decision only infrequently in the intervening 50 years. See NOPSI, 491 U. S. 350 (1989).\\nIn NOPSI, our most recent exposition of the Burford doctrine, we again located the power to dismiss based on abstention principles in the discretionary power of a federal court sitting in equity, and we again illustrated the narrow range of circumstances in which Burford can justify the dismissal of a federal action. The issue in NOPSI was pre-emption. A New Orleans utility that had been saddled by a decision of the Federal Energy Regulatory Commission (FERC) with part of the cost of building and operating a nuclear reactor sought approval of a rate increase from the Council of the City of New Orleans. The council denied the rate increase on the grounds that \"a public hearing was necessary to explore `the legality and prudency\\' [sic] \" of the expenses allocated to the utility under the FERC decision, 491 U. S., at 355, and the utility brought suit in federal court, seeking an injunction against enforcement of the council\\'s order and a declaration that the utility was entitled to a rate increase. The utility claimed that \"federal law required the Council to allow it to recover, through an increase in retail rates, its FERC-allocated share of the [cost of the reactor].\" Ibid.  The federal pre-emption question was the only issue raised in the case; there were no state law claims.\\nIn reversing the District Court\\'s decision to dismiss under Burford, we recognized \"the federal courts\\' discretion in determining whether to grant certain types of relief,\" 491 U. S., at 359, and we indicated, as we had previously in Alabama Pub. Serv. Comm\\'n v. Southern R. Co., 341 U. S. 341, 350-351 (1951), that Burford permits \"a federal court sitting in equity,\" 491 U. S., at 361, to dismiss a case only in extraordinary circumstances. We thus indicated that Burford allows a federal court to dismiss a case only if it presents \"`difficult questions of state law bearing on policy problems of substantial public import whose importance transcends the result in *727 the case then at bar,\\' \" or if its adjudication in a federal forum \"`would be disruptive of state efforts to establish a coherent policy with respect to a matter of substantial public concern.\\' \" 491 U. S., at 361 (quoting Colorado River, supra,  at 814).\\nWe ultimately held that Burford did not provide proper grounds for an abstention-based dismissal in NOPSI because the \"case [did] not involve a state-law claim, nor even an assertion that the federal claims [were] `in any way entangled in a skein of state law that must be untangled before the federal case can proceed,\\' \" 491 U. S., at 361 (quoting McNeese v. Board of Ed. for Community Unit School Dist. 187, 373 U. S. 668, 674 (1963)), and because there was no serious threat of conflict between the adjudication of the federal claim presented in the case and the State\\'s interest in ensuring uniformity in ratemaking decisions:\\n\"While Burford is concerned with protecting complex state administrative processes from undue federal influence, it does not require abstention whenever there exists such a process, or even in all cases where there is a `potential for conflict\\' with state regulatory law or policy. Here, NOPSI\\'s primary claim is that the Council is prohibited by federal law from refusing to provide reimbursement for FERC-allocated wholesale costs. Unlike a claim that a state agency has misapplied its lawful authority or has failed to take into consideration or properly weigh relevant state-law factors, federal adjudication of this sort of pre-emption claim would not disrupt the State\\'s attempt to ensure uniformity in the treatment of an `essentially local problem.\\' \" 491 U. S., at 362 (quoting Alabama Pub. Serv. Comm\\'n, supra, at 347) (citations omitted).\\nThese cases do not provide a formulaic test for determining when dismissal under Burford is appropriate, but they do demonstrate that the power to dismiss under the Burford *728 doctrine, as with other abstention doctrines, see supra, at 716-723 (describing the traditional application of the abstention doctrines), derives from the discretion historically enjoyed by courts of equity. They further demonstrate that exercise of this discretion must reflect \"principles of federalism and comity.\" Growe v. Emison, 507 U. S. 25, 32 (1993). Ultimately, what is at stake is a federal court\\'s decision, based on a careful consideration of the federal interests in retaining jurisdiction over the dispute and the competing concern for the \"independence of state action,\" Burford, 319 U. S., at 334, that the State\\'s interests are paramount and that a dispute would best be adjudicated in a state forum. See NOPSI, supra, at 363 (question under Burford is whether adjudication in federal court would \"unduly intrude into the processes of state government or undermine the State\\'s ability to maintain desired uniformity\"). This equitable decision balances the strong federal interest in having certain classes of cases, and certain federal rights, adjudicated in federal court, against the State\\'s interests in maintaining \"uniformity in the treatment of an `essentially local problem,\\' \" 491 U. S., at 362 (quoting Alabama Pub. Serv. Comm\\'n, supra, at 347), and retaining local control over \"difficult questions of state law bearing on policy problems of substantial public import,\" Colorado River, 424 U. S., at 814. This balance only rarely favors abstention, and the power to dismiss recognized in Burford represents an \"`extraordinary and narrow exception to the duty of the District Court to adjudicate a controversy properly before it.\\' \" Colorado River, supra, at 813 (quoting County of Allegheny, 360 U. S., at 188).\\n\\nC\\nWe turn, finally, to the application of Burford in this case. As in NOPSI, see 491 U. S., at 363, the federal interests in this case are pronounced, as Allstate\\'s motion to compel arbitration under the Federal Arbitration Act (FAA) implicates a substantial federal concern for the enforcement of arbitration *729 agreements. See Mitsubishi Motors Corp. v. Soler Chrysler-Plymouth, Inc., 473 U. S. 614, 631 (1985) (FAA reflects \"emphatic federal policy in favor of arbitral dispute resolution\"); cf. Moses H. Cone, 460 U. S., at 25-26 (in deciding whether to defer to state court adjudication under the Colorado River doctrine, \"the presence of federal-law issues must always be a major consideration weighing against surrender\"). With regard to the state interests, however, the case appears at first blush to present nothing more than a run-of-the-mill contract dispute. The Commissioner seeks damages from Allstate for Allstate\\'s failure to perform its obligations under a reinsurance agreement. What differentiates this case from other diversity actions seeking damages for breach of contract, if anything, is the impact federal adjudication of the dispute might have on the ongoing liquidation proceedings in state court: The Commissioner claims that any recovery by Allstate on its setoff claims would amount to an illegal \"preference\" under state law. This question appears now to have been conclusively answered by the California Supreme Court, see Prudential Reinsurance Co. v. Superior Court of Los Angeles Cty., 3 Cal. 4th 1118, 842 P. 2d 48 (1992) (permitting reinsurers to assert setoff claims in suits filed by the Commissioner in the Mission insolvency), although at the time the District Court ruled this question was still hotly contested.\\nThe Ninth Circuit concluded that the District Court\\'s remand order was inappropriate because \"Burford abstention does not apply to suits seeking solely legal relief.\" 47 F. 3d, at 354. Addressing our abstention cases, the Ninth Circuit held that the federal courts\\' power to abstain in certain cases is \"locat[ed] . . . in the unique powers of equitable courts,\" and that it derives from equity courts\\' \"`discretionary power to grant or withhold relief.\\' \" 47 F. 3d, at 355 (quoting Alabama Pub. Serv. Comm\\'n v. Southern R. Co., 341 U. S., at 350-351). The Ninth Circuit\\'s reversal of the District Court\\'s abstention\\x97based remand order in this case therefore *730 reflects the application of a per se rule: \"[T]he power of federal courts to abstain from exercising their jurisdiction, at least in Burford abstention cases, is founded upon a discretion they possess only in equitable cases.\" 47 F. 3d, at 355-356.\\nTo the extent the Ninth Circuit held only that a federal court cannot, under Burford, dismiss or remand an action when the relief sought is not discretionary, its judgment is consistent with our abstention cases. We have explained the power to dismiss or remand a case under the abstention doctrines in terms of the discretion federal courts have traditionally exercised in deciding whether to provide equitable or discretionary relief, see supra, at 717-719, 721-722, and the Commissioner appears to have conceded that the relief being sought in this case is neither equitable nor otherwise committed to the discretion of the court. See App. to Pet. for Cert. 35a\\x9737a (order denying petition for rehearing). In those cases in which we have applied traditional abstention principles to damages actions, we have only permitted a federal court to \"withhold action until the state proceedings have concluded,\" Growe, 507 U. S., at 32; that is, we have permitted federal courts applying abstention principles in damages actions to enter a stay, but we have not permitted them to dismiss the action altogether, see supra, at 719-721.\\nThe per se rule described by the Ninth Circuit is, however, more rigid than our precedents require. We have not strictly limited abstention to \"equitable cases,\" 47 F. 3d, at 356, but rather have extended the doctrine to all cases in which a federal court is asked to provide some form of discretionary relief. See Huffman, 319 U. S., at 297; Samuels, 401 U. S., at 69-70, 72-73; supra, at 718-719. Moreover, as demonstrated by our decision in Thibodaux, see supra, at 719\\x97 721, we have not held that abstention principles are completely inapplicable in damages actions. Burford might support a federal court\\'s decision to postpone adjudication of a damages action pending the resolution by the state courts *731 of a disputed question of state law. For example, given the situation the District Court faced in this case, a stay order might have been appropriate: The setoff issue was being decided by the state courts at the time the District Court ruled, see Prudential Reinsurance Co., supra, and in the interest of avoiding inconsistent adjudications on that point, the District Court might have been justified in entering a stay to await the outcome of the state court litigation.\\nLike the Ninth Circuit, we review only the remand order which was entered, and find it unnecessary to determine whether a more limited abstention-based stay order would have been warranted on the facts of this case. We have no occasion to resolve what additional authority to abstain might be provided under our decision in Fair Assessment,  see supra, at 719. Nor do we find it necessary to inquire fully as to whether this case presents the sort of \"exceptional circumstance\" in which Burford abstention or other grounds for yielding federal jurisdiction might be appropriate. Under our precedents, federal courts have the power to dismiss or remand cases based on abstention principles only where the relief being sought is equitable or otherwise discretionary. Because this was a damages action, we conclude that the District Court\\'s remand order was an unwarranted application of the Burford doctrine. The judgment is affirmed.\\nIt is so ordered. \\nJustice Scalia, concurring.\\nI join the opinion of the Court. I write separately only to respond to Justice Kennedy\\'s concurrence.\\nJustice Kennedy, while joining the opinion of the Court, says that he would \"not rule out . . . the possibility that a federal court might dismiss a suit for damages in a case where a serious affront to the interests of federalism could be averted in no other way,\" post, at 733. I would not have joined today\\'s opinion if I believed it left such discretionary *732 dismissal available. Such action is foreclosed, I think, by the Court\\'s holding, clearly summarized in the concluding sentences of the opinion: \"Under our precedents, federal courts have the power to dismiss or remand cases based on abstention principles only where the relief being sought is equitable or otherwise discretionary. Because this was a damages action, we conclude that the District Court\\'s remand order was an unwarranted application of the Burford  doctrine.\" Ante, at 731.\\nJustice Kennedy\\'s projected horrible of a \"serious affront to the interests of federalism\" cannot possibly materialize under the Court\\'s holding. There is no \"serious affront to the interests of federalism\" when Congress lawfully decides to pre-empt state action\\x97which is what our cases hold (and today\\'s opinion affirms) Congress does whenever it instructs federal courts to assert jurisdiction over matters as to which relief is not discretionary.\\nIf the Court today felt empowered to decide for itself when congressionally decreed jurisdiction constitutes a \"serious affront\" and when it does not, the opinion would have read much differently. Most pertinently, it would not have found it unnecessary \"to inquire fully as to whether this case presents the sort of `exceptional circumstance\\' in which Burford  abstention or other grounds for yielding federal jurisdiction might be appropriate.\" Ibid. There were certainly grounds for such an inquiry if we thought it relevant. The \"[then] unsettled but since resolved question of California law\" to which Justice Kennedy refers, post, at 733, was only part of the basis for the District Court\\'s decision to remand to state court; the court also pointed more generally to what it thought was the State\\'s \"overriding interest in regulating insurance insolvencies and liquidations in a uniform and orderly manner,\" App. to Pet. for Cert. 34a. As the Court\\'s opinion says, it is not necessary to inquire fully into that matter because this was a damages action.\\n*733 Justice Kennedy, concurring.\\nWhen this suit first was filed, it raised an unsettled but since resolved question of California law concerning the ability of companies in Allstate\\'s position to set off claims held against Mission. The principal reason for the District Court\\'s decision to dismiss the case was the threat posed to the state proceedings by different state and federal rulings on the question. The court\\'s concern was reasonable. States, as a matter of tradition and express federal consent, have an important interest in maintaining precise and detailed regulatory schemes for the insurance industry. See, e. g., the McCarran-Ferguson Act, 59 Stat. 33, as amended, 15 U. S. C. § 1011 et seq. The fact that a state court rather than an agency was chosen to implement California\\'s scheme provided more reason, not less, for the federal court to stay its hand.\\nAt the same time, however, we have not considered a case in which dismissal of a suit for damages by extension of the doctrine of Burford v. Sun Oil Co., 319 U. S. 315 (1943), was held to be authorized and necessary. As the Court explains, no doubt the preferred course in such circumstances is to resolve any serious potential for federal intrusion by staying the suit while retaining jurisdiction. We ought not rule out, though, the possibility that a federal court might dismiss a suit for damages in a case where a serious affront to the interests of federalism could be averted in no other way. We need not reach that question here.\\nAbstention doctrines are a significant contribution to the theory of federalism and to the preservation of the federal system in practice. They allow federal courts to give appropriate and necessary recognition to the role and authority of the States. The duty to take these considerations into account must inform the exercise of federal jurisdiction. Principles of equity thus are not the sole foundation for abstention rules; obligations of comity, and respect for the *734 appropriate balance between state and federal interests, are an important part of the justification and authority for abstention as well. See, e. g., id., at 334 (\"[A] sound respect for the independence of state action requires the federal equity court to stay its hand\"); Younger v. Harris, 401 U. S. 37, 44 (1971) (rooting abstention in \"a proper respect for state functions\" and \"sensitivity to the legitimate interests of both State and National Governments\"); Colorado River Water Conservation Dist. v. United States, 424 U. S. 800, 817 (1976) (abstention doctrines are based on \"considerations of proper constitutional adjudication and regard for federal-state relations\"). See also Shapiro, Jurisdiction and Discretion, 60 N. Y. U. L. Rev. 543, 551-552 (1985). The traditional role of discretion in the exercise of equity jurisdiction makes abstention easiest to justify in cases where equitable relief is sought, but abstention, including dismissal, is a possibility that may yet be addressed in a suit for damages, if fundamental concerns of federalism require us to face the issue.\\nWith these observations, I join the opinion of the Court.\\nNOTES\\n[*]   Richard Ruda and James I. Crowley filed a brief for the Council of State Governments et al. as amici curiae urging reversal.\\n\\nBriefs of amici curiae urging affirmance were filed for the Commonwealth of Massachusetts et al. by Scott Harshbarger, Attorney General of Massachusetts, and Thomas W. Rynard; for the National Association of Independent Insurers et al. by Charles Platto and Phillip Stano; and for the Reinsurance Association of America et al. by Maureen E. Mahoney. \\n'}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_dataset = interleave_datasets(streaming_datasets)\n",
        "combined_dataset = combined_dataset.skip(10001)\n",
        "next(iter(combined_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73jtIJvP__dj",
        "outputId": "b00d42e0-6a16-4b7c-9e1f-acdaa93874be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:datasets.builder:Using custom data configuration default-6e3092816c4f845b\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.builder:Using custom data configuration default-a1d9e8eaedd958cd\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n",
            "INFO:datasets.builder:Using custom data configuration default-de993bbf5aabe685\n",
            "INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-cb7569a16fd5>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# streaming datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdatasets_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_streaming_mlm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_streaming_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-cb7569a16fd5>\u001b[0m in \u001b[0;36mprocess_streaming_mlm_data\u001b[0;34m(data_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# combine the datasets to stream together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     datasets_combined = interleave_datasets(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mdatasets_to_stream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mstopping_strategy\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'all_exhausted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/combine.py\u001b[0m in \u001b[0;36minterleave_datasets\u001b[0;34m(datasets, probabilities, seed, info, split, stopping_strategy)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         return _interleave_iterable_datasets(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopping_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_interleave_iterable_datasets\u001b[0;34m(datasets, probabilities, seed, info, split, stopping_strategy)\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[0;32m-> 2309\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;31m# Perform checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[0;32m-> 2309\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;31m# Perform checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_resolve_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex_iterable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_features_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_head\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_examples_to_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_effective_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m                 \u001b[0;31m# `IterableDataset` automatically fills missing columns with None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle_data_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"TakeExamplesIterable\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mArrowExamplesIterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_arrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                         \u001b[0;32mdel\u001b[0m \u001b[0mtransformed_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'meta'"
          ]
        }
      ],
      "source": [
        "## Need a function to randomly\n",
        "# ... function takes the first 5000 entries as the dev set\n",
        "# ... then skips 5000 to make the starting position for the train set\n",
        "# ... then randomly takes another start position to cycle trhough all the data\n",
        "# ... then what? Hardens it and converts it into 512 chunks? filters out small segments (<200)\n",
        "data_files_streaming = [\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\",\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst\",\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", # ledgar worked\n",
        "\n",
        "]\n",
        "dataset_probabilities = [\n",
        "    14.40,\n",
        "    6.12,\n",
        "    6\n",
        "]\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files_streaming,\n",
        "    'val_size':10000,\n",
        "    'min_seq_length':200,\n",
        "    'max_seq_length':512,\n",
        "    'dataset_probabilities':dataset_probabilities\n",
        "}\n",
        "\n",
        "def nwords(sentence):\n",
        "    return len([w for w in sentence.split(' ') if len(w)>0])\n",
        "\n",
        "def process_streaming_mlm_data(data_config):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "    if data_config['dataset_probabilities'] is not None:\n",
        "        dataset_probabilities = [a/sum(data_config['dataset_probabilities']) for a in data_config['dataset_probabilities']]\n",
        "    else:\n",
        "        dataset_probabilities = [1.0/len(data_config['files']) for _ in range(len(data_config['files']))]\n",
        "\n",
        "    # concatenate list of streaming datasets\n",
        "    datasets_to_stream = []\n",
        "    for file_to_stream in data_config['files']:\n",
        "        dataset_to_stream = load_dataset(\"json\", data_files=file_to_stream, split=\"train\", streaming=True)\n",
        "        datasets_to_stream.append(dataset_to_stream.remove_columns(\"meta\"))\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy ='all_exhausted',\n",
        "        probabilities = dataset_probabilities\n",
        "    )\n",
        "    return datasets_combined\n",
        "\n",
        "# streaming datasets\n",
        "datasets_combined = process_streaming_mlm_data(data_streaming_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_9jBxe3_PEQ"
      },
      "outputs": [],
      "source": [
        "if True:\n",
        "\n",
        "    # make the dev set\n",
        "    datastream_for_dev = datasets_combined.take(data_config['val_size'])\n",
        "\n",
        "    # now what? harden the set?\n",
        "    dataslist_for_dev = list(datastream_for_dev)\n",
        "\n",
        "    # reject any sentences less thatn data_config['min_sentence_size]\n",
        "    dataslist_for_dev = [s['text'] for s in dataslist_for_dev if nwords(s['text']) > data_config['min_seq_length']]\n",
        "\n",
        "    # maybe use line by line\n",
        "    #dataset = LineByLineTextDataset(tokenizer=tokenizer, examples=openwebtext_dataset, block_size = 512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx8n9Ht1mow1"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Need a function to randomly\n",
        "# ... function takes the first 5000 entries as the dev set\n",
        "# ... then skips 5000 to make the starting position for the train set\n",
        "# ... then randomly takes another start position to cycle trhough all the data\n",
        "# ... then what? Hardens it and converts it into 512 chunks? filters out small segments (<200)\n",
        "data_files_streaming = [\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\",\n",
        "    \"https://the-eye.eu/public/AI/pile_preliminary_components/FreeLaw_Opinions.jsonl.zst\",\n",
        "    \"https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019.jsonl.zip\", # ledgar worked\n",
        "\n",
        "]\n",
        "dataset_probabilities = [\n",
        "    14.40,\n",
        "    6.12,\n",
        "    6\n",
        "]\n",
        "\n",
        "data_streaming_config = {\n",
        "    'files':data_files_streaming,\n",
        "    'val_size':10000,\n",
        "    'min_seq_length':200,\n",
        "    'max_seq_length':512,\n",
        "    'dataset_probabilities':dataset_probabilities\n",
        "}\n",
        "\n",
        "def nwords(sentence):\n",
        "    return len([w for w in sentence.split(' ') if len(w)>0])\n",
        "\n",
        "def process_streaming_mlm_data(data_config):\n",
        "    \"\"\"Creates dev-set and a random chunk for training set from a massive streaming dataset (pile)\"\"\"\n",
        "    if data_config['dataset_probabilities'] is not None:\n",
        "        dataset_probabilities = [a/sum(data_config['dataset_probabilities']) for a in data_config['dataset_probabilities']]\n",
        "    else:\n",
        "        dataset_probabilities = [1.0/len(data_config['files']) for _ in range(len(data_config['files']))]\n",
        "\n",
        "    # concatenate list of streaming datasets\n",
        "    datasets_to_stream = []\n",
        "    for file_to_stream in data_config['files']:\n",
        "        dataset_to_stream = load_dataset(\"json\", data_files=file_to_stream, split=\"train\", streaming=True)\n",
        "        datasets_to_stream.append(dataset_to_stream.remove_columns(\"meta\"))\n",
        "\n",
        "    # combine the datasets to stream together\n",
        "    datasets_combined = interleave_datasets(\n",
        "        datasets_to_stream,\n",
        "        stopping_strategy ='all_exhausted',\n",
        "        probabilities = dataset_probabilities\n",
        "    )\n",
        "    return datasets_combined\n",
        "\n",
        "# streaming datasets\n",
        "datasets_combined = process_streaming_mlm_data(data_streaming_config)\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MLMDataset(Dataset):\n",
        "    \"\"\"Do I want to pre-tokenize? If so, then the Collator will call .pad\"\"\"\n",
        "    def __init__(self, input_text, tokenizer, max_seq_length=512, min_seq_length=200):\n",
        "        self.data = []\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        for text in input_text:\n",
        "            word_count = nwords(text)\n",
        "            if word_count <= self.max_seq_length and word_count >= self.min_seq_length:\n",
        "                self.data.append(text)\n",
        "            elif word_count > self.max_seq_length:\n",
        "                text_split = text.split(\" \")\n",
        "                chunks = [\n",
        "                    text_split[i:i+self.max_seq_length] for i in range(0, word_count, 512)\n",
        "                ]\n",
        "                chunks = [\" \".join(s) for s in chunks if len(s)>=self.min_seq_length]\n",
        "                self.texts.extend(chunks)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRTYXoMV8TMY"
      },
      "outputs": [],
      "source": [
        "dataset_mlm_val = MLMDataset(texts = dataslist_for_dev, max_seq_length=data_config['max_seq_length'], min_seq_length=data_config['min_seq_length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw10KVdO8-54"
      },
      "outputs": [],
      "source": [
        "from transformers.data.data_collator import DataCollatorForLanguageModeling, Mapping\n",
        "collator_mlm = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm = True,\n",
        "    pad_to_multiple_of = 4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcvv6EivJjhW",
        "outputId": "8554a017-5386-4013-cf01-7e2cbb884832"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataslist_for_dev[7].split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bp5xbiSoqT0"
      },
      "outputs": [],
      "source": [
        "# Example of loading multiple datasets\n",
        "if False:\n",
        "    from datasets import load_dataset\n",
        "\n",
        "    # Download Wikipedia dataset\n",
        "    wikipedia_dataset = load_dataset('wikipedia', '20200501.en', split='train')\n",
        "\n",
        "    # Download OpenWebText dataset\n",
        "    openwebtext_dataset = load_dataset('openwebtext', split='train')\n",
        "\n",
        "    # Download BookCorpus dataset\n",
        "    bookcorpus_dataset = load_dataset('bookcorpus', split='train')\n",
        "\n",
        "    # Preprocess and tokenize the datasets\n",
        "    from transformers import BertTokenizer\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        return tokenizer(examples['text'], truncation=True, padding='max_length')\n",
        "\n",
        "    wikipedia_dataset = wikipedia_dataset.map(preprocess_function, batched=True)\n",
        "    openwebtext_dataset = openwebtext_dataset.map(preprocess_function, batched=True)\n",
        "    bookcorpus_dataset = bookcorpus_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "    # Combine the datasets\n",
        "    combined_dataset = wikipedia_dataset.concatenate(openwebtext_dataset)\n",
        "    combined_dataset = combined_dataset.concatenate(bookcorpus_dataset)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    combined_dataset = combined_dataset.shuffle()\n",
        "\n",
        "    # Split the dataset into training and validation sets\n",
        "    train_dataset = combined_dataset.train_test_split(test_size=0.1)['train']\n",
        "    val_dataset = combined_dataset.train_test_split(test_size=0.1)['test']\n",
        "\n",
        "    # Convert the datasets to PyTorch tensors\n",
        "    train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "    val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "    # Print some examples from the dataset\n",
        "    print(train_dataset[:5])\n",
        "    print(val_dataset[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "5d6d6c79117c4418ae920f3a3933ce8c",
            "c226f3cbc6c741749fdd62c73e6800c6",
            "66dffa1174af472cb6b6f7cdbb99d81a",
            "4dbe3181aa2f4fed8c105e0175bdf9a6",
            "849e8f1cbf6346eca2ec181e13ceb2b8",
            "ba8a7860db844d0e869d8d77c6e18d83",
            "9e4b3e23a0d94fbdace001eef383c56a",
            "69cf10a71fae487f8f1cc913f9214c98",
            "fe784053e3d047758731e6f99283d772",
            "6584e12814444c46be4fc1107d52b0ec",
            "d390110fecc7409291f79bc41e3e7c19",
            "037af811550e4536938e1fc2b2f60729",
            "c7255329fcf94a7dade2742f7407d41c",
            "db7e607a483e49d78b3c9491464490b5",
            "6e7c559006d24081b1ae338d3f443a8b",
            "c86fedd6bd374d4586e51c030cbfea1b",
            "7b56936ebd914109a0d5546c65fff0b3",
            "5b92dc1fae394c1f98221dc9762f5779",
            "24ab213f928c43b0a6fb840c03ec05a7",
            "677c94eab4d04efaba8770b32b6e82d5",
            "efb59704b56142dc82b819e7828ccaf4",
            "9d20832d687b4fe6bc280d912d203013"
          ]
        },
        "id": "5RkpXr8doqRX",
        "outputId": "87184feb-6e88-422f-c8fa-86628b00fcb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset openwebtext/plain_text to /root/.cache/huggingface/datasets/openwebtext/plain_text/1.0.0/6f68e85c16ccc770c0dd489f4008852ea9633604995addd0cd76e293aed9e521...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d6d6c79117c4418ae920f3a3933ce8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "037af811550e4536938e1fc2b2f60729",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset openwebtext downloaded and prepared to /root/.cache/huggingface/datasets/openwebtext/plain_text/1.0.0/6f68e85c16ccc770c0dd489f4008852ea9633604995addd0cd76e293aed9e521. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6f8f1a0a520a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# openwebtext_dataset = datasets.load_dataset('openwebtext') full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mopenwebtext_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openwebtext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'train[:{subset_size}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mis_small_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m     )\n\u001b[0;32m-> 1810\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m     \u001b[0;31m# Rename and cast features to match task schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# Create a dataset for each of the given splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         datasets = map_nested(\n\u001b[0m\u001b[1;32m   1146\u001b[0m             partial(\n\u001b[1;32m   1147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_single_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mdisable_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_tqdm\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_progress_bar_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, in_memory)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# Build base dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         ds = self._as_dataset(\n\u001b[0m\u001b[1;32m   1176\u001b[0m             \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[0;34m(self, split, in_memory)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \"\"\"\n\u001b[1;32m   1245\u001b[0m         \u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strip_protocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m         dataset_kwargs = ArrowReader(cache_dir, self.info).read(\n\u001b[0m\u001b[1;32m   1247\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0minstructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, name, instructions, split_infos, in_memory)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Instruction \"{instructions}\" corresponds to no data!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mget_file_instructions\u001b[0;34m(self, name, instruction, split_infos)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_file_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;34m\"\"\"Return list of dict {'filename': str, 'skip': int, 'take': int}\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         file_instructions = make_file_instructions(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiletype_suffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filetype_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mmake_file_instructions\u001b[0;34m(name, split_infos, instruction, filetype_suffix, prefix_path)\u001b[0m\n\u001b[1;32m    126\u001b[0m     }\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Create the absolute instruction (per split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mabsolute_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname2len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mfrom_spec\u001b[0;34m(cls, spec)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No instructions could be built out of {spec}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_str_to_read_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_str_to_read_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36m_str_to_read_instruction\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SUB_SPEC_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized instruction format: {spec}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_pct\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"to_pct\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"abs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     return ReadInstruction(\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized instruction format: train[:0.03]"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling\n",
        "import datasets\n",
        "# openwebtext_dataset = datasets.load_dataset('openwebtext') full dataset\n",
        "#openwebtext_dataset = datasets.load_dataset('openwebtext', split=f'train[:{0.03}]') # doesn't work\n",
        "\n",
        "pubmed_dataset_streamed = load_dataset(\n",
        "    \"json\", data_files=data_files, split=\"train\", streaming=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Mw-H31ooqNS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "dataset = LineByLineTextDataset(tokenizer=tokenizer, examples=openwebtext_dataset, block_size = 512)\n",
        "\n",
        "# Create a subset of the dataset with the desired number of samples\n",
        "subset_dataset = Subset(dataset, range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMawKzdFoqDj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "b6b5640287e64eaaa8d910072ea8a49b",
            "ec12f15c6abf453abab53377bc2e9ba7",
            "58221644a9f040cbaf0377564f066623",
            "c0ff005b169d428ba1930ab99f2ad5e2",
            "bc918c49557c428da985c29669a4ef59",
            "1a63b32a25944a0d9b407d8e113cc473",
            "39465c30a6d846f2a78d4016152041e4",
            "e46716dcab7c4e5f8477931b7e12ea6a",
            "80c9e2fa3d1d42f88f42e35e01cbfdc3",
            "328dedc4b7db45738e274196f66dabc6",
            "32d19b7f1d224f9fb2a0f2518c02e5bd"
          ]
        },
        "id": "w_Zygln6aW0G",
        "outputId": "7fa96ebc-005d-4064-db46-0de29d06e45f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6b5640287e64eaaa8d910072ea8a49b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "basemodelLM = AutoModelForMaskedLM.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gqsw72LkUAi",
        "outputId": "8bbcdefa-6be1-4c62-becc-529278f88a93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 512)\n",
              "      (token_type_embeddings): Embedding(2, 512)\n",
              "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-3): 4 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basemodelLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "f90ae6d8c7e94e7a970a5b50c7721618",
            "12472278f82a48cfb84182a57092617e",
            "28118200f74e4935b8e87af4a20034c8",
            "4fc404853fe84976afd7674ab97d1533",
            "4617c5d3e4df42fe8e6d5220c94e443f",
            "800359cf35c04fb08fffcfe9de625e54",
            "a5adffec44744a10b0ac45f73eba6058",
            "7936aeb365f44e9685dce4015da9d5e9",
            "3dd36967afcc40329fcb44b346fdeebc",
            "eb77d7017bbd48f6937c38c219acc095",
            "666b0b8c335b4905baaf810735d244c9",
            "ca51f90211e14e13902200d819bfe447",
            "07b52d5502284df5b12b39c47d107310",
            "9cbd7c17733a4b01b8717c98c41ffee4",
            "ce050a2ed895498dba3347c1c4bb092d",
            "dbb5a92189d34f4d8571106c29dee036",
            "8e347cd029c24f57b55467966708d0eb",
            "743ba3957fde4d10935f4089f4da9aad",
            "c927ee3e4fa84190a00a29aea856bef8",
            "6c200c3e72394f20a570f130a707e9ad",
            "a94a510c49414b75818b4c1654394703",
            "6b62d7166e614b6ead8a0af96758cef1",
            "61455bbef8d645ec991263a9dfe13410",
            "5c1b6064c01a4f3981fe47abf757d31c",
            "c03bdfe1869d45a28466a072aa408ae0",
            "172cde34c43d40a68e2b80fad3ded0f4",
            "4b184b86f7814565936c60466ee24b32",
            "cd116c11c9cc4b56ab67ebc8649767bf",
            "562dc2a8529f4836b9afe3fcb405b27e",
            "16b987c8b2b449248ff874bc78eb39c5",
            "cb402bb1c4e14e859d55089494954a79",
            "2938bb3525c440efaec111b271dac957",
            "aad70e180d49469ca01ecfd84eb2225d"
          ]
        },
        "id": "UBP8eW-SE4Xh",
        "outputId": "ee9b721b-2b4a-47eb-a015-22ad58969e80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f90ae6d8c7e94e7a970a5b50c7721618",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca51f90211e14e13902200d819bfe447",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61455bbef8d645ec991263a9dfe13410",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['delivery', 'for', 'ex', '##w', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'reduce', 'all', 'risk', 'and', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'delivery', 'carrier', '.', 'is']\n",
            "['.', 'for', 'ex', 'works', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'assume', 'all', 'risk', ',', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'responsible', 'carrier', '.', '.']\n"
          ]
        }
      ],
      "source": [
        "## try to grab a MLM classification head\n",
        "## let's verify they have the same vocabulary\n",
        "# models from: https://arxiv.org/pdf/1908.08962.pdf\n",
        "from transformers import AutoModelForMaskedLM, AutoConfig\n",
        "modelstring_base = \"google/bert_uncased_L-12_H-512_A-8\" #\n",
        "modelstring_base = \"google/bert_uncased_L-4_H-512_A-8\"\n",
        "#modelstring_base = 'google/bert_uncased_L-6_H-512_A-8'\n",
        "basemod = AutoModelForMaskedLM.from_pretrained(modelstring_base)\n",
        "basemod_tokenizer = AutoTokenizer.from_pretrained(modelstring_base)\n",
        "# the minatoure googles have a vocab size of: 30522\n",
        "\n",
        "modelstring_lg = 'bert-large-uncased' # I think the google-team used this for the miniature models\n",
        "# bert-large uncased has a vocab size of: 30522\n",
        "#modelstring_lg = \"google/bert_uncased_L-12_H-768_A-12\"\n",
        "largmod = AutoModelForMaskedLM.from_pretrained(modelstring_lg) #\n",
        "largmod_tokenizer = AutoTokenizer.from_pretrained(modelstring_lg)#\"google/bert_uncased_L-12_H-768_A-12\")\n",
        "\n",
        "\n",
        "# note: which datasets used to train large\n",
        "# wikipedia\n",
        "# bookcorpus\n",
        "# ... but seem more about datasets and models from: https://arxiv.org/pdf/1908.08962.pdf\n",
        "\n",
        "\n",
        "text = \"For Ex Works (EXW) terms, the Supplier will [MASK] all risk and liability for the Delivered [MASK] up until delivering the goods to the nominated Carrier.\"\n",
        "with torch.no_grad():\n",
        "    inputs1 = basemod_tokenizer(text, return_tensors='pt')\n",
        "    outputs1 = basemod(**inputs1)\n",
        "    preds1 = outputs1.logits\n",
        "    inputs2 = largmod_tokenizer(text, return_tensors='pt')\n",
        "    outputs2 = largmod(**inputs2)\n",
        "    preds2 = outputs2.logits\n",
        "\n",
        "    assert (inputs1['input_ids']-inputs2['input_ids']).sum()==0, 'ids are different'\n",
        "\n",
        "    predicted_token_ids1 = preds1[0].argmax(dim=-1)\n",
        "    predicted_token_ids2 = preds2[0].argmax(dim=-1)\n",
        "\n",
        "    print(basemod_tokenizer.convert_ids_to_tokens(predicted_token_ids1))\n",
        "    print(basemod_tokenizer.convert_ids_to_tokens(predicted_token_ids2))\n",
        "\n",
        "\n",
        "# confirmation: the minature berts and the"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEOZ6zRDKivA",
        "outputId": "1f15aaa6-aa45-41a5-b0f4-24e249ecb81b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'for', 'ex', '##w', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'cover', 'all', 'risk', 'and', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'delivered', 'carrier', '.', '.']\n",
            "['.', 'for', 'ex', 'works', '(', 'ex', '##w', ')', 'terms', ',', 'the', 'supplier', 'will', 'assume', 'all', 'risk', ',', 'liability', 'for', 'the', 'delivered', 'goods', 'up', 'until', 'delivering', 'the', 'goods', 'to', 'the', 'responsible', 'carrier', '.', '.']\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUkcyKo7Mos3",
        "outputId": "64c43793-b93c-47f6-e7e4-4af099fd7f96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1996,  2005,  4654,  2860,  1006,  4654,  2860,  1007,  3408,  1010,\n",
              "         1996, 17024,  2097,  3104,  2035,  3891,  1998, 14000,  2005,  1996,\n",
              "         5359,  5350,  2039,  2127, 12771,  1996,  5350,  2000,  1996,  5359,\n",
              "         6839,  1012,  1012])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_token_ids1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr6SQ5lNMXgG",
        "outputId": "c027ad64-87f8-40d9-b672-a6e04f81fd81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs1['input_ids']-inputs2['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gal1ffFFAXn",
        "outputId": "1cd3d0ce-585c-48aa-ac94-9695056265a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertOnlyMLMHead(\n",
              "  (predictions): BertLMPredictionHead(\n",
              "    (transform): BertPredictionHeadTransform(\n",
              "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (transform_act_fn): GELUActivation()\n",
              "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): Linear(in_features=512, out_features=30522, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basemod._modules['cls']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1on2GfKsWjxJ",
        "outputId": "7736eb78-5fff-4707-8355-544b3681e846"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/bert_uncased_L-12_H-512_A-8 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "config = make_config('google/bert_uncased_L-12_H-512_A-8') #\n",
        "\n",
        "# make the basemod and tokenizer\n",
        "basemod = AutoModel.from_pretrained(config.model_string)\n",
        "basemod.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3sw0PbVXu8c"
      },
      "outputs": [],
      "source": [
        "anathem_encoder1 = AnathemBaseModule(config, basemod, tokenizer)\n",
        "anathem_encoder2 = AnathemMidModule(config, basemod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gaew7zT4XVQz",
        "outputId": "b1547ee9-319c-4290-d9d9-ec88883f959b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2566087245941162\n"
          ]
        }
      ],
      "source": [
        "time1 = time.time()\n",
        "for iteration, batch in enumerate(tqdm(dl_train, disable=True)):\n",
        "    if iteration>30:\n",
        "        time2 = time.time()\n",
        "        print(time2-time1)\n",
        "        break\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenize_anathem(batch['text'])\n",
        "        (hidden_states, extended_attention_masks) = anathem_encoder1(\n",
        "            input_ids = tokens['input_ids'],\n",
        "            attention_mask = tokens['attention_mask'],\n",
        "            token_type_ids = tokens['token_type_ids']\n",
        "        )\n",
        "        features,_ = anathem_encoder2(\n",
        "            hidden_states_highres = hidden_states[0],\n",
        "            hidden_states_midres = hidden_states[1],\n",
        "            hidden_states_lowres = hidden_states[2],\n",
        "            extended_attention_mask_highres = extended_attention_masks[0],\n",
        "            extended_attention_mask_midres = extended_attention_masks[1],\n",
        "            extended_attention_mask_lowres = extended_attention_masks[2]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_90_OeZ8YaQ7"
      },
      "outputs": [],
      "source": [
        "# the new method takes: 3.198051929473877 / 200 iterations (I can't really te)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNupLa7q4YkDEe/2jfyvmQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00001f9f055045f9ae35f94f76be8fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16dd57325504698b35f155d1bd040b5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7950d803ab5b4c4ab10dc9e0902e34b1",
            "value": 1
          }
        },
        "0003c5e497294b5abf83ff5edbf90261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28542ed3d1b443c9a7ba7074825ee208",
              "IPY_MODEL_7c01fc1aabb0486f9f1f0674b46b5481",
              "IPY_MODEL_6b349f8f7890488eaa05b156ec971bf6"
            ],
            "layout": "IPY_MODEL_1602c7712db64b829a6ed1fa73367a1e"
          }
        },
        "000f6133e191461c893cffdc6783a5f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "00c7829ca16746089c8896865f374b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ef066e53974658a59443c917b2c615",
            "placeholder": "​",
            "style": "IPY_MODEL_98bd45b05dda4319adf853b5104f0a0a",
            "value": " 1725/1725 [00:00&lt;00:00, 3472.08 examples/s]"
          }
        },
        "01ac22caf29c4b2baf0ebc428f3398b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01bc3f5cd2ec4435b5a97c1dbbe7a86e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f4a70e089f4fe5abb0d9246aeee403": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01fa51a473a6472da89d47bf1116e575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02191a5509094a0abcf8862d3a8ee4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029adddbce024f50bc5d7a06d304632d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0322aeeda2bd42c1b8ce348bd56424eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5398b51140574840979cfe9ae2640c96",
            "placeholder": "​",
            "style": "IPY_MODEL_d6012c2d60024501a1bd8c529bf055e6",
            "value": "Generating validation_matched split:  99%"
          }
        },
        "037af811550e4536938e1fc2b2f60729": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7255329fcf94a7dade2742f7407d41c",
              "IPY_MODEL_db7e607a483e49d78b3c9491464490b5",
              "IPY_MODEL_6e7c559006d24081b1ae338d3f443a8b"
            ],
            "layout": "IPY_MODEL_c86fedd6bd374d4586e51c030cbfea1b"
          }
        },
        "0381ff6309df4052bb0ce823e7ff741b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a6cc127c8c4f03bab0b31bb3a1721b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ccd976679e45fcbf6d6b5d06360ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_f6c454dc6dcb4528b7b05b83c72640fc",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "03a8f530cfb0469998f56dcca5f00803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cafc757655d74a2697f4ba566b3623ee",
              "IPY_MODEL_46cd1079cad04e7ea04959e14225b7fb",
              "IPY_MODEL_c508e67d54c24888b82b66108681da19"
            ],
            "layout": "IPY_MODEL_b08eba43d39846869bdd9050836be1cb"
          }
        },
        "0457dfcb462c4173bbfb7890bb043c97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0491c321ae9344ff98592968423dccd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f9c6c1ac8a4eec97466e0f2108ce39",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea3b3bc369804d85b562e7b83bc34804",
            "value": 1
          }
        },
        "04db53bae1ea4e81a1acbad7401cd331": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81afc2262c8545dab41aacde91066b7d",
              "IPY_MODEL_b96a361475c947e5a0f9e5f0f867ced7",
              "IPY_MODEL_f697e928e02f405d99c43c4b1fd890c9"
            ],
            "layout": "IPY_MODEL_6da885f236a24cf5a09add7c9927db76"
          }
        },
        "052465580f854b15be0d29e9dc59125b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05fd99843ed746d1baf705e6c31881f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0787d9b7b9c649c9a8a70dd37d645a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2dfbd412e2c4420931223730a476148",
            "placeholder": "​",
            "style": "IPY_MODEL_9977be2298704813a37ed7c23e31d840",
            "value": "Generating validation split: "
          }
        },
        "07b52d5502284df5b12b39c47d107310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e347cd029c24f57b55467966708d0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_743ba3957fde4d10935f4089f4da9aad",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "08187ae67b63489bba4a7b9c10d4d719": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c60bb508854cc9b6772ab78502b6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497aad7b9ab34f158382033f65d9a8c9",
            "placeholder": "​",
            "style": "IPY_MODEL_814c0fc7e64c49bfa85d5087d1e07cb4",
            "value": " 383/383 [00:00&lt;00:00, 8.70kB/s]"
          }
        },
        "08fbdead6ab540d4a1d2d8f06879e417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029adddbce024f50bc5d7a06d304632d",
            "max": 314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a8de725a934927b52792351e0d5099",
            "value": 314
          }
        },
        "09a93d25cd25426e9c60222b29321889": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a024ed7f3514fd6a544804a8bee0d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a320f7b8bba47ddb97d2aff966e162f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0c4175d283414ab014c95269b4421b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17a0dd6bd24481e8e597415bfc02c87",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c43b4c9b58842acaf321862c3a1625d",
            "value": 1725
          }
        },
        "0cbd831de3c64f4aa269776dc73c5e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4848184b58645b2a572c6e1a1231f05",
            "placeholder": "​",
            "style": "IPY_MODEL_92d450929c8e45539c2726eaf96d5ddb",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "0db15040be1242378220fa56a21aba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e215f7f87fc48bfbb3e74c9c97b23a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ea16b4f2c6d428191dd7d31d21ad659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f331a136adf425f87a1a35682256cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f2289d8f6c460892864f1ef5ad8e08",
            "max": 392702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f81a1dd1a8b547b39297478219b41c81",
            "value": 392702
          }
        },
        "1034a93ce59f439bb128b6c096eefdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c225230ea12f4f90bd461485f300580e",
            "placeholder": "​",
            "style": "IPY_MODEL_4d3b7432f11a4a4b9eb444743d158c0d",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "11a1247638b6426c961fa4705dc85fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11db36da26a94bae9ad00e99a10d8c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5323c16a9ca4decbe25c651a14517de",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb0aa78ac5ed4e8189871f2dcb7b68d0",
            "value": 408
          }
        },
        "12371b67bb334b2786c3809702b7bac7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "12472278f82a48cfb84182a57092617e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_800359cf35c04fb08fffcfe9de625e54",
            "placeholder": "​",
            "style": "IPY_MODEL_a5adffec44744a10b0ac45f73eba6058",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "1290569b6a4d490fbfc8ca3915983263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1602c7712db64b829a6ed1fa73367a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "16501e0f5de84fc7bbbdcc9b37f61d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1672001c1d7e449f9cc0ce76fcf50fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "169e8fa7a73d4797945e98ccba4cd10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b072faf11c504e39939d1ad4534f9112",
              "IPY_MODEL_f3707c74969e4f6c84d6a36b59d6fa9e",
              "IPY_MODEL_32184fc9b099416a8d49ef3c3f8c3a2e"
            ],
            "layout": "IPY_MODEL_2b95b44611524401ac7826dab5a21aa8"
          }
        },
        "16b987c8b2b449248ff874bc78eb39c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172cde34c43d40a68e2b80fad3ded0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2938bb3525c440efaec111b271dac957",
            "placeholder": "​",
            "style": "IPY_MODEL_aad70e180d49469ca01ecfd84eb2225d",
            "value": " 232k/232k [00:00&lt;00:00, 5.34MB/s]"
          }
        },
        "177dee7aa0754c7db2b595f83a4eb105": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "195b549a3cd745ffbe55e24f5865b1da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e70f5c3ae04d4b8b4a86c1233418be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7fcfc2727db445695b908ffd3370feb",
              "IPY_MODEL_546b278b05e643a4905055d1d7ffeea5",
              "IPY_MODEL_289aa49d154a496d9804cf30545bc5fc"
            ],
            "layout": "IPY_MODEL_f54be5e820704ad2b31b6b7a6b946181"
          }
        },
        "1a3234bae89d4c1eb7e84da16675cde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c50e41b12ab40ae88db5a68806a5287",
              "IPY_MODEL_9a675022c08043438f0288c2dc3d1692",
              "IPY_MODEL_42ed4267878a46a9a1a1de7f63006ab4"
            ],
            "layout": "IPY_MODEL_a587d42c581c4f75984a189ebe1b1831"
          }
        },
        "1a63b32a25944a0d9b407d8e113cc473": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7dd0c3112945959e9908425fcaa8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1aea1f6de91a43a4b491c82ffc1522be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c00f260ca44415c9c2cc342c9cab470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c5678cdeb204d21b94526ccdab34d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0381ff6309df4052bb0ce823e7ff741b",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd79d8ce5e28404c988f4965873a2f2c",
            "value": 440449768
          }
        },
        "1d322e088a6a4904a0b99740d8d4e45c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d567e39c5ac4b9f8d9908111b04100f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1deae35c0489408fa7e374cd93cca642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7d06e9df9b4a88a003bbba433c1cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d151de5a1862426f9d3ab2aaae73f4d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3963ddae09b14417abf20a566ce82a03",
            "value": " 441k/? [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "1eb78591c14840daaf6741730f2280f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f65726d2e20471e99928e5dc96726c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454aeb5a95b94bb580698d8d2f62f43f",
            "placeholder": "​",
            "style": "IPY_MODEL_a417b74f6fdb4dedbd6bf3408d0dea69",
            "value": " 392000/392702 [01:52&lt;00:00, 7530.77 examples/s]"
          }
        },
        "20402646761d4cf3975763fc130d6ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20ae65dc26cb4ab98a9637dfa2bd5a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2137d76adc0b4235bcf4e52ab94ae445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2166426a7a224f1da2065f3221463693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216e1650231e471fa0d88e3d73bf6da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2bbd67afcb9463cb0f78d7a24c5f126",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9c165248ef4e0b9c357316b95f66af",
            "value": "Downloading data: "
          }
        },
        "21f6c046574b4badbf5dac2bd4989d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235afab600844a9f8ef8f45cdba142e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ab213f928c43b0a6fb840c03ec05a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e977d511bd4f03bc8d730cd4c86027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2b4543fdb94a1d9153de7f18d108be",
            "placeholder": "​",
            "style": "IPY_MODEL_da3eb201a16240aaa91baf19b49d4209",
            "value": " 5.14k/5.14k [00:00&lt;00:00, 173kB/s]"
          }
        },
        "251219f28bd54de9a608686672dddf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e61f641028148e988678a2ecbe24a21",
            "placeholder": "​",
            "style": "IPY_MODEL_df8de4914b3f4c51b4e048f053a0e009",
            "value": " 9703/9815 [00:01&lt;00:00, 7528.70 examples/s]"
          }
        },
        "260f38a6c52d464999f74443c04cdc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2750de9a4c5740b080f5a8145de41111": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28118200f74e4935b8e87af4a20034c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7936aeb365f44e9685dce4015da9d5e9",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dd36967afcc40329fcb44b346fdeebc",
            "value": 383
          }
        },
        "282f350bdadd41fa82b37f527ffe8a63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283065bbec654b89a6be726e3fe790fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28542ed3d1b443c9a7ba7074825ee208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72812af3cd8475f8a76a8ff3ec236e9",
            "placeholder": "​",
            "style": "IPY_MODEL_40731cc8e1a245868c9bf6d0972c0467",
            "value": "Map: 100%"
          }
        },
        "289aa49d154a496d9804cf30545bc5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c0e136fa3f400bab5deec7a0aff11f",
            "placeholder": "​",
            "style": "IPY_MODEL_bcee86d4105743f5a69c595029994bc8",
            "value": " 116M/116M [00:03&lt;00:00, 35.9MB/s]"
          }
        },
        "292c0b150eb84f06a012e2084b035350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2938bb3525c440efaec111b271dac957": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2958b232a65d47d7950e040ddd583898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82db512ae4ce4b1fbde3aed3d893e032",
              "IPY_MODEL_8b3982acce834b95a6f318dfb78add1c",
              "IPY_MODEL_3df2e72406454de7ade25cfe0fca7295"
            ],
            "layout": "IPY_MODEL_979449deb4254629b80f0089584c851a"
          }
        },
        "29e9e92bc30c4b2f89416481b4fb1455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34433ff3b52491fb5829b9f1522e162",
            "placeholder": "​",
            "style": "IPY_MODEL_5250f6a6e5c34894adb20a9120388ba0",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2a7388d890b2460c86be4cd32187f319": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38b91d162c304c6eaad444f0abffa931",
              "IPY_MODEL_0f331a136adf425f87a1a35682256cd9",
              "IPY_MODEL_1f65726d2e20471e99928e5dc96726c7"
            ],
            "layout": "IPY_MODEL_dae9d080adfc4bfbba896820bbf57c3b"
          }
        },
        "2b5f6a6687b34036bd5a87c8b61dc2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d265db9a419d4edfbdb91e4bd8f78846",
            "placeholder": "​",
            "style": "IPY_MODEL_aae2a30b7f474dbcbf55aa677b9518f9",
            "value": "Downloading metadata: 100%"
          }
        },
        "2b95b44611524401ac7826dab5a21aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c148a8aa9fe4f30a69392f10a350eac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c43b4c9b58842acaf321862c3a1625d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fe3c4d6e4774be691e7c0551fd334ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f6111712e2491198ac03400ef0ce7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312b0a411cf7451d845fae7b77dff7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "31fef27ae4d44fa691185c3fa750756a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa205a1da88e418a881efb0963042e9d",
            "placeholder": "​",
            "style": "IPY_MODEL_30f6111712e2491198ac03400ef0ce7d",
            "value": "Generating validation split:  73%"
          }
        },
        "32184fc9b099416a8d49ef3c3f8c3a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2137d76adc0b4235bcf4e52ab94ae445",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb506371e6e4cd2947988d6c7050809",
            "value": " 232k/232k [00:00&lt;00:00, 6.89MB/s]"
          }
        },
        "326c1c104f254d1189c78c6abd318451": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328dedc4b7db45738e274196f66dabc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d19b7f1d224f9fb2a0f2518c02e5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32f65d2703c048929de10720219fdf53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33088ffab85f4898bc39a1167e70388c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3312caf3fc76420ead7f4945675df52a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3315267c32f24d29804c12af760956aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31fef27ae4d44fa691185c3fa750756a",
              "IPY_MODEL_11db36da26a94bae9ad00e99a10d8c5a",
              "IPY_MODEL_f4bb56cde5b042e8821ee26d25da4ea2"
            ],
            "layout": "IPY_MODEL_312b0a411cf7451d845fae7b77dff7d6"
          }
        },
        "33ae5a6ee9244aeea02e10990e8dd3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f1b9961c6b14a1a92f3cb2c82883a17",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd3f1f64d81471083416a3e4ca6aa60",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "3650364038714617bd315e4fcd23d3bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c0e136fa3f400bab5deec7a0aff11f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3751db7e581847efa6c224dd50c9b7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "377a7fa0ebce4c8a96a55c6e1c08403f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff3a2b6be1f4220b0e3c055fc587c7e",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af816340aae74a81a6eaf63a1933f5bf",
            "value": 1340616616
          }
        },
        "379f64826a714ae89a85c265b4937902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37e0abc511f04624986368ef45b50131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33088ffab85f4898bc39a1167e70388c",
            "placeholder": "​",
            "style": "IPY_MODEL_1672001c1d7e449f9cc0ce76fcf50fc8",
            "value": " 2.88k/2.88k [00:00&lt;00:00, 139kB/s]"
          }
        },
        "38b91d162c304c6eaad444f0abffa931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef72b344a964832bd2b19140d230f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_b719af868833401c86d45d2ae059c868",
            "value": "Generating train split: 100%"
          }
        },
        "39465c30a6d846f2a78d4016152041e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3963ddae09b14417abf20a566ce82a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3988d9e57bc841b49a5079130f071dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ba6ff0046c843679c0581a44ec69e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c45e6794f974b4199098bcd87765e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c54d6fd6a004ed98c1cb595a0bb84a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cfadb1af62b45e1b6cf9f3243a281d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a51c61ff30d4474080167a38356ca402",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f38b1623f14bc9bea9b812f9102fce",
            "value": " 68.0/68.0 [00:00&lt;00:00, 1.39kB/s]"
          }
        },
        "3dd36967afcc40329fcb44b346fdeebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3df2e72406454de7ade25cfe0fca7295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7834f7deaa3b43669cd0de893fa62448",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa5b162648c4abca773a478c3e3beb9",
            "value": " 227M/227M [00:07&lt;00:00, 30.8MB/s]"
          }
        },
        "3e72971bf9804c3688c24e0a3eca0da7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2b4543fdb94a1d9153de7f18d108be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb4b68eda9f481abbc7b2456644e16b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40731cc8e1a245868c9bf6d0972c0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422ac21cdb1d45a8a0814ef00c9769ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "429379eb4c4f452d94a52521911811a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68c38cc7bf84db2ab1540ca985599e2",
            "max": 8671,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4ccb21f87954a31ab7ab0fd7e11a8c4",
            "value": 8671
          }
        },
        "42c13d8f7c694c6599c0a2e10ca0765f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0322aeeda2bd42c1b8ce348bd56424eb",
              "IPY_MODEL_c0908ccc452b42e681765c37a139e878",
              "IPY_MODEL_251219f28bd54de9a608686672dddf0d"
            ],
            "layout": "IPY_MODEL_e982215023c24a3caf881dd3986cca86"
          }
        },
        "42ed4267878a46a9a1a1de7f63006ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba76516f42224f79a9dfe8a36385bb22",
            "placeholder": "​",
            "style": "IPY_MODEL_c6b2dc48588b482f80e9a2473dc5b452",
            "value": " 28.8k/28.8k [00:00&lt;00:00, 619kB/s]"
          }
        },
        "4326c46139fd4b6882d864400e35a9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e76cddc6d7d04d3fb01c11225ec1b6a2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ad1276e945e4915a079e97e06048ee9",
            "value": 570
          }
        },
        "44ce4959b2bc410a8b455eb2adb7ffc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d07abd85374cca92698119139b140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1deae35c0489408fa7e374cd93cca642",
            "placeholder": "​",
            "style": "IPY_MODEL_260f38a6c52d464999f74443c04cdc03",
            "value": "Downloading data: "
          }
        },
        "454aeb5a95b94bb580698d8d2f62f43f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4617c5d3e4df42fe8e6d5220c94e443f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46cd1079cad04e7ea04959e14225b7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef504e4ab1384063bff714e1649e0aa3",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b387dec327543f79f957f81fb651cc7",
            "value": 3668
          }
        },
        "46f2289d8f6c460892864f1ef5ad8e08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ff0481a7a94abb9cea91aaacd1ea29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470a84311bbf40c6ae6322d6edc353ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9568bdb74f3e450f91b3558cf5ad5da1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7b946e1ad95455b818512986f83f7cd",
            "value": 231508
          }
        },
        "476c5672e7784cda8255af2049de1ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73e2bfea29de4c47b0c60590deff9771",
              "IPY_MODEL_4326c46139fd4b6882d864400e35a9bc",
              "IPY_MODEL_a53d537c8c0e48d1a77fbc22e5c41402"
            ],
            "layout": "IPY_MODEL_4eba976ecf5145e0a60cc8a838bff5c9"
          }
        },
        "4818654025b94f38a631b2bcdf36014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48729429682c4b37a624ba2eb55d1966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497aad7b9ab34f158382033f65d9a8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499cfcd99b96406383ff92126cab7c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0787d9b7b9c649c9a8a70dd37d645a11",
              "IPY_MODEL_a18b3a57972c42e1b061e2ada2c7858e",
              "IPY_MODEL_f5a25f48fd7045d092d4b4b1a66f296c"
            ],
            "layout": "IPY_MODEL_dbbeb2e4f0ca4e3b831fc5f58b883cf7"
          }
        },
        "49a90c227b9342ddbb670c9fe85591cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a1ecdd97d194a9ab63a15980d1e2e31",
            "placeholder": "​",
            "style": "IPY_MODEL_5dd1df4079d44b1aad849b4a0a5e3b55",
            "value": " 8.67k/8.67k [00:00&lt;00:00, 296kB/s]"
          }
        },
        "4a16335de26a43c09d578cbbe20e98d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d567e39c5ac4b9f8d9908111b04100f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f619ea2b062a4eacb80ade328d56c2aa",
            "value": 231508
          }
        },
        "4b184b86f7814565936c60466ee24b32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b242512f1ca473793bf144e5d062a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b35ff0e35ca4e6088f2f1f687ff924c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b4dae6b5bd5474491e1c86a6e462ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3b7432f11a4a4b9eb444743d158c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d798a40b2a24c4f8ce823023d75ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10d3cde2d7b4121971d8e19e3362b30",
            "placeholder": "​",
            "style": "IPY_MODEL_4818654025b94f38a631b2bcdf36014c",
            "value": "Downloading readme: 100%"
          }
        },
        "4dbe3181aa2f4fed8c105e0175bdf9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6584e12814444c46be4fc1107d52b0ec",
            "placeholder": "​",
            "style": "IPY_MODEL_d390110fecc7409291f79bc41e3e7c19",
            "value": " 21/21 [00:00&lt;00:00, 516.13it/s]"
          }
        },
        "4eba976ecf5145e0a60cc8a838bff5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef3bcbd56164ddaac3068fb93a66630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cbd831de3c64f4aa269776dc73c5e28",
              "IPY_MODEL_d947bfe9101646c9a7222ada482d4455",
              "IPY_MODEL_8e9137be11744d329bceecd548d91025"
            ],
            "layout": "IPY_MODEL_326c1c104f254d1189c78c6abd318451"
          }
        },
        "4fc404853fe84976afd7674ab97d1533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb77d7017bbd48f6937c38c219acc095",
            "placeholder": "​",
            "style": "IPY_MODEL_666b0b8c335b4905baaf810735d244c9",
            "value": " 383/383 [00:00&lt;00:00, 19.0kB/s]"
          }
        },
        "4fe04dcab6654d0594a56109e7eb6805": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516b1796b208442ca32a48c8611b35fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd0803047b8426eb76e8412d6cf976a",
            "placeholder": "​",
            "style": "IPY_MODEL_6b6b3265e630457aac2433dea92348e9",
            "value": "Downloading data: 100%"
          }
        },
        "5183ef3eec0d4bdfbcc5544b0fec573b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5250f6a6e5c34894adb20a9120388ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5398b51140574840979cfe9ae2640c96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546b278b05e643a4905055d1d7ffeea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195b549a3cd745ffbe55e24f5865b1da",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe156388571b4c63b5fc5f5ca857e522",
            "value": 116252865
          }
        },
        "5589d685cbc94ea0a045dcba0e69a7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600bc8f5877547aca898f8c85902040e",
            "placeholder": "​",
            "style": "IPY_MODEL_b65ef6da8ad34e2285813544d00bf3e5",
            "value": " 711k/711k [00:00&lt;00:00, 10.2MB/s]"
          }
        },
        "560c716068a645d596cc2fe9b886c0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235afab600844a9f8ef8f45cdba142e0",
            "max": 383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7537c19825a49cd8f3343c153fe56ef",
            "value": 383
          }
        },
        "562dc2a8529f4836b9afe3fcb405b27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "573b3112cbee4ba581c18884df0a269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc799bb2e34741fabc79181ea30ee78f",
            "placeholder": "​",
            "style": "IPY_MODEL_a78c45e4929847f0a635988d1ef9d78f",
            "value": " 232k/232k [00:00&lt;00:00, 2.46MB/s]"
          }
        },
        "58221644a9f040cbaf0377564f066623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46716dcab7c4e5f8477931b7e12ea6a",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80c9e2fa3d1d42f88f42e35e01cbfdc3",
            "value": 116252865
          }
        },
        "595530337aab40f6b5cc24d69b3ebaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab64a9556124cf892f33cc9973240ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b92dc1fae394c1f98221dc9762f5779": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bd4908665db4c8baac9d52a40a1c28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46ff0481a7a94abb9cea91aaacd1ea29",
            "placeholder": "​",
            "style": "IPY_MODEL_05fd99843ed746d1baf705e6c31881f6",
            "value": " 9832/9832 [00:01&lt;00:00, 7725.02 examples/s]"
          }
        },
        "5c1b6064c01a4f3981fe47abf757d31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd116c11c9cc4b56ab67ebc8649767bf",
            "placeholder": "​",
            "style": "IPY_MODEL_562dc2a8529f4836b9afe3fcb405b27e",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "5c69e45579f54fc6b2415ebbad4da477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c96dd4ef67f4900af004f322706921f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd0803047b8426eb76e8412d6cf976a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d276b68035e42d79ec3d6c3600cd125": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6d6c79117c4418ae920f3a3933ce8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c226f3cbc6c741749fdd62c73e6800c6",
              "IPY_MODEL_66dffa1174af472cb6b6f7cdbb99d81a",
              "IPY_MODEL_4dbe3181aa2f4fed8c105e0175bdf9a6"
            ],
            "layout": "IPY_MODEL_849e8f1cbf6346eca2ec181e13ceb2b8"
          }
        },
        "5dc68509c6494c6ebdd22c30ea632bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd1df4079d44b1aad849b4a0a5e3b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5df7aa079833485bbde65e4658b496e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283065bbec654b89a6be726e3fe790fd",
            "max": 28682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebf0c7ac01e441d68a38cac5fed89d00",
            "value": 28682
          }
        },
        "5e1a387877054dacbb6bf1fa32b08d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed5174d9d6c4680bb7cc1e803184102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91bcf74809894d39b5199ca23691f00f",
            "placeholder": "​",
            "style": "IPY_MODEL_85a35c16364f4c6880dbbecf061faf44",
            "value": " 1.34G/1.34G [00:17&lt;00:00, 83.7MB/s]"
          }
        },
        "5ef185dc852646fbb92d1eb31981bed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f0512fb3607471f817b5c215d94e4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd68849bd0a44238fbb9bec129b0511",
            "placeholder": "​",
            "style": "IPY_MODEL_3312caf3fc76420ead7f4945675df52a",
            "value": " 314/314 [00:00&lt;00:00, 4.38kB/s]"
          }
        },
        "5f1b9961c6b14a1a92f3cb2c82883a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdca1f2b388437fac7624c0eca1ec26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600bc8f5877547aca898f8c85902040e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610680918453400fba82622926af1b56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "61455bbef8d645ec991263a9dfe13410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c1b6064c01a4f3981fe47abf757d31c",
              "IPY_MODEL_c03bdfe1869d45a28466a072aa408ae0",
              "IPY_MODEL_172cde34c43d40a68e2b80fad3ded0f4"
            ],
            "layout": "IPY_MODEL_4b184b86f7814565936c60466ee24b32"
          }
        },
        "619bcc47eac24a098ac5908bddc4297d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638f36ef35ec4ec88ba057c63093eca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a2424581894ab48ad61b9f38cc882e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641fd37171904fb590b7877d8403aeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8f710e2dcfc40398ce16a4ac265cc26",
              "IPY_MODEL_377a7fa0ebce4c8a96a55c6e1c08403f",
              "IPY_MODEL_5ed5174d9d6c4680bb7cc1e803184102"
            ],
            "layout": "IPY_MODEL_2c148a8aa9fe4f30a69392f10a350eac"
          }
        },
        "656cb0e3b85c4a57936749caa02f664d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6584e12814444c46be4fc1107d52b0ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666b0b8c335b4905baaf810735d244c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6679251fa0b64c59ab34bf7a811e0ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fdb79deb808435caba9e231f98118f0",
            "placeholder": "​",
            "style": "IPY_MODEL_7bac298bf1954016a76ce82ab5842870",
            "value": " 61.5M/61.5M [00:02&lt;00:00, 25.4MB/s]"
          }
        },
        "66dffa1174af472cb6b6f7cdbb99d81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cf10a71fae487f8f1cc913f9214c98",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe784053e3d047758731e6f99283d772",
            "value": 21
          }
        },
        "677c94eab4d04efaba8770b32b6e82d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "686aaeb98c1a4e688af5030963b8525e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68db1531b9574e72a2ff0d52995a7347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694f0df64a4b433aa22afef48d968090": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d264b002cc4c3889089fe28f6cfa80",
              "IPY_MODEL_f6a686a076954e0c9c5d11429a14d582",
              "IPY_MODEL_9f512b3c83bf4fcaa1640cf5cdbea8c8"
            ],
            "layout": "IPY_MODEL_282f350bdadd41fa82b37f527ffe8a63"
          }
        },
        "69cf10a71fae487f8f1cc913f9214c98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b349f8f7890488eaa05b156ec971bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3537b58aca04f398663d6a8f6bd7cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_0ea16b4f2c6d428191dd7d31d21ad659",
            "value": " 1725/1725 [00:03&lt;00:00, 758.62 examples/s]"
          }
        },
        "6b62d7166e614b6ead8a0af96758cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b6b3265e630457aac2433dea92348e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6baecbf668bc4a6f93be03e5f671b76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d322e088a6a4904a0b99740d8d4e45c",
            "placeholder": "​",
            "style": "IPY_MODEL_20402646761d4cf3975763fc130d6ff5",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "6c200c3e72394f20a570f130a707e9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6da885f236a24cf5a09add7c9927db76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7c559006d24081b1ae338d3f443a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb59704b56142dc82b819e7828ccaf4",
            "placeholder": "​",
            "style": "IPY_MODEL_9d20832d687b4fe6bc280d912d203013",
            "value": " 8013685/8013769 [48:13&lt;00:00, 2131.36 examples/s]"
          }
        },
        "6eeb3579c2b644a6b8501cc246083c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f102144e4fd4840b77808f1e6ff7697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fdb79deb808435caba9e231f98118f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff3a2b6be1f4220b0e3c055fc587c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70225a6a843d4ccf87d1b43d4cf1895b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7081369f016f46ec9ad16edcedd027b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e2bfea29de4c47b0c60590deff9771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2750de9a4c5740b080f5a8145de41111",
            "placeholder": "​",
            "style": "IPY_MODEL_ecf9c5705a7b491c82d4e8b5cbd8c439",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "743ba3957fde4d10935f4089f4da9aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "755e3809aa3043f99d3664955a3a2c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d07abd85374cca92698119139b140e",
              "IPY_MODEL_00001f9f055045f9ae35f94f76be8fe4",
              "IPY_MODEL_1e7d06e9df9b4a88a003bbba433c1cae"
            ],
            "layout": "IPY_MODEL_a87f8ff9f575436da0dcf9a31642f7b7"
          }
        },
        "75d264b002cc4c3889089fe28f6cfa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052465580f854b15be0d29e9dc59125b",
            "placeholder": "​",
            "style": "IPY_MODEL_619bcc47eac24a098ac5908bddc4297d",
            "value": "Downloading data files: 100%"
          }
        },
        "75d76bf886514ba5ac9fedee0fcfba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fd0e5e6b8f47c6a4c9557f127ef73b",
            "placeholder": "​",
            "style": "IPY_MODEL_b963a45c28d1437f86109f283a370f38",
            "value": " 384/384 [00:00&lt;00:00, 3.58kB/s]"
          }
        },
        "77d712d32c0f491cb9a58df33b012b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7834f7deaa3b43669cd0de893fa62448": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78608a4a3a8f4c119d9a0128153a39eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48729429682c4b37a624ba2eb55d1966",
            "placeholder": "​",
            "style": "IPY_MODEL_6eeb3579c2b644a6b8501cc246083c97",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7936aeb365f44e9685dce4015da9d5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7950d803ab5b4c4ab10dc9e0902e34b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ad09b3ac2d5406caa626954d7dc4b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b387dec327543f79f957f81fb651cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b56936ebd914109a0d5546c65fff0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bac298bf1954016a76ce82ab5842870": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bdb5cce9c364437970f01220e5f0aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e72971bf9804c3688c24e0a3eca0da7",
            "placeholder": "​",
            "style": "IPY_MODEL_d36c80ffd8824fdb8e1e344f41fa3669",
            "value": "Downloading metadata: 100%"
          }
        },
        "7c01fc1aabb0486f9f1f0674b46b5481": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f102144e4fd4840b77808f1e6ff7697",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82084929de714135a363f5693f4a0aac",
            "value": 1725
          }
        },
        "7c1ea655a2844e0e81c89529f95acb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fca62c132b4b9c9af64955480ac905",
            "placeholder": "​",
            "style": "IPY_MODEL_7081369f016f46ec9ad16edcedd027b0",
            "value": "Generating validation_mismatched split: 100%"
          }
        },
        "7c50e41b12ab40ae88db5a68806a5287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aea1f6de91a43a4b491c82ffc1522be",
            "placeholder": "​",
            "style": "IPY_MODEL_3c45e6794f974b4199098bcd87765e63",
            "value": "Downloading builder script: 100%"
          }
        },
        "7e61f641028148e988678a2ecbe24a21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f511160291e4a4a82f8694772449ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800359cf35c04fb08fffcfe9de625e54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808dad49922a431d9c43faf48478a069": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80c9e2fa3d1d42f88f42e35e01cbfdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80fd0e5e6b8f47c6a4c9557f127ef73b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814c0fc7e64c49bfa85d5087d1e07cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81afc2262c8545dab41aacde91066b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638f36ef35ec4ec88ba057c63093eca2",
            "placeholder": "​",
            "style": "IPY_MODEL_4b35ff0e35ca4e6088f2f1f687ff924c",
            "value": "100%"
          }
        },
        "82084929de714135a363f5693f4a0aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "825fb9aa19594a61b2a779837eb230b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686aaeb98c1a4e688af5030963b8525e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a024ed7f3514fd6a544804a8bee0d78",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "82db512ae4ce4b1fbde3aed3d893e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd748fe04232441abb30f153e54f9890",
            "placeholder": "​",
            "style": "IPY_MODEL_8eda2864b2774815bd6d860c1fdf2625",
            "value": "Downloading data: 100%"
          }
        },
        "82f1dc2ca5ef4e45818a2b9107732d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae32d0dd19e40e8a0fc4b04b325abd6",
            "placeholder": "​",
            "style": "IPY_MODEL_20ae65dc26cb4ab98a9637dfa2bd5a62",
            "value": " 616/616 [00:00&lt;00:00, 9.58kB/s]"
          }
        },
        "843d11a2271246f49dbabe80fc4762d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84949f4ae0b6402aaca1326d124436b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3650364038714617bd315e4fcd23d3bd",
            "placeholder": "​",
            "style": "IPY_MODEL_f6823010dba245d1843a2f324e00c382",
            "value": " 1/1 [00:03&lt;00:00,  3.31s/it]"
          }
        },
        "849e8f1cbf6346eca2ec181e13ceb2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a35c16364f4c6880dbbecf061faf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85aa23b715f248248204a2bdf3e5f7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8631f393c12e4ebaa57838a4f1c1efb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868c8d0c5a4a4535a00dd833ad0dbb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1ea655a2844e0e81c89529f95acb4c",
              "IPY_MODEL_f4a51d5c122645a5a58acfbadb0cf752",
              "IPY_MODEL_5bd4908665db4c8baac9d52a40a1c28e"
            ],
            "layout": "IPY_MODEL_000f6133e191461c893cffdc6783a5f9"
          }
        },
        "8974203b2bde4395b3144ffe61596643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdca1f2b388437fac7624c0eca1ec26",
            "placeholder": "​",
            "style": "IPY_MODEL_1c00f260ca44415c9c2cc342c9cab470",
            "value": " 232k/232k [00:00&lt;00:00, 9.15MB/s]"
          }
        },
        "8a0851189dae4fbdb953f6afe6f3ba29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1ecdd97d194a9ab63a15980d1e2e31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae32d0dd19e40e8a0fc4b04b325abd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3982acce834b95a6f318dfb78add1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a93d25cd25426e9c60222b29321889",
            "max": 226850426,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0db15040be1242378220fa56a21aba28",
            "value": 226850426
          }
        },
        "8c45ce351a9b45dda4359b706ea36aba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbb1fccc920458cbffc7029953e5363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29e9e92bc30c4b2f89416481b4fb1455",
              "IPY_MODEL_1c5678cdeb204d21b94526ccdab34d32",
              "IPY_MODEL_dea6b34486294d388d68aa9ef3aaa281"
            ],
            "layout": "IPY_MODEL_e34566724c6e4598860e77d6b710faf8"
          }
        },
        "8e347cd029c24f57b55467966708d0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e856b6e5ce74a4fa9b35ae801df4d31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9137be11744d329bceecd548d91025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c45ce351a9b45dda4359b706ea36aba",
            "placeholder": "​",
            "style": "IPY_MODEL_9e2644d3c3bb40aa9eba632e756112a3",
            "value": " 125/125 [00:00&lt;00:00, 3.05kB/s]"
          }
        },
        "8ea68f6b18c342938de8be19d3896038": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42f3b105ff645dcb58805289594baad",
            "placeholder": "​",
            "style": "IPY_MODEL_d4214693adb54e44b31fd40e549802b8",
            "value": "Generating test split: 100%"
          }
        },
        "8eda2864b2774815bd6d860c1fdf2625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1bf2df4214449483a37dc84d9f3c43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8f8bd06e8b4ce7bb74b30a5a2e68b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af00aa1a3bd64be9ad8f4df3e3c5f942",
            "placeholder": "​",
            "style": "IPY_MODEL_11a1247638b6426c961fa4705dc85fee",
            "value": "Downloading data files: 100%"
          }
        },
        "90cd613da6d54fa881f325d531f371c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f8f8bd06e8b4ce7bb74b30a5a2e68b4",
              "IPY_MODEL_0491c321ae9344ff98592968423dccd3",
              "IPY_MODEL_84949f4ae0b6402aaca1326d124436b3"
            ],
            "layout": "IPY_MODEL_8e856b6e5ce74a4fa9b35ae801df4d31"
          }
        },
        "91738a91e20344f1b848ccc39bd0b686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d88bd9fdda49bcbf01366f8fe6fab2",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5cfab63b2d47869f69b772f9801d69",
            "value": "Downloading data: "
          }
        },
        "91bcf74809894d39b5199ca23691f00f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91de7341a97a4415b5656ee33fe6395f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1bf2df4214449483a37dc84d9f3c43",
            "max": 616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9afa2b87f4a94a58b7c639a0a7f63813",
            "value": 616
          }
        },
        "91eebca40ce344039704522c4570353c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "928685f89f3e40ddbf9b97a5281bb86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "928bc9d9e240469298d2a267fe3b9e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595530337aab40f6b5cc24d69b3ebaf9",
            "max": 5145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85aa23b715f248248204a2bdf3e5f7ec",
            "value": 5145
          }
        },
        "92d450929c8e45539c2726eaf96d5ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "933e94b11adf415abb0b16cad1201e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9568bdb74f3e450f91b3558cf5ad5da1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e7d97dc8f44c7d873060a89f82ce0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "979449deb4254629b80f0089584c851a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98371c9b595a4354a51020081c8adaa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d25f24f6c4464900af0369a1d34197af",
              "IPY_MODEL_cf24681dbccd42f59ffda006ca4cdac6",
              "IPY_MODEL_afbc002e8eed45b78884f7c4ccd6f37f"
            ],
            "layout": "IPY_MODEL_12371b67bb334b2786c3809702b7bac7"
          }
        },
        "98bd45b05dda4319adf853b5104f0a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9977be2298704813a37ed7c23e31d840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99ef066e53974658a59443c917b2c615": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a675022c08043438f0288c2dc3d1692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff58b4945b004e9996568c228986d287",
            "max": 28751,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1290569b6a4d490fbfc8ca3915983263",
            "value": 28751
          }
        },
        "9ad1276e945e4915a079e97e06048ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9afa2b87f4a94a58b7c639a0a7f63813": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c8b871e03af41ada7990e7b76084f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ae5a6ee9244aeea02e10990e8dd3da",
              "IPY_MODEL_470a84311bbf40c6ae6322d6edc353ae",
              "IPY_MODEL_8974203b2bde4395b3144ffe61596643"
            ],
            "layout": "IPY_MODEL_d4ea11ee38044f7cb7ffe1a5b018bda7"
          }
        },
        "9cbd7c17733a4b01b8717c98c41ffee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c927ee3e4fa84190a00a29aea856bef8",
            "max": 116252865,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c200c3e72394f20a570f130a707e9ad",
            "value": 116252865
          }
        },
        "9d20832d687b4fe6bc280d912d203013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e2644d3c3bb40aa9eba632e756112a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e4b3e23a0d94fbdace001eef383c56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ef72b344a964832bd2b19140d230f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f512b3c83bf4fcaa1640cf5cdbea8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab64a9556124cf892f33cc9973240ea",
            "placeholder": "​",
            "style": "IPY_MODEL_656cb0e3b85c4a57936749caa02f664d",
            "value": " 3/3 [00:01&lt;00:00,  2.26it/s]"
          }
        },
        "a03e87f36c0240e0afd87ff4ebc334a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfa3fef5ad8743228d10e60238d91449",
              "IPY_MODEL_fd04d23b69a545d4acab01dd3046b44a",
              "IPY_MODEL_f6eac59aef894d88bcae4654df6ef1b2"
            ],
            "layout": "IPY_MODEL_ea4024140d39477884175e9aa9c2f796"
          }
        },
        "a18b3a57972c42e1b061e2ada2c7858e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610680918453400fba82622926af1b56",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_933e94b11adf415abb0b16cad1201e93",
            "value": 0
          }
        },
        "a2bbd67afcb9463cb0f78d7a24c5f126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31311fbeb1d49c1a34ce41c4b01c22f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33ab96c585c411ab148d76865b848f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5183ef3eec0d4bdfbcc5544b0fec573b",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3751db7e581847efa6c224dd50c9b7bb",
            "value": 711396
          }
        },
        "a417b74f6fdb4dedbd6bf3408d0dea69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4848184b58645b2a572c6e1a1231f05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51c61ff30d4474080167a38356ca402": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a53d537c8c0e48d1a77fbc22e5c41402": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02191a5509094a0abcf8862d3a8ee4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_5c69e45579f54fc6b2415ebbad4da477",
            "value": " 570/570 [00:00&lt;00:00, 6.61kB/s]"
          }
        },
        "a587d42c581c4f75984a189ebe1b1831": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5967030d5aa4581b66d319588b92db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6baecbf668bc4a6f93be03e5f671b76a",
              "IPY_MODEL_a33ab96c585c411ab148d76865b848f2",
              "IPY_MODEL_5589d685cbc94ea0a045dcba0e69a7e5"
            ],
            "layout": "IPY_MODEL_01ac22caf29c4b2baf0ebc428f3398b3"
          }
        },
        "a5adffec44744a10b0ac45f73eba6058": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6770d150cfa459780d5adb12fc7c7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78608a4a3a8f4c119d9a0128153a39eb",
              "IPY_MODEL_91de7341a97a4415b5656ee33fe6395f",
              "IPY_MODEL_82f1dc2ca5ef4e45818a2b9107732d58"
            ],
            "layout": "IPY_MODEL_5e1a387877054dacbb6bf1fa32b08d7a"
          }
        },
        "a6f38b1623f14bc9bea9b812f9102fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78c45e4929847f0a635988d1ef9d78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a87f8ff9f575436da0dcf9a31642f7b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94a510c49414b75818b4c1654394703": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f66a8eed1443d099d0fadab83d02e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa099b9c51d6447a9a22fb13b103cb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a6cc127c8c4f03bab0b31bb3a1721b",
              "IPY_MODEL_08fbdead6ab540d4a1d2d8f06879e417",
              "IPY_MODEL_5f0512fb3607471f817b5c215d94e4d8"
            ],
            "layout": "IPY_MODEL_0457dfcb462c4173bbfb7890bb043c97"
          }
        },
        "aad70e180d49469ca01ecfd84eb2225d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aae2a30b7f474dbcbf55aa677b9518f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab4bf3b1267743a8960deeeafcd0fcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f216f345dde54c35abaff30dac041c89",
            "placeholder": "​",
            "style": "IPY_MODEL_e7cd7488f7264496be788107804bc9e8",
            "value": "Downloading data: 100%"
          }
        },
        "ab8bf4aa34c5452d8c6d01df44402eea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8df595bb704a599d9abd994aa65691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_516b1796b208442ca32a48c8611b35fe",
              "IPY_MODEL_e8db7bdb8bf04011874e6bb31570d763",
              "IPY_MODEL_6679251fa0b64c59ab34bf7a811e0ae0"
            ],
            "layout": "IPY_MODEL_c03bf64ecd204abab3d1b97eb32e0fdf"
          }
        },
        "ad9c165248ef4e0b9c357316b95f66af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc06005b98c44f0a6308cbd4f6a3527": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "addf3619a835489f8d9f3ce4498daf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adef362bc525401c8b657d33dfec55ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae85f3dd9b864de7897e02a2313c8093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea00ba0feb164981bdb521803fd29049",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16501e0f5de84fc7bbbdcc9b37f61d85",
            "value": 1
          }
        },
        "af00aa1a3bd64be9ad8f4df3e3c5f942": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af816340aae74a81a6eaf63a1933f5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afbc002e8eed45b78884f7c4ccd6f37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e779447c8d8e4578bd3a7747941bfbeb",
            "placeholder": "​",
            "style": "IPY_MODEL_928685f89f3e40ddbf9b97a5281bb86f",
            "value": " 109429/0 [00:35&lt;00:00, 4036.36 examples/s]"
          }
        },
        "afd68f4512e045c2bfaa46eb36d4ab5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f387685057a6405f86292bd9ce5df000",
            "max": 27887,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_808dad49922a431d9c43faf48478a069",
            "value": 27887
          }
        },
        "b0546b4b929f4fe3927af49ab119d99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df31cc0682014cdb881817de1c02288f",
            "max": 2877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01fa51a473a6472da89d47bf1116e575",
            "value": 2877
          }
        },
        "b072faf11c504e39939d1ad4534f9112": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb4b68eda9f481abbc7b2456644e16b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c54d6fd6a004ed98c1cb595a0bb84a0",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b076eddbd7a74d5495615776c26a6f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f230ba518eed434fb107f97c66293470",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a7dd0c3112945959e9908425fcaa8b8",
            "value": 384
          }
        },
        "b08eba43d39846869bdd9050836be1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b17a0dd6bd24481e8e597415bfc02c87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34433ff3b52491fb5829b9f1522e162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42f3b105ff645dcb58805289594baad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5641641fc6e4f72b58c505565e16367": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fca62c132b4b9c9af64955480ac905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65ef6da8ad34e2285813544d00bf3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b5640287e64eaaa8d910072ea8a49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec12f15c6abf453abab53377bc2e9ba7",
              "IPY_MODEL_58221644a9f040cbaf0377564f066623",
              "IPY_MODEL_c0ff005b169d428ba1930ab99f2ad5e2"
            ],
            "layout": "IPY_MODEL_bc918c49557c428da985c29669a4ef59"
          }
        },
        "b6f9c6c1ac8a4eec97466e0f2108ce39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70156e5cb144e75b97697a2439d9a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b719af868833401c86d45d2ae059c868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7b946e1ad95455b818512986f83f7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b963a45c28d1437f86109f283a370f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b96a361475c947e5a0f9e5f0f867ced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c9ec9890384cb4b17139a7335e371e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adef362bc525401c8b657d33dfec55ce",
            "value": 1
          }
        },
        "ba76516f42224f79a9dfe8a36385bb22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8a7860db844d0e869d8d77c6e18d83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc799bb2e34741fabc79181ea30ee78f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7e0e6c4b154e55875c6fddc0aac6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc918c49557c428da985c29669a4ef59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcee86d4105743f5a69c595029994bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd79d8ce5e28404c988f4965873a2f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc7642ca3e748069974df4a510470ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1034a93ce59f439bb128b6c096eefdf2",
              "IPY_MODEL_4a16335de26a43c09d578cbbe20e98d1",
              "IPY_MODEL_573b3112cbee4ba581c18884df0a269e"
            ],
            "layout": "IPY_MODEL_4fe04dcab6654d0594a56109e7eb6805"
          }
        },
        "be7af49d0afe4ecdaa800be969d5a3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2166426a7a224f1da2065f3221463693",
            "placeholder": "​",
            "style": "IPY_MODEL_77d712d32c0f491cb9a58df33b012b0c",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "bf4d157f4fc041fca5718cdd41e73c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab4bf3b1267743a8960deeeafcd0fcee",
              "IPY_MODEL_ecaeab95cff44076a0a84cca103b6b60",
              "IPY_MODEL_3cfadb1af62b45e1b6cf9f3243a281d5"
            ],
            "layout": "IPY_MODEL_b5641641fc6e4f72b58c505565e16367"
          }
        },
        "c03bdfe1869d45a28466a072aa408ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b987c8b2b449248ff874bc78eb39c5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb402bb1c4e14e859d55089494954a79",
            "value": 231508
          }
        },
        "c03bf64ecd204abab3d1b97eb32e0fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0908ccc452b42e681765c37a139e878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74fd39704b44cea8f012402e7449a80",
            "max": 9815,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5e5dd22e0b24a30a485b54dbdacf1cf",
            "value": 9815
          }
        },
        "c0ff005b169d428ba1930ab99f2ad5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328dedc4b7db45738e274196f66dabc6",
            "placeholder": "​",
            "style": "IPY_MODEL_32d19b7f1d224f9fb2a0f2518c02e5bd",
            "value": " 116M/116M [00:00&lt;00:00, 151MB/s]"
          }
        },
        "c16dd57325504698b35f155d1bd040b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c1ad349038c94c1f9ec7b1d0d7245699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c225230ea12f4f90bd461485f300580e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c226f3cbc6c741749fdd62c73e6800c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba8a7860db844d0e869d8d77c6e18d83",
            "placeholder": "​",
            "style": "IPY_MODEL_9e4b3e23a0d94fbdace001eef383c56a",
            "value": "Downloading data files: 100%"
          }
        },
        "c508e67d54c24888b82b66108681da19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d71e718353ac40788febf07676b3cb25",
            "placeholder": "​",
            "style": "IPY_MODEL_addf3619a835489f8d9f3ce4498daf36",
            "value": " 3668/3668 [00:01&lt;00:00, 2844.62 examples/s]"
          }
        },
        "c519b80ce005494caf41456ec90111bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5323c16a9ca4decbe25c651a14517de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5adcad970e4455cbf797f14e2e5303e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f6c046574b4badbf5dac2bd4989d67",
            "placeholder": "​",
            "style": "IPY_MODEL_e844aa942c604f17b61375f59aad56f3",
            "value": "Downloading builder script: 100%"
          }
        },
        "c6b2dc48588b482f80e9a2473dc5b452": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7255329fcf94a7dade2742f7407d41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b56936ebd914109a0d5546c65fff0b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5b92dc1fae394c1f98221dc9762f5779",
            "value": "Generating train split: 100%"
          }
        },
        "c7537c19825a49cd8f3343c153fe56ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d86dc22b0747dba72d6aa5fd899df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7fcfc2727db445695b908ffd3370feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0851189dae4fbdb953f6afe6f3ba29",
            "placeholder": "​",
            "style": "IPY_MODEL_01f4a70e089f4fe5abb0d9246aeee403",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "c86fedd6bd374d4586e51c030cbfea1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c927ee3e4fa84190a00a29aea856bef8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca51f90211e14e13902200d819bfe447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07b52d5502284df5b12b39c47d107310",
              "IPY_MODEL_9cbd7c17733a4b01b8717c98c41ffee4",
              "IPY_MODEL_ce050a2ed895498dba3347c1c4bb092d"
            ],
            "layout": "IPY_MODEL_dbb5a92189d34f4d8571106c29dee036"
          }
        },
        "ca59bd8ff338413c8514ab0eee2d8ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca5cfab63b2d47869f69b772f9801d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafc757655d74a2697f4ba566b3623ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1837578698f426d8c65a40770a3488c",
            "placeholder": "​",
            "style": "IPY_MODEL_fdf37a5ac48c477d99318631238a5756",
            "value": "Generating train split: 100%"
          }
        },
        "cb402bb1c4e14e859d55089494954a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd116c11c9cc4b56ab67ebc8649767bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd748fe04232441abb30f153e54f9890": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce050a2ed895498dba3347c1c4bb092d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a94a510c49414b75818b4c1654394703",
            "placeholder": "​",
            "style": "IPY_MODEL_6b62d7166e614b6ead8a0af96758cef1",
            "value": " 116M/116M [00:03&lt;00:00, 41.3MB/s]"
          }
        },
        "cf24681dbccd42f59ffda006ca4cdac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f48649787c3d4f0f8de5d5eb8fdfc31b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca59bd8ff338413c8514ab0eee2d8ec3",
            "value": 1
          }
        },
        "cfa3fef5ad8743228d10e60238d91449": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d276b68035e42d79ec3d6c3600cd125",
            "placeholder": "​",
            "style": "IPY_MODEL_dbe7e052a2994aadac7b883a020cd42f",
            "value": "Downloading data files: 100%"
          }
        },
        "cfa5b162648c4abca773a478c3e3beb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d151de5a1862426f9d3ab2aaae73f4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1837578698f426d8c65a40770a3488c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1dafb9eb15541489d740cbf202fac2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adc06005b98c44f0a6308cbd4f6a3527",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eace7bc2187b4dd0af47dbee9327903a",
            "value": 1
          }
        },
        "d25f24f6c4464900af0369a1d34197af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b7f6b62b45464db85df430da2ab97f",
            "placeholder": "​",
            "style": "IPY_MODEL_dda17487487843c7a86152cde6220a6b",
            "value": "Generating train split: "
          }
        },
        "d265db9a419d4edfbdb91e4bd8f78846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a8de725a934927b52792351e0d5099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d365ebcd816a44da80bc74870dd008bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36c80ffd8824fdb8e1e344f41fa3669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d390110fecc7409291f79bc41e3e7c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4214693adb54e44b31fd40e549802b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4ccb21f87954a31ab7ab0fd7e11a8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4ea11ee38044f7cb7ffe1a5b018bda7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6012c2d60024501a1bd8c529bf055e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ccd976679e45fcbf6d6b5d06360ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71e718353ac40788febf07676b3cb25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72812af3cd8475f8a76a8ff3ec236e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74fd39704b44cea8f012402e7449a80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87e9ee37dfe44bcad7b97ccfef0f5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ce4959b2bc410a8b455eb2adb7ffc9",
            "placeholder": "​",
            "style": "IPY_MODEL_422ac21cdb1d45a8a0814ef00c9769ff",
            "value": "Downloading readme: 100%"
          }
        },
        "d947bfe9101646c9a7222ada482d4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a90b08aaec44d9962e8c090b8d0baa",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70225a6a843d4ccf87d1b43d4cf1895b",
            "value": 125
          }
        },
        "d9a90b08aaec44d9962e8c090b8d0baa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9bcbb8cd61d4fa5b9e0b95304f8969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ea68f6b18c342938de8be19d3896038",
              "IPY_MODEL_0b0c4175d283414ab014c95269b4421b",
              "IPY_MODEL_00c7829ca16746089c8896865f374b1f"
            ],
            "layout": "IPY_MODEL_f9f77be1c3044483bbd3714a5a45e2ad"
          }
        },
        "da3eb201a16240aaa91baf19b49d4209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dab6a9ff832540bfae51a3f0dcfedfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5adcad970e4455cbf797f14e2e5303e",
              "IPY_MODEL_928bc9d9e240469298d2a267fe3b9e65",
              "IPY_MODEL_24e977d511bd4f03bc8d730cd4c86027"
            ],
            "layout": "IPY_MODEL_4b4dae6b5bd5474491e1c86a6e462ebf"
          }
        },
        "dae9d080adfc4bfbba896820bbf57c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "db1f664494c94faf8998df1f25718b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c96dd4ef67f4900af004f322706921f",
            "placeholder": "​",
            "style": "IPY_MODEL_c519b80ce005494caf41456ec90111bf",
            "value": " 27.9k/27.9k [00:00&lt;00:00, 587kB/s]"
          }
        },
        "db7e607a483e49d78b3c9491464490b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ab213f928c43b0a6fb840c03ec05a7",
            "max": 8013769,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_677c94eab4d04efaba8770b32b6e82d5",
            "value": 8013769
          }
        },
        "dbb5a92189d34f4d8571106c29dee036": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbeb2e4f0ca4e3b831fc5f58b883cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "dbe7e052a2994aadac7b883a020cd42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcd68849bd0a44238fbb9bec129b0511": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda17487487843c7a86152cde6220a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de941ef06f9a4974ba4e4075d96d5637": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea6b34486294d388d68aa9ef3aaa281": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70156e5cb144e75b97697a2439d9a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_96e7d97dc8f44c7d873060a89f82ce0e",
            "value": " 440M/440M [00:05&lt;00:00, 85.0MB/s]"
          }
        },
        "df31cc0682014cdb881817de1c02288f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8de4914b3f4c51b4e048f053a0e009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfd3f1f64d81471083416a3e4ca6aa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c9ec9890384cb4b17139a7335e371e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2dfbd412e2c4420931223730a476148": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f772d1181b417e8f3bc2feee4f6e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825fb9aa19594a61b2a779837eb230b4",
              "IPY_MODEL_b076eddbd7a74d5495615776c26a6f3e",
              "IPY_MODEL_75d76bf886514ba5ac9fedee0fcfba8d"
            ],
            "layout": "IPY_MODEL_e9685ee9b4aa47fcb5a3a79261ca87c7"
          }
        },
        "e34566724c6e4598860e77d6b710faf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e362a74248d24aa28ab7dd3500c9d303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f66a8eed1443d099d0fadab83d02e9",
            "placeholder": "​",
            "style": "IPY_MODEL_292c0b150eb84f06a012e2084b035350",
            "value": " 1.05M/? [00:00&lt;00:00, 3.55MB/s]"
          }
        },
        "e3712984d7774865be2c1e97faf82d57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b7f6b62b45464db85df430da2ab97f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46716dcab7c4e5f8477931b7e12ea6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76cddc6d7d04d3fb01c11225ec1b6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e779447c8d8e4578bd3a7747941bfbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bd0a23537441b6a41373c7db399423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bdb5cce9c364437970f01220e5f0aa3",
              "IPY_MODEL_5df7aa079833485bbde65e4658b496e0",
              "IPY_MODEL_e9149263e2264fe6b5e5cb50f67d55c2"
            ],
            "layout": "IPY_MODEL_e3712984d7774865be2c1e97faf82d57"
          }
        },
        "e7cd7488f7264496be788107804bc9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84136de295d4d39b44c908ff2458ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e844aa942c604f17b61375f59aad56f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e891d996e42f425cb2b31d563dfc77ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216e1650231e471fa0d88e3d73bf6da0",
              "IPY_MODEL_d1dafb9eb15541489d740cbf202fac2f",
              "IPY_MODEL_e362a74248d24aa28ab7dd3500c9d303"
            ],
            "layout": "IPY_MODEL_1eb78591c14840daaf6741730f2280f8"
          }
        },
        "e8db7bdb8bf04011874e6bb31570d763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31311fbeb1d49c1a34ce41c4b01c22f",
            "max": 61491876,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba6ff0046c843679c0581a44ec69e1c",
            "value": 61491876
          }
        },
        "e8f710e2dcfc40398ce16a4ac265cc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_177dee7aa0754c7db2b595f83a4eb105",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe3c4d6e4774be691e7c0551fd334ff",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "e9149263e2264fe6b5e5cb50f67d55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab8bf4aa34c5452d8c6d01df44402eea",
            "placeholder": "​",
            "style": "IPY_MODEL_c1ad349038c94c1f9ec7b1d0d7245699",
            "value": " 28.7k/28.7k [00:00&lt;00:00, 559kB/s]"
          }
        },
        "e9685ee9b4aa47fcb5a3a79261ca87c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97d23572a21475fa4b5b9fa4454d4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68db1531b9574e72a2ff0d52995a7347",
            "placeholder": "​",
            "style": "IPY_MODEL_eeafa1a037dd42a88774f76ea6275360",
            "value": " 6.22k/? [00:00&lt;00:00, 91.2kB/s]"
          }
        },
        "e982215023c24a3caf881dd3986cca86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ea00ba0feb164981bdb521803fd29049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ea3b3bc369804d85b562e7b83bc34804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea4024140d39477884175e9aa9c2f796": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eace7bc2187b4dd0af47dbee9327903a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb0aa78ac5ed4e8189871f2dcb7b68d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb77d7017bbd48f6937c38c219acc095": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf0c7ac01e441d68a38cac5fed89d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec12f15c6abf453abab53377bc2e9ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a63b32a25944a0d9b407d8e113cc473",
            "placeholder": "​",
            "style": "IPY_MODEL_39465c30a6d846f2a78d4016152041e4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "ecaeab95cff44076a0a84cca103b6b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc68509c6494c6ebdd22c30ea632bfb",
            "max": 68,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ad09b3ac2d5406caa626954d7dc4b92",
            "value": 68
          }
        },
        "ecf9c5705a7b491c82d4e8b5cbd8c439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeafa1a037dd42a88774f76ea6275360": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef504e4ab1384063bff714e1649e0aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb59704b56142dc82b819e7828ccaf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10d3cde2d7b4121971d8e19e3362b30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f216f345dde54c35abaff30dac041c89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f230ba518eed434fb107f97c66293470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3537b58aca04f398663d6a8f6bd7cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3707c74969e4f6c84d6a36b59d6fa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f511160291e4a4a82f8694772449ea8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91eebca40ce344039704522c4570353c",
            "value": 231508
          }
        },
        "f387685057a6405f86292bd9ce5df000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48649787c3d4f0f8de5d5eb8fdfc31b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f4a51d5c122645a5a58acfbadb0cf752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8631f393c12e4ebaa57838a4f1c1efb0",
            "max": 9832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc7e0e6c4b154e55875c6fddc0aac6f0",
            "value": 9832
          }
        },
        "f4bb56cde5b042e8821ee26d25da4ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe8145192c34433b3140f05b5b2528f",
            "placeholder": "​",
            "style": "IPY_MODEL_3988d9e57bc841b49a5079130f071dfc",
            "value": " 296/408 [00:00&lt;00:00, 1064.07 examples/s]"
          }
        },
        "f53073dd81bf427188a9cfde75c18bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b5f6a6687b34036bd5a87c8b61dc2c3",
              "IPY_MODEL_b0546b4b929f4fe3927af49ab119d99a",
              "IPY_MODEL_37e0abc511f04624986368ef45b50131"
            ],
            "layout": "IPY_MODEL_d365ebcd816a44da80bc74870dd008bd"
          }
        },
        "f54be5e820704ad2b31b6b7a6b946181": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5912ed9e9c944e5ae35be20f0634165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a25f48fd7045d092d4b4b1a66f296c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de941ef06f9a4974ba4e4075d96d5637",
            "placeholder": "​",
            "style": "IPY_MODEL_4b242512f1ca473793bf144e5d062a9b",
            "value": " 0/0 [00:00&lt;?, ? examples/s]"
          }
        },
        "f5e5dd22e0b24a30a485b54dbdacf1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f619ea2b062a4eacb80ade328d56c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6823010dba245d1843a2f324e00c382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f68c38cc7bf84db2ab1540ca985599e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f697e928e02f405d99c43c4b1fd890c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5912ed9e9c944e5ae35be20f0634165",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d86dc22b0747dba72d6aa5fd899df0",
            "value": " 1/1 [00:00&lt;00:00, 33.60it/s]"
          }
        },
        "f6a686a076954e0c9c5d11429a14d582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a320f7b8bba47ddb97d2aff966e162f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e215f7f87fc48bfbb3e74c9c97b23a8",
            "value": 3
          }
        },
        "f6c454dc6dcb4528b7b05b83c72640fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6eac59aef894d88bcae4654df6ef1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08187ae67b63489bba4a7b9c10d4d719",
            "placeholder": "​",
            "style": "IPY_MODEL_379f64826a714ae89a85c265b4937902",
            "value": " 1/1 [00:00&lt;00:00,  1.53it/s]"
          }
        },
        "f7ca459667fe48c2a54d0ca13ccfe114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91738a91e20344f1b848ccc39bd0b686",
              "IPY_MODEL_ae85f3dd9b864de7897e02a2313c8093",
              "IPY_MODEL_e97d23572a21475fa4b5b9fa4454d4cc"
            ],
            "layout": "IPY_MODEL_32f65d2703c048929de10720219fdf53"
          }
        },
        "f81a1dd1a8b547b39297478219b41c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f90ae6d8c7e94e7a970a5b50c7721618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12472278f82a48cfb84182a57092617e",
              "IPY_MODEL_28118200f74e4935b8e87af4a20034c8",
              "IPY_MODEL_4fc404853fe84976afd7674ab97d1533"
            ],
            "layout": "IPY_MODEL_4617c5d3e4df42fe8e6d5220c94e443f"
          }
        },
        "f9d88bd9fdda49bcbf01366f8fe6fab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f77be1c3044483bbd3714a5a45e2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fa205a1da88e418a881efb0963042e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb064cacf0e243299a2d092facae8c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7af49d0afe4ecdaa800be969d5a3e7",
              "IPY_MODEL_560c716068a645d596cc2fe9b886c0ad",
              "IPY_MODEL_08c60bb508854cc9b6772ab78502b6fb"
            ],
            "layout": "IPY_MODEL_e84136de295d4d39b44c908ff2458ba9"
          }
        },
        "fc2d3eb4b1304b97bf336245736983ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d798a40b2a24c4f8ce823023d75ea6a",
              "IPY_MODEL_429379eb4c4f452d94a52521911811a8",
              "IPY_MODEL_49a90c227b9342ddbb670c9fe85591cc"
            ],
            "layout": "IPY_MODEL_843d11a2271246f49dbabe80fc4762d4"
          }
        },
        "fc40e712ccca489e8cb2eaadbc47aa54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87e9ee37dfe44bcad7b97ccfef0f5ff",
              "IPY_MODEL_afd68f4512e045c2bfaa46eb36d4ab5a",
              "IPY_MODEL_db1f664494c94faf8998df1f25718b9f"
            ],
            "layout": "IPY_MODEL_63a2424581894ab48ad61b9f38cc882e"
          }
        },
        "fcb506371e6e4cd2947988d6c7050809": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd04d23b69a545d4acab01dd3046b44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01bc3f5cd2ec4435b5a97c1dbbe7a86e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ef185dc852646fbb92d1eb31981bed0",
            "value": 1
          }
        },
        "fdf37a5ac48c477d99318631238a5756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe156388571b4c63b5fc5f5ca857e522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe784053e3d047758731e6f99283d772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff58b4945b004e9996568c228986d287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe8145192c34433b3140f05b5b2528f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ecd72edd7024c928abac93cca7633c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8551a294d6e848ebb3e2cc651b3daa0b",
              "IPY_MODEL_1fc36937c6ec496a9cd3f1cf39066ffb",
              "IPY_MODEL_c534ba27943d4cd1ab04746e895ac394"
            ],
            "layout": "IPY_MODEL_baf63ae6960f4d68be5aecdb9aa285de"
          }
        },
        "8551a294d6e848ebb3e2cc651b3daa0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_833d0bdc1ba84115b85199198e56cfe4",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e8213df9624001b14d925b82018b99",
            "value": "Downloading readme: 100%"
          }
        },
        "1fc36937c6ec496a9cd3f1cf39066ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fddd931718714d54a2a1b310f5de2beb",
            "max": 5408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71d79fe8de5045efb2d6f5e9653de71e",
            "value": 5408
          }
        },
        "c534ba27943d4cd1ab04746e895ac394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c768181aa5d140cf804d4aeafbfd103e",
            "placeholder": "​",
            "style": "IPY_MODEL_0f78dfdff85f43638d7c07b394f340a8",
            "value": " 5.41k/5.41k [00:00&lt;00:00, 182kB/s]"
          }
        },
        "baf63ae6960f4d68be5aecdb9aa285de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833d0bdc1ba84115b85199198e56cfe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e8213df9624001b14d925b82018b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fddd931718714d54a2a1b310f5de2beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d79fe8de5045efb2d6f5e9653de71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c768181aa5d140cf804d4aeafbfd103e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f78dfdff85f43638d7c07b394f340a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28c201d8b4d84b47977726d6bbffced2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a611080cabe463a8c156fb797eac504",
              "IPY_MODEL_9094d7253c00453f9984521104809c7e",
              "IPY_MODEL_f8b4a2c6d17040c49c4aaf3c053ba88c"
            ],
            "layout": "IPY_MODEL_595db8762907461dab43756c13c372d5"
          }
        },
        "2a611080cabe463a8c156fb797eac504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c05e7787e9483d9be431cb8885c4e2",
            "placeholder": "​",
            "style": "IPY_MODEL_e51b8f78489c47a9a79c06f3eb32eda4",
            "value": "Downloading readme: 100%"
          }
        },
        "9094d7253c00453f9984521104809c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c983680e0824fab964e15b13402258b",
            "max": 486,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31efc8645d854ddf9341d0e1f4540826",
            "value": 486
          }
        },
        "f8b4a2c6d17040c49c4aaf3c053ba88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3949e84ade442c1828471ba0849df8a",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b28a56c22b4f46a702530a3d7ae9f8",
            "value": " 486/486 [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "595db8762907461dab43756c13c372d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c05e7787e9483d9be431cb8885c4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51b8f78489c47a9a79c06f3eb32eda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c983680e0824fab964e15b13402258b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31efc8645d854ddf9341d0e1f4540826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3949e84ade442c1828471ba0849df8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b28a56c22b4f46a702530a3d7ae9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f4ff0b97afc49c5a65c3b5ef5656099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66a7ef4424c34441acc2b4201cc1d14f",
              "IPY_MODEL_95e81df782f94757805a169b734611ec",
              "IPY_MODEL_54d1564c13ef43dc9b5c97522c5973d8"
            ],
            "layout": "IPY_MODEL_3738f31b3ebc4c2b93a678b2b2a44350"
          }
        },
        "66a7ef4424c34441acc2b4201cc1d14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9329eedde6d14ed48ffe2ec2e4990f95",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ea814082974891ab93fd256996b7c6",
            "value": "Downloading builder script: 100%"
          }
        },
        "95e81df782f94757805a169b734611ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f173bb5283044c484a33148e616d542",
            "max": 3789,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56ded92e780748c8942ed7eb5ff33234",
            "value": 3789
          }
        },
        "54d1564c13ef43dc9b5c97522c5973d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea04d2eb176424b8160e452f6a31f4f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f9fc535a10e4fcbba6b41666daf29e0",
            "value": " 3.79k/3.79k [00:00&lt;00:00, 153kB/s]"
          }
        },
        "3738f31b3ebc4c2b93a678b2b2a44350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9329eedde6d14ed48ffe2ec2e4990f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ea814082974891ab93fd256996b7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f173bb5283044c484a33148e616d542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ded92e780748c8942ed7eb5ff33234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aea04d2eb176424b8160e452f6a31f4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9fc535a10e4fcbba6b41666daf29e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c838a0bd327747a4bf1219c1b864a361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f495af78544a457baedaf5f6fb0b7dce",
              "IPY_MODEL_7fee84bb7d8c454bb9b4a295847a706b",
              "IPY_MODEL_e01b8b277f2a460e8388fc71f0622a07"
            ],
            "layout": "IPY_MODEL_da8f5c8f27ca4dcfb9d059a139959c1a"
          }
        },
        "f495af78544a457baedaf5f6fb0b7dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28a2b37ba339456bbba7db989e4ac67f",
            "placeholder": "​",
            "style": "IPY_MODEL_cec8455d549246ff98bb1a568e5e5a3f",
            "value": "Downloading metadata: 100%"
          }
        },
        "7fee84bb7d8c454bb9b4a295847a706b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1008435d5743484580aa54d74b213866",
            "max": 1773,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea40ab309284464fb2d1e8bf03901ed8",
            "value": 1773
          }
        },
        "e01b8b277f2a460e8388fc71f0622a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab81a1ae592d4a87bf394bd558629735",
            "placeholder": "​",
            "style": "IPY_MODEL_6659194808734cda94ab339614ded0a1",
            "value": " 1.77k/1.77k [00:00&lt;00:00, 66.0kB/s]"
          }
        },
        "da8f5c8f27ca4dcfb9d059a139959c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a2b37ba339456bbba7db989e4ac67f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec8455d549246ff98bb1a568e5e5a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1008435d5743484580aa54d74b213866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea40ab309284464fb2d1e8bf03901ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab81a1ae592d4a87bf394bd558629735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6659194808734cda94ab339614ded0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675e4bba675f4add809495c61a69ffd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1af85f5380a349f29d9260a216ffbeba",
              "IPY_MODEL_35fa4715503b4b2aa5fab358f64d1f34",
              "IPY_MODEL_7a9e6cd46a5843b189f63c45e57e9496"
            ],
            "layout": "IPY_MODEL_9b179ae2db3044db97c466a74243cf50"
          }
        },
        "1af85f5380a349f29d9260a216ffbeba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8075f31cedc24f979cf1a057575edc65",
            "placeholder": "​",
            "style": "IPY_MODEL_e47fb85db6f84544a79c4f5b9dad4ae0",
            "value": "Downloading readme: 100%"
          }
        },
        "35fa4715503b4b2aa5fab358f64d1f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a1dbbd108646e594c7afb4ecd864be",
            "max": 13596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe0b1080f0d74ff681a6529d046a4932",
            "value": 13596
          }
        },
        "7a9e6cd46a5843b189f63c45e57e9496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcae0738b6cf40c4bab01e512adc18b1",
            "placeholder": "​",
            "style": "IPY_MODEL_f0742346b8bf4022a9583f5258c6a63f",
            "value": " 13.6k/13.6k [00:00&lt;00:00, 688kB/s]"
          }
        },
        "9b179ae2db3044db97c466a74243cf50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8075f31cedc24f979cf1a057575edc65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47fb85db6f84544a79c4f5b9dad4ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49a1dbbd108646e594c7afb4ecd864be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0b1080f0d74ff681a6529d046a4932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcae0738b6cf40c4bab01e512adc18b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0742346b8bf4022a9583f5258c6a63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0ff34de926f4c0d8a4aba8c00356ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcd9c59700d24bc1a46c454e559960b5",
              "IPY_MODEL_d11a9fd00ce741a6b89343c33b83026c",
              "IPY_MODEL_e933054cc0904f48b4691db57bafc358"
            ],
            "layout": "IPY_MODEL_a818dc39d66a40fab33efcba4aa497b8"
          }
        },
        "dcd9c59700d24bc1a46c454e559960b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a63ec248c0cc40b1b546d3a434632621",
            "placeholder": "​",
            "style": "IPY_MODEL_24a0eb797aa4418daebc63c29ab03395",
            "value": "Downloading readme: 100%"
          }
        },
        "d11a9fd00ce741a6b89343c33b83026c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbacecf8618c4ee185e5fd9afd2e1703",
            "max": 4949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b32b93922b6c48ec88cf40ee16b5ccab",
            "value": 4949
          }
        },
        "e933054cc0904f48b4691db57bafc358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95dac27cd28b4f48b802605853109dcd",
            "placeholder": "​",
            "style": "IPY_MODEL_15fe2a8ef27a4a09b16905b070a2d1bf",
            "value": " 4.95k/4.95k [00:00&lt;00:00, 112kB/s]"
          }
        },
        "a818dc39d66a40fab33efcba4aa497b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63ec248c0cc40b1b546d3a434632621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a0eb797aa4418daebc63c29ab03395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbacecf8618c4ee185e5fd9afd2e1703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32b93922b6c48ec88cf40ee16b5ccab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95dac27cd28b4f48b802605853109dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15fe2a8ef27a4a09b16905b070a2d1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a442a786e1364627a3ca7279b5490faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_509d56758ff9483bb02acba1730f6ff0",
              "IPY_MODEL_b4ce72155770425f948cefc0f34bff28",
              "IPY_MODEL_5173fa33e14a4277af0a9bc7b0f58e2c"
            ],
            "layout": "IPY_MODEL_a6a1c946c3a0402e91afe910089db701"
          }
        },
        "509d56758ff9483bb02acba1730f6ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01fe3d374b854114bdf0b56ea578862e",
            "placeholder": "​",
            "style": "IPY_MODEL_0567e8d57a214d88b1167d6166a4eba3",
            "value": "Downloading builder script: 100%"
          }
        },
        "b4ce72155770425f948cefc0f34bff28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef478c42e6e44bbb2e51b990c8cf258",
            "max": 5758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65609d903bcb475bbee60ff6cd268924",
            "value": 5758
          }
        },
        "5173fa33e14a4277af0a9bc7b0f58e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5379cf0af15244749db8561aa398f42a",
            "placeholder": "​",
            "style": "IPY_MODEL_aef562fe4c064fb090a8b4d1578fecbb",
            "value": " 5.76k/5.76k [00:00&lt;00:00, 84.2kB/s]"
          }
        },
        "a6a1c946c3a0402e91afe910089db701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01fe3d374b854114bdf0b56ea578862e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0567e8d57a214d88b1167d6166a4eba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef478c42e6e44bbb2e51b990c8cf258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65609d903bcb475bbee60ff6cd268924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5379cf0af15244749db8561aa398f42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef562fe4c064fb090a8b4d1578fecbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46bfc1bf0bca4dd7995d50aac0740aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d70f3f3bc1094e8f9f9d65ef98307d1f",
              "IPY_MODEL_6cb29b3930e74da1addfd7e01b480b9e",
              "IPY_MODEL_4ef7438078364ae78c49e774d77b7d1c"
            ],
            "layout": "IPY_MODEL_4bf0047d256645d1962d1d2980e844af"
          }
        },
        "d70f3f3bc1094e8f9f9d65ef98307d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac893ea96eb14ce196b8d7bb16bb7cbc",
            "placeholder": "​",
            "style": "IPY_MODEL_c7f0033a9c2547c39f23d802e5fb2762",
            "value": "Downloading readme: 100%"
          }
        },
        "6cb29b3930e74da1addfd7e01b480b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb4eeb1a53d44a49d37a492e2492678",
            "max": 6243,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a52edda927341dd808210e14b9a21bb",
            "value": 6243
          }
        },
        "4ef7438078364ae78c49e774d77b7d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd5815d04cb548cba6d40c9ca7eb7764",
            "placeholder": "​",
            "style": "IPY_MODEL_7743b1759eae4a8bb92245f70ea884c7",
            "value": " 6.24k/6.24k [00:00&lt;00:00, 93.1kB/s]"
          }
        },
        "4bf0047d256645d1962d1d2980e844af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac893ea96eb14ce196b8d7bb16bb7cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f0033a9c2547c39f23d802e5fb2762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eb4eeb1a53d44a49d37a492e2492678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a52edda927341dd808210e14b9a21bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd5815d04cb548cba6d40c9ca7eb7764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7743b1759eae4a8bb92245f70ea884c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f239a76bd9b4660ac3c5ab58313eeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba28cb7c70bd4b0e85f8eef8bd9c4d73",
              "IPY_MODEL_3a741126430d462baa81186128dfad4b",
              "IPY_MODEL_6a3755e2b13e4cf99748950698d3b495"
            ],
            "layout": "IPY_MODEL_ca777753c26146a9a91182e8efadc8c6"
          }
        },
        "ba28cb7c70bd4b0e85f8eef8bd9c4d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_266a7d5ca58441c69fb05fecb411dc11",
            "placeholder": "​",
            "style": "IPY_MODEL_fb4943bf76a54fc7b210b725c46ec061",
            "value": "Downloading readme: 100%"
          }
        },
        "3a741126430d462baa81186128dfad4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90cd4e91692b47b9bae0815044a0c4a3",
            "max": 4164,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f451287caf474e1f8dbf8d92212fe25a",
            "value": 4164
          }
        },
        "6a3755e2b13e4cf99748950698d3b495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a4d1bf5a3a450ab1e013589cb8d039",
            "placeholder": "​",
            "style": "IPY_MODEL_d59c376f8a7a46adb6f4de05630af5f7",
            "value": " 4.16k/4.16k [00:00&lt;00:00, 83.9kB/s]"
          }
        },
        "ca777753c26146a9a91182e8efadc8c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266a7d5ca58441c69fb05fecb411dc11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb4943bf76a54fc7b210b725c46ec061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90cd4e91692b47b9bae0815044a0c4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f451287caf474e1f8dbf8d92212fe25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46a4d1bf5a3a450ab1e013589cb8d039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59c376f8a7a46adb6f4de05630af5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "746ea389134e43a19e5a4e67c657f932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a26750dadb9248ad954d8e1addc839cf",
              "IPY_MODEL_601fb20facea4991a61721f32db43f50",
              "IPY_MODEL_caa0cd0225544234929d3c7b141a9351"
            ],
            "layout": "IPY_MODEL_e96a022d39584d4ab8e61c0d62e2c7ef"
          }
        },
        "a26750dadb9248ad954d8e1addc839cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd74402341554d19a884aa27632a7938",
            "placeholder": "​",
            "style": "IPY_MODEL_eb67c2a41012497595c66df5621a55ff",
            "value": "Downloading readme: 100%"
          }
        },
        "601fb20facea4991a61721f32db43f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32130426dda343cd9e684a2344640706",
            "max": 5266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cceb2e6641d34edfb0e46f534f40c835",
            "value": 5266
          }
        },
        "caa0cd0225544234929d3c7b141a9351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9554e2ca1f4b6c92262606f7afd6f7",
            "placeholder": "​",
            "style": "IPY_MODEL_2d7408a9420d44fba968912aaadb815c",
            "value": " 5.27k/5.27k [00:00&lt;00:00, 278kB/s]"
          }
        },
        "e96a022d39584d4ab8e61c0d62e2c7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd74402341554d19a884aa27632a7938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb67c2a41012497595c66df5621a55ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32130426dda343cd9e684a2344640706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cceb2e6641d34edfb0e46f534f40c835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d9554e2ca1f4b6c92262606f7afd6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7408a9420d44fba968912aaadb815c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dccc6eb38ac74f02989fa5720c3379f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d0abe6ee1c4482cb8aa9a51b0a16923",
              "IPY_MODEL_0e578c34a0744116b5a5a49af5e4c83c",
              "IPY_MODEL_f2605e9ee97a4adeb4493d914d9fd4c0"
            ],
            "layout": "IPY_MODEL_929303df0e824d6f806b4b28e3fca015"
          }
        },
        "8d0abe6ee1c4482cb8aa9a51b0a16923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f202ac68b744047824a047b35b46ca2",
            "placeholder": "​",
            "style": "IPY_MODEL_eaae9abe7e404ff6b8c6fd0f42473ec0",
            "value": "Downloading readme: 100%"
          }
        },
        "0e578c34a0744116b5a5a49af5e4c83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ae4f6c0316f4e0c9b13a75dc7554433",
            "max": 4283,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08790cac4e344781b209462cb6c29627",
            "value": 4283
          }
        },
        "f2605e9ee97a4adeb4493d914d9fd4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4f507a7281a4f7283e5e0f91e7703da",
            "placeholder": "​",
            "style": "IPY_MODEL_ae3bee755e4047aebf584bafee614f43",
            "value": " 4.28k/4.28k [00:00&lt;00:00, 199kB/s]"
          }
        },
        "929303df0e824d6f806b4b28e3fca015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f202ac68b744047824a047b35b46ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaae9abe7e404ff6b8c6fd0f42473ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ae4f6c0316f4e0c9b13a75dc7554433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08790cac4e344781b209462cb6c29627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4f507a7281a4f7283e5e0f91e7703da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae3bee755e4047aebf584bafee614f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fb51c9851be49f189d5a268706ce43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6f03c945886482c8c1b8ba90cc6ab49",
              "IPY_MODEL_f515f4f5b0234c569b2d4d39bf9b1ffd",
              "IPY_MODEL_6f2a6e7619b340dcabc40f70686c9e94"
            ],
            "layout": "IPY_MODEL_435f4b7337764b608fae8d398477983e"
          }
        },
        "d6f03c945886482c8c1b8ba90cc6ab49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0afd44b499a4d72bf05127d9b9d289a",
            "placeholder": "​",
            "style": "IPY_MODEL_658afb168e0f441dbbedbe466e0fa6a9",
            "value": "Downloading builder script: 100%"
          }
        },
        "f515f4f5b0234c569b2d4d39bf9b1ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5673b8be254271b35bbc226c43346a",
            "max": 8425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84f6fffcfd8c4811a6318e9214fcef91",
            "value": 8425
          }
        },
        "6f2a6e7619b340dcabc40f70686c9e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e96be3c1cb4ab6a524e6de8175fa73",
            "placeholder": "​",
            "style": "IPY_MODEL_12d7a97bc95c4262b7c75267d312f510",
            "value": " 8.43k/8.43k [00:00&lt;00:00, 402kB/s]"
          }
        },
        "435f4b7337764b608fae8d398477983e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0afd44b499a4d72bf05127d9b9d289a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658afb168e0f441dbbedbe466e0fa6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac5673b8be254271b35bbc226c43346a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f6fffcfd8c4811a6318e9214fcef91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69e96be3c1cb4ab6a524e6de8175fa73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d7a97bc95c4262b7c75267d312f510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83d4d749ca174bd591cfdf45fef6935b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38d1e3b06f8347bd95a107e83c9e713b",
              "IPY_MODEL_241e42019ecc4786987e6086d9ebf44a",
              "IPY_MODEL_c576aaeea0cc4f3588e5df6b857350d3"
            ],
            "layout": "IPY_MODEL_c6eac3fed56947ccb3650cc8ccda8727"
          }
        },
        "38d1e3b06f8347bd95a107e83c9e713b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea02c34d69404d5b8ed90ef0c22e1958",
            "placeholder": "​",
            "style": "IPY_MODEL_a343c3d004be4f53a8170537a53f34f9",
            "value": "Downloading metadata: 100%"
          }
        },
        "241e42019ecc4786987e6086d9ebf44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_234dee5fb2114d7da17e156ffb705e6b",
            "max": 7520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f597bca895584eb58306488899ae6e34",
            "value": 7520
          }
        },
        "c576aaeea0cc4f3588e5df6b857350d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2783284dd5d145dfbc24b3e703122abb",
            "placeholder": "​",
            "style": "IPY_MODEL_5b12243b856442e784c19b26e6ae3069",
            "value": " 7.52k/7.52k [00:00&lt;00:00, 424kB/s]"
          }
        },
        "c6eac3fed56947ccb3650cc8ccda8727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea02c34d69404d5b8ed90ef0c22e1958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a343c3d004be4f53a8170537a53f34f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "234dee5fb2114d7da17e156ffb705e6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f597bca895584eb58306488899ae6e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2783284dd5d145dfbc24b3e703122abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b12243b856442e784c19b26e6ae3069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "740c622838294ecb9e647a832064b1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f560ac80fc5e4422a43102db965d8c55",
              "IPY_MODEL_c39c40ad52e443e083130378c354775b",
              "IPY_MODEL_a93691ca1f1f422dbf1548543de23a00"
            ],
            "layout": "IPY_MODEL_8bdb3c00c1d243c1a118e9501e51a9ae"
          }
        },
        "f560ac80fc5e4422a43102db965d8c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f605d617b2d94d3d94da2579f0ff6fdf",
            "placeholder": "​",
            "style": "IPY_MODEL_7187834292a54fc480a72f8f0be77db8",
            "value": "Downloading readme: 100%"
          }
        },
        "c39c40ad52e443e083130378c354775b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ec492a404e417c90039e544ed74723",
            "max": 9339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d46df2d332d640469c0d21b4c94c3e59",
            "value": 9339
          }
        },
        "a93691ca1f1f422dbf1548543de23a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a2af9c82a7d4cc7bee2d8d5e3bf48b5",
            "placeholder": "​",
            "style": "IPY_MODEL_74fa5c65c69346b38ec9688b8bc67b5a",
            "value": " 9.34k/9.34k [00:00&lt;00:00, 423kB/s]"
          }
        },
        "8bdb3c00c1d243c1a118e9501e51a9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f605d617b2d94d3d94da2579f0ff6fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7187834292a54fc480a72f8f0be77db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ec492a404e417c90039e544ed74723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46df2d332d640469c0d21b4c94c3e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a2af9c82a7d4cc7bee2d8d5e3bf48b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74fa5c65c69346b38ec9688b8bc67b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "169b2f6b694a40529c890c917a137084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8afb91f12f494343811a93619fb60e9b",
              "IPY_MODEL_6a4fa34d0af34da591623b6bb3e4a984",
              "IPY_MODEL_3819209218114aa1815307413c47a358"
            ],
            "layout": "IPY_MODEL_0e63c6878ab04842b0e0e97f6645bbae"
          }
        },
        "8afb91f12f494343811a93619fb60e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da591812b8b487a98229bf048d8eb8b",
            "placeholder": "​",
            "style": "IPY_MODEL_42560b42979344dca72e9ed1d723dc8e",
            "value": "Downloading readme: 100%"
          }
        },
        "6a4fa34d0af34da591623b6bb3e4a984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c127886375e54fcbb03fbdf95f8b38c7",
            "max": 6266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_083b5fc625bb4f818a81ec7164b911e6",
            "value": 6266
          }
        },
        "3819209218114aa1815307413c47a358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a227b8b562fb438f9fa53c52a61a8c86",
            "placeholder": "​",
            "style": "IPY_MODEL_0d18b91afafb4ab589a64cd73bdaa315",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 333kB/s]"
          }
        },
        "0e63c6878ab04842b0e0e97f6645bbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da591812b8b487a98229bf048d8eb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42560b42979344dca72e9ed1d723dc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c127886375e54fcbb03fbdf95f8b38c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083b5fc625bb4f818a81ec7164b911e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a227b8b562fb438f9fa53c52a61a8c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d18b91afafb4ab589a64cd73bdaa315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7907f0448ac24d0ab68922eab2180309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9af957b0c234764978fbec13325c5cf",
              "IPY_MODEL_4f489eeaf5bd42d688cb208f9b926283",
              "IPY_MODEL_5be4ffb23c714749a5eddca7c928589a"
            ],
            "layout": "IPY_MODEL_177528ee59df40bfbfc9566e7a1def79"
          }
        },
        "d9af957b0c234764978fbec13325c5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ed13dc26cf4ddeaa5963ab8c1caa82",
            "placeholder": "​",
            "style": "IPY_MODEL_ab6bfa3295464a78b44aa7f6271c72da",
            "value": "Downloading builder script: 100%"
          }
        },
        "4f489eeaf5bd42d688cb208f9b926283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5ae80299f54c1693938a7ce6f68572",
            "max": 8737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39841995387741b4baea5de2b66af81b",
            "value": 8737
          }
        },
        "5be4ffb23c714749a5eddca7c928589a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473efafc58f5482295145a31a6a3ff93",
            "placeholder": "​",
            "style": "IPY_MODEL_375bdb5429c049049542fcbd2693f688",
            "value": " 8.74k/8.74k [00:00&lt;00:00, 330kB/s]"
          }
        },
        "177528ee59df40bfbfc9566e7a1def79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ed13dc26cf4ddeaa5963ab8c1caa82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab6bfa3295464a78b44aa7f6271c72da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e5ae80299f54c1693938a7ce6f68572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39841995387741b4baea5de2b66af81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "473efafc58f5482295145a31a6a3ff93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375bdb5429c049049542fcbd2693f688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9207b345df8648df9f6741d3c750ee58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7958d26a685425d8224454e0cc30385",
              "IPY_MODEL_ac83b7d0740f489daa469558926d9dda",
              "IPY_MODEL_773fe8319423428093600b7a97a2f89c"
            ],
            "layout": "IPY_MODEL_e6a6f345fdb549f890bf27b5be269d6a"
          }
        },
        "d7958d26a685425d8224454e0cc30385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea7a5c9fb470492f857abec551356016",
            "placeholder": "​",
            "style": "IPY_MODEL_9de3b861fe7141bfa7ef73e98e49a761",
            "value": "Downloading metadata: 100%"
          }
        },
        "ac83b7d0740f489daa469558926d9dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e68ac35d0e7b430c890279c2d99198cc",
            "max": 38552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cd9d78ab7f54cd7b9404ded21e7a66f",
            "value": 38552
          }
        },
        "773fe8319423428093600b7a97a2f89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f181f29b47854712bd566a9470680b58",
            "placeholder": "​",
            "style": "IPY_MODEL_ff6f8e3e9ec74ad894de1e4e634fef5b",
            "value": " 38.6k/38.6k [00:00&lt;00:00, 593kB/s]"
          }
        },
        "e6a6f345fdb549f890bf27b5be269d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7a5c9fb470492f857abec551356016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de3b861fe7141bfa7ef73e98e49a761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e68ac35d0e7b430c890279c2d99198cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd9d78ab7f54cd7b9404ded21e7a66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f181f29b47854712bd566a9470680b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6f8e3e9ec74ad894de1e4e634fef5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e77eb9d9d55a4db0ab97fb23186f0d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e14c758d9a464f9daf7c712d3e2a7e60",
              "IPY_MODEL_7ee470eee65f4309b85681afee9a8f97",
              "IPY_MODEL_c06b49f9451d430f987b123438b53ca1"
            ],
            "layout": "IPY_MODEL_656c9027ff994a29be7dc36ad932994e"
          }
        },
        "e14c758d9a464f9daf7c712d3e2a7e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7e6a2db63246d2a7cb4639ca804188",
            "placeholder": "​",
            "style": "IPY_MODEL_cdcd553dadff4dd2a23df9f1424b56bd",
            "value": "Downloading extra modules: 100%"
          }
        },
        "7ee470eee65f4309b85681afee9a8f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e8d30c4d4c462da677a7073a726f85",
            "max": 26270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_985f0c26ea9f4921b5050857ca38bc15",
            "value": 26270
          }
        },
        "c06b49f9451d430f987b123438b53ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_798b89ccec8845bdb293709f22f15617",
            "placeholder": "​",
            "style": "IPY_MODEL_c8cbc5da6f30420d9a211d406c050adb",
            "value": " 26.3k/26.3k [00:00&lt;00:00, 792kB/s]"
          }
        },
        "656c9027ff994a29be7dc36ad932994e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7e6a2db63246d2a7cb4639ca804188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdcd553dadff4dd2a23df9f1424b56bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e8d30c4d4c462da677a7073a726f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "985f0c26ea9f4921b5050857ca38bc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "798b89ccec8845bdb293709f22f15617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cbc5da6f30420d9a211d406c050adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31068127c0e146558d579218a1238423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d69a6fd1e4a4aa39891847877cb8a0e",
              "IPY_MODEL_700bcbfdc23d4b15964c418a3bbe6495",
              "IPY_MODEL_04f93ffee13740b2b7f47b7221f11109"
            ],
            "layout": "IPY_MODEL_76210af5255c4b509a77777eab64a930"
          }
        },
        "4d69a6fd1e4a4aa39891847877cb8a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c526b7e1224145318c3cc055ccef9797",
            "placeholder": "​",
            "style": "IPY_MODEL_1579dcb354fe45b4b2a2a20ebbe02143",
            "value": "Downloading builder script: 100%"
          }
        },
        "700bcbfdc23d4b15964c418a3bbe6495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b614fef1b624d7caf53b692dcd5a8ad",
            "max": 1893,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccdecddef4224dd3ac04098e4e217d43",
            "value": 1893
          }
        },
        "04f93ffee13740b2b7f47b7221f11109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46b1a73c1cf544afb65f2a0ec8376e62",
            "placeholder": "​",
            "style": "IPY_MODEL_96b9def9783645c096485761baf8c5dc",
            "value": " 1.89k/1.89k [00:00&lt;00:00, 74.7kB/s]"
          }
        },
        "76210af5255c4b509a77777eab64a930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c526b7e1224145318c3cc055ccef9797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1579dcb354fe45b4b2a2a20ebbe02143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b614fef1b624d7caf53b692dcd5a8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccdecddef4224dd3ac04098e4e217d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46b1a73c1cf544afb65f2a0ec8376e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b9def9783645c096485761baf8c5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a52234530a64c05b1a8c57c4d4c4868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_270f07b0f48b4fb28948a6dd1e431ca7",
              "IPY_MODEL_c024c9065fd0468fa4d558aff8e1a4df",
              "IPY_MODEL_c76d11293e1f473f8773ca211d7b4a0e"
            ],
            "layout": "IPY_MODEL_0566161de3434736bb0bd9c174ee8266"
          }
        },
        "270f07b0f48b4fb28948a6dd1e431ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509332c6fa4142e3a0aee21b4216499b",
            "placeholder": "​",
            "style": "IPY_MODEL_ae62d10114dd43ceb12078f221b83aaf",
            "value": "Downloading builder script: 100%"
          }
        },
        "c024c9065fd0468fa4d558aff8e1a4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebaec37eab474bdc9bc4036feb149a4a",
            "max": 5110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4332f096643e46c3bc2a54e5bd167874",
            "value": 5110
          }
        },
        "c76d11293e1f473f8773ca211d7b4a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f35e135e2c44365ad09be201437577d",
            "placeholder": "​",
            "style": "IPY_MODEL_c08b8363c8884d6e90e1656fff3dac78",
            "value": " 5.11k/5.11k [00:00&lt;00:00, 196kB/s]"
          }
        },
        "0566161de3434736bb0bd9c174ee8266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509332c6fa4142e3a0aee21b4216499b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae62d10114dd43ceb12078f221b83aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebaec37eab474bdc9bc4036feb149a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4332f096643e46c3bc2a54e5bd167874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f35e135e2c44365ad09be201437577d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c08b8363c8884d6e90e1656fff3dac78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68eb6da6255c4721bfc99ec0efacbc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33dec1672e2841438b9a9147aedc8816",
              "IPY_MODEL_29c4097638f141759c5c7393059dac1c",
              "IPY_MODEL_ed5d1d7caea34bd580ec3019bf3c3de2"
            ],
            "layout": "IPY_MODEL_d89694a7f84e4b068c587ae262ca9692"
          }
        },
        "33dec1672e2841438b9a9147aedc8816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38af96d518154547ae628ab00cba2f94",
            "placeholder": "​",
            "style": "IPY_MODEL_38aad5870af84aec897694c8c302d6f5",
            "value": "Downloading metadata: 100%"
          }
        },
        "29c4097638f141759c5c7393059dac1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e232fbef2a944e788ca3b999b62385f",
            "max": 2037,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1edf1e5c06724474bf893c10d695ecbb",
            "value": 2037
          }
        },
        "ed5d1d7caea34bd580ec3019bf3c3de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a9fe64cccb4d16b9cbaeda0b154f61",
            "placeholder": "​",
            "style": "IPY_MODEL_1ea29188c7bc46b0b722618e5607339a",
            "value": " 2.04k/2.04k [00:00&lt;00:00, 86.3kB/s]"
          }
        },
        "d89694a7f84e4b068c587ae262ca9692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38af96d518154547ae628ab00cba2f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38aad5870af84aec897694c8c302d6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e232fbef2a944e788ca3b999b62385f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1edf1e5c06724474bf893c10d695ecbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5a9fe64cccb4d16b9cbaeda0b154f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea29188c7bc46b0b722618e5607339a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1535ed154ef14aa19d3f0fe429391ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbca09626e6d4343be0afa31ca017a63",
              "IPY_MODEL_a74bad864878448a80a327805ee508a6",
              "IPY_MODEL_ab4bc42d4842453e8fee047fa038f918"
            ],
            "layout": "IPY_MODEL_ed86fcfa873844e8aa2776417b0aa9fe"
          }
        },
        "cbca09626e6d4343be0afa31ca017a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eac936319dd24c79a9d1c1372c8185e9",
            "placeholder": "​",
            "style": "IPY_MODEL_380af89beabf46c596bd8b8f8238f1d1",
            "value": "Downloading readme: 100%"
          }
        },
        "a74bad864878448a80a327805ee508a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c1fac8ee114eef924b9feca7ac6296",
            "max": 10877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cee7dfe1b9e9457fa7194b0cc4b12161",
            "value": 10877
          }
        },
        "ab4bc42d4842453e8fee047fa038f918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bbab6e00879438d9cd08084eee39a24",
            "placeholder": "​",
            "style": "IPY_MODEL_e6f70e92809b4b428c06e46b750aa504",
            "value": " 10.9k/10.9k [00:00&lt;00:00, 442kB/s]"
          }
        },
        "ed86fcfa873844e8aa2776417b0aa9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac936319dd24c79a9d1c1372c8185e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "380af89beabf46c596bd8b8f8238f1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2c1fac8ee114eef924b9feca7ac6296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cee7dfe1b9e9457fa7194b0cc4b12161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bbab6e00879438d9cd08084eee39a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f70e92809b4b428c06e46b750aa504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}